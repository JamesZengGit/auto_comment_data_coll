general
good
practice
strings
several
places
unnamed
strings
e
concat-ing
name
next
person
code
few
different
places
simple
script
small
team
huge
deal
larger
production
environment
habit
technical
debt
other
thing
variables
single
dict
additional
text
easier
whole
output
looks
Very
comment
e
errors
=
[
]
msg
=
]
line
=
e
]
+
matter
convention
better
+
e
]
clearer
Anyway
error-message
code
cleaner
f-strings
people
simple
templating
package
function
f-strings
whole
error
msg
place
|
linum
|
col
colnum
\n
\n
message
\n
|
severity
other
comment
format
code
readable
maintainable
reason
comment
e.g
aborts
long-living
connections
python
cluster_client_options
retry-on-timeout
]
=
True
simpler
PID
process
startup
check
PID
file
provision
launch
subcommand
way
simpler
integration
test
integration-test.sh
integration
test
lines
provision
distribution-version=6.8.0
car=4gheap
provisioner-id=
PROVISIONER_ID
check
node
reachable
HTTP
provisioner-id=
PROVISIONER_ID
bad
Python
minimum
version
requirement
[
standard
library
]
https
//docs.python.org/3/library/stdtypes.html
str.removeprefix
TODO
code
nit
*
*
*
JAVA_HOME
minor
comment
.format
consistency
forwards
meta-data
*
*
valid
earlier
commit
comment
Thanks
aware
code
comment
parameterless
version
parameterized
versions
track
ok.
nit
little
method
name
capitalization
implementation
clear
sure
docstring
useful
Might
good
info
comments
QueryEncryptionStatus
volume
type
Please
test
case
scenario
Hmm
important
installed
physical
memory
size
/proc/meminfo
MemTotal
xxxxxxxx
kB
good
formula
threshold
information
Please
[
]
http
//unix.stackexchange.com/questions/199482/does-proc-pid-status-always-use-kb
Hosung
issue
Amount
memory
mdsd
restart
PublicConfig
parameter
something
hard-coded
good
idea
small
VMs
A1
lot
memory
config
parameter
sounds
good
Good
point
KB
caller
conversion
Thanks
only
place
extension
publicSettings
JSON
issue
if/when
want
feature
Please
note
first
step
self-mitigate
rare
occasions
VmSize
relevant
measure
RSS
active
memory
VmSize
issue
overall
system
health
reason
other
VmSize
aggressive
OK
folks
good
isSuccess=True
Enable
success
rate
purist
actual
extension
operation
type
success=true
more
comment
extension
op
type
auto-restart
closest
HeartBeat
success=true
Thanks
series
refactorings
diagnostic.py
more
issue/comment
non-pythonic
monolithic
complaints
something
near
future
documentation
]
https
//en.opensuse.org/SDB
Find_openSUSE_version
first
lines
/etc/os-release
NAME
VERSION
order
NAME
VERSION
[
human-readable
fields
https
//en.opensuse.org/SDB
Find_openSUSE_version
ID
VERSION_ID
need
version
control
Remove
line
reference
tests
comment
to-do
item
samples
necessary
comment
version
control
same
other
line
changes
backup
old
fstab
entry
Disable
Encryption
Will
comments
nit
due
low
Thanks
clarification
obvious
meaning
instanced
dictionary
above
boolean
flag
duplicate
string
constants
possible
Well
course
right
way
Python
constants
strings
only
comment
beginning
Builtin.py
MIT
license
statement
attributes
constants
meaning
future
meantime
comment
introductory
comments
PR
module
active
result
PR
Unit
tests
code
ready
integration
significant
comment
beginning
Builtin.py
provider
second
check
values
flatten_multi_geoms
colors
None
colors
[
None
]
*
len
geoms
values
None
data
geom
data
Again
comment
sure
TODO
items
TODO
pygeos
issues
familiar
code
impossible
GeocodeFarm
API
key
higher
number
requests
second
available
slow
anything
below
random
selections
comments
collection
exp_colors
segfault
happier
pygeos
side
set
empty
geometries
None
indexing
issue
mention
upstream
suggestion
def
_convert_to_wkb
gdf
geom_name
👍
check
specific
error
AssertionError
more
explicit
geom_types
raise
TODO
comment
other
PR
_Geometry
Collection_
Multi-
geometry
So
GeometryCollections
care
collection
Multi-
Todo
comment
suggestion
use
WKT
geometries
pytest.warns
FutureWarning
match=
spatial
index
empty
message
Sorry
match=
suggestion
good
idea
specific
add
message=
spatial
index
empty
good
docstring
empty
geometries
empty
tree
thoughts
format
CRS
other
day
interests
redundancy
interoperability
helpful
geoparquet
metadata
standard
definitions
formats
CRS
WKT
PROJ
authority
code
i.e
EPSG
code
something
capture
CRS
self.crs
crs
=
pyproj.CRS.from_user_input
self.crs
crs
=
assign
CRS
data
new
metadata
CRS
crs
crs_val
=
wkt
crs.to_wkt
proj
crs.to_dict
auth
auth_name
epsg
auth_code
crs.to_epsg
min_confidence=0
geometry_metadata
[
geometry_fields
]
[
crs
=
PS
thank
work
PR
@
brendan-ward
PPS
familiar
PR
review
process
comments
future
thing
worth
kind
private
pandas
thing
validate_dataframe
import
checking
convenient
..
same
>
>
df.dtypes.loc
[
geometry
]
.tolist
<
geopandas.array.GeometryDtype
object
>
]
>
>
>
df.dtypes.loc
[
geometry
]
.index.tolist
]
case
name
string
jorisvandenbossche
geometry
columns
same
names
deep
copy
DataFrame
df
shallow
copy
original
tests
sure
original
@
jorisvandenbossche
suggestion
fine
index
data
frame
parquet
file
[
col
]
=
GeoSeries
from_wkb
df
[
col
]
.values
index
data
frame
>
>
print
df
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
File
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/core/frame.py
line
__repr__
show_dimensions=show_dimensions
File
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/core/frame.py
line
formatter.to_string
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/io/formats/format.py
line
strcols
=
self._to_str_columns
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/io/formats/format.py
line
_to_str_columns
fmt_values
self._format_col
i
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/io/formats/format.py
line
_format_col
decimal=self.decimal
File
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/io/formats/format.py
line
format_array
return
fmt_obj.get_result
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/io/formats/format.py
line
get_result
fmt_values
self._format_strings
/Users/bcward/.local/share/virtualenvs/geopandas-3VgNznKR/lib/python3.7/site-packages/pandas/io/formats/format.py
line
_format_strings
values._formatter
boxed=True
/Users/bcward/projects/geopandas/geopandas/array.py
line
_formatter
xmin
ymin
xmax
ymax
=
~self.isna
[
:10
]
File
/Users/bcward/projects/geopandas/geopandas/array.py
line
total_bounds
b
[
]
.min
minx
IndexError
many
indices
array
GeoSeries
looks
valid
data
frame
from_wkb
reason
check_like
column
order
suggestion
import
rtree.index
ToblerityRtreeIndex
aliasing
array
Series
wrong
non-default
index
Similar
raw
results
inputs
underlying
index
query_bulk
returns
index
position
ndarray
values
index
values
series
index
Same
indexes
tree
geometries
use
/
AttributeError
more
explicit
handling
supported
types
better
Untested
code
example
index
None
isinstance
geometry
GeoSeries
geometry
=
geometry.values.data
index
=
geometry.index
elif
isinstance
geometry
GeometryArray
geometry
geometry.data
isinstance
geometry
np.ndarray
raise
ValueError
=
.query_bulk
geometry
predicate
original
indices
index
None
res
]
=
index
[
]
]
]
=
self.ids
res
]
]
performance
many
comparisons
thoughts
tree
geometries
input
geometries
case
multiple
input
geometries
same
tree
geometries
datasets
sure
general
solution
best
datasets
Other
things
lines
geometry
threshold
geometry
number
matches
single
comparison
Use
getattr
masks
operation
bit
use
intersects
left
side
tree
geom
geom
obvious
further
explanation
comment
Test
prepared
tree
geometry
input
geometry
intersects
cache
prepared
tree
geometries
other
way
input_geom.predicate
tree_geom
least
pygeos
docstring
predicate
geometry
tree_geometry
comment
conditional
unnecessary
res
length
lines
effect
following
comment
unclear
sorting
following
lines
minor
nit
bit
more
space
breathing
room
good
newline
conditional
block
comment
conditional
suggestion
return
np.array
tree_query
dtype=np.intp
unsorted
empty
arrays
same
other
occurrences
array
suggestion
empty
integer
array
similar
comment
unnecessary
comment
following
cases
easier
group
input
geometries
predicate
easier
variations
output
predicate
None
LineString
[
]
]
box
intersects
intersects
LineString
[
]
[
]
geometry
LineString
[
]
[
]
intersects
contains
LineString
[
]
[
]
intersects
good
touches
variant
overall
other
comments
exhaustive
rtree
implementation
most
predicates
least
pygeos
tests
same
comment
expected
error
implementation
comment
box
shapely
geometry
Suggestion
loop
box
methods
input
geometries
pygeos
geometry
types
GDAL-style
paths
fiona
recommended
way
things
GeoPandas
out
suggestion
warnings.filterwarnings
ignore
Geometry
column
geometry
UserWarning
specific
Might
.numeric_types
attribute
numeric
dtypes
good
switch
future
reference
full-res
images
doc/source/gallery/images
yep
sure
directory
examples
intention
examples
better
name
nyc_boros
file
files
documentation
note
auto-building
part
documentation
example
savefigs
images
sphinx-gallery
generates
LMK
comment
super
API
pages
e.g.
API
page
from_file
sphinx-gallery
examples
method/function/etc
way
bit
sphinx
comments
nyc_boros.py
file
sphinx-gallery
images
same
way
images
repo
README.md
comment
true
plotting
geometries
cartopy
geopandas
example
difficult
[
len
new_geometries
]
additional
necessary
boilerplate
different
things
Eg
plot
countries
geopandas
.plot
capitals
cartopy
oceans
gdf
result
column
Points
bit
best
way
lambda
row
Point
row.Longitude
row.Latitude
version
lot
easier
same
reason
test
lines
one
previous
review
TODO
tiny
comment
line
aware
alternative
name
geometry
column
shapefile
current
version
GeoDataFrame
geometry
column
geometry
geodataframe.GeoDataFrame.from_features
name
place
read_postgis
geometry
column
last
different
name
column
geometry
last
column
geometry
column
'geometry
case
code
fine
first/last
position
geometry
column
precedents
other
io
functions
certain
way
question
last
one
geometry
column
'geometry
bit
difficult
comments
same
comment
temporary
columns
reason
useful
equals
prepared
version
example
interesting
real-world
data
much
data
geopandas
principle
countries
cities
datasets
countries
box
cities
subset
countries
datasets
warning
below
collections
fine
reasons
warnings
result
other
geometry
types
errors/warnings
keep_geometry_type=True
whole
block
types
input
gdf
default
keep_geometry_type=False
General
question
assert
hasattr
geometry
output
GeoDataFrame
specific
test
idea
kwarg
API
code
course
'markersize
users
'markersize
clear
name
user
scatter
squaring
bit
surprising
matplotlib
scatter
docs
markersize
*
*
default
https
//matplotlib.org/api/pyplot_api.html
matplotlib.pyplot.scatter
OK
note
clarify
comment
test
geoplot
note
import
mc
line
suggestion
FutureWarning
rtree
index
list
tuples
empty
>
>
RTreeIndex
np.array
[
]
]
]
[
]
good
comment
item
present
index
]
]
rtree
spatial
index
empty
future
confusion
something
present
separate
test
something
minor
nit
indentation
suggestion
TODO
pagination
endpoint
defaults
tree_in_limit
tree_out_limit
first
todo
general
useful
pylint
exception
comment
outdated
Coud
comment
summary
PR
message
dead
code
pylint
disable
necessary
files
pre-commit
prompt
issue
double-check
line
active
total
active
states
many
need
'complex
logic
creation
nodes
Edit
total
other
setupClass
comment
path
=
calcjob.get_option
'input_filename
rid
extra
logic
default
filename
specific
Therefore
comment
line
comment
order
bytes
return
outputs
exit
code
exit
code
suggest
attachment
old
code
sure
useful
bits
bunch
more
comments
verdi
code
duplicate
true
above
sd1
jc1
tests
code
proceed
delete
commented
line
huge
number
lines
comments
Todo
Ensure
function
unicode
suggestion
A
manager
jobs
Computer
suggestion
Make
sure
minimum
interval
case
user
last
time
right
way
py2/py3
e.g
py2
str
content
CifEntry
DbEntry
DbEntry
minor
comment
run_materialsproject_api_tests
profile_conf.get
'run_materialsproject_api_tests
False
property
True/False
good
comment
profile
configuration
comment
function
revert_database_schema
such
code
tearDown
method
unnecessary
double
quotes
function
model
parameters
comment
correct
suggestion
slashes
suggestion
return
torch.hub.load_state_dict_from_url
path_or_url
map_location=map_location
ananthsub
noob
question
torch.hub
code
torchtext
reference
docstring
top
file
proper
attribution
name
library
authors
date
purpose
model
fir
types
break
np.generic
docs
state
item
virtual
attribute
np.generic
np.object_
types
edge
cases
block
necessary
though
correct
suggestion
filepath
trainer
runtime
self.dirpath
self.filename
=
None
None
suggestion
filename
default
name
filename
=
epoch
check
user
keys
string
groups
re.findall
r
[
\
]
filename
groups
metrics
]
=
epoch
tmp
groups
name
=
tmp
]
filename
=
filename.replace
tmp
name
+
'=
+
name
name
metrics
metrics
name
]
filename
=
filename.format
*
*
metrics
formatting
Great
catch
readable
no_sync
main
loop
__enter__
__exit__
variable
self.trainer.batch_idx
self.trainer.accumulate_grad_batches
suggestion
class
StorageType
Enum
item
tuple
seed
other
tests
value
test
crash
weights
initialization
small
norm
Makes
sense
suggestion
trainer
=
Trainer
max_epochs=3
logger=logger
track_grad_norm=norm_type
row_log_interval=1
request
grad_norms
batch
result
=
trainer.fit
model
suggestion
@
pytest.mark.parametrize
norm_type
]
def
tmpdir
norm_type
rtol=5e-3
rtol=5e-3
decmials
.grad_norms
above
reset_seed
suggestion
ones
end
epoch
gamma=0.1
suggestion
steps
epoch
batches
times
gamma=0.1
py2.x
try-catch
block
=
getattr
'rank
int
os.environ.get
'LOCAL_RANK
i
suggestion
discrete
values
probability
model
changes
lands
same
weights
end
training
>
😄
comment
assertion
comment
suggestion
state
[
'_id
]
=
self._experiment.id
self._experiment
None
None
suggestion
Add
program
level
break
DDP
process
experiment
multiple
times
same
brackets
comment
sup==0
tp+fp
==
line
tp+fp==0
fair
https
//github.com/PyTorchLightning/pytorch-lightning/pull/3098/commits/a63d40351cdb2c6bc711e9223436cc4a06a0d41c
block
code
comment
code
tracing
defensive
future
editors
logic
something
block
separate
block
own
comment
personal
preference
standards
repo
bit
overkill
P
Anyway
story
short
unnecessary
comment
suggestion
rates
lr
schedulers
information
suggestion
lr
key
=
pg
[
'lr
]
f
name
/
i
suggestion
i
name
=
Multiple
schduler
same
type
True
name
names
break
i
name
=
i
f
opt_name
self.lrs
defaultdict
loop
suggestion
trainer.logger
latest_stat
note
reason
suggestion
def
restore_model_state
model
LightningModule
checkpoint
>
None
suggestion
restore
model
datamodule
state
self.restore_model_state
model
checkpoint
model.cuda
self.trainer.root_gpu
restore
training
state
self.restore_training_state
checkpoint
suggestion
Restore
model
states
'PyTorch-Lightning
checkpoint
dictionary
object
suggestion
triple
quote
strings
warnings
logs
extra
whitespace
>
>
import
warnings
>
>
m1
=
test
>
>
warnings.warn
m1
stdin
>
:1
UserWarning
test
>
>
>
m2
=
test
>
>
>
warnings.warn
m2
stdin
>
:1
UserWarning
test
=
DeviceDtypeModuleMixin.__ignored_properties__
+
[
example_input_array
datamodule
on_gpu
hparams
suggestion
none
important
JIT
suggestion
Test
model
arguments
constructor
suggestion
return
ITERABLE_DATASET_EXISTS
hasattr
dataloader
'dataset
isinstance
dataloader.dataset
IterableDataset
suggestion
log
metrics
single
dict
suggestion
Check
attribute
datamodule
datamodule
Trainer
suggestion
Check
attribute
datamodule
datamodule
Trainer
last
case
user
positional
arguments
suggestion
equal
anything
condition
only
trainer.use_amp
suggestion
self.auto_lr_find
=
False
avoid
lr
multiple
times
sure
return
types
OK
right
prepare_data
method
need
order
model
/
current_epoch
suggestion
suggestion
x
y
=
torch.randn
metric
x
metric
save_path
=
os.path.join
tmpdir
'save_test.ckpt
metric
save_path
load
metric
new_metric
=
torch.load
save_path
results_after_load
=
new_metric
x
Borda
import
importlib
importlib.util.find_spec
ipywidgets
None
tqdm.auto
import
tqdm
tqdm
import
brain
typos
ImportError
suitable
general
nice
inference
usage
segment
image
dataset
comment
error
error
comment
code
suggestion
@
pytest.mark.skip
reason='dp
+
amp
suggestion
batch
size
scaling
result
overrides
default
suggestion
default
Trainer
scaling
batch
size
suggestion
batch
size
scaling
result
overrides
new
test
class
suggestion
Check
model
weights
batch
size.
suggestion
Test
trainer
suggestion
optimizers
[
opt_dict
[
optimizer
]
opt_dict
optim_conf
]
lr
wif
exists
ot
None
lr_schedulers
[
opt_dict
[
lr_scheduler
]
opt_dict
optim_conf
opt_dict.get
lr_scheduler
freq
wif
exists
ot
None
=
[
[
frequency
]
opt_dict
optim_conf
opt_dict.get
frequency
suggestion
assert
optim
]
==
]
]
suggestion
assert
]
==
dict
scheduler=scheduler_a
interval='epoch
frequency=1
suggestion
try
true/TRUE/false/FALSE
return
eval
x.lower
NameError
>
>
type
eval
'true'.lower
class
'bool
>
difference
backends
I.e
same
dependency
apex
Thought
dependencies
pt
native
amp
support
course
backwards
compatible
amp
new
dependency
new
feature
pass
logger
suppression
nice
function/method
wrapper
Overwhite
>
Overwrite
👍
great
let
change
logging
statement
eg
import
_logger
log
log.info
'LR
finder
due
loss
figure
object
Promt
>
Prompt
suggestion
train_dataloader
PyTorch
suggestion
optimizer
wrapped
optimizer
end_lr
final
learning
rate
num_iter
number
iterations
test
last_epoch
index
last
epoch
Default
-1
docs
page
lrfinder
LRfinder
nice
consistency
pythonic
naming
suggestion
type
comments
other
places
assertion
clear
suggestion
TODO
Figure
runs
weights
count
print
TODO
Figure
runs
weights
count
=
IDE
suggestion
TODO
Figure
runs
weights
count
=
comment
suggestion
diff
assert
torch.abs
torch.sum
self.weight_before
torch.sum
.item
10e-6
dd
test
parametrization
something
keys
warning
good
comment
https
//github.com/PyTorchLightning/pytorch-lightning/pull/1561/files
r413230111
enabled=True|False
arguments
help
native
amp
branches
self.trainer.use_native_amp
self.trainer.scaler.scale
loss
.backward
loss.backward
scaler
GradScaler
use_native_amp
precision
self.trainer.scaler.scale
loss
.backward
cases
scale
no-op
scaler
rest
integration
convenience
branches
matter
preference
mcarilli
optimizer
second_order_closure
@
soumith
suggestion
comment
manual_optimization
suggestion
empty
dict
error
suggestion
key
scheduling
suggestion
self.best_k_models
self.save_top_k
readable
cut-out
section
method
suggestion
os.makedirs
os.path.dirname
filepath
suggestion
less_than_k_models
self.best_k_models
self.save_top_k
word
define
define
modulo
master
same
let
style
other
comment
suggestion
NVIDIA
Apex
trainer
=
Trainer
PyTorch
built-in
AMP
trainer
=
Trainer
amp_type='native
suggestion
doctest
decoration
see
http
//z4r.github.io/python/2011/12/02/hides-the-prompts-and-output/
implement
PR
applies
TODO
imports
block
Separate
service
creation
use
other
GCP
sync
modules
AWS
multi-account
pattern
compelling
reason
Ideally
get_projects
issue
comment
cross-dependency
compute
crm
Rather
re-raising
empty
string
get_zones_in_project
empty
string
HTTPError
ERROR-level
message
uncaught
exceptions
Sync.run
block
multiple
log
messages
same
error
branch
exception
bubble
else
branch
extra
context
necessary
new
exception
object
HTTPError
new
exception
Same
comment
boto3
function
Same
comment
load_policy_data
name
function
return
output
modules
enrichment
jobs
expectation
internal
version
such
connectivity
source
JAMF
module
MERGE
fine
future
fair
intel
modules
aware
others
schema
]
array
Neo4j
managing
easier
id
email
concerns
Email
Gsuite
User
mutable
[
schema
]
way
risk
Risk
other
scenarios
cve
vulndb
safedb
..
example
question
query
risk
schema
same
comment
documentation
Nit
use
proper
caps
Nit
testtest
proper
caps
Sorry
😛
Remove
dead
code
cartography-admin
@
lyft.com
needs
config
file
os.environ
object
default
elegant
manner
Please
comment
link
AWS
datatype
Principal
field
policy
statement
instructions
Readme
user
Github
sync
SimoRubi
comment
Check
currency.position
symbol
amount
advantage
Monetary
field
Please
license
https
//github.com/OCA/maintainer-tools/blob/9766529146bcb61ce746623da74a23163199bdd3/template/module/models/model_name.py
L3
Qui
ancora
tutti
@
sergiocorato
elimini
tutti
i
correlati
anche
se
AGPL
LGPL
https
//github.com/OCA/l10n-italy/pull/706/files
diff-30c0ebdefdf55908a3fa04cc2c78ea2fR2
@
SimoRubi
la
fiscale
entra
gioco
quanto
è
abilitare
i
quest'ultima
il
partner
ha
la
posizione
fiscale
e
questa
ha
il
flag
corrispettivi
deve
il
registro
@
GSLabIt
puoi
solo
più
chiaro
il
commento
default
cosa
si
riferisce
@
scigghia
puoi
un
commento
spiegare
la
sostituzione
@
sherpya
quindi
caso
di
XML
non
firmati
una
di
queste
eccezioni
viene
sollevata
Se
sai
quale
caso
una
e
quale
l'altra
lo
puoi
un
commento
link
image
documentation
suggestion
coordinate_maskes
]
True
force
coordinate_maskes
values
false
sense
segmentation
somebody
list
tests
todo
comment
function
TODO
takecore
test
segmentation
class
name
default
classes
height
width
comment
list
comment
sense
enable_prefetch
enable
Please
comment
comments
v_pred
necessary
descriptive
variable
name
joint_count
IMO
better
np.zeros
numpy
array
raw
Python
array
line
iterate
lines
statement
iteration
debug
lines
Please
add
comments
conversion
operation
convert
gratscale
image
RGB
grayscale
image
channel
size
better
lines
absolute
line
number
49-50
lines
unused
comment
unused
comment
unused
comment
unused
comment
query
wrong
nginx
container
resources
expiration
incorrect
mru
sru
differences
i
deployment
container
nginx
query
workload
resources
nginx
container
resources
SINGLE_STORY_TEMPLATE
variable
outside
story
need
line
line
SINGLE_PROJECT_TEMPLATE
variable
data
go
UPPER_CASE
letter
local
variable
free
IP
free
IP
workloads
node
target
network
IPs
node
range
Line
end
@
koitoror
many
lines
Remove
lines
commented
line
Refer
line
Try
noqa
self
i
object
class
method
call
week
End
date
Jan
typo
use
commented
line
Remove
code
lines
noqa
comments
function
definition
Use
https
//www.python.org/dev/peps/pep-0008/
block-comments
specifics
specific
method
noqa
parentheses
noqa
way
line
noqa
parentheses
good
picture
noqa
lines
responses
[
]
new
line
noqa
code
createResponse
responses
[
parameters
code
file
Please
noqa
parentheses
possible
noqa
noqa
spelling
details
comments
blocks/lines
code
Please
https
//www.python.org/dev/peps/pep-0008/
documentation-strings
Hello
@
BonifaseOrwa
more
light
Which
variable
particular
start_dt
code
base
same
person
code
tou
noqa
date_now
=
datetime.strptime
%
b
%
d
%
Y
relativedelta
days=1
+
Z'
comment
necessary
Comment
Varnish
cache
nice
comment
historical
reasons
etc
weird
someone
year
Single
issues
someone
boost
configuration
migration
issues
entire
config
item
list
comment
good
comment
RealtimeSignalProcessor
overloads
ES
BaseSignalProcessor
index
updates
sure
tests
objects
index
@
MatthewPiatetsky
necessary
changes
tests
@
MatthewPiatetsky
okay
Could
comment
effect
USE_API_CACHING
configuration
thing
further
troubleshooting
BTW
someone
later
rid
unnecessary
sort
order
consequences
specific
exception
type
Doc
string
comment
Algolia
iterable
Nit
part
comment
changes
course
creation
fails.
AtomicTransaction
blocker
comments
code
block
top
one
status
whole
function
Drop
comment
relevant
code
comments
code
block
nit
repetitive
editor_course
=
discovery_course.draft_version
discovery_course
CourseEditor.objects.update_or_create
course=editor_course
user=user
section
comment
lines
official
version
draft
editors
sense
official
versions
drafts
ensure_draft_world
something
mention
comment
code
transition
old
publisher
new
someone
line
comfortable
IntegrityError
Good
catch
courses
end
dates
intentional
sure
courses
state
Super
minor
negative
bool
variables
reason
is_active
logic
use
Sorry
comment
verbose
Might
EITHER
image
Discovery
Drupal
draft_version.subjects
Feels
typo
subject
prices
comment
sense
current
code
time/resources
bulk
num_indices_to_remove
=
len
sorted_indexes_by_timestamp
settings.HAYSTACK_INDEX_RETENTION_LIMIT
num_indices_to_remove
indices_to_remove
=
sorted_indexes_by_timestamp
[
num_indices_to_remove
]
logger.info
indices
%
s
indices_client.delete
index=
logger.info
indices
%
s
logger.info
'No
indicies
comma-separated
list
indexes
bulk
http
//elasticsearch-py.readthedocs.io/en/1.9.0/api.html
elasticsearch.client.IndicesClient.delete
for-loop
possible
list
indexes
Remember
*
anything
settings.HAYSTACK_INDEX_RETENTION_LIMIT
fewer
indexes
comment
sense
assumption
case
alias
distinct
indices
alias
index
sorted_indexes_by_timestamp
=
sorted_indexes_by_timestamp
set
current_alias.keys
need
parentheses
True
simplification
backend
Use
backend.conn
count
indexes
live
index
untouched
purpose
tests
*
*
indexes
certain
number
index
number
indexes
host
less
number
indexes
indexes
assert
pytest
Same
assert
set
all_indexes
indexes_to_keep
tests
scenarios
count
appropriate
way
reliance
command
command
Move
code
ElasticsearchUtils
]
https
//github.com/edx/course-discovery/blob/master/course_discovery/apps/core/utils.py
L11
appropriate
tests
assert
set
all_indexes
indexes_to_keep
good
comment
number
queries
curricula
*
How
many
queries
course
curriculum
*
How
many
queries
program
curriculum
way
future
selves
kind
stare
blankly
void
existence
method
DRY
docstring
helpful
documentation
docstring
method
Comment
part
test
test_instructor_autocomplete
test
permission
test
comment
sure
node
id
api
client
something
session
something
Session
API
response
response
changes
ProgramType
slug
value
different
name
slug
URL
name
bunch
work
distincts
fields
subquery
much
different
join
good
s/Elastic
Search/Elasticsearch
👍
Could
comment
Amazon
Elasticsearch
service
.get_settings
Extra
credit
link
AWS
Haystack
documentation
necessary
nit
get_img_url
get_image_url
@
McKenzieW
comment
accurate
replacement
happening
removal
bit
=
cache.get
cache_key
api_access_request
try
results
getattr
self.client
resource
.get
*
*
query_parameters
'results
]
results
logger.warning
'Multiple
APIAccessRequest
models
LMS
API
user
%
s
]
user.username
api_access_request
=
results
]
cache.set
cache_key
SlumberBaseException
ConnectionError
Timeout
logger.exception
API
Access
Request
LMS
user
%
s
user.username
IndexError
KeyError
logger.exception
'APIAccessRequest
model
user
%
s
]
user.username
return
stub
methods
super
fine
FYI
pattern
Discovery
autogenerated
swagger
docs
http
//localhost:18381/api-docs/
stubs
docstrings
little
specific
list
Collaborators
default
text
swagger
ambivalent
value
pattern
comment
number
queries
prevents
variable
distinct
course
objects
course
org
drafts/official
primary
keys
drafts
officials
open
different
approach
comment
odd
unnecessary
Just
comment
save
method
pattern
appropriate
exception
several
cases
minimum
endpoint
tests
exceptions
fatal
Studio
hey
bud
uh
moment
Studio
short_name
Studio
sync
case
fatal
log
ignore
certain
codes
except
HttpException
e
exception
class
e.code
log
ditto
one-off
command
suggestion
row
values
worth
avoid
circular
dependencies
comment
comment
line
useful
Nothing
crazy
mention
review
givin
consistency
Docstrings
other
methods
worth
fields
methods
other
indices
worthy
thing
fields
scope
idea
case
content
type
piece
issues
case
comment
recent
commit
course
key
course
key
intentional
comment
courses
course
runs
same
search
results
Please
comment
course
runs
course
course
course
Line
serializer
=
self.get_serializer
data=json.loads
request.data.get
'data
json.loads
nested
AJAX
post
data
great
format
own
'position
BECOMES
'position
[
title
]
'test
post
data
DRF
other
ways
sense
Happy
other
design
options
similar
implementation
base
class
@
MatthewPiatetsky
consistent
use
isnull
module
second
thought
pretty
clear
comment
value
work
clearer
need
comment
correct
behavior
face
drf-haystack
drf
defaults
Might
comment
effect
clear
Use
getters
setters
Python
property
settings
module
@
amangano-edx
thanks
context
fair
comment
effect
top
module
clearer
Haystack
final
code
Sorry
PR
general
change
full
language
tag
Chinese
zh_TW
zh_CN
Chinese
only
language
treatment
different
language
tag
pt
others
same
tags
answer
above
PR
hardcoded
method
is_chinese
something
uses_full_language_tag
something
better
@
property
translated_macrolanguage
consumer
translated_tag
good
name
weird
get_active_language
something
Chinese
users
Just
need
comment
test
case
update
format
docstring
please
consistent
camel
case
small
letter
comment
commented-out
code
docstring
method
second
return
list
comment
good
idea
short
todo
Are
tests
pass
sufficient
coverage.
[
]
https
//i.imgur.com/kGisi63.png
commented
code
Reviewers
sure
course
runs
date
comment
duplicate
line
Ditch
comment
help
text
better
field
mark
translation
python
help_text=_
'This
field
API
clients
order
instructors
program
pages
Instructors
list
others
programs
runs
official
entitlements
different
mode
Same
Q
seats
plan
duplication
code
function
advantage
side
effect
previous
promise
ensure_official_version
no-op
draft
true
please
sure
DB
old
data
data
draft
HOWEVER
code
data
first
time
ensure_official_version
copy
Hmph
someone
ensure_draft_version
*
DB
sane
migration
purposes
check
ensure_official_version
same
vibe
copy
draft
official
sense
PR
blurred
line
line
entitlements
less
lines
e
obj.entitlements
set_draft_state
e
[
]
[
obj
]
None
obj.course_runs
check
draft
different
set
assumptions
early
exit
top
function
course-world
draft
draft
early
exit
partial
world
comment
contain
characters
problem
html
version
Might
html
/
text
indentation
level
publisher_course
fine
Every
publisher
run
link
course
Comments
model
djangoapp
Ah
course-run
course
comment
course
multiple
course
runs
Comment
Updated
Return
None
False
duplicate
comments
recent
course-run
Canonical
partner
organization
docstring
function
SalesforceUtil
return
value
_by
you_
function
point
best
live
helper
function
Util
file
helper
comment
comment
code
obvious
Mention
local
object
db
post_save
hook
@
MatthewPiatetsky
dictionary
consistent
ordering
tuple
overkill
last
paginator
list
proxy
other
element
ProxiedCall
query
parameters
other
element
tuple
clearer
way
dictionary
tuple
@
MatthewPiatetsky
comment
more
clear
comment
nothing
sounds
benign
log.exception
worth
intended
course
action
assumption
forwards
things
period
entry
django
admin
worth
logging
exception
level
topics
set
Tag
objects
<
Tag
stardust-2019
>
<
Tag
finance
>
topics
tag
manager
django
admin
sure
test
_fill_cache
better
bet
len
caches
results
Potentially
pagination
somehow
unnecessary
second
query
paginated
requests
necessary
queryset
execution
something
more
conventional
length
example
len
Haystack
source
several
places
_fill_cache
option
easier
test
Elasticsearch
client
use
requests
valid
docstring
format
comment
arguments
attributes
section
something
docstring
format
http
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
open
'synonyms.yml
path
manipulation
clinton
renzo
comments
new
lines
better
readability
bit
text
parsing
format
SYNONYMS
variable
name
nice
URL
config
variable
case
future
more
modular
other
users
code
other
providers
Nit
cleaner
fragile
app_id
parameter
argument
requests.get
method
string
http
//docs.python-requests.org/en/master/user/quickstart/
passing-parameters-in-urls
details
something
following
url
=
//openexchangerates.org/api/latest.json'
response
=
requests.get
url
params=
'api_key
api_key
get_rates
None
such
exception
method
get
rates
dictionary
None
stack
traces
something
'NoneType
object
attribute
'get
key
such
sandbox
devstack
purposes
failures
exception
type
message
useful
more
conditions/tests
comments
Conditions
Course
multiple
course
runs
Course
multiple
course
runs
program
course
multiple
runs
other
courses
Course
runs
enrollable/purchaseable
default-model
values
variable
MODE_SLUGS_AND_DEFAULTS
defaults
dict
create
*
little
*
default
values
weird
line
/
block
Could
comment
review
status
first
review
step
something
B
logic
draft
course_run.status
=
extra
complication
C
complication
duplicate
logic
block
above
temporary
variable
something
future
mistake
update
comments
functionality
part
send_email
return
type
function
queryset
list
consuming
functions
queryset
Nit
comment
code
authors
docstring
users
function
information
list
querystring
comment
value
value
backlog
Story
Epic
comment
boost
first
Please
comment
separate
test
ddt.data
upper
part
test
sense
Feels
course
value
request
data
view.course
value
more
sense
view
permission
classes
independent
lookup
idea
comment
courses
admin_url
need
status
code
comment
effect
nice
issue
form
restful
API
form
renders
login
instance
response
code
can_access_admin
redundant
point
sure
instance
same
Course
query
query
identical
Courses
able
original
query
result
copies
same
course
comment
out-of-date
docstring
Maybe
mention
commerce
API
logic
hard
Could
intermediate
variable
help
clarity
Nit
extra
'to
Nit
Fix
comment
CreatedDate
CreatedAt
comment.created
Nit
Fix
comment
CreatedDate
CreatedAt
clintonb
model
versioned
registry
None
model
methods
available
properties
comment
nothing
DB
enforcing
row
SINGLETON_INSTANCE_PRIMARY_KEY
solo
singleton
model
DB
possibility
duplicate
rows
convention
variable
same
name
model
ElasticsearchBoostConfig
=
apps.get_model
'edx_haystack_extensions
'ElasticsearchBoostConfig
Nitpick
stick
single
quotes
consistent
rest
project
migration
hardcoded
primary
key
advantage
fact
singleton
model
use
boost_config
=
ElasticsearchBoostConfig.objects.first
boost_config
=
ElasticsearchBoostConfig.get_solo
current
code
new
instance
ElasticsearchBoostConfig
class
save
default
values
ie
brand
new
row
defaults
function_score
field
save
other
field
values
db
.first
first
object
get
pk=1
preferred
way
key
library
record
future
versions
library
primary
key
key
IMO
constant
better
communicates
future
someone
migrations
question
value
anything
everyone
use
use
explicit
primary
key
migration
file
cleaner
call
library
hardcoded
primary
key
package
anything
@
amangano-edx
latest
version
library
[
docs
]
https
//github.com/lazybird/django-solo
use-cases
bit
singleton_instance_id
suggested
model
singleton
difference
boost_config
__
=
ElasticsearchBoostConfig.objects.get_or_create
pk=1
need
constant
Comment
comment
correct
name
example
create_or_update_boost_config
little
misleading
ElasticsearchBoostConfig
record
DB
function_score
column
new
value
control
page
size
calculation
page
size
calls
seconds
seconds
future
rate
limiting
concern
Please
comment
following
Calculations
potential
call
rate
JIRA
ticket
details
deeper
follow-up
fix
ahsan-ul-haq
please
more
clear
comment
others
test
separate
test
thing
test
setup
stuff
Independent
master
backward
compatibility
plugins
transaction_ids
type
ldap_v
list
map_k
[
mobile
memberOf
]
list
Multivalue-Attributes
resolver
way
flexible
future
MULTI_VALUE_ATTRIBUTE
=
[
mobile
memberOf
elif
type
ldap_v
list
map_k
MULTI_VALUE_ATTRIBUTE
backward
compatiblity
clean
way
other
resolvers
validations
problem
class
method
testconnection
python
Thanks
JSONDecodeError
parameter
empty
default
value
=
errorResponse
True
empty
dict
False
code
checking
unnecessary
data
database
data
correct
simple
self.config
=
config
Sorry
trouble
lot
api
calls
data
fewer
calls
fine
big
deal
suggestion
host
=
self.instance.get
'host
host
host
parameter
exsists
conf.yaml
raise
ConfigurationError
fix
pihole.d/conf.yaml
host
parameter
array
agent
__NAMESPACE__
NvmlCheck
https
//datadoghq.dev/integrations-core/base/about/
uuid
extreme
cardinality
Let
use
self.
self.service_check
is/else
line
message
topology_status
case
process_
*
function
charge
metrics
dict
need
_gt
tuple
value
tags
helpful
comments
parameters
comment
necessary
CBL
version
test
applicable
CBL
Please
comments
hardcoding
Centos
Can
comment
test
comment
test
comment
breaks
SRP
principle
From
design
readability
better
way
replicate
configure
thing
go
case
failure
function
SRP
principle
same
field
constant
check
replication
key
value
true
key
update
part
original
doc
keys
comments
string
possible
user
role
mapping
comment
line
second
changes
view
call
comment
unnecessary
step
comment
unnecessary
push
replication
same
above
empty
new
line
comment
replication
configuration
comment
little
comment
appropriate
place
Add
different
type
verification
flag
other
count
sure
one
series
asserts
method
main
someone
script
validation
flag
other
Assert
vbucket
files
Explain
rollback
behavior
Removed
Linux
Linux
opinion
comment
kind
duplicate
same
purpose
code
test_generate_clusters_from_pool_ip_to_node
Verify
IP
couchbase_servers
mock_pool_ip_to_node_type.json
assert
pool_data
[
ip_to_node_type
[
]
==
couchbase_servers
Verify
IP
couchbase_servers
mock_pool_ip_to_node_type.json
assert
pool_data
[
ip_to_node_type
[
]
==
couchbase_servers
please
comment
todo
exception
liteserv
app
remove
sanity
tag
push/pull
replication
push
valid
summary
same
test
summary
test
functionality
sanity
imports
uncomment
reason
comments
same
above
no.s
reader
available
comments
Same
comments
API
comment
API
lines
lines
lines
comment
sense
lines
commented
line
lines
commented
line
[
Add
carriage
return
end
line
]
https
//robots.thoughtbot.com/no-newline-at-end-of-file
comment
koji
buildError
E501
line
characters
note
TODO
final
review
E261
least
spaces
inline
comment
Yes
please
AddContentSetsPlugin
same
method
code
value
Cachito
insecure
configuration
important
development
environments
such
osbs-box
function
session
bit
verbose
deprecation
comments
common
code
add_helper
plugin
good
idea
GET
requests
insecure
True
*
*
*
certificates
other
words
actual
insecure
value
secure
connection
insecure
available
reason
cachito
configuration
available
resolve_remote_source
execution
block
plugin
failure
case
safe
comment
deepcopy
point
image_str
image
part
code
comments
None
comment
accurate
IMO
works
python
>
>
>
some_list
=
[
]
>
>
>
some_other_list
=
[
]
>
>
>
print
some_list.extend
some_other_list
None
>
>
>
print
some_list
]
some_list
anything
i.e
Python
terms
returns
None
need
type
extra_image_mts
sleep
koji
registries
source
+
pull
comment
Comment
TODO
empty
source
container
image
valid
comment
pi
right
guard
answer
arbitrary
Expression
s
place
GateParameter
restrictive
Parameter
type
specifier
Comment
spec
bug
ClassicalStore
constant
mem
ref
final
argument
suggestion
dispatch
service
per
private
discussion
docstring
reflect
current
state
error
Expression
complains
unused
import
something
effect
comment
chicken-and-egg
situation
Expression
license
unused
good
grief
See
comment
RE
wait
spurious
period
machine_epsilon
code
relic
suggestion
Experiment
suggestion
prepare
Experiment
bunch
diag_in_term
diag_out_term
good
use
few
lines
use
updated
private
function
_expt_settings_diagonal_in_tpb
comment
set
code
experiments
simultaneously/are
diagonal
same
natural
tpb
summary
line
suggestion
self.qpu_compiler_client
return
rest
code
comment
copy
comment
FYI
line
same
loss
metadata
qubit
placeholders
PR
practice
anything
fix
safe
suggestion
native_quil_to_executable
docstring
version-specific
important
information
context
PR
irrelevant
more
information
worth
@
abstractmethod
AbstractCompiler
documentation
note
intent
abstract
methods
case
parity
subclasses
units
signature
timeouts
compiler.rst
timeout
datetime.duration
timeout_seconds
int
likely
consistency
explicit
comment
docstring
issue
comment
append
function
construct_tpb_graph
..
function
TypeError
object
type
'Experiment
len
ExperimentSuite
Experiment
list
Experiment
example
import
pyquil.operator_estimation
oe
import
pyquil.paulis
pl
expt1
=
oe.Experiment
pl.sX
*
pl.sZ
pl.sX
*
pl.sY
*
pl.sZ
=
oe.Experiment
pl.sZ
*
pl.sX
pl.sY
*
pl.sZ
*
pl.sX
=
oe.Experiment
pl.sX
*
pl.sY
*
pl.sZ
pl.sZ
*
pl.sX
*
pl.sY
=
[
expt1
expt2
expt3
]
expt_suite
=
oe.ExperimentSuite
expt_list
Program
H
H
H
]
expt_suite.append
Experiment
pl.sX
pl.sZ
oe.construct_tpb_graph
expt_suite
error
msg
TypeError
object
type
'Experiment
len
record
reflect
docstring
esteemed
colleague
comment
__iter__
__reversed__
functions
definition
__contains__
Experiment
ExperimentSuite
>
>
import
pyquil.operator_estimation
oe
>
>
>
import
pyquil.paulis
pl
>
>
>
=
oe.Experiment
pl.sX
*
pl.sZ
pl.sX
*
pl.sY
*
pl.sZ
>
>
expt2
=
oe.Experiment
pl.sZ
*
pl.sX
pl.sY
*
pl.sZ
*
pl.sX
>
>
expt3
=
oe.Experiment
pl.sX
*
pl.sY
*
pl.sZ
pl.sZ
*
pl.sX
*
pl.sY
>
>
expt_list
=
[
expt1
expt2
expt3
]
>
>
>
oe.ExperimentSuite
expt_list
Program
H
H
H
]
>
>
>
expt1
expt_suite
ll
get
“
False
”
output
’
t
nice
Note
ll
“
True
”
]
expt_suite
comment
I-
>
in_operators
identity
whereas
measured_qubits
qubits
out_operators
better
comment
something
lines
Identity
operator
*
*
prepared
state
expecation
value
variance
opinion
exp
code
Experiment
confusion
exponentiation
enough
times
code
base
comment
__contains__
ExperimentSuite
Experiments
Experiments
example
import
pyquil.operator_estimation
oe
import
pyquil.paulis
pl
expt1
=
oe.Experiment
pl.sX
*
pl.sZ
pl.sX
*
pl.sY
*
pl.sZ
=
oe.Experiment
pl.sZ
*
pl.sX
pl.sY
*
pl.sZ
*
pl.sX
=
oe.Experiment
pl.sX
*
pl.sY
*
pl.sZ
pl.sZ
*
pl.sX
*
pl.sY
=
[
expt1
expt2
expt3
]
expt_suite
=
oe.ExperimentSuite
expt_list
Program
H
H
H
]
expt_suite.count
expt1
other
hand
expt_suite.count
[
expt1
]
OK
user
aware
type
comment
non-comment
annotation
above
clear
extra
values
picking
none
multiple
ones
respective
fields
instance
workflow
help
good
partially_available
state
move
quantity
unit
something
picking1.move_lines
]
.product_uom_qty
Otherwise
comment
state
test
simpler
comment
field
Odoo
core
sure
same
line
other
access
pickings
moves
more
clear
way
field
None
field
entity_stub.keys
field
requirements.get
entity_type
sure
mappings
least
spaces
piece
code
inline
comment
suggestion
return
getattr
request
'headers
New
Django
little
comment
something
ODK
Collect
python
by_schemas_list
=
\
.filter
schemadecorators__entities__in=entities
.values
'definition__name
value
.annotate
count=Count
'schemadecorators__entities
.values
'count
'name
original
AVRO
schema
definition
tweaked
one
id
grimacing
random_avro
avro_schema
data
sample
'schema
avro_schema
avro
schema
sure
mappingset
instance
fields
mapping
definition
thinking
schema
coherence
same
https
//github.com/eHealthAfrica/aether/blob/develop/aether-ui/aether/ui/api/models.py
L32-L36
python
class
Pipeline
ExportModelOperationsMixin
'ui_pipeline
TimeStampedModel
avro
schema
schema
=
JSONField
null=True
blank=True
default=dict
example
data
avro
schema
input
=
JSONField
null=True
blank=True
default=dict
woman_shrugging
Same
gb
de
fr
comment
suggestion
serializer
class
trailing
whitespace
field
suggestion
filter
test
generated
string
space
events_id
=
'stim
raw
annotations
present
raw
events
annotation
sure
correct
bids
events.tsv
mne
annotations
.txt
csv
suggestion
events
events_data
suggestion
Convert
BIDS
sappelhoff
Just
patience
here…
aaargh
Argh
sorry
consistent
other
headers
suggestion
Convert
BIDS
BIDS
sense
tag
files
coordinates
templates
scope
PR
curious
little
odd
ears
suggestion
BIDS
suggestion
description
easy
logic
statements
parts
n/a
tempita
mne
externals
mne/report.py
file
mne-python
maybe
word
template
sidecar
redundant
section
entry
level
example
complex
code
sure
line
route
schema
mne-bids
repo
alteration
eg
https
//github.com/bids-standard/bids-validator/blob/master/bids-validator/validators/json/schemas/meg.json
python
way
json
schema
something
clear
documentation
bids_path
multiple
paths
BIDSPath
docstring
dictionary
update
Python
folks
familiar
behavior
suggestion
First
BIDSPath
object
suggestion
MRI
anonymization
deface=True
suggestion
check
CIs
merge
fix
pybv
https
//github.com/bids-standard/pybv/issues/45
new
PR
mne-bids
XXX
suggestion
suggestion
fmt
=
XXX
issue
pybv
https
//github.com/bids-standard/pybv/issues/45
fmt
=
resolution
1e-9
precise
loss
suggestion
Loop
keys
original
data
original
order
data
user
participants
files
easier
way
suggestion
comments
code
docstring
write_raw_bids
custom
values
TSV
file
anything_
warning
value
MNE
–
sex
unknown
–
information
present
original
BIDS
dataset
suggestion
value
None
MNE
skip
warn
'Unable
sex
value
MNE
subject
sex
@
hoechenberger
ALLOWED_MODALITY_EXTENSIONS
string
TODO
note
preload=False
annotations
stim
channel
drop
MNE-Python
docstring
line
file
path
BIDS
compatible
raw
file
case
multifile
systems
e.g.
vhdr
.ds
path
folder
files
comment
copyfile_brainvision
multifile
system
files
copyfile_eeglab
facultative
multifile
system
file
files
location
header
file
myfile.vhdr
directory
good
idea
suggestion
folders
folders
session
level
check
unnecessary
reconsidering
mne.datasets.testing.data_path
BrainVision
files
awscli
suggestion
readme
file
XXX
README
future
template
API
XXX
see
https
//github.com/mne-tools/mne-bids/issues/551
comment
future
devs
suggestion
participant
name
birthdate
safe
id_info
=
[
pid
sex
X
X
]
rec_info
=
[
Startdate
startdate
admin_code
tech
suggestion
Get
subject
info
info
date
suggestion
Try
date
4-digit
year
Startdate
field
info
section
standard
startdate
field
2-digit
years
XXX
recording
dates
EDF/EDF+/BDF
MNE-Python
2-digit
year
field
4-digit
field
try-except
clause
https
//github.com/mne-tools/mne-python/issues/8544
suggestion
Startdate
field
info
section
e.g.
X
fall
standard
startdate
field
only
2-digit
years
MNE-Python
raw.info
meas_date
suggestion
manuscript
sure
MNE-BIDS
suggestion
mne-bids
manuscript
sure
MNE-BIDS
suffix
suggestion
Create
data
path
available
entities
bids_root
subject
session
constants
[
config.py
]
https
//github.com/mne-tools/mne-bids/blob/master/mne_bids/config.py
user
more
convenience
private
function
make_bids_folders
users
EOF
parantheses
else
Exception
carryover
error
file
extension
dict
suggestion
BIDS_EEG_COORDINATE_FRAMES
=
[
'captrak
]
BESA
bugfix
good
log
message
warning
message
verbose
coordsystem_name
Other
CoordsystemDescription
dataset
whole
purpose
BIDS
people
other
suggestion
coordsystem_name
==
verbose
print
Other
keyword
CoordinateSystem
field
'Please
CoordinateSystemDescription
field
coordinate
json
data
structure
suggestion
XXX
landmarks
present
suggestion
MNE-BIDS
module
function
private
functions
@
jasmainak
noqa
better
mne_bids.read
stuff
place
same
mne_bids.write
email
address
commits
email
address
suggestion
original
units
data
conversion
optimization
din
suggestion
Check
handling
datatype
comment
NIfTI
same
MGH
use
single
letter
variable
name
reason
pragmatic
+
F
comment
BIDSPath
test
fact
else
part
test
coverage
hack
iEEG
channel
locations
MRI
coordinate
system
suggestion
raw
=
mne.io.RawArray
info
raw.set_montage
montage
lines
code
file
read_raw_bids
sensor
locations
round
trip
successful
suggestion
data
new
BIDS
dataset
use
mne.get_config
'MNE_DATA
suggestion
info
=
mne.create_info
ch_names
'ecog
compat
suggestion
data
purpose
second
subplot
Sorry
examples
P.
command
sequence
story
complete
sensor
plot
data
MNE-BIDS
contents
channels.tsv
file
first
rows
user
fact
file
montage
plot
sensor
locations
bit
incomplete
user
workflow
BIDS
data
+
code
able
sidecars
data
anything
default
comment
line
variable
afterwards
figure
raw.plot_sensors
ch_type='ecog
same
suggestion
plot
sensors
plane
systems
BIDS
systems
se
similar
FIFF
BIDS
system
BIDS
usage
suggestion
ElektaNeuromag
system
equivalent
CapTrak
system
line
triple
backticks
>
>
user
root
basename
niche
example
first
example
show
suggestion
FIXME
e.g
FIFF
data
split
multiple
files
suggestion
Check
root
available
suggestion
Order
XXX
fix
suggestion
cases
status
/
status_description
columns
optimal
terms
performance
anyone
list
entities
user
chase
documentation
functions
documentation
code
*
*
kwargs
param
*
*
vals
*
*
data
something
dict
sense
data
least
way
debug
logs
best
move
Good
question
bound_pressure_matrix_key
Biot
en-US
hour
checks
hour
bit
overlap
example
hour
pass
minutes-ago
data
ES
order
more
similar
Django
syntax
Please
comment
code
update
copyright
year
commented
line
necessary
Ah
Nevermind
s/if
python_command
python_command
is/
comment
sure
setting
PYTHONHOME
leftover
Wait
statement
English
root
cwd
mkdir
\
<
user\
>
problem
bug
conditionals
way
stuck_out_tongue
comment
helpful
exit_code
means
username
use
comment
clearer
error
.format
args
replacement
curious
group
comment
reason
need
__init__
avoid
things
Quick
note
PR
description
CLI
ProjectEnvironment
instance
Project
need
attributes
Hmm
noqa
personal
preference
everything
truthtable
case
environment
triggers
pack_project
actual
step
traditional
host
build
today
bases
e.g
i.e
elif
grammar
strings
iterables
clever
huge
fan
inline
statements
bit
verbose
comment
useful
future
processor.get_properties
]
code
comment
Provider
Multipass
provider
versus
multipass
base
provider
BaseProvider
comment
check
mapped_channel.expiration_date
None
comment
snap
latest
version
channel
confinement
type
snap
new
version
comment
install_snaps
confinement
huh
string
intuitive
Seems
legacy
copy
/
paste
error
suggestion
build_base
core
core16
core18
plugin_version
v1
elif
build_base
==
raise
RuntimeError
last
check
precaution
case
someone
skips
other
precaution
snapcraft.internal.meta.snap.Snap.get_build_base
someone
schema
checks
development
schema
snapcraft.yaml
build_base
None
raise
RuntimeError
None
suggestion
build_base
Project
suggestion
Note
core2y
future
base
_not_
cmdline
comment
sense
'hooks
'assets
assets
nothing
wrappers
presence
v2_lint
return
code
Thanks
comment
order
tuple
example
value
constant
x86-64
e_machine
wrong
value
way
script
need
source
rest
env
ubuntu_repo
comment
checks
unrelated
weird
read
indentation
black
nothing
comment
thoughts
mind
comment
ProviderExecError
casual
future
code
contributor
ourselves
smile
FWIW
snapcraftctl
functionality
plugins
commands
plugin
such
old
colcon
PoC
e.g
https
//github.com/cjp256/snapcraft/blob/7fc1e8f09f5b03d4590fd3cfe8c3e3e344a57e40/snapcraft/plugins/colcon.py
L640
build
command
f
sys.executable
-m
snapcraft.plugins.v2.
<
plugin
>
<
command
>
sys.executable
import
snapcraft
snapcraft.internal.mangling.rewrite_python_shebangs
SNAPCRAFT_PART_INSTALL
bits
bash
comment
misleading
anything
path
'name
extension
class
hard-coded
ExtensionImpl
year
comment
@
elopio
comment
code
bit
easier
whole
configuration
single
go
str.format
method
named
parameters
config
moduleset
=
module_set
r
jhbuildrc_file.write
config.format
module_set=self.options.module_set
comment
source
code
nit
single
line
docstrings
single
line
need
own
lines
documentation
cflags
parameter
Could
comment
source
code
other
docstring
gid
mygid
default
base
class
need
plugin
docstring
function
useful
clear
little
confused
refresh
type
need
file
suggestion
Clear
prime
directory
host
Windows
snaps
WSL
speaking
fine
Windows
WSL
snaps
Windows
..
call
stack
something
stack
comment
Hack
Windows
=
Snaps
Windows
something
No
need
>
LXD
platform
Use
multipass
snapcraft
non-Linux
systems
https
>
LXD
Try
lxd
init
auto
pylxd.exceptions.LXDAPIException
bug
LXD
true
right
comments
abc
Sorry
terrible
place
comment
improved
comment
more
sense
Thanks
comment
Mind
login
command
documentation
snapd
snap
type
account
changin
prefix
KPIs
safer
configurable
parameter
method
code
comment
[
]
few
statements
packages
[
'cmake
Dependencies
FastRTPS
'libasio-dev
'libtinyxml2-dev
Dependencies
rest
ros2
python-empy
dependency
necessary
[
source
build
]
https
//github.com/ros2/ros2/wiki/Linux-Development-Setup
instructions
likely
brief
discussion
coworkers
suggests
likely
necessary
necessary
ROS
bridge
point
dependency
list
suppress
readable
os.link
I/O
error
file
behind
@
contextlib.suppress
FileNotFoundError
destination
strong
opinion
contextlib
points
contextlib
pass
exception
checking
dir
pass
OSError
Right
confusion
example
name
foo
build-packages
[
bar
]
parts
part1
plugin
nil
build-packages
[
baz
point
code
build
packages
self.build_packages
]
build-packages
part
anything
package
name
version
place
'bar
part.build_packages
only
concern
re-calculated
step
same
part
things
place
part
something
similar
Create
type
try
succeeding
matching
man_shrugging
types
mean
path
absolute
os.path.join
[
]
preferable
comment
nice
Note
[
absolute
]
https
//github.com/snapcore/snapcraft/pull/1130/files
diff-3cc26b49a70ee86523598a96dd385301R363
retry
loop
lot
timeouts
comment
code
profile
active
_add_catkin_profile
subsequent
command
downside
profile
possible
developer
settings
necessary
build
Likewise
sure
possible
changes
build
snap
likely
Just
thoughts
bug
catkin
tools
[
bug
]
https
//github.com/catkin/catkin_tools/issues/74
old
comment
ruby
stuck_out_tongue
update
copyright
year
explode
headless
systems
Might
useful
method
_clean_catkin
_add_catkin_profile
_install_catkin_packages
dst
slash
test
condition
@
elopio
ups
handles
stuff
dst
line
test
lstrip
Wrong
snapcraft
string
message
nice
thing
sorry
project.printString
sure
arguments
Please
use
single
quotes
consistency
build_profile
=
'snapcraft-qbs-
self.options.qt_version
self.options.profile
comment
Good
point
case
qmake
/usr/bin
conditional
necessary
comments
guide
code
blocks
Thanks
machine
qt5-qmake
qt4-qmake
Which
qmake
specific
path
os.path.exists
raise
RuntimeError
qbs
plugin
/usr/bin/qmake
path
Hopefully
correct
one
-D
QT_SELECT
env
var
QbsPlugin._build_environment
qt-chooser
magic
care
rest
run
time
correct
qmake
add
STRIP
=
PRIME
comment
backwards
compat
comment
check
important
example
output
pattern
packages
module
errors
_errors
symbols
specific
exception
+1
isinstance
use
isisnstace
Feels
less
comment
statement
None
potential
action
code
comment
initial
value
loop
problem
example
amd64
foo
try
bar
baz
process_grammar
entire
thing
top
level
list
try
*
Parsing
amd64
*
statement
None
None
statements
collection
]
https
//github.com/snapcore/snapcraft/pull/1059/files
diff-68c6d965d4ff21ecd61544afbc4bb051R119
new
OnStatement
*
Parsing
*
*
new
statement
]
https
//github.com/snapcore/snapcraft/pull/1059/files
diff-68c6d965d4ff21ecd61544afbc4bb051R68
OnStatement
onto
complete
collection
new
TryStatement
*
Parsing
*
clauses
nothing
OnStatement
TryStatement
]
https
//github.com/snapcore/snapcraft/pull/1059/files
diff-68c6d965d4ff21ecd61544afbc4bb051R95
presence
error
TryStatement
*
Parsing
complete
*
*
TryStatement
[
collection
]
https
//github.com/snapcore/snapcraft/pull/1059/files
diff-68c6d965d4ff21ecd61544afbc4bb051R77
*
[
Process
statements
collection
]
https
//github.com/snapcore/snapcraft/pull/1059/files
diff-68c6d965d4ff21ecd61544afbc4bb051R78
*
first
match
satement
=
None
Honestly
isinstance
duck
typing
pythonic
Happy
empty
line
blank
line
docstring
https
//www.python.org/dev/peps/pep-0257/
class
blank
line
multiple
returns
elif
final
assertions
constant
var
much
variable
way
value
property
plugin
self._runtime
exception
core
base
nothing
None
>
base
None
statements
comment
work
comment
implementation
_run
wrong
latest
pip
wheels
setuptools
args
=
[
'pip
'setuptools
'wheel
]
pip_command
=
[
self._get_python_command
'-m
]
pip
=
_Pip
exec_func=subprocess.check_call
runnable=pip_command
package_dir=self._python_package_dir
env=env
extra_install_args=
[
ignore-installed
]
python
host
tools
venv
central
steps
repo
install
prebuilt
wheel
debatable
benefits
nothing
breaks
account
wheels
dependencies
source
refactor
sure
args
args
answer
@
sergiusens
FIXMEs
install
below
wheel
python
forgiveness
permission
nicer
function
everything
falls
fact
defer
equivalent
more
apparent
contextmanager
simple
/
catch
catch
wink
Make
sure
pip
host
try
self._python_home
=
os.path.join
'usr
host
pip
own
pip
other
tools
self.download
'setuptools
'wheel
self.install
'setuptools
'wheel
own
pip
python
home
self._python_home
=
method
name
something
closer
sweep
entire
loaded
yaml
fine
previous
comment
guessed
name
tests
'snapcraft
name
behaviour
click
pointless
point
returns
specific
code
ignored
error
specific
code
ignored
error
logic
feels
groups
patching
everything
latter
statement
logical
patching
pathing
no-patchelf
patching
enable-patchelf
no-patchelf
last
possible
logger.warning
patch
precaution
elif
raise
RuntimeError
doctstring
method
code
comment
Worth
snapcraft
function
inject_snapcraft
right
place
little
comment
possible
URL
wstool
Comment
site
packages
entry
execution
path
case
mind
comment
rogue
comment
minor
edits
docstring
method
type
things
month
sense
date
name
bug
name
date
reason
VCS
try
catch
Make
get
exception
return
None
try
core_snap
=
cache.get
NotFoundInCache
core_snap
=
download
Raise
fails
save_to_cache
core_snap
core_snap
twice
wrong
approach
impossible
unit
test
proxy
unit
test
anything
run_mock
rustup
cargo
download
rid
'permissions
fifo
O_RDWR
_fifo_open
method
__init__
bug
scriptlet
errors
attributes
let
try
word
bit
confrontational
Please
code
comment
copyfile
next
person
wink
reply
kyrofa
code
comment
Uh
set
Same
Maybe
comments
user
attention
lines
tough
smdebug
modification
nit
commented
lines
comment
regex
.json
.csv
clear
groups
underscore
middle
Just
someone
file
format
bunch
files
add
comment
top
function
clear
check
minimal
argument
code
good
opportunity
comment
comment
Comment
tape
attribute
base
class
KerasHook
methods
AssertionError
method
SessionHook
tape
comment
pre-defined
collection
https
//github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md
collection
comments
ZCC
GradientTape
function
correct
nit
collections
prepared
same
lines
tf2
strategy
line
usage
var
https
//www.tensorflow.org/versions/r1.15/api_docs/python/tf/distribute/MirroredStrategy
https
//www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/distribute/MirroredStrategy
different
subtle
differences
imports
comment
set_optimizer_variables
calls
vanilla
custom
TF
right
custom
TF
call
set_optimizer_variables
same
set
tensors
different
additional
set_optimizer_variables
call
variables
c
Andrew
Kofink
Red
Hat
please
smile
comment
half
true
entity
spec
name
conversions
ansible
'the
program
original
GPL
Katello
proxies
certs
stuff
examples
docs
oddity
comment
https
//github.com/theforeman/foreman-ansible-modules/pull/864/files
r473665687
module
state=absent
invocation
API
same
time
*
entity
*
module
*
entity
invocation
deletion
updating
following
good
start
use
ForemanTaxonomicAnsibleModule
module.run
python
entity
=
module.lookup_entity
'entity
entity
None
module.ensure_entity
'job_invocations
module.foreman_params
entity
module.fail_json
msg=
job_invocation
lookup_entity
comment
search_by
suggestion
'command
module.foreman_params
searches
keys
default
Look
required_one_of
required_if
ansible
features
something
list
job-invoaction
whole
block
anything
template
correct
API
]
https
//github.com/theforeman/foreman/blob/develop/app/controllers/concerns/foreman/controller/parameters/template.rb
L11
template
key
layout
value
different
parameter
[
]
https
//github.com/theforeman/foreman/blob/develop/app/controllers/concerns/foreman/controller/parameters/ptable.rb
L10
agrees
API
]
https
//github.com/theforeman/foreman/blob/develop/app/controllers/concerns/foreman/controller/parameters/ptable.rb
L11
suggestion
results
results.values
]
readable
first
entry
dict
unsed
friendly_name
friendly_name
comments
following
assignments
redundant
actual
code
comment
worth
try/except
code
comment
instrumentation
key
admniistrator
admniistrator
HTTPRequestType
sdk/core/azure-core/azure/core/pipeline/__init__.py
Minor
filesystem
word
QQ
old
directory
new
directory
content
present
comments
line
so
future
confused
zikalino
duplicated
comment
public
API
test
catch
BaseException
s
docstring
>
Yield
refresh
tokens
account
scopes
subset
token
scopes
case
scopes
token.get
[
]
yield
case
refresh
token
family_id
need
[
KT
VT
]
acceptable
dependency
six.moves
pylint
disable=protected-access
code
snippet
tables
tables
separate
code
snippet
right
May
TINY
bit
explicit
RULE_SQL_COMPATIBILITY_LEVEL
tiny
little
comment
headers
blocks
constants
constants
X
Y
instance
random
instance
generic
rules
xml
schemas
something
Service-Bus
wide
XML
tags
understand-ability
parameters
other
possible
error
types
AuthenticationError
ConnectTimeoutError
possible
case
_enpoint_available
False
updated
key
new
key
same
name
curious
error_map
parameter
way
errors
code
value
modularity
method
async
credential
async
Arc
credential
different
policies
reasoning
constructor
matters
try
IndexError
method
ClientAuthenticationError
Arc
environment
authentication
suggestion
await
asyncio.sleep
message
long
period
E.g
application
logic
comment
effort
suggestion
renewer.register
msg
timeout=100
Message
processing
registration
processing
longer
seconds
autorenewer
lock
message
verbose
hell
anything
processing
registration
suggestion
await
asyncio.sleep
message
long
period
E.g
application
logic
suggestion
time.sleep
message
long
period
E.g
application
logic
states
details
Array
JSON
objects
similar
comments
re
optionality
docstring
None
Are
AsyncHttpTransport
correct
Input
type
HTTPRequestType
imports
necessary
suggestion
type
str
AzureKeyCredential
>
None
shame
code
SeachServiceClientBase
sample
files
docstrings
format
example
https
//github.com/Azure/azure-sdk-for-python/blob/master/sdk/storage/azure-storage-blob/samples/blob_samples_common.py
L10-L17
guarantee
headers
OT
KeyError
policy
NEVER
suggestion
connection
properties
component
parts
something
heavy
comment
flow
SAS
token
path
type
hint
correct
params
Suggest
first
sentence
class
names
conflict
sync
classes
style
point
consideration
classes
tests
module-level
functions
*
*
Any
SupportsGetToken
[
]
length
=
changes
other
PR
heads
order
Just
problem
disable=missing-client-constructor-parameter-
*
*
credential
*
*
discussion
today
office
credential
param
singular
plural
protocol
span
type
annotation
SyntaxError
messages
helpful
path
type
ignore
None
docstring
comment
exc_type
None
raise
ValueError
raise_with_traceback
except
clauses
comment
change
temporary
code
generation
_version.py
files
sample
code
renewable.auto_renew_error
self._renewable
renewable
error
message/session
renewable
on_lock_renew_failure
renewable
discussion
receiver
message
alive
test
case
Thank
comments
comment
decorator
functions
comment
top
get_parent
high
level
outline
.join
str
x
x
self._sync_tokens.values
reason
Same
comment
re
parameter
name
Same
comment
re
parameter
name
Deserve
comment
per
team
last
doc
meeting
Markdown
template
Same
compatiblity
stuff
assert
True
assert
recommended
pytest
syntax
Valid
point
tough
discussion
least
link
//github.com/Azure/azure-sdk-for-python/wiki/Contributing-to-the-tests
consumer
client
kind
call
processing
span
suggestion
receiver
new
session
receiver
thing
above
tweak
<
waves
github
multi-line
suggestions
motivation
pitfalls
WRT
next
session
IDs
diversity
session
failure
modes
original
verbage
implied
service
reason
other
languages
custom
type
context
valid
values
/
/keys
specific
Key
resource
Id_
pythonic
way
same
thing
nit
type
hint
uuid.UUID
Iterable
other
libraries
issue
]
https
//github.com/Azure/azure-sdk-for-python/issues/13373
Nit
few
comments
units
nit
pyPI
>
installs
pyPI
classes
use
methods
user
CommunicationAreaCodesSamplesAsync
datetime
import
datetime
type
checking
unused-import
error
datetime
import
datetime
type
import
section
Rather
private
function
EventData
disable
separate
util
function
def
get_last_enqueued_event_properties
event_data
last
enqueued
event
received
event
delivery
annotations
rtype
Dict
[
str
Any
]
event_data.message.delivery_annotations
=
event_data.message.delivery_annotations.get
PROP_LAST_ENQUEUED_SEQUENCE_NUMBER
None
enqueued_time_stamp
=
event_data.message.delivery_annotations.get
PROP_LAST_ENQUEUED_TIME_UTC
None
enqueued_time_stamp
enqueued_time_stamp
=
utc_from_timestamp
float
enqueued_time_stamp
/1000
retrieval_time_stamp
=
event_data.message.delivery_annotations.get
PROP_RUNTIME_INFO_RETRIEVAL_TIME_UTC
None
retrieval_time_stamp
retrieval_time_stamp
=
utc_from_timestamp
float
retrieval_time_stamp
/1000
=
event_data.message.delivery_annotations.get
PROP_LAST_ENQUEUED_OFFSET
None
offset
=
offset_bytes.decode
'UTF-8
offset_bytes
None
return
offset
enqueued_time
enqueued_time_stamp
retrieval_time
retrieval_time_stamp
None
unlikely
tool
comment
markdown
sample
soft-delete
scenarios
place
soft-delete
allows
other
samples
shorter
length
execution
time
likely
same
https
//github.com/Azure/azure-sdk-for-python/pull/5883
discussion_r294397116
same
https
//github.com/Azure/azure-sdk-for-python/pull/5883
discussion_r294397116
same
https
//github.com/Azure/azure-sdk-for-python/pull/5883
discussion_r294397116
single
REST
call
multiple
ones
master
methods
inherit
boolean
type
annotation
out-of-date
specific
reason
default
value
parameter
Are
certain
none
positional
arguments
optional
legitimate
answer
😄
sid
names
nit
commented
line
comment
same
comment
sync
sure
customers
copy
entity
dictionary
able
something
=
dict
source
shallow
copy
to_send.pop
'_metadata
None
Remove
metadata
copy
type
comment
function
get_connection_manager
return
type
comment
protocol
value
kty
found_body
unnecessary
body
]
==
RSA
return
end
function
assert
False
request
body
Add
keyword
loop
keyword
loop
request_id
policy
creation
scenario
reason
*
name
*
header
scenario
new
keyword-only
constructor
parameter
breaking
change
service
Copy-paste
mistake
comment
results_per_page
parameter
important
by_page
@
annatisch
Cosmos
PR
relevant
unhappy
more
robust
bit
verbose
output
data
\_\_repr\_\_
unambiguity
aspirations
comment
moot
only
enqueued_time
broad
handwaving
precise
exception
precision
self-guilt
sort
comment
\_\_repr\_\_
commence
P
docstrings
types
~
linking
[
~azure.data.tables.TableEntity
]
Hi
@
xiafu-msft
DirectoryClient
url-encoding
path
bar/baz
%
Please
behaviour
accurate
Hi
@
xiafu-msft
FileClient
url-encoding
components
path_
bar/baz/file
behaviour
correct
current
package
behaviour
first
model
model
=
next
custom_models
print
model.model_id
content
gate
include_text_content
different
docstring
name
optional
label
Per
comment
accuracies
let
comment
let
move
END
snippet
tables
TODO
suggestion
list_data_sources
get_data_source
delete_data_source
comment
queue_message
comment
closer
line
Nitpicking
condition
arguments
suggestion
url
secret
thumbprint
Service
Fabric
identity
available
environment
None
return
dict
_identity_config=identity_config
base_headers=
Secret
secret
request_factory=functools.partial
_get_request
url
version
version
version
portions
true
accounts
same
user
case
accounts
username
possible
😸
Which
thinking
username
cache
accounts
multiple
unidentified
users
username
len
accounts
usernames
account.get
username
account
accounts
usernames
usernames
None
intent
user
name
more
account
previous
version
code
multiple
accounts
user
name
other
words
check
username
None
len
accounts
return
None
loop
accounts
Nitpicking
improvement
module
preparer
New
tests
assert
unittest.TestCase
assertions
suggestion
assert
parsed_key_id.name
==
key_name
MessageSizeExceededError
add_message
size
ValueError
part
redundant
user
ValueError
Better
hopeless
markdown
e.g
See
https
//
more
information
soft-delete
docstring
case
value
relevant
function
name
span
docstring
tough
kind
supports
serial
comma
type
hint
arbitrary
triple
function
parent_span
argument
parent_span
get_parent
parent
triple
reason
parent_span
second
parameter
Optional
type
hint
signature
parent_span
parent_span
orig_wrapped_span
i.e
current
span
third
thing
current
span
uncertain
setting
questions
return
current
span
current
span
current
span
should_use_trace
argument
good
None
particular
set
parameters
different
util
module
boilerplate
conn
str
function
map_error
value
anything
single
line
comments
sync
client
self.max_wait_time
+
time
receive
time
AFAIK
receive
times
reconnection
receiver
default
config
max_wait_time
unit
seconds
seconds
time
trigger
reconnection
Suggest
default
value
amqp
most
users
web
socket
code
part
sample
web
socket
Same
comment
merge
function
main
receive
client
easier
Just
clarity
example
end
specified
partition_id
load-balance
example
client.receive
on_event=on_event
partition_id=
Similar
comment
option
partition_context
dict
acceptable
on_error
callback
partition_context
None
sure
samples
good
practice
partition_context
partition_context.partition_id
position
third
last
event
partition
sample
snippet
data
source
indexer
lines
data
source
part
least
snippets
data
source-specific
sample
file
Does
value
successful
cases
error.error.code
above
function
code
InvalidArgument
example
service
team
extra
check
sorry
i
sure
case
user
input
sure
id
exception
sure
innererror
swagger
safe
error
code/message
innererror
innererror
hasattr
check
_close_connection_async
concern
connection
future
EventHubError
link/session
level
error
connection
result
poller
something
sample
valuable
user
sample
different
RIDs
ids
database
collection
reproducable
better
RID
item
id
fly
use
permission_definition
syntax
~azure.digitaltwind.DigitalTwinsEventRoute
docstrings
type
hints
imported
model
suggestion
Spans
creation
OpenTelemetry
comment
reason
part
ABC
class
nothing
implementation
exists
pass
something
span
creation
OT
something
pylint
pragma
necessary
initializer
other
places
same
comment
applies
print
statement
\n
..
Certificate
bad
Are
content-type
response.headers
line
client
response
current
time
distant
time
request
request_time
suggestion
self._last_refresh_time
=
request_time
matter
last
refresh
time
dequeue
empty
list
case
only
suggestion
try/except
blocks
own
functions
get_status_code
get_content_type
kind
implementation
more
hidden
common_key
common_candidates
right
Shall
multiple
test
cases
message
Nitpick
list
necessary
iterable
sure
link
long
anchor
new
section
[
questions
https
//tmt.readthedocs.io/en/latest/questions.html
anchor
stories
identifier
dict
structured
field
[
purpose-file
]
Just
run
help
sure
binary
sane
simple
more
fmf
]
'/
'/home/psss/git/tmt/examples/convert
'test-export
'github.com
psss/tmt.git
structured-field-end
]
yaml
dictionary
fmf
identifier
[
examples
https
//fmf.readthedocs.io/en/latest/concept.html
identifiers
provisioners
opts
@
psss
needs
proper
override
case
env
L1
results
traceback
Requires
Makefile
File
/home/psss/git/tmt/tmt/cli.py
line
convert
data
=
tmt.convert.read
path
makefile
nitrate
purpose
/home/psss/git/tmt/tmt/convert.py
line
read
data
[
'requires
]
KeyError
test
hard
RhtsRequires
case
directory
structure
deep
space
min
block
n
index
arr
condition
looks
better
piece
code
i
bug
free
point-out
arr
[
]
>
target
return
array
value
block
<
=
n
arr
[
block
]
<
target
block_prev
=
block
block
+=
block_size
space
comments
suggestion
idx
f
=
front
se
snake
case
variables
bit
mask
O
algo
same
PR
ditto
class
function
goswami-rahul
N^2
Thanks
contribution
third
party
libraries
possible
implement
everything
project
use
integer
division
//
please
use
None
default
value
arguments
function
mutable
type
[
]
algorithms
names
strip_url_params1
strip_url_params2
library
urlparse
available
urllib.parse
@
keon
a^b
path.rpartition
'/
easier
[
str.rpartition
]
https
//docs.python.org/3/library/stdtypes.html
str.rpartition
animatable
redundant
default
state
properties
properties
attribute
animatable
default
update_sv_links
process_from_nodes
get_effected_nodes
=
True
self.process
check
top
processing
outputs
//github.com/nortikin/sverchok/blob/master/utils/modules/geom_utils.py
fine
socket.is_linked
i
indentation
level
rest
block
[
'Vertices
]
family
listMatcher
[
vertsAll
radiusAll
verticesAll
edgesAll
]
self.listMatch
human
way
something
way
suggestion
next_mutation_success=
random
next_mutation_success
<
mutation
success_barrier
next_mutation_success
success_barrier
total
gene
new_gene
=
o_gene.min_n
+
random
o_gene.range
string
next
few
cases
comment
line
code
lines
check
directory
raise
ValueError
Please
Entrez.cache
directory
name
None
self
separate
comment
separate
test
method
e.g
def
test_count_overlap_start_end
efficient
way
copy
array
python
self._data
=
data._data
[
]
copy
comment
Again
False
ideas
letter
long
ID
longest_possible_len_of_26
maximum
possible
old_max_name_length_was_26
characters
Please
brief
comment
logic
standard
copyright
license
header
comment
underscores
implied
private
public
API
indentation
comment
strange
comment
least
stray
L
end
comment
same
explanation
Sphinx
examples
special
comment
noqa
A502
flake8-assertive
thinking
parser
literal
value
True
value
true
non-empty
string
list
Anyone
second
opinion
comment
line
code
line
black
style
different
previous
check
nothing
cols
elif
len
cols
tests
related
note
ok
entire
loop
re-written
cols
x
x
self.line.strip
.split
]
cols
raise
ValueError
Less
columns
%
i
%
len
cols
]
=
'.join
cols
]
same
effect
previous
if-clauses
line
look
problem
cases
self.assertEqual
self.assertNotEqual
source
code
https
//github.com/python/cpython/blob/master/Lib/unittest/case.py
originals
self.assertFalse
clearer
self.assertEqual
False
second
opinion
lines
special
comment
noqa
A500
flake8
warning
flake8-assertive
@
MarkusPiotrowski
comment
HTML
headers
present
network
handle
context
hard
lsplit
comment
lines
r
split
comment
lines
Minor
style
point
TravisCI
flake8
Bio/
Bio/SearchIO/BlastIO/blast_tab.py:160:1
D202
No
blank
lines
function
Performance
issue
single
bytes
temp
=
ValueError
Empty
file
temp
raise
ValueError
bytes
handle
current
exception
specific
raise
ValueError
file
byte
header
incomplete
temp
obvious
reason
original
code
value
different
versus
fine
noqa
W291
comment
closing
triple
flake8
complains
whitespace
expected
output
Same
applies
noqa
E731
line
lambda
flake8
fine
needs
integer
etc
elif
lots
stray
comment
markers
strange
indentation
Please
space
indentation
stray
comment
line
other
please
Comment
ImportError
change
Tiny
style
issue
flake8
flake8
./Tests/test_PDB.py:687:9
E303
many
blank
lines
blank
line
default
values
comment
least
rephrase
suggestion
include_package_data=True
MANIFEST.in
setuptools
old
code
level
special
case
Minimum
Alignment
Matrices
dm
new
code
len
dm
old
code
dm
new
code
len
dm
old
code
diff
smaller
easier
straight
brackets
necessary
only
option
comment
Using
seconds
NCBI
rate
limit
pause
seconds
reliable
value
code
comments
looks
typo
comment
Me
wrong
break
reading
harder
loop
nice
busted_pipelines
'stylesheets
]
generator
list
surprising
something
key
=
busted_pipelines
[
'stylesheets
]
.keys
]
break
less
surprising
code
intention
Using
first
item
weird
break
code
helpful
busted_pipeline
values
generators
good
practice
language
something
thing
things
Python
keys
*
view
*
list
keys
copy
things
things
comment
Ha
negative
effect
code
line
line
line
more
lines
Just
easy
something
code
something
key
list
raw_crash.keys
iterate
*
copy
*
keys
reason
key
raw_crash
comment
API
documentation
endpoint
mm/dd/yyyy
format
skip
index
https
//github.com/mozilla-services/socorro/blob/master/socorro/lib/transform_rules.py
L91
bad
more
clear
try
suggestion
NOQA
E501
line
drop
extra
points
obs_resampled
data
[
fx
]
add
NaNs
times
data
[
fx
]
exists
obs_resampled
comment
long
run
observation
quality
flag
extra
line
Aw
variable
closed
label
Just
clear
correct
data
[
inherit
]
.resample
inherit.interval_length
i
embarrassed
Good
point
test
case
good
point
case
reference
forecast
option
function
reporting
resample
interval
argument
only
Observations
nice
isinstance
model
datamodel.Observation
logical
separation
checking
datamodel.Forecast
data
dictionary
object
key
actual
timeseries
data
pd.Series
Nighttime
version
version
lines
sense
comment
motivation
approach
clear
forecast.run_length
short
yes
solar
gen
variable
name
comment
future
reference
implication
source=None
display
bars
flags
least
occurrence
suggestion
inconsistency
line
mess
comments
torn
looping
arrays
case
most
iterations
extra
work
reliability
resolution
uncertainty
Again
code
efficient
harder
Overall
comment
way
ease
reliability
resolution
calculations
functions
similar
API
standpoint
good
implementation
single
function
reliability_resolution
def
reliability_resolution
fx
fx_prob
obs
calculation
return
rel
def
reliability
fx
fx_probs
obs
return
reliability_resolution
fx
fx_probs
]
def
resolution
fx
fx_probs
obs
return
reliability_resolution
fx
fx_probs
]
private
function
_reliability_resolution
api
simple
public
function
def
reliability_resolution_uncertainty
return
_reliability_resolution
uncertainty
implementation
correct
more
clear
reader
f_i
N_i
np.nditer
np.unique
f
return_counts=True
o_i
=
np.mean
o
[
f
==
]
rel
+=
N_i
*
o_i
rel
/=
len
f
Good
suggestion
comments
forecast
<
MW
%
probability
correct
list
comprehensions
None
args
x
=
np.sort
np.concatenate
avoids
interpolation
ECDF
sides
documentation
right
endpoint
rule
default
ECDF
f
ECDF
[
]
f
x
x
<
suggestion
%
previous
value
fill
upward
behavior
suggestion
constant
values
symmetric
create
intervals
necessary
df
[
i
]
suggestion
integrand
=
o
suggestion
NOQA
E501
suggestion
%
s
reference
forecast
fx.forecast_id
suggestion
instantaneous
labels
last_probable_issue_time
min
=
interval_length
last_probable_issue_time
forecast.interval_label
=
last_probable_issue_time
forecast.interval_length
copy
pasta
part
much
important
function
easier
model
interpolate
v
_interpolate_slice
sets
args
def
_interpolate_slice
forecast
*
slice_only_args
interpolate_slice_args
interval_label
start
end
freq
start_adj
end_adj
=
adjust_start_end_for_interval_label
interval_label
start
end
=
list
slice_only_args
deepcopy
args
+=
[
forecast.interpolate
v
freq=freq
v
interpolate_slice_args
]
return
slice_args
args
start=start_adj
end=end_adj
r
result
little
confusing
context
r
metric
res
similar
check
Event-type
forecasts
observations
deterministic
anything
datamodels
same
comment
move
loop
@
cwhanse
approach
normalization
reasonable
irradiance
variables
GHI
DNI
DHI
POA
+1
separate
test
fixture
parameters
new
test
thte
duplication
reference
comment
sum
DataFrame
Series
sums
overall
total
whole
DataFrame
comment
suggestion
NOQA
E501
Raises
section
functions
suggestion
e.g
Prob
o
MW
Forecast
%
constant
value
MW
object.__setattr__
cls
'constant_value_units
cls.units
good
idea
sure
handling
site.site_id
=
fx_dict
[
]
ValueError
same
suggestion
stacking
null
characters
same
name
GH463
val
ser
data
[
[
'abbrev
]
]
.groupby
'abbrev
suggestion
ok
null
characters
end
labels
=
x_values.map
lambda
x
len
x.rstrip
'\0
ok
change
short
term
inconsistent
comment
Could
issue
references
cds
nix
insert
comment
pvwatts_ac
comment
maintainability
comment
block
Easier
rid
reverse
hard
time
True
blocks
code
clear
something
>
>
>
itertools
import
chain
>
>
>
=
chain
range
range
range
>
>
next
c
>
>
>
next
c
w/
error
error
none
below
way
suggestion
total_cost
=
np.sum
error
cost
efficient
sum
error
cost
parts
code
code
many
poses
same
sim_time
first
pose
sim_time
change
sense
base/mixin
class
__enter__
__exit__
calls
copies
same
code
limit
ROS
tf_conversions.transformations.euler_from_quaternion
<
pre
>
>
>
>
help
tf_conversions.transformations.euler_from_quaternion
Help
function
euler_from_quaternion
module
tf.transformations
euler_from_quaternion
quaternion
axes='sxyz
Return
Euler
angles
quaternion
axis
sequence
>
>
>
angles
euler_from_quaternion
[
]
>
>
numpy.allclose
angles
]
True
END
/pre
older
comment
sim_time
interested
time
s/rspect/respect
hm
functions
capital
letters
class
kind
factory
hmm
sure
tank
place
intentional
d
[
]
dt
reason
heading
unexpected
simpler
suggestion
self.finish_time
=
int
self.robot_name
]
T100
example
[
math.radians
degrees
https
//docs.python.org/3/library/math.html
math.radians
kind
conversion
spaces
PEP8
possible
threads
daemon
daemon
threads
abrupt
resources
context
managers
thread
OS
level
AFAIK
threads
well-behaved
exit
bus
mechanism
timeout
recv
thread
self.bus.is_alive
false
config
anything
prev
previous
sequence
name
propagation
history
joint
numpy-style
numpy
something
python
i
arft_type
position
_
_
enumerate
dist
=
distance3D
p
[
x/1000.0
x
position
]
dist
[
i
[
-1
]
=
data
'score_change
]
>
return
ok
only
position
likely
different
artifacts
exact
same
position
comment
artf_all
call
publish_artf
call
functionality
TfDetector
i.e
CamelCase
above
comment
assumption
quaternion
first
good
assumption
unexpected
input
Second
block
kind
normalization
’
t
_HostWrapper_
data
dictionary
_stale_timestamp_
argument
_facts_
separate
instruction
python
host_data
=
test_data
facts=None
stale_timestamp=
timedelta
weeks=3
host_data.data
suggestion
suggestion
def
test_ignore_culled_host_on_update_by_elevated_id
host_to_create_data
=
test_data
insights_id=generate_uuid
stale_timestamp=
timedelta
weeks=3
Create
host
response
=
self.post
HOST_URL
[
host_to_create_data
]
self._verify_host_status
response
created_host
=
self._pluck_host_from_response
response
Update
host
host_to_update_data
=
*
*
host_to_create_data
ip_addresses
]
new_response
=
self.post
HOST_URL
[
host_to_update_data
]
self._verify_host_status
new_response
updated_host
=
self._pluck_host_from_response
new_response
self.assertNotEqual
id
]
updated_host
[
id
]
suggestion
aws_stream_name
=
os.getenv
AWS_LOG_STREAM
_get_hostname
default
comment
XJOIN_GRAPHQL_URL
obvious
extra
comment
anyone
na
comment
metric
nice
comment
statement
attributes
host
good
comment
inaccurate
regex
prevents
ReDoS
search
mechanics
injected
string
literal
match
regex
only
appropriate
way
non-regex
search
fields
suggestion
Test
host
schemas
fields
TODO
method
TODO
necessary
i.e
message
script
constructor
obj
A
data
representation
obj
dict
code
comment
suggestion
hosts
different
process
event
OK.
self.delete
url
global
keyword
possible
class
properties
instance
properties
client
active
life
container
much
trouble
..
python
class
Test
object
CLS_PROP
=
None
def
__init__
Test.CLS_PROP
Test.CLS_PROP
def
get_prop
return
self.CLS_PROP
i
range
i
object
print
prop
init
%
d
%
s
%
i+1
Test.CLS_PROP
tester
=
Test
print
prop
init
%
d
%
s
%
i+1
Test.CLS_PROP
print
'Instance
prop
init
%
d
%
s
%
i+1
tester.get_prop
client
class
*
EDIT
*
*
Pardon
naivety
client
wrapper
context
particular
error
okay
only
logs
others
different
actions
private
instance
methods
list
jack
result
save
binary
fact
mea
if/else
logic
code
True
return
statement
Copy-pasta
comment
policy
Great
comment
above
block
block
ie
is_excluded_ioc
ioc_type
ioc_value
IOC
lookup
IOC
Args
ioc_type
type
IOC
md5
ip
domain
value
value
IOC
Returns
IOC
lookup
value
False
IOC
ioc_type
==
try
ip_addr
=
IPAddress
str
ioc_value
=
self.excluded_iocs.get
return
in_network
ip_addr
excluded_networks
pylint
disable=bare-except
LOGGER.error
IOC
Exclusion
%
s
ioc_value
return
True
return
ioc_value
self.excluded_iocs.get
ioc_type
good
catch
comment
check
suggestion
check
_request_token
version
less
Thanks
code
comment
PR
Hz
Hz
common
audio
many
speech-related
tasks
Hz
Hz
run
time
current
order
TorchaudioTestCase.setUp
Which
TestBaseMixin.setUp
self.backend
future
more
functionality
other
mixins
robust
Thoughts
Mocked
audio
data
files
different
seed
value
files
same
sake
test
reproducibility
test
helper
functions
deterministic
default
fixed
seed
value
dataset
implementation
files
order
variable
sample_rate
=
something
future
easier
way
hack
case
librispeech_test
dataset
audio
extension
constructor
TEDLIUM
audio_ext
tedlium.TEDLIUM._ext_audio
=
.wav
=
tedium.TEDLIUM
self.root_dir
audio_ext=
.wav
suggestion
utterance
UTTERANCES
enumerate
mocked
datasets
releases
releases
separate
test
case
method
sha256sum
different
values
Which
sha256sum
archives/tedlium/
*
archives/tedlium/TEDLIUM_release-3.tgz
archives/tedlium/TEDLIUM_release1.tar.gz
modification
user
code
user
experience
suggestion
self._phoneme_dict
[
content
]
]
=
tuple
content
[
]
content
[
]
empty
list
frame_offset
arguments
directory
entire
audio
file
sample_rate
beforehand
sample
rate
torchaudio.info
performance
issue
file
fine
TED-LIUM
dataset
[
Hz
]
discussion
NamedTuple
new
comment
prior
discussion
type
data
points
particular
NamedTuple
[
internal
document
]
https
//fb.quip.com/vlWwA35cmq0t
value
data
point
discussion
pull
request
function
private
suggestion
def
_load_tedlium_item
fileid
str
line
int
path
str
>
Tedlium_item
file
Different
OS
files
different
order
suggestion
file
stm_path
true
walker
other
datasets
stm
files
job
same
folder
duration=6
specific
YesNo
dataset
something
smaller
please
seed
value
data
same
shape
above
comment
randomness
tricky
case
failure
everything
failure
case
seed
case
question
Are
randomness
randomness
wider
coverage
test
cases
generated
samples
homogeneous
Dataset
class
more
multiple
samples
code
way
Dataset
traverses
Which
ultimate
motivation
test
https
//github.com/pytorch/audio/issues/794
context
code
contents
module
level
hope
improved
readability
module
level
train_csv_headers
client_ids
path
sentence
up_votes
down_votes
age
gender
accent
]
Note
extension
sake
test
Note
first
content
values
age
gender
accent
original
data
train_csv_contents
=
[
common_voice_en_18885784.wav
State
funeral
Drayton
Toowoomba
Cemetery
c82eb9291328620f06025a1f8112b909099e447e485e99236cb87df008650250e79fea5ca772061fb6a370830847b9c44d2078cfa0f601b1f8cf6b98c479a7fc
common_voice_en_556542.wav
breach
thirties
male
f74d880c5ad4c5917f314a604d3fc4805159d255796fb9f8defca35333ecc002bdf53dc463503c12674ea840b21b4a507b7cd0b3c636434f9a06bd81538de4f9
common_voice_en_18607573.wav
Caddy
Miss
Clare
Miss
Summerson
rooms
twenties
male
canada
]
setUpClass
writer.writerow
train_csv_headers
i
content
enumerate
train_csv_contents
writer.write
content
audio_filename
=
content
]
data
=
get_whitenoise
sample_rate=cls.sample_rate
duration=1
seed=i
dtype='float32
f
i:04d
patterns
kind
comments
ones
more
information
code
expresses
necessary
comment
TODO
NOTE
information
necessary
iterating
metadata
path
Linter
anyway
>
random
test
complexity
benefit
comment
https
//github.com/pytorch/audio/pull/827
discussion_r460899418
random
Directory
structure
real
dataset
directory
names
following
details
bed
bird
cat
follow
happy
house
learn
marvin
off
right
sheila
stop
tree
visual
wow
yes
/details
supposed
label
values
dataset
Dataset
directories
alphabetical
order
samples
expected
order
nit
spaces
nit
conventional
spaces
inline
comment
output
=
resblock
input
shape
same
=
torch.rand
random
spectrogram
data
first
value
i
constant
c
prime
number
p
So
element
element
i
+
c
mod
p
element
element1
+
c
mod
trial
same
data
implementation
comments
torch.cat
expensive
faster
DCT
matrix
matmul
latter
limited
number
self.n_mfcc
components
Old
implementation
def
create_dct
dim
outdim=None
orthogonal=True
DCT
transformation
matrix
@
param
dim
Dimensionality
input
data
@
param
outdim
matrix
first
DCT
coefficients
full
DCT
matrix
@
param
orthogonal
transform
orthogonal
@
transformation
matrix
right-multiplied
data.
outdim
None
outdim
=
dim
elif
outdim
>
dim
raise
ValueError
DCT
outdim
larger
dim
http
//en.wikipedia.org/wiki/Discrete_cosine_transform
DCT-II
n
=
np.arange
dim
k
=
np.arange
[
np.newaxis
]
dct
=
np.cos
np.pi/dim
*
n
+
k
orthogonal
dct
]
*
/
np.sqrt
dct
*
=
np.sqrt
/
dim
return
matrix
construction
time
torch
numpy
forward
pass
docstring
strong
warning
top_db
output
maximum
value
spectrogram
e.g.
different
outputs
audio
file
snippets
whole
same
applies
MFCC
default
top_db
nit
comment
documentation
enough
_ext_audio
walker
__init__
files
extension
able
something
[
mask1
]
=
torch.tensor
-2.0
/
dtype=dtype
device=device
comment
constant
Tensor
Torchscript
same
dtype
input
tensor
i.e
diff
@
@
-1262,23
+1262,24
@
@
def
overdrive
http
//sox.sourceforge.net/sox.html
actual_shape
=
waveform.shape
+
device
dtype
=
waveform.device
waveform.dtype
actual_shape
waveform
=
waveform.unsqueeze
gain
=
_dB2Linear
gain
colour
colour
/
last_in
=
torch.zeros
waveform.shape
]
waveform.shape
]
last_out
=
torch.zeros
waveform.shape
]
waveform.shape
]
last_in
=
torch.zeros
waveform.shape
]
waveform.shape
]
dtype=dtype
device=device
last_out
=
torch.zeros
waveform.shape
]
waveform.shape
]
dtype=dtype
device=device
sys.float_info.epsilon
EPSILON
compute_spectral_flatness
energy
amplitudes.pow
sure
bug
point
logic
filters
yaml
chunk
*
_upload
jobs
Linux
Python
logic
behavior
sure
rationale
intentional
Nit
regular
Tensors
inputs
edge
behavior
something
user
future
people
deltas
frames
TODO
Replace
torchaudio
https
//github.com/pytorch/audio/pull/593
suggestion
workflow
split
functionality
percentage
Redefine
ProcessedLJSpeech
transforms
Use
MapMemoryCache
*
natural
percentage
number
other
dataset
Thoughts
*
curious
others
choice
word
train
test
validation
development
evaluation
something
Thoughts
def
gen_datasets_ljspeech
args
transforms
data
=
LJSPEECH
root=args.file_path
train_dataset
split_data
data
args.val_ratio
args.seed
train_dataset
=
train_dataset
transforms
=
val_dataset
transforms
=
MapMemoryCache
MapMemoryCache
val_dataset
return
train_dataset
python
class
Splitted
def
__init__
indices
=
dataset
self._indices
indices
.__init__
def
__getitem__
key
return
self._dataset
[
[
key
]
]
def
split_data
data
val_ratio
seed
random.seed
seed
=
random.sample
range
data
int
val_ratio
*
len
data
val_indices
[
i
i
range
data
train_indices
]
return
Splitted
data
train_indices
Splitted
data
val_indices
python
class
def
__init__
transforms
=
dataset
self.transforms
transforms
.__init__
def
__getitem__
key
item
=
self._dataset
[
key
]
return
self.process_datapoint
item
def
process_datapoint
item
return
target
def
__len__
return
len
curious
others
choice
word
train
test
validation
development
evaluation
same
remove
Please
standard
docstring
comment
nit
indentation
same
torch
comment
definition
linear_to_mel
nit
sure
necessary
comment
redundant
PR
code
comment
Legacy
API
label
TODO
Remove
parameter
deprecation
epoch
meaning
context
pytorch
nit
let
use
density_function
parameters
exchange_candidate
Abstract
subclass
*
*
exchange_type
*
*
guess
Please
change
lspci
output
Please
clarify
variable
name
f
please
valid
variable
name
least
length
please
sure
port
'port
info
<
portid
>
command
port
timeout
messages
light
siganl
linux
side
indentation
comment
check
Arabic
numbers
test
Galician
Spanish
numbers
Wrong
comment
suggestion
parse_kwargs
keyword
arguments
TiffFile
class
tiff_keys
dictionary
in-place
kwargs_tiff
=
parse_kwargs
*
tiff_keys
suggestion
algorithm
channels
present
array
fashion
dimension
=
np.ascontiguousarray
image
[
c
c+1
]
stack
level
correct
Gah
sorry
form
phone
hard
level
warning
sure
safe
few
issues
other
circumstances
line
necessary
suggestion
suggestion
data
=
cells3d
dependency
*
slightly_smiling_face
same
thing
use
itertools
product
paragraph
one
cautious
skimage
sure
way
future
proof
newcomer
Remove
extra
line
suggestion
suggestion
ax.imshow
tf_img
plt.show
suggestion
inverse
first
translation
utility
function
output
lines
suggestion
closing
parenthesis
affine
transformations
second
option
degrees
poor
choice
piece
therefore
super
tricky
image
analysis
Suggestion
transformation
image
image
transformation
useful
coordinate
input
image
output
transform
pixel
coordinate
*
output
*
image
input
image
*
inverse
*
tform
html
page
little
issue
sign
blank
line
suggestion
ax.set_title
transformation
plt.show
necessary
bottom
See
suggestion
assert
abs
flow
gt_flow
First
time
way
dtypes
bit
brittle
cases
such
np.float64
==
float64
False
use
np.float64
similar
other
places
Done
suggestion
ramp
filter
fourier
transform
frequency
domain
representation
artifacts
small
bias
[
]
fourier_filter
*
np.real
fft
f
filter
pre-allocated
array
test_ineq_temp
tolerance
out=coords_single_ineq
readable
sure
measurable
improvement
performance
suggestion
return
img_as_float
image
convert
concistancy
clear
arr_in
grayscale
fill
scalar
neccessary
upcast
ndarray
ndim
np.asarray
scalar
array
indexing
https
//github.com/scikit-image/scikit-image/pull/2626/files/95a8513cfaee0e99cf85f75c091a7575e89499c8
diff-81a8a5406b37c24a621cf34d9208fcc0R115
@
soupault
Well
readable
option
fill
=
np.atleast_1d
fill
amazed
float
>
*
=
<
array
>
suggestion
Spacing
minimum
distance
Several
suggestions
step
min_distance
correct
description
parameter
docstring
similar
part
*
min_distance
clearer
Cython
rid
slow
loop
PR
suggestion
transform
coordinates
global
image
indices
space
docstring
=
suggestion
Vendored
i.e
suggestion
scikit-image
convention
suggestion
available
pooch
version
version
docs
sciunto
comment
test
testing.raises
ValueError
equal
sum
pixel
intensities
value
descriptor
equal
difference
sums
intensity
values
green
red
rectangles
Different
types
Haar-like
feature
descriptor
feature
value
dst
[
:2
]
/=
dst
[
]
Broadcasting
[
Figure_2
]
https
//user-images.githubusercontent.com/263366/93184334-656d9400-f73c-11ea-83e3-52426195bc66.png
series
tricks
PR
voxels
array
indices
more
comments
bit
cryptic
PR
full
string
TypeError
example
case
typos
flat
float
output_dtype
None
none
ifs
True
np.array
[
]
dtype=None
suggestion
rect_ax.set_axis_off
line
CI
failures
suggestion
skimage.data
import
path
=
image_fetcher.fetch
'data/cells.tif
img_orig
=
io.imread
path
informative
Rescale
image
intensity
iax
readibility
True
hashtags
sphinx
imports
main
issue
8-bits
image
other
image
dtypes
suggestion
careful
point
images
radius
topic
ball/cap
ellipsoid
different
shape
ball/cap
particular
borders
kernel
non-square
kernels
terminology
ellipsis
vertex
terminology
ball
radius
suggestion
other
np.uint8
suggestion
skimage
import
img_as_float
image
=
img_as_float
data.coins
suggestion
parameters
spatial
dimensions
intensity
dimension
comparison
plot
last
commit
Will
suggestions
much
Compute
time
aspect
reasonable
kernel
small
axis
good
axes
large
good
example
clear
advantage
ellipsoid
wrong
visualization
skimage
limited
plane-wise
slices
image
identical
ellipsoid
data
=
np.zeros
dtype=np.uint8
note
rescaling
docstring
nice
solution
happy
question
https
//github.com/scikit-image/scikit-image/pull/3515
issuecomment-447579732
more
explicit
code
easier
original
papers
docstring
Great
nD
computations
equivalent
hessian_nd_matrix/eigenvalues
functions
functions
feature
module
results
identical
much
cleaner
thanks
Hessian
stuff
feature
module
general
spot
reasonable
discussion
https
//github.com/scikit-image/scikit-image/pull/3515
issuecomment-433627181
Please
docstring
returned
value
docstring
returned
value
file
_io.py
file
something
[
'ax
]
returned
fig
https
//github.com/scikit-image/scikit-image/blob/master/skimage/io/_io.py
L166
suggestion
Images
windows
circular
symmetry
rofl
comment
suggestion
Build
computation
graph
dask
use
multiple
Hot
tip
utilize
use
suggestion
salient
features
face
classification
idea
suggestion
salient
features
subsequent
steps
suggestion
computation
accuracy
suggestion
determine
features
ensemble
trees
word
—
adverb
suggestion
%
cumulative
value
%
ELLIPSIS
output
suggestion
sigma
column
dimension
sigmas_of_peaks
sigmas_of_peaks
[
]
possible
meaningful
name
function
acronym
full
name
horizon
public
function
name
suggestion
self-supervised
loss
PR
line
Does
ASV
own
overhead
comment
redundant
message
everything
rid
loop
bit
sad
mkcor
comment
same
issue
own
version
file
tiff
problem
rug
great
alternative
solution
Hysteresis
connected
components
values
higher
high
multi-otsu
threshold
pixels
higher
value
other
higher
threshold
classical
method
small
spurious
objects
large
smooth
objects
=
filters.apply_hysteresis_threshold
image
thresholds
]
*
thresholds
]
]
colors=
yellow
results
same
current
method
biologist
result
best
title
Microscopy
image
human
cells
suggestion
thresholds
filters.threshold_multiotsu
image
classes=3
label
measure
morphology
inline
comment
block
comment
@
change
master
suggestion
opt_threshold5
=
filters.threshold_li
cell
initial_guess=np.quantile
cell
other
comment
same
thing
scope
API
Users
things
more
generic
own
function
wrapper
@
paulmueller
happy
form
initial_guess=lambda
x
np.quantile
q=0.95
example
function
above
Li
thresholding
local
optima
cleanest
solution
images
quantile_95
image
scikit-image
quantile
percentile
return
np.percentile
image
line
comment
case
labels
build
output
label
uncorrect
recursive
call
call
label
please
comment
loop
reader
honesty
multiple
images
motif
option
gallery
happy
favorite
function
i
m
enumerate
np.ndindex
chance
section
example
earlier
comment
color
image
docstring
function
A
Boolean
array
same
shape
image
suggestion
return
np.zeros
image.shape
dtype=np.uint8
nested
workflow
first
glance
simpler
solution
Wouldn't
inplace
image.flags.contiguous
warnings.warn
'Non-contiguous
array
image
contiguous
array
copy
Flood
fill
sort
contiguity
copy
image
=
np.ascontiguousarray
image
inplace
image
=
image.copy
mask
=
flood
image
seed_point
selem=selem
connectivity=connectivity
tolerance=tolerance
image
[
mask
]
=
new_value
return
image
same
convention
scikit-image
functions
indices
E.g
boolean
array
same
shape
array
np.nonzero
former
comment
dtype
explore_slices
figure
doc
html
page
quantiles
personal
preference
comment
optional
=
suggestion
vmin
data
q=
suggestion
common
pixel
intensities
contrast
low-contrast
areas
downside
approach
background
noise
suggestion
Generally
image
dimensionality
pixel
spacing
local
exposure
correction
window
size
equal
size
*
real
*
coordinates
axis
Typo
>
less
number
more
less
data
types
mailing
list
more
aware
error
messages
specific
cause
error
*
example
message
RANSAC
vector
initial
inliers
%
i
number
samples
%
i
vector
initial
inliers
same
length
number
samples
True
sample
initial
inlier
False
one
values
stefanv
care
significant
policy
change
positive
Style
comment
kinds
comments
belong
tests
something
kind
message
explicit
https
//docs.pytest.org/en/latest/assert.html
assertions-about-expected-exceptions
Try
message
parameter
future
developers
spirit
error
messages
useful
thanks
code
suggestion
Remove
peaks
close
other
suggestion
Use
KDtree
peaks
close
other
most
matrix=\n
+
textwrap.indent
params
suggestion
separate
test
Set
threshold
values
sure
correct
syntax
documentation
something
different
line
anchor_heads
inter_outs
part
bottom-up
path
comment
exception
plot
curve
>
curves
filename
_
key
fn_key
>
task
May
comments
forward
method
steps
May
comments
tensor
shape
default
comment
comment
comma
Which
name
HRNet
HighResolutionNet
BTW
arxiv
url
docstring
comments
wrapper_out_empty
list
dict
following
steps
noqa
W605
applicable
dict
e.g
optimizer
optimizer
comment
ambiguous
src_type
Rename
param
param_fp16
more
clear
comments
float_x
May
dataset.CLASSES
class
names
category
id
else
block
remark
reason
comments
AnchorGenerator
free
branch
comments
anchor
generator
*
*
*
*
level
instance
map
common
practice
FSAF
shape
shape
end
first
letter
description
0-based
class
cat
code
base
easy
understanding
core
/
shadow
docstring
torch.tensor
device=priors.device
comment
line
__init__
method
same
parent
arguments
shape
end
first
letter
description
shape
end
first
letter
description
comment
line
return
kind
method
such
situation
h
w
w
h
TODO
check
image
matter
gt_bbox
comment
error
wrong
sampling_results
None
model
straightforward
paper
link
better
API
documentation
MMDetection
code-style
consistent
new
arguments
def
__init__
post_cfg
pre_cfg
reduce_cfg
*
*
kwargs
API
documentation
clear
NoProcess
necessary
nn.Sequential
same
thing
Add
comments
error
rpn
gt_labels
None
Foreground
first
class
v2.5.0
Add
comments
comments
out_indices
tests
architecture
Only
exceptions
Normal
test
cases
state
equivalent
workaround
ONNX
comments
normalization
bbox2result
[
bboxes
[
==
i
]
i
range
num_classes
core
temp
file
temp
dir
freeze
optional
Btw
parameters
YOLOv3
backbone
frozen
original
setting
comments
comment
ConvModule
ConvModule
s
assertions
unit
tests
comments
Will
bbox_overlaps
trick
pretrained
necessary
comments
motivation
comment
incorrect
May
PReLU
RReLU
ReLU6
SELU
CELU
GELU
able
discrimination
method
use
same
goal
method
AnchorHead
class
super
PAAHead.__bases__
]
flat_anchors
valid_flags
gt_bboxes
gt_bboxes_ignore
gt_labels
img_meta
label_channels=label_channels
unmap_outputs=unmap_outputs
specific
file
Add
comments
conditions
assert
standard
comments
dataset
length
larger
error
model.CLASSES
unused
sets
arguments
comments
above
comments
clear
fill=self.num_classes
May
more
safe
context_mask.unsqueeze
-1
comments
scale_factor
=
det_bboxes.new_tensor
scale_factor
avg_factor
loss
avg_factor
None
loss
=
reduce_loss
loss
reduction
reduction
mean
loss
avg_factor
reduction
loss
=
loss.sum
avg_factor
reduction
nothing
error
elif
reduction
ValueError
reduction=
sum
'open-mmlab
//res2net101_v1d_26w_4s
MMCV
more
straightforward
python
mmdet.models
ResNet
test_forward
import
_get_detector_cfg
Donate
>
Denote
larger
sigmoid
softmax
step
maximum
scores
foreground
classes
comments
little
confusing
..
/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py
comment
bbox_targets
]
bbox_weights
easier
users
Add
more
comments
above
logics
comprehensible
variable
names
IoU
history
past
udpate_iter_interval
iterations
self.iou_history
=
[
]
beta
history
past
udpate_iter_interval
iterations
self.beta_history
=
[
]
update_statistics
good
method
name
method
updating
statistics
parameters
iou_thr
beta
docstring
TODO
hard
nms
type
comments
sort
topk
function
level_ids
little
bit
first
glance
users
line
comments
boxes
different
levels
NMS
level_ids
act
labels
different
classes
batched_nms
acceleration
comments
other
developers
core
atss
complex
more
comments
part
clear
easy
official
implementation
num_total_samples
gpus
mean
mAP
convention
mmdetection
coordinates
real
length
x1
[
bbox_overlaps
]
https
//github.com/open-mmlab/mmdetection/blob/e907139cb8f4c0195abcf31101925819f369ecc1/mmdet/core/bbox/geometry.py
L63
function
Quality
Focal
Loss
label
assign
consistent
loss
calculation
MMDetection
implements
IoU
calculation
[
]
https
//github.com/open-mmlab/mmdetection/blob/e7537a4b394728eb02133e27b5aadcd8caec8268/mmdet/core/bbox/iou_calculators/iou2d_calculator.py
L38
function
necessary
MMDetection
V2.0
width
height
xmax
xmin
+1
necessary
influence
iou
days
docstrings
codebase
high
coverage
many
methods
class
docstrings
Assign
=
pos
unnecessary
bit
more
explanation
formula
paper
intuitive
consistent
way
positive
negative
labels
Please
comment
default
value
long
term
utility
useful
parsing
snippet
line
documentation
sample
file
data
folder
fine
developers
expectation
sufficient
%
python3
reason
please
use
https
//six.readthedocs.io/
module-six.moves.urllib.parse
Suggestion
pre-computing
combos
nested
loop
https
//google.github.io/styleguide/pyguide.html
showone=List_Comprehensions
List_Comprehensions
Done
next
commit
question
value
p.wait
command
way
timeout
p.wait
Note
sleep
in-between
individual
runs
relevant
discussion
discussion
run
least
look
simple
timeout
PR
TODO
hard
timeout
value
p.wait
PR
TODO
need
deadcode
line
necessary
comment
next
commit
p.wait
process
discussed
phase
sleep
line
time.sleep
SLEEP_TIME_BETWEEN_RUNS
pkb
cmd
Suggest
code
note
support
Ubuntu
Ubuntu
Drop
Ubuntu
long-term
support
version
Sorry
non
existent
URL
%
time
yuyantingzero
previous
comments
pattern
gcp_bigtable.py
cloud_bigtable_ycsb_benchmark.py
bad
design
gcp_spanner.py
flags
gcp_spanner.py
class
library
lower
layer
cloud-spanner_ycsb_benchmark.py
driver
top
layer
gcp_spanner.py
flags
flags
cloud
spanner
instance
parameters
class
constructor
cloud_spanner_ycsb_benchmark.py
way
driver
layer
top
layer
extra
logic
gcp_spanner.py
flags
class
reduces
readability
check
instance
exists
warning
default
cloud_spanner_instance
ycsb-
USER
users
doc
string
FLAGS.cloud_spanner_instance
user
multiple
benchmarks
parallel
non
existent
tar
Sorry
reason
flags
local
benchmark
benchmark
cloud
spanner
resource
access
flags
pull
request
common
set
properties
cloud
spanner
bigtable
benchmarks
TODO
warning
info
spanner
specific
storage
such
bigtable
key-value-pair
storage
concept
table
previous
comment
flag
Otherwise
datastore_ycsb_table
bigtable_ycsb_table
Sorry
late
reply
comment
github
webpage
Re
benchmarks
cloud
spanner
resource
access
configuration
flags
own
set
flags
Most
flags
benchmarks
default
values
YCSB
benchmark
different
default
value
other
benchmarks
instance
ycsb
benchmark
default
value
ycsb-
USER
benchmark
e.g.
tpcc
tpcc-
USER
database
ycsb
benchmark
default
value
benchmark
e.g.
tpcc
ddl
ycsb
benchmark
other
benchmark
e.g.
tpcc
many
others
yscb-specific
list
flags
cloud_spanner_project
cloud_spanner_endpoint
cloud_spanner_config
likely
bad
design
benefit
share
same
default
values
benchmarks
creates
trouble
benchmark
values
cloud
spanner
team
tuple
project
/
config
/
endpoint
YCSB
cloud_spanner_ycsb_benchmark.py
default
values
gcp_spanner.py
change
flags
clear
ycsb-specific
flags
Non
existent
URL
comment
line
Delete
Create
sure
previous
instances
same
name
expected
behavior
users
same
project
same
benchmark
default
instance
name
todo
ycsb
self
build
ones
DONE
Sorry
pollution
issue
API
response
non
deterministic
project
specific
DONE
same
logic
hard
helper
method
more
comments
tests
possible
\
glint
compliant
Suggest
parenthesis
comment
format
http
//google.github.io/styleguide/pyguide.html
38-comments-and-docstrings
i.e
single
line
Returns
vm_groups.
None
type
optional
sure
cases
single
one
=
pd.DataFrame
[
[
]
]
]
columns=list
'AB
df2
=
pd.DataFrame
[
[
]
]
]
columns=list
'BC
result
=
df.append
df2
import
further
sure
result
documentation
due
empty
lines
block
Comment
redundant
Let
unused
code
unicode
strings
returns
number
chars
number
bytes
StringArray
total
number
bytes
chars
sure
applicable
case
better
get_utf8_size
consistency
variable
none_index
=
isinstance
self.index
types.NoneType
self.index
None
common
implementations
hpat_pandas_series_idxmax_impl
hpat_pandas_series_idxmax_impl
cases
index
index
implementations
something
none_index
True
result
self._index
[
int
result
same
applicable
idxmin
Sorry
nq
noqa
Please
doc-string
func
good
name
argument
@
AlexanderKalistratov
PR
rewrites
pay
attention
comment
need
_df_cov
add
docstrings
_df_cov
overloads
handle
allocating
list
something
errorptr
=
cgutils.alloca_once_value
c.builder
cgutils.false_bit
ok
inst
=
listobj.ListInstance.allocate_ex
c.context
c.builder
col_list_type
n_cols
c.builder.if_else
ok
if_ok
if_not_ok
if_ok
code
inst
if_not_ok
c.builder.store
cgutils.true_bit
errorptr
error
whole
native
list
c.builder.if_then
c.builder.load
errorptr
c.context.nrt.decref
c.builder
col_list_type
inst.value
Comment
redundant
such
lines
code
file.write
f
encoding_info
\n
formatted
string
f
arithmetic_binops_symbols
name
]
@
AlexanderKalistratov
function
code
dataframes
specific
code
lines
compile-time
values
approach
something
hardcoded
template
same
specific
case
better
formatted
strings
template
code
valid
python
function
easy
it/navigate
IDE
different
names
input
different
names
results
=
pd.DataFrame
data
=
df1
.copy
deep=True
test_impl
df1
key
value
result
=
df1
pandas
setitem
modifies
original
DF
result_ref
=
sdc_func
df2
key
value
SDC
new
DF
original
unchanged
pd.testing.assert_frame_equal
result
result_ref
sure
big
prange
assert
exception
match
specific
parameter
dict
[
find_operations
block
'call
]
https
//github.com/IntelPython/sdc/blob/master/sdc/rewrites/ir_utils.py
L48
parameters
.kws
Positional
.args
[
get_call_parameters
https
//github.com/IntelPython/sdc/blob/master/sdc/rewrites/ir_utils.py
L331
dict
https
//github.com/IntelPython/sdc/blob/master/sdc/rewrites/dataframe_constructor.py
L74
parameters
list
https
//github.com/IntelPython/sdc/blob/master/sdc/rewrites/dataframe_constructor.py
L56
Probably
function
definition
May
multiple-line
comments
Series
-1
dtype
int64
same
above
same
Yes
comment
Pandas
behavior
Same
comment
commented
code
suggestion
Copyright
c
Intel
Corporation
All
rights
year
copyright
result
comment
result
comment
other
examples
comment
code
line
comment
code
line
result
comment
opportunity
user
result
suggestion
Support
Parquet
HPAT
pipeline
test
due
results
series.str.zfill
built-in
zfill
different
Python
Currently
such
test
such
description
issue
link
incorrect
test
test_series_str_zfill_limitation
limitation
documentation
suggestion
return
series.shape
Expect
sure
Expectation
right
sure
such
precision
case
parallel
execution
value
different
@
PokhodenkoSA
@
Hardcode84
[
]
https
//docs.djangoproject.com/en/1.8/ref/models/fields/
blank
people
able
admin
panel
other
forms
migration
clear
code
ideas
better
names
comment
nit
least
easy
someone
new
method
sense
comment
due
extra
argument
comment
conditions
english
condition
*
sibs
faster
Wait
sibs
users
winners
group
asyncio.cancelled
documentation
sake
record
cryotank
JSON
compatible
bytes
dictionary
Notes
section
docstring
iff
Was
accident
FIXME
right
D
err
column
NOQA
multiple
things
access
lenv
responsible
lenv
single
call
overhead
actual
remote
execution
synapse.common
synapse.coro
something
meaningful
excellent
tests
meant
synapse
users
parts
library
-OO
code
generator
wrapper
tracking
variable
outside
original
loop
ig-got-nodes
variable
nodes
raw
queries
possible
confusion
None
None
None
object
storm
pipeline
needs
prop
function
prefix
data
propagation
context
spool
slab
fact
backup
need
NOQA
whups
good
point
Fixed
nope
test
1-12
capability
PR
Locale
issues
terms
date
parsing
cron
jobs
parsing
Cortex
prebuilt
docker
containers
Locale
Improve
comment
comment
difficult
long-ish
running
query
sleep
task
comment
lines
..
datetime
extra
T
Comment
individual
combos
outstanding
non-recurring
appointments
trabeback
event
weird
error
_
unused
variable
Queries
extended
model
props
additional
PR
following
query
change
ast.py
loc
assignment
value
runtime
value
path
object
runtime
miss
[
test
comp=
lulz
>
test
int
[
loc=haha
loc=
loc
lib.print
loc
path
None
speed
benefit
dict
comprehension
new
dictionary
construction
newopts
vars
dict
dangers
foo.get
production
anything
meaningful
@
invisig0th
thoughts
future
main
right
interpreter
fini
future
objects
chance
production
anything
meaningful
@
invisig0th
thoughts
laods
>
loads
Same
comment
grammar
comment
implementation
detail
user
suggested
comment
…
suggestion
function
args/kwargs
different
thread
Exceptions
function
error
handlers
meth
add_error_handler
webhook
empty
url
unnecessary
API
call
method
prone
actions
comment
delete
webhook
logic
confusing
potential
minus
group
id
negative
entire
login
self.chat.type
=
Chat.GROUP
id_to_link
=
self.chat.id
]
id_to_link
=
self.chat.id
]
2015-2020
similar
comments
user_ids
documentation
username
@
@
…
Documentation
set
user_ids
Thinking
proper
function
user_ids
def
add_user_id
user_id
def
remove_user_id
user_id
Rationale
user
polls
current
user_ids
new
Set
time
different
thread
user_ids
race
condition
granular
operations
useful
users
bool
bool
same
thing
comment
promises
item
telegram.util.promise.Promise
object
example
edits
lines
order
first
things
command
Poolitzer
chat
id
Change
developer
chat
line
error
e.g
=
unfinished
line
DEVELOPER_CHAT_ID
=
zero
syntax
error
python
Make
bot
module
level
edits
place
option
things
assumption
user
line
needs
code
update.effective_user
updates
ones
docstring
suggestion
Wrapper
func
to_float_timestamp
integer
nearest
integer
documentation
func
to_float_timestamp
more
details
%
sure
/en
comment
few
lines
suggestion
'pt_BR
main
focus
Brazilian
Portuguese
suggestion
filter
Wagtail
language
codes
OpenGraph
locale
strings
register.filter
suggestion
'pt_BR
idea
old
petitions
apps
comment
Lazy
Values
section
file
sure
lazy
values
though
pages
visible
https
//github.com/mozilla/foundation.mozilla.org/issues/2362
code
TODO
wish
python
nicer
syntax
data
best
loop
function
locale
rogue
comment
suggestion
Effect
custom
admin
scores.sum
differnt
dict_learning.score
func_filenames
suggestion
scores
dict_learning.score
func_filenames
per_component=True
suggestion
samples
problem
accuracy
cell
break
processes
rst
block
suggestion
class
baseline
paragraph
comment
mention
example
statistical
inference
details
consistency
other
titles
example
following
change
suggestion
@
jeromedockes
>
masker
parameters
fwhm
mask_strategy
low_pass
high_pass
t_r
target_shape
target_affine
something
purpose
line
parameters
_BaseDecoder
masker
object
case
std
folds
fitted
models
able
standard
deviation
coefficients
folds
efficient
built-in
cross-validation
estimators
such
LogisticRegressionCV
RidgeCV
bootstrap
model
less
folds
hyperparameters
resamplings
nonparametric
estimation
coefficients
variance
valid
numpydoc
standard
space
suggestion
estimator
str
optional
occurrences
parameters
Same
comment
above
py
super
.__init__
params
Ridge
RidgeClassifier
@
tbng
Ok
fact
baseDecoder
Decoder
DecoderRegressor
super.fit
call
ok
hard
docstring
hard
role
function
object
good
state
function
several
parameters
estimator
train
test
fold
one
weird
selector
X
[
train
]
y
[
train
]
line
copies
y_train
X_test
FMI
StandardScaler
latter
test
suggestion
test
model.masker_
desire
@
GaelVaroquaux
similar
test
doable
DecoderRegression
object
dataset
ok
users
naming
conventions
Rename
valid_aggregation_functions
superfluous
comment
Check
function
Superfluous
comment
code
self-explanatory
suggestion
mask
func
masker.generate_report
suggestion
A
mask
Ventral
Temporal
VT
suggestion
input
func
suggestion
NiftiMasker
mask
data
suggestion
case
look
report
suggestion
consequence
input
data
much
smaller
suggestion
subject
suggestion
light
free
suggestion
number
non-negative
voxels
binary
brain
mask
suggestion
samples
condition
mask
suggestion
tangent
space
embedding
suggestion
connectivity
matrices
features
children
warning
suggestion
fmri
data
many
EPI
images
func
suggestion
decoder
Support
Vector
Classifier
linear
kernel
suggestion
strategy
scikit-learn
object
newest
error
blank
line
sections
suggestion
scikit-learn
classifier
........................
many
predictive
models
scikit-learn
pipelines
same
fit
predict
functions
Support
Vector
Classifier
<
http
//scikit-learn.org/stable/modules/svm.html
>
_
SVC
sklearn.svm
import
SVC
svc
=
SVC
data
...................................
scikit-learn
estimator
brain
images
data
class
nilearn.input_data.NiftiMasker
voxels
mask
interest
input
data
arrays
shape
=
n_timepoints
n_voxels
estimators
adjacency
extra
params
i
check
Are
anything
anything
repeat
comment
deployemnt
number
hosts
number
entries
range
number
range
Below
code
rho
Ansible
info
sys
count
https
//github.com/quipucords/rho/blob/master/rho/host_discovery.py
L127
Does
swagger
docs
array
strings
Many
Many
Modeling
capabilities
Django
https
//docs.djangoproject.com/en/1.11/ref/models/fields/
django.db.models.ManyToManyField.through_fields
array
comma
string
Swagger
doc
*
credential_ids
ID
modeling
relationships
array
stored
Host
Credential
Django
existence
comment
default
sqlite
Let
move
HushUpStderr
redirect_stdout
common
test
utilities
stale
comment
stale
comment
stale
comment
dicts
Let
same
list
initialization
top
file
=
FluentParser
Nit
debug
messages
parameters
comments
few
things
inconsistent
related
review
views
unreject
delete
translation.entity.reset_active_translation
care
active
flag
lines
call
model
instance
method
Reject
translations.
block
unnecessary
care
changes
place
able
user
=
request.user
other
related
methods
Thanks
little
bit
user
sure
data
kept
user
Hence
new
user
data
user
See
details
nice
comment
new
user
user
order
ID
Note
translations
active
translations
comment
translations
non-active
suggestions
search
refactor
specific
variable
names
https
//github.com/mozilla/pontoon/pull/779/files
diff-c0c8d928e6b5c9e664c03f6b16316c48R137
only
active
translations
non-active
translations
sense
example
nit
first
last
comment
kind
repeat
code
middle
comment
docstring
function
comment
helpful
old
value
string
theory
order
order
actual
file
Anyhow
inconsistencies
[
important
]
https
//github.com/mozilla/pontoon/pull/846
issuecomment-365400510
good
nice
comment
algorithm
different
actions
pontoon.base.views
update_translation
translation
additional
translation
update
translation
different
types
Did
comment
specific
line
e.g
Log
actions
block
custom_homepage
compute
]
https
//irccloud.mozilla.com/pastebin/HthfU0wU/
D
sentence
comment
shorter
characters
teams/request/
'pontoon.teams.request
consistent
'pontoon.teams.request
'pontoon.teams.request.projects
URL
rules
Nit
Change
comment
Request
new
teams
Nit
Add
line
line
comment
Request
projects
team
lower
case
settings
az-latn-az
code
reason
microsoft
version
unique
microsoft
social_adapter0
file
sense
confident
pytest
possible
easier
tests
fixtures
pretty
obscure
tests
closer
noqa
Nit
AJAX
view
Project
tag
teams
Nit
localization
module
pontoon.tags.ajax.teams
consistent
Nit
other
way
formats
SUPPORT
translations
good
real
plural
form
e.g
Invalid
entity
Invalid
entities
translation
Invalid
translation
Invalid
translations
possible
warning
[
incorrect
number
plurals
]
https
//hg.mozilla.org/l10n/compare-locales/file/tip/compare_locales/checks.py
l108
locale
e.g
string
french
Invalid
entities
plurals
warning
Nit
comment
translations
nothing
source
directory
comment
previous
version
Same
assumption
top-level
complexity
something
python
entity
=
get_object_or_404
Entity
pk=entity
locale
=
get_object_or_404
Locale
code=locale
comments
Comment.objects.filter
entity=entity
locale=locale
brackets
qs
i
code
style
nits
pep8
put
operators
end
line
wrong
lot
pref
operators
next
lines
example
entity_filters
+
Q
string__icontains=search
|
Q
string_plural__icontains=search
|
Q
comment__icontains=search
|
Q
key__icontains=search
+
search
search_list
i
clearer
entity
translate
probs
comment
strings
file
lot
more
docstrings
functions
_create_site_root
sure
site
matrix
site
root
short
explanation
useful
functions
anything
items
interested
numbers
file
look
magic
numbers
comment
*
*
Again
consistent
FTL
silme
formats
source
file
basis
untranslated
update
strings
tree
localized
file
unnecessarily
large
diff
problem
extensive
refactoring
Saved
wrong
tense
same
block
silme
FTL
Note
os.path.isdir
self.path
false
self.path
path
resource
file
Start
comments
capital
letter
<
br
>
blank
lines
tags
=
lines
Nit
Please
change
Store
locales
locales
resources
new_locales
[
]
original
comment
valid
non-blocking
comment
type
translations_to_update
something
translation_pk
index
changes
time-stamps
same
confusing
gt_translation
entities
]
while
response_b
last
test
case
Please
last
paragraph
previous
comment
code
allowed_max_job_name_length
width
first
column
equal
width
terminal
less
space
State
ID
columns
space
columns
sure
i
comment
last
thing
function
parser
args
few
lines
comment
function
name
talks
comment
number
comment
vector
same
type
correct
map
tuple
list
tuples
list/tuple
context
type
checker
able
type
__init__
function
Four-Vector
=
accurate
nit
spaces
properly
today
states
docstring
completeness
tests
replacement
tests
coverage
line
self.responses_test
[
D
]
[
C
]
*
+
[
D
]
*
[
D
]
+
[
C
]
*
corresponds
actions
[
C
D
+
[
D
C
+
[
D
*
*
value
original
test
original
test
player
next
move
opponent
@
marcharper
original
state
current_average
guidance
Thanks
@
alajara
https
//github.com/alajara/Axelrod/pull/4
branch
test
bit
tricky
current_average
>
very_good_score
player
length
Match
Note
PR
merge
master
PR
good
>
need
logic
program_enrollment
code
platform
super
tiny
nit
instances
comments
Add
comment
user
username
uuid
enterprise
formatting
😅
nice
code
below
clear
comment
commented
code
please
Use
p
f
face
Again
comment
wrong
code
wrong
case
VectorFunctionSpace
section
dofs
python
indices
range
*
V.value_size
+
dof
V.value_size
use
numpy
numpy.arange
*
V.value_size
V.value_size
*
+
dof
comment
_wrong_
default
cells
base
mesh
global_indices
check
traceback
'exception
kwargs
sys.exc_info
]
self._debug
self._verbosity
way
handling
results
[
'exception
]
controller-side
code
easier
None
UUID
second
pass
delete
case
creation
case
uuid
part
result
API
uuid
trusted
names
users
able
captures
uuid
fact
names
mandatory
something
new
flow
capture
node
gremlin
query/expression
parameter
please
upper
comment
boto
exceptions
*
*
exception
issues
able
%
unbounded
general
higher
timeout
minutes
sufficient
most
stack
changesets
fine
avoids
infinite
loop
need
'else
everything
'else
continuation
program
'name
alias
parameter
name
boto_params
access_key
secret_key
profile
profile
parameter
AWS_PROFILE
set
https
//github.com/jmenga/requests-aws-sign
way
session
=
session.Session
credentials
session.get_credentials
profile
parameter
line
dates
old
U
https
//www.zabbix.com/documentation/3.2/manual/appendix/api/hostinterface/definitions
host_interface
hyperlink
*
nit
*
/play.For/playbook
/
particular
new
pyOpenSSL
versions
requirement
Same
previous
comments
defensive
coding
way
IMHO
=
True
overkill
exception
Fixed
comment
other
ClientError
handling
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md
boto3-2
comment
please
ansible_dict_to_boto3_tag_list
note
ec2
import
import
ansible.module_utils.ec2
import
class
qualified
path
old
code
path
result
[
]
=
True
same
new
stack
instances
True
exception
other
plugins
set_options/get_option
base
methods
work
documentation
validation
defaults
scaleway
modules
series
fallback
environment
variables
module
option
same
thing
plugin
options
oauth_token
env
order
precedence
name
SCW_TOKEN
name
SCW_API_KEY
name
SCW_OAUTH_TOKEN
self.get_option
'oauth_token
path
module
specific
pki
upload
script
files
backup_path
=
dict
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/basic.py
L1659
~
value
https
Code
module_utils
GPL
BSD
other
scripts
requirement
sure
other
BSD
licenses
type='path
options
AnsibleModule
able
options
modules
examples
mutually_exclusive
required_together
required_one_of
require_if
commented
comprehensions
unfortunate
dict
comprehensions
available
code
helpful
python
better
code
problems
inconsistent
rest
module
args
REST
api
names
way
ok
dict
class
local
ansible
module
arg
name
remote
rest
api
name
required
change
something
api_map
=
'id
other
names
code
something
api_map
[
'client_id
]
updated_client
stuff
overkill
isolation
potential
keycloak
rest
api
name
changes
worried
blocker
merge
right
little
ill-described
docstring
False
None
case
method
Handler
superset
task
Might
good
idea
short
comment
whichever
components
part
vlan
primary
key
parent
interface/node/interface_name
sure
top
head
least
warn/error
requested
state
suggestion
lines
same
current
PyOpenSSL
code
clear
PyOpenSSL
code
comment
similar
PyOpenSSL
code
cert.has_expired
older
versions
buggy
implementation
new
module
backwards
compatibility
docs
examples
following
lines
docs
argument
favor
match
none
future
version
force=dict
default=False
type='bool
something
specific
Add
user
backend
uses
parameter
check-mode
wrong
easy
Check-mode
case
anything
table
user
mistakes
real
run
modules
v2.4
right
Good
point
import
HAS_GSSAPI
IPA
modules
community.general
gssapi
auth
urllib_gssapi
depends
gssapi
True
means
GSSAPI
auth
available
urls.py
comment
urls.py
HAS_GSSAPI
backwards
compatibility
PodmanContainer
execute
method
checks
Please
None
helpful
suggestion
self.executable
=
self.module.get_bin_path
module.params
[
'executable
]
required=True
case
values
suggestion
params
[
'blkio_weight
]
Shorter
version
header
[
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/mlnxos/mlnxos_config.py
L4
reason
AWSRetry
jittered_backoff
nice
suggestion
Most
values
integers
field
comment
exception
handler
top
entire
block
safer
query
Ansible
required_if
Isn
’
possible
comment
anything
useful
old
legacy
thing
vm
module
easier
part
condition
new
one-line
GPL
message
below
header
various
aliases
upper
case
version
sure
much
value
Use
dict.get
key
[
default
]
default
values
'operation
None
operation
None
validation
values
input
parameter
good
addition
available
mutually_exclusive=
[
'inputFile
]
'inputFile
]
right
code
sure
anything
presentable
result
mode
brief
example
mode
check_mode
module
IP
address
interface
module
output
actual
task
final
commit
operation
task
force
Copyright
line
delay_min_macos
=
delay_min
Copyright
c
Ansible
Project
extra
Mac
comment
ssl_ca_cert
path
use
ansible.module_utils.url
requests
spaces
comment
space
bool
space
end
line
Are
f-strings
available
Python2
error
user
VM
vmware_guest_powerstate
Ansible
operation
documentation
maintenance
i
bug
plugin
collection
correct
name
collection
name
other
plugin
base
class
collection
comment
docstring
docstrings
memory
comments
copy/paste
DHCPd
relation
exact
p
comments
error
handling
@
dkhenry
logic
much
section
code
limit
number
versions
comment
refers
Thanks
extra
info
@
dkhenry
comment
reason
parameter
strategy
easy
default
license
block
much
simpler
http
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
copyright
good
idea
variables
bytes
b_
easier
variables
type
data
suggestion
self.b_delimiter
=
b
@
@
Known
delimiter
output
results
bikeshed
cheaper
exception
vs
attribute
time
suggestion
re.compile
br
%
Prefix
length
less
precise
error
exceptions
function
docstring
short
form
BSD
license
c
René
Moser
<
mail
@
renemoser.net
>
Simplified
BSD
License
licenses/simplified_bsd.txt
https
//opensource.org/licenses/BSD-2-Clause
@
pilou-
possible
function
several
times
different
UUID
UUID
host
dictionary
Please
use
PEP257
style
guide
good
docstrings
title
sentence
period
end
line
empty
line
separator
long
description
comment
useless
suggestion
suggestion
err=err
construct
string
list
list
same
thing
/
suggestion
archives
directories
'/'
os.path.sep
dirname
+=
os.path.sep
dirname
=
dirname
[
-1
slash
no-slash
paths
PR
loop
nested
KeyError
suggestion
member_names
[
to_native
dirname
[
-1
]
.endswith
os.path.sep
member_names.append
member_names
-1
]
+
os.path.sep
name
member_names
try
=
tar.getmember
name
KeyError
break
AnsibleError
Unable
%
s
collection
%
[
]
more
options
future
vrf_aftype
description
VPN
instance
address
family
false
choices
[
]
default
v4
aftype
valut
check
options
true
Ansible
Currently
false
aftype
DOCUMENTATION
check
one-line
GPL
statement
New
unit
tests
pytest
style
unittest
style
Documentation
'RETURNS
section
anything
Might
nice
information
current
firewall
profile
state
users
register
conditionals
Name
Enabled
attribute
values
profile
options
currently-implemented
version
top-level
sub-options
IMO
commented
stuff
good
Same
s/
/
Copyright
c
Ansible
Project
suggestion
name
list
hooks
repository
GitHub
enterprise
token
auth
suggestion
name
list
hooks
repository
password
auth
listdir
output
unicode
objects
u
single
tuple
u
u'~
code
spath
'~
way
required=True
*
*
examples
check-mode
possible
changes
case
Spark
message
connectivity
login-errors
check-mode
Please
comment
name
e.g
name
facts
device
mlnxos_facts
gather_subset
Best
practice
name
Ansible
people
examples
playbooks
provider
accurate
version
comment
https
//pyyaml.org/wiki/PyYAMLDocumentation
pyyaml
Python
unicode
bytes
byte
strings
unicode
Python2
right
time
byte
strings
trip
yaml
Python3
Python2
code
work
same
Python2
Python3
Python3
behaviour
methods
Ansible
byte
strings
Python2
Convert
byte
strings
strings
workaround
current
behavior
nice
way
'supported-platforms
[
....
]
such
similar
tag-flattening
name
action
comment
PS
things
original
documentation
things
ansible-vault
script
YAML
files
http
//docs.ansible.com/playbooks_vault.html
more
details
true
subliminal
publicity
vault
SEQUENCETYPE
is_iterable
python
ansible.module_utils.common.collections
is_iterable
[
]
[
Line
becomes
is_iterable
aliases
comment
code
exceptions
correctly
snip
legal_inputs
None
legal_inputs
DEFAULT_LEGAL_PARAMS
[
]
elif
legal_inputs
legal_inputs
legal_inputs
[
]
self._legal_inputs
empty
list
reason
legal_inputs
function
responsible
end
result
docstring
_cluster_stable
method
*
*
method
contents
RETURN
Use
booleans
test
identities
objects
need
boolean
False
elif
self._has_migs
local
fixed
string
success
Just
anything
fine
more
comments
version
0-2
]
unescaped
dot
matches
anything
suggestion
re.search
[
0-3
]
\\.|4\\
0-2
]
self._build_list
raw
strings
double
suggestion
re.search
R'^
[
0-3
]
\.|4\
0-2
]
self._build_list
case
module
data
information
Aerospike
anything
empty
comment
case
self._has_migs
local
row
sleep
inbetween
False
elif
sense
suggestion
has_migrations
comment
Python
[
docstrings
]
https
//en.wikipedia.org/wiki/Docstring
Python
method
documentation
comments
get_bin_path
AnsibleModule
standalone
function
lib/ansible/module_utils/common/process.py
function
method
rest
code
Import
PY3
suggestion
PY3
great
Python
capability
avaialble
conext
Python
>
=3
Linux
systems
available
AttributeError
case
available
docs
Worth
docs
condition
Can
global
declarations
place
Easy
future
maintainer
function
main
ansible
guildelines
Ansible
C-style
code
flow
caller
functions/methods
bottom
file
callee
implementations
them.
suggestion
Copyright
c
Red
Hat
Inc.
suggestion
name
self-heal
facts
gluster
hosts
cluster
gluster_heal_facts
name
test_volume
status_filter
self-heal
register
self_heal_status
debug
var
self_heal_status
other
comments
hard
vars
options
env
var
option
force
either/or
able
things
config
file
others
env
vars
user
eggs
basket
config
file
plugin
tower
entry
ensure_type
function
plugin
equal
path.strip
==
@
tower_inventory
wrap
exceptions
to_native
Rather
environment
variables
config
flexible
use
case
option
plugin
e.g
document
options
environment
components
options
tower_host
description
env
[
TOWER_HOST
]
true
allow
parsing
file
tower_inventory
self._read_config_data
path
*
access
options
self.get_option
'tower_host
self._read_config_data
path
options
tower_inventory
file
environment
vars
self._options
dict
tower-cli
tower
environment
variable
replacement
inventory
option
id
other
inputs
lookup
name
ONLY
env
var
comment
side-effect
obvious
code
Move
DOCUMENTATION
metadata
description
notes
Use
[
formatting
function
]
http
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
formatting-functions
URL
Please
RETURN
documentation
https
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
return-block
module
doesn
’
return
anything
standard
returns
RETURN
=
only
values
returns
msg
stdout
stderr
copyright
date
code
year
copyright
suggestion
Copyright
c
Felix
Fontein
<
felix
@
fontein.de
>
suggestion
Ansible
dev
guide
better
docstring
unnecessary
comment
ansible
following
ansible.module_utils.six.moves.urllib.parse
import
suggestion
pulp_ansible
sure
module
anything
anything
special
things
run
check
mode
suggestion
supports_check_mode=True
@
flowerysong
extra
/a/
sample
path
condition
expression
following
version
error
*
*
*
conditions
above
versions
suggestion
LooseVersion
api_version
.version
[
:3
]
==
LooseVersion
.version
conditional
expression
problem
following
version
*
*
*
*
AnsibleAWSModule
BotoCoreError
.response
attribute
AttributeError
*
=
backoff
copyright
http
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
copyright
value
comments
exact
same
information
name
entries
suggestion
yes/no
values
booleans
examples
part
module
documentation
documentation
consistent
documentation
Please
task
names
consistency
documentation
as-si
suggestion
name
Ensure
server
absent
module_utils
honor
description
param
name
arg
policies
specify
state
absent
policies
list
user
example
policies
A
B
playbook
sure
A
present
play
book
policy
B.
p.s
new
actions
policies
profile
e.g
assign
set
policies
cc
@
cben
@
joelddiaz
comment
old_notes
new
empty
string
old/new
non-empty
different
notes
needs
None
[
sugguest
'resources
]
difference
code
[
]
resources
key
response
Note
python-2.7
function
py3cmp
function
python-2.7
problem
code
something
aware
Comments
list_keys
gluster_peer_ops
method
get_nodes
get_nodes
fails
nodes
parameter
parameter
mandatory
empty
custom
method
something
class
AnsibleModuleCheckListNotEmpty
AnsibleModule
def
_check_type_list_not_empty
value
value
=
self._check_type_list
value
default
checks
list
value
ValueError
list
empty
value
[
]
module
=
AnsibleModuleCheckListNotEmpty
argument_spec=dict
force=dict
type='bool
type=self._check_type_list_not_empty
required=True
get_nodes
method
parsing
work
gluster
case
meaningfull
message
nice
changed=True
better
Ack
force
boolean
comment
force
=
self.module.params.get
'force
Ack
Done
use
fail_json
exit_json
check_mode
documentation
state
check
mode
quotes
example
name
subsets
settings
roles
postgresql_facts
filter
settings
roles
particular
example
Generally
better
quotes
examples
simplier
weird
Please
rid
whole
block
anything
facts-module
exact
documentation
postgresl.org
receiver
info
receiver
archives
something
postgres
easier
suggestion
argument_spec.update
use
name
field
comment
Same
one-line
GPL
header
tags
Name
key
set
better
example
instances
Environment
tag
set
tag
Environment
dev
dev
QA
hosts
tag
Environment
dev
qa
tag
Name
tags
name
dev
dev
true
something
Modules
json
typos
persistent
/
reboots
module
state
choice
pressent
absent
include
thankx
fork
import
json
module
old
development
stuff
wrong
way
Ansible
user
desired
state
modules
actions
module
actions
specific
state
needs
current
state
desired
state
idempotency
state=present
check-mode
support
diff
support
important
tool
IMO
normalize_interface
redundant
interface
names
running-config
Please
https
//github.com/ansible/ansible/pull/59929/files
diff-0573c4d180b8184c07ae778232ecb216R21
https
//github.com/ansible/ansible/pull/59929/files
diff-0573c4d180b8184c07ae778232ecb216R120
bad
role
docker-py
weird
behaviour
box
sorry
Feel
free
comments
Might
useful
deprecation
docker.__version__
least
older
roles
most
distros
older
version
library
argument
..
line
NetBox
documentation
https
//netbox.readthedocs.io/en/latest/api/overview/
change
Prefix
custom
fields
cf_
field
value
line
code
comment
wrong
move
place
server
state
comment
backwards
compat
party
connection
Same
above
v3
authorization
Replace
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
__future__
import
absolute_import
division
print_function
__metaclass__
=
type
=
[
]
'community
'metadata_version
get_bin_path
function
Copyright
c
Michael
Heap
native
strings
line
to_native
regex
matches
type
shell=sh
chances
available
higher
bash
available
env
variables
available
such
TLS
related
ones
suggestion
matcher
=
re.search
=
^
]
+
env_var_name
matcher
env_var_value
=
matcher.group
self.inventory.set_variable
id
ignore
....
avaliable
suggestion
tags
=
self.node_attrs
[
'Driver
]
.get
'Tags
suggestion
same
name
value
dm_
name
prefix
pass
original
exception
orig_exc
traceback
-vvv
anything
stdout
stderr
failures
only
clue
lv_type=dict
default='jfs2
snip
opts=dict
default=
typo
email-address
Hello
Thanks
comment
size
attribute
string
able
parameter
easier
end
user
test
above
comment
date
option
name
wrong
more
sense
other
command
command
same
time
comment
date
module
documentation
name
suggestion
marked
portion
file
project
Apache
License
Replace
Line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
string
list
HP
copyright
Comment
required_if
module
returns
name
data
docs
default=None
default
line
module
data
correct
please
document
other
modules
example
Please
examples
multi-line
YAML
key
value
use
name
comment
task
correct
methods
wrappers
writer
module
ANY
editor
minimal
capability
methods
FortiManager
Basically
ENSURE
method
correct
keyword
FMG
person
module
“
intellisense
”
wrong
function
name
call
function
’
t
plugin
call
method
JSON-RPC
standard
FortiManager
one-hand
half-dozen
other
thing
s
sure
module
writer
someone
method
API
something
FMG
d
place
s
external
API
calls
libraries
specific
keywords
easier
module
writer
plugin
Basically
small
amount
code
string
module
writer
thing
exec
”
“
execute
”
“
post
”
’
t
Most
user
’
s
“
post
”
good
call
FMG
internal
JSON-RPC
method
such
temptation
module
writer
correct
options
method
–
documentation
guidelines
FMG
standard
REST
few
things
JSON-RPC
requirement
easier
module
writers
standard
tools
self._url
/jsonrpc
login
to_text
preceding
line
code
next
line
code
particular
reason
clear
suggestion
response
response_data
=
path='/jsonrpc
data=to_text
data
state
results
Already
return
values
Ansible
snake_case
Use
dict
usage
future
library
way
python
problems
other
libraries
unicode_literals
harder
code
easier
file
unicode_literals
top
file
present
switch
github
comments
data
key
resource
BSD
license
module_utils
GPLv3+
look
basic.py
instance
proper
license
Note
copy
library
ansible
module_utils
py2/py3
compatibility
python
ansible.module_utils
sphinx
docstrings
Generic
implementation
absent
state
OneView
resources
resource
arg
dict
resource
Resource
arg
str
method
Function
OneView
client
resource
deletion
Usually
return
dictionary
expected
arguments
meth
ansible.module_utils.basic.AnsibleModule.exit_json
http
//www.sphinx-doc.org/en/stable/domains.html
info-field-lists
Scratch
comment
item_key
items_map
requirements
documentation
fragments
i
top
loop
suggestion
Copyright
c
F5
Networks
Inc.
suggestion
Copyright
c
F5
Networks
Inc.
better
commented
variables
os.path.abspath
*
real
*
filesystem
path
simplification
strings
os
call
real
filesystem
right
point
case
remote
node
Windows
server
Python
API
os.path.abspath
current
machine
remote
machine
comment
multiple
lines
several
sentences
please
use
correct
casing
terminate
sentences
period
Examples
name
static
network
route
win_route
destination_ip
suggestion
vm_folder
=
self.find_folder_by_name
content=self.destination_content
folder_name=self.params
[
]
configurable
something
documentation
parameters
argument
spec
other
way
Chances
datastore
possible
user
datastore
name
error
message
Username
password
port
validate_certs
vmware.documentation
values
present
absent
Copyright
c
Ansible
Project
Copyright
c
Armin
Ranjbar
Daemi
<
randjbar
@
gmail.com
>
same
comment
postgresql
review
update
database
state
present
check
mode
change
correct
comment
part
name
required=True
good
idea
options
AnsibleModule
able
options
modules
examples
mutually_exclusive
required_together
required_one_of
require_if
move
check
try
block
nesting
Are
able
bit
info
byte
array
hex
values
good
documentation
Same
thing
copyright
example
with_
defaults
error
Ansible
module
level
directory
exceptions
failures
code
function
module
argument
—
let
separate
different
abstraction
layers
Comment
extensive
state
order
configuration
Python-2.6
tmp_file
=
RoleRequirement.scm_archive_role
keep_scm_meta=self.options.keep_scm_meta
*
*
self.spec
comment
chcp.com
encoding
==
utf-8
toml_dumps
=
partial
toml.dumps
guard
expression
above
group_data
None
return
key
data
group_data.items
tab
less
low
style
consistent
Please
commented
code
unnecessary
sensitive
info
possible
particular
function
path
./
top
file
other
functions
return
simple
comments
comment
blocks
XXX
mean
same
tmp
directory
modules
Well
bcoca
generic
function
name
temporary
directory
Ansible
function
function
empty
string
appropriate
test
None
return
value
function
same
applies
functions
module
use
result
[
]
=
changed
=
=
result
[
]
main
function
one-line
GPLv3+
header
modules
modules
network
much
network
modules
least
future
one-line
version
cuts
bandwidth
usage
http
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
copyright
python-2.6+
remote
side
people
standard
boilerplate
modules
license
header
python
__future__
import
absolute_import
division
print_function
__metaclass__
=
type
>
none
Replace
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
ansible.module_utils._text
import
to_native
alu
to_native
Copyright
C
above
scope
comment
redundant
code
current_bandwidth
=
bandwidth
current_location
=
location
conditional
resource
connection
return
'connection
connection
]
return
'connection
cases
if/elif/else
returns
Same
return
True
create_connection
variable
name
confusing
connection
regex
L279
\S+
lines
comment
redundant
variable
intentional
space
s
concatenated
multi-line
value
documentation
output
values
sec
delay
good
api
call
task
timeout
module
changed=true
ip
module
task
module
wait
sec
task
sec
module
wait
task
waitForNoTask
function
module
true
waitForNoTask
task
status='todo
function='genericMoveFloatingIp
sec
module
changed=true
ip
move
OVH
side
line
trailing
slash
line
ansible.module_utils.ec2
import
ansible_dict_to_boto3_filter_list
camel_dict_to_snake_dict
HAS_BOTO3
use
task_keys
'password
]
correct
precedence
suggestion
modules
'context
key
suggestion
modules
'passwords
key
more
understanding
value
logic
service
side
difference
service
updatable
except
OSError
err
seconds
long
time
progress
updates
seconds
sleep
time
end
operation
nothing
sleep
Might
worth
comment
suggestion
self.igmp_info_data
igmp_info
value
suggestion
igmp_info_data
value
subtle
bug
dhparam
file
changes
permissions
return
permission
end
function
param
dhparam
temp
file
success
temp
file
real
file
module.atomic_move
case
interruptions
errors
destinations
course
wrong
curiosity
reason
module.run_command
module.get_bin_path
True
path
openssl
binary
name
comment
force
true
regeneration
level
i.e
spaces
above
invocation
]
module_args
=
self._task.args.copy
var
specific
name
generic_vmw_errors
clear
exception
comparison
smth
python
ansible.module_utils
import
module
heading
=
task.info.error
try
error_msg
=
error_msg.msg
AttributeError
Keep
message
msg
attribute
pass
raise_from
exception1
exeption2
exception1
exeption2
Python
exception1
not.
six.raise_from
TaskError
error_msg
task.info.error
unused
code
suggestion
multicast_global_info
multicast_global
value
suggestion
multicast_global_info
multicast_global
value
suggestion
i.e
mcast_enable_key
=
vrfName:11
'xx
good
reason
different
name
Standard
good
hard
readability
something
value
ansible
command_line
sense
Bingo
psexec_command
descriptive
context
clarity
only
reason
output
sure
win_psexec
right
thing
people
same
thing
issues
wrt
etc.
paste
module
Well
same
content
command
same
name
command
original
command
psexec
cmd
complete
command
line
target
psexec
command
line
open
command_line
standard
naming
shame
Any
reason
'cmd
return
corresponding
module
param
same
'command
whole
words
better
terse
vowel-free
versions
command
line
suggestion
TODO
default
True
future
release
something
module.params.get
'template
entity_name
=
module.params.get
'template
collection_service
=
connection.system_service
.templates_service
module.params.get
'vm
entity_name
=
module.params.get
'vm
collection_service
=
connection.system_service
.vms_service
TODO
search_by_name
function
entity
=
search_by_name
collection_service
entity_name
entity
None
raise
Exception
Vm/Template
%
s
%
entity_name
service
=
collection_service.service
entity.id
cluster_id
entity.cluster
suggestion
HAS_OVH
self.fail_json
msg=missing_required_lib
'python-ovh
suggestion
ImportError
HAS_OVH
=
False
OVH_IMPORT_ERROR
=
traceback.format_exc
suggestion
import
traceback
connections
other
OVH
modules
suggestion
ansible.module_utils.basic
import
AnsibleModule
suggestion
ID
project
U
https
//api.ovh.com/console/
/cloud/project
GET
HAS_OVH
suggestion
ID
instance
U
https
//api.ovh.com/console/
%
%
GET
suggestion
ovh_monthly_billing
project_id
instance_id
8fa89ad2-8f08-4220-9fa4-9695ea23e948
suggestion
installed_packages
defaultdict
list
PEP
docstrings
Docstrings
attributes
Import
name
library
package
manager
@
abstractproperty
def
lib_name
pass
http
//www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
directive-autoattribute
Same
comments
LibMgr
python
line
stdout.split
'\n
one-line
license
declaration
consistency
please
delegate_to
localhost
syntax
name
Ensure
network
present
cs_physical_network
~~~
full
license
header
needs
following
Simplified
BSD
License
licenses/simplified_bsd.txt
https
//opensource.org/licenses/BSD-2-Clause
part
auto-generated
header/warning
files
documentation
fragments
options
service_account_email
service_account_file
options
exclusive.
part
auto-generated
header/warning
part
auto-generated
header/warning
pep8/flake8
comments
Minor
pep8
happy
contrib/inventory/apstra_aos.py:286:9
E265
comment
contrib/inventory/apstra_aos.py:288:9
E265
comment
contrib/inventory/apstra_aos.py:298:9
E265
comment
contrib/inventory/apstra_aos.py:300:9
E265
comment
contrib/inventory/apstra_aos.py:316:13
E266
many
block
comment
contrib/inventory/apstra_aos.py:333:13
E266
many
block
comment
contrib/inventory/apstra_aos.py:334:13
E266
many
block
comment
contrib/inventory/apstra_aos.py:342:9
E265
comment
contrib/inventory/apstra_aos.py:344:9
E265
comment
Do
plugin
description
notes
file
cloudscale.yml
cloudscale.yaml
try/except
block
calls
cryptsetup
use
self._cryptsetup_bin
variable
get_bin_path
much
superfluous
sure
terminated/shutting-down
instances
instances
states
available
https
//docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html
better
default
pending/running/stopping/stopped
hosts
available
play
vars
one-line
BSD
statement
Correct
circular
parenting
call
get_ancestors
checks
circular
parenting
prior
behavior
method
circular
maximum
recursion
depth
error
compatible
new
code
structure
add_child_group
nice
test
documentation
test
shallow
merge
current
new
contain
same
category
whole
category
BTW
simpler
current_values_categories.update
new_values_categories
self-evident
deep
merge
union
current
|
new
tags
category
managed_filters_merge_mode
documentation
case
something
/managed/
safer
]
list-of-lists
dict-of-sorted-lists
transform
separate
method
current
have_same_values_nested_array
simple
==
simple
.values
Exception
e
reason
sys.exc_info
code
formatting
standards
character
width
same
line
readable
split
headers
payload
different
items
fail_json
python
fail_json
msg='asfad
headers=headers
payload=payload
useful
own
part
error
msg
Could
comment
better
code
readability
module
hard
Updated
AnsibleModule
module_spec
parameters
mutually_exclusive
required_if
required_together
parameters
manual
validation
parameters
sure
mode
way
errors
Ansible
attribute
None
new
copyright
plugins
property
paginator
more
results
lock
stable
box
later
todo
Please
comments
function
doc
comment
multiple
dictionary
access
required_config.get
'rotation
None
rotation
required_config
[
'rotation
]
use
python
rotation
=
required_config
'rotation
rotation
None
stuff
rule
dictionary
access
below
Could
Line
//gist.github.com/abadger/35f6918ac1ce48f97cc173c35a718d76
file-header-boilerplate-txt
Could
comment
name
line
module_check
sense
module_utils
Hi
per
suggestion
@
thaumos
Please
license
Generally
files
BSD
people
custom
modules
okay
custom
modules
module
general
thin
api
wrapper
useful
users
'expert
mode
addition
actual
options
usage
Ansible
best
practice
-name
people
examples
own
playbooks
clearer
name
Get
Pool
Information
avi_api_session
avi_api_session
controller
controller
examples
only
option
HTTP
patch
semantics
full
object
references
actual
field
use
cases
client
append
C
client
client
name
https
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
formatting-options
Thanks
comments
tomorrow
Friday
…
@
yungezz
module
imports
explicit
top
file
documentation
See
e.g
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/ec2_vpc_nat_gateway_facts.py
L92-L94
need
boto3
HAS_BOTO3
module_utils.ec2
s/ec2_asg/api_gateway/
comment
code
connections
hosts
TODO
TODO
exclusive
access
comments
docker
connection
plugin
comment
examples
something
Create
shortcuts
key
module.params.keys
setattr
key
module.params
[
key
]
above
functions
object
global
variable
object
variable
elegant
comment
bellow
shortcuts
p
[
]
variables
easier
code
object
swupd
=
SwUpd
module
Create
shortcuts
update
=
p
[
'update
]
verify
=
p
[
'verify
]
state
=
p
[
'state
]
name
=
p
[
'name
]
Trigger
action
update
swupd.update
verify
swupd.verify
state
==
present
swupd.install
name
elif
state
absent
swupd.remove
name
object
approach
more
shortcuts
__init__
method
example
p
[
format
]
p
[
manifest
]
p
[
contenturl
[
versionurl
self.format
self.manifest
self.contenturl
commit
meaning
FOREMAN_ORGANIZATION
variable
organization
name
label
example
comment
Satellite
Foreman
Please
year
Please
statement
Provider
New
modules
suggestion
details
documentation
version
Docker
API
U
https
//docs.docker.com/engine/api/
L
links
titles
[
Details
]
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
few
days
*
module_utils/digital_ocean.py
*
*
Ansible
Digital
Ocean
utils
PR
generic
configurations
documentation
function
*
digital_ocean_argument_spec
*
*
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/digital_ocean.py
A
few
days
*
lib/ansible/module_utils/digital_ocean.py
*
*
Ansible
Digital
Ocean
utils
PR
generic
configurations
documentation
function
*
digital_ocean_argument_spec
*
*
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/digital_ocean.py
construction
pg_utils
postgres
[
]
https
//github.com/ansible/ansible/pull/52077/files
=
postgres_common_argument_spec
argument_spec.update
table=dict
type='str
required=True
aliases=
[
]
type='str
default=
present
absent
present
]
db=dict
type='str
default=
]
port=dict
type='int
default=5432
aliases=
[
'login_port
]
type='str
default='prefer
'allow
'disable
'require
'verify-ca
'verify-full
]
tablespace=dict
unlogged=dict
type='bool
including=dict
type='str
rename=dict
truncate=dict
type='bool
columns=dict
type='list
type='list
module
=
AnsibleModule
argument_spec=argument_spec
supports_check_mode=True
_check_conditional
way
block
self._check_conditional
x
templar
all_vars
x
self.when
checks
function
checks
places
option
Exception
incase
file
json
uppercase
standard
lowercase
bad
practice
args
use
*
*
*
Better
explicit
arguments
lower_case_with_underscores
preferrable
code
base
wrong
documentation
format
look
etc/cartesian/etc
examples
line
Ansible
loads
lines
variables
conditionals
option
bit
expensive
default
value
config
object
config.get
default
key
file
value
key
file
things
better
errors
PowerShell
following
conditional
following
import
ansible.plugins.shell.powershell
import
_common_args
.join
_common_args
-EncodedCommand
cmd
=
self._shell._encode_script
cmd
preserve_rc=True
detects
cmd
PowerShell
plugin
sure
command
PowerShell
-EncodedCommand
format
reasons
quotes
other
special
chars
powershell
command
value
LASTEXITCODE
execution
status
cmd
nothing
command
Number
important
operation
remote
side
Invoke-WebRequest
LASTEXITCODE
separate
process
downside
_
prefixed
function
variable
powershell.py
better
way
code
point
line
mark_start
[
]
https
//docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_automatic_variables
view=powershell-6
section-1
variable
status
last
executed
command
echo
useless
LASTEXITCODE
output
last
command
Use
to_text
line
obvious
comment
something
suggestion
name
plugin
callback
list
Thanks
missing_required_lib
because
DO
Good
spot
comment
nonsense
typo
target_group_ar_ns
Thanks
reviews
Was
powershell
object
json
result
able
dictionary
first
though
Will
documentation
errors
integration
test
bit
Will
commit
ready
Same
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
key
names
ok
case
password
pwd
print
directory
ryansb
github
comment
comment
block
'start'/'stop
comment
_state_
values
Remove
code
Replace
line
extends_documentation_fragment
ipa.documentation
parameters
IPA
documentation
fragment
s/2.3/2.5/
s/2017/2018/
addition
examples
docs
RETURN
snapshot_facts
module
Nice
+1
type
module
class_name_to_type
None
clear
error
message
new
omitted
type
clear
error
message
+1
https
//github.com/ManageIQ/manageiq/pull/13400
bug
older
API
versions
less
fields
playbook
new
fields
Subtle
top-level
fields
create
inside
endpoints
partial
edit
s/user/provider
documentation
FYI
comments
RETURN
table
future
developers
module
fine
link
users
module
notes
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
suggestion
Add
'public
names
tables
schema
identifier
absent
'name
task
keyword
better
way
tasks
entry
six.moves
python
ansible.module_utils.six.moves
import
http_client
OR
ansible.module_utils.six.moves
httplib
change
changed=True
better
user
playbook
user
playbook
changes
check_mode
False
copyright
line
simple
Copyright
Ansible
Project
legal
questions
git
log
real
copyright
holders
catchall
above
okay
Note
other
pieces
code
same
fix
note
standard
python
style
groups
imports
libraries
standard
library
third
party
libraries
imports
project
part
imports
alphabetical
order
imports
more
import
json
try
import
httplib
ImportError
Python
import
http.client
httplib
ansible.module_utils.basic
import
AnsibleModule
ansible.module_utils._text
import
to_text
ansible.module_utils.six.moves.urllib.error
import
HTTPError
ansible.module_utils.urls
import
httpclient
try
block
alphabetical
sorting
comment
http.client
choices
documentation
code
default
code
new
format
Copyright
c
Wei
Gao
<
gaowei3
@
qq.com
>
pretty
old
need
support
statements
long
time
other
versions
please
people
module
old
module
improvements
@
Akasurde
statements
comments
documentation
Could
Line
shorter
version
GPL
lience
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
@
bcoca
section
SUSE
family
distros
cold
other
systemd-based
distros
symlink
Same
debian
jessie
systemd
mode
mode
/sbin/init
symlink
SysV
binary
non-systemd
distro
available
package
/sbin/init
such
distro
FWIW
linux
service_mgr
code
small
tweak
openrc
examples
suggestion
ipv4
address
above
Please
name
Install
Logstash
beats
plugin
logstash_plugin
later
example
Certificates
parameter
clear
list
dicts
string
ARN
comment
nice
example
docs
Protocol
HTTP
http
CamelCase
listeners
options
blocker
purge_listeners
option
modification
ELB
listeners
time
Ansilble
parameter
child
listeners
naslanidis
unsure
convert_tg_name_arn
ARN
part
listener
module
i
following
failure
exception
task
execution
full
traceback
use
-vvv
error
KeyError
'TargetGroupName'
fatal
[
localhost
]
FAILED
=
>
false
true
module_stderr
Traceback
recent
call
last
\n
File
\
/tmp/ansible_YZ6wr2/ansible_module_elb_application_lb.py\
line
<
module
>
\n
main
File
\
/tmp/ansible_YZ6wr2/ansible_module_elb_application_lb.py\
line
main\n
create_or_update_elb
connection
connection_ec2
module
File
\
/tmp/ansible_YZ6wr2/ansible_module_elb_application_lb.py\
line
create_or_update_elb\n
=
create_or_update_elb_listeners
connection
module
elb
File
\
/tmp/ansible_YZ6wr2/ansible_module_elb_application_lb.py\
line
create_or_update_elb_listeners\n
default_action
[
'TargetGroupArn
]
=
convert_tg_name_arn
connection
module
default_action
[
'TargetGroupName
]
\nKeyError
'TargetGroupName'\n
module_stdout
msg
FAILURE
rc
expected
keys
error
CamelCase
listeners
options
CamelCase
example
inventory
plugin
module
'short
form
licenses
compose/groups
constructed
vars
groups
virtualbox
example
comment
necessary
bug
docker/moby
someone
future
person
use
required_one_of
kwarg
AnsibleModule
sphinx
format
docstrings
sphinx
format
arg
terms
list
lookups
e.g
[
'parameter_name
]
kwarg
variables
ansible
variables
active
time
lookup
kwarg
aws_secret_key
part
AWS
credentials
kwarg
aws_access_key
second
part
AWS
credentials
kwarg
aws_security_token
Third
part
AWS
credentials
kwarg
region
AWS
region
lookup
kwarg
bypath
Set
lookup
variables
path
kwarg
recursive
Set
paths
path
returns
list
parameter
values
list
dictionaries
bypath=True
Copyright
c
Hiroyuki
Matsuo
<
hiroyuki3569825
@
gmail.com
>
Best
practice
tasks
rewrite
name
configure
cross-region
snapshot
cluster
johniscool
redshift_cross_region_snapshots
suggestion
self.client.module.params
docker_object
]
Python3
python
__future__
import
absolute_import
division
print_function
__metaclass__
=
type
Replace
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
Replace
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
above
boilerplate
Please
shallow
copies
original
data
suggestion
new_item
=
dict
new_item
old_item
=
dict
old_item
Sort
aliases
sure
lines
Could
helpful
documentation
botocore
HAS_BOTO3
examples
easy
exp
exception
Use
to_native
exp
unwanted
/
code
blocker
lot
data
top
fields
nice
blocker
module
vdo_cmd
globals
short
script
own
process
globals
bad
JSON
result
output
module
vital
module
development
useful
customers
bugs
way
JSON
output
diagnostics
size
ASN1.TIME
format
date
string
comparison
time
specific
case
case
pyOpenSSL
possible
order
cryptography
things
simple
possible
TODO
futur
documentation
-P
Suggestion
Retrieve
certificate
ACME
protocol
check
ones
harder/less
correct
general
case
strings
point
Might
work
most
time
TODO
comment
case
few
months/years
road
someone
module
cryptography
high
level
crypto
library
popular
end
life
alternatives
available
stable
distributions
method
final
diff
code
Just
call
operation
repetition
code
Use
regular
expression
split
Typo
Please
empty
line
nice
object
res
]
=
self._get_saml_provider
self._get_provider_arn
name
standard
client
setup
exceptions
self.conn
=
module.client
'iam
other
exception
standard
convenience
function
exception
self.module.fail_json_aws
e
msg='Error
provider
ARN
name
suggestion
Note
examples
authentication
details
AWS
Guide
details
helpful
AWS
Guide
reason
Request
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/urls.py
L1031
Ah
thing
3-clause
BSD
license
module_utils
2-clause
BSD
license
best
way
short
header
Copyright
c
Entrust
Datacard
Corporation
something
Simplified
BSD
License
licenses/simplified_bsd.txt
https
//opensource.org/licenses/BSD-2-Clause
Similar
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/basic.py
possible
customer
non-public
certificate
authorities
guard
explicit
exception
case
comment
suggestion
Always
new
certificate
certificate
get_file_content
module_utils/facts.py
Could
boolean
value
return
value
method
argument
defaults
unused
arguments
NotImplementedError
Easier
VALID_ARGS
=
tuple
BASE
+
FROM_ARGS
+
OTHER_ARGS
imports
start
module
possible
e.g
ucsmsdk
part
try/except
block
set
HAS_UCSMSDK=True/False
proper
fail_json
error
HAS_UCSMSDK
False
Note
code
module_utils
GPL
content
path_content
more
sense
argument
name
Ca
none
PyVmomi
helper
class
Could
example
2-line
CSV
file
docs
suggestion
GIT_TERMINAL_PROMPT
reports
terminal
prompts
password
GIT_ASKPASS
/bin/true
git
version
Authentication
password
day
head
end-of-year
break
exception
unhandled
argument_spec
string
type
limitations
argument
spec
ie
longer
choices
code
AnsibleModule
module.params
'region
]
get_dd_regions
[
default
value
]
Thanks
go
example
ipadefaultemaildomain
few
notes
string-like
*
keys
scalar
json
dict
keys
scalars
caveat
docstring
clearer
secret_name_for_VAR_NAME_1
same
VAR_NAME_2
example
output
'udevadm
info
query
property
name
DEVICE
test
case
regex
easier
parsing
bit
separate
method
simple
regex
moment
same
pre-existing
bug
exception
better
is_boto3_error_code
'NotFoundException
Key
return
None
botocore.exceptions.ClientError
botocore.exceptions.BotoCoreError
pylint
disable=duplicate-except
Legitimate
failure
module.fail_json_aws
actual
issues
Commenting
error
zabbix-server
following
test
def
test_nxos_vpc_vrf_7
'my_vrf
>
vrf
idempotence
self.get_config.return_value
=
load_fixture
'vrf_test_vpc_config
set_module_args
dict
domain=100
pkl_dest='192.168.1.1
pkl_vrf='my_vrf
self.execute_module
changed=False
device='_vrf_test
change
valid
single
word
license
full
license
header
order
approval
following
additional
authors
code
Qalthos
ganeshrn
Please
debug
comment
applicable
other
places
comment
TODO
code
idea
global
variable
unused
syntax
copyright
statements
Copyright
c
Abhijeet
Kasurde
<
@
redhat.com
>
Thanks
hints
documentation
Ansible
documentation
guidelines
module
documentation
line
guidelines
documentation
lot
easier
user
new
vNIC
reconfigure
state
new
mac
xxx
check
Thanks
mac
Windows
msg
family
family
get_distribution
Windows
code
Please
change
protocol=dict
type='str
v2.6
matches
https
//github.com/ansible/ansible/pull/27070
checkmode
notes
section
DOCUMENTATION
Please
use
name
comments
e.g
name
Create
origin
access
identity
cloudfront_origin_access_identity
right
many
SELECT
LIMIT
SQL
limitation
documentation
Creating
dirs
number
security
problems
add_group
creates
'sanitized
group
name
warnings
self._sanitize_group_name
name
commented
example
required_if
checks
absent
Please
use
name
comment
suggestion
name
Test
VMware
Tools
Connection
Plugin
Linux
suggestion
ansible_vmware_validate_certs
False
default
True
https
//github.com/ansible/ansible/blob/a2eb227970b5f53a648af3daf58d745d2f33067e/lib/ansible/modules/cloud/vmware/vmware_vm_shell.py
L303
true
suggestion
name
Test
VMware
Tools
Connection
Plugin
Windows
modules
new
removed_in_version
gundalow
compatibility
earlier
modules
more
years
compatibility
releases
Fix
spelling
duplicate
Will
paginators
code
hidden
gem
paginators
search
key
lists
=
self.connection.get_paginator
list
pg.paginate
.search
[
*
]
result
loop
return
pg.paginate
.search
[
*
]
iterator
results
fly
paginated
list
gateways
gateways
empty
list
Example
cloudformation
module
paginators
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/cloudformation.py
L294
Please
documentation
template
same
template
name
data
domain
templates
system
Thanks
single
liner
GPL
licence
[
]
https
//github.com/ansible/ansible/blob/513b582ba39a83c9400b986ff02fdd43c9ed0820/lib/ansible/modules/identity/ipa/ipa_dnsrecord.py
L4
added
thing
whole
stdout
line
feeds
suggestion
is_jsonl
=
[
modern
podman
pretty-printed
json
list
Just
whole
thing
return
json.loads
stdout
docker
json
object
line
a.k.a
JSONL
[
json.loads
json_str
json_str
stdout.splitlines
line
json
code
related
checks
good
idea
early
suggestion
return
[
]
podman
tests
suggestion
.lstrip
noqa
E501
abadger
thank
explanation
stable
API
subtle
way
past
few
releases
default
error
handler
surrogate_or_replace
cornercase
surrogate_or_replace
to_
*
methods
issues
conversion
bytes
much
simpler
ad
hoc
solution
bonus
unstable
code
sure
changes
lucky
front
only
things
functions
few
things
interface
stable
new
versions
functions
backwards
incompatible
changes
maintainers
new
versions
deprecation
cycle
license
block
much
simpler
http
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
copyright
loader
use
get_file_contents
other
modules
code
right
context
shell
non-privileged
code
task
non-privileged
current
code
ios
supports
https
//github.com/ansible/ansible/blob/devel/lib/ansible/plugins/action/ios.py
L72-L86
Various
bits
code
code
Please
line
name
maintainer
year
applicable
headers
other
files
function
none
calling_format
main
necessary
options
docs_fragments
code
module
utils
arg
spec
module
other
examples
module_utils
paramiko
=
None
statement
OK
collisions
facts
modules
last
writer
wins
OK
minor
corner
case
warning
better
somebody
merge_hash
point
ick
warning
gather_subset
config/play
vs
module
args
new
module
arg
suggestion
Change
argument_spec
warning
required_by=
[
'groups
]
module.warn
'groups
Use
new
groups
error
Ansible
bfd
set
disable
default
state
disable
preference
same
variable
confusion
*
string_types
*
string_types
list
string_types
create
string_types_list
=
list
string_types
list
multiple
times
Ok
Any
lines
string_types
order
arguments
one
star
last
one
Examples
name
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
examples-block
details
Use
name
comment
comment
most
ports
fine
port
next
time
python
try
vm_stat_command
get_bin_path
'vm_stat
ValueError
vm
stat
early
values
able
return
memory_facts
err
=
self.module.run_command
vm_stat_command
[
early
code
reader
code
other
conditional
path
function
Jack
talk
Pycon
comment
better
suggestion
Create
temporary
file
new
directory
unnecessary
code
Note
ex
module.params
'virtualenv_command
]
ex
'-m
venv
difference
minor
need
second
parens
generator
expression
tuple
list
other
changes
comment
default
False
..
case
whole
option
blocker
couple
examples
nice
'return
documentation
Constructable
Cacheable
features
self._read_config_data
access
Cacheable
Constructed
options
self.get_option
option_name
user
options
default
doc
fragments
https
//github.com/ansible/ansible/blob/devel/lib/ansible/utils/module_docs_fragments/constructed.py
https
//github.com/ansible/ansible/blob/devel/lib/ansible/utils/module_docs_fragments/inventory_cache.py
extends_documentation_fragment
able
instance
possible
unneeded
abstractions/indirections
simple
possible
parameters
MO-related
clear
options
documentation
sync
*
opinion
fine
one-line
GPLv3
license
statement
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
format
Python
older
Ansible
supports
higher
old
formatting
method
http
reason
choices
documentation
better
single
definition
list
parameters
modules
light
stderr
output
command
user
complexity
tooling
possible
impact
incorrect
input
big
risk
data-loss
data-corruption
more
safe
big
chance
valid
options
module
maintainer
real
concern
older/newer
versions
same
tool
present
absent
Ok
question
module
wrapper
data
validation
specific
piece
recommended
approach
python
elif
state
==
'absent
state
present
absent
align
lowercase
name
option
[
restriction
]
https
//www.gnu.org/software/parted/manual/html_node/name.html
list
big
mistake
code
discussion
next
core
meeting
https
//github.com/ansible/community/issues/150
issuecomment-282733423
useless
state
absent
present
suggestion
kv
v2
vault
kv
v2
GET
method
PATH
secret/data/
path
suggestion
name
Return
v2
secrets
path
Same
remark
__create_host_group
try/catch
May
want
message
non-existent
rule
same
comment
__create_host_group
section
line
other
todo
wrong
display
program
global
initialization
effect
other
things
wcwidth
instance
layer
abstraction
things
environment
ansible
runs
def
first_initialization
global
locale.setlocale
locale.LC_ALL
Could
things
initial
logger
[
configuration
]
=
True
Call
first_initialization
cli
code
document
display.get_text_width
initialization
function
global
variable
nice
error
def
get_text_width
text
display.error
[
Usage
eval
use
ast.literal_eval
Refer
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/network/common/utils.py
L432-L435
return
data
worth
note
legacy
mode
Which
version
[
docstrings
]
https
//en.wikipedia.org/wiki/Docstring
Python
comments
functions
other
places
to_text
errors='surrogate_or_strict
exceptions
docstring
IMO
auto
repo
changes
files
PRs
local
changes
specific
reason
unacceptable
name
yours
Can
_state_
*
class
methods
methods
class
reason
methods
staticmethod
Please
per
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
import
*
ansible.module_utils.basic
import
AnsibleModule
global
docstrings
suggestion
difficult
function
user
flatpakref
url
class
init
comments
'state
vs
'action
'check_client
function
requirements
present
module
import
exception
call
class
init
module
need
required=False
type=str
defaults
variables
main
function
reason
global
share
multiple
functions
supports_check_mode
block
Validate
storage_path
valid
directory
os.path.isdir
storage_path
module.check_mode
mksysb
image
backup
mksysb_cmd
=
module.get_bin_path
mksysb
True
rc
mksysb_output
err
=
module.run_command
%
s
%
%
s
%
s
%
s
%
s
%
s
%
s
%
s
%
s
%
s/
%
s
%
mksysb_cmd
create_map_files
use_snapshot
exclude_files
exclude_wpar_files
extended_attrs
backup_crypt_files
backup_dmapi_fs
storage_path
name
module.exit_json
changed=True
msg=mksysb_output
module.fail_json
msg=
mksysb
rc=rc
err=err
module.exit_json
changed=True
module.fail_json
msg=
Storage
path
%
s
valid
%
storage_path
ok
block
changes
fork/branch
line
pass
AnsibleAWSModule
Interesting
devel
anything
suggestion
state
above
validate_config
needs
present
type
before/after
docs
Shippable
complains
couple
sample
commands
doc
good
output
possible
dictionary
ARN
name
output
lines
load_balancers
list
]
load_balancers_by_arn
arn
aws
alb
....
ALB
load_balancers_by_name
fooBarBalancer
ALB
easier
particular
ALB
users
such
examples
sort
thing
trip
return
values
RETURN
section
enough
Just
scenario
user
particular
arn
name
filter
_facts
module
result
scenario
list
ordering
existence
something
string-y
key
my_lbs.load_balancers_by_name.myAlbName.someproperty
several
load
balancers
tonight
comment/docstring
standards
bit
haphazard
comment
docstring
Replace
Line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
AWS
exceptions
guidelines
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md
boto3-2
'standard
AWS
examples
comment
Note
examples
authentication
details
AWS
Guide
details.
NameError
Duplicate
comment
options
comment
space
valid
host
key
sshd
fine
man
pages
OpenSSH
code
man
pages
ambiguous
host
key
file
formats
follow
key
format
code
different
path
cargo-culted
time
authorized
keys
parser
options
field
host
public
keys
sense
possibility
sshd
upstream
man
anything
explicit
host
key
file
format
man
analogous
info
AuthorizedKeysFile
section
fact
off-chance
option
present
way
Thanks
OpenSSH
issue
PR
regular
function
last
method
class
conditional
vendored
modules
suggestion
import
import
pkgutil
Indent
necessary
suggestion
already_loaded_vendored_modules
print
stuff
already_loaded_vendored_modules
something
ResourceWarning
default
Python
warnings
infra
suggestion
print
sys.path
ansible-vendored
files
bwahaha
log
entry
fact
suggestion
print
sys.path
ansible-vendored
files
bwahaha
💣💣💣
booleans
following
statements
above
type
bool
default
documentation
consistent
booleans
human
readable
format
strings
YAML
True/False
Same
only
line
Copyright
statement
s
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
msg
documentation
message
module
whole
section
state
'present
loss
==
module.fail_json
*
results
state
==
'absent
loss
=
module.fail_json
*
results
module.exit_json
*
*
results
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
helper
function
module
utils
comparison
AWS
guidelines
details
suggestion
description
output
message
test
module
generates
suggestion
bit
newcomers
such
unnecessary
things
basic
examples
suggestion
part
collection
semantic
versioning
i.e
version
form
suggestion
type
dict
suggestion
description
Facts
ansible_facts
licensing
rest
Ansible
example
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/plugins/lookup/dig.py
L1-L16
try/except
dance
urlparse
ansible.module_utils.six
Such
ansible.module_utils.six.moves.urllib.parse
urlparse
ansible.module_utils.six.moves.urllib.parse
import
code
Please
commented
lines
Mb
MB
commented
line
s/lenovo/Lenovo/
Akasurde
rule
user
parameters
rule
current
rule
user
parameters
*
existing_rule
[
'rule_vms
]
==
self.vm_list
→
existing_rule
[
'rule_vms
]
=
self.vm_list
rule
user
parameter
existing_rule
[
'rule_vms
]
==
self.vm_list
+
existing_rule
[
]
==
existing_rule
[
'rule_mandatory
]
==
self.mandatory
+
self.module.exit_json
changed=False
rule_key=rule_key
Delete
rule
result
=
self.delete
rule_name=self.rule_name
+
+
self.module.fail_json
msg=
rule
%
s
due
%
s
%
self.rule_name
result
result
=
self.create_rule_spec
*
reason
affinity/anti-affinity
state
rule
exit
filesystem
list
paths
other
sanity
tests
file
paths
list
suggestion
name
Create
event
ovirt_event
Replace
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
__future__
import
absolute_import
division
print_function
__metaclass__
=
type
suggestion
name
Create
event
specific
object
ovirt_event
code
note
Copyright
c
Ansible
Project
documentation
fcp
parameter
action
logical_units
]
different
targets
multiple
logical
units
host_storage
Just
clarity
comment
smu/patch
rpm.
else
block
defensive
U
validate_operation
most
errors
smu/patch
rpm
syntax
commit
message
copyright
line
suggestion
Copyright
Sviatoslav
Sydorenko
<
@
redhat.com
>
Short
copyright
http
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
copyright
Shorter
version
header
[
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/mlnxos/mlnxos_config.py
L4
Use
latest
license
template
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/cli/cli_config.py
L1-L5
Hmm
list
somewhen
suggestion
require
final
stack
state
DELETE_COMPLETE
suggestion
require
final
stack
state
CREATE_FAILED
suggestion
require
final
stack
state
ROLLBACK_COMPLETE
Unused
code
arguments
safer
sys.stdout
switcharoo
*
try
python
try
old_stdout
=
sys.stdout
sys.stdout
=
captured_stdout
=
StringIO
sys.stdout
RETURN
section
appropriate
attributes
Code
module_utils
licensed
values
open
point
decision
design
guidelines
typo
Please
one-line
license
statement
task
name
large
comment
task
statement
explanation
guidance
task
name
something
user
own
playbooks
more
documentation
additional
information
comment
name
Add
Pester
module
action
module_name
ansible_powershell_version
>
name
Pester
state
present
UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS
string
ROLLBACK_COMPLETE
intentional
cleanup
progress
state
end
condition
Same
comment
name
field
task
comment
name
field
r
Please
examples
multi-line
YAML
key
value
use
-name
comment
support
mode
suggestion
HAS_YAML
module.fail_json
msg=missing_required_lib
'PyYAML
cert_body
comment
cert_body
comment
+
docs
point
something
keys
familiar
inventory
plugins
sense
metadata
host
node
ID
etc.
dynamic
inventory
ID
hostname
Swarm
node
swarm
manager
default
entries
same
hostname
unreachable
part
swarm
second
active
multiple
nodes
same
hostname
nothing
wrong
safer
ID
inventory
entry
swarm
modules
dynamic
inventory
detected
modules
suggestion
self.node_attrs
[
'Spec
]
.get
'Labels
crash
'Labels
self.node_attrs
[
'Spec
]
self.node_attrs
[
]
[
'Labels
]
None
WojciechowskiPiotr
ssl_version
other
cases
i
'compose
users
groups
data
plugin
'original_safe
import
base
class
backwards
compatibility
base
class
self._sanitize_group_name
suggestion
'Leader
self.node_attrs
[
'ManagerStatus
]
sense
label-based
groups
something
docker_swarm-label-
short/generic
labels
groups
prefix
option
inventory
plugin
users
collisions
suggestion
self.inventory.add_group
'docker_swarm-label-
self.label
Same
next
line
sanity
tests
Python
suggestion
def
_set_tls_connect_params
method
final
TLS
connection
parameters
previous
comment
ID
suggestion
self.get_option
'tls
self.get_option
'tls_verify
self.get_option
'tls
self.get_option
'cert_path
self.get_option
'key_path
TLS
certs
host
verification
self.tls_config
=
self._get_tls_config
client_cert=
self.get_option
'cert_path
self.get_option
'key_path
ssl_version=self.get_option
'ssl_version
self.get_option
'tls
TLS
certs
verification
self.tls_config
=
self._get_tls_config
verify=False
ssl_version=self.get_option
'ssl_version
self.get_option
'tls_verify
self.get_option
'cert_path
self.get_option
'key_path
TLS
certs
host
verification
self.get_option
'cacert_path
self.tls_config
=
self._get_tls_config
client_cert=
self.get_option
'cert_path
self.get_option
'key_path
ca_cert=self.get_option
'cacert_path
assert_hostname=self.get_option
'tls_hostname
ssl_version=self.get_option
'ssl_version
self.tls_config
=
self._get_tls_config
client_cert=
self.get_option
'cert_path
self.get_option
'key_path
assert_hostname=self.get_option
'tls_hostname
ssl_version=self.get_option
'ssl_version
self.get_option
'tls_verify
self.get_option
'cacert_path
TLS
cacert
=
self._get_tls_config
ca_cert=self.get_option
'cacert_path
assert_hostname=self.get_option
'tls_hostname
ssl_version=self.get_option
'ssl_version
self.get_option
'tls_verify
TLS
verify
certs
=
self._get_tls_config
verify=True
assert_hostname=self.get_option
'tls_hostname
ssl_version=self.get_option
'ssl_version
self.set_option
False
self._populate
def
_get_tls_config
*
kwargs
try
tls_config
=
docker.tls.TLSConfig
*
*
kwargs
return
tls_config
docker.tls.TLSParameterError
exc
self.fail
TLS
config
error
%
s
%
exc
Part
code
TLS
client.nodes.get
APIError
s
failure
options
AnsibleModule
able
options
modules
examples
mutually_exclusive
required_together
required_one_of
require_if
space
thanks
logger
poolname
parameter
default
type
str
comment
parameter
order
te
consistent
other
str
parameter
declaration
poolname
webfilter_profile
Use
same
case
comments
IPv4
first
daft
_
lot
errors
playbook
readable
way
username
same
thing
code
pull-request
fortios_ipv4_policy
other
FortisOS
pull-requests
[
fortios_address_group
]
fortios_address
]
block
connect
method
block
method
blocks
[
module_utils/fortios.py
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/fortios.py
helper
method
parent
class
example
[
cloudstack
]
https
//github.com/ansible/ansible/tree/devel/lib/ansible/modules/cloud/cloudstack
modules
common
code
AFAICT
statement
useless
sure
exceptions
easier
end-user
exception
python
e
=
get_exception
module.fail_json
msg='Error
device
%
s
%
e
comment
sure
f.rollback
[
FortiOS._commit
method
]
https
//github.com/spotify/pyfg/blob/master/pyFG/fortios.py
L280
pyFG
library
wraps
batch
command
order
commands
[
FortiOS
cli
]
http
//docs.fortinet.com/uploaded/files/2194/fortiswitchos-cli-30.pdf
behavior
batch
command
wrapped
command
FortiOS.execute_command
error
cases
CommandExecutionException
exceptions
]
https
//github.com/spotify/pyfg/blob/master/pyFG/fortios.py
L160
exception
API
Given
doubts
rollback
better
nat
true
fixedport
poolname
Will
date
case
comments
better
beginning
query
Assume
query
SELECT
*
FROM
USER_UPDATES
case
INSERT
q.upper
cursor.rowcount
>
table
empty
module
something
AnsibleModule
enclosed
string
documentation
ami
]
http
//docs.ansible.com/ansible/latest/ec2_ami_search_module.html
synopsis
issue
Boto
Docs
]
https
//boto3.amazonaws.com/v1/documentation/api/latest/reference/services/acm.html
ACM.Client.get_certificate
certificate
other
failure
boto
exception
lines
keys
circumstances
keys
regex
Valid
PEM
files
dashes
kind
PEM
format
good
idea
ignore
case
module_utils.crypto.get_fingerprint
overkill
IMO
better
PEM
DER
binary
format
ASCII
armour
Python
standard
library
https
//docs.python.org/3/library/ssl.html
ssl.PEM_cert_to_DER_cert
Should
work
Python
BTW
code
PEM
files
PEM
object
first
one
chain
results
module
function
chains
something
different
Better
store
global
variable
need
certificate
same
headers
different
content
important
headers
suggestion
assert
pem_compare
d
check
description
type
parameter
Valid
values
[
String
StringList
]
variables
region
https
//github.com/ansible/ansible/blob/devel/lib/ansible/plugins/lookup/__init__.py
L76-L85
lookup
key
region='us-east-1
sure
good
idea
more
parameters
boto3
module
get_parameter
parameter
lookup
key
region='us-east-1
key_id='alias/demo
reason
lookup
region=us-east-2
Second
consistant
code
hashi_value.py
lines
Remove
code
Same
common
azure_tags
documentation
fragment
sure
correct
theory
reason
pending_declarations
extra
check
'children
dupicate
vars
suggestion
people
containers
actual
valid
passwd/shadow
use
host
uids
last
lines
part
DO
few
days
*
lib/ansible/module_utils/digital_ocean.py
*
*
Ansible
Digital
Ocean
utils
PR
generic
configurations
documentation
function
*
digital_ocean_argument_spec
*
*
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/digital_ocean.py
values
absolute
values
i.e
standard
units
easier
sure
line
something
def
_attached_sd_service
storage_domain
dc_name
=
]
datacenter
parameter
case
state
==
absent
iterate
dcs
dc_name
self._module.params
'state
]
'absent
dcs_service
=
self._connection.system_service
.data_centers_service
dc
=
search_by_attributes
dcs_service
storage=self.param
'name
dc
None
raise
Exception
Ca
storage
dataceneter
bla
bla
attached_sds_service
=
self._attached_sds_service
dc_name
attached_sd_service
=
attached_sds_service.storage_domain_service
storage_domain.id
return
attached_sd_service
NameError
except
list
need
disk_size_m
+
=
disk_size_m.group
unit
=
disk_size_m.group
try
+
re.match
r'\d+\.\d+
+
float
value
string
+
=
float
+
int
value
string
+
=
int
TypeError
ValueError
NameError
+
Common
failure
+
self.module.fail_json
msg=
disk
size
disk
index
%
s
]
value
documentation
%
disk_index
=
disk
[
'size
]
.rstrip
'tgmkb
use
user
try
something
'1gb500mb
comments
information
ValueError
case
user
try
something
funny
'1gb500mb
key
dict
current_scsi_info
key
device.key
key
device.busNumber
device.key
key
device.key
something
Done
case
datastore_cluster_obj
None
misleading
get_recommended_datastore
code
datastore_cluster_obj
None
document
docstring
None
datastore
size_tb
size_gb…
suggestion
=
disk
[
param
]
vm
module.fail_json…
try
…
cosmetic
isinstance
ds
vim.Datastore
necessary
datastores
get_all_objs
self.content
[
]
ds
type
additional
group
hosts
clear
more
hosts
colon
Rest
LGTM
Consider
ansible.module_utils.urls
option
dependency
requests
argument
spec
work
descr
key
lookup
error
module.params
comment
imports
timezone
Note
_plugin
option_
configuration
path
new
parameter
plugin
metadata
[
example
]
https
//github.com/ansible/ansible/blob/03794864c2c3267f1fbff6ac49e2d883090284ad/lib/ansible/plugins/connection/ssh.py
L188
use
get_option
method
order
option
value
[
example
]
https
//github.com/ansible/ansible/blob/03794864c2c3267f1fbff6ac49e2d883090284ad/lib/ansible/plugins/connection/ssh.py
L973
Same
comment
below
plugin
option
%
positive
trailing
/
import_uri
trailing
/
incorrect
value
task_id
change
valid
single
word
license
full
license
header
order
approval
following
additional
authors
code
kedarX
ganeshrn
Please
update
sync
other
community
platforms
c
Red
Hat
Inc.
c
Lenovo
Inc.
No
Before
keys
state
comment
expected
output
command
good
idea
comment
few
linex
output
command
Red
Hat
decorator
function
fetch_rpm_from_url
sure
other
parts
code
variable
name
yum_base
object
VM
+
vm
+
vm
VM
+
…
matter
taste
compute_client
common
pls
use
consistent
modules
common
client
private
in-consistent
issue
version
upgrading
new
modules
mgmt
client
common
ok
module
better
name
hard
values
argument
spec
choices
check_mode
situation
Whats
right
behavior
user
purge_app_settings
True
settings
Changed
False
new_settings
dict
old
one
python
new_settings
dict
self.purge_app_settings
self.app_settings_strDic.properties
key
self.app_settings.keys
self.app_settings_strDic.properties
key
]
=
self.app_settings
[
key
]
new_settings
=
set
self.app_settings_strDic.properties
to_be_update
=
True
comment
class
plain
dict
approach
interface
MutableMapping
one-liner
[
]
https
//github.com/ansible/community/wiki/Testing
-boilerplate
-wildcard-imports
-and-get_exception
boilerplate
anomaly
module_utils
code
GPL
BSD
Simplified
BSD
License
licenses/simplified_bsd.txt
https
//opensource.org/licenses/BSD-2-Clause
copyright
Register
VM
id
ClientError
comment
PR
inline
other
boto3
facts
modules
NoCredentialsError
ClientError
sure
default
key
argument_spec
something
defaults
module
Please
force
shlex
....
PR
Could
line
Copyright
c
Abhay
Kadam
<
@
gmail.com
>
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
design
choice
comment
Strike
necessary
account_id
required
parameter
guidance
parameter
comment
volume
names
same
lines
s
fine
line
easiest
api
whats
easier
playbook
developer
must-fix
PR
impact
module
SF
modules
associated
playbooks
account
names
account
id
playbooks
easier
module
nicety
amount
needless
lines
code
module
module
community
important
decision
pattern
Disregard
volume
delete
comment
incorrect
indentation
space
Please
use
updated
boilerplate
[
Reference
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/iosxr/iosxr_banner.py
newer
endpoint
documentation
need
minimum
version
SANtricity
OS
RETURN
doc
string
check_flag
[
]
module
https
//github.com/ansible/ansible/blob/34ecd6cb25258116d394ffcbaf9ec29504a3919a/lib/ansible/modules/system/syspatch.py
L128-L129
syspatch
available
patches
-l
user
specifies
module
check_flag
'-l
]
[
'-c
]
default
suggestion
check_flag
=
[
run_flag
]
syspatch
available
patches
False
'-c
]
syspatch
available
patches
suggestion
Set
safe
defaults
run_flag
check_flag
run_flag
=
[
code
pull-request
other
FortisOS
pull-requests
[
fortios_ipv4_policy
]
https
//github.com/ansible/ansible/pull/21849
discussion_r103169920
fortios_address
]
block
compare_config
block
commit
method
helper
method
parent
class
example
[
cloudstack
]
https
//github.com/ansible/ansible/tree/devel/lib/ansible/modules/cloud/cloudstack
modules
common
code
Typo
s/decalre/declare/
group_members
date
_match
checks
match
beginning
string_
^
pattern
module.params
'comment
]
useless
Parentheses
e.message
useless
name
parameter
something
module.params
[
'member
]
+
[
[
'name
]
]
V2
chars
beginning
end
i
pattern
valid
bjolivot
>
same
parameters
example
[
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/files/unarchive.py
L155
[
example
]
https
//pymotw.com/2/re/
compiling-expressions
regular
expression
object
time
check
bjolivot
>
See
[
documentation
]
https
//docs.python.org/2/library/re.html
re.match
TODO
False
s/privatekey/privatekey_path/
other
module
convention
privatekey_path
examples
code
OpenSSLModule
OpenSSLObject
OpenSSLModuleError
OpenSSLObjectError
other
modules
uses
ansible.module_utils
crypto_utils
documentation
aliases
keyword
friendly_name
documentation
aliases
keyword
path
parens
necessary
return
values
addition
Glandos
comment
[
]
https
//github.com/Glandos/ansible/blob/f4204aa69c7e3429b83b3d5d7d5f7ee07f29407e/lib/ansible/modules/database/postgresql/postgresql_db.py
L451
import
ansible.module_utils.postgres
pgutils
try
pgutils.ensure_libs
sslrootcert=module.params.get
'ssl_rootcert
db_connection
psycopg2.connect
*
*
kw
pgutils.LibraryError
e
module.fail_json
msg=
unable
.format
to_native
TypeError
e
'sslrootcert
e.args
]
module.fail_json
msg='Postgresql
server
least
version
sslrootcert
exceptions
[
]
https
//github.com/Glandos/ansible/blob/f4204aa69c7e3429b83b3d5d7d5f7ee07f29407e/lib/ansible/modules/database/postgresql/postgresql_db.py
L462
[
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py
L42
Good
point
token
name
token_type
likely
useful
return
idea
rules
ACL
extra
API
call
helpful
return
consistent
RETURN
documentation
conclusion
suggestion
module_util
hack
suggestion
situation
same
parameter
prev_value_pretty
value_pretty
more
correct
suggestion
try
collection
world
name
module_utils
files
BSD
right
git
grep
-i
user_agent
few
different
conventions
popular
Ansible
lib/ansible/module_utils/ec2.py
config.user_agent_extra
=
__version__
lib/ansible/plugins/inventory/azure_rm.py
self.add_user_agent
'ansible-dynamic-inventory/
release.__version__
Ansible-gcdns/
%
s
Ansible-gce_inventory_plugin/
%
s
ansible-healthcheck/
%
s
ansible-target_proxy/
%
s
..
module
provider
name
feature
Ansible
different
join
python
snaps_to_install
snaps_to_install
bad
practice
variable
type
useful
status
data
message
easy-to-understand
explanation
user
detail
command
implementation
able
access
stderr/out/_lines
result
variable
indented
else-block
Better
use
command
list
right
list
easier
python
cmd_parts
[
snap_path
]
module.params
'classic
]
cmd_parts.append
classic
=
'.join
cmd_parts
rc
module.run_command
cmd
check_rc=False
|=
install_snap
module
snap_name
need
snaps
afterwards
need
extra
var
default
kwargs
exiting
exit_kwargs
=
'classic
module.params
'classic
]
False
module.exit_json
*
*
exit_kwargs
time
]
=
other
exits
module.exit_json
cmd=
stdout=
stderr=
*
exit_kwargs
same
fail_
vlc
error
message
useful
nice
details
comment
module
snap_name
continue
snaps_to_install.append
snap_name
nice
list
snaps
example
foo
bar
ok
change
additional
formatting
changes
current
formatting
meets
code
standards
short
comment
Limit
read
rate
/dev/sda
mebibytes
second
correct
style
note
cases
generator
expression
false
case
yaml
extenstion
valid
files
empty
extensions
files
test_ext
ext
ext
C.YAML_FILENAME_EXTENSIONS
ext
cases
condition
simple
code
things
easier
specific
reason
DVP
Debug
required=False
need
warning
changed
==
False
lines
suggestion
sequence
=
Sequence
module
cursor
cosmetic
suggestion
name
data
object
postgresql_copy
data
suggestion
ansible.module_utils.database
import
suggestion
class
Sequence
object
Maybe
docstrings
classes
methods
PEP257
proposal
author
autocommit
Ah
sorry
type
annotations
code
return
[
]
suggestion
return
[
]
podman
suggestion
return
podman
AnsibleParserError
other
inventory
sources
requirement
versions
build
system
docstring
user
Examples
Playbook
best
practice
name
comment
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
examples-block
imports
top
functionality
new
best
practice
suggestion
name
Install
python
package
proxy
Pip
standard
environment
variables
please
CAPITALIZED
ones
built-in
waiters
docs
suggestions
good
https
//boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rds.html
waiters
Aurora
work
general
rds
module
aurora
snapshots
blocker
suggestion
state
absent
register
rds
environment
var
something
user
specifies
CLI
CLI
self.boto_profile
=
self.args.boto_profile
os.environ.get
'AWS_PROFILE
below
conditional
config
file
right
precedence
profile
environment
command-line
option
other
way
precedence
order
highest
lowest
Command-line
flag
Environment
variable
Config
file
module
connection
message
API
stub
messages
messages
authentication/connection
other
way
method
connect_timeout
command_timeout
suggestion
t
=
cls._NOTES.sub
r
Note
nicer
note
Please
DOCUMENTATION
block
e.g
requirements
ncclient
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
documentation-block
consider
miq_expression
hash_expression
params
user
param
type
+
expression
option
function
least
consideration
class
format
Neat
heart
Worth
IMHO
PR
See
https
//github.com/ansible/ansible/pull/32136
issuecomment-341520122
example
older
MIQ
best
thing
exception
error
message
hash
expression
better
name
extra
word
Handler
something
generic
big
Examples
name
comment
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
examples-block
details
Minor
issue
CI
though
DOCUMENTATION
block
order
/usr/bin/perl
GPL
ANSIBLE_METADATA
DOCUMENTATION
EXAMPLES
RETURNS
AnsibleAWSModule
single
line
blank
line
Copyright
c
Kairo
Araujo
<
kairo
@
>
line
problem
yaml
validation
failure
\
line
continuation
\
inside
single
quotes
same
issue
lines
real
problem
CI
people
-P
issue
line
colon
backslashes
problem
fact
args
key
hum
advantages
=
r
e-mail
comment
empty
line
name
assert
task
parameter
openssl_certificate_info
bit
try
open
key_file
'rb
f
key
=
load_pem_private_key
f.read
b_key_passphrase
default_backend
IOError
e
Handle
bad
files
ValueError
TypeError
e
Handle
issues
key
C
voluptuous.MultipleInvalid
Exception
[
]
https
//github.com/alecthomas/voluptuous/blob/e72fd3bfb24f89888f51825313de98c397641674/voluptuous/schema_builder.py
L268-L271
voluptuous.error
]
https
//github.com/alecthomas/voluptuous/blob/master/voluptuous/error.py
Classes
things
easier
module
you'rd
state
self
name
]
program
instance
class
ma
get_bucket_list
top-level
method
idea
module
future
i
easier
expansion
filters
example
more
AWS
modules
same
easier
majority
classes
understandable
result
blocker
commit
line
Generate
privatekey6
standard
non-ASCII
passphrase
test
'ascii
codec
byte
position
ordinal
range
Stacktrace
/tmp/ansible_openssh_keypair_payload_kCnMbD/__main__.py
line
generate
tf.write
%
s
%
quote
self.passphrase
/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py
line
write
return
self.writer.write
data
/usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/lib/python2.7/codecs.py
line
write
data
=
self.encode
object
self.errors
Python
tests
Python
~~private
key~~
key
pair
typo
message
newline
lot
spaces
.py
module.fail_json
msg=
RSA
keys
minimum
size
bits
default
bits
bit
lengths
module
dictionary
key
key
pythonic
way
things
way
more
common
single
call
loop
device
data
Fans
]
fan_details.append
dict
Name=device
[
FanName
]
RPMs=device
[
Reading
]
Again
dictionary
piece
piece
little
sense
data
hand
Hard-coding
id
format
compatibility
bugs
function
complete
location
id
job
resource
service
use
Id
property
id
Same
things
IPv4
addresses
v6
counterparts
Facts
modules
results
ansible_facts
key
order
facts
something
line
redfish
inventory
[
]
accounts
[
]
system
[
]
updates
[
]
chassis
]
redfish_inventory
[
]
redfish_accounts
[
]
sure
types
facts
lists
dicts
idea
Feel
free
clarification
sure
contents
result
look
good
idea
own
key
e.g.
redfish_facts
top
level
facts
PEP257
sentence
hence
period
suggestion
Test
lenient_lowercase
proper
results
useful
info
Replace
line
GNU
General
Public
License
v3.0+
COPYING
https
//www.gnu.org/licenses/gpl-3.0.txt
Copyright
c
Ansible
Project
state
DOCUMENTATION
say
state
DOCUMENTATION
argument_spec
better
practice
hyperthreading_info.active
good
reboot
active
ideas
unicode
sandwich
text
bytes
example
role
nice
suggestion
return
LooseVersion
'version
]
<
Proxmox
suggestion
return
LooseVersion
'release
]
>
=
Proxmox
suggestion
return
LooseVersion
'version
]
reason
comment
other
module
want_local
count
key
Made
change
ImportError
sufficient
wrong
suggestion
query
=
SELECT
tc.table_name
FROM
information_schema.columns
tc
JOIN
t
ON
tc.table_name
=
t.tablename
WHERE
tc.column_name
=
'id
AND
tc.column_default
IS
NULL
AND
t.schemaname='public
consulta
abaixo
vai
te
trazer
todas
tabelas
que
não
possuem
DEFAULT
caso
sequence
ela
Poderíamos
iterar
sobre
essa
lista
O
que
acha
Lembre-se
que
tabela
já
pode
estar
sendo
populada
setar
start
para
ele
vai
chocar
com
todos
os
IDs
já
gerados
que
podem
já
estar
por
exemplo
Isso
dar
pau
tabela
Tem
que
setar
para
o
MAX
id
valor
que
tabela
vazia
Acho
presença
poderia
ser
fundida
nos
métodos
acima
Remover
método
pois
não
é
mais
necessário
Esse
bloco
não
poderia
simplificado
assim
data_inicial
=
cleaned_data
[
'data_inicial
]
data_final
=
cleaned_data
[
'data_final
]
data_inicial
data_final
data_inicial
>
data_final
raise
ValidationError
_
Data
Final
não
pode
ser
menor
Data
Inicial
condicao1
data_inicial
data_final
condicao2
condicao1
condicao2
raise
ValidationError
_
pesquise
por
data
os
campos
Data
Incial
e
+
Final
devem
ser
preenchidos
obrigatoriamente
Erro
português
Incial
ao
invés
Inicial
necessary
xarray
to_dataframe
to_decoded_dataframe
line
sphinx
markup
inline
code
markup
e.g
group_by=
Axes.CH
someone
different
git
repo
installs
starfish
hash
repo
starfish
starfish
install
-e
conda
equivalent
case
commit
hash
chdir
user
file
look
ups
comment
code
something
target
index
repeated
value
bounding
box
spot
simpler
way
regionprops
Exception
normal
limit
jupyter
notebook
render
suggestion
spots
it2
border
it1
total
spots
spots
it1
total
spots
suggestion
compare
section
more
spots
comments
Will
reshape
operation
i
less
TODO
fixme
kne42
=
np.nan
work
segmentation
simple
suggestion
create
example
image
file
schema
inputdir
=
tempfile.TemporaryDirectory
suggestion
write
coordinates
coordinates_path
=
os.path.join
inputdir.name
coordinates.csv
thanks
great
explanations
comments
suggestion
metric='euclidean
distance
metric
distance
pixel
vector
codeword
norm_order=2
L_n
norm
pixel
vector
codeword
distance
n
distance_threshold=0.5176
minimum
distance
pixel
vector
codeword
gene
magnitude_threshold=1.77e-5
pixel
vectors
magnitude
min_area=2
'spot
area
threshold
pixels
'spot
area
threshold
pixels
suggestion
scale
data
user-defined
factors
images
data
set
scale
factors
experiment.json
scale
factors
experiment.json
work
return
type
ehhh
IMO
Codebook
object
code
class
ugh
groupbys
gross
pandas
whitespace
yep
whitespace
PR
ask
context
manager
methods
IntensityTables
return
IntensityTables
decoders
segmentation
assignment
something
class
docstring
different
approaches
context
PR
explanation
kinda
much
code
-1
last
item
something
long
@
ambrosejcarr
opinion
SeqFISH
Thanks
comment
things
re
https
//github.com/spacetx/starfish/issues/834
more
explanation
comments
input
error
oh
lines
everything
imagestack
notebooks
run
suggestion
ch
number
larger
possible
such
spots
General
comment
sure
dtype
np.zeros
matches
output
pre-allocation
worthless
input_dtype==output_dtype
answer
float64
default
@
sofroniewn
image
dtypes
intensity
scales
example
minimum
intensity
*
*
n_bits
max
intensity
images
different
scales
largest
data
type
intensity
dtype
uint8
image
*
>
*
largest
dtype
good
scaling
point
Deep
starfish
requests
uint16
future
PR
rescaling
specific
dtype
tools
skimage
most
dtypes
[
http
//scikit-image.org/docs/dev/user_guide/data_types.html
]
http
//scikit-image.org/docs/dev/user_guide/data_types.html
background
scaling
important
images
multiple
dtypes
warning
weird
sense
defaults
algorithms
classes
reminder
explicit
TODO
Nice
re
*
https
//github.com/spacetx/starfish/pull/516
issuecomment-419557387
*
//github.com/joshmoore/starfish/commit/d2d028499a31c3049bb9f08192e2dbeab0bf63c8
diff-3ab8577a09cb5f1f0d1527d305d08bd4
way
verify_results
_into_
exec.stages
post-processing
stage
_only_
input
shutil.rmtree
block
Note
review
@
ttung
rmtree
use
TemporaryDirectory
https
//github.com/spacetx/starfish/pull/538/commits/6a590d6ab7bde830514bb686466ee55453cf892f
check=True
possible
w/o
numpy
w/
xarray
TODO
i
everything
un-filtered
boolean
filters
i
qualities
distances
tuple
store
passes_filter
mean_pixel_traces
order
props
matches
order
x-array
spots
simpler
way
above
reason
suggestion
Save
.netcdf
starfish
pipeline
mat.save
'expression_matrix.nc
Save
.h5ad
file
scanpy
mat.save_anndata
'expression_matrix.h5ad
Save
.loom
file
loompy
loomR
mat.save_loom
'expression_matrix.loom
different
API
GaussianSpotDetector
ISS
pipeline
=
SpotFinder.GaussianSpotDetector
min_sigma=min_sigma
max_sigma=max_sigma
num_sigma=num_sigma
threshold=threshold
blobs_stack=blobs_stack
measurement_type='mean
=
dots
spots
dots
image
stack
intensities
p.find
filtered_stack
simpler
API
methods
'spot_intensities
table
optional
dictionary
key
value
pairs
tutorials
imports
same
block
large
list
imports
likely
imports
same
block
user
understand
step
lives
wordy
comment
doc
string
something
suffice
demand
errors
happen
access
views
Pyramid
request
pipeline
return
value
property
mutable
mutability
Worth
note
Canvas
specific
block
feels
trifle
multiple
try/excepts
reasonable
code-reader
other
Exceptions
statements
code
summary
own
GH
comment
jwt
present
pass-thru
wrangling
settings
H
API
following
several
lines
opportunity
helper
function
road
config
settings
config
settings
present
Does
little
pattern
generation
dictionary
other
generation
happens
separate
line
user_data
definition
little
easier
point
heady
utopian
future
bits
helper
function
jwt
param
unused
other
wrapped
view
tight
view
decorators
views
view
decorators
params
result
AJ
Python
decorators
views
code
Sure
Generally
stuff
standard
features
libraries
example
comment
time
particular
Factory
Boy
feature
time
better
solution
own
Factory
Boy
crash
course
cheat
sheet
Factory
Boy
/
features
Factory
Boy
Might
nice
short
comment
guys
suggestion
TODO
LISResultSourcedId
lookup
problem
LISResultSourcedId
DB
Canvas
API
lookup
fallback
assignments
Other
kind
comments
clear
canvas
names
methods
Canvas-specific
comment
something
Canvas-specific
comment
lie
suggestion
parameter
part
Canvas
SpeedGrader
code
comment
docstring
method
detail
code
comment
lis_result_sourcedid
lis_outcome_service_url
params
clear
outcome
reporting
params
refers
bit
verbose
clear
code
def
initialise_canvas_submission_params
Add
config
frontend
Canvas
record_submission
API
=
self.request.params.get
self.request.params.get
lis_outcome_service_url
assignments
Canvas
assignment
teacher
submission-related
params
other
reason
return
submissionParams
=
h_username
self.context.h_user.username
lis_result_sourcedid
lis_result_sourcedid
lis_outcome_service_url
lis_outcome_service_url
plain
old
loop
lot
easier
comprehension
case
Might
help
docstring
group
record
LTI
app
db
course
_actually_
Thank
type-correct
Hmm
good
point
note
charset
param
adverse
affects
people
test
value
default
content
type
Thoughts
import
hierarchy
bit
parallel
tracks
WSGI
Python
Cython
ASGI
grimacing
Tbh
note
thinking
base
vs
IOError
comment
answers
case
note
_maxmize_
sic
spelling
arrow_right
helpful
inline
NOTE
comment
app
code
Context
subclasses
mapping
interface
unnecessary
inheritance
chain
sake
efficiency
default
implementations
ABC
overridden
https
//github.com/falconry/falcon/issues/1579
TODO
arrow_up
coding
artifact
purpose
list
Might
inline
comment
double-CRLF
nice
inline
comment
effect
handler.exhaust_stream
self.bounded_stream.exhaust
developer
preference
stream
regardless
flag
handler
habit/stylistic
preference
extra
line
break
open_mouth
style
consistent
rest
majority
Falcon
code
FWIW
preference
CONTRIBUTING.md
consistent
FWIW
[
PEP
form
]
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
summary
line
same
line
opening
next
line
entire
docstring
same
quotes
first
line
example
style
Remove
linebreak
only
test
single
cookie
multiple
helpful
posterity
comment
particular
input
variation
if/when
test
separate
test
single
cookie
request
safer
choice
ASGI
server
point
slightly_smiling_face
resp.get_media
Good
catch
comment
statement
ASGI
version
examples
integer
uvicorn
barfs
recent
call
last
/Users/kgriffs/.pyenv/versions/3.8.0/lib/python3.8/site-packages/uvicorn/protocols/http/httptools_impl.py
line
run_asgi
result
=
await
app
self.scope
self.receive
self.send
/Users/kgriffs/.pyenv/versions/3.8.0/lib/python3.8/site-packages/uvicorn/middleware/proxy_headers.py
line
__call__
return
await
self.app
scope
receive
send
/Users/kgriffs/.pyenv/versions/3.8.0/lib/python3.8/site-packages/falcon/asgi/app.py
line
__call__
await
send
/Users/kgriffs/.pyenv/versions/3.8.0/lib/python3.8/site-packages/uvicorn/protocols/http/httptools_impl.py
line
send
content
=
[
STATUS_LINE
[
status_code
]
]
KeyError
whole
file
WSGI
flavour
tests_asgi
Intent
note
unclear
copy-paste
L216
Thanks
comments
vytas7
idea
EAFP
fact
issubclass
ValueError
TypeError
BaseException
arg
class
way
user
function
iterable
AFAIK
simple
pythonic
way
EAFP
better
stricter
checks
nature
exception
argument
way
tuple
EAFP
issubclass
exc
BaseException
exc
exception_tuple
list
handlers
descriptive
TypeError
A
link
documentation
format
individual
author
lists
files
@
mraspaud
list
more
suggestion
subject_info
=
info.get
'subject_info
suggestion
subject_info
None
brainc
hard
code
suggestion
reconstructions
example
load
white
surface
suggestion
mesh
subject
sample
cyan
spherical
surface
suggestion
brain
mesh
set
vertices
shape
n_vertices
set
triangles
shape
vertices
rr
form
triangular
facet
mesh
info
important
note
sentence
suggestion
important
part
FreeSurfer
cortical
surface
suggestion
Notice
head
coordinate
nasion
values
x
z
directions
sense
nasion
y
axis
system
suggestion
hood
functions
func
mne.setup_source_space
suggestion
head
coordinate
frame
voxels
head
→
MRI
surface
RAS
transform
suggestion
mesh
top
MRI
slice
mesh
surfaces
millimeters
MRI
FreeSurfer
surface
RAS
coordinate
frame
voxels
inverse
Torig
transform
properties
dig
code
_make_dig_points
function
dig
@
agramfort
data
self
comments
right
whitening
output
values
unit-noise-gain
noise-cov
[
'Intercept
]
this_data
small
norm
=
np.linalg.norm
this_data
axis=1
allocation
this_data
*
comment
empty
line
comment
list
comprehension
drop_inds
None
droped_indices
[
d
]
//
len
inst.times
d
drop_inds
easier
variables
such
similar
names
comment
necessary
'cos
need
comment
comment
auto
delegate
reject
ica
empty
line
reading
clear
things
act
reject
otherwise
switch
case
auto
delegate
reject
ica
reject
==
reject
getattr
ica
None
pass
reject
None
drop_inds
None
=
inst
data
=
inst.get_data
data
=
_reject_data_segments
data
ica.reject_
flat=None
decim=None
info=inst.info
tstep=2.0
=
RawArray
data
inst.info
pass
Docstring
squeeze
comment
test
hack
meth
time_unit=
warnings
advanced
string
formatting
loops
etc
annotations
:3
]
new
Annotations
first
annotations
]
new
Annotations
annotation
doc
likes
str
lists
acronym
singular
value
decomposition
Please
PCA
way
various
pyvista
sliders
figures
interactive
helpful
way
stc.plot
GuillaumeFavelier
@
larsoner
suggestion
suggestion
Matplotlib
figure
facecolor
interactive
display
versus
saved
figures
facecolor
labels
title
visible
sure
comment
next
line
read_inverse_operator
function
advantage
good
naming
choices
API
suggestion
print
f
name
var.sum
.1f
%
var
output
line
label
f-string
syntax
%
-replacement
suggestion
cruft
sLORETA
suggestion
Compute
label-to-label
leakage
Pearson
correlation
PSFs
sign
correlation
arbitrary
absolute
values
leakage_mne
=
np.abs
np.corrcoef
psfs_mat
suggestion
rm_mne
=
make_inverse_resolution_matrix
inverse_operator
method='MNE
lambda2=lambda2
need
method
arg
suggestion
y-locations
labels
=
[
np.mean
labels
[
label_names.index
name
.pos
[
]
name
lh_labels
sure
suggestion
cryptic
savings
lines/characters
Feel
free
suggestion
node_order
=
[
:-1
]
+
rh_labels
mirror
label
order
hemis
something
bad
I/O
round-trip
shift
Evoked
files
FIFF_FIRST_SAMPLE
FIFF_LAST_SAMPLE
FIFF_FIRST_TIME
FIFF_NO_SAMPLES
First
last
sample
write_int
fid
FIFF.FIFF_FIRST_SAMPLE
write_int
fid
FIFF.FIFF_LAST_SAMPLE
e.last
decision
times
first
None
nsamp
=
last
first
+
elif
first_time
None
first
=
int
round
first_time
*
info
[
'sfreq
]
last
=
+
nsamp
times
np.arange
last
+
dtype=np.float
info
[
'sfreq
]
spirit
TDD
test
I/O
round-tripping
1e-6
evoked
instance
shift
Always
FIFF_FIRST_TIME
FIFF_NO_SAMPLES
addition
FIFF_FIRST_SAMPLE
FIFF_LAST_SAMPLE
FIFF_FIRST_TIME
FIFF_NO_SAMPLES
available
available
compatible
work
sub-sample
shift
case
noqa
end
event.xdata
float
tuple
consisting
floats
idea
while
super
happy
such
complex
/
low
level
code
alternative
@
agramfort
more
decision
point
FIFF
namespace
FIFF.FWD_
values
part
FIFF
spec
new
FWD.
bunch
mne/forward/forward.py
things
people
FIFF.FWD_
own
code
Typo
Revert
comment
suggestion
ch_type
self.reject.keys
Yeah
true
arrays
big
complete
copies
.conj
time
detail
fwiw
inner
loop
output
[
appropriate_slice
]
=
ifft
X_fft
[
ch0
]
*
X_fft
[
ch0
]
random
github
user
interesting
PR
idea
big
arrays
data
shift
end
phase
memory
usage
unnecessary
computations
looping
count
N
*
N
current
bottleneck
way
somehow
nearby
features
yeah
case
example
difference
laplacian
ugh
yes
numpy
arrays
.imag
.real
views
array
complex
mult
multiplies
route
scipy.fftpack.rfft
np.fft.rfft
follow-up
PR
someone
yeah
number
operations
half
good
Existing
annotations
right
mouse
description
keyword
left
annotation
sure
tutorial
something
MNE
term
trigger
many
labs
FieldTrip
nice
people
other
software
lot
pain
STIM
channel
explanation
abbreviation
reality
short
stimulation
pulse
>
pulse
channels
>
stim
channel
term
trial
epoch
better
clear
explanation
terms
equivalent
worth
trial
terminology
other
software
FieldTrip
list
teh
readers
read_raw_artemis123
read_raw_brainvision
read_raw_bti
read_raw_cnt
read_raw_ctf
read_raw_edf
read_raw_bdf
read_raw_gdf
read_raw_eeglab
read_raw_egi
read_raw_eximia
read_raw_fieldtrip
read_raw_fif
read_raw_nicolet
annot_from_events
mne
need
raw
object
orig_time
explicit
+1
short
title
bullet
reason
list-like
append
method
quacks
list
md
~the
function
documentation
further
details~
more
details
ref
New
section
doc
_bla
>
part
API
section
end
document
chunk_duration
mne.make_fixed_length_events
new
section
state
tutos/examples
functions
API
API
point
section
ie
chunk_duration
todo
point
example
own
event
parser
little
paragraph
more
entity
entire
thing
example
point
*
*
*
[
events
annotations
data
structures
]
https
//13302-1301584-gh.circle-artifacts.com/0/dev/auto_tutorials/intro/plot_object_annotations.html
the-events-and-annotations-data-structures
temp
directory
tests
f-string
syntax
lot
compatible
python
installation
guide
>
MNE-Python
Python
version
higher
documentation
f-strings
ok
general
policy
formatting
MNE
future
Fstrings
.format
syntax
%
syntax
concatenation
best
https
//github.com/drammock/mne-python/pull/3
entity
enough
index
subtitle
possibility
point
top
document
events
raw
object
Reading
events
Subselecting
events
Event
IDs
trial
descriptors
events
Overlay
events
raw.plot
first
part
tutorial
top
tutorial
..
tutorial
detail
doc
..
/intro/plot_object_annotatios
reminder
top
first
python
stuff
inline
comment
line
other
tutorial
link
enough
ie
quick
reminder
[
events
=
mne.find_events
raw
stim_channel='STI
]
https
//13302-1301584-gh.circle-artifacts.com/0/dev/auto_tutorials/intro/plot_object_annotations.html
converting-a-stim-channel-signal-to-an-events-array
events
ref
sample
dataset
<
bla
>
channel
STI014
explanation
new
section
events
raw
object
pick_events
typo
fix
next
lines
onsets
start
stop
onsets
np.clip
=
np.ones
start
bool
onset
end
zip
onsets
ends
>
=
end
continue
[
start
end
start
=
True
=
np.concatenate
[
[
False
]
[
False
]
]
=
~used
[
-1
]
]
]
+
start
[
-1
]
[
]
]
+
start
something
numpy
operations
loop
brain_ple_diff
>
brain_ple_dspm
print
statement
odd
ways
line
continuation
operator
\
means
indentation
spaces
following
line
part
string
space
most
pairs
words
spaces
pairs
words
Python
strings
multiple
lines
print
'foo'
'bar
baz
foobar
baz.
lack
commas
explicit
inclusion
space
bar
foo
EDIT
print
statements
second
way
odd
useful
informative
statements
auto-generated
output
code
rendered
text
code
blocks
line
plots
dSPM
lower
peak
localization
error
red
color
MNE
deeper
brain
areas
higher
error
blue
color
superficial
areas
same
thing
other
print
statement
end
tutorial
suggestion
Compute
spatial
deviation
SD
PSFs
@
olafhauk
headers
examples
Authors
docstring
title
===
suggestion
Compute
peak
localisation
error
PLE
PSFs
same
rmk
title
name
brain_le_mne
consistent
naming
same
brain_ple_dspm.add_text
dSPM
'title
font_size=16
prior
comment
print
statements
rendered
example
text
prior
comment
print
statements
empty
lines
blocks
single
lines
kind
metric
lines
lines
minimal
disambiguation
meanings
peak
metrics
=
'cog
'sd
'maxrad
'peak_ratio
'sum
metric
metrics
ValueError
%
s
metric
%
metric
lines
code
lot
way
code
harder
arguments
right
way
users
different
aspects
resolution
e.g
localisation
spatial
extent
estimation
expense
more
lines
code
lines
opinion
logic
well-written
docstring
well-chosen
parameter
values
thorough
examples/tutorials
effective
goal
kind
metric
single
string
e.g.
spatial_deviation
spatial_max_rad
spatial_area
loc_error_peak
loc_error_cog
insufficient
user
choose
different
public
*
functions
different
kinds
metric
more
sense
current
implementation
suggestion
ns
=
shape
]
//
shape
]
number
source
components
vertex
author
+
licence
proper
names
event
fif
files
-eve.fif
use
example-eve.fif
haha
old
example
subsection
full
events
new
subsection
events
ok
latest
push
full
sphinx-gallery
treatment
explanation
columns
question
suggestion
sort_by_spectral_ratio=False
False
purpose
example
suggestion
Note
necessary
sort_by_spectral_ratio=True
default
Say
something
trans=None
MRI
head
coordinate
frames
subsequent
PR
issue
TODO
true
practice
MNE
reference
raw.set_eeg_reference
analyses
Cz
reference
Might
something
mne.add_reference_channels
new
reference
channels
part
data
proper
reference
big
effect
noise
levels
story
way
people
EEG
reference
EEG
voltage
Voltage
*
difference
*
electric
potential
points
EEG
*
*
reference
set_eeg_reference
signal
channel
reference
channel
recording
'virtual
channel
average
channels
current
reference
sentence
parentheses
unfinished
paragraphs
capital
letters
suggestion
average
referencethe
EEG
channels
EEG
channels
present
https
//17962-1301584-gh.circle-artifacts.com/0/dev/auto_examples/inverse/plot_psf_ctf_vertices_lcmv.html
sphx-glr-auto-examples-inverse-plot-psf-ctf-vertices-lcmv-py
test
diagonal
entries
corrcoef
results
commit
correlation
coefficient
rows
numbers
low
fail
Hopefully
able
suggestion
First
let
look
CSD
scalp
topography
times
topos
same
time
instants
suggestion
traditional
ERP
plot
something
CSD
parameters
lambda2
smoothing
spline
flexibility
solution
param
name
lambda2
lambda
subplot
lambda
superscript
plot
titles
matplotlib
LaTeX
support
unicode
λ²
same
Pass
times
BSD
permission
authors
original
GPL
code
._data
wrapper
purpose
[
]
=
notices
code
AFAIK
code
computations
sure
multiple
subjects
and/or
runs
only
way
duration
vary
subjects
runs
worse
tradeoff
last
chunk
subject/run
different
least
typical
duration
recordings
st_duration
choices
note
last
window
longer
duration
worse
shy
*
st_duration
suggestion
signals
internal
subspace
oblique
projection
suggestion
magnetometer
gradiometer
sensor
units
collateral
effects
_regularized_covariance
input
data
unchanged
only
assert
regression
test
PR
comment
check
input
data
unchanged
gh-5698
raw.pick_types
belongs
section
raw.crop
pick_types
dimension
book
object
indexing
index
ambiguous
wording
value
index
epochs.selection
suggestion
inset_axes
axes
figure
necessary
documentation
server
fig
ax
plt.subplots
figsize=
ax.plot
times
mean
ax.set
xlabel=
Time
Amplitude
µV
suggestion
Recreate
figure
sensor
dots
figure
fig
ax
plt.subplots
figsize=
ax.plot
times
mean
ax.set
xlabel=
Time
Amplitude
µV
=
inset_locator.inset_axes
ax
width=
%
height=
%
loc=2
raw.pick_channels
to_plot
.plot_sensors
title=
docstrings
stuff
Notes
detailed
Channels
default
/
optional
Sorry
lists
blank
line
beginning
end
list
blank
lines
list
item
optional
much
indentation
bullet
list
text
text
text
other
words
space
space
text
single
space
line
subsequent
paragraph
blockquote
list
blank
lines
suggestion
sample
data
literature
reference
aparc
]
_
References
..
[
]
Destrieux
al
etc
bottom
http
//docutils.sourceforge.net/docs/ref/rst/restructuredtext.html
citations
suggestion
class
~mne.simulation.SourceSimulator
label
single
backticks
italics
code
case
better
function
func
tilde
mne.simulation.
link
parentheses
single
space
line
much
indentation
bullet
character
space
True
line
line
check
possible
better
beamformer
advanced
cross-validated
estimators
e.g.
shrunk
best
reg
clear
okay
bullet
cleanup
TFMxNE
>
TF-fMxNE
please
percentage
proportion
class
obj
single-backticks
docstring
f
suggestion
total
length
number
channels
time
points
Docstring
wrong
annotations
much
value
pass
case
comment
anything
conditional
ecog
seeg
pick_types
line
MNE
line
[
quote
+
list
]
https
//5720-1301584-gh.circle-artifacts.com/0/tmp/circle-artifacts.t2SHhHb/html/auto_tutorials/plot_info.html
channel-types
bulleted
list
Python
capital
P
same
use
inverse_operator
'source_ori
]
=
FIFF.FIFFV_MNE_FREE_ORI
better
private
function
places
suggestion
invmat
=
np.delete
invmat
ch_idx_bads
suggestion
invmat.ndim
suggestion
shape
=
invmat.shape
invmat
=
invmat.reshape
shape
]
*
shape
]
shape
]
dims
word
dims
shape
common
name
cleanup
suggestion
turn
source
estimate
numpy
array
suggestion
Does
sLORETA
localization
error
columns
acronyms
harder
new
comers
suggestion
assert_array_equal
maxidxs
goodidxs
license
author
//github.com/mne-tools/mne-python/blob/master/mne/tests/test_event.py
L2
more
Just
suggestion
Test
make_resolution_matrix
function
cleanup
google
ngram
online
]
https
//books.google.com/ngrams/graph
content=on-line
%
year_start=1800
year_end=2000
corpus=15
smoothing=3
share=
direct_url=t1
%
%
%
20-
%
%
%
%
%
%
%
%
on-line
awesome
ninja
weaponry
novices
channels
info
[
'bads
]
list
pointer
tasks
http
//autoreject.github.io
automated
method
technical
detail
something
purists
channels
bad
data
channels
bad
first
bad
channels
shorthand
channels
artifacts
other
hand
machine
learning
bad
channels
impact
longish
sentence
splitting
list
exhaustive
additional
classes
such
ICA
TFR
sentence
lot
more
lot
more
scalp
potentials
true
MEG
important
point
data
shape
consistent
subjects
lot
analysis
code
hmm
@
dengemann
ICA
variance
statistical
independence
whoaaaa
something
same
comment
offline
Seems
something
ERF/P
plot
bad
channels
fantastic
way
issues
bit
abstract
example
good
ICA
SSP
convenient
subjects
advanced
usage
standard
event
detection
hmm
story
complicated
preload=True
epochs
other
hand
epochs
access
epochs.load_data
stringent
parameters
constructor
suggestion
chanidx
<
chanidx
channel
data
file
e.g
Ref
channel
list
Git
issue
everything
diff
git
blame
nicer
more
PEP8-compatible
space
clear
short-circuit
/
ignore
branch
comments
caps
large
point
number
>
more
information
sentence
period
closing
parenthesis
proper
reference/link
raw.set_annotation
i.e
method
something
>
element
class
mne.Annotations
comma
objects
first
sample
data
=
raw.first_samp
same
raw.info
[
'meas_date
]
annotation
object
+
operator
Remove
parenthesis
Check
better
start
Refer
documentation
mne.Annotations
comment
full
stop
signatures
PSG
>
=
freqs
<
pre-processing
purpose
Sleep
stage
Sleep
stage
able
function
resampling
problem
need
interested
couple
lines
pipeline
>
range
No
need
comment
FunctionTransformer
float
x
TypeError
x
None
case
None
certain
situations
suggestion
isinstance
str
None
clipping.lower
clipping
None
try
clipping
=
float
allow
float
ValueError
pass
+0.X2020
+0.X
initial
double
quote
closing
end
@
jhouck
description
process
ideas
other
ways
comments
case
better
someday
Python3
__truediv__
suggestion
sake
example
note
uncertain
lines
MNE-Python
NOT
auto
average
refs
function
signature
regexp=None
*
check
regex
parameter
none
inner
function
comment
RandomizedPCA
https
//github.com/scikit-learn/scikit-learn/pull/2273
comments
much
time
week
unlikely
more
constants
uV
Ohm
dimensionless
distinction
unrecognized
unit
==0
GDF
unsupported
dimensions
something
warning
unsupported
case
lot
constants
constants.py
other
readers
FIF
CTF
KIT
things
readable
DRY
comments
code
lines
RuntimeError
user
MNE
developers
suggestion
top
brain
func
~mne.viz.snapshot_brain_montage
early
electrode
location
plot
opinion
suggestion
fig
axs
plt.subplots
figsize=
colormap
range
wide
frequency
Suggestion
suggestion
locations
electrodes
subject
brain
func
~mne.viz.snapshot_brain_montage
plot
image
data
xy
positions
electrode
image
frequency
band
power
top
..
note
real
electrodes
subject
cortical
surface
suggestion
Create
1x2
figure
average
power
gamma
alpha
bands
suggestion
Next
signal
power
gamma
30-90
Hz
alpha
8-12
Hz
https
//mne.tools/dev/generated/mne.make_fixed_length_epochs.html
pointer
estimators
suggestion
Let
investigate
spatial
filter
max
power
ratio
different
sections
better
narrative/rendering
control
suggestion
Let
investigate
spatial
filter
max
power
ratio
suggestion
below50
=
freqs
comment
API
arrays
=
freqs_sig
]
<
=
freqs
freqs
<
=
]
interest
suggestion
initial
sorting
eigenvalues
None
spatial
filter
high
pass
linebreak
ii
i
debugger
many
special
commends
single
character
names
SSD
instantiated
object
test
test
something
pytest.raises
ValueError
SSD
filt_params_signal
filt_params_noise
whitespaces
comma
whitespace
better
explicit
error
=
list
indent
Do
test
correlation
independent
scale
location
variance
R2
score
line
break
unnecessary
hanging
indents
indent
white
sapces
multiplication
operator
white
spaces
equals
white
spaces
subtraction
operator
white
spaces
indent
large
de-indent
previous
line
indents
point
/
filenames
easier
last
line
print
nothing
Grainger
render
properly
My
marketing
mind
tells
Raw
data
source
space
MNE
less
minutes
bit
software
architecture
e.g.
different
options
method
method
'MNE
different
source
localization
methods
functions
plot_
figure
handle
matplotlib
point
people
whole
lot
little
people
Matlab
shape
matrices
numpy
matrix
epochs
get_data
people
matrix
feedback
emails
subjects_dir
end
section
tutorial/example
ICA
Maxfilter
SSP
Annotations
rejection
thresholds
suggestion
source
space
inverse
operator
>
snr
variable
names
rest
examples
tutorials
little
bit
easier
cost
users
other
examples
same
thing
signal
ratio
inline
comment
step
bit
opaque
beginners
something
Basically
covariance
source
space
forward
only
external
files
trans
coregistration
bem
Freesurfer
recon-all
sure
preload
logic
fits
basic
tutorial
advanced
people
memory
Most
beginners
L42
note
numbers
dataset
specific
autoreject
paper
issue
rendered
version
boxes
bit
many
colors
same
color
code
shade
gray
PR
own
os.path.join
=
sample_data_folder
+
most
machines
many
examples
tutorial
simple
people
minutiae
Python
SSP
MEG
centric
concept
EEG
audience
ICA
Just
bit
explicit
units
inverse
operator
glossary
point
source
entry
glossary
data
entry
doc
links
rest
doc
people
materials
*
*
Detecting
experimental
events
*
*
*
*
Epoching
continuous
data
*
mne.make_fixed_length_events
nitpick
extra
white
space
read_raw_fif
artefact
concept
channel
type
worth
upon
briefly
MNE
multiple
channel
types
libraries
EEGLAB
types
dictionary
constructions
tutorial
confusion
beginner
dict
stuff
opinion
SSP
projectors
external
noise
MEG
measurements
raw.plot_psd
raw.filter
need
much
text
figure
source
time
course
STC
pick_types
'eeg
beginning
rest
tutorial
channel
type
other
hand
MNE
different
channel
types
binary
bit
necessary
integer
integer
value
unique
stimulus
show
tell
approach
data
shape
reason
note
raw.get_data
[
'nchan
]
worth
metadata
raw.info
information
frequency
channel
names
lowpass/highpass
tutorial
epochs
object
object
fact
info
object
kwargs
construction
bit
advanced
new
Matlab
introductory
tutorial
spatial
filters
SSP
eye
movements
heartbeats
raw
data
topographies
projectors
shape
evoked.data
n_channels
x
n_times
redundant
field
same
info
testtime
testdate
suggestion
num_comments
comments_dict
mult
unused
code
projectors
care
stuff
info
[
]
[
k
]
[
'cal
]
1e-6
mult
div
*
1e-6
equivalent
effect
dict
lookup
uncovered
lines
easier
sex_dict
=
dict
m=
male=
f=
female=
[
'sex
]
=
sex_dict.get
subject_info
[
'sex
]
FIFF.FIFFV_SEX_UNKNOWN
order
order
reason
order
user
file
WDYT
worth
key
lower
same
try
subject_info
[
'hand
]
=
hand_dict
[
subject_info
[
'hand
]
]
KeyError
subject_info.pop
'hand
old
way
use
pytest
fixture
suggestion
out_dir
=
mne.utils._TempDir
=
str
tmpdir
array_equal
atol
1e-30
same
Typo
thing
mne/data
https
//github.com/mne-tools/mne-python/blob/master/mne/data/fsaverage/fsaverage-fiducials.fif
boxy
version
number
@
rob-luke
ok
line
loop
suggestion
boxy_coords
np.array
boxy_coords
float
assert
boxy_coords.shape
==
boxy_coords
better
preallocate
boxy_coords
=
np.zeros
boxy_coords
old
NumPy
error
mne/io/boxy/boxy.py:240
_read_segment_file
mode='empty
/
..
/
/miniconda/envs/test/lib/python3.6/site-packages/numpy/lib/arraypad.py:1325
pad
kw
allowedkwargs
[
mode
]
E
KeyError
many
typo
@
kuziekj
better
trans
head
>
MRI
transformation
Can
returned
types
data
annotations
annotations
deprecation
please
variant
deprecat
*
git
grep
deprec
useful
tool
deprecation-related
things
problem
order
foo.dig
issue
error
maximum
add
plot
full
example
statsmodels
tests
t-values
section
T
-np.log10
p
visual
intuition
end
summary
view
t-test
several
times
section
t-test
null
hypothesis
means
voxel
independent
test
voxel
something
talks
tests
different
methods
test
*
statistics
*
*
*
*
*
*
parametric
Hm
ok
useful
state
beginning
permutation
*
exchangeability
*
*
correlation
structure
data
reads
abstract
underlying
concept
intuitive
effects
cluster
time
space
property
time
space
frequency
data
i.e.
effects
time
space
lower
closer
math-impaired
people
*
*
*
*
*
distribution
~~a~~
greater
lower
case
type
*
*
*
*
*
*
single
p-values
p-value
weird
ears
accurate
*
data
*
parametric
test
statistic
concerns
full
data
null
hypothesis
cluster
structure
full
data
vertex
tf
data
source
space
data
..
distribution
test
statistic
count
[
comma
]
sum
Really
space
channel
dimension
time
dimension
MNE
conservative
procedure
distribution
p-value
spatial
connectivity
general
function
dimension
connectivity
structure
distribution
true
Right
value
singular
regressor
distribution
*
clusters
null
derivable
permutation
tests
apt
cluster-based
approaches
spatial
points
i.e.
vertices
adjacent
sensors
neighbours
comment
random
subsamples
permutation
testing
available
samples
flip
signs
*
type
*
*
lower-case
t
plot
end
section
linguists
useful
continuous
predictors
Bonferroni
correction
Bonferroni
honest
sure
math
impaired
t-statistic
smaller
set
degrees
freedom
suggestion
actual_gof
=
np.ones
dip
GOF
Dipole
instance
suggestion
actual_gof
=
np.ones
dip
GOF
Dipole
instance
cases
real
least
division
zero
noqa
E501
restrictive
DRY
alarms
head
keys
=
'evt
=
dict
key
keys
files
key
]
=
glob.glob
%
s/
*
%
s
%
fname
key
files
key
]
raise
[
key
]
=
[
key
]
[
]
files
key
glob.glob
%
s/
*
%
s
%
fname
key
key
keys
key
keys
suggestion
elif
subject_info
[
'sex
]
F
'Female
proper
check
optional
MNE
dependency
way
np.loadtxt
manual
open
r
fid
few
lines
suggestion
subject_info
[
'sex
]
=
FIFF.FIFFV_SUBJ_SEX_MALE
suggestion
subject_info
[
'sex
]
=
FIFF.FIFFV_SUBJ_SEX_FEMALE
whole
file
time
lines
AFAIK
sort
thing
raw_extras
time
files
dict
self._raw_extras
]
entry
possible
specific
dtype
np.array
sources
float
np.array
sources
int
FIF
dtype
entries
info
API
page
https
only
output
format
FIF
anything
actual
analysis
way
Info
things
specific
data
disk
separate
dict
file-format
specific
_raw_extras
my_extra_dict
temporary
sense
format
file
fname
raw_read
=
mne.io.read_raw_fif
fname
anything
actual
analyses
wavelengths
Info
proper
WIP
fine
point
fnirs_
entries
ndarray
shapes
clear
singleton
element
channel
multiple
elements
channel
units
Candela
list
https
//github.com/mne-tools/mne-python/blob/master/mne/io/constants.py
L740
units
type
FNIRS
https
//github.com/mne-tools/mne-python/blob/master/mne/io/constants.py
L170
ch_types='fnirs
different
coil
type
intensity
measurements
[
HbO/HbR
]
https
//github.com/mne-tools/mne-python/blob/master/mne/io/constants.py
L803
appropriate
coil
type
electrode
MEG
SQUID
OPM
physical
thing
physical
things
measumerments
Let
try
sensible
names
FNIRS_001B
FNIRS_002A
better
something
descriptive
A
B.
S/R
send/receive
channel
channels
np.loadtxt
able
suggestion
open
file_hdr
]
.read
hdr_str
context
manager
incl
error
use
fnirs
section
projectors
del_proj
method
acronym
SVD
common
SVD
projection
computation
suggestion
proj='reconstruct
evoked
plotting
functions
good
brief
explanation
*
*
*
*
possible
counter-intuitive
many
people
ICA
data
data
thread
list
https
//mail.nmr.mgh.harvard.edu/pipermail/mne_analysis/2018-March/004785.html
better
way
ICA
fitting
different
solutions
different
initializations
ICA
involves
randomness
impression
algorithm
true
sure
worth
mentioning
reader
scikit-learn
method
MNE
same
small
number
Makeig
group
dimensionality
40-60
channel
ICA
virtual
ECG
channel
creation
possible
MEG
data
https
//martinos.org/mne/stable/generated/mne.preprocessing.find_ecg_events.html
computation
noise
model
white
identity
covariance
sorry
earlier
discussions
parameters
max_pca_components
+
n_components
full
figure
okay
+
explanation
confusion
fact
single
source
data
source
ICA.fit
ICA.apply
ICA.fit
diagram
ICA
ICA.fit
more
original
sources
technical
SOBI
time-domain
information
course
most
ICA
example
feedback
blue
colorbar
buggy
epochs.plot_image
groupby=rois
combine='mean
order=order
sigma=1.5
/
colorbar=True
vmin=lambda
x
x.min
clear
error
epochs.plot_image
combine='mean
axes=axes
order=order
sigma=1.5
/
vmin=lambda
x
x.min
blue
epochs.plot_image
combine='mean
order=order
sigma=1.5
/
vmin=lambda
x
x.min
vmax
max
epochs.plot_image
combine='mean
order=order
sigma=1.5
/
colorbar=True
blue-white-red
values
positive
epochs.plot_image
combine='std
order=order
sigma=1.5
/
colorbar=True
such
scenarios
unit
tests
example
axes
Use
default
behaviors
sure
nice
default
params
example
xticks
default
subfunction
_combine_data
returns
description
bit
redundant
code
comments
clearer
comments
code
description
sure
better
comments
code
monkey
patch
please
comment
lest
people
private
matplotlib
var
comment
BCA
groupby
dictionary
containing
group
name
>
channel
indices
mappings
way
gfp
way
>
bad_chs
consistent
rest
repo
@
AdoNunes
good
practice
thing
same
variable
name
displacement_limit=displacement_limit
AdoNunes
ideas
script
branch
faster
bunch
comments
import
matplotlib
import
mne
private
function
function
rot_qs
input
returns
method
param
_average_quats
branch
_average_quats
_average_quats
negative
eig
decomposition
=
_average_quats
rot_qs
weights=dt
rot_qs
*
=
dt
[
]
rank
update
method
https
//arc.aiaa.org/doi/abs/10.2514/1.28949
journalCode=jgcd
https
//github.com/tolgabirdal/averaging_quaternions/blob/master/wavg_quaternion_markley.m
noqa
E501
qs.append
rot_qs
outers
np.einsum
ik-
>
ijk
rot_qs
rot_qs
=
outers.sum
axis=0
dt_sum
=
dt.sum
dt_sum
>
=
norm
=
dt_sum
norm
<
raise
RuntimeError
good
segments
norm=
%
s
%
norm
/=
norm
best_q
=
linalg.eigh
]
[
-1
]
largest
eigenvector
wavg
Same
largest
eigenvector
concatenation
best_q
=
linalg.svd
np.concatenate
qs
.T
]
[
]
best_q
=
best_q
[
:3
]
*
np.sign
best_q
[
-1
]
obscure
quaternians
values
best_q1
best_q
different
True
problem
meg
eegs
mmm
times
recording
short
bad
channels
=
None
=
new_metadata
dangerous
way
Epochs.__init__
self.set_metadata
metadata
epochs.set_metadata
new_metadata
epochs.set_metadata
None
work
much
extra
effort
General
question
good
idea
baseline
inverse
solution
useful
baseline
sensor
level
valuable
information…
things
source
level
*
*
look
inverse
baseline
state
memory
suggest
users
home
flake8
editor
complains
sure
MNE
List
comprehension
redefines
fname
comment
plt.xlabel
plt.ylabel
thanks
good
time
pytest
parametrize
approach
Dont
class
Just
dumb
plain
private
function
annotation
object
Thx
events
markers
ok
element
difference
stim
ch
MarkerFile.mrk
same
information
least
test
case
MarkerFile.mrk
negative
times
sync
points
sh
TRIAL
NUMBER
TIME
FROM
SYNC
POINT
seconds
+0.474166666667
+6
+1.06
+46
+1.2725
+48
-0.148333333333
+52
+0.831666666667
+56
-0.0266666666667
+57
+0.453333333333
+60
+1.23833333333
cc
@
hyperbolicTom
@
larsoner
@
agramfort
good
practice
raw
data
user
blinks
VEOG
HEOG
channels
nice
channel
numbers
raw
plots
easier
VEOG
HEOG
MEG
channels
same
feedback
EOG
section
raw
plots
side
side
ECG
epochs
side
side
attention
y-axis
limits
impressive
y-axis
limit
original
limit
obvious
eye
blinks
interested
MEG
signals
zoom
great
person
course
native
speaker
waveforms
reference
signal
suggestion
same
process
ECG
likely
ECG
signal
dipole
ECG
electrode
time
waveform
same
temporal
dynamics
manifest
MEG
channel
Other
approaches
ref
<
tut-artifact-ica
>
ref
<
tut-artifact-ssp
>
better
dataset
warning
UserWarning
figure
Axes
compatible
tight_layout
results
incorrect
suggestion
effect
clearer
epochs
EOG
comma
suggestion
First
let
data
normal
way
event
type
standard
trials
delete
Probably
cleaner
chars
e.g
←
coding
utf-8
top
file
[
'Right
]
Right
object
Right
-type
epochs
something
one
error
try/except
worth
none
error
conditional
merge_grads
ch_type
assert
fnirs_ch_type
non-nicety
explicit
flag
PR
logger.info
Client
server
start_time
current_time
=
time.time
current_time
<
start_time
+
self.wait_max
try
self.connect
logger.info
Client
self._enter_extra
Exception
current_time
=
time.time
time.sleep
success
while
exits
RuntimeError
Buffer
PR
Anyways
wdyt
D
connect
logger.info
Client
server
start_time
=
time.time
time.time
<
start_time
+
self.wait_max
try
self.connect
logger.info
Client
break
Exception
time.sleep
av_tfr.plot
[
]
vmin=chance
title=
Time-Frequency
Decoding
Scores
cmap=plt.cm.Reds
explicit
/
future-compatible
None
example
docstring
related
[
CircleCI
failure
]
https
//circleci.com/gh/mne-tools/mne-python/4154
utm_campaign=vcs-integration-link
utm_medium=referral
utm_source=github-build-link
other
examples
format
new
version
sklearn.discriminant_analysis
import
LinearDiscriminantAnalysis
cycles
huge
sections
breaks
https
//4168-1301584-gh.circle-artifacts.com/0/home/ubuntu/mne-python/doc/_build/html/auto_examples/decoding/plot_decoding_csp_timefreq.html
empty
newline
space
examples
sure
much
screen
real
estate
Screenshot
2020-02-13
09-33-22
]
https
//user-images.githubusercontent.com/2365790/74445206-02351f80-4e44-11ea-8082-c3c249b7a4ba.png
plotters
tutorial
docstrings
users
fsaverage
latest
files
CircleCI
SUBJECTS_DIR
sample
dataset
directory
files
fsaverage
/home/circleci/mne_data/MNE-sample-data/subjects/fsaverage
Downloading
files
https
//files.osf.io/v1/resources/rxvq7/providers/osfstorage/5cb759eea3bc970017f17d50
action=download
version=1
direct
revision=1
MB
Verifying
File
/tmp/tmpihd8a9hb/fsaverage.zip
files
files
difference
make_bem_model
make_bem_solution
newcomer
short
comment
model
variable
bem_surfaces
users
SUBJECTS_DIR
set
nothing
EEG
users
value
SUBJECTS_DIR
MNE
config
~/mne_data/MNE-fsaverage-data
tmpdir_factory
fixture
tmpdir
doc
informative
mocking_date
EXPECTED_DATE_REPRESENTATION
EXPECTED_DATE__REPR__
fixture
tmpdir_factory
writing
file
fixture
fixture
file_name
intermediate_rep
date_repr
See
https
//github.com/pytest-dev/pytest/issues/1595
need
private
function
+1
tests
@
larsoner
code
duplication
suggestion
Richard
Höchenberger
<
richard.hoechenberger
@
gmail.com
>
need
blank
lines
line
evoked.first
.last
description
little
confused
example
look
values
attributes
everything
super
clear
slow
thinker
bad
reader
something
things
suggestion
evoked.first
evoked.last
sample
indices
sample
sample
time=0
evoked.first
negative
example
data
Hz
epochs
sec
experimental
event
evoked.first
-180
length
mne.make_fixed_length_events
comment
per-epoch
double
backticks
code
suggestion
default
stc.plot_3d
mne.VolSourceEstimate.plot_3d
>
time
course
source
largest
absolute
value
time
point
example
source
largest
raw
signal
value
location
brain
small
blue
definition
mags
grads
variables
ch_type
[
'mag
'grad
]
evk
=
[
'aud/right
]
.copy
.pick
ch_type
ch_type
title
neat
syntax
black
magic
new
comers
tuto
pretty
entry
level
options
something
naive
explicit
stupid
code
evokeds_list
]
evokeds_list
]
current
flow
orientation
magnetic
field
vector
field
note
butterfly
plot
..
note
Such
plot
butterfly
plot
source
brain
positive
negative
values
sensors
lines
wings
butterfly
special
warning
function
deals
logger
..
utils
import
warn
warn
tests
pytest.warns
match=
print
logger.info
case
something
intervals
bands
topo
subtitles
perfect
consensus
correct
bands
good
reasons
good
default
explicit
suggestion
data
=
np.loadtxt
signals
ndmin=2
*
1e-6
convert
raw
many
blank
lines
good
call
good
get_gfp_ci
average
rank=rank
confidence
intervals
non-parametric
bootstrap
indices
np.arange
average.ch_names
dtype=int
gfps_bs
=
np.zeros
average.data.shape
]
iter_
range
n_draws
bs_indices
rng.choice
indices
replace=True
indices
gfps_bs
[
iter_
]
=
average.data
[
bs_indices
*
*
.sum
/
rank
gfps_bs
=
mne.baseline.rescale
gfps_bs
baseline=
None
ci_low
ci_up
=
np.percentile
gfps_bs
return
ci_low
line
*
estimate
*
D
reversed
more
explicit
frequency
spatial
*
patterns
private
attribute
problematic
use
method
example
filters
different
transition
bandwidths
l_trans_bandwidth='auto
mode
bandwidth
depend
freq
comparable
same
value
axes
[
:-1
]
problem
GFP
variance
sensors
colors
plt.cm.viridis
subtraction
evoked
response
first
subtract
rank
header
last
cell
able
evoked
Nice
one
plot_compare_evokeds
thanks
typo
=
abs
baseline
purposes
D
empty
line
Ah
one-timepoint
freq-bin
case
way
Nice
frequency
error
case
plot
freq
+
conditional
freq_diff
=
]
freq
else
np.diff
freq
Same
comment
time_diff
inline
comment
colormap
limits
UrbanM
idea
type
acquisition/manufacturer
software
tell
filter
settings
acquisition
vstack
coord
right
shape
im
=
plt.imread
'./brain.png
click
=
ClickableImage
im
click.plot_clicks
ValueError
values
guess
Please
comment
sfreq
different
obvious
first
sight
comment
useful
better
comment
code
line
currenlty
last
line
method
bit
weird
comment
code
SilenceStdout
Mayavi
backend
peculiarity
old
version
library
comment
Clean
comments
merge
minor
point
other
link
does.
[
image
]
https
//user-images.githubusercontent.com/7044835/47516734-86961480-d886-11e8-96db-7ebb3f85bd71.png
conditional
plot
info=raw.info
way
code
readability
full
credit
meth
<
mne.io.Raw.plot_projs_topomap
>
/home/circleci/project/doc/auto_tutorials/plot_visualize_raw.rst:227
WARNING
py
func
reference
target
mne.io.proj.Projection.plot_topomap
python_reference.rst
[
mne.Projection
]
https
//9990-1301584-gh.circle-artifacts.com/0/html/python_reference.html
func
proj.plot_topomap
<
mne.Projection.plot_topomap
>
Sphinx
error
suggestion
positions
channels
sharex
unnecessary
suggestion
x
x
position
Oz
channel
y
y
position
T8
channel
z
average
z
position
Oz
Fpz
T7
T8
z
position
same
channels
positive
cm
suggestion
position
eye
sensor
locations
tutorial
<
tut-sensor-locations
>
position
Fpz
T8
Oz
T7
channels
available
montage
suggestion
required
x
y
z
center
radius
suggestion
_check_option
border
string
/home/circleci/project/doc/auto_tutorials/intro/plot_40_sensor_locations.rst:250
WARNING
py
meth
reference
target
mne.channels.DigMontage.plot
fly-by
comment
many
users
plotting
'standard_1020
biosemi
montage
brief
example
ch_types='eeg
works
shorter
Feel
free
separate
examples/visualization/plot_eeglab_head_sphere.py
Good
practice
reproducibility
suggestion
rng
=
np.random.RandomState
data
rng.randn
n_channels
1e-6
suggestion
interested
beta
band
12-30Hz
suggestion
DICS
beamformer
single
sensor
type
gradiometers
example
necessary
subject
name
play
plotting
subject
suggestion
Compute
source
estimates
different
methods
DICS
LCMV
MNE
MNE-dSPM
suggestion
Weighted
averaging
addition
covariance
objects
DICS
short
Dynamic
imaging
coherent
sources
more
explicit
contrast
dSPM
model
course
suggestion
stc_base
freqs
=
apply_dics_csd
csd_baseline.mean
filters
Lot
comments
example
code
above
comment
good
example
useful
comment
windows
comment
suggestion
Compute
covariance
matrices
LCMV
MNE
methods
_gen_
*
functions
_gen_
*
functions
covariance
matrices
weird
story
wise
suggestion
stc_act.plot
subject='sample
subjects_dir=subjects_dir
explanatory
comments
covariance
matrices
plots
beneficial
novice
users
suggestion
stc_act
/=
stc_base
consistent
other
example
tmin=-1.0
tmax=1.5
other
example
way
equal
number
data
point
baseline
ERS
parts
code
something
REQUIRED_FILES_EXT
=
[
.dap
.dat
.rs3
]
[
.cdt
.cdt.dpa
]
def
_check_missing_files
full_fname
fname_base
curry_vers
neccessary
files
path
extension
CURRY
version
_msg
=
Message
account
list
files
=
[
Path
dirname
fname
.with_suffix
ext
ext
REQUIRED_FILES_EXT
[
curry_vers
Path
dirname
fname
.with_suffix
ext
missing
raise
FileNotFoundError
_msg.format
full_fname
fname_base
code
Make
sure
variables
descriptive
impossible
variables
descriptible
statements
readable
ie
Path
dirname
fname
.with_suffix
ext
docstring
something
units
uV
fT
adequate
[
cal
]
value
FIFF
unit
types
recent
comments
mind
_read_annotations_curry
def
_read_annotations_curry
fname
sfreq='auto
latency
description
=
_read_events_curry
fname
sfreq
=
_get_sfreq
fname
==
'auto
else
sfreq
return
Annotations
orig_time=None
onset=latency
/
sfreq
duration=np.zeros_like
latency
description=description
_get_curry_file_structure
files
_read_curry_info
name
curry
info
nothing
_get_sfreq
def
_get_freq
fname
curry_file
=
_get_curry_file_structure
fname
return
_read_curry_info
curry_file
info
__init__
_get_info
ParsedInfo
=
namedtuple
n_samples
is_ascii
foo
bar
def
_read_curry_info
fname
Extract
info
curry
parameter
files
=
[
'NumSamples
'SampleFreqHz
'DataFormat
'SampleTimeUsec
'SAMPLE_FREQ_HZ
'DATA_FORMAT
]
param_dict
=
dict
=
dict
open
fname
fid
line
iter
fid
var_name
line
var_name
var_names
key
val
line.replace
.replace
\n
=
[
key.lower
.replace
_
val
type
CHANTYPES
DEVICE_PARAMETERS
+
CHANTYPES
[
type
]
+
START
line
data_unit
=
next
fid
unit_dict
[
type
]
=
data_unit.replace
.replace
\n
=
float
param_dict
[
samplefreqhz
]
time_step
=
float
param_dict
[
sampletimeusec
]
1e-6
sfreq
==
time_step
sfreq
/
time_step
return
ParsedInfo
sfreq=sfreq
n_samples=float
param_dict
[
'samplefreqhz
]
..
is_ascii=
param_dict
[
dataformat
]
ASCII
def
_get_info
curry
CurryFileStructure
>
info_dict
parsed_info
=
_read_curry_info
curry.info
=
_read_curry_lines
curry.label
LABELS
+
CHANTYPES
[
key
]
key
[
meg
eeg
misc
]
]
sensors
_read_curry_lines
curry.label
SENSORS
+
CHANTYPES
[
key
]
key
[
meg
eeg
misc
]
]
=
list
key
[
meg
eeg
misc
]
ind
chan
enumerate
labels
LABELS
+
CHANTYPES
[
key
]
]
ch
=
ch_name
chan
unit
unit_dict
[
key
]
kind
FIFFV_CHANTYPES
[
key
]
key
meg
eeg
loc
=
sensors
SENSORS
+
CHANTYPES
[
key
]
]
[
ind
]
ch
[
loc
=
np.array
loc
dtype=float
all_chans.append
ch
=
[
chan
ch_name
]
chan
all_chans
info
=
create_info
ch_names
parsed_info.sfreq
ind
ch_dict
enumerate
info
[
chs
]
ch_dict
kind
]
all_chans
[
]
[
kind
]
ch_dict
[
'unit
]
=
SI_UNITS
[
[
ind
]
[
'unit
]
]
]
ch_dict
[
'cal
]
=
SI_UNIT_SCALE
[
[
ind
]
[
'unit
]
]
]
ch_dict
kind
]
FIFF.FIFFV_MEG_CH
FIFF.FIFFV_EEG_CH
ch_dict
loc
]
all_chans
[
]
[
loc
]
return
info
n_samples
preload
header
first
line
https
//www.python.org/dev/peps/pep-0257/
mutliline
docstrings
suggestion
curry_vers
bit
sure
preferable
e.g
n_samples
int
param_dict.get
NUM_SAMPLES
[
NumSamples
]
dict
=
.replace
_
value
key
value
param_dict.items
File
python
function
basename
save_labels
line
=
\n
docstring
format
summary
inputs
necessary
mne
namesapce
relative
imports
suggestion
open
fname_base
+
file_extension
fid
suggestion
sfreq
time_step
def
_get_curry_version
fname
return
Path
fname
def
_check_missing_files
fname
vesrion
check
files
....
def
read_raw_curry
input_name
version
=
_get_curry_version
input_name
_check_missing_fiels
dirname
fname
version
info
bla
Try
try
block
IOError
test
files
private
attributes
examples
something
corrupted_data
=
raw.get_data
corrupted_data
[
]
=
corrupted_od
=
mne.io.RawArray
corrupted_data
raw_od.info
first_samp=raw_od.first_samp
top
mne.preprocessing.fnirs
import
optical_density
temporal_derivative_distribution_repair
suggestion
data
indexing
exact
times
convenient
same
Do
other
imports
Flake8
errors
suggestion
inputted
raw
data
single
channel
type
threshold
something
users
reasonable
default
%
cases
external
variable
implies
users
advice
filter_freq
introduction
example
resample
filtering
least
low
pass
comment
steps
high
pass
raw
data
good
idea
necessary
low-passed
z-scores
i.e.
suggestion
View
annotations
number
cautious
such
statements
large
validation
reference
paper
punctuation
labels
time
unit
parentheses
period
movement
Unfortunatelly
NaNs
import
np
scipy.stats
zscore
data
=
np.array
[
]
zscore
data
array
[
nan
nan
]
TypeError
get_channel_types
unexpected
keyword
argument
'unique
meg
data
hard-coded
parameter
function
nitpick
sure
np.unique
point
earlier
comment
branch
new
changes
get_channel_types
available
*
anything
*
set
np.unique
unique=True
earlier
calls
get_channel_types
fine
places
ch_type
places
*
specific
channel
*
*
specific
type
*
more
type
present
type
MEG
type
MEG
channels
mean
code
EEG
way
more
muscle
artifacts
EEG
data
avoid
single
letter
variable
names
hard
Ctrl
+
F
clearer
something
suggestion
meg
=
np.in1d
ch_type
'grad
meg
suggestion
variance
kurtosis
idx
calculations
formula
possible
epochs.get_data
start
end
]
copy
private
attribute
class
volume
vector
source
estimate
<
mne.VolVectorSourceEstimate
>
information
covariance
plots
next
subsection
great
plots
rank-deficiency
tutorial
covariance
matrix
*
%
regularization
informative
many
users
suggestion
spatial
filter
unit
noise
gain
depth
bias
orientation
sources
such
output
power
pick_ori='max-power
source
estimate
source
voxel
known
scalar
beamformer
possible
vector
beamformer
estimates
voxel
direction
components
source
pick_ori='vector
class
volume
vector
source
estimate
<
mne.VolVectorSourceEstimate
>
prev
comment
depth
bias
background
intro
section
possible
changes
Well
MNE-Python
warning
threshold
rules
thumb
end
question
source
reconstruction
weird
covariance
matrix
typical
pattern
sure
Ideas
glossary
entry
whitening
Consider
section
heading
background
beamformers
introduction
beamformers
section
brief
discussion
depth
bias
mention
ways
things
result
expectation
left
auditory
stimulus
attention
features
source
estimate
unique
suggestion
<
mne.VolSourceEstimate
>
visualization
oops
typo
analysis
scripts
common
file
I/O
better
tutorial
forward
solution
need
load
raw
data
epoch
plot
evoked
butterfly
plot
explain
covariances
explain
forward
solution
role
beamformer
part
forward
cross-reference
other
example
tutorial
function
compute
forward
model
users
step
compute
spatial
filter
spatial
filter
visualize
source
suggestion
stimulus
left-ear
auditory
stimulation
old
sad
way
things
Nowadays
footbibliography
example
tutorials/preprocessing/plot_60_maxwell_filtering_sss.py
good
bit
more
detail
misrepresentation
beamformers
*
volume
source
space
emphasis
legitimate
reasons
cortical
surface
estimate
conditions
appropriate
oops
underscores
..
[
]
Gross
al
calls
single
line
marks
larger
side
side
worth
plots
suggestion
depth
bias
forward
model
solution
superficial
sources
single
conditions
depth
bias
several
ways
func
mne.beamformer.make_lcmv
depth
parameter
forward
model
spatial
filters
docstring
details
Unit
noise
gain
beamformers
depth
bias
weights
spatial
filter
weight_norm='unit-noise-gain
Neural
activity
index
beamformers
depth
bias
weights
noise
]
_
weight_norm='nai
Note
conditions
depth
bias
possible
parameters
None
suggestion
beamformers
time
arguments
helpful
common
dict
kwarg
unpacking
easy
visualization
other
Example
=
dict
src=forward
[
'src
]
subject='sample
subjects_dir=subjects_dir
initial_time=0.087
verbose=True
stc.plot
mode='stat_map
clim=dict
kind='value
pos_lims=lims
*
*
kwargs
stc.plot
mode='glass_brain
clim=dict
kind='value
lims=lims
*
*
kwargs
suggestion
coordinate
space
native
digitizer
equipment
head
surface
MRI
voxel
coordinate
frame
coordinate
frames
same
mismatch
something
important
clear
frame
start
same
coordinate
frame
suggestion
renderer
=
mne.viz.backends.renderer.create_3d_figure
variables
head_space
mri_space
mri_voxel_space
definitions
section
coordinate
frames
head
meg
mri
more
explanation
variable
name
choices
diagrams
sphinx
https
//sphinxcontrib-mermaid-demo.readthedocs.io/en/latest/
naive
learner
knows
coord
systems
RAS
clear
coordinate
frame
plot
origin
second
plot
good
most
learners
fact
correct
explanation
wrong
wrong
clearer
E.g.
clue
figure
advance
sure
scaling
helper
function
scipy
import
linalg
linalg.inv
practice
Please
plot_alignment_custom
something
name
confusion
mne.viz.plot_alignment
cruft
Prose
sections
tutorials
terse
code-comment-like
sentence
fragments
plot_dig_alignment
easier
freesurfer
surface
meters
cruft
/home/circleci/project/doc/auto_tutorials/source-modeling/plot_source_alignment.rst:311
WARNING
Title
short
suggestion
Get
landmarks
head
space
DigMontage
raw
trans
m
translation
component
=
trans.copy
trans_mm
[
:3
]
*
trans
use
trans
head
points
meters
do
standard
scheme
suggestion
KIT.SYSTEM_YOKOGAWA_2017_01
=
Kanazawa
KIT.SYSTEM_YOKOGAWA_2018_01
Kanazawa
KIT.SYSTEM_YOKOGAWA_2020_08
Kanazawa
August
precision
header
check
encode
u
E
+
text_type
sn
meta
data
[
fieldtrip
]
https
//github.com/fieldtrip/fieldtrip/blob/master/external/egi_mff/mff_getSummaryInfo.m
L111
size
hard
camelCase
please
name
explicit
comment
pib
current
president
Poland
wink
reasonable
good
comment
lines
=
int
mff_hdr
[
'nTrials
]
unsupported
Improve
sentence
small
real-world
analysis
Better
isinstance
raise
TypeError
upstream
code
necessary
list
docstring
Did
things
IIRC
LCMV/DICS
tests
bit
sensitive
params
suggestion
extinction_fname
=
op.join
op.dirname
__file__
..
'data
sure
comment
suggestion
default
unit
property
empty
BV
spec
len
props
necessary
cases
len
props
condition
props
]
==
props
]
==
explicit
fourth
entry
last
minor
comments
period
statement
most
lower
case
painful
@
larsoner
_picks_to_idx
[
]
int
note
_picks_to_idx
allow_empty
parameter
ok
True
gamma_map
@
yousrabk
XXX
>
chance
comments
easier
somebody
logic
=
dict
ch_pos_use
copy
name
info_names
name
ch_pos_use
_ch_pos_use
[
name
]
=
[
np.nan
np.nan
something
suggestion
func
mne.channels.make_eeg_layout
function
suggestion
sensor
positions
measurements
recording
session
digitization
implies
measurement
part
sentence
clear
people
such
terminology
sentence
different
data
formats
mention
formats
layout
montages
considerable
diversity
suggestion
folders
suggestion
interested
standard
EEG
sensor
positions
spherical
head
model
point
reader
.lout
short
intro
good
suggestion
coord_frame
transformation
native
mne
head
MRI
coord_frame
trans
_
=
_get_trans
trans
coord_frame
allow_none=True
suggestion
convert
head
positions
>
coord_frame
MRI
pos
=
apply_trans
trans
pos
suggestion
plot
Nutmeg
style
suggestion
src=vol_src
mode='nearest
raw
traces
example
fsaverage
suggestion
standard
fsaverage
volume
source
space
fetch_fsaverage
subjects_dir=subjects_dir
necessary
fname_src
=
op.join
subjects_dir
'fsaverage
'bem
'fsaverage-vol-5-src.fif
vol_src
=
mne.read_source_spaces
fname_src
suggestion
contacts
FreeSurfer
surface
RAS
MRI
coordinate
system
subject
mind
special
MNI
space
example
sample
fsaverage
way
ECoG
example
ECoG
data
subject
space
surface
sEEG
example
sEEG
data
MNI
space
volume
people
ECoG/sEEG
x
x
surf/vol
parts
tutorials
narrative
docs
examples
something
example
sEEG
data
channel
locations
MNI
space
projection
volume
example
ECoG
data
channel
locations
subject-specific
MRI
projection
surface
see
ref
tut-working-with-ecog
similar
list+ref
separate
section
rendered
doc
suggestion
Plot
source
brain
region
visualization
Delete
mention
difference
top
Can
blank
line
necessary
spaces
formatting
https
//7471-1301584-gh.circle-artifacts.com/0/HTML/html/auto_examples/preprocessing/plot_ica_comparison.html
Remove
blank
line
Extended
Infomax
capital
Infomax
space
algorithm
>
parameter
[
]
_
more
information
References
section
bottom
paper
preprint
okay
Probably
ICA
same
tradeoffs
PR
comments
i.e
something
equivalent
convergence
behavior
tolerance
square
equal
picard
stable
double-backticks
names
comment
ref
warnings
simple
assert
len
w
other
warnings
short
comment
assert
str
@
agramfort
work
same
test_dics
_caller
event_nums
=
events
[
events
[
]
return_index=True
]
]
iterate
e
event_nums
conditional
int
comment
type
event_desc
list
dict
callable
None
event_desc
None
planar
gradiometers
gradients
latitude
longitude
flatten
manifold
span
magnetometer
radial
gradiometers
gradients
Cartesian
coordinate
system
visualization
topoplot
plot
gradiometer
data
arrowmap
topoplot
time
maximum
sensor
space
activity
plot_arrowmap
evoked_grad.data
[
info_from=evoked_grad.info
info_to=evoked_mag.info
Vectorview
system
perform
sparse
spatial
sampling
magnetic
field
data
Vectorview
high
density
CTF
system
info_to
visualization
plot
gradiometer
data
arrowmap
topoplot
time
maximum
sensor
space
activity
path
=
bst_raw.data_path
raw_fname
=
path
+
'/MEG/bst_raw/
\
'subj001_somatosensory_20111109_01_AUX-f_raw.fif'
raw_ctf
=
mne.io.read_raw_fif
raw_fname
preload=True
meg=True
ref_meg=False
plot_arrowmap
evoked_grad.data
[
info_from=evoked_grad.info
info_to=raw_ctf.info
scale=2e-10
mapping
necessary
first
place
paper
possible
little
bit
method
few
lines
np.abs
evoked.data
.mean
axis=0
.argmax
maximum
time
*
*
actual
*
*
current
flow
activations
arrow
maps
top
topoplot
arrows
estimation
current
flow
MEG
sensors
ms
time
maximum
sensor
space
activity
tricky
one
question
https
//github.com/mne-tools/mne-python/pull/5574
issuecomment-429533658
line
backward
compatibility
PR
right
afterwards
open
bug
repord
line
tests
_synthetize_stim_ch
events
same
file
type
EDF
stores
extra
sample
case
kind
strange
page
visualization
methods
raw
container
page
Sure
details
plot_sensor_locations
small
summuary
plot
good
way
page
raw
visualizing
page
page
entire
page
plots
plots
start
reading
hypothetical
workflow
speech
speech.T
alpha=1
default
explicit
Ridge
tr
tt
=
>
train
test
+1
separate
PR
cv
squeeze
unnecessary
layout
vectorview
Y
_
=
raw
[
]
add
coments
Average
cv
splits
comment
good
way
Many
users
down
parameter
re
input
shape
previous
iteration
PR
people
explicit
sklearn
API
standard
MNE
input
shape
re
CV
same
point
last
API
CV
etc
object
pretty
sure
folks
complex
CV
object
coefficients
linear
coefficients
beta
values
lag
=
>
raw
[
]
]
[
>
raw
[
:800
]
]
.T
clickable
links
//journal.frontiersin.org/article/10.3389/fnhum.2016.00604/full
F1
http
//journal.frontiersin.org/article/10.3389/fnhum.2016.00604/full
F2
mon
=
>
%
s
%
%
ii
n_splits
n_splits
good
catch
mean_scores
legend
plot
hackish
favor
pick_channels
method
Montage
object
ya
way
selection
such
method
exists
Future
PR
issue
Ah
good
point
coefficients
worth
modifications
use-case
work
pitfalls
next
push
computation
data
features
low-frequency
nature
squeeze
samples
standard
sklearn
feature
right
rst
links
noqa
end
link
OK
doc
https
//3444-1301584-gh.circle-artifacts.com/0/home/ubuntu/mne-python/doc/_build/html/auto_examples/decoding/plot_receptive_field.html
investigate-model-coefficients
Nah
idiot
first
time
comment
rf.mask_pred
mean_coefs
dashes
section
heading
good
https
//3441-1301584-gh.circle-artifacts.com/0/home/ubuntu/mne-python/doc/_build/html/auto_examples/decoding/plot_receptive_field.html
re-order
imports
fit
folds
>
splits
samples
standard
sklearn
>
model
selection
/
GridSearchCV
API
rf
=
ReceptiveField
RidgeCV
noqa
E501
sklearn
uses
param
score
grep
scorer=
returns
nothing
sklearn
code
base
data
standard
EEG
channels
form
layout
layout.pos
end
script
best
way
API
way
order
future
upfirdn
behavior
n_channels
variable
Just
inline
blah
blah
figure
<
http
>
noqa
blah
figure
<
http
noqa
channels
Ridge
multiple
predictions
rf.score
method
educational
purpose
@
Eric89GXL
matlab
same
API
https
//fr.mathworks.com/help/signal/ref/resample.html
good
sign
comment
dimensionality
coef_
bit
lengthy
explanation
model
selection
/
GridSearchCV
API
max_coef
=
mean_coefs.max
abs
necessary
ax.pcolormesh
vmin=-max_coef
vmax=max_coef
optional
arguments
auto
refers
markdown
[
figure
]
http
//journal.frontiersin.org/article/10.3389/fnhum.2016.00604/full
F1
noqa
order
fact
URLs
much
space
time
next
push
LMK
mind
@
choldgraf
free
resample
up=down=1
defaults
down=n_decim
topomap
plotters
able
use
channel
positions
evoked.plot_topomap
something
case
PR
Eric89GXL
API
resample
mne.filter.resample
raw
/
n_decim
npad='auto
down=1
default
Okay
time
silly
work
fold-in
method
link
..
_figure
http
//
topmost
string
block
*
string
termination
noqa
E501
figure
_
talk
bit
design
choice
years
]
https
//github.com/mne-tools/mne-python/pull/126
issuecomment-9003727
idea
polyphase
available
[
]
https
//github.com/scipy/scipy/pull/5749
up=down=1
defaults
fine
worth
polyphase
mind
meantime
cleanest
thing
resample
data
down=n_decim
resample
data
decim
=
Y.T
readable
array
number
inside
clearer
]
ReceptiveField
coefficients
shape
n_outputs
n_features
n_lags
n_features
dimension
]
comment
effect
one
vmax/vmin
asymmetry
pcolormesh
instances
-.180
tuples
lists
shape
same
use
single
return
function
attribute
estimator_
case
attribute
YAGNI
check
sklearn.metrics.scorer
import
=
check_scoring
self.base_estimator
same
comment
init
parameter
steps
objects
hood
point
public-facing
API
sklearn
style
add
check
X.ndim
tutorial
well-behaved
machine
learning-y
metric
r
ok
only
randomness
noise
input
data
enough
reason
rng
happy
random.randn
continuum
values
curve
ax.plot
marker=
o
better
n_seconds
variable
n_times_sec
slice
squeeze
conversation
w/
Frederic
other
day
pros
cons
sprint
examples
future
tuple
len_epochs
=
>
r
chance
level
simpler
more
information
r²
strong
opinion
necessary
https
//3441-1301584-gh.circle-artifacts.com/0/home/ubuntu/mne-python/doc/_build/html/auto_tutorials/plot_receptive_field.html
zeros
blue
clim
symmetric
comment
magic
name
truncation
log
overlaps
assert
pytest
context
channels
single
go
ie
def
test_duplicate_channel_labels_edf
Test
reading
edf
file
duplicate
channel
names
EXPECTED_CHANNEL_NAMES
=
[
F1-Ref-0
F2-Ref
F1-Ref-1
]
pytest.warns
match='Channel
names
unique
raw
=
read_raw_edf
edf_with_duplicated_channels_path
raw.ch_names
==
EXPECTED_CHANNEL_NAMES
data
need
comment
NICE_NAME
=
constant
top
function
BTW
@
cbrnr
@
larsoner
data
Probabilistic
prediction
performance
speed
data
time
interval
signal
solver
big
diff
example
manual
labels
]
*
+
[
'face
]
+
[
]
*
+
[
]
+
[
]
*
]
ax.set_ytickslabel
labels
speed
comment
use
time-average
50-300
ms
interval
one
full
multinomial
regressoin
model
cm
=
>
confusion
oct
old
code
ssp_ecg_eog
output
compute_proj_eog
comment
thas
stc.sum
same
topo
choice
regularization
Please
>
Well
first
sentence
1e-12
better
threshold
double
precision
eigenvalue
spectra
1e-6
1e-12
better
choice
np.diag
advantage
equivalent
broadcasting
bonus
points
X
[
]
case
able
computation
Uc
[
]
Uc
lead
fields
point
1e-12
better
threshold
double
precision
eigenvalue
spectra
1e-6
1e-12
better
choice
low
test
super
low
same
line
eigenvalue
spectra
safe
1e-12
good
check
Can
comment
definition
nasion/lpa/rpa
spherical
coords
next
time
example
different
sidebar
title
EEGLAB
users
something
current
docstring
time
sentence
docstring
documents
dipole
directions
plot_trans
src
argument
work
more
localization
least
case
accurate
geometry
+
coreg
[
problem
better
way
]
http
//onlinelibrary.wiley.com/wol1/doi/10.1002/hbm.20155/full
good
loose
lh
[
]
lh
[
]
.astype
bool
unrestricted
free
make_inverse_operator
link
Same
comment
doc
template
sure
docstring
raw.plot_psd
bit
src_ind
src_sel
ind
=
==
[
]
]
ind
[
hemi_ind
]
[
ind
]
+=
data
[
src_ind
]
duplicates.append
src_ind
data
nice
non-obvious
behaviors
equivalent
Did
comment
R
X
C
cont
inputs
F
cont
gemm
gemm2
case
same
dtypes
FORTRAN
flag
true
inputs
suggestion
suggestion
gemm
gemm2
comment
nice
refactor
dictionary
python
coefficients
most_probable
try
coefficient
=
coefficients
ndim
]
[
method
]
KeyError
raise
ValueError
Method
method
thermal_speed
dict-indexing
steps
exceptions
V
=
np.sqrt
coefficient
*
k_B
*
T
/
m
dictionary
function
unnoticeable
amount
time
call
Oh
wow
Awesome
https
//2687-46810954-gh.circle-artifacts.com/0/root/project/docs/_build/html/api/plasmapy.physics.parameters.gyrofrequency.html
highlight=gyrofrequency
Parameters
heading
suggestion
Additional
parameters
course
Parameters
let
parsing
suggestion
ω
=
frequencies
*
np.pi
*
u.rad
.to
u.rad
/
u.s
kind
unicode
character
Python
smile_cat
Could
[
f-string
]
https
//realpython.com/python-f-strings/
suggestion
Calculate
bremsstrahlung
power
spectral
density
several
steps
hours
duolingo
good
use
Minor
edit
requiremnets
requirements
suggestion
Use
passing
ion
species
Particle
suggestion
Calculate
longitudinal
dielectric
function
Great
code
exception
plasma
frequency
numeric
constant
hard-coded
cleaner
variable
naming
smile
good
ideas
relative
newbie
theory
same
http
//docs.plasmapy.org/en/latest/api/plasmapy.formulary.dispersionfunction.plasma_dispersion_func.html
plasmapy.formulary.dispersionfunction.plasma_dispersion_func
Comments
tend
variable
names
suggestion
scattering_angle
=
np.arccos
np.dot
probe_n
scatter_n
k
=
np.sqrt
ks
*
*
+
kl
*
*
ks
*
kl
*
np.cos
scattering_angle
Eq
Sheffield
variable
single
expression
worried
line
length
fine
full
Unicode
suggestion
scattering_φ
=
np.arccos
np.dot
probe_n
scatter_n
k
=
np.sqrt
ks
*
*
+
kl
*
*
ks
*
kl
*
np.cos
scattering_φ
Eq
Sheffield
case
_param_names
class
attribute
same
instances
true
class
suggestion
LaTeX
friendly
representation
fit
function
suggestion
scipy.optimize.curve_fit
suggestion
Test
AbstractFitFunction
abstract
methods
long
run
test
suggestion
Test
AbstractFitFunction
methods
attributes
one-line
docstrings
tests
tests
few
months
fine
branch
PR
master
branch
naming
convention
bit
vague
something
https
//github.com/PlasmaPy/PlasmaPy/pull/919
discussion_r504986757
module
plasmapy.test.helpers.failures
something
>
Error
<
something
>
Failure
failure
error
reference
pytest.fail
>
>
>
>
>
pytest.fail
>
instance
>
>
explicit
failure
route
plasmapy.fail
version
[
pytest.fail
]
https
//docs.pytest.org/en/stable/_modules/_pytest/outcomes.html
fail
custom
failures
__all__
exceptions
Same
above
comment
Same
comment
exception
errors
WarnsError
everything
second
plot
theoretical
curve
suggestion
plt.plot
n_e
formulary.plasma_frequency
n_e
labels
scatter
plot
suggestion
plt.scatter
n_e
formulary.plasma_frequency
n_e
label=
7-X
prints
less
clutter
code
output
new
dependency
snakemake-wrapper-utils
version
wrapper
yesterday
afraid
master
conflicts
Sorry
inconvenient
timing
great
wrapper
BCF
IO
snpeff
wrapper
https
//github.com/snakemake/snakemake-wrappers/blob/master/bio/snpeff/wrapper.py
L14
Please
f
syntax
Snakemake
Python
shell
local
variables
necessary
Does
callpeak
output
files
same
name
output
directory
out_dir
shell-command
matter
terms
real
consequences
little
bit
least
accurate
name
object
body
recursive
function
ignorenames
generic
name
specific
purpose
general
context
localnames
Please
type
annotation
comment
purpose
attribute
obsolete
unused
suggestion
role
comment
string-like
thing
regexps
Typo
DESCRIBE
Let
debug
code
fragile
check
simple
regexp
module\s+\w+\s+
con
gen_meta_grammars
main
con.close
block
*
Outdated
comment
optional
typo
advantage
std
namespace
separate
schema
elprans
different
schema
name
edgedb
internal
structures
functions
standard
library
separate
schema
reason
simple
dumps
logical
replication
upgrades
etc
simpler
separate
system
structures
user-defined
structures
edgedbstd
standard
library
internal
helpers
edgedbinstdata
unique
instance
data
present
edgedbpub
user
data
Please
comment
GC
comment
UNION
approach
highlighter
>
Ditto
easy
array
literal
handler
commented
code
Comments
type
attribute
Please
review
comment
Pls
comment
formula
Right
comment
code
callback
approach
__all__
=
'xfail
file
comment
perf
closures
toplevel
funcs
functools.partial
explicit
ordering
favor
topological
sorting
diff
ordering.py
explicit
order
parameter
fit
records
None
true
algorithms
optional
e.g
FM
XGBoost
algorithm
dependent
lda.record_set
numpy
arrays
binary
files
respect
other
comment
from_s3
call
__dict__
class
attribute
class
method
instance
method
Might
comment
briefly
regex
internal
resources
github
longer
spaces
inline
comment
noqa
Add
types
docstrings
comment
better
ValueError
model
other
parameters
image
role
self.model
vpc_config
.deploy
same
enable_network_isolation
difference
private
public
model_data_prefix
possible
local
files
Python
SDK
care
local
model
files
S3
paths
S3Uploader
https
//github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/s3.py
L37
possible
MultiDataModel
Model
images
roles
consequence
case
nit-
[
pep257
]
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
line
blank
line
body
detail
necessary
tuples
tuples
more
value
breaking
change
good
fast
test
more
test
cases
test
local
mode
timeouts
global
variables
'repo
file
names
repo/file
changes
actual
code
changes
personal
preference
string
'SomethingInvalid
comment
seeing
better
list
namespaces
S3_INPUT
[
BASE_S3_INPUT
]
little
unintuitive
own
charactors
>
characters
XGBOOST_SUPPORTED_VERSIONS
get_image_uri
iirc
tensorflow
people
TF
serializers/deserializers
library
part
old
change
fabric
part
test
scope
request
bounds
docker-compose
requests
*
https
//github.com/aws/sagemaker-python-sdk/pull/533
*
https
//github.com/aws/sagemaker-python-sdk/pull/538
Very
nice
comments
Minor
]
*
suggestion
Validate
file
directory
PR
need
disable
suggestion
latest
registries
py_versions
repository
values
comment
possible
docstring
little
bit
function
while
grammar
typo
many
steps
learning
rate
something
lower
number
steps
comment
role
Vindex
python2
tests
missed
arguments
super
python3
tests
mystery
everything
ok
local
machine
reason
Thanks
batch_shape
predictors
Could
batch_shape
cutpoints
parameters
cutpoints.shape
==
batch_shape
+
event_shape
predictors.shape
==
batch_shape
event_shape
=
cutpoints.shape
[
-1
]
batch_shape
empty
parameters
[
MVN
implementation
]
https
//github.com/pytorch/pytorch/blob/master/torch/distributions/multivariate_normal.py
L130
p_shape
=
q.shape
[
-1
]
+
q.shape
[
-1
]
+
case
predictor.shape
=
cutpoints.shape
=
ordered_vector
[
constraint
]
https
//github.com/pyro-ppl/pyro/blob/dev/pyro/distributions/constraints.py
arg_constraints
constraint
cutpoints
constraints.ordered_vector
same
device
dtype
q
.view
favor
.reshape
.unsqueeze
safer
q
=
torch.sigmoid
cutpoints
predictor.unsqueeze
-1
info_vec
values
missing
term
logsumexp
change
Thanks
stefanwebb
group
sites
frame
boundary
super-exponential
growth
exponential
growth
B
=
B
/
nit
comment
cholesky
error
retry
smaller
tail
part
B.
i
range
num_attempts
nit
docstring
sound
entries
larger
R0
....
Could
links
stable
release
e.g
http
//docs.pyro.ai/en/stable/parameters.html
typo
distriburtions
transition_logits.dim
transition_logits
observation_dist
model
>
self.model
gradient
callback
sort-of-complex
training
mechanism
necessary
decent
performance
preferable
Done
@
fritzo
better
way
use
PyroModule
maybes
comments
nit
comment
badge
removal
bit
lines
better
way
cause
TraceMeanField_ELBO
missed
opportunity
KL
due
pattern
Delta
distributions
single
Normal
distribution
problem
comment
>
Note
easy
guide
auto
guide
cases
KL
divergences
ELBO
guide
model
sample
sites
Delta
distribution
part
expm1
NumPyro
warning
error
value
out-of-support
log_prob
-inf
values
Pyro
cc
@
neerajprad
nit
assignment
comment
typo
S_logp
>
I_logp
nit
i
reparameterization
lossless/does
unstable
reference
>
categorical
Bernoulli
distribution
prob
eps
1-eps
comment
hook_fn
i
important
point
great
head-to-head
comparison
nit
=
>
nit
filtering
typo
Bernoullis
linear
spline
way
reset_parameters
prefix
private
methods
underscore
comment
Pyro
special
care
public
interface
changes
backwards
compatible
easy
way
publish
methods
Python
convention
privacy
leading
underscores
Pyro
stability
methods
[
RELEASE_MANAGEMENT.md
]
https
//github.com/pyro-ppl/pyro/blob/dev/RELEASE-MANAGEMENT.md
method
EXPERIMENTAL
docstring
ditto
other
method
file
change
move
nit
need
todo
uncommented
code
todo
comments
own
voice
Can
following
license
header
comment
Copyright
Contributors
Pyro
project
Copyright
c
Hadi
M.
Dolatabadi
Sarah
Erfani
Christopher
Leckie
Copyright
c
Conor
Durkan
Artur
Bekasov
Iain
Murray
George
Papamakarios
Copyright
c
Tony
Duan
SPDX-License-Identifier
MIT
naming
convention
pyro.ops.spline
pyro.ops.ode
low
level
numerics
pyro.ops
nit
docstrings
columns
important
users
help
Spline
jupyter
notebook
fits
window
dostrings
Pyro
spaces
character
lint
Btw
lint
x.new_zeros
[
-1
]
x.dtype
single
flow
multiple
reflections
quantity
comment
shape
rho
Copy
draft
tutorial
file
comments
API
continuous-time
GP
models
best
way
docstring
base
class
predicted_covar2
bit
tricky
monotonicity
test
correct
more
tests
typo
epmhasize
assert
popped
site
name
same
name
argument
list
list
..
direction
x-z
data
dependency
site
due
handler
problematic
'poutine.condition
PR
Ellipsis
special
way
batch
dims
event
dims
indexed
tensor
x
meaning
integer
indexing
named-vs-positional
pattern
Funsor
NEP
semantics
x
dims
event
dims
Ellipsis
batch
shape
delimiter
middle
explanation
docstring
use
cases
minimal
useful
unit
code
way
arange
PR
hand
[
scheduler
]
https
//pytorch.org/docs/stable/optim.html
highlight=scheduler
torch.optim.lr_scheduler.MultiStepLR
@
fehiepsi
test
@
neerajprad
look
reasonable
interface
subsample
sites
non-empty
cond_indep_stack
try-catch
block
sample
sites
something
diff
def
_adjust_to_data
trace
data_trace
name
site
list
trace.nodes.items
+
name
site
trace.iter_stochastic_nodes
Adjust
subsample
sites
site_is_subsample
site
site
fn
]
=
[
name
]
[
fn
site
value
=
[
name
]
[
value
Adjust
sites
independent
stacks
try
site
cond_indep_stack
=
[
name
]
[
cond_indep_stack
site
fn
]
=
[
name
]
[
fn
cis
site
[
cond_indep_stack
]
Select
random
sub-indices
values
independent
stacks
dependence
indexes
data
prediction
data
site_is_subsample
site
batch_dim
=
batch_dim
=
site
fn
]
subidxs
=
torch.randint
site
[
'value
]
.size
batch_dim
device=site
value
]
.device
site
value
=
site
[
value
.index_select
batch_dim
subidxs
KeyError
pass
+
site
[
cond_indep_stack
=
[
name
]
[
cond_indep_stack
+
site
[
fn
=
[
name
]
[
fn
+
cis
site
[
cond_indep_stack
]
+
Select
random
sub-indices
values
independent
stacks
+
dependence
indexes
data
prediction
data
batch_dim
=
cis.dim
site
fn
]
.event_dim
+
=
torch.randint
site
[
'value
]
.size
batch_dim
+
value
]
.device
site
[
value
=
site
[
value
.index_select
batch_dim
subidxs
use
cases
mistaken
site_is_subsample
True
@
fehiepsi
Feel
free
branc
smile
Distribution
case
release
subtle
untested
example
variational
intervention
case
py
poutine.do
poutine.trace
tr
guide
poutine.replay
trace=tr.trace
model
samples
distributional
intervention
guide
model
group
issues
test
reference
see
https
//docs.python.org/3/howto/descriptor.html
something
wrong
comments
data
structures
neighbors
few
others
i
comment
ref
]
use
language
surrogate
loss
function
section
Hmm
poutine.block
case
py
my_module.requires_grad_
False
my_module
*
skips
pyro.module
interface
fact
PyroParam
poutine
aware
ConstrainedParam
use
case
PyroSample
attributes
params
useful
attributes
sample
statements
most
models
limited
scope
useful
biggest
difference
posterior
samples
trained
module
Tanh
transform
upstream
https
//pytorch.org/docs/stable/distributions.html
torch.distributions.transforms.TanhTransform
PyTorch
Pyro
version
dependency
upstream
note
TODO
move
upstream
short-term
implementations
@
fehiepsi
easy
way
@
martinjankowiak
points
most
interesting
datasets
stability
FIXME
warning
docstring
validation
check
future
stability
Ready
review
rtype
RandomVariable
torch.nn.ParameterDict
]
https
//pytorch.org/docs/stable/nn.html
torch.nn.ParameterDict
available
N_seq
independent_priors
stale
comment
romain-lopez
i
simple
@
romain-lopez
logic
reasonable
context
i
big
scanpy
objects
work
particular
adata
UMAP
plots
scanpy
TraceEnum_ELBO
Trace_ELBO
@
romain-lopez
i
numerical
instabilities
detail
major
sources
instability
experiments
py
description=
single-cell
ANnotation
Variational
Inference
nit
comment
punctuation
>
note
softplus
stable
normalizer
/
q
z|x
p
x|z
normalizer
integral
p
x|z
dz
bit
strange
bit
wary
tuples
functions
scalars
changes
PR
minimal
sure
Basically
_sleep-phi_
processing
order
_wake-
*
_
unconditioned
model
trace
guide
guide
observation
variable
things
replay
same
procedure
CSIS
use
keyword
observations
observations
guide
cleaner
handle
arbitrary
tuple
namedtuple
objects
isinstance
loss
tuple
namedtuple
return
type
loss
torch_item
loss
return
torch_item
loss
move
logic
torch_item
torch_isnan
svi.py
unmodified
WDYT
fill
training
conjugate
nit
pyro.infer.mcmc.api
>
pyro.infer.mcmc.api.MCMC
issue
PR
little
safer
commit
release
worried
branch
branch
changes
able
bisect
alternatives
pinning
current
master
pinning
tag
funsor
repo
pyro-1.4.0
pyro-1.4.1-pre0
tags
funsor
pyro
relevant
PR
HMC
case
able
samples
base
distribution
Normal
transformed
distribution
log
density
samples
HMC
delta
function
IIUC
sample
infinite
energy
Just
FYI
case
different
separate
solutions
non-centered
parametrization
MCMC
case
time
nice
default
guide
MAP
arg
random
variables
delta
variational
distributions
process
nit
b
monotonicity
init_loc_fn
init_loc_fn
init_to_feasible
raise
NotImplementedError
TODO
follow-up
PR
happy
support
second
thought
easiest
init_loc_fn
PR
py
name
site
self.prototype_trace.iter_stochastic_nodes
shapes
unconstrained
values
shapes
constrained
values
constrained_shape
site
value
.shape
=
biject_to
site
fn
]
.support
.inv
site
value
.detach
[
name
]
=
init_loc.shape
Collect
independence
contexts
self._cond_indep_stacks
name
]
=
site
[
cond_indep_stack
init_scale
=
torch.full_like
init_loc
self._init_scale
_deep_setattr
self.locs
name
nn.Parameter
init_loc
self.scales
name
PyroParam
init_scale
constraints.positive
__init__
rid
xfail_if_not_implemented
s
tests
necessary
h2o
API
load
path
file
afraid
cases
No
need
anything
quick
note
implementation
micro-batch
disabled
first
item
micro-batching
better
way
library
batch
processing
API
batch
input
data
step
gap
loop
item
array
user
inference
API
micro-batching
code
use
cases
e.g
single
item
micro
batching
src_text
=
parsed_json.get
text
cool
great
example
string
pretrained
model
@
code
problematic
bundled
bentoml
sagemaker
deployment
update
comment
same
update
comment
_is_bentoml_in_develop_mode
comment
BentoML
developer
BentoService
custom
branches
BentoML
library
BentoML
module
pip
install
editable
reason
*
setup.sh
*
Use
python
docstring
def
install_serverless_package
Install
serverless
package
BentoML
home
directory
onnx
pip_dependencies
python
try
import
onnx
ImportError
return
_ExportedOnnxModelArtifact
isinstance
onnx.ModelProto
return
_OnnxModelArtifactWrapper
return
_ExportedOnnxModelArtifact
rename
onnxruntime
backend
SUPPORTED_ONNX_BACKEND
check
self._model
onnx.ModelProto
isinstance
self._model
onnx.ModelProto
return
_OnnxModelArtifactWrapper
return
_ExportedOnnxModelArtifact
inline
comment
onnx
file
nit
open
template_file_path
sure
easy
implementation
samtranslator.translator.managed_policy_translator
import
ManagedPolicyLoader
botocore.exceptions
NoCredentialsError
.lib.exceptions
InvalidSamDocumentException
.lib.sam_template_validator
import
SamTemplateValidator
sam_template
=
_read_sam_file
template
iam_client
=
boto3.client
validator
=
SamTemplateValidator
sam_template
ManagedPolicyLoader
iam_client
try
validator.is_valid
InvalidSamDocumentException
e
something
NoCredentialsError
e
something
upload_bentoservice_artifacts_to_s3
move
time.sleep
check_interval
block
container
state
API
server
frontend
server
gunicorn
server
responses
case
test
code
sending
requests
wait
if/else
naming
orm
object
protobuf
object
use
previous_deployment
=
self.deployment_store.get
@
yubozhao
has_bentoml_bundle
related
code
safe
import
line
safe
python
create_bucket_configuration
=
'LocationConstraint
region
region
east-1
s3_client.create_bucket
Bucket=bucket_name
CreateBucketConfiguration=create_bucket_configuration
user
defines
API
'hello
right
inline
comments
variables
inline
comments
variables
notes
case
ImportError
notes
uncomment
let
1-second
timeout
case
long
slow/limited
internet
connection
try/catch
deployment
status
platform
archive_path
region
stage
delete
deployment
user
sense
path
archive
service
name
archive
path
'service-name
internal
concept
anything
user
curious
difference
=
subprocess.Popen
stdout
stderr
=
p.communicate
more
common
same
warning
message
previous
comment
exception
inline
comment
ClientError
Code
target
object
'head_object
TODO
validation
apply
deployment
Check
[
similar
test
implementation
]
https
//github.com/bentoml/BentoML/blob/5450d6cddacc04e37be4daaedb4b419c65c821cc/tests/bento_service_examples/transformer_gpt_example.py
[
test
]
https
//github.com/bentoml/BentoML/blob/5450d6cddacc04e37be4daaedb4b419c65c821cc/tests/integration/test_transformers_model_artifact.py
something
parsed_json
string
temporary
file
need
seek
instinct
property
bento_service
e.g
@
property
def
static_files
Returns
static
files
present
Raises
AttributeError
static
files
return
maintainers
more
Motivation
underscore-prefixed
attributes
private
sense
access
Could
inline
comments
url_rule
code
clear
comment
deployments
field
database
bento_pb.uri.type
=
repository_pb2.BentoUri.LOCAL
one
test_deployment_pb.spec.operator
=
deployment_pb2.DeploymentSpec.AWS_SAGEMAKER
nit
s/fake_yatai_service/yatai_service_mock
commented
code
suggestion
FIXME
gevent
bug
busy
loop
suggestion
Test
credential
API
authentication
first
sync
displayname
instance
User
able
displayname
events
available
_validate_userid_signature
http
request
above
correct
whole
test
Mine
transaction
block
number
receipt
wait
transaction
127th
block
query
*
previous
block
*
first
statement
other
comment
transaction
block
transaction
block
corollaries
block
transaction
block
Transactions
blocks
younger
pruning
block
transport
alarm
task
first
run
transport
alarm
task
transfer
>
transfer
initiators
backing
transfer
expiraton
arbitrary
*
mediator
*
*
mediator
>
*
mediator
transfer
>
transfer
suggestion
Currently
only
case
initiators
change
raiden-contracts
link
commit
use
>
use
@
nlsdfnbch
sufficient
suggestion
same
underlying
tracer
false
positives
switch
rename
UPGRADES_MAP
mapping
comment
mapping
typo
latest
>
[
last
|
latest
]
result
put
register_chunk
data
plasma_store
GC
ObjectType
scalar
tensor
on_input_modify
..
DataFrame
type
test
changes
test_api
costly
comment
hard
means
TODO
float32
bit
duplication
first
row
null
data
data
types
Same
comments
need
meta
chunk
Add
comment
_col_names
tuple
consistent
pandas
Cold
Cathode
component
Pirani
cleanest
prefix
prefix
able
info
comment
Probably
docstring
value
comments
repr
good
catch
pre-existing
bug
default
values
*
strongly-typed
config
object
issue
comment
issue
necessary
comment
i
%
certain
dicts
abc
mind
abcs
much
all-or-nothing
derived
classes
*
*
methods
@
abstractmethod
base
class
comments
methods
RunStorageMode.S3
SparkDataFrameS3Storage
RunStorageMode.FILESYSTEM
SparkDataFrameFilesystemStorage
helpful
comment
black
py27-compatible
formatting
below
invocation
comma
*
*
check.opt_dict_param
black
supports
multiple
python
versions
__future__
import
print_function
https
//github.com/ambv/black/issues/768
little
name
method
return
transform
function
transform
function
let
comment
HACK
dagit
process
reload
pitfall
source
regex
sense
dagster-azure
PR
PR
TODOs
sc
issue
object
aware
Repository
Pipeline
issue
comment
Thanks
little
gnomic
nice
comment
usage
diff
clear
someone
new
code
type
hints
little
weird
type_of
'InvalidSubplanExecutionError
'ExecutionStep
step=type_of
'ExecutionStep
step_of
invalid_subplan_error
process.exitcode
something
sys.platform
return
os.path.join
tempfile.gettempdir
'runs
bit
concerned
late
import
missing
dependency
failures
solution
same
problem
executor
👍
explanatory
comment
plz
everything
play
Phần
chính
của
code
để
trong
một
hàm
main
chẳng
hạn
Sau
đó
__name__
main
main
Không
nên
để
quả
nhiều
code
ở
global
scope
như
thế
này
Những
biến
global
có
thể
ảnh
hưởng
tới
các
biến
trong
từng
hàm
nhỏ
gây
ra
những
lỗi
khó
debug
được
Có
biến
global
rồi
sao
lại
viết
lại
như
thế
dễ
có
bug
nếu
có
typos
Viết
hoa
toàn
bộ
chứ
em
suggestion
Add
html
code
new
page
part
thêm
comment
giải
thích
dòng
này
được
không
operation
expressible
code
code
good
comments
redundant
Comment
commit
comment
HTTPError
base
classes
instance
class
present
map
util
function
whole
logic
function
params
returns
vehicle.get_ids
veh_id
None
veh_id
list
veh_id
list
same
comment
lines
Plan
folder
consisting
energy
models
i
name
enermod
section
idea
folder
end
function
def
lines
comment
misleading
policy
graph
V_ENTER
reason
magic
number
least
comment
argument
docstring
comment
ES
issue
Same
other
TODOs/FIXME
particular
local
observability
good
first
issue
Comment
essential
cases
attribute
pipeline_params
instance
ahh
type-hooks
great
documentation
early
exit
response.ok
return
early
exit
nothing
nit
json=
i
original
code
passing-through
check_http_code
argument
self._post
shorten
fetch
appropriate
term
code
repo.tree
happy
name
irrelevant
particluar
code
existence
sub-module
path
implementation
detail
'_serialise_and_path_tree'-function
>
ls-tree
tree
turn
sequence
trees
blobs
submodule
worth-while
mentioning
reference
please
caller
function
'post_to_slack
name
dump
comment
sleep-time
+
retries-amount
metadata
different
comment
yesterday
comment
margin
errors
suggestion
JSONDecodeError
resource
someone
wait
pass
other
errors
sure
connection
errors
fine
warning
bug
previous
job
lock
coupling
maximum
retries
maximum
waiting
time
places
ideal
>
consider
retries
comment
possible
pinning
comment
w/o
pin
update
time
triggering
last-tried
timestamp
+
sleep-time
case
anything
last
time
update
sleep-time
last-time-of-update
+
sleep-time
>
something
wrong
_latest_
brief
comment
implementation
idea
allow
stale
lock
branch
/
comment
dataclass
comment
human-friendly
comment
such
username
obvious
stmt
such
please
~5m
idea
dead
code
+
add
TODO
resource-upgrades
data-class
return-type
OR
to_version
=
str
use
type-hint
XXX
valid
imo
nit
coulod
brief
comment
ok
ethanbao
Python
optional
parameters
constructor
Luke
Oh
Misunderstood
comment
right
Fixed
protobuf
objects
python
Artifact
name=
%
s_gapic
%
lang
Artifact.Language.Value
point
kind
error
deep
merge
dict.extend
familiar
python
protobuf
API
Java
Builder
class
canonical
way
python
protobuf
Luke
comment
Google
style
guide
https
//google.github.io/styleguide/pyguide.html
showone=Conditional_Expressions
Conditional_Expressions
unused
former
structure
lang
git_repos
common
git
repo
bit
artman
logic
langs
api-client-staging
default
new
artifact
publish
target
legacy
lang
config
git
repo
Done
Ack
follow-up
files
point
legacy_config_dict
code
main.py
rest
main2.py
file
Good
catch
Ruby
additional
step
bogus
alternate
pb2s
yard
documentation
perfect
world
protoc-docs-plugin
Ruby
protobuf
output
insertion
points
Jacob
offline
as-is
Done
comment
remote
execution
part
out
docstring
regular
comment
=
flags.image
only
reason
refactoring
PR
current
main.py
follow-up
PR
main2.py
Luke
Ethan
offline
sense
meantime
nit
unnecessary
parens
_should_
bug
REPOROOT
/toolkit
config
TOOLKIT
warning
paths
proto_path
directory
file
E.g.
https
//github.com/googleapis/googleapis/blob/master/gapic/core/artman_core.yaml
L8
nit
statement
internal
customers
v1alpha
https
//github.com/googleapis/toolkit/issues/1335
version
matcher
api-compiler
https
//github.com/googleapis/api-compiler/blob/master/src/main/java/com/google/api/tools/framework/aspects/versioning/model/ApiVersionUtil.java
L40
rightmost
occurrence
match
rare
other
package
version
regex
knowledge
transforming
people
install
transforming
artifact
time
smart
👍
line
fail
Travis
dmri
image
error
message
system
exit
Are
DICT_URL
DICT_URL
need
same
file
suggestion
fname_labelz
=
fname_initlabel
docstring
return
value
sct_apply_transfo
other
ways
e.g
memory
file
comment
status
output
big
fan
free
issue
discussion
PR
section
multiclass
segmentation
feature
flag
multiclass
segmentation
models
metadata
segmentation
user
able
feature
lot
confusion
comment
case
multi-class
segmentation
class-specific
suffixes
surprise
neural
network
models
suggestion
command-line
tool
interface
deepseg
API
segmentation
deep
learning
ivadomed
package.
module-level
docstrings
python
treats
comments
module
docstrings
s
triple-string
idiomatic
ParamDeepseg
something
suggestion
args
=
parser.parse_args
args=None
sys.argv
]
[
help
]
=
k
v
k
vars
args
v
None
separate
segmentation
param
top
level
args
input
=
args.pop
i
list_models
args.pop
'list_models
install_model
=
args.pop
'install_model
install_default_models
args.pop
'install_default_models
default
sure
None
default=param_default.keep_largest_object
extra
layer
defaults
model
metadata
user
largest
object
results
other
objects
-largest
comment
shorter
something
suggestion
help=
Keep
largest
segment
noise
users
-largest
n
n
possible
values
everything
self.param
precedence
self.metadata
None
undefined
next
option
do_process
=
param
metadata
default
False
next
expression
function
possible
values
simplification
meaning
self.metadata
metadata
None
pprint
import
pprint
def
do_process
param
metadata
default
param
True
return
True
elif
param
None
metadata
None
'keep_largest_object
self.metadata
<
=
>
metadata
None
return
metadata
default
pprint
[
param
metadata
default
>
do_process
param
metadata
default
param
[
True
False
None
]
metadata
[
True
False
None
]
default
[
True
False
]
]
truth
table
[
True
True
True
>
True
True
True
False
>
True
True
False
True
>
True
True
False
False
>
True
True
None
True
>
True
True
None
False
>
True
False
True
True
>
True
False
True
False
>
False
False
False
True
>
True
False
False
False
>
False
False
None
True
>
True
False
None
False
>
False
None
True
True
>
True
None
True
False
>
True
None
False
True
>
False
None
False
False
>
False
None
None
True
>
True
None
None
False
>
False
cases
True
True
course
logic
False
metadata
param=False
same
param=None
metadata=False
means
weird
actual
logic
def
do_process
param
metadata
default
param
True
return
True
elif
param
False
return
False
elif
param
None
metadata
None
return
metadata
default
shorter
def
do_process
param
metadata
default
param
None
return
param
metadata
None
return
metadata
default
truth
table
[
True
True
True
>
True
True
True
False
>
True
True
False
True
>
True
True
False
False
>
True
True
None
True
>
True
True
None
False
>
True
False
True
True
>
False
False
True
False
>
False
False
False
True
>
False
False
False
False
>
False
False
None
True
>
False
False
None
False
>
False
None
True
True
>
True
None
True
False
>
True
None
False
True
>
False
None
False
False
>
False
None
None
True
>
True
None
None
False
>
False
@
kousu
overkill
Class
function
nii
param
metadata
input
parameter
@
kousu
good
practice
input
variable
output
typo
suggestion
prediction
threshold
UI
scripts/sct_deepseg.py
listing
displaying
keep
file
version
def
list_models
return
name
value
name
value
MODELS.items
name
parts
fiddle
terminal
colours
expense
extra
dependency
colouration
readable
https
//pypi.org/project/colored/
simpler
data
place
suggestion
class
DeepsegModel
Metadata
deep
learning
models.
def
__init__
name
url
description
self.name
=
name
boilerplate
py3.7
@
dataclass
self.url
=
url
self.description
=
description
@
property
def
folder
return
os.path.join
'models
self.name
def
Check
model
.pt
file
SCT
directory
os.path.exists
os.path.join
self.folder
self.name
+
'.pt
\
os.path.exists
os.path.join
self.folder
self.name
+
'.json
return
True
FileNotFoundError
model
.pt
.json
files
present
basename
same
folder
name
Example
my_model/my_model.pt
my_model/my_model.json
install
Download
model
SCT
directory
param
name_model
return
NotImplementedError
MODELS
=
[
DeepsegModel
name
=
'coord-t2star
url
//osf.io/v9hs8/download
version=1
description
=
'Cord
segmentation
T2
*
contrast
DeepsegModel
name
=
'uqueensland-mice-sc
url
//osf.io/nu3ma/download
version=1
description
=
'Cord
segmentation
mouse
MRI
Data
University
Queensland
DeepsegModel
name
=
'uqueensland-mice-gm
url
//osf.io/mfxwg/download
version=1'
description
=
matter
segmentation
mouse
MRI
Data
University
Queensland
]
MODELS
=
model.name
model
model
MODELS
other
option
dictionary
case
extra
layer
class
users
import
sct.models
'mouse-mri-2
suggestion
MODELS
=
'cord-t2star
'https
//osf.io/v9hs8/download
version=1
'description
segmentation
T2
*
contrast
'uqueensland-mice-sc
'https
//osf.io/nu3ma/download
version=1
'description
segmentation
mouse
MRI
Data
University
Queensland
'uqueensland-mice-gm
'https
//osf.io/mfxwg/download
version=1
'description
matter
segmentation
mouse
MRI
Data
University
Queensland
def
folder
name
return
os.path.join
'models
name
def
name
Check
model
.pt
file
SCT
directory
os.path.exists
os.path.join
folder
name
name
+
'.pt
\
os.path.exists
os.path.join
folder
name
self.name
+
'.json
return
True
FileNotFoundError
model
.pt
.json
files
present
basename
same
folder
name
Example
my_model/my_model.pt
my_model/my_model.json
install
name
Download
model
SCT
directory
param
name_model
return
NotImplementedError
suggestion
comment
static
typing
something
class
Model
url
string
description
string
None
default
bool
=
False
pythonic
way
static
mypy
tests
issues
suggestion
output
=
sct.deepseg.core.segment_nifti
sct.__models_dir__
't2star_sc
TODO
implement
integrity
test
output
segmentation
file
exists
output
==
'sct_testing_data/t2s/t2s_seg.nii.gz'
assert
os.path.isfile
output
instinct
assert
output
==
'sct_testing_data/t2s/t2s_seg.nii.gz
actual
filename
SCT
batch-scripty
pattern
filenames
lot
important
right
suggestion
assert
'description
value
assert
value
comment
code
KeyError
comment
contradiction
code
i
~~~
input
-1
maximum
dimension
i.e
change
input
-2
maximum
dimension
minus
~~~
~~~
style
please
documentation
convention
L29-L43
Could
other
options
handles
OOV
necessary
judgment
special
judgment
implementation
[
mx.gluon.utils.split_and_load
]
https
//mxnet.apache.org/_modules/mxnet/gluon/utils.html
split_and_load
checkpoints
worker
other
workers
job
machines
machine
GPUs
rank
number
[
]
local
rank
number
[
]
rank
args.ckpt_dir
==
reminder
root
path
nit
sequential
add
mind
overflow
happens
update
docstring
update
function
exists
command
line
options
environment
variables
need
more
way
such
input
dummy
input
data
>
=0
case
src_max_len=0
error
Same
comment
please
document
input
output
data
shapes
GluonNLP
nltk
integration
tokenization
necessary
way
http
//gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html
Attaching-word-embeddings
=
versions
hope
CI
installation
problems
approach
minimum
version
requirement
nice
reference
idea
better
previous
code
single
trainer
observation
need
ctx
support
ctx
flag
arguments
https
//github.com/dmlc/gluon-nlp/blob/66e5e057347c3710eb8fa27c134a9303309e94c0/tests/test_models_bert.py
L94
model
cpu
GPU
Sure
parser
options
MXNet
check
Same
bert/run_glue.py
necessary
extra
name
fact
code
version
Let
args.X
version
X
lines
Same
bert/run_glue.py
workaround
MXNet
https
//github.com/apache/incubator-mxnet/pull/17123
available
MXNet
comment
TODO
Replace
ctx=context.Context
@
eric-haibin-lin
accumulate
ls
=
/
accumulate
bias
correction
algorithm
check
clip
performs
r1
g
r2
larger
Need
documentation
return
delete
code
nit
nice
pass-through
function
suggestion
license
Unlicense
vcpkg
license
https
//github.com/microsoft/vcpkg/blob/master/ports/cute-headers/portfile.cmake
suggestion
TODO
CMake
target
option
suggestion
del
self.settings.compiler.libcxx
del
self.settings.compiler.cppstd
suggestion
]
default
directory
leftover
pain
packaging
rofl
suggestion
def
package
self.copy
LICENSE
src=self._source_subfolder
dst=
licenses
-c
-m
'/Users/jenkins/w/cci_PR-2875
@
2/.conan/data/coin-cgl/0.60.3/_/_/build/12380cd09889cf0f93b5621cb258b79493b4c9a5/source_subfolder/Cgl/src/CglLandP/CglLandP.hpp
'/Users/jenkins/w/cci_PR-2875
@
2/.conan/data/coin-cgl/0.60.3/_/_/package/12380cd09889cf0f93b5621cb258b79493b4c9a5/include/coin/CglLandP.hpp'
Statis
default
recipes
static
suggestion
super_component
gmp
:GMP
target
different
enable_cxx
option
bit
weird
idea
suggestion
self.cpp_info.components
gmpxx
]
[
cmake_find_package
]
GMPXX
self.cpp_info.components
gmpxx
]
[
cmake_find_package_multi
]
GMPXX
suggestion
suggestion
suggestion
issue
upstream
higher
cppstd
version
https
//github.com/pboettch/json-schema-validator/issues/106
self.settings.get_safe
cppstd
tools.check_min_cppstd
cppstd
ditto
change
[
True
False
]
suggestion
TODO
Workaround
better
solution
nit
keyword
editors
such
things
discoverable
suggestion
comment
Header-only
libs
options
settings
orthogonal
suggestion
suggestion
suggestion
self.requires
suggestion
suggestion
args
=
[
]
args.extend
[
enable-shared
disable-static
]
args.extend
[
disable-shared
enable-static
]
suggestion
self._cmake
return
self._cmake
=
CMake
self._cmake.definitions
BUILD_REGRESS
]
False
self._cmake.definitions
BUILD_EXAMPLES
]
False
self._cmake.definitions
BUILD_DOC
]
False
self._cmake.definitions
ENABLE_LZMA
]
=
self.options.with_lzma
self._cmake.definitions
ENABLE_BZIP2
]
=
self.options.with_bzip2
self._cmake.definitions
ENABLE_ZSTD
]
=
self.options.with_zstd
self._cmake.definitions
ENABLE_COMMONCRYPTO
]
=
False
TODO
CommonCrypto
package
self._cmake.definitions
ENABLE_GNUTLS
]
=
False
TODO
GnuTLS
package
self._cmake.definitions
ENABLE_MBEDTLS
]
=
self._crypto
==
mbedtls
self._cmake.definitions
ENABLE_OPENSSL
]
=
self._crypto
==
openssl
self._cmake.definitions
ENABLE_WINDOWS_CRYPTO
]
=
self._crypto
==
win32
self._cmake.configure
CCI
hook
PR
add
settings
warnings
HOOK
conan-center.py
]
pre_export
WARN
[
HEADER_ONLY
NO
COPY
SOURCE
KB-H005
recipe
header
library
'settings
Please
'no_copy_source
unnecessary
copy
steps
poppler-data/0.4.9
WARN
compiler
setting
poppler-data/0.4.9
WARN
build_type
setting
poppler-data/0.4.9
WARN
compiler
setting
poppler-data/0.4.9
WARN
compiler
setting
poppler-data/0.4.9
test
package
WARN
conanfile
build
step
suggestion
tools.rmdir
self.package_folder
'share
'man
suggestion
suggestion
cmake.definitions
CMAKE_CXX_STANDARD
]
=
suggestion
autotools
msvc
canonical
name
suggestion
self.requires
zdigest
re-triggered
CI
something
more
suggestion
self.cpp_info.components
mongoc
[
cmake_find_package
]
mongoc_static
self.cpp_info.components
mongoc
[
cmake_find_package_multi
]
mongoc_static
patches
better
functionality
different
workflows
suggestion
def
source
tools.get
*
*
self.conan_data
[
sources
[
self.version
]
=
name
version
.format
name=self.name
version=self.version
os.rename
extracted_dir
self._source_subfolder
def
_patch_sources
todo
fix
//github.com/bincrafters/community/issues/995
tools.replace_in_file
self._source_subfolder
src
libmongoc
CMakeLists.txt
add_executable
mongoc-stat
PROJECT_SOURCE_DIR
/
..
/
..
/src/tools/mongoc-stat.c
add_executable
mongoc-stat
PROJECT_SOURCE_DIR
/
..
/
..
/src/tools/mongoc-stat.c
tools.replace_in_file
self._source_subfolder
src
libmongoc
CMakeLists.txt
target_link_libraries
mongoc-stat
LIBRARIES
target_link_libraries
mongoc-stat
LIBRARIES
==
tools.replace_in_file
self._source_subfolder
src
libmongoc
CMakeLists.txt
self._libressl_find_pattern
self._libressl_replacement_pattern.format
LIBRESSL_INCLUDE_DIRS=self.deps_cpp_info
[
libressl
]
.include_paths
[
]
LIBRESSL_LIBRARY_DIRS=self.deps_cpp_info
[
libressl
]
.lib_paths
[
]
def
build
self._patch_sources
=
self._configure_cmake
cmake.build
suggestion
self.cpp_info.components
bson
[
cmake_find_package
]
bson_static
self.cpp_info.components
bson
[
cmake_find_package_multi
]
bson_static
suggestion
to_replace_old_new
=
[
Fix
Snappy
old
FindSnappy
\nif
SNAPPY_INCLUDE_DIRS
new
ENABLE_SNAPPY
MATCHES
\
ON\
find_package
Snappy
REQUIRED
old
SNAPPY_LIBRARIES
new
Snappy_LIBRARIES
old
SNAPPY_INCLUDE_DIRS
new
Snappy_LIBRARIES
Fix
Openssl
old
OPENSSL_FOUND
new
OpenSSL_FOUND
old
OPENSSL_VERSION
new
OpenSSL_VERSION
old
OPENSSL_CRYPTO_LIBRARY
new
OpenSSL_Crypto_LIBS
old
OPENSSL_LIBRARIES
new
old
OPENSSL_INCLUDE_DIR
new
OpenSSL_INCLUDE_DIR
Fix
LibreSSL
old
set
SSL_LIBRARIES
-ltls
-lcrypto
new
]
old_new
to_replace_old_new
tools.replace_in_file
self._source_subfolder
src
libmongoc
CMakeLists.txt
[
old
]
[
new
]
Last
modification
libressl
build
set
SSL_LIBRARIES
-ltls
-lcrypto
mongo-c-driver
CMakeLists.txt
suggestion
FIXME
config
files
mongoc-1.0-config.cmake
bson-1.0-config.cmake
self.cpp_info.filenames
cmake_find_package
]
mongoc-1.0
conan
client
cmake_find_package
cmake_find_package_multi
generators
future
suggestion
self.settings.os
os
host
system
=the
system
libary
build
system
=the
system
library
suggestion
isWindows
share
common
parts
untested
suggestion
nested_path
facet
[
'aggregation_type
]
=
range'
field
=
facet
[
'aggregation_type
]
+
+
primary_agg
=
cls._build_nested_aggregation
range_agg
nested_path
regular
non-nested
range
field
facet
[
'aggregation_type
]
=
RANGE
field
=
facet
[
'aggregation_type
]
+
+
primary_agg
=
range_agg
aggs
[
field
]
=
AGGS
primary_agg
FILTER
facet_filters
scope
concern
dcicutils
data-driven
idea
customer/client
names
code
ticket
least
TODO
comment
controllable
other
administrative
mechanism
database
table
set
endpoints
administrators
set
allowed
things
regexp
bad
idea
regexp
such
data
NESTED
incorrect
critical
something
nested
field
terms
field_with_the_word_nested_in_it
bug
fix
permissions
check
term
intersected
permissions
null
bad
understanding
other
things
earlier
DSN
outside
wrapper
sentry-specific
stuff
own
file
minimal
intrusion
loaded
invoked
information
registry
ini
file
line
SENTRY_DSN
line
harmless
beanstalks
.ini
env
variable
empty
string
example
sentry.py
file
untested
sentry_sdk.integrations.pyramid
import
PyramidIntegration
sentry_sdk.integrations.sqlalchemy
import
SqlalchemyIntegration
init_sentry
dsn
Initialize
sentry
use
DSN
None
need
sentry
here.
dsn
sentry_sdk.init
dsn
integrations=
[
PyramidIntegration
SqlalchemyIntegration
]
environment
variable
__init__.py
.sentry
import
init_sentry
init_sentry
settings.get
None
noqa
<
reason
>
note
comment
versions
string
mapping
table
good
naive
assumption
transformation
snake
case
reasons
true
good
things
snake
case
snake
case
future
Python
computation
inline
if/elif/else
chain
course
if/else
more
stuff
assignment
res_json
=
structure
first
set
tests
matches
second
one
easier
comparison
blocks
assignments
same
value
second
time
lowercase
comment
attempt
CamelCase
snake_case
versions
Workflow
something
Did
word
'header
HTTP
error
code
grep
reasons
same
line
error
message
other
Redirect
location
original
HTTP
method
raise
HTTPTemporaryRedirect
location=location
place
urllib.parse.urlencode
dictionary
string
handy
Easier
variables
wired
string
unhelpful
meaning
indirect
accesses
clear
comment
indirect
Nice
able
flakiness
number
test
Python
nicer
solution
Python
random
library
psudo-random
series
random
numbers
[
random
seed
]
https
//docs.python.org/3/library/random.html
random.seed
python
random.seed
[
get_platform
'hebrew_letters
]
_
range
N
==
[
results
same
order
time
pytest
fixture
something
advantage
fixture
@
pytest.fixture
def
_cfg
dic
return
resutl
@
pytest.mark.parameterize
[
]
def
test_upgrade_param_env_templates
_cfg
config
assert
_cfg
config
==
advantage
scenario
separate
test
section
functionality
e.g
[
platform
]
[
[
foo
]
]
b
c
selection
=
random
[
[
bar
]
]
=
c
d
e
selection
=
mem_avail
thresholds
load_15
platform
aliases
confusing
name
aliases
platform
groups
something
effect
function
openml.evaluations.list_evaluations
example
focused
line
hashes
first
line
block
header
ugly
horizontal
bar
output
code
example
final
output
random
state
contributor
variance
Could
use
https
//pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html
dataframe.values
noqa
example
idea
uploader
study
hash
necessary
markdown
rst
backticks
code
rendering
way
possible
part
evaluation
running
time
example
good
brief
title
plot
plt.show
rendered
website
thumbnail
_Examples_
page
parameters
separate
lines
parity
similar
call
script
column
sklearn.svm.classes.SVC
_C
sklearn.svm.classes.SVC
_gamma
check
colnames
list
_in_
operator
Could
descriptive
self.assertNone
SMAC
Bayesian
optimization
more
general
good
intended
audience
OpenML
general
ML
user
examples
test
server
task
anneal
possible
load
appropriate
paper
repo
dependencies
test
Could
name
descriptive
comment
hardcoded
variable
assignment
line
trouble
comment
Could
comments
clear
direct
context
rid
comment
possible
new
admin
API
token
able
api
key
environment
variable
travis/appveyor
accounts
high
access
key
commented
line
necessary
logger
file
comment
Are
comments
suggestion
Attribute
list
attributes
such
identifiers
indexes
E.g
feat1
feat1
feat2
test
correct
files
Could
unit
tests
feather
search
status
publish
function
index
column
openml
logger
implementation
detail
file
desired
level
Github
issues
useful
full
context/explanation
good
reasonable
brief
explanation
file
way
slight
idea
editor
e.g
>
flow
external
version
[
skip
ci
]
rerun
change
Could
function
same
way
creation
dataset
more
html
tag
Same
target
name
tasks
Users
outdated
OpenML100
paper
warning
something
lines
code
OpenML100
paper
lots
things
Please
visit
<
url
>
up-to-date
example
something
page
important
differences
link
documentation
e.g
concept
benchmark
suite
Good
catch
categorical
Study
Same
uuid
nicer
unrelated
things
brief
see
comment
case
special
curve
classification
classification
sample
sorry
things
diff
reference
task
type
ids
idem
loops
small
comment
task
few
observations
well-known
iris
print
little
bit
verbose
good
logging.info
%
s
%
d
repeats
%
d
folds
%
d
samples
%
task.get_dataset.name
n_repeats
n_folds
n_samples
loop
single
repeat
/
yep
thanks
bad
single
dataset
versus
King+Pawn
A7
Will
idem
loops
mention
loop
folds
server
None
values
case
comment
fields
edits
new
versions
iterate
attributes
loop
attribute
new
version
unit
test
runtime
much
Could
comments
translations
Let
elif
comment
specific
suggestion
elif
wagtail.VERSION
>
=
construct_whitelister_element_rules
hook
Wagtail
register_rich_text_features
Hallo
editors
custom
AtomicTableBlock
table
cells
Looks
rid
commented
line
suggestion
key
params.keys
note
@
schbetsy
[
HMDA_OUTAGE
flag
]
https
//github.com/cfpb/cfgov-refresh/blob/master/cfgov/cfgov/settings/base.py
L696-L699
flag
Minor
space
text
Good
point
intention
comparisons
public
schools
private
schools
for-profit
private
schools
cohort
clearer
comments
little
bit
assumption
year
code
custom
StreamBlock
example
]
https
//github.com/cfpb/cfgov-refresh/blob/1b478eb9fe2b61ea29a344e898028da4f92130eb/cfgov/v1/models/sublanding_filterable_page.py
L29
backend
validation
time
additional
blocks
editor
Wagtail
same
limitation
example
py
class
BannerContent
StreamBlock
content
=
molecules.Notification
class
Meta
block_counts
'content
possible
further
regex
matching
part
database
query
Add
banners
current
request
path
context
[
'banners
]
=
Banner.objects
\
.filter
enabled=True
\
.annotate
path=Value
request.path
.filter
path__regex=F
'url_patterns
SQL
query
SELECT
v1_banner
id
v1_banner
title
v1_banner
url_patterns
v1_banner
content
v1_banner
enabled
/about-us/careers/
path
v1_banner
WHERE
v1_banner
enabled
=
True
/about-us/careers/
:text
~
v1_banner
url_patterns
banner
regex
/about-us/
page
http
//localhost:8000/about-us/careers/
report_type
field
more
generic
color
scheme
options
green
blue
teal
other
projects
charts
css
new
data
attribute
value
meaning
not~~
return
empty
responses
comment
explanation
peers
body
parts
certain
headers
headers
comment
kind
latter
next
release
web3py
bytes
addresses
wait
release
minor
nicety
comment
@
pipermerriam
previous
comment
latest
force
push
Mind
comment
block
number
subclass
ETHPeer
reason
ETHPeer
attributes
able
comment
correct
len
check
best
is_bytes
value
return
b
elif
is_text
value
is_hex
value
return
decode_hex
value
TypeError
repeated
assignment
self.block
place
context
manager
py
block_builder
=
self.block.build_copy
transactions=block.transactions
uncles=block.uncles
block_builder
next_block
next_block.header
=
self.configure_header
*
*
block.header.as_dict
transactions
transaction
next_block.transactions
self.apply_transaction
transaction
to_block=next_block
self.block
=
next_block
embrace
mutable
block
context
apply_transaction
block
place
return
copy
new
block
transaction
//github.com/ethereum/py-evm/issues/557
issuecomment-384255221
Will
care
something
docs
mind
free
sure
intentional
way
chain
much
easier
indentations
level
structure
physical
shape
transactions
API
python
mine_block
txn
sender=account_0
txn
senter=account_1
to='0x0123
txn
safe
defaults
extra_data=b'heres-some-extra-data
transactions
block
same
thing
fork_chain
more
reliance
mutation
pipe
/
exit_fn
API
fan
https
//github.com/ethereum/py-evm/pull/1209
discussion_r212447203
option
pipe
chain
splitting
own
top-level
method
py
chain_a
chain_b
=
api.chain_split
chain
api.mine_block
'uncle'
api.mine_block
extra_data=b'fork-it
body
convert_split_fn
link
list
chain
ids
Ethereum
Classic
network
ID
chain
ID
better
list
network
IDs
https
//ethereum.stackexchange.com/a/17101/1461
TangerineWhistleVM
ropsten
network
*
*
VM
Frontier
Homestead
correcty
class
name
something
BaseAsyncChainDB
change
methods
NotImplementedError
exceptions
implementation
trinity
trinity
tests
use
cases
overhead
database
process/manager
docstring
disclaimer/warning
implementation
implementation
*
production
networking
connections
due
networking
await
asyncio.gather
pretty
doable
PR
significant
complication
issue
preferable
TODO
use
to_uris
due
inability
Node
class
comment
link
github
issue
@
jannikluhn
@
hwwhww
theory
trinity-beacon
node
discovery
discv5
plugin
base
plugin
trinity
trinity-beacon
https
//github.com/ethereum/py-evm/pull/1556/files
diff-bcb3f875bb745a964ec62cfb0d9ac188R44
practice
trinity-beacon
command
stub
point
bootstrap
sense
things
specific
error
noqa
comment
@
gsalgado
hard
circular
dependencies
python
way
problem
imports
file
hence
BaseChainDB
circular
dependency
use
forward
references
https
//www.python.org/dev/peps/pep-0484/
forward-references
use
NewType
reference
import
evm
evm.db.chain.BaseChainDB
more
ideas
Again
comment
mypy
line
comment
good
point
lines
bit
P
good
catch
supported
conv2d
test
line
comment
default
seed
way
@
mortendahl
feel
sub
bit
right
fyi
approach
fastest
z
=
x
+
correct
overflow
z
=
z
+
tf.logical_and
y
>
x
>
y
tf.ones
z.shape
dtype=tf.int32
z.shape
dtype=tf.int32
correct
underflow
z
=
z
tf.where
tf.logical_and
y
<
x
<
y
tf.ones
z.shape
dtype=tf.int32
z.shape
dtype=tf.int32
extra
comment
block
above
loop
exits
source_from_reagent
source_from_reagent
source
regex
sources.items
loop
check
second
loop
first
second
multiple
values
None
cases
good
variable
name
generic
block
code
different
value
[
]
unmatched
reagents
code
value
[
'reagents
]
dependent
other
value
reagents
value
end
comment
code
bad
idea
weird
comment
top
init
sub
function
Just
next
line
code
confusing
general
comments
function
argument
definitions
explanation
use
comments
end
lines
line
many
ways
goal
comment
change
variable
good
name
'paired-ended
comment
function
declaration
combination
first
method
code
comment
code
clearer
test
correct
audit
comment
something
test
incorrect_index
little
bit
bind-n-seq
stuff
needs
bind-n-seq
unreplicated
replicates
biosample
true
ureplicated
top
bind-n-seq
def
replication_type
request
original_files=None
replicates=None
assay_term_name=None
original_files
None
return
None
=
'content
error
=
request.embed
f
@
@
object
f
paths_filtered_by_status
request
original_files
exclude=excluded_statuses
=
f.get
'replicate
f
filtered_file_objects
f.get
'replicate
f.get
'replicate
replicates
=
request.embed
r
@
@
object
r
paths_filtered_by_status
request
related_replicates_from_filtered_files
exclude=excluded_statuses
=
r
filtered_replicate_objects
bio_rep_num
=
r
[
'biological_replicate_number
]
bio_rep_num
bio_rep_dict
bio_rep_dict
[
bio_rep_num
]
=
r
tech_rep_num
=
r
[
'technical_replicate_number
]
tech_rep_num
<
bio_rep_dict
[
bio_rep_num
]
[
'technical_replicate_number
]
bio_rep_dict
[
bio_rep_num
]
=
r
biosample_donors_set
=
biosample_numbers_set
=
replicate_object
bio_rep_dict.values
libraries
r.get
'libraries
libraries
replicate
library
call
replicate
structure
None
biosamples
request.select_distinct_values
*
biosamples
Special
treatment
RNA
Bind-n-Seq
unreplicated
mind
assay_term_name
==
Bind-n-Seq
return
library
biosample
call
replicate
structure
None
b
biosamples
biosample_object
=
request.embed
b
@
@
object
biosample_donors_set.add
biosample_object.get
'donor
biosample_numbers_set.add
replicate_object.get
'biological_replicate_number
return
return
None
return
return
hard
time
RNA
Bind-n-Seq
experiment
unreplicated
case
top
function
calculation
cheaper
such
experiments
bonus
clearer
function
special
case
special
behavior
function
docstring
paths_filtered_by_status
function
https
//github.com/ENCODE-DCC/encoded/blob/88169b961a82a1d45772772dabd07eff8e82cf5d/src/encoded/types/base.py
L117
Original_files
files
https
//github.com/ENCODE-DCC/encoded/blob/88169b961a82a1d45772772dabd07eff8e82cf5d/src/encoded/types/dataset.py
L127
technical
replicates
future
k
Can
use
little
suggestion
'library
r
bio_rep_dict.values
replicate
library
call
replicate
structure
None
Unnecessary
comment
suggestion
DNase
technial
replicates
assay_name
=
'ChIP-seq
replicate_type
=
else
replicate_type
=
rep
=
bam_file.get
replicate_type
Comment
space
level
COMPLIANT'
value
[
..
]
[
'tissue
'primary
cell
]
level='INTERNAL_ACTION'
yield
AuditFailure
level
comment
weird
assignment
necessary
edge
case
checksum
weird
reassignment
clarity
IMO
Do
translation
variables
comment
msg
_
MFA
section
Sure
downside
sudo
time
method
necessary
major
concern
sure
guidelines
Thanks
clarify
code
fine
comments
Nitpicky
let
sudos
top
comment
SudoConfig
=
request.env
[
'ir.config_parameter
]
.sudo
SudoUser
=
request.env
[
'res.users
]
.sudo
Sudo
dangerous
beast
stand
possible
code
provide
context
reasoning
Otherwise
questioning
sudo
yearly
occurrence
migrations
Nope
fine
Ok
import
alpha
weird
look
https
//github.com/OCA/maintainer-tools/blob/master/CONTRIBUTING.md
imports
chat
questions
order
correct
lack
whitespace
groups
problem
lines
block
fine
prob
See
import
comment
int
second
arg
[
fields.ids
[
cmd+f
]
https
//www.odoo.com/documentation/8.0/reference/orm.html
openerp.fields.One2many
Readability
remote
remote
+
login
combination
parts
share
code
worth
separate
helper
function
similar
define
method
comment
Calle
ir.cron
self.env
Pool
old
API
Please
[
PEP-257
]
https
//www.python.org/dev/peps/pep-0257/
Pythonic
docblocks
akin
C
docblock
self.env
perf
browse
loop
partner
self.env
[
'res.partner
]
.browse
partner_ids
work
Commented
code
'fields
None
case
nit-picky
comment
logic
unique
name
make_name_unique
helper
proposed_name
=
self._make_name_unique
f
col
_
category
_make_name_unique
def
_make_name_unique
name
seen_before
Helper
name
unique
i
name
seen_before
name
f
name
[
name.rindex
_
]
_
i
i
return
name
D
Extraneous
comment
targets
conversion
code
y
comment
@
bchen1116
Hahaha
Can
comment
Wait
None
boosting_type
=
rf
None
lightgbm
boosting_type
==
rf
lg_parameters.update
'subsample
None
None
pass
way
nice
impl
use
dicts
harder
buggy
future
test
ensembler
fit
correct
number
times
different
values
max_iterations
example
max_pipelines=49
max_pipelines=50
ensembler
max_pipelines=50
good
test
cool
features
largest
SHAP
values
tuples
tuples
x
x
]
reverse=True
Syntax
ahaha
Typo
top_k
largest
shap
values
firt
top_k
largest
shap
values
first
time-series
data
past
daily
data
reason
whole
month
irregularly-spaced
time
series
out-of-scope
first
release
https
//alteryx.quip.com/AM04ASOaQS4v/Time-Series-November-Design-Document
Changed
None
more
comments
previous
comment
^
comments
examples
own
not-blocking
comment
regexp
reason
entire
match
string
regexp
Could
docstring
sub-layers
similar
please
more
generic
layer
other
comments
much
cleaner
IPv6
code
improvement
multiple
IPv6
addresses
defaul
tone
comment
code
e.g
stackoverflow
please
kind
enough
comment
link
code
https
//stackoverflow.com/a/43722441/3223422
value
names
'CONNECT
enough
other
value
name
dictionaries
code
Same
stackoverflow
hack
comment
more
welcome
Hi
Thanks
PR
everyone
line
noqa
tag
possible
code
base
noqa
automatic
line
noqa
line
>
characters
cool
rid
noqa
Thanks
line
flake8
line
imports
add
imports
line
textt
more
explicit
comments
useless
spaces
PEP-08
That
busy
loop
synchronization
mechanism
event
advantage
query
self.event.wait
scapy_end
self.event.set
effort
comments
fact
implementation
query
longest
code
worth
kind
changes
PEP-08
compliant
line
length
docstrings
way
dangerous
/
Please
comment
.subtypes
attribute
definition
IMHO
readable
pkt.type
==
pkt.subtype
self.subtypes
thoughts
Python
return
pkt.type
pkt.subtype
self.subtypes
Could
function
parameters
construct
type
>
None
need
noqa
tag
unused
comment
issue
need
question
smile
something
more
string
function
super
inconsistent
half
strings
half
useless
methods
consistent
half
indexes
hexadecimal
other
half
suggestion
Chebychev
code
necessary
precise
calculation
number
ancillas
_reset_registers
AncillaRegister
appropriate
size
suggestion
comment
code
error
message
error
message
False
True
bit
failure
exceptions
run
tests
parallel
_exec_notebook
try
exception
tests
tests
assert
though
subprocess.check_call
L24
return
code
_decompositions
part
API
underscore
important
note
pass
assumption
pass
clarity
likely
future
generation
devices
methods
qid
range
n_qubits
num
qubits
config
self.bp_t1_time
[
qid
]
=
backend_prop.t1
qid
nanoseconds
self.bp_t2_time
[
qid
]
=
backend_prop.t2
qid
self.bp_u1_error
=
round
backend_prop.gate_error
qid
NUM_PREC
=
backend_prop.gate_length
qid
etc
CX_01
CX_10
different
error
rates
less
code
assumption
same
reason
same
Rather
attributes
backend
methods
disable
belong
diagonal.py
class
other
library
objects
pylint
artifact
suggestion
inst.condition
=
node.condition
suggestion
Get
arguments
classical
condition
documentation
standard
broadcasting
rules
Gates
comment
helpful
future
comment
switch
useful
to_matrix
method
ControlledGate
class
test
same
unit
tests
x-
>
cx
y-
>
cy
z-
>
cz
u1-
>
cu1
unit
tests
cx-
>
ccx
u3-
>
cu3
h-
>
ch
swap-
>
cswap
block
only
difference
coeff=1
same
general
many
manual
checking
whereas
math
things
consistent
compose
full
subsystem
..
equal
point
work
other
smaller
larger
self
previous
comment
None
default
Smart
duplicates
e.g
h
h
h
]
times
operation
circuit
operations
circuit
ITS
source
basis
calibration
more
explicit
....
Update
suggestion
suggestion
qubit
duration
minor
round
space
docstrings
Minor
calendar
component
events
Events
section
docstring
sphinx
math
mode
part
AFAICT
implementation
python
>
Slices
able
__getslice__
suggestion
PulseError
name
qubits
suggestion
qubits
Optional
[
Union
[
int
Iterable
[
int
]
]
]
=
None
suggestion
property
align
indentation
line
statement
user
operation
other
suggestion
name
Optional
[
str
]
=
None
>
Tuple
[
Any
datetime.datetime
]
error
argument
gate_property
suggestion
qubits
Union
[
int
Iterable
[
int
]
]
qubit
properties
suggestion
return
True
property
operational
existent
True
suggestion
i
range
FIXME
randomized
algorithm
horrendous
place
qiskit
documentation
definition
context
helpful
users
suggestion
C
Copyright
IBM
something
channels_to_plot
tf
=
schedule.timeslots.ch_duration
*
channels_to_plot
tf
=
schedule.stop_time
tf
=
tf
suggestion
C
Copyright
IBM
years
copyright
suggestion
C
Copyright
IBM
code
self
explanatory
only_acquire
no_acquire
=
self.filter
schedule
tells
schedule
pieces
acquires
pieces
code
clear
same
info
comment
people
superfluous
comments
way
comment
way
code
comment
necessary
test
lot
comments
headers
test
Acquire
test
other
instruction
types
framechange
comments
headers
instruction
separate
tests
official
color
codes
classical
phase
hadamard
FA4D56
quantum
non-unitary
A8A8A8
same
comment
zero_at
suggestion
C
Copyright
IBM
suggestion
suggestion
suggestion
suggestion
work
init
comments
suggestion
Base
class
pulse
visualization
interface
suggestion
objects
pulse
drawer
suggestion
objects
important
roles
IR
abstract
sense
terminology
AFAIK
plotting
suggestion
isinstance
node.op
ControlledGate
node.op._open_ctrl
pass
comments
suggestion
C
Copyright
IBM
suggestion
[
[
]
[
]
]
[
]
[
]
]
]
>
[
q
]
]
]
[
]
[
]
]
function
able
list
numpy
array
Operator
Channel
Unitary
etc
input
error
anything
Unitary
object
something
isinstance
unitary
Unitary
Operator
unitary
=
Operator
unitary
unitary.is_unitary
raise
QiskitError
input
unitary
mat
=
unitary.data
operator
Unitary
class
same
interface
operator
sure
list
types
something
suggestion
[
int
reg
=
reg
reg
regs
]
exception
warning
Hm
self._configuration_is_valid
checks
value
part
tests
Did
code
snippet
comment
sense
line
suggestion
label
name
flow
controller
parameter
suggestion
permutation
initial
physical
qubits
final
physical
qubits
suggestion
Plot
pulse
top
check
begin
ie
|drag
x
<
suggestion
C
Copyright
IBM
internal
attributes
nice
gate
configurable
case
other
basis
gates
ways
cmd_def
gate
calibration
argument
form
parameter
max_calibration_duration
argument
case
cmd_def
empty
list
CmdDef
assumption
wrong
u2
single
parameter
schedule
CmdDef.get_parameters
required
parameters
parameters
schedule
u2
required
duration
first
channel
AcquireInstruction
meas_group
union
meas_map
elements
share
least
element
[
acq.index
acq
inst.acquires
acquires
same
time
instruction
same
delay
instance
Acquire
q0
Acquire
q1
X
q0
Y
q1
>
Acquire
q0
+1
Acquire
q1
shift
X
q0
+1
Y
q1
shift
Was
different
way
case
same
delay
acquires
same
time
expected
behavior
gates
acquires
Acquire
CNOT
Acquire
Technically
above
valid
acquires
same
time
CNOT
other
edge
cases
TODO
lines
782-783
next
PR
todo
files
gates
cyclic
imports
max_qubits
simulator
good
tuple
slow
O
able
above
issue
same
time
inst
idx
inst
enumerate
other_instructions
instructions
i
=
inst
instructions
i
=
inst.time
.time
thing
idea
return
False
moment
oracle
Gate
object
cool
Gate
s
.num_ancillas
sure
best
approach
.num_ancillas
method
Gate
class
case
oracle
Gate
unsure
ramifications
disable
disable
end
docstring
consistency
rest
project
human-readable-name
A
Jupyter
magic
function
status
Qiskit
job
instance
pylint
disable=some-name-that-can-be-understood
append
None
method
documentation
right
comment
comment
__init__
sounds
reasonable
advantage
line
self.data_dict.get
'type
similar
variations
rest
properties
chance
type
returned
values
docstring
readability
suggestion
Copyright
IBM
*
n_qubits
kwarg
eigenvalue
command
eigen
decomposition
qsphere
better
eigenvector
equal
suggestion
pylint
disable=unused-argument
non-requested
qubits
ancilla
memory_slots
clear
circuit
single
set
measures
Ie.
same
qubit
output
schedule
undesired
behaviour
results
MemorysSlot
same
index
qubit
Similar
right
approach
near-term
creation
year
Qiskit
least
last
Paul
wrong
free
suggestion
C
Copyright
IBM
suggestion
try
pylint
disable=no-member
return
scipy.linalg.expm
*
self.params
]
*
float
self.params
]
TypeError
raise
TypeError
Unable
Unitary
matrix
unbound
t
parameter
.format
self.params
]
float
ParameterExpression
TypeError
unbound
parameter
changes
docstring
updated
Time
evolution
minus
sign
suggestion
return
scipy.linalg.expm
-1j
*
self.params
]
*
float
self.params
]
anything
afaik
self.definition
suggestion
def
_define
Calculate
subcircuit
unitary
self.definition
UnitaryGate
.definition
suggestion
C
Copyright
IBM
drawn
circuit
HamiltonianGate
examples
test/python/visualization/test_circuit_text_drawer.py
tests
easier
bit
narrower
scope
single
property
use-case
test
elegant
way
suggestion
hamiltonian
=
HamiltonianGate
[
[
]
]
]
self.assertEqual
hamiltonian.num_qubits
suggestion
C
Copyright
IBM
test
right
UnitaryGate
suggestion
C
Copyright
IBM
samples
test
samples
above
unnecessary
Use
library.continuous.gaussian
samples
fine
comments
tests
one
disable
monkey-patched
method
files
suggestion
C
Copyright
IBM
=
Union
[
int
float
]
problem
operands
channels
new
name
parameter
inst_param
Channel
https
//www.python.org/dev/peps/pep-0484/
arbitrary-argument-lists-and-default-argument-values
ABC
suggestion
comment
suggestion
float
free
symbols
float
expr_grad
blocker
more
question
comment
bit
bit
more
detail
something
helpful
suggestion
example
Aer
expectation_value_snapshot
[
complex
X
]
expected
better
try
hasattr
run_config
'meas_map
errors
_validate_meas_map
good
catch
~
val.table.X
|
val.table.Z
De
Morgan
law
Same
comment
tensor
miss
]
False
clifford
table
symplectic
matrix
method
'is_symplectic
stabilizer
destabilizer
multiplication
multiplicatio
extra
space
line
actual
append
non
other
operators
moment
private
need
comment
check
Yep
comment
older
static
constructor
sense
killjoy
comment
please
P
Remove
comment
blank
line
please
Sure
sure
kind
comments
Qobj
case
required
argument
commented
offline
talk
diego-plan9
functionality
class
sure
from_dict
behaves
similar
way
test
expect
Add
tests
from_dict
one
vague
line
TODO
chriseclectic
use
case
expand
method
opposite
tensor
terms
ordering
A.tensor
B
mathematical
A
⊗
B.
A.expand
B
QuantumCircuit
A
B
convention
subspace
A
B
significant
qubit
B
Might
worth
comment
desired
behavior
suggestion
C
Copyright
IBM
comment
self
thing
do
use
QuantumCircuit.qasm
qasm
string
pass
parser
example
example
=
QuantumRegister
q
=
ClassicalRegister
circ
=
QuantumCircuit
q
c
circ.h
q
]
circ.cx
q
]
[
]
circ.measure
q
]
[
]
circ.rz
q
]
.c_if
qasm_str
=
circ.qasm
=
qasm.Qasm
data=qasm_str
dag
=
ast_to_dag
ast
dag_drawer
dag
jupyter-execute
part
code
benefit
phase
suggestion
large
num_qubits
function
ignore
same
line
name
entire
function
block
suggestion
def
__new__
cls
name
uuid=None
pylint
disable=unused-argument
topological
sort
nodes
list
nodes
graph
idea
topology
._node_id
only
part
ordering
lists
multigraph_layers
layers
successors
nodes
lists
topology
sort
method
form
sort
case
nodes
order
different
one
example
CX
gates
]
https
//github.com/Qiskit/qiskit-terra/blob/ae1921a41a481ae90b12ea7c494c19fdbf4f70fe/test/python/visualization/test_circuit_text_drawer.py
L643
original
dag
original
dag
node.op
apply_operation_back
dag_to_circuit
def
duplicate_instruction
inst
Create
fresh
instruction
input
instruction
inst.name
==
params
[
inst.qargs
]
elif
inst.name
==
'snapshot
params
inst.params
+
[
inst.qargs
]
params
inst.params
+
inst.qargs
+
inst.cargs
new_inst
=
inst.__class__
*
params
return
inst
duplicate_instruction
node.op
default
pass
manager
parallelization
suggestion
rng
=
np.random.RandomState
self.seed
parameter
function
scope
conversion
passes
passmanager
suggestion
C
Copyright
IBM
C
function
call
Python
method
call
keyword
arguments
C
function
left-to-right
.pxd
declarations
default
argument
optional
argument
sure
improvement
suggestion
self.visitchildren
node
attrs=None
exclude=outer_attrs
suggestion
utility
code
module
user
code
original
compiler
directives
body
module
node
set
directives
suggestion
Cygdb
Cython
source
line
corresponds
C
line
information
self.buffer.markers
cython_debug/cython_debug_info_
*
ModuleNode._serialize_lineno_map
filename_line
=
self.last_marked_pos
[
:2
]
self.last_marked_pos
None
self.buffer.markers.extend
[
filename_line
]
*
s.count
'\n
suggestion
[
]
https
//github.com/cython/cython/pull/3372
discussion_r382061610
friend
getattr
cases
reason
name
unclear
use
getattr
pass
reassign
.type
assignment
case
pass
comment
case
other
special
cases
future
string
type
name
available
older
Py3
versions
single
line
tags
other
test
files
explanatory
comment
nothing
OK
C++11
features
C++11
feature
comment
redundant
section
list
suggestion
statement
difference
i.e
tests
suggestion
have_gil=not
self.in_nogil_context
code
clear
warning
comment
actual
put_var_decref
second
case
needs_refcounting
xxxref
confusing
unclear
name
versions
better
pure
optimisation
reasonable
optimisation
coerced
values
slow/fast
comments
alternative
implementations
optimisation
implementation
state
good
reason
careful
benchmarking
comments
suggestion
=
import_array
_import_array
good
test
bit
risky
code
pass-through
anything
tests
tests
something
other
error
test
cases
declaration
wrong
IIRC
error
messages
ErrorWriter
entire
test
source
file
reason
language_level
ISTM
type1
type2
unicode_type
other
unicode_type
str_type
…
reason
test
files
…
nice
much
new
test
suggestion
refcount
user
code
recursive
deallocation
code.putln
__Pyx_SET_REFCNT
Py_REFCNT
o
suggestion
@
cython.locals
arg=NotInPy
loc=NotInPy
NameError
'NotInPy
pure
Python
interested
generated
file
version
Python
Cython
able
file
Py2
Py3
Meh
preference
^^^^
sure
variable
PIE
space
%
strings
nice
P.
sure
PIE
bit
binaries
least
wrong
modification
resolve
issue
design
Avoid
redundant
dereferences
bare
metal
mode
address
vmmap
pages
info
>
PR
issue
big
issue
TODOS
bare
metal
stack
size
stack
layout
page
fault
bare
metal
mode
current
page
walkaround
baremetal
docs
suggestion
address
None
suggestion
current_pagination
=
current_pagination.split
-1
]
.rstrip
Take
last
word
skip
period
Btw
execute
False
True
False
True
part
explicit
keyword
arguments
source
links
e.g
link
commit
explanatory
comment
glibc
version
etc
Can
comment
Mb
x86
Mb
x64
length
+=
int
escape_sequence
bool
int
custom
type
commands
expressions
arguments
lines
lets
segment
good
candidate
Page
object
property
Typo
foom
>
Btw
other
archs
e.g
MIPS
comments
sth
Can
u
example
output
command
E.g
>
maintenance
print
current
target
stack
remote
Remote
serial
target
gdb-specific
protocol
exec
Local
exec
file
None
None
relative
paths
point
e.g
pwndbg
directory
base
path
os.path.dirname
pwndbg.__file__
pwntools
test
objects
https
//github.com/Gallopsled/pwntools/blob/dev/pwnlib/data/elf/__init__.py
something
BASH_BIN
=
pwndbg.tests.corefiles.bash.get
'binary
suggestion
def
test_hier_makefile
>
None
Test
Makefile
hierarchical
design.
suggestion
def
test_flat_makefile
>
None
Test
Makefile
flat
design
correctly.
reason
reason
precision
1e-9
scaling
precision
original
gds
Is
startswith
correct
filter
worried
people
other
cells
ASAP7_75t
cells
string
cell
filter
bit
comment
name
loop
comment
dictionary
entry
Nit
only
play
double
quotes
index
dict
wait
hammer
library
users
able
custom
submit
commands
function
list
available
ones
par
Generally
good
is_yaml
detection
logic
load_from_dir
e.g
defaults.yml/json
exact
load
plugin
logic
suggestion
Custom
sdc
constraints
appended
sounds
appended
verbatim
suggestion
custom_sdc_constraints
vlsi.inputs.custom_sdc_constraints
type
List
[
str
]
custom
custom_sdc_constraints
Let
TODO
/
issue
IR
library
terror
function
name
__
[
Flake8
]
__
[
E501
]
line
characters
Comment
[
SideCI
]
https
//sideci.com
Did
comment
code
bugzilla
reference
dnfautomatic
demand
someone
unneeded
lines
config
file
commandline
file
[
Flake8
]
__
[
E125
]
continuation
line
same
indent
next
logical
line
[
link
]
https
//sider.review/gh/repos/3671909/pulls/1401
issue-4103344
sub
>
Sider
<
/sub
>
text
something
package
non-modular
part
stream
backslash
comment
commit
message
double
backslash
bit
confusing
escaping
necessary
comments
single
backslash
commit
message
comment
clearer
path
try
statement
same
problem
line
github
line
hdr
]
=
distroverpkg
distroverpkg
bytes
hdr
[
]
str
condition
true
Use
distinct
https
//docs.djangoproject.com/en/2.2/ref/models/querysets/
A
small
comment
nice
0-compression
gzip
no-op
comment
compression
level
case
file
good
call
sorry
documentation
README
basic
explanations
everything
example
multiple
passes
script
file
substitutions
tags
underlying
assumption
.par
file
present
output
bazel
rule
possibility
file
exists
L61
L83
try
OSError
exception
appropriate
message
assumptions
extraneous
logs
routines
comment
command
side
effects
intuitive
people
get_latest_digest
string
case
bug
special
case
'latest
logic
anything
tag
latest
shutil
copytree
import
cases
sure
Could
logging
clear
sense
function
error
local
cache
remote
cache
case
error
>
comment
error
case
something
double
negative
boolean
opposites
e.g
deploy
parser.add_argument
no-deploy
dest='deploy
help=
args.deploy
suggestion
genomic_set_member.validation_status
columns
Does
logic
TODO
deceased
status
field
correct
value
participant
UNSET
value
vs
PENDING
APPROVED
comment
line
above
new
cutoff
date
old
version
enrollmentStatus
status
comment
line
unnecessary
activate_sql_proxy
exact
same
steps
instance
port
arguments
function
return
value
successful
connection
logic
RDR
participant_summary_dao
lines
only
disposed
times
samples
test
use
disposed
times
participant
non-disposed
samples
test
different
stages
logic
RDR
participant_summary_dao
maximum
disposal
times
participant_summary
test
earlier
time
test
minimum
dates
tests
maximums
unclear
fields
run_status
result_message
BQ
schemas
RDR
BQGenomicJobRun
schema
RDR
genomic_job_run
table
idea
same
Visitor
Pattern
approach
query
expressions
abstraction
reusable
old
query
new
query
old
one
enough
structure
work
class
hierarchical
expression
flat
collection
several
hierarchical
expressions
structure
visitor
much
use
cases
multiple
formatters
class
case
old
new
query
old
query
visitor
comment
relevant
constructor
Right
prewhere
wrong
group
weak
approach
Clickhouse
way
coincidence
behavior
stop
entire
function
NULL
transaction_status
NULL
condition
https
//clickhouse.tech/docs/en/sql-reference/functions/conditional-functions/
transaction_status
IS
NULL
NULL
divide
......
way
verbose
lot
more
robust
readable
unspecified
Clckhouse
behavior
mental
leap
NULL
NOT
IN
condition
external
function
return
NULL
comments
code
self
explanatory
right
way
way
query
logic
concerns
logic
concerns
transformation
Example
right
json
validation
Query
object
today
query
object
abstract
list
columns
AST
dataclasses
string
bare
strings
today
dataset
custom
dataclasses
Tags
example
way
query
processors
query
Clickhouse
query
class
formatting
logic
example
FunctionCall
class
function
x
logic
today
column_expr
abstract
query
editing
dataset
column_expr
events
sure
]
[
self.EVENTS_ALIAS
self.GROUPS_ALIAS
]
part
expression
error
condition
somebody
invalid
table
alias
suggestion
joinable
datasets
easier
TableStorage
abstraction
function
much
clearer
general
thanks
details
torn
comment
closer
regular
expression
definition
something
exp
[
]
becasue
exp
[
]
+
string
quick
comment
type
signature
method
[
Expression
]
wrong
likely
Tuple
[
str
Expression
]
Same
concern
previous
comment
hint
test
same
cases
max
prewhere
conditions
minor
optimization
queries
readability
reason
aliases
alias
name
same
column
name
group_id
group_id
explicit
None
comparison
extra
safe
paranoid
Kind
off-topic
and/or
scope
class
parsing
formatting
separate
class
longer
first
implementation
abstraction
Token
simple
formatter
further
processing
formatted
query
useless
different
ways
formatted
query
suggestion
Tokens
constant
suggestion
return
value
visitor
APIs
conditions
moment
Kafka
consumer
auto.offset.reset
consumer
part
unique
consumer
group
UUID
consumer
group
name
less
Sentry
today
implementation
good
tolerant
blocker
moment
only
change
ready
final
review/merging
substantial
change
python
None
dictionary
keys
due
prior
comment
concerns
case
task
ident
mismatch
warning
suggestion
DDL
create
statements
form
CREATE
IF
NOT
EXISTS
comment
statement
CREATE
statement
SELECT
means/how
migrate
script
SELECT
statement
work
different/clearer
wording
suggestion
ClickHouse
SQL
query
view
Clockhouse
😄
range
sense
least
comment
+
timedelta
seconds=1
works
events
something
_date_inclusive
parameters
behavior
higher
precision
timestamps
comment
regex
hard
regex
original
intent
able
column
result
expression
value
column
general
False
case
parameter
column
project
id
conditions
%
sure
useful
column
type
modifiers
nullable
time
group
alias
timeseries
results
bucketed_end
alias
time
events
let
TODO
cleaning
timeseries
Clickhouse
driver
Which
ip_address_v4
ip_address_v6
system
assignment
separate
thread
everything
documentation
threadsafe
something
concerned
assignment
separate
thread
callsite
able
synchronization
Same
comment
above
comment
QueryTranslator
instance
nit
relational_source
mandatory_conditions
query.get_data_source
.get_data_source
.get_mandatory_conditions
docstring
class
processor
good
approach
comment
context
responsibilities
more
details
single
line
successful
way
general
following
questions
line
maximum
description
responsibility
processor
class
circumstances
case
implicit
fact
query
processor
fit
larger
context
case
class
query
processor
way
parent
class
need
Limitations
case
lines
explanation
specific
processor
engouh
StorageSchema
read_schema
write_schema
intermediate_schema
dataset
storages
schemas
Sequence
schemas
DDL
operations
matviews
schemas
dedicated
schema
queries
StorageSchemas
TableWriter
schema
step
StorageSchemas
DDL
operations
order
fitting
change
PR
big
entity
Did
chance
try
dataset
discover
theory
storages
transactions
events
create
statements
Nullable
root
span
parent
something
worth
trace_id
table
little
easier
cross-transaction
analysis
spans
processed
accurate
name
entire
snapshot
process
case
need
columns
present
concrete
column
table
schema
better
way
key
value
present
Enum
generic
exception
smell
unlikely
other
reasons
https
//docs.python.org/3/library/enum.html
iteration
sure
request
object
response
sure
comment
pertinent
Pay
attention
request
Snuba
query
object
parse_and_run_query
mutable
query
execution
object
request.body
request.query.body
query
execution
query
extensions
query
object
query
body
legacy
representation
place
dataset
query
processors
query
place
request
clickhouse
query
processor
copy
translation
query
point
general
request
object
mutable
objects
safer
copy
request
course
processed
query
suggestion
way
value
type
consistency
promotion
something
dataset
definition
entities
method
dataset
good
end
loop
beginning
—
second
other
message
clearer
assignment
callback
Type
annotation
type
aliases
comment
helpful
tests
sense
least
single
underscore
prefix
public
API
sure
comment
logical
schema
column
approach
better
separation
logical
schema
clockhouse
schema
uneasy
fact
part
DDL
nice
ColumnSet
abstraction
part
bare
strings
consistency
problem
views
parts
interdependent
later
TODO
special
//github.com/getsentry/snuba/blob/master/tests/test_util.py
L129-L134
Does
special
>
confluent
api
EOF
error
stream
anything
standard
condition
alternatives
exception
state
true
only
other
alternative
ConsumerError
EndOfStream
hierarchy
return
Union
[
Message
[
TStream
TOffset
TValue
]
]
EndOfStream
[
TStream
]
None
]
method
Advantages
end
stream
error
likely
exception
machinery
runtime
Disadvantages
EndOfStream
part
type
signature
consumer
configuration
type
checker
method
>
Kafka
implementation
things
tricky
EOF
partition
consumer
plenty
valid
messages
partition
end
stream
matter
documentation
fact
streams
multiplexed
mention
class
docstring
assumption
anybody
EOF
clear
nobody
right
/
same
way
message.error
Confluent
consumer
Kafka
implementation
comment
first
least
events
topic
events
topic
events
transactions
today
project_id
group_id
id
Oops
ones
something
worth
space
Clickhouse
level
bare
string
coincidence
temporary
prudent
complexity
bare
string
tuple
changes
little
level
most
final
sample
Logical
query
Entity
simple
type
alias
order
build
translation
rules
specific
types
Column
generic
expression
such
types
subtypes
Clickhouse
Expression
ClickhouseExpression
=
NewType
ClickhouseExpression
SnubaExpression
ClickhosueExpression
subclass
Column
FunctionCall
etc
ClickhouseExpression
useful
problem
type
meant
clickhouse
expression
code
Snuba
Expressions
clarity
options
separate
clickhouse
AST
different
classes
aliases
NewTypes
other
Likely
common
parent
class
SnubaExpression
CLickhouseExpression
siblings
most
reason
Expression
AST
Query
class
different
case
expression
AST
same
data
structure
alias
same
object
easier
logical
expression
clickhouse
expression
file
lot
more
Likely
constraint
real
translation
rules
@
amount
rows
second
metrics
ok
Please
comment
TODO
None
few
months
road
organizaiton
column
empty
MutableMapping
user
context
Mapping
hoods
mutable
mapping
least
type
checker
user
conceptual
name
context
manager
code
unchanged
pervious
implementation
Could
TODO
method
mark
default
table
writer
dataset
world
entities
writer
entity
suggestion
First
check
top
level
condition
event
type
Same
motivation
retention_days
Useless
materialization
delete
PII
retention
raw
data
handy
timestamp
protocol
implementors
Please
TODO
same
schema
raw
table
query
aggregate
query
processing
way
tables
queries
comments
review
respect
events
clap
glad
names
test
Sentry
duration
pxx
field
aliases
least
while
https
//github.com/getsentry/snuba/pull/942
discussion_r427556300
sense
comments
future
reference
someone
later
same
question
Interesting
way
line
False
parameter
patterns
list
Tuple
actual
parameter
list
exact
same
length
result
table
alias
column
alias
assertion
suggestion
ifNull
function
optimization
class
good
test
negative
cases
unary
operator
operands
binary
conditions
[
TIMESTAMP
=
TIMESTAMP
>
EVENT_ID
>
condition
event_id
splitter
intentional
optimization
legacy
query
representation
code
end
week
comment
parameters
code
methods
override
mapping
reason
logic
settings
logic
multiple
scripts
methods
storage
annd
default
def
build_kafka_consumer_config
storage_name
str
group_id
str
override_params
Mapping
[
str
Any
]
>
Mapping
[
str
]
storage
def
build_default_kafka_consumer_config
group_id
str
override_params
Mapping
[
str
Any
]
>
Mapping
[
str
]
def
build_producer_config
storage
str
override_params
Mapping
[
str
Any
]
>
Mapping
[
str
]
methods
config
overrides
server
name
integrity
config
None
values
packed
dictionary
type
alias
returned
field
=
Mapping
[
str
Any
]
cosmetics
file
file
specific
type
something
semantics
bare
mapping
reason
fromtimestamp
appropriate
timezone
docs
utcfromtimestamp
https
//docs.python.org/3/library/datetime.html
datetime.datetime.utcfromtimestamp
@
fpacifici
Do
same
list
columns
sharding
key
Same
org_id
order
write
schemas
read
ones
case
comment
comments
discussion
code
review
agreement
columns
comments
columns
clickhouse
bare
minimum
set
PG
search
backend
xid
right
32-bit
variant
sense
structure
function
Union
[
str
FunctionCall
parameters
Sequence
[
Expression
]
…
permissive
calls
f
g
x
z
valid
construct
idea
hashes
data
integrity
good
reason
Just
executor
timeout
longer
shutdown
method
https
//docs.python.org/3/library/concurrent.futures.html
concurrent.futures.Executor.shutdown
timeout
futures
arbitrary
time
delays
multithreaded
code
unreliable
test
flaky
time
short
suggestion
Seems
negative
durations
DB
Processors
scope
mutation
function
comment
change
implies
true
nothing
reminder
debt
list
comment
https
//github.com/getsentry/snuba/pull/865
discussion_r404553324
please
comment
condition
context
column_list
Node
sure
node.text
right
way
raw
string
collect
clause
expressions
whole
raw
collect
expression
safe
way
raw
string
Expression
object
visit_collect_clause
raw
string
statement
Could
comment
valid
name
kind
confusing
singular
spec
objects
logic
other
tags
optimizations
tags
readable
mixed
process_query
logic
path
Query
super
logic
parent
class
comment
relevant
datasets
project
extension
comment
accurate
way
dataset
instances
names
sort
URL
critical
concern
IMO
TODO
dangerous
thing
recursion
cloned
jina-hub
repo
API
u
cna
use
sure
u
w
reasons
batching
memory
footprint
low
explicit
conversion
list
enforces
iterators
data_args
list
memory
stream
full
stream
docstring
caller
function
to-be-batched
function
in-memory
data
suggestion
_pea_list
=
[
]
'peas
pea_args
remote
Pods
isinstance
pea_args
[
'peas
]
list
_pea_args
pea_args
[
'peas
]
_pea_list.append
_pea_args
remote
Peas
_pea_list.append
pea_args
_pea_args
_pea_list
_add_files_in_main_yaml
current_pea=_pea_args
uses_files=uses_files
pymodules_files=pymodules_files
logger=logger
weird
executors
compound
executor
compound
executor
same
file
comment
batching
traversal
logic
chunk
modality
point
duplicated
Error
interface
executor
messy
suggestion
num_modalities
self.position_by_modality
suggestion
decorator
Python
suggestion
TODO
sileht
subscription
GitHub
Action
workers
same
branch
push
None
cherrypick
failure
PR
broken
commit
suggestion
GitHub
App
mandatory
suggestion
NOTE
jd
GitHub
ability
private
fork
rebase
impossible
suggestion
TODO
sileht
event
base
branch
change
case
suggestion
FIXME
sileht
pass
theory
suggestion
Currently
race
condition
suggestion
FIXME
sileht
January
kinds
payload
token
dict
string
while
meantime
dashboard
access_token
tokens
=
dict
login
[
access_token
]
isinstance
token
dict
login
sub
[
tokens
]
.items
tokens
hour
suggestion
TODO
sileht
command
runner
solar
=
None
warning
fetch_production
other
keys
target_datetime=None
logger=logging.getLogger
__name__
fetch_production
suggestion
hour
dt
=
pd.to_datetime
date
%
Y-
%
m-
%
d
'Chile/Continental
dt
=
dt
+
pd.DateOffset
hours=hour
dt
=
dt.tz_convert
'UTC
comment
PR
future
maintainers
Thanks
problem
more
Pythonic
something
nearest
exchanges
time
nearest_exchanges
exch_list
exch
abs
exch
[
'datetime
]
dt
nearest
exchange
TODO
exch
[
'datetime
]
[
]
exch
=
-1
*
]
[
'netFlow
]
brief
comment
number
rows
weird
format
data
sources
link
move
import
code
nice
use
arrow
Seems
source
mapping
i
range
sources
source
sources
readable
format
generation
mapping
changes
month
month
due
seasonal
use
biomass
i
concatenation
permissible
interpolation
fstring
str.format
case
i
str.format
appropriate
Add
Docstring
please
Coverage
test
case
Further
small
error
index
Rescue
object
board
index
previous
comment
board
rescue
e.
Please
ratsignal
something
good
please
logger
please
whole
message
Add
def
Needs
whitespace
punctuation
atmosphere
professionalism
client
Plz
uncomment
line
multiple
assert
statements
clearer
pytest
able
helpful
info
statement
large
Docstrings
test
please
full
docstring
basis
wrong
safer
string
many
assertions
statement
[
Suggestion
]
Can
pytests
parametrize
function
more
strings
idea
much
data
possible
TDD
great
contents
rescue
prudent
attributes
Context
fixture
best
new
Context
object
test
multiple
cases
function
Please
split
call
necessary
fixture
function
plz
use
str
format
indexed
placeholder
comments
generator
expression
extracted
package
lazy
generator
empty
modules
packages_gen
=
task
[
'action
]
.get
key
key
self._package_name_keys
non_empty_packages_gen
=
package_name
package_name
packages_gen
package_name
try
package_name
=
next
non_empty_packages_gen
StopIteration
return
True
non-empty
packages
steps
packages_gen
=
map
task
[
'action
]
.get
self._package_name_keys
=
filter
bool
packages_gen
FP
style
most
Pythonistas
non-pythonic
multiple
times
Let
try
comment
suggestion
flat
suggestion
os.path.isfile
referenced_file
None
Invert
check
items
suggestion
key
val
task.items
proper
fallback
idiom
suggestion
try
import
Literal
pylint
disable-msg=E0611
ImportError
typing_extensions
Literal
py3.6
link
solution
motivation
plz
use
readable
message
identifiers
numbers
suggestion
parametrize_match_error
=
pytest.mark.parametrize
'left_match_error
'right_match_error
message
MatchError
z
MatchError
filename
priority
MatchError
filename=
b
MatchError
filename=
rule
>
rule
id
MatchError
rule=BecomeUserWithoutBecomeRule
MatchError
rule=AlwaysRunRule
rule
>
rule
MatchError
rule=AnsibleLintRuleWithStringId
MatchError
rule=AlwaysRunRule
line
account
MatchError
b
MatchError
parametrize_match_error
def
test_match_error_less_than
left_match_error
right_match_error
Check
protocol
implementation
MatchError
assert
left_match_error
<
right_match_error
@
parametrize_match_error
def
test_match_error_greater_than
left_match_error
right_match_error
Check
protocol
implementation
MatchError
assert
left_match_error
>
right_match_error
@
parametrize_match_error
def
test_match_error_not_equal
left_match_error
right_match_error
Check
equals
protocol
implementation
MatchError
assert
left_match_error
=
right_match_error
test
case
file
non-numeric
ID
latest
comment
param
different
line
arg
suggestion
def
test_matcherror_invalid
Ensure
MatchError
message
rule
classes
good
idea
modules
suggestion
'right_match_error
MatchError
MatchError
line
comparisions
different
MatchError
MatchError
b
def
test_matcherror_compare
left_match_error
right_match_error
Check
MatchError
instances
similar
attrs
equivalent
assert
left_match_error
==
right_match_error
eq
==
=
refactoring
Simple
better
complex
suggestion
ansiblelint.rules.AlwaysRunRule
import
AlwaysRunRule
FIXME
https
//
....
_sanitize_task
task
result
var
double
computation
obvious
same
data
places
Please
comment
conditional
suggestion
pyyaml_data
]
[
]
=
_get_rule_skips_from_yaml
ruamel_data
easy
further
processing
code
thing
extra
checks
dict
key
existence
comment
implementation
right
Better
use
comments
motivation
high-level
effect
typo
suggestion
warn_list
functional
style
generator
expressions
Line
end
fact
l10n_
*
installation
suggestion
whole
python
file
dependency
old-style
rml_parse
report
try
things
comment
@
sure
matters
functions
ufuncs
minimal
fix
test
May
comment
dask.bytes
side-effect
fsspec
common
tokenization
name
collections
different
much
nicer
gen_cluster
possible
faster
easier
Looks
job
glob
yaml.load
f.read
try/except
logger
warnings
syntax
errors
files
config
nit
wayt
o
>
way
second
exception
failed
HEAD
such
useful
more
verbose
errors
HTTPFile
things
wrong
naive
usage
OrderedDict
last
assignment
python
]
collections
OrderedDict
[
]
o
=
OrderedDict
]
o
[
]
=
b
]
list
]
[
b
]
]
o
[
]
=
list
]
[
b
]
self.dicts
OrderedDict
comment
//github.com/dask/dask/pull/6799
issuecomment-725631268
helpful
tsqr
checks
orthogonality
normal
svd
heart
tsqr
'option
svd
statement
superfluous
samen
vt
norm
tests
cases
len
lenghts
=
npartitions
invalid
value
lengths
slight
preference
descriptive
name
_normalize_path
comment
docstring
private
function
public
functions
people
public
functions
source
code
choices
particular
Neat
Was
aware
option
Will
objects
anything
shape
chunks
better
fix
block
x
=
asarray
x
dask.array.core.asarray
useful
actual
response
skip
docktest
flag
function
k
convoluted
response
map
partition
reduction
lambda
x
x
partial
_sample_map_partitions
k=k
replace=replace
reduction
kwargs
dask.dataframe
https
//github.com/dask/dask/blob/8efdf989cf44a03ac265ffde4342ec2348937902/dask/dataframe/core.py
L833-L835
test
unit
partition
elements
case
exception
maps
other
non-empty
partitions
other
words
entire
sampling
existence
empty
partition
def
test_choices_size_over_repartition
Number
elements
partition.
=
db.from_sequence
range
partition_size=9
=
a.repartition
s
=
random.choices
k=2
assert
list
s.compute
exception
k
overall
bag
empty
behaviour
random.choices
function
experiment
>
>
>
import
random
>
>
>
random.choices
]
k=0
]
>
>
>
random.choices
[
]
k=0
]
>
>
>
*
*
fnmatch
n._v_pathname
key
keys
nodes
file
much
long
term
test
https
//github.com/pandas-dev/pandas/pull/27350
changes
backwards
compatible
Could
small
comment
isinstance
+
deepcopy
uncommented
same
code
comment
uncomment
value
comment
better
comment
fft
part
case
fft
doctests
functions
NumPy
pytest
tests
wrapped
versions
e.g
Dask
Arrays
NumPy
arrays
suggestion
_isnonzero_vec
NumPy
suggestion
NumPy
all-whitespace
strings
falsy
np.nonzero
len
v
v
rdeps.values
fast
exit
idea
significant
comment
docstring
behavior
d
b
runs
b
Small
nitpick
general
c
non-numeric
e.g
columns
suggestion
chunks
columns
tuples
value
name
value
part
@
mrocklin
@
TomAugspurger
cudf-specific
test
dask
thoughts
dropna
test
CI
test_groupby_dropna_pandas
sufficient
Nitpick
nice
comment
Same
comment
error
https
//docs.python.org/3/library/warnings.html
suggestion
warnings.warn
objects
method
users
users
visualise
object
method
code
comment
dtype
Persumabley
dtype=kwargs.get
cases
type_arg
other
places
__no_default__
sphinx
ipython
defaults
signature
something
more
human-readable
nice
skein
something
__reduce__
option
picklable
singleton
default
=
type
object
dict.fromkeys
[
'__repr__
]
lambda
s
'default
same
purpose
fine
something
other
raw
object
suggestion
safe
_meta
attribute
ndim
attribute
default
ndim
Same
question
item
seq
_meta
attribute
Went
Happy
other
comment
though
merge
operations
index
non-index
remain
dataframes
few
partitions
task
graph
small
<
shuffle='tasks
keyword
Ah
sorry
comment
Line
early
test
behavior
sample
part
right
comment
only
path
files
_metadata
user
splitting
statistics
parse
files
good
comment
separate
test
dd.from_pandas
pandas_series
attrs
pandas
release
XPASSing
builds
pandas
version
good
few
more
examples
more
test
coverage
outputs
'ab
b
output
indices
e.g.
b-
>
broadcasting
e.g.
informative
error
alternative
syntax
einsum
sublist0
op1
sublist1
]
informative
error
comment
fail
pass
columns_or_index
sequence
more
logic
check
isinstance
columns_or_index
pd.compat.string_types
able
no-shuffling
assertion
size
task
graph
len
result.dask
much
smaller
efficient
case
dask.set_options
shuffle='tasks
block
Can
result
assert_eq
result
suggestion
=
d
[
d.a
]
.set_index
sorted=True
Set
index
null
partition
assert_eq
understanding
wrong
comment
high-level
graph
dsk_culled
graph
same
suggestion
dsk_dict
=
dict
_
=
cull
dsk_dict
keys
==
separate
comments
function
larger
header
something
comment
merge
conflicts
ready
status
@
TomAugspurger
tuple
axis
order
a.sum
axis=axis
shape
chunks
order
return
ones
reduced.shape
chunks=reduced.chunks
dtype='f8
zeros
reduced.shape
chunks=reduced.chunks
dtype='f8
scalar
reductions
scalar
TODOs
interface
differences
stable
parallel
general
moments
algorithm
https
//github.com/dask/dask/blob/master/dask/array/core.py
L1542
nans
only
difference
untested
Looks
same
other
defaults
order
>
Scipy
special
cases
orders
code
new
moments
code
Ah
ok
test
failure
previous
Windows
check
line
spawn
code
good
dtype='category
pandas
Typo
unknown
array
output
sense
open
multiple
outputs
note
main
comments
=
None
signature
required
argument
reviewing
reading
future
devs
functions
simple
docstrings
couple
examples
inputs/outputs
def
parse_signature
signature
Parse
gufunc
signature
Examples
>
>
>
parse_signature
output_dtypes
uniform
form
output_dtypes='dd
valid
least
np.vectorize
doubles
Ideally
thing
numpy
gufunc
protocol
dask
arrays
doable
today
more
comment
Style
note
>
>
>
individual
line
dangerous
file
changes
Thanks
much
cleaner
pandas
behaviour
case
index
few
lines
range-index
case
default
..
N
index
data
case
range
index
useful
repr
col
understanding
==
arg.transpose
tidc
accessible
dataset
partitions
typical
granularity
ORC
nicer
sample
names
Just
minor
comments
Good
perspective
Just
curious
doctest
dask
use
assert_eq
equality
values
metadata
dask
arrays
correctness
able
calls
assert_array_equal
Nice
tests
negative
axis
warning
python
pytest.warns
assert_eq
da.topk
da.topk
comment
obvious
value
column_names
[
real_name
storage_name
real_name
pairs
storage_name
index_storage_names
same
logical
suggestion
assert_eq
method
cov
suggestion
assert_eq
Verbosity
harder
people
code
Reuse
extra
arguments
store_chunk
load_chunk
huge
deal
code
different
styles
comment
fine
linter
space
comma
flake8
code
root
directory
install
flake8
flake8
dask
comment
eras
epochs
helpful
IIRC
call
today
changes
tactical
goals
map_overlap
test
FWIW
things
diff
diff
git
a/dask/order.py
b/dask/order.py
index
a/dask/order.py
+++
b/dask/order.py
@
@
-297,12
+297,19
@
@
def
order
dsk
dependencies=None
i
deps
+
num_needed_inner
=
[
]
dep
deps
[
dep
]
+
[
dep
]
+
num_needed_inner.append
dep
inner_stack
deps
inner_stack.append
dep
+
elif
num_needed_inner
+
deps2
=
deps
x
-num_needed
[
x
]
inner_stack.extend
deps2
+
deps.discard
inner_stack
[
-1
]
safe
deps
diff
git
a/dask/tests/test_order.py
b/dask/tests/test_order.py
index
..
a/dask/tests/test_order.py
+++
b/dask/tests/test_order.py
@
@
-516,7
+516,7
@
@
def
test_map_overlap
abcde
|/
|
\
|
/
|
\|
d1
d2
d3
d4
d5
|
|
|
e1
e2
e5
+
e3
e5
Want
b1
e5
way
case
intuition
deps
Hopefully
line
exception
pytest
import
traceback/error
message
tests/test_groupby.py
groupby_value_counts
groupby_unique
pdb
<
details
pytest
tests/test_groupby.py
-k
groupby_value_counts
groupby_unique
=================================
test
session
==================================
platform
darwin
Python
pytest-5.1.2
py-1.8.0
pluggy-0.13.0
rootdir
/Users/scott/Developer/stsievert/dask
inifile
setup.cfg
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
traceback
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
/Users/scott/anaconda3/lib/python3.7/site-packages/py/_path/local.py:701
pyimport
__import__
modname
__init__.py:14
<
module
>
.groupby
import
Aggregation
groupby.py:1617
<
module
>
class
SeriesGroupBy
_GroupBy
groupby.py:1695
SeriesGroupBy
def
unique
split_every=None
split_out=1
..
/utils.py:651
wrapper
original_klass
method
ua_args=ua_args
extra=extra
/utils.py:613
_derived_from
get_named_args
original_method
/compatibility.py:120
get_named_args
s
=
inspect.signature
func
/Users/scott/anaconda3/lib/python3.7/inspect.py:3083
signature
return
Signature.from_callable
/Users/scott/anaconda3/lib/python3.7/inspect.py:2833
from_callable
follow_wrapper_chains=follow_wrapped
/Users/scott/anaconda3/lib/python3.7/inspect.py:2208
_signature_from_callable
raise
TypeError
r
callable
object'.format
TypeError
<
property
object
>
callable
object
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
PDB
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
PDB
post_mortem
IO-capturing
>
raise
TypeError
r
callable
object'.format
Pdb
/details
>
Yes
ridiculous
someone
point
comment
purpose
comment
try/except
suggestion
Preference
top-level
imports
preference
inner
functions
method
group
describe
stuff
describe
function
method
function
name
columns
sqlalchemy
functions
column
names
same
function
multiple
times
way
index
curious
nice
way
underlying
functions
meta=
keyword
comment
boolean
dtype
checks
cast
first
place
comment
bit
need
cudf
thing
_key_columns
pandas
master
dask
Might
note
Flake8
indented
comment
comments
state
line
clse
>
cls
Request
typ
docstring
Return
function
implementation
cls
lot
space
comments
something
Dask
Dataframe
perspective
fringe
Most
maintainers
much
cudf
Style
nits
bool
type
call
Sorry
necessary
context
manager
cleanup
case
single-value/scalar
case
possible
input
user
place
python
]
import
np
]
x
=
np.array
[
]
]
np.asanyarray
x
Out
]
True
]
np.sort
x
Out
]
array
[
]
]
np.sort
x
Out
]
False
rid
branch
inline
identity_slices
slc
==
slice
d
slc
d
zip
slices
self.shape
cognitive
load
future
readers
bit
check
variable
definition
right
exception
subprocess
arbitrary
reason
test
way
right
integration
double
instrumentation
overhead
suggestion
dog
False
containment
suggestion
dogs
False
containment
transaction
events
exempt
WSGI
app
useful
WSGI
middleware
https
//docs.sentry.io/platforms/python/wsgi/
data
crash
@
untitaker
interested
insights
sentry-python
members
kind
handlers
nothing
particular
framework
capable
anything
similar
documentation
code
base
rush
light
event_from_exception
reason
exception
mechanism
trytond
integration
hub
=
Hub.current
hub.get_integration
TrytondWSGIIntegration
None
return
user-set
properties
concern
_do_init
multiple
times
possibilities
method
Please
early
return
Hub.current.get_integration
SparkIntegration
None
such
integration
weakref
request
someone
scope
request
handler
many
resources
Flask
Django
ok
placeholder
string
user
raw
data
part
request
end
raw
payload
sensitive
data
arbitrary
blobs
*
contents
*
file
uploads
reason
problematic
request
data
event
exceptions
concern
Scope.closeSession
session
state
session
field
instance
caller
Hub
responsible
double
dispatch
weakref
better
>
s.session.close
flush
finished/flushed
session
bound
scope
Scope.apply_to_event
behavior
JS
Note
span.transaction
regular
span
transaction
towards
clearer
conceptual
separation
transactions
spans
separation
clear
https
//github.com/getsentry/sentry-python/pull/715
Transaction
class
Span.transaction
>
Transaction.name
function
transaction_from_function
useful
full
path
module
None
same
instance
bottle.LocalRequest
Flask
weakref
current
request
object
such
user
scope
new
thread
job
queue
original
request
data
request
alive
current
request
thread
data
sure
request
object
threadlocals
LocalRequest
errors
safe
desirable
familiar
sdk
suggestion
Transactions
events
attachments
suggestion
attachments
hint
suggestion
attachments
hint
callbacks
btw
i
discussions
comments
sourcecode
aside
PR
standard
comment
JS
major
version
decision
context.pop
function
Ah
please
use
pop
None
Please
Hub.current.get_integration
check
other
integrations
integration
later
point
time
arguments
use
*
args
*
*
read
api
changes
thread
full
waiting_time
handler
returns
timeout_thread.stop
thread
self._stop_event.wait
self.waiting_time
https
//docs.python.org/2.7/library/threading.html
return
value
wait
same
region
same
region
start-api
fallback
AWS_S3
good
local
devs
additional
things
Nit
kwarg
mapping
comment
line
resource
path
string
resource_path
resource_id
root
path
Sorry
hard
time
path
more
explicit
resource
awhile
comment
isinstance
helpful
nit
suffix
clear
suffix
something
path
param
wildcard
ones
ie
ones
+
end
Right
comment
variable
name
descriptive
same
fallback
previous
fallback
value
False
Will
good
point
important
part
Docstrings
intention
first
last
quotes
case
beginning
end
string
input
Below
Python3.8
>
>
value
=
a\
>
>
>
value.strip
a'
>
>
value
=
>
>
>
value.strip
a'
slice
better
>
>
value
=
a\
>
>
>
value
-1
]
>
>
>
value
=
>
>
>
value
-1
]
Path
__file__
.resolve
[
]
variable
get_command_list
comment
worthy
Hang
file
path
content
files
intentional
sufficient
question
possible
execute
permissions
files
current
user
read/write
group
global
permissions
build
directory
same
note
files
directory
permissions
aws_lambda_builders
module
os.path
Failure
cases
nit
param
order
cli
do_cli
methods
good
default
sure
builds
'correct
allow
customers
speed
'clean
possible
higher
flow
common
pattern
example
SAM
Pathlib
Transforms
point
SAM
place
easier
Might
scope
something
head
capture
exhaustive
whole
different
ball
game
check
exhaustive
suggestion
list
check
methods
same
parameter
return
true
false
type
auth
easy
more
auth
methods
responses
share
same
structure
Message
property
invalid_request_context
method
method
msg
error
enum
ex
UnsupportedMediaTypeException
service
response
way
place
key
names
comment
please
self-explanatory
necessary
Could
comment
super
clear
reason
code
bit
bmoffatt
comments
necessary
cases
item
type
cipo.settings
Change
cipo
circulation
policy
lines
tow
comment
Order
lines
number
order
lines
cosmetic
facets
*
*
get
index
'if
statement
backend
API
cookies
session
better
new
language
optional
URL
parameter
pickup_location_pid
great
tests
coverage
green
不要行内注释
whole
list
single
option
number
calls
nothing
suggestion
Ensure
build_isolation
option
PyPIRepository
value
typo
suggestion
Dry-run
message
output
empty
out.stderr
exception
==
Flags
dry-run
-n
same
pip-compile
help
dry-run
flags
typo
suggestion
Dry-run
message
output
short
comment
startswith
equals
nit
https
//issues.apache.org/jira/browse/BEAM-3357
comment
better
design
'contract
method
i.e
comments
Variant
MalformedVcfRecord
way
MalformedVcfRecord
next
method
VcfParser
type
Variant
Malformed
right
thing
allow_malfored_records
way
Nucleus
logic
better
explicit
True
string
None
comment
something
next
line
next
line
_get_record
method
get_record
behavior
independent
VcfParser.next
relationship
get_record
method
note
current
logic
bug
None
pipeline
empty
line
PyVcf
[
empty
lines
]
https
//github.com/jamescasbon/PyVCF/blob/master/vcf/parser.py
L280
integration
test
empty
line
sure
changes
valid-4.2.vcf
empty
line
middle
file
https
//github.com/googlegenomics/gcp-variant-transforms/issues/324
line
comment
Please
other
reasons
pretty
sure
comment
previous
review
sure
process
generator
yield
list
general
lists
value
code
readable
value
big
worth
generators
big
memory
copy
value
non-insignificant
performance
consequences
benifit
pysam
tabix
indexes
much
code
comment
anything
name
constant
value
guess
side
specification
value
bin
index
index
metadata
blocks.
least
understanding
eg
specific
File
data
header
line
header_line.startsWith
strip
faster
weird
irrelevant
variables
something
function
name
docstring
better
solution
size_in_bytes
filesystems.FileSystems.match
[
file_name
]
]
.metadata_list
]
.size_in_bytes
costly
value
condition
readability
white
spaces
size
sample
list
size
bit
unclear
True
source
code
ReadAllFiles
own
line
inline
comment
splittable
helpful
readers
nit
VcfHeader
'formats
consistent
Definition
s/when
vcf
files/for
field
compatibilities
VCF
files
Thanks
error
sure
schema
empty
header
fields
merge
headers
pipeline
empty
file
error
records
error
case
merge_headers
pipeline
user
path
representative
header
file
case
job
likely
pipeline
nit
please
more
explicit
comment
None
arbitrary
number
values
Please
comment
Args
section
resolver
type
annotations
same
'infos
class
nit
python
statement
cases
annotations
class
descriptive
VariantAlternateBase
similar
VariantCall
simple
storage
class
similar
proto
nit
info
cleaner
top-level
info
per-alt
per-call
info
Please
small
example
string
return
value
nit
comments
spaces
*
correct
value
Please
comment
Please
method
comment
detailed
description
formatting
replacement
logics
replacing
TABLE_NAME
'Args
section
query
list
strings
single
string
]
https
//github.com/googlegenomics/gcp-variant-transforms/blob/master/gcp_variant_transforms/transforms/merge_headers.py
L107
example
good
way
'query
fields
_validate_test
method
i.e
support
keys
query
expected_result
assertion_config
TODO
nit
please
comment
something
Runs
query
verifies
output
expected
result
nit
please
TODO
username
special-casing
'assertion_configs
generic
validation
logic
keys
point
special
logic
assertion_configs
TODO
generic
option
function
list
strings
[
]
https
//jameshfisher.com/2018/01/09/how-to-hash-multiple-values/
function
bit
specialized
def
generate_int64_hash_code
string
min_hash_value
=
sys.max_int
def
generate_int64_hash_code
'test
hash
values
[
range
offline
useful
http
//www.cim.mcgill.ca/~langer/250/27-hashing.pdf
TODO
useful
annotation
sure
_shard_variants
_read_variants
use_1_based_coordinate=False
0-based
coordinate
use_1_based_coordinate=False
shards
1-based
VCF
expected
coordinate
VEP
variants
annotation
same
So
annotation
variants
use_1_based_coordinate
variant
VEP
annotation
0-based
coordinate
correct
comment
informative
connection
False
value
one
_shard_variants
TODO
BTW
version
greater
sure
version
works
>
TODO
nit
note
reference
Issue
nit
dependency
issues
matter
install
difference
install
stops
pip
versions
change
pretty
cryptic
clear
goal
documentations
users
@
bashir2
Can
method
warning
List
dictionary
proc_variant_factory
proc
great
processed_variant_factory
example
type
comment
next
line
doable
docstring
great
alternative
design
much
code
change
specific
suggestion
TODO
nit
oops
Done
Thanks
guess
InteliJ
random
comment
Good
catch
challenge
unused-import
/
Hopefully
pylint
type
third
party
tools
general
type
ways
line
type
annotation
https
//github.com/googlegenomics/gcp-variant-transforms/blob/master/gcp_variant_transforms/transforms/merge_headers.py
L47
Multiple
lines
example
https
//github.com/googlegenomics/gcp-variant-transforms/blob/master/gcp_variant_transforms/transforms/merge_headers.py
L39
first
line
second
one
alias
shorter
readability
name
update
type
Args
nit
comment
comment
separate
module
similar
BQ
BQ
row
generation
inside
/libs
other
use
cases
PTransform
'styleguide
TODO
VCF
BQ
job_name
https
//github.com/googlegenomics/gcp-variant-transforms/blob/master/gcp_variant_transforms/vcf_to_bq.py
L166
i
same
same
problem
table
ID
So
common
lib
lib
_is_direct_runner
function
free
code
job_name
TODO
parameters
line
easier
line
nit
please
indent
Please
start
end
comment
reference_bases
start
end
same
Please
TODO
non-variant
regions
obvious
WIP
Please
comment
value
DoFn
methods
worker
new
bundle
https
//github.com/apache/beam/blob/e30e0c807321934e862358e1e3be32dc74374aeb/sdks/python/apache_beam/transforms/core.py
L329
nit
add
spaces
=
nit
comment
i.e.
discussion
yesterday
other
version
conflicts
own
code
anything
specific
nit
s/add/get
nit
s/yifangchen/allieychen
better
new
issue
logic
validate
TODO
comment
happens
final
sample_ids
sample_names
values
sure
data
data
Order
pcoll
sample_names
flag
flag
preserve_sample_order
flag
misunderstood
other
method
check
Please
Again
let
explicit
name
_id_to_name_dic
Type
Dict
int
>
str
Tuple
old
artifacts
nit
empty
line
next
function
field.description
SchemaDescriptor
representation
description
sure
class
more
sense
class
RecordDescriptor
SchemaDescriptor
ditto
private
_
ditto
next
field
documentation
nit
option
assignments
bigquery_util.TableFieldConstants
Consts
something
style
guide
individual
class
imports
tests
reason
long
names
Done
'CSQ
other
comments
demonstrate
multiple
fields
fine
file
list
lines
correct
python
builtin
something
open
s/str/List
[
str
]
Indentation
inconsistent
comments
section
text_line
line
header
read
due
section
records
text_lines
text_source
StopIteration
right
case
absent
default
CHROM
line
empty
file
complications
text_lines
=
text_source
read
least
actual
record
CHROM
line
exists
error
function
meant
comment
function
helpful
variety
conversions
string
number
value
type
numeric
value
python
functions
Drop
comments
logic
lot
n
tasks
m
workers
something
file_metadata_chunks
[
file_metadata_list
[
i
:num_workers
i
range
num_workers
file_metadata_chunk
file_metadata_chunks
file_metadata_chunk
continue
case
num
files
num
workers
=
_SingleWorkerActions
file_metadata
file_metadata_chunk
worker.io_map
file_metadata.path
]
=
worker.disk_size
+=
self._single_vm_actions_list.append
worker
point
DeepVariant
experience
users
single
output
path
runs
details
users
hitting
exception
pipeline
unique
folder
common
case
user
program
correct
VEP
cache
program
log
file
exists
directory
empty
way
goals
i.e
flexibility
user
exact
output
folder
Done
please
note
file
empty
lock
overwrites
TODO
information
actual
log
files
output_VM
*
_get_output_log_path
.log
extension
s/upate/updates
TODO
ok
Please
update
comment
VEP
suffix
ah
sounds
good
ah
operations
_running_operation_ids
self-assigned
LGTM
PR
flags
good
idea
general
users
default
setup
line
work
definitions
comment
sure
duplicate
definitions
idea
generate_rb_sequence
programs
least
docstring
generate_rb_sequence
generate_rb_sequence
programs
QubitPlaceholder
objects
programs
QubitPlaceholder
i.e
inverse
mapping
qvm
semaphore
several/most/all
tests
forest
fixture
test
QVM
docstring
comment
thread
things
merge
comment
much
code
>
docstring
broken
Comment
_is_segments_intersecting
checks
Comment
traffic
light
waypoints
mean
_key_net
comment
algorithm
icm
rewards
rollout
comment
event_files
multiple
runs
same
configuration
different
random
seeds
min
necessary
tf.cast
min_v
max_v
min_v
=-1
max_v=1
better
B
[
,d
]
prior
knowledge
lower
order
polynomial
similar
scaling
haar
basis
[
B
l
]
>
[
B
n
]
wrong
comment
A
minor
point
other
items
many
models
state
dependent
std
class
Remove
TODO
following
line
path
format
field
fields
None
field
different
current
assumption
FrameStack
fields
fields
None
Please
comment
fields
None
double
check
sure
current
gin
files
right
fields
only
wrong
on_policy_driver
ScalarAdaptiveNormalizer
rewards
Might
problems
RNN-actor
networks
Description
class
name
class
better
general
class
uniformprioractor
different
variable
constant
comment
normal_batch
recent
data
duplicate
recent_batch
case
w/o
replacement
better
explicit
reference
such
arXiv
essential
conditional
VAE
please
comment
formulation
conditional
VAE
log
p
x|y
E_
z~q
z|x
y
log
P
x|z
y
KL
q
z|x
y
||p
z|y
class
compute
z
KL
divergence
case
discount
step_type
MID
former
case
self._fail_frame
=
current_frame
actions
better
trunc_normal_
vector
form
mean
std
b.
comment
keep_vars
tests
tmp
files
tempfile
context
manager
tmp
directories
rl_algorithm_test
comment
format
other
comment
alf
code
explanations
comments
vector
episode
reward
different
dimension
different
meaning
suicidal
move
merged
new
CC
obvious
num_parallel_environments
Right
mdq
target_critic_networks
note
code
clear
better
shape
log_pi
easier
code
shape
[
B
Comments
added
comments
state
comments
shapes
actions
log_pi
comments
shape
free-form
adv
cases
[
B
*
action_dim
d
]
>
[
B
action_dim
d
]
type
mean
maximise
=
>
maximize
use
alf.utils.common.transpose2
more
general
tensors
arbitrary
rank
specific
comment
tr.random.shuffle
y_in_tran
case
other
dimension
tf.squeeze
loss
axis=-1
output
[
[
]
]
assertion
inconsistent
comment
support
tuple
conv_layer_params
list
[
tuple
]
assertion
inconsistent
comment
support
tuple
deconv_layer_params
list
[
tuple
]
frames_per_sec
env.metadata
[
'video.frames_per_second
]
=
>
tf-agents
trained
model
batch_size
tf-agents
Seems
comments
troubles
today
FWIW
comment
separate
utils
devices
module
callable
__main__
_unless_
utils
folder
development
little
annoying
util
file
sensors
file
something
pocs/utils/devices.py
list_arduinos
python
pocs/utils/devices.py
list_cameras
python
pocs/utils/devices.py
list_attached_hardware
Comment
latest
input
buffer
latest
above
simple
move_distance
=
position
%
self._n_positions
larger
position
chance
race-condition
most
body
class
point
TODO
fine
necessary
default
values
set_point
filter_type
Camera
classes
sensible
things
arguments
absent
item
images
more
images
private
variable
docstring
kind
think
port
private
Comment
other
PR
status
decision
user
Docstrings
Important
parameters
open
dome
moving
consistency
eventual
other
dome
subclasses
open
method
sense
domes
way
Document
parameters
sure
bytes
string
target_feedback
Hmmm
obvious
mix
casting
scale
factors
unit
conversions
enum
lookup
dictionary
lambda
functions
things
group
bools
elif
control_type
<
list
control
types
nice_value
=
bool
int_value
bit
Could
partition
_
middle
value
multiple
name
suggestion
Camera._assigned_ids.remove
uid
bit
RAW16
correct
suggestion
uid
=
self.uid
suggestion
self._filter_type
=
'M
Monochrome
suggestion
self.logger.debug
assigned
IDs
list'.format
uid
log
able
beginning
first
reading
arbitrary
point
input
docstring
notes
delay
first
place
TODOs
Issue
part
PR
>
IIRC
many
log
entries
count
variable
above
Docstrings
good
measure
😄
point
announce
first
message
gap
messages
i.e
power
camera
box
Which
behavior
level
system
device
way
Docstring
Docstrings
Thanks
ChainMap
performance
try
lines
place
Just
note
default
edit
sleep
perplexed
config
file
lists
canon
cameras
prefixes
serial
numbers
order
ports
comment
mount
confused
vs
vs
w.r.t
/
mount
i.e
other
None
alternative
course
single
function
e.g
FWIW
reason
functions
enable
testing
distinct
features
minds
readings
comment
true
PanMemoryDB
Just
marking
comments
more
generic
Might
nice
comment
_why_
python
after_signal
=
True
assert
after_signal
clear
statements
more
comments
lack
problem
description
PR
curious
exp_time=None
parameter
list
function
decl
kwargs
sure
comment
idea
pointers
POCS
env
POCS
suggestion
create_cameras_from_config
camera
config
cameras
simulation
suggestion
self.filterwheel.move_to
observation.filter_name
blocking=True
block
capture
event
exposure
middle
filter
movement
_setup_observation
take_observation
nice
FITS
headers
PR
_setup_observation
sense
suggestion
self.filterwheel
None
observation.filter_name
None
docstring
comment
true
call
write_fits
_readout
readout
comment
format
helpful
little
work
suggestion
'CCD_INFO_EXTENDED2_IMAGING
info
full
frame/frame
transfer
interline
appropriate
sense
UID
characters
Canon
gphoto2
Camera
Camera
classes
AbstractSDKCamera
full
UIDs
uncropped
UIDs
AbstractGPhotoCamera
exact
meaning
bit
camera
types
sort
identifier
camera
identifier
scan
cameras
individual
camera
current
camera
types
_different_
identifier
same
camera
other
operations
subsequent
camera
former
self._address
latter
self._handle
'at
works
most
time
version
FLI
SDK
device
node
/dev/fliusb0
SBIG
int
enum
strings
'DEV_USB1
unreleased
libusb
FLI
SDK
something
similar
SBIGs
ZWO
SDK
small
integer
suggestion
Create
random
serial
number
_setup_obseravtion
Property
should_retry
problematic
property
value
Just
note
comment
same
thing
short
delay
suggestion
filterwheels
f
product
_
fw_id
fw_id
product
fw_id
zip
products
ids
id
python
bulit-in
best
situations
init
param
explanation
comment
updated
version
true
suggestion
thread
check
value
minutes
@
burhandodhy
private
property
response
object
request
crum
import
get_current_request
request
=
get_current_request
lms
app
>
apps
'edly_panel_app
scantance
correct
update
docscrting
comments
unnecessary
comments
length
list
attributes
consistent
name
EdlyOrganization
EdlySubOrganization
Organization
same
.all
_could_
following
better
clarity
Set
JAVA_HOME
CP_JAVA_HOME
available
empty
string
os.environ
None
valid
environment
variable
os.environ
[
'JAVA_HOME
]
=
os.environ.get
'JAVA_HOME
os.environ.get
'CP_JAVA_HOME
CP_JAVA_HOME
consistency
comment
incomplete
next
prs
scope
iteration
Hehe
*
Optional
*
*
Comment
view
__getattribute__
ah
right
such
comments
https
//github.com/ManageIQ/integration_tests/pull/4387/files
diff-fa6a86dc0dc65ab876b17fc13b55f6b6R238
simpler
view_selector
=
View.nested
DetailsToolBarViewSelector
construciton
dtto
rest
such
calls
View.nested
decorator
Can
point
better
solution
solution
refactor
chance
ASAP
promise
*
*
OPTIONAL
*
*
better
way
method
people
ipython
methods
available
b
massive
conditional
eyes
comment
newness
feature
feature
sentence
fragment
templates
section
elipsis
i.e
purpose
section
*
*
REQUIRED
*
*
fail_condition=False
redundant
TODO
drag_and_drop
WT
browser
able
self.browser.drag_and_drop
sel
reference
FIxed
Widgetastic
drag
drop
browser
class
indentation
wrong
approach
preallocated
small
template
provider
update
yamls
field
sparse
True/False
templates
yamls
sparse
template
present
sort
approach
console_template
something
case
*
Required
*
list
comprehension
lambda
necessary
following
same
thing
assert
[
'resume
item.lower
item
view.toolbar.configuration.items
]
menu
refresh
take
place
update
part
update
mechanism
wait_for
place
update
method
separate
method
multiple
reasons
need
b
name
ambiguous
wait_for
method
PR
cleanup
necessary
instance
_Optional_
formatting
python
method
=
original_class.methods.create
name=fauxfactory.gen_alphanumeric
display_name=fauxfactory.gen_alphanumeric
location='inline
script=script
testSteps
results
optional
such
cases
textwrap
dedent
script
proper
way
https
//github.com/ManageIQ/integration_tests/blob/c6913cc5bf0ff2f0c8186c5a84be0f9ea4a8e620/cfme/tests/automate/custom_button/test_service_vm_custom_button.py
L46
small
comment
logic
*
*
Optional
*
TODO
BZ-1743579
........
noqa
*
*
optional
*
*
Put
calls
method
*
*
REQUIRED
*
*
Resetter
use
enitities
Check
host_views.py
provider_views.py
example
*
REQUIRED
*
*
entities
Details
views
reviewers
TODO
big
chance
long
time
bug
way
test
bug
original
code
intact
time
old
workarounds
BZs
easy
lines
other
changes
test
necessary
post
methods
TODO
bug
appliance.db
object
Test
pattern
good
host
states
states
DB
good
alternative
assumption
current
settings
test
bit
default
configuration
value
default
*
*
Required
*
*
Please
comment
index
Can
comment
finalizer
request
otherwise
unused
bit
confusing
finalizer
ID
object
id
attribute
good
practice
test
steps
automated
test
cases
level
detail
great
manual
case
automation
methods
actions
function
calls
test
mechanism
text
fruitless
game
sync
description
accurate
testSteps/expectedResults
automated
tests
happy
details
automation
test
please
comment
name
BZ
state
Question
noqa
Question
function
use
L65
observation
possible
fixture
test
*
*
Optional
*
better
parametrization
giant
list
tuples
namedtuple
*
*
Required
*
*
Pass
ids
parametrization
test
functions
test_reports_with_timelines
virtualcenter-6.0-path0-updates0
]
right
way
issue
something
work
worth
framework
issue
comment
>
TimedOutError
advanced
search
....
Anyway
applicable
Hmm
function
default
link
filtering
comments
suggestion
wrong
way
report
reports
report
selected_options
pass
report
present
pass
use
loop
@
valaparthvi
full
work
Please
Note
Inline
comment
feature
understand
whats
problem
Yadnyawalkya
bz
blocker
BZ
.blocks
host.update_credentials_rest
credentials=host_data
[
]
[
'credentials
]
UI
way
long
time
session
something
provider
multiple
test
module
scoping
test
automation
impression
providers
function
module
much
time
idea
able
providers
appliance
need
module
class
session
something
everything
function-scoped
expectations
things
fixture
things
Right
func
*
*
REQUIRED
*
Done
*
*
REQUIRED
*
*
@
digitronik
explanation
//github.com/ManageIQ/integration_tests/pull/7041
discussion_r180976007
good
test
minutes
wait_candu_data_available
https
//github.com/ManageIQ/integration_tests/blob/master/cfme/common/vm.py
L539
Please
PR
*
QUESTION
*
prevent
proper
wait_for
0th
index
comment
vm_obj
list
element
*
*
REQUIRED
*
*
assert
filters.tree.has_path
Filters
filter_name
Filter
*
REQURIED
*
*
Please
comment
line
*
*
REQUIRED
*
*
assert
view.my_filters.navigation.has_item
filter_name
Filter
*
*
REQUIRED
*
*
assert
filters.tree.has_path
param.my_filters
]
Filters
filter_name
Filter
*
*
REQUIRED
*
*
python
assert
exp_text
Filter
*
*
REQUIRED
*
readable
python
filters
getattr
view
param.my_filters
]
*
*
REQUIRED
*
*
assert
function
statement
try
ASCII
switch
size
call
reason
comment
condition
BZ
.block
need
extra
parentheses
indentation
enough
expression
lines
return
statement
parentheses
additional
ones
line
continuation
same
Question
browser
update
login
error
ok_hand
same
que
more
explanation
case
sporadic
StaleElementReferenceException
while
page
reason
js
magic
tests
different
PR
much
better
WIP
Great
kind
things
widgetastic
prevents
*
Optional
*
*
known
quantities
cell
=
row.get
row.get
None
col
name
=
cell.text
exception
logging
nice
typo
😺
*
*
REQUIRED
*
*
Please
comment
lines
second
parametrized
test
new
state1
state2
state3
same
klass
first
test
..
everything
child
method
common
parameters
same
parent
klass/method/instance
test
please
use
len
tags_available
May
in-line
comment
import_dialog
fixture
comment
case
fixture
None
list
selector
[
'clusters
'datastores
'vlans
]
use
host.provider.one_of
RHEVMProvider
Please
docblock
descriptive
clause
conversion
host
CFME
categories
categories
typo
sure
command
duplicate
entries
sshveta
usecase
migration
progress
conversion
host
host
busy
UI
'Conversion
progress
[
RHV
more
conversion
]
https
//github.com/ManageIQ/integration_tests/pull/8480/files
diff-ed6030ba2f5ff1aa837d6e8cbfaf433cR146
same
OSP
t
descriptive
sshveta
rails
commands
need
resource_id
resource_type
res
Vm.find_by
name
'my_osp_instance
conversion_host
=
ConversionHost.create
name
res.name
resource
res
=
true
appropriate
transport
method
RHV
conversion
hosts
change
res
Host.find_by
name
same
comment
output
:100
Q
noqa
Q
meaning
comp_name
None
riggerlib
straightforward
fill_dict
methods
comment
widget
test
case
clear
newbie
rename
VM
VM
object
new
name
instantiate
*
SUGGESTION
*
*
Could
hard
code
redhat-uep.pem
*
*
SUGESTION
*
*
Use
variable
hard
code
please
use
back
slash
statement
line
*
Required
*
*
use
soft_assert
minimum
catch
assertionerror
log
warning
REQUIRED
property
thing
So
data
property
such
things
Please
same
approach
https
//github.com/ManageIQ/integration_tests/blob/master/widgetastic_manageiq/__init__.py
L1829
sense
same
approach
data
property
f.e
list
items
more
data
quad
icons
data
accessable
dict
property
cases
izapolsk
Maybe
sense
__getattr__
case
okay
todo
property
@
izapolsk
backward
compatibility
example
https
//github.com/ManageIQ/integration_tests/blob/master/cfme/tests/infrastructure/test_advanced_search_host.py
L28
use
name=
Calendar
TextInput
things
consistency
ThingFormView
ThingFormView
ThingForm
other
partial
views
ExpressionEditor
class
attributes
widgets
nested
views
correct
@
mfalesni
IPv6
TODO
db
collection
*
QUESTION
*
*
lines
states.but
right
error
states
conditional
view
checks
calls
methods
location
view
several
python
words
PR
good
idea
filter
reload
etc
names
method
check
flash
messages
return
x
y
@
izapolsk
Generally
up-to-date
data
/api/requests
other
comment
Ah
return
bool
self.view
comment
floating
ip
name
address
%
sure
comment
Remove
comment
small
comment
flavors
indexes
correspond
yamls
Same
*
REQUIRED
*
*
BZ
number
in-line
commenting
intent
steps
look
utilizing
bitmath
https
//pypi.org/project/bitmath/1.0.2-3/
need
fixture
collection
instance
appliance
test
functions
fixtures
required
setup
prerequisite
resources
test
*
*
REQUIRED
*
*
def
test_relationships_tables
appliance
provider
has_persistent_volume
appliance
test_item
appliance.version.is_in_series
[
]
Treat
BZ
relations
filter
lambda
rel
rel
=
'Containers
relations
pytest.mark.usefixtures
setup_provider_modscope
setup_provider
same
above
Was
default
True
*
*
Required
*
*
Try/except
delete_stack
call
loop
stacks
stack
delete
whole
cleanup
Minor
point
TODO
suggestion
TODO
additional
crud
functionality
right
forgetfulness
Pagination
pane
sense
PaginationPane
view
VersionPick
widgetastic
widget
parent
ordinary
way
sense
case
PaginationPage
ipython
changes
such
use
case
future
Thoughts
way
fill
I.e
nothing
changes
False
ROOT
auto
locator
+1
Required
Space
questions
review
block
warrant
in-line
comments
intent
boot_index
-1
non-bootable
disk
s
device_name
'counts
'vda
'vdb
quarckster
appliance
lof
time
ruby
MIQ
Server
process
ruby
few
times
systemctl
status
evmserverd
MIQ
Server
process
active
long
time
DISABLE_DATABASE_ENVIRONMENT_CHECK=1
bin/rake
-f
/var/www/miq/vmdb/Rakefile
evm
db
MIQ
Server
same
systemctl
stop
evmserverd
processes
much
quicker
fashion
quicker
cleaner
way
course
comments
Please
provide
reason
uncollect
useful
test
operator
applicable
test
longer
name
big
string
doc
blocks
blabla
Please
comment
in-line
endpoint
hostname
+
port
+
sec_protocol
default
endpoint
AttributeError
parent_provider
None
*
*
QUESTION
*
*
create
parent
provider
actual
provider
super
call
way
intermediate
variable
*
*
REQUIRED
*
*
view
=
self.create_view
ProvDiagDetailsView
*
*
REQUIRED
*
*
A
brief
comment
blank
string
helpful
suggestion
volume
=
volume_collection.create
name=fauxfactory.gen_alpha
tenant=provider.data
[
]
[
'cloud_tenant
]
volume_size=STORAGE_SIZE
az=provider.data
[
]
[
]
appliance.version
None
provider=provider
re-implement
widgetastic.widget.TextInput.Fill
super
.fill
filling
field
parent_view
access
interaction
returns
True
bit
comment
block
parametrize
lines
comment
block
please
IRC
error
commented
line
sel.select
commented
line
error
error
sel.select
*
*
Optional
*
in-line
comment
switches
UI
helpful
long
term
maintenance
drop
function
docblock
separate
comment
block
*
Required
*
*
Use
SSHResult
object
*
*
Required
*
*
Use
SSHResult
built-in
method
overrides
rc==0
comparison
stdout
string
+1
right
good
todo
*
*
REQUIRED
*
*
Please
appliance.version
version.pick
Q
lines
able
navigation
title
text
comment
Rest
good
+1
tree.image_getter
tree.root_item
view
=
navigate_to
migration_plan
InProgress
migration_plan.plan_started
Same
thing
TODO
BZ
.blocks
flash_assertion
comment
ambiguous
intent
_tag_cleanup
boolean
return
clear
Please
comments
intent
tags
call
cleanup
true
cleanup
comment
means
provider
Never
form_data
[
]
vm_obj
]
fixtures
similar
names
test
please
comment
code
Anyway
Reviewer
stats
could/would
separate
PR
Please
comment
[
]
*
*
REQUIRED
*
cfme_data.yaml
*
Required
*
*
able
setup_provider_modscope
fixture
fixtures/provider.py
control/skipping
problematic
providers
provider
setup
method
provider
CFME
inventory
refresh
complete
use_fixtures
pytestmark
list
L9
tests
module
need
setup_provider
fixtures
provider
necessary
opinion
opinion
free
crud
test
core
functionality
i.e
object
parametrization
update
part
separate
test
test_infrastructure_host_update_scenarios
crud
test
basic
update
scenario
if/else
logic
hard
crud_action
[
'cancel
'nav_away_changes
'nav_away_no_changes
]
crud_action
=
crud_action
[
'cancel
'nav_away_changes
'nav_away_no_changes
]
something
clearer
crud_action
[
delete
]
elif
crud_action
'edit_from_hosts
'edit_from_details
[
update
call
]
[
navigate_away/cancel
helper
method
call
new
kwargs
update
better
explicit
values
crud_action
correspond
values
crud_action
'nav_away_changes
'nav_away_no_changes
crud_action
VersionPick
repo
failing
PRT
providers
version
several
other
please
comment
check
Does
BZ
cover
more
providers
Thoughts
IDs
idlist
=
thin
thick
thick_lazy
thick_eager
last
TODO
Eager
zero
max
retries
build
feature
ready
holy
uncollectif
batman
way
readable
@
john-dupuy
comment
change
user
load
yaml
file
objects
python/object
xmlrpclib.DateTime
safe_load
Loader=yaml.BaseLoader
strings
way
noqa
use
__
function
name
inline
comment
second
element
@
mkoura
note
cached_property
invalidation
review
Do
KeyError
*
*
Required
*
*
Add
TODO
view
assert
redirect
Requests
widgetastic
flash
widget
several
views
good
idea
sure
least
conv
hosts
conv
host
vm
popup
way
conversion
host
empty
throttled
vm
conv
vms
statement
end
test
TODO
other
conversions
Please
TODO
match_location
widgetastic
difficult
test
Resource
pools
by-product
other
infrastructure
def
test_delete_resource_pool_appear_after_refresh
setup_provider
provider
delete
pool
Metadata
test_flag
delete_object
resourcepool_name
=
provider.data
[
'remove_test
]
'resource_pool
]
test_resourcepool
=
resource_pool.ResourcePool
name=resourcepool_name
test_resourcepool.delete
cancel=False
wait=True
provider.refresh_provider_relationships
__get__
repository
Widget.is_displayed
widget
own
is_displayed
safe
case
widget
locator
Please
BZ
inconsistency
UI
UX
whiteboard
right
wait
@
jamesooden
last
step
short
description
[
doc
steps
https
//github.com/ManageIQ/integration_tests/pull/7171/files
diff-db180b74ac3901aac7ad21913712960eR48
sufficient
TODO
Change
code
owner
indicated
code
owner
typo
compatibility.it
fields
fields
SetownershipForm
select_owner
=
BootstrapSelect
'user_name
select_group
=
BootstrapSelect
'group_name
button
Yep
mea
culpa
other
comment
same
previous
comment
line
less
indentation
[
bundle_name
part
message
dependent
intention
messages
*
Successfully
*
]
Successfully'.format
bundle_name
navigate_and_get_rows
function
object
page
few
random
rows
case
i
row
function
returns
list
value
amount
code
un-needed
variables
value
same
line
comment
reality
last
line
table
random.choice
pop
multiple
uses
code
DRY
function
something
Use
test_item.obj.name
Yes
name
navigate_and_get_rows
navigate_and_get_random_rows
scope
PR
commented
line
external
lib
external
libraries
case
workloads
mysterious
Workloads
combination
Infra
VMs
+
Instances
/
Infra
Templates
+
Images
testing
use
side
locator
wrong
page
code
other
place
codebase
cfme.infrastructure.virtual_machines
BaseProvider
EC2Provider
lets
f-string
vm_name
=
vm_name
assignee
optional
good
default
None
Due
service
timestamp
template.name
name
service
same
label
dialog
service
template
correct
approach
dialog
label
regex
IMHO
commented
lines
current
PRT
run
Gotcha
Little
overzealous
quest
regular
conditional
expression
line
recommendation
PEP
Same
list
comprehensions
Please
BZ
number
related
GH
issue
reference
Optional
default
table
filtering
intent/purpose
method
bit
odd
widget
object
navigation
destination
self.is_plan_in_progress
_something_
view
clear
button
page
something
Note
comment
destination
short
name
argument
comment
below
due
Consider
Same
comment
classes
regards
@
geokala
please
doubt
mind
reader
P
right
Same
comment
informative
status
int
string
comment
same
thing
code
comment
degraded
node
i
nodes
db
nodes
rabbit
nodes
comment
uri
sample
local
client
target
node
client
same
reason
step
btw
send_task
start_task
reschedule_task
zip
retry_events
[
:3
]
retry_events
:3
]
retry_events
:3
]
skip
index
Components
*
*
*
*
multiple
Comments
next
commit
comments
context
manager
option
huge
amount
place
only
way
context
reset
exception
end
execution
context
manager
worth
Capital
letter
beginning
comments
line
string
/opt/manager/cloudify-rest.conf
constant
CONFIG_FILE_LOCATION
integration_tests.framework
import
constants
command
restart
fine
os.system
'systemctl
cloudify-restservice
commented
code
same
other
method
Please
comment
comment
new
line
redundant
Please
comment
Redundant
comment
Please
link
code
least
name
file
line
number
people
commit
comment
bit
suggestion
Prepend
BEGIN
transaction
deferrable
constr
comments
commit
msg
clear
future
fixes
deployments
visibility
error
change
comment
explanation
..
comment
+
yaml
comment
const
first_schema_revision
'333998bc1627
Maybe
big
try
box
VMs
something
fails
Could
bit
docstring
sure
sources
Do
box
base
image
own
function
build_in_vagrant
function
3-5
parts
large
self
piece
logic
Let
docstring
dependencies
comment
straight
copy
docstring
better
name
docstring
reasonable
starting
point
nyquist
line
refactor
comment
return
HEALTHY_STATE
status
==
HEALTHY_STATE
status
statuses
FAIL_STATE
small
style
comment
better
manager
rest
last
maybe
execution
system
update
assert
stopping
whitespace
blank
line
contains
Can
field
names
class
data
class
comment
See
better
abseil
Python
logging
https
//abseil.io/docs/python/guides/logging
absl
import
logging.info
geodi
advantage
caller
logging
statements
standard
output
xor
favorite
flag
alsologtostderr
messages
standard
error
standard
output
need
verbose
disappears
better
exception
files
tempfile.TemporaryFile
mode=
r+
f1
tempfile.TemporaryFile
mode=
r+
f2
https
//docs.python.org/3/reference/compound_stmts.html
grammar-token-with-stmt
Will
anything
script
nice
Returns
Effects
line
comment
conversion
pull
request
git
PR
hash
number
suggestion
TODO
intrepiditee
Change
other
resources
optional
arg
suggestion
TODO
intrepiditee
Move
model
suggestion
TODO
intrepiditee
helper
get
TODO
intrepiditee
Use
exception
request
errors
base
files
classes
much
e.g.
import_attempt.Model
easier
separate
code
change
suggestion
TODO
intrepiditee
Add
optional
arg
log
message
manager
suggestion
TODO
intrepiditee
Add
optional
arg
resources
client
Pandas
wide_to_long
melt
suffice
https
//pandas.pydata.org/pandas-docs/stable/reference/api/pandas.wide_to_long.html
https
//pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html
Pandas
read_csv
presence
header
row
comment
rows
suggestion
regular
filename
structure
suggestion
Downloads
World
Bank
country
data
countries
suggestion
permutations
stat
var
properties
suggestion
optional_col
[
'populationType
'measurementDenominator
]
suggestion
assert
file_to_open
None
f
file
country_iso
syntax
correct
nit
readable
lines
join
mcf_lines
]
mcf_lines.append
+
name
mcf_lines.append
+
name
return
mcf_lines
name_seen
brittle
exact
order
MCF
nodes
line
mcf.split
'\n
line
=
line.strip
line.startswith
'name
name
line.startswith
dcid
nit
comment
block
example
nit
get_mcf_piece
arg
special
handling
suggestion
TODO
intrepiditee
Limit
number
argument
specification
constant
string
comment
Explain
indexes
mean
symbolic
constants
ditto
beam
search
important
Bart
sense
greedy
/
beam
search
suggestion
shift
row
step
columns
diagonals
column
diagonal
suggestion
Matrix
multiplication
query
key
tensors
sliding
window
attention
pattern
suggestion
allocate
space
overall
attention
matrix
chunks
last
dimension
re
comment
last
dims
suggestion
compute
global
attn
indices
.forward
doc
style
usage
examples
end
Usage
AdaFactor
model.parameters
lr=1e-3
eps=
..
second
docstring
breaks
style
convention
OK
useful
better
class
suggestion
_ignore_modules
comment
commented
lines
abstraction
better
BertModel
layer
python
self.bert_encoder
=
BertModel
composition
cases
model
layer
IMO
@
LysandreJik
Add
transformers
import
DPRQuestionEncoder
DPRTokenizer
docstrings
great
N
M
num_questions
num_passages
seq_length
lot
easier
code
cf
prev
comment
Cf
tokenizer
input/output
PT/TF-accelerated
stuff
DprBertEncoder
input_ids
=
tokenizer
Hello
dog
cute
division
actual
batch
size
ignore_index
account
=
lprobs.shape
]
ignore_index
None
[
pad_mask.long
.sum
loss
/
bs
/
bs
same
result
cross
entropy
nll_loss
assert
TODO
Please
bbox
argument
documentation
remark
comment
multiplication
dumb
code
sentence
case
sentence
wasnt
EOS
sentence
unfinished
code
comment
FORCE
BOS
comment
beam
batch
sentence
list
tokens
same
ngrams
code
comment
FORCE
EOS
comment
*
num_beams
words
fairseq
code
https
//github.com/pytorch/fairseq/blob/fba10af9db5edd61f78ccdb9d115c4eafbcc561d/fairseq/search.py
L78
>
best
x
beam_size
predictions
first
>
beam_size
order
statements
sequential
logic
step
Force
BOS
lprobs
[
+
]
step
min_len
lprobs
[
]
=
-math.inf
elif
step
==
max_length
FORCE
EOS
lprobs
[
eos
=
-math.inf
[
+
]
suggestion
seeds
cuda
generator
available
suggestion
use_cache
active
mem_len
model
last
hidden
necessary
logic
attention
mask
attention_mask
generate
use_cache=True
same
attention_mask
IMO
complex
logic
cached
generation
TBH
saved_state
None
=
>
prev_key
saved_state
couple
lines
whole
function
lot
code
hard
lines
key
states
=
tf.reshape
saved_state
[
prev_key
]
bsz
*
self.num_heads
-1
self.head_dim
=
prev_key
static_kv
else
tf.concat
[
prev_key
k
]
axis=1
value
prev_value
=
tf.reshape
saved_state
[
prev_value
]
bsz
*
self.num_heads
-1
self.head_dim
=
prev_value
static_kv
else
tf.concat
[
prev_value
v
]
axis=1
assert
misleading
function
prev_key
prev_value
saved_state
k
v
None
afterwards
assert
statement
good
BERT_START_DOCSTRING
moveling_tf_bert.py
BertConfig
>
BartConfig
output
docstrings
part
Bart
modeling
file
lines
BART
work
decoder_input_ids.shape
[
-1
]
+
use_cache
=
True
edge
case
issues
feature
other
models
https
//github.com/huggingface/transformers/issues/4368
issuecomment-630244541
docs
change
indentation
lack
change
indentation
first
line
hard
suggestion
masked_lm_labels
obj
tf.Tensor
shape
obj
sequence_length
optional
defaults
obj
None
bad
programmer
good
Do
cast_bool_to_primitive
arguments
model
BERT_INPUT_DOCSTRING
modeling_tf_bert
model
closer
unused
args
docstring
PyTorch
models
args
replacement
torch.Tensor
tf.Tensor
nit
consistency
use
tf.keras.layers.LayerNormalization
LayerNormalization
same
different
kinds
layer
norm
layers
Compilation
something
necessary
TF
line
suggestion
See
RetriBert
models
https
//huggingface.co/models
filter=retribert
docstrings
ones
other
configurations
instance
configuration_bert.py
example
string
boolean
str
bool
arguments
optional
\
arguments
description
new
indented
line
abbreviations
documentation
code
comment
capital
end
period
suggestion
logger
=
logging.get_logger
__name__
configuration
please
updated
tokenizer
BertTokenizer
documentation
method
token_ids_1
user
docs
warning
Ca
Blenderbot
multiple
sequences
same
__init__
comment
comment
wrong
error
comments
suggestion
outputs
=
model.generate
input_ids=input_ids
max_length=40
temperature=0.7
do_sample=True
candidates
suggestion
student
layers
teacher
suggestion
A
custom
distutils
dependency
table
nit
styling
other
files
user
dependencies
file
=
>
Ca
output
Please
sure
xxx
pip
....
functionalities
bit
someone
*
tqdm==4.16
error
pkg_resources.VersionConflict
tqdm
>
=4.27
normal
functioning
module
normal
error
ModuleNotFoundError
module
reason
tqdm
is_tokenizers_available
put
tokenizers
last
place
pkgs
list
=
python
tqdm
regex
numpy
tokenizers
.split
b
import
is_tokenizers_available
pkg
tokenizers
correct
error
message
tqdm
dont
need
bool
TPU
Only
validation
data
test
eval
run_eval.py
intention
self-contained
important
utils
Documentation
args
good
help
comments
instance
epsilon
label
smoothing
suggestion
decoder_start_token_id
MBart
TODO
@
sshleifer
use_task_specific_params
Hi
@
sgugger
validation
test
eval
eval
suggestion
pred_str
=
tokenizer.batch_decode
pred.predictions
skip_special_tokens=True
label_str
=
tokenizer.batch_decode
pred.label_ids
skip_special_tokens=True
suggestion
AttributeError
T5
MBartTokenizer
attribute
add_prefix_space
logger
batch
logs
todo
use_task_specific_params
👍
@
staticmethod
simple
use
case
Might
compute_loss
Trainer
use
case
suggestion
hidden_states
hidden_states
[
]
<
s
equiv
CLS
]
suggestion
suggestion
tie
encoder
weights
config
suggestion
encoder
decoder
kwargs
suggestion
instantiate
config
kwargs
method
necessary
nit
code
nit
identical
code
identical
please
comment
comment
less
chars
suggestion
past_key_value
]
n_heads
dim_per_head
suggestion
weights
self.dropout
weights
n_heads
query_length
key_length
suggestion
attn_output
=
tf.matmul
weights
value_states
n_heads
query_length
dim_per_head
suggestion
Input
query_length
dim
suggestion
weights
tf.nn.softmax
scores
axis=-1
n_heads
query_length
key_length
suggestion
position_bias
=
position_bias
+
mask
n_heads
query_length
key_length
MarianTokenizer
other
Marian
tokenizers
AlbertSentencePieceTokenizer
XLNetSentencePieceTokenizer
SP
tokenizers
workaround
desynchronisation
SPM
file
way
tokenizer
useful
comment
@
stefan-it
issue
Original
fairseq
vocab
spm
vocab
Vocab
|
|
|
|
|
|
|
|
|
fairseq
|
<
s
>
|
<
pad
>
|
<
/s
>
|
<
unk
>
|
|
|
|
|
|
'-'
spm
|
<
unk
>
|
<
s
>
|
<
/s
>
|
|
|
|
|
|
'-
|
suggestion
is_regression
=
[
'train
]
.features
'label
]
.dtype
[
'float32
]
is_regression
num_labels
useful
fast
method
https
//huggingface.co/docs/datasets/package_reference/main_classes.html
datasets.Dataset.unique
label_list
=
train
]
.unique
label
.sort
Let
sort
determinism
num_labels
label_list
suggestion
Get
datasets
own
CSV/JSON
training
evaluation
files
GLUE
benchmark
task
dataset
datasets
Hub
CSV/JSON
files
script
while
use
label
column
pair
sentences
sentences
columns
such
column
exists
first
columns
least
columns
CSV/JSON
contain
non-label
column
script
single
sentence
classification
single
column
behavior
suggestion
See
more
type
standard
custom
dataset
https
//huggingface.co/docs/datasets/loading_datasets.html
suggestion
batch
creation
max
sequence
length
batch
suggestion
>
>
>
model
=
EncoderDecoderModel.from_pretrained
'my-model
suggestion
>
>
>
model
configuration
suggestion
>
>
>
bert2bert
BERT
models
Note
cross-attention
layers
>
>
>
model
=
EncoderDecoderModel.from_encoder_decoder_pretrained
'bert-base-uncased
'bert-base-uncased
>
>
model
fine-tuning
>
>
>
./bert2bert
load
fine-tuned
model
>
>
>
model
=
EncoderDecoderModel.from_pretrained
./bert2bert
suggestion
tokenizers
config
suggestion
suggestion
correct_outlen
loss
suggestion
correct_outlen
start_logits
end_logits
output
copyright
Google
AI
NVIDIA
Are
snippets
codebases
experience
users
GPT
GPT-2
CTRL
script
GPT
GPT-2
CTRL
link
suggestion
library
models
causal
language
modeling
GPT
GPT-2
CTRL
text
file
dataset
full
list
model
architectures
script
documentation
https
//huggingface.co/transformers/model_doc/auto.html
transformers.AutoModelWithLMHead
bit
much
README
simpler
suggestion
See
more
type
standard
custom
dataset
files
python
dict
pandas
DataFrame
etc
calls
nice
reference
multi-processing
num_proc
link
doc
https
//huggingface.co/docs/datasets/package_reference/main_classes.html
datasets.Dataset.map
suggestion
name
public
datasets
available
hub
https
//huggingface.co/datasets/
dataset
datasets
Hub
suggestion
Main
data
processing
function
texts
dataset
generate
chunks
block_size
only
problem
method
below
fast
tokenizers
special
tokens
important
class
TFT5MainLayer
self.shared
NoLayerWrapper
weights
layer
example
weights
main
class
TFT5Model
new
weights
craffel
@
thomwolf
Thanks
mfuntowicz
abstraction
idea
Maybe
error
message
function
Roberta
model
ok
@
thomwolf
@
LysandreJik
safer
embeddings
pad_token_id
input_embeds
order
input_embeds
code
value
care
model
HF
model
page
value
bit
uneasy
comments
meaningful
new
docstring
master/
tokenization_utils_base.py
reuse
b
modify
suggestion
batch
instance
BartModel
nit
callback
logger
callback
logs
right
hooks
suggestion
extended_attention_mask
torch.Tensor
=
self.get_extended_attention_mask
attention_mask
input_shape
device
suggestion
head_mask
=
self.get_head_mask
head_mask
self.config.num_hidden_layers
BartConfig
self
.....
statements
great
config
stand-alone
file
config
logic
Abstraction
much
functionality
IMO
great
docstrings
arguments
suggestion
tokenizer
suggestion
output
example
example
deterministic
great
same
format
docstrings
document
model
arguments
docstrings
return_tensors
truncation
tokenization_utils_base
careful
great
same
format
other
models
documentation
example
[
RoBERTa
]
https
//70643-155220641-gh.circle-artifacts.com/0/docs/_build/html/model_doc/roberta.html
transformers.RobertaTokenizer.build_inputs_with_special_tokens
code
below
fast
maybe
global
variables
much
code
smell
Python
other
languages
suggestion
model
PyTorch
torch.nn.Module
<
https
//pytorch.org/docs/stable/nn.html
torch.nn.Module
>
sub-class
suggestion
See
multilingual
BART
models
https
//huggingface.co/models
nit
share
comment
annoying
line
wrap
suggestion
model
=
FlaxAutoModel.from_pretrained
'./test/bert_model/
E.g
model
'./test/bert_model/
module
config
properties
base
class
time
code
jax.nn.gelu
same
result
lib
sure
exact
same
formula
PyTorch
output
initial
jax.nn.gelu
version
defined
objects
convention
TF
objects
object
TF
TFBertEmbeddings
TFBertSelfAttention
etc
same
convention
Flax
outside
__call__
everything
@
jax.jit'ed
multiple
times
call
__call__
lot
compilation
overhead
Curious
awkward
input_i
=
output_i
=
+
input_i
=
output_i
inputs
layer
inputs
attention_mask
nit
nn
PyTorch
>
different
naming
People
nit
lines
less
wide
BertModel
LysandreJik
@
>
same
PT
Copy
code
Sylvain
safety
check
property
config
overridden
child
necessary
attribute
FlaxPreTrainedModel
dataset
index
user
index
@
dataclass
config
=
hfArgParser
csv_path
main
default
test_data/my_knowledge_dataset.csv
better
julien-c
different
names
labels
Trainer
same
issue
Might
refactor
better
time
average
minimum
average
account
hardware
stability
likely
results
stable
approach
model
hardware
absolute
best
model
runs
criticism
minimum
first
version
[
original
benchmark
script
TensorFlow
team
François
Chollet
comments
https
//gist.github.com/LysandreJik/c174a4fdc43004f5a2389f81d11444cd/5362a9236ed1d1739df7caa9e0d83a65ee07f2d0
https
//docs.python.org/2/library/timeit.html
timeit.Timer.repeat
min
average
@
thomwolf
number
bit
smaller
sequence
lengths
little
difference
time
suggestion
CSV/JSON
files
script
column
first
column
column
suggestion
dataset
datasets
Hub
suggestion
suggestion
eos
=
config.eos_token_id
bs
=
input_ids.shape
]
scores_that_should_be_inf
=
[
[
i
i
range
bs
]
+
[
i
i
range
bs
+
[
]
[
i
eos
i
range
bs
]
comment
scores
care
padding
options
tokenizer
@
patrickvonplaten
global
attention
mask
different
different
tasks
attention_mask
zeros
locations
tokens
patil-suraj
earlier
Change
attention_mask
None
attention_mask
no_global_attention_in_attention_mask
global_attention_mask
=
compute_global_attention_mask
same
code
None
attention_mask
=
global_attention_mask
attention_mask
combine
global_attention_mask
attention_mask
docstring
comment
equivalent
line
original
code
https
//github.com/zihangdai/xlnet/blob/bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660/data_utils.py
L381
copy
past
comment
algo
comment
plm
mlm
plm_probability
sequence
length
>
assert
statement
small
words
ctx
=
context_length
better
self.tokenizer.mask_token_id
convert_tokens_to_ids
nice
assert
statement
error
sequence
length
bit
weird
=
>
masked_indices
[
i
start_idx
start_idx
+
span_length
]
enough
start_idx
+
span_length
bigger
max_length
error
Python
n
span_length
self.max_gram
=
>
self.max_span_length
self.max_span_length_tokens_to_predict
code
much
clearer
Ca
something
=
start
+
max
min
start
better
name
=
>
n_gram_length
official
code
n_gram_length
https
//github.com/zihangdai/xlnet/blob/bbaa3a6fa0b3a2ee694e8cf66167434f9eca9660/data_utils.py
L351
important
torch.float32
clarity
suggestion
name
name
comment
May
GPT2
roberta
inherit
copies
initial
tensor
repeat
Tensor
specified
number
chunks
=
torch.distributed.get_world_size
Create
PyTorch
Tensor
pt_arr
=
torch.from_numpy
arr
.to
self.args.device
Repeat
tensor
specific
size
i.e
number
workers
=
pt_arr.unsqueeze
.repeat
.chunk
]
actual
data
other
torch.distributed.all_gather
[
]
suggestion
distributed
case
samples
right
order
crucial
prediction
instance
Additional
inputs/outputs
START/INPUTS
docstrings
forward
method
cf
BertForPreTraining
]
https
//github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py
L830-L877
important
same
API
other
models
reorder_encoder_out
similar
logic
generation
i.e
model.generate
method
encoder-decoder
models
work
decoder
models
better
logic
generate
method
base
class
derived
class
same
code
encoder-decoder
models
arguments
encoder_
prefix
related
argument
encoder
decoder_
prefix
related
arguments
decoder
preferred
signature
Seq2Seq
APIs
encoder_input_ids
encoder_attention_mask
head_mask=None
encoder
encoder_hidden_states=None
name
encoder_output
decoder_input_ids=None
decoder_attention_mask=None
caller
seq2seq
nature
model
e.g
BartForSequenceClassification
tokens
BartForSequenceClassification
input_ids=tokens
little
bit
explicit
happy
way
Cf
comment
forward
method
API
logic
inner
model
specific
model
BertForSequenceClassification
inputs
forward
method
cf
[
BERT
file
]
https
//github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py
L635
docstring
Pascal
case
caps
BART
Note
LayerNorm
completeness
default
standard
initialization
PyTorch
practice
good
idea
cached_states
decoder_cached_states
cached_states
correspond
decoder
🙃
Maybe
TODO
sure
deadcode
update
S3
Will
comments
sense
case
part
generate
method
base
class
PretrainedModel
start
docstrings
add_start_docstrings
decorator
language
generation
following
variables
decoder_outputs
encoder_outputs
variable
output
decoder_outputs
]
logits
lm_head
BartForMaskedLM
variable
cached_states
decoder_outputs
]
faster
decoding
variable
encoder_hidden_states
encoder_outputs
]
variable
inputs
first
decoding
step
afterwards
prepare_bart_inputs
Copy
docstring
template/BERT
great
same
style
library
docstrings
See
BERT
docstrings
example
https
//github.com/huggingface/transformers/blob/48ff6d5109d691e3630169962a5052586aaaf659/src/transformers/configuration_bert.py
L63-L92
Same
docs
suggestion
@
add_start_docstrings_to_callable
DEBERTA_INPUTS_DOCSTRING.format
docstring
DeBERTaConfiguration
object
Sam
worse
suggestion
@
add_start_docstrings_to_callable
DEBERTA_INPUTS_DOCSTRING.format
parenthesis
new
docstring
inputs
suggestion
model
PyTorch
torch.nn.Module
<
https
//pytorch.org/docs/stable/nn.html
torch.nn.Module
>
__
subclass
regular
PyTorch
Module
PyTorch
documentation
matter
general
usage
behavior.
links
references
obscure
sphinx
warnings
Same
copy
adapt
template
Please
new
value
part
docstring
template/BERT
file
suggestion
something
scale_factor
+=
len
self.pos_attn_type
cleaner
config.pos_att_type
list
strings
string
|
suggestion
wrapper
GPT2
tokenizer
similar
interface
BERT
docstrings
useful
class
docstrings
one
Mos
arguments
documentation
tokenizer
file
template
pass
@
slow
integration
test
tokenizer
model
mask
way
way
someone
refactors
code
performance
test
suggestion
suggestion
normal
attention
layer
implements
classes
[
't
forget
docstring
hidden_states.permute
sure
lines
letter
easier
few
sentences
warning
template
docs
..
warning
input
data
output
encoder
format
obj
[
batch_size
sequence_length
]
data
encoder
obj
[
batch_size
]
format
obj
inside
documentation
LysandreJik
nn.LayerNorm
understood
nit
pytimeout
code
duplicated
easy
+
performant
way
duplication
=
vars
f
f
features
top
dicts
things
times
comment
intro
notes
corresponding
code
own
function
code
logging.debug
purpose
comment
VAD
max_seconds
batch
window
time
length
comment
comment
TODO
nvidia.dali.plugin.pytorch
import
LastBatchPolicy
LastBatchPolicy
Dither
default
please
==========
Please
files
textclassificationmodel
needs
comments
docstings
Maybe
string
list
names
dictionary
pointing
paths
import
lib
poll
slack
default
directory
Please
vote
ModelCheckpoint
callback
trainer
checkpoint_callback=model_checkpoint_callback
callbacks
errors
https
//github.com/PyTorchLightning/pytorch-lightning/issues/1524
Good
catch
wrong
check
Im
worried
tokenized
data
fact
base
directory
~10-20
convergence
longer
convergence
10-20
epochs
something
similar
clear
epochs
steps
later
correction
User
code
todos
trails-
>
trials
keys
trial_embs
KALDI
PLDA
argument
save_kaldi_emb
part
code
save_kaldi_emb
code
same
condition
May
store
keys
trial_embs
dict
keys
line
Union
Hydra/OmegaConf
comments
todo
support
Width
Height
image
models
Same
comment
above
comment
slot_relation_file
lines
self.slots_relation_file
=
dialogues_example_dir
slots_relation_list.np
same
docstrings
comments
Could
comments
Please
comment
PL
NeuralModule
experimental
Remove
comment
strin
apis
full
name
prefix
optional
prefix
svc
xiv
nothing
code
blocks
same
bock
elif
else
Right
So
relevant
elif/else
comment
elif
block
msg
=
volume
array
name
self.identifier
res.get
RES_MSG
long
line
arguments
lines
volume
array
err_msg
=
name
self.identifier
res.get
RES_MSG
@
igorgonibm
info
docstring
function
other
comment
new
file
copyright
line
matches
WPILibJ
many
blank
lines
fact
blank
line
imports
odd
uh
baseurl
localhost
https
live
site
https
setting
git
default
account
name/email
today
arguments
baseurl
username
password
https
//localhost:3000
unauthorized
person
Anonymous
actual
reviewer
names
email
mandler
@
titian.cs.umass.edu
mandler
@
cs.umass.edu
Whether
argparse
important
superuser
password
previous
comment
example
[
script
]
https
//github.com/iesl/openreview-scripts/blob/master/iclr2017/python/export-members.py
arguments
username
baseurl
password
author
group
paper
number
blinded
note
original
note
right
@
mspector
kind
print
statement
exception
something
simple
print
profile
reason
worthwhile
possible
exception
something
other
error
contents
error
sure
error
raise
e
error
normal
function
openreview-py
library
tools
module
https
//github.com/iesl/openreview-py/blob/master/openreview/tools.py
L6
create
profile
library
https
//github.com/iesl/openreview-py/blob/master/openreview/tools.py
L17
profile
specific
call
profiles
id
outside
call
POST
notes
string
id
POST
notes
id
body
note
note
Obs
http
PUT
operations
object
POST
objects
POST
notes
PUT
POST
code
blind
submissions
config.BLIND_SUBMISSION
unnecessary
uppercase
email
member
reviewer
group
lowercase
email
uppercase
email
part
profile
lowercase
email
member
relationships
lowercase
group
signatures
readers
writers
tauthor
uppercase
email
lowercase
email
sure
uppercase
group
assign
function
library
https
//github.com/iesl/openreview-py/blob/master/openreview/tools.py
L275
same
code
conferences
pmandler
comments
name
question
oops
comment
date
domains
list
folders
parameter
same
templates
important
uncomment
emails
members
group
groups
members
input
body
safer
moment
scripts
groups
empty
active
users
errors
call
existent
groups
https
//openreview.net/groups
id=ICLR.cc/2018/Conference/Paper
*
/Authors
reviewer
group
admin-init.py
cc/
@
mspector
else
block
condition
True
correct
everything
other
root
groups
admin
group
admin-init
empty
process
function
message
stuff
suggestion
>
[
dict
]
fix
suggestion
assistance=
available
regions
United
States
type
PluginException
future
message
UI
suggestion
MAC
addresses
separator
suggestion
raise
APIException
cause=
A
region
lstrip
//
Users
able
URL
Fortinet
instance
https
//fortigate-vm02.vuln.lax.rapid7.com/ng/
rstrip
/
anything
suggestion
Run
function
TODO
comment
suggestion
Get
list
users
docstring
comment
best
function
documentation
Can
code
comment
something
orcehstrator
spec
workflow
spec
'cloud_ready
spec
manifest_obj
required_rapid7_features
=
[
orchestrator
screenshots
plugins
example
screenshots
spec
code
KeyError
something
similar
poll
same
function
logging
statement
send
functions
Same
comments
lines
need
comment
right
place
sure
i
comment
comment
Given-When-Then
suggestion
string
word
underscore
e.g
input
entry
copy
reference
use
copy.deepcopy
dont
different
requests
mocks
second
case
please
use
@
pytest.mark.parametrize
code
cases
first
time
suggestion
rn_desc
=
f
New
\n-
desc
\n
is_new_file
suggestion
rn_desc
=
New
\n-
desc
\n
is_new_file
%
%
UPDATE_RN
%
%
sure
i
comment
suggestion
Unit
test
Given
table
part
numbered
section
setup
section
integration
README
generate_table_section
command
Validate
table
beginning
line.
suggestion
REMOVE
condition
branches
task_condition_labels
UPPER
update
docs
expiration
validation
change
default
value
number
disabled
inline
comments
preferable
examples
example
func
hard
suggestion
Asserting
Dependencies
mandatory
non-mandatory
suggestion
Demisto
Bleve
DB
keys
cliName
suggestion
integrations
package
format
image
yml
wrong
reputations
field
reputations.json
comment
devs
reputations
field
schema
validate
command
Packs/CommonTypes/IndicatorTypes
sure
suggestion
'regex
key
new
reputations
files
'reputations
key
old
reputations
reputations.json
file
length
test
case
tuple
type
hints
docstrings
suggestion
reference
sub
reference
original
mention
comment
case
mapping
suggestion
reference
sub-schema
reference
original
suggestion
need
sub-schemas
suggestion
need
sub-schemas
lets
comment
logic
comment
unit
test
suggestion
CONTRIBUTOR_DETAILED_DESC
=
Integration\n
\
suggestion
'Please
following
contact
details
suggestion
'Support
maintenance
integration
author
\
suggestion
CONTRIBUTOR_DETAILED_DESC
=
Contributed
Integration
\
docstring
Can
object_type
docstring
message
comment
post
Just
safe
iterator
input
argument
details
output
exception
message
stack
trace
traceback.format_exc
unquoted
exception
setting
true
days
latest
weekly
email
user
valid
token
Might
empty
programs
none
courses
program
course
ids
instance
local
instance
RC
Analog
Learning
Digital
Learning
programs
sure
likely
production
small
typo
TBD
courses
mitx
availabilities
Current
Archived
point
PR
front-end
JS
code
]
https
//github.com/mitodl/open-discussions/blob/e710b62e1f39d02ec1dc065d745a87be6551b89b/static/js/lib/courses.js
L11-L20
values
[
course
data
import
]
https
//github.com/mitodl/open-discussions/blob/e710b62e1f39d02ec1dc065d745a87be6551b89b/course_catalog/task_helpers.py
L320
case
extra
positional
argument
*
args
user=None
warning
earlier
comment
case
patching
separate
fixture
actual
tests
clearer
fixture
celery.app.task.Task.replace
search.tasks.group
search.tasks.chain
other
celery
library
functions
future
return
value
fixture
exception
pytest.raises
assertion
something
pytest.raises
celery_mock.expected_exception
Anything
finicky
library
patching
actual
intent
tests
helpful
IMO
descriptive
comment
least
test
cases
worth
rid
boilerplate
patch
assertions
fixture
@
pytest.fixture
def
wrap_retry_mock
wrap_retry_exception
context
manager
test
wrap_mock
=
mocker.patch
'search.tasks.wrap_retry_exception
yield
wrap_mock.assert_called_once_with
PrawcoreException
PRAWException
def
test_index_post_with_comments
mocker
wrap_retry_mock
Suggested
comment
Celery
'group
function
generator
argument
order
assertions
items
generator
iteration
items
comment
comment
needs
Curious
way
request
i
choice
comment
nice
sure
edge
cases
user
function
logic
Same
remark
functions
commented
line
suggestion
INFO
G.M
2020-07-23
explicit
message
exceptions
unserialize_bookmark
method
sqlakeyset
explicit
message
See
https
//github.com/djrobstep/sqlakeyset/issues/34
comment
index
different
name
discussion
//github.com/tracim/tracim/issues/2401
issuecomment-565478710
suggestion
self.custom_toolbox_files
[
]
type
typing.List
os.DirEntry
suggestion
self.custom_toolbox_files
[
]
type
typing.List
[
os.DirEntry
suggestion
need
name
worker_job
fails
pytest
line
cryptic
little
self._run_middlewares
=
self._run_middlewares
subapp._run_middlewares
change
middlewares
deep
nested
subapps
app
>
>
subapp2
logins
-1
]
Please
comment
logins
]
empty
file
tab
Use
platform.system
Please
Application
TraceConfig
signature
Maybe
define
Signal
[
Callable
[
[
'Application
]
Awaitable
[
None
]
]
]
top
level
comments
qa
disable
case
exception
type
text
meaningless
end
user
text
consequence
reason
field
actual
problem
assertion
sake
mypy
assertion
way
mypy
assert
self.reason
None
simplest
possible
fix
test
case
Again
hints
comments
suggestion
self._expirations
type
Dict
[
Tuple
[
str
str
]
datetime.datetime
]
line
flake8
same
issue
noqa
flag
flake8
same
d
specific
suggestion
self._expirations
type
Dict
[
Tuple
[
str
str
]
datetime.datetime
]
noqa
E501
asvetlov
flake8-bugbear
flexible
line
length
project
black
future
’
good
addition
suggestion
TYPE_CHECKING
pragma
cover
pragma
cover
comment
line
coverage
tool
MyPy
sure
feedback
=
SimpleCookie
self._quote_cookie
BaseCookie
type
Union
[
SimpleCookie
[
str
]
BaseCookie
[
]
]
suggestion
event
await
event
=
self._throttle_dns_events
key
]
suggestion
result
await
result
=
self._cached_hosts.next_addrs
key
comment
meaning
__
[
Flake8
]
__
[
W292
]
newline
end
file
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
F401
]
unused
<
Comment
[
SideCI
]
https
//sideci.com
wrong
normal
user
new
version
changelog
manager
staff
view
HTML
template
button
visible
explicit
False
is_staff
=
False
lines
please
able
line
S3
same
Again
comments
lint
nothing
Please
change
python
enterprise_customer_name
[
:48
]
characters
fine
comment
enterprise_customer_name
characters
complete
name
format
Discount
type
site
enterprise_name
catalog_uuid
limit
characters
Oscar
name
instance
name
unique
catalog_uuid
name
Thats
enterprise_name
catalog_uuid
unique
constraint
Note
name
UUID
receipt
offer
name
company
offer
name
catalog
uuid
sense
end
user
georgebabey
programs
[
similar
approach
]
https
//github.com/edx/ecommerce/blob/master/ecommerce/programs/forms.py
L92
issue
Thoughts
comment
nit
actual
value
comment
program
vs
program_id
Could
last
sentence
Typo
TODO
LEARNER-XXXX
comment
new
ticket
clean-up
@
staubina
comment
own
statement
clear
log
message
case
log
message
cases
Delete
marketing
user.
add
TODO
LEARNER-XXXX
clean-up
story
comment
better
job
original
voucher
variable
case
possible
scenario
failure
consent
function
comment
Rather
siteconfig
option
enable
minimal
payment
fields
bool
way
/
different
sites
good
siteconfig
flag
Could
whats
github
comment
better
verification
course
way
clean
Exception
TestCreditProvider
rid
case
functional
right
credit
provider
hand
future
credit
courses
best
way
command
command
other
courses
json
variable
Just
store
line
part
above
Condition
query
comments
new
baskets
old
basket
comment
necessary
DynamicCustomerCondition
dynamic_discount_condition
Could
docstring
class
odd
discount_jwt
get
parameter
post
comment
semantics
comment
logic
inverse
actual
check
@
asadiqbal08
Ah
gotcha
glad
concern
comment
thanks
sure
test
log
error
add
comment
key
city
months
next
person
HttpNotFoundError
more
error
useful
note
Note
query
filter
product
types
course_id.
note
defensive
code
Note
query
filter
selective
product
types
course_id.
test
test_set_enterprise_cookie
line
35-36
same
comment
statement
docstring
docstring
multiple
values
enterprise
customer
uuid
test
None
state
other
none
assert
test
docstring
nit
move
comment
condition
comment
oh
pete
sake
enterprise
coupons
ranges
comment
Reviewers
Implement
TODO
part
ticket
ARCH-XXX
comment
different
ticket
info
safety
net
anything
TODO
change
decorator
comment
Faker
decorator
factory
dependent
decorators
factory
faker
lambda
issue
idea
switch
tests
test
suggestion
more
sense
order
fake
url
@
mock_course_catalog_api_client
decorator
refactor
PR
comment
Decorator
SiteConfiguration.discovery_api_client
mocks
mock_dynamic_catalog_single_course_runs_api
factory
discovery_api_url
discovery
client
faker
decorator
urls
Use
faker
http
//faker.readthedocs.io/en/master/providers/faker.providers.internet.html
highlight=url
faker-providers-internet
>
i
common
option
types
scripts
option
sleep
updates
couple
seconds
only
first
enterprise
customer
LMS
endpoint
returns
useful
command
enterprise
customer
uuid
ecommerce
coupon
specific
enterprises
line
site
=
SiteConfiguration.objects.first
None
class
logger.exception
cutoff
date
[
CommandError
]
https
//docs.djangoproject.com/en/1.11/howto/custom-management-commands/
django.core.management.CommandError
issue
msg
=
cutoff
date
cutoff_date
logger.exception
msg
raise
CommandError
msg
pylint
disable=unused-variable
unused
variable
comment
parameter
test
ecommerce/enterprise/tests/test_entitlements.py
necessary
valid
argument
premature
optimization
other
selenium
instances
test
run
clintonb
cool
premature
call
necessary
other
selenium
instances
guess
TODO
PR
ticket
versus
track
future
development
work
code
mattdrayer
ticket
https
//openedx.atlassian.net/browse/ENT-159
TODO
TODO
PR
ticket
versus
track
future
development
work
code
feasible
explicit
possible
exceptions
simple
return
waffle.switch_is_active
settings.ENABLE_ENTERPRISE_ON_RUNTIME_SWITCH
comment
Marketing
email
bounces
code
path
corresponding
OfferAssignment
i
need
comment
relevant
git
history
comment
sure
flow
everything
static
page
correct
thing
rest
flow
explicit
sort
order
-id
.first
methods
lot
logic
serializers
both
>
strings
I18N
Unnecessary
comment
comment
catalog
more
course
attach
loong
time
true
catalog
query
seat/course
information
case
i
predicates
similar
data
api
PR
https
//github.com/edx/edx-enterprise-data/pull/112/files
diff-6c49a377b4da1d1d150c51be9f4afffeR19
nitpicky
thing
args
function
definition
user
args
*
*
kwargs
nit
typo
contrant
COURSE_ENTITLEMENT_PRODUCT_CLASS_NAME
exception
https
//docs.python.org/2/library/logging.html
logging.Logger.exception
logger.exception
python
logger.exception
basket
discount
SKUs
[
<
comma-separated
list
>
]
[
<
code
>
]
value
unexpected
exceptions
parameters
exception
mechanism
oscar
receipt
page
filter
method
Did
something
@
clintonb
Please
techdebt
ticket
comment
code
good
solution
issue
moment
Where/how
format_benefit_value
methods
conditional
offer
details
benefit
details
record
https
//s-media-cache-ak0.pinimg.com/736x/79/28/2b/79282b550b4bc6d13dfd6ea87e12eb79.jpg
Oscar
mechanism
value
receipt
page
https
//github.com/edx/ecommerce/blob/39151c18cd187f59fa73efcf8b6ebfd62c10228f/ecommerce/templates/edx/checkout/receipt.html
L100-L119
Replicate
further
customization
case
discount
value
basket
page
sure
comment
someone
waffle
flag
temporary
ticket
flag
mixin
PR
My
opinion
Entitlement
part
comment
generic
Range
method
helpful
docstring
code
comment
use
case
block
Bookings
limit
course
price
amount
course
price
offer
course
%
offer
’
limit
course
%
offer
’
limit
nit
enterprise
offer
upto
times
times
Comment
Offer
data
current
request
nit
code
dead
code
repo
Value
seconds.
case
consistency
sake
comment
🎱
minor
code
clear
comment
Lets
sure
big
comment
base
permission
class
priority
constants
descriptive
VOUCHER_PRIORITY
ENTERPRISE_OFFER_PRIORITY
=
docstring
method
catalog
offer
catalog
basket
Did
threshold
adjustable
runtime
sort
configuration
good
practice
excepts
type
exception
Might
worth
threshold
warning
picky-
good
call
🎱
unit
test
contents
something
CSV
sure
file
download
functionality
processing
functionality
easy
accident
actual
data
CSV
sure
personal
data
US
government
list
PII
....
comment
helpful
switch
Again
comment
helpful
batch
index
pk
comment
leftover
populate_sdn_fallback_data_and_metadata
method
regular
data
records
docstring
class
tests
ProductViewSetCourseEntitlementTests
comfortable
Course
Entitlement
docstring
Feels
something
dashboard
assertion
Best
difficult
reason
please
minimum
LMS
assertion
comment
access
LMS
pragma
cover
acceptable
failure
case
Get
rid
pragma
cover
conditional
new
private
function
descriptive
name
comments
lines
line
comment
functionality
correct
element
path
typo
example
last
sub_dir
erroneous
sub_dir
middle
Noah
comment
potential
directory
reorganizing
indexing
experienced
tempfile
potential
way
anything
bounds
length
valid_parts
TemporaryDirectory
path
easiest
consistent
way
ellipse
w/
random
values
little
bit
something
pixel
value
up/down/left/right
generate
thick
ellipse
coords
_perimeter
membrane
ellipse
nuclear
xx
=
skimage.draw.ellipse_perimeter
cx
cy
rx
ry
rotation=angle
generate
corruption
coordinates
xx_cor
=
xx
+
np.around
*
np.random.rand
*
xx.shape
-0.5
yy_cor
=
yy
+
np.around
*
np.random.rand
*
yy.shape
-0.5
signal
ellipse+corruption
values
signal_data
=
np.zeros
size_img
signal_data
[
xx
yy
]
signal_data
[
xx_cor
yy_cor
]
return
signal_data
example
output
something
[
example
]
https
//user-images.githubusercontent.com/36260163/89069584-48196d80-d328-11ea-824e-f4fde0956ed0.png
Ah
OK
comment
sure
prob_mask
placeholder
intermediate
calculations
current
way
probability
values
entire
image
certain
non-square
subset
intermediate
variable
next
version
nuclear
expression
best
way
prob_mask
topographical
map
mountain
higher
values
higher
elevation
highest
value
center
values
further
center
probability
representation
higher
values
closer
center
distribution
earlier
comment
function
default
dependence
data_utils
test
functions
kinda
thing
earlier
np
unique
comment
comment
@
ngreenwald
@
clear
non-cell2cell
distances
fov_data
[
cell_label_col
]
indexes
rows
columns
cell2cell
distances
case
calc_dist_matrix
spatial_analysis_utils
dist_matrix
function
non-cell2cell
distances
least
summary
helpful
further
non-cell2cell
distances
context
function
function
create_neighborhood_matrix
Alex
comments
earlier
logic
something
np.unique
returns
sorted
order
positive
ids
ids
]
nuclear_mask_id
=
ids
np.argmax
]
]
nuclear_mask_id
=
None
one-line
ternary
statement
little
messy
See
comment
i
'test
file
lol
line
Rather
loop
beginning
specific
reason
is_mibitiff
True
points
list
names
points
[
Point1
Point2
]
mibitiff_files
argument
list
full
file
names
ex
[
]
points
current_points
subset
points
regex
match
MIBItiff
files
desired
Point
prefixes
os.listdir
Points
test
OK
default
time
MIBItiff
file
name
Point8.tif
Point8.tiff
Noah
comment
nuanced
delimiter
splitting
PR
complicated
names
points
None
clearer
conditional
mibi_tiff
output
data
ready
calc_dist_matrix
better
understanding
best
practice
asserts
actual
test
functions
pretty
sure
a_a_dist
symmetric
real
harm
symmetry
anyways
big
matrices
performance
drop
comment
negligible
performance
difference
matrix
covariance
tuple
sigx
sigy
theta
covariance
matrix
something
generate
scale
=
np.array
[
[
sigx
*
*
]
*
]
]
generate
rotation
matrix
s
=
np.sin
theta
theta
rot
=
np.array
[
[
c
-s
]
[
s
]
]
compute
covariance
matrix
cov
=
rot
*
scale
*
final
matrix
symmetric
positive
definite
possible
cases
separate
function
method
random
distance
matrix
non-physical
results
case
cell-A
plane
distances
a23
geometric
cases
cells
co-linear
reordering
a12
+
a23
=
a13
true
cells
triangle
inequalities
a12
+
a23
<
a13
+
a23
<
a12
+
a13
<
a23
method
distance
matrices
criteria
un-physical
situations
Rather
function
use
get_random_centroid_centers
point_init_dist_matrix
defaults
mean_C
comment
lines
need
new
variables
distr_AB
necessary
different
name
row
single
row
answer
un-needed
oopsie
direct_init_dist_matrix
comment
segmentation
mask
pixels
cell
center
actual
cell
pixels
cell
way
im
cell_coords
num_cells-by-2
array
num_cell_coords
cell_coords.shape
]
compute
centroid
centroid
=
np.sum
cell_coords
axis=0
/num_cell_coords
compute
distances
ord=np.inf
box
norm
ord=2
regular
euclid
time
default
=
np.linalg.norm
cell_coords
centroid
axis=1
idk
weighting
current
version
weights
distances/
np.max
distances
=
image_data.values
tuple
cell_coords.T
lined-up
channel_counts
weights.dot
channel_values
few
indexing+typos
bit
inefficient
image_data
array
array
Most
cells
pixels
~500
cells
image
sure
ogrid
pretty
better
way
regionprops
example
coordinates
bounding
box
cell
regionprops
cell
image
centroid
things
centroid
function
threshold
value
Let
new
synthetic
data
function
signal
extend
pixel
boundaries
weighting
reduced
counts
wrong
marker
wrong
cell
comment
better
way
amount
bleedover
less
naive
extraction
function
good
comments
cryptic
sure
comment
loop
entire
loop
other
markers
single
iteration
loop
someone
code
cells
positive
kth
marker
Let
move
cells
positive
markers
j
k
great
descriptive
patient_data_markers
function
example
closenum
example
data
closenum
more
clear
point
function
dict
col_names
equal
everything
brackets
pandas
arrays
call
.rename
col_names
axis=1
way
img_data
fact
python
bindings
boost
variant
python
support
correction
[
~~~~
dependency
boost
python
dependency
boost
explicit
dependency
boost
depends_on
'boost~python
when='~python_bindings
depends_on
'boost+python
when='+python_bindings
boost
python
explicit
depedency
good
practice
worth
descriptive
name
comment
-1
magic
next
reader
Can
patch
comment
suggestion
Copyright
2013-2020
Lawrence
Livermore
National
Security
LLC
other
Spack
Project
Developers
top-level
COPYRIGHT
file
details
SPDX-License-Identifier
Apache-2.0
OR
MIT
comment
something
>
libxpm
external
package
gettext
available
spec
https
//github.com/spack/spack/pull/10881
details
refactor
Could
comment
relevant
bug
report
https
//bugzilla.mozilla.org/show_bug.cgi
id=638056
installed
files
least
comment
question
logic
possibility
padding
length
larger
new
exception
someone
comment
darwin
few
references
rid
Sorry
[
comment
]
https
//github.com/spack/spack/pull/19672
pullrequestreview-521844640
Remove
comments
license
blas/lapack
packages
responsible
task
package
query
parameters
libs
[
hdf5
]
https
//github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hdf5/package.py
L107-L167
same
i
headers
idea
something
spec
[
'lapack
e
]
.headers
query
parameter
topic
lapacke
i
https
//github.com/spack/spack/pull/7501/
anymore
conflict
specific
version
suggestion
MPICH
Yaksa
submodule
comment
few
lines
statement
Apple
line-by-line
list
comment
clang
line
clang
[
c99-gcc
-nm
clang
clang++
matches
reason
nervous
interested
install_tree
copy_tree
anything
blank
line
end
file
flake8
necessary
resource
line
Please
FIXME
stuff
license
patches
spack/spack
subset
hash
first
characters
comment
same
package
multiple
patches
same
name
different
contents
subset
hash
qualification
collision
necessary
few
other
spots
compilers
dependencies
long
discussion
//github.com/spack/spack/issues/896
cxx14_flag
flag
least
error
version
c++14
suggestion
PyPI
latest
version
release
candidate
stable
variants
depends_on
descriptions
GRASS
package
GDAL
GDAL
with-grass
option
circular
dependency
GRASS
GDAL
GDAL
GRASS
familiar
GRASS
template
stuff
license
type=build/run
things
Python
libraries
default
deptype
headers
type='link
suggestion
def
view_copy
src
dst
view
spec=None
file
src
Use
spec
view
relocations
suggestion
commands
comment
v
lines
note
https
//github.com/spack/spack/pull/7469
better
way
correct
@
mgsternberg
shutil.copy
favor
dst
=
shutil.copy
src
dest
function
override
necessary
spack
url
parse
https
//github.com/ocaml/opam/releases/download/1.2.2/opam-full-1.2.2.tar.gz
==
>
Parsing
URL
https
//github.com/ocaml/opam/releases/download/1.2.2/opam-full-1.2.2.tar.gz
==
>
Matched
version
r'^
a-zA-Z+._-
]
+
[
._-
]
v
\\d
[
\\d._-
]
*
==
>
Matched
name
r'github\\.com/
[
^/
]
+/
[
^/
]
+
==
>
https
//github.com/ocaml/opam/releases/download/1.2.2/opam-full-1.2.2.tar.gz
~~~~~
name
opam
version
==
>
version
https
//github.com/ocaml/opam/releases/download/9.9.9b/opam-full-9.9.9b.tar.gz
args
setup_environment
conversion
package_prefs.spec_externals
enforcement
conversion
more
sense
values
guess
latter
@
jgalarowicz
commented
code
worthwhile
default
phases
cmake/build/install
Spack
flag
part
base
package
default
work
variant
other
packages
incompatibility
CUDA
issue
https
//github.com/clara-parabricks/GenomeWorks/issues/570
CUDA
CUB
GenomeWorks
sub-modules
patch
installation
CUDA
<
forbidden
depends_on
flags
compiler
self.compiler.cxx11_flag
compiler
@
gartung
check
patchelf
print-rpath
try/except
reader
check
comment
helpful
get_existing_elf_rpaths
IMO
check
sethrj
IMO
more
examination
necessary
'gcc
key
multiple
times
loop
expectation
such
gcc
file
suffix
criteria
logic
more
straightforward
bin_names
os.listdir
bin_path
exe_name
[
'gcc
g++
]
suffix
GccCompiler.suffixes
alt_names
list
x
x
bin_names
re.match
exe_name
+
suffix
x
alt_names
compiler_names
exe_name
]
=
[
]
break
suggestion
less
clear
problem
same
more
explanation
-style
comment
e.g
make
clean
installation
whole
method
build_directory
=
package-level
build
method
suggestion
SOFA
likely
present
most
systems
only
line
Delete
everything
good
case
bug
Spack
core
issue
steps
following
build
dependencies
m4
libtool
automake
autoconf
cleaner
patch
=
'patch
patch
'-p0
'verrou/valgrind.diff
version
Spack
default
autoreconf
method
sure
conflicts
checks
spec
valid
LMod
conflicts
statement
reason
systems
library
python_lib_path
[
'python
]
.libs
works
suggestion
num
compile
jobs
wrf
Spack
make_jobs
argument
value
spack
install
-j
X
suggestion
csh
'-j
int
make_jobs
>
caches
module
level
difficult
test
failures
look
IMO
worth
TODO
worth
mutable_config
fixture
everything
configuration
original
state
side
effects
functions
Cool
look
modifications
comment
idea
version
setuptools
breaks
things
comment
https
//github.com/berkerpeksag/astor/issues/162
way
work
suggestion
root_cmakelists_dir
src
None
complexity
appropriate
flags
cmake_args
CMakePackage
base
class
std_cmake_args
cmake_args
issue
issue
base
class
+python~docs
~python+docs
Sphinx
Python
support
*
*
*
documentation
*
*
*
*
python
depends_on
'py-sphinx
when='+python
depends_on
'py-sphinx
when='+docs
Python
support
Python
dependency
CMake
flags
variant
URL
versions
URL
mean
possible
variorum+python~shared
case
conflicts
suggestion
depends_on
@
type=
build
brief
comment
API
deprecates
previous
API
other
version
numpy
suggestion
TODO
Gentoo
website
BerkeleyDB
archives
suggestion
newer
versions
login
gentoo
mirror
author
line
unit
tests
old
APIs
setup_environment
setup_dependent_environment
new
APIs
setup_build_environment
setup_run_environment
setup_dependent_build_environment
etc
docstring
description
Need
description
suggestion
depends_on
@
:10.2.89
when=
@
:2.5.3
incompatible
CUDA
suggestion
depends_on
@
:10
when=
@
:2.5.3
incompatible
CUDA
case
new
CUDA
releases
everything
license
python
depends_on
type='build
when=
@
master
open
version
range
master
higher
@
master
valid
brief
comment
OCAMLPARAM
build
function
def
build
spec
prefix
make
'lib-ext
spec.satisfies
@
:1.2.2
make
'man
expensive
find
afterwards
necessary
logic
suggestion
Exit
libtool
self.patch_libtool
return
libtool
find
self.build_directory
'libtool
recursive=True
-based
comments
space
Acceptable
python
Other
LGTM
comments
excellent
state
diagram
e.g
prior
code
red
line
>
OS
termios
code
termios
sure
block
anymore
inclined
diagram
class
excellent
great
yeah
comment
protocol
read
bg
SIGTTIN
SIGTTIN
call
EIO
signal
docstring
idea
parent
child
process
Done
Note
https
//docs.python.org/3/library/os.html
section
openpty
mentions
non-inheritable
problem
Windows
Python
>
=
Mac
OS
doc
pty
module
portable
useful
child_process
better
name
track
process
matter
_child_process
_set_up_and_run_child_function
follow-on
PR
thing
comment
offs
good
tighter
bound
test
function
v
latency
something
proportional
number
ons
offs
*
output
simple
name
worth
docstring
issues
SIGTOU
error
running
process
proc
attrs
order
API
boilerplate
comment
functions
class
document
class
level
true
non-conditional
requirements
own
statement
python
depends_on
+regex+filesystem+system+icu+program_options
depends_on
@
:1.72.0
when=
depends_on
@
:1.69.0
when=
work
docstring
symbols
Same
comment
-DCUDA_TOOLKIT_ROOT_DIR=
Flake
whitespace
points
exec_module
work
suggestion
spack
amd
gpu
abstraction
suggestion
equivalent
call
end
comment
something
obvious
need
comment
closer
code
comments
call
env_mod.prune_duplicate_paths
need
TODO
question
approach
mock
non-mock
packages
trouble
https
//github.com/spack/spack/pull/13249
discussion_r336248474
>
builtin.mock
packages
new
API
backwards
compatibility
old
API
Was
complication
try
/
package
mock
repo
meaning
comment
order
|
rule
>
target
string
REs
'|
pattern
matches
branch
[
Python
regex
docs
]
https
//docs.python.org/3/library/re.html
problem
different
FIXME
constraint
meson
dependency
spack
spec
atk
See
python3
dependency
@
higher
depends_on
depends_on
when=
@
main
problem
first
place
clear
depends_on
line
comment
common
arguments
python
arguments
[
silent
disable
interactive
prompts
compiler
version
checks
toolkit
install
CUDA
Toolkit
]
spec.satisfies
arguments.append
installpath=
%
s
%
prefix
arguments.append
%
s
%
prefix
runfile
*
arguments
-block
intermediate_mode
None
bit
for-loop
specific
b/c
MPI
providers
configuration
providers
same
virtual
dependency
same
DAG
own
edification
*
case
backend
MPI
Charm++
MPI
symbol
conflicts
runtime
test
deptype
available
@
Sinan81
package
description
template
placeholder
text
suggestion
F95FLAGS=
-O3
-std=f2003
-ffast-math
.format
self.compiler.pic_flag
sure
other
flags
-fPIC
compilers
suggestion
F95=
+
spack_fc
Spack
compiler
wrappers
compilers
compiler
different
name
Hmm
external
charm++
installation
build
times
users
dependencies
Spack
nightmare
hard
libpng
@
Spack
depends_on
Never
system
package
manager
spec.satisfies
%
intel
user
intel-mpi
intel-parallel-studio+mpi
GCC
compilers
compiler
flags
relevant
Intel
compiler
>
hsa
requirements
setup.py
+future_regex
variant
optional
version
requirement
suggestion
depends_on
'py-pytest-mypy
type='test
setup.py
suggestion
Package
default
comment
provenance
patch
latest
commit
branch
dependencies
Prior
ch-grow
manual
make
file
build
sure
much
matters
issue
more
older
versions
Charliecloud
python
test
suite
line
bash
harness
bats
depends_on
type='test
depends_on
type='test
legacy
build
system
manual
build
process
something
more
explicit
following
suggestion
Use
skopeo
umoci
older
ch-grow
version
lib/spack/llnl/util/filesystem.py:1393
[
F821
]
name
lib/spack/llnl/util/filesystem.py:1398
[
F821
]
name
first
part
removal
order
[
x/
x/y
]
removal
order
[
x/y
x/
]
logic
x/y
x/
error
Sorting
shorter
paths
abspath
everything
mixture
files
directories
file
directories
issue
[
x/
x/y
]
case
x/
x/y
error
user
absolute
paths
issue
Exception
excludes
KeyboardInterrupt
exceptions
guard
minor
name
src
tmp_path
dst
clear
feel
free
hand
os.realpath
chain
symlinks
useful
relative
correct
path
TODO
worthwhile
comment
i.e
realpath
relative
symlinks
unsafe
docstring
method
absolute
symlinks
explicit
IMO
detail
path_names
absolute
docstring
md5
point
older
packages
new
packages
sha256
homepage
current
releases
current
@
alalazo
Do
way
self.spec.libs
dir
build
time
module
creation
time
setup_environment
separate
functions
script
comment
comment
test
test
relative
RPATH
ORIGIN
comment
anything
python
maintainers
[
'pinnown
]
class
definition
bullet
https
//spack.readthedocs.io/en/latest/packaging_guide.html
creating-editing-packages
description
tbh
default
stacks
I/O
libs
HDF5
NetCDF
ADIOS1/2
large
applications
busy
thesis
compiler
F90FLAGS
Users
Intel
background
%
gcc
url
Update
url
Update
url
Python
many
dependencies
earlier
versions
specific
dependency
versions
All
versions
depends_on
r
type=
'run
depends_on
r
when=
@
type=
'run
depends_on
when=
@
type=
'run
depends_on
'py-jinja2
when=
@
type=
'run
depends_on
'py-six
when=
@
type=
'run
depends_on
r
when=
type=
'run
depends_on
'py-singledispatch
@
:2
type=
'run
last
line
things
nice
Python
support
newest
version
response
comment
s
race
directory
user
sufficient
user
RW
access
llnl.util.filesystem.can_access
directory
creation
user
directories
user
FIXME
block
Remove
FIXME
comment
Can
variables
cmake_args
else
clause
true
Python
Python
python
executable
spec
[
'python
]
.command.path
url
Update
url
terms
terminology
Spack.Spec.traverse
DAG
x-
>
y-
>
z
x
y
y
depends
z
post-order
means
[
z
y
x
]
sure
something
different
reversal
to_deactivate_sorted
preordered
traversal
correct
comments
e.g
lines
following
comment
>
order
view
dependents
dependencies
line
clarity
declaration
to_deactivate_sorted
order
view
dependents
dependencies
=
list
depmap
=
dict
to_deactivate_sorted.reverse
Does
reasonable
sorting
comment
line
http
//spack.readthedocs.io/en/latest/getting_started.html
highlight=binutils
binutils
G-Ragghianti
variant
future
Likewise
package
use
cblas/scalapack
future
variants/deps
useful
useful
Flake
space
depends_on
comments
space
Flake
indentation
conflicts
optional
msg
comment
version
others
semver
problematic
thinking
@
adamjstewart
Do
experience
package
vsc-install
EasyBuild
v4.0.0
newer
vsc-base
EasyBuild
newer
https
//easybuild.readthedocs.io/en/develop/EasyBuild4-overview-of-changes.html
no-more-required-python-packages
boilerplate
lines
Everything
pretty
standard
configure_args
remark
future
expansions
Update
url
Same
above
optional
installed
argument
bowtie
issues
older
versions
reliable
conflict
statement
case
comment
spack/spack
Can
uncomment
dependencies
.0
versions
worthwhile
versions
x.y.z
format
https
//github.com/spack/spack/issues/6524
python
package
@
chissg
getattr
eval
above
comment/noqa
variants
dependencies
conflicts
suggestion
make-wrappers.py
wrapper
generator
script
build-time
run-time
Python
libraries
current
deptype
incorrect
extra
indentation
new-line
characters
spack
info
output
something
python
foo=
parentheses
Python
Just
space
end
line
python
foo=
problematic
Spack
air-gapped
networks
downloads
Spack
closer
look
script
resource
calls
section
Packaging
Guide
resources
docs
aren
’
great
suggestion
library
small
causes
much
harm
new
license
recent
file
single
condition
suggestion
Singularity
container
support
spec.satisfies
'+singularity
@
:4.9
singularity_opt
=
with-singularity=
spec
[
'singularity
]
.prefix
config_args.append
singularity_opt
work
suggestion
Fix
bug
configure.ac
issues
RHEL
<
version
>
<
compiler
>
install
adios
patch
applies
errors
older
version
Otherwise
suggestion
patch
//github.com/ornladios/ADIOS/pull/207.patch
sha256=
<
please_add_sha256
>
when=
WTF
....
integers
precious
problem
normal
biologists
v1.2.2
certain
*
<
img
width=
alt=
screen
pm
src=
https
//user-images.githubusercontent.com/312978/50570670-6b44fb00-0d48-11e9-9413-bb14358a4137.png
>
conflict
versions
one
package
version
compiler
conflicts
things
problems
someone
problem
conflict
rid
comment
info
visit
better
comment
docstring
way
need
suggestion
self.run_tests
variants
things
only
change
unit
tests
test=root
flag
variant
data/
directory
part
examples
build
able
default
parameters
default
libceed
makefile
e.g
makeopts
%
%
spec
AFAIK
FASTMath
package
suite
@
balay
dependency
FIXME
stuff
license
outdated
comment
hash
end
hash
Flake8
blank
lines
stuff
new
users
first
package
@
alalazo
way
*
build_type
Debug
CPU
backend
OpenMP
dependency
comment
patch
provenance
convenient
next
guy
package
hard
old
version
package
wx
reason
comments
license
able
url
use
config_dict
functionality
environment.py
name
top-level
key
environment
users
able
software
container
http
//www.cpan.org/src/README.html
maintenance
release
Maintenance
releases
section
policy
versions
Perl
policy
releases
maintenance
numbered
releases
development
link
page
comment
End
life
releases
Honestly
Misc
releases
End
life
releases
Misc
releases
section
End
life
section
msg
attribute
comment
user
%
apple-clang
compiler
>
typo
release
>
typo
compilers
>
compiler
python
depends_on
@
:1.6
when=
@
:0.13
dependency
version
Which
URLs
docstring
true
bug
ch_grow
Variants
dash
variant
name
default
>
Requires
local
build
BLAS
unfortunate
Spack
baberlevi
comment
PR
thread
i.e
own
versions
libxml2/libxslt
case
fine
as-is
suggestion
depends_on
@
type=
build
CMake
>
dependency
build-time
suggestion
filter_file
'/usr/local/harris
prefix
'silent/idl_answer_file
able
regular
url
need
url_for_version
suggestion
env.prepend_path
self.prefix.idl.bin
default
autoreconf
method
similar
Did
default
work
fixme
message
deactivated
triangle
variant
triangle
bug
configure
fallback
qhull
lines
variant
depends_on
configre_Args
Therefore
fixme
fixme
comments
variant
line
reason
python
@
multi-valued
variant
openssl
gnutls
Spack
syntax
self.spec
question
depends_on
'berkeley-db
slapd
depends_on
slapd
curious
sense
~client_only+perl_backend
conflicts
lot
conflicts
depends_on
statements
conflicts
concretizer
suggestion
args.extend
[
'-DUSE_OPENCL=OFF
top
file
homepage
BLAS
provider
spec
[
'blas
]
.name
==
spec
suggestion
version
'master
last
variants
package
users
dependencies
console
install
tangram
@
adamjstewart
deepcopy
function
right
IMO
explanatory
-style
comment
useful
suggestion
rbconfig
=
/lib/ruby/
.0/x86_64-linux/rbconfig.rb'.format
self.spec.prefix
self.spec.version.up_to
purpose
options
OPTION
build
necessary
comment
package
particular
needs
files
calls
things
packages
Versions
Variants
Dependencies
Conflicts
Functions
configure_args
variant
versions
dependencies
fl
package
something
something
comment
lines
necessary
regression
test
logic
Good
catch
bug
possibility
empty
list
directory
test
comment
date
@
adamjstewart
https
//github.com/spack/spack/pull/8613
issuecomment-412738031
wording
way
something
package
author
work
core
e.g
PackageViewMixin
symlink
jar
files
lib/ext
Other
good
justintoo
author
package
Spack
ability
maintainers
package
major
change
package
Okay
Greg
@
safe
change
install
install_tree
glob
characters
possible
work
install
*
.h
prefix.include
install
*
.hpp
prefix.include
older
code
line
breaks
kind
funny
problematic
Spack
philosophy
package
installation
package
own
prefix
package
resource
spiral
package
activation/deactivation
hcol
spack
activate
hcol
hcol
own
prefix
spiral
installation
prefix
python
package
example
experience
scheibelp
@
alalazo
@
becker33
proper
way
activate
deactivate
extendable
package
part
install
phase
lot
print
statements
package
FIXME
stuff
license
_not_
GCC
~atomic
atomic=False
possible
version
boost
default
variants
users
multiple
copies
boost
@
Zehvogel
boilerplate
comment
tests
Zehvogel
tests
boilerplate
comment
@
alalazo
everything
good
IMO
test
fragile
example
hashing
algorithm
changes
test
flags
concretized
Specs
case
test
compiler
flags
worth
comment
issue
e.g
Spack
flags
manner
different
orderings
repeated
concretizations
same
spec
config
Someone
reading
worth
time
name
[
'_instance
'instance
]
comment
while
part
Windows
fork
true
need
underscores
variables
functions
private
docstring
Could
line
thing
configure
advantage
more
dependencies
good
assumption
self.spec
[
'ncurses
]
comment
PGI
compilers
end
GCC
Intel
package
suggestion
return
http
//ftp.mcs.anl.gov/pub/petsc/release-snapshots/petsc-lite-
.tar.gz
.format
version
Python
support
other
function
definitions
@
sknigh
patch
come
IMO
worthwhile
link
summary
patch
worth
prefix
install
function
prefix.bin
install
function
install
'tcptrace
prefix.bin
'cp
line
sorry
i
logic
actual
header
package
‘
-openmp
’
default
intel
gcc
Could
above
comments
suggestion
config_args.append
enable-mca-no-build=btl-uct
comment
additional
directory
level
HPC
SDK
bin
lib
example
compilers
prefix/compilers/
bin
lib
necessary
PATH
suggestion
FrontFlow/red
Fortran
format
I/E
width
Example
suggestion
FrontFlow/red
Fortran
format
I/E
width
Example
version
http
//spack.readthedocs.io/en/latest/packaging_guide.html
version-comparison
comment
same
previous
line
comment
suggestion
Patch
fetch_strategy
util.executable
symbol
monkeypatch.setattr
spack.fetch_strategy
'which
_which
alternative
import
fetch_strategy.py
module
symbol
reference
//github.com/Sleepyowl/doxygen/commit/6c380ba91ae41c6d5c409a5163119318932ae2a3
comment
convenient
way
anybody
patch
spec
[
'python
]
.command
run-time
easier
install_args
dependency
beginning
setup.py
imports
versioneer
present
most
Python
installations
py-basemap
package
type=
'run
setuptools
build
time
https
//github.com/mysql/mysql-connector-python/blob/master/setup.py
L40
dependency
py-protobuf
@
https
//github.com/mysql/mysql-connector-python/blob/master/setupinfo.py
L139
typo
>
note
variant
mwkrentel
risky
useful
comment
glad
evil
sources
requests
older
versions
worthwhile
constraint
depends_on
when=
@
x.y
versions
binutils
+rpath
@
best
way
dependencies
variants
individual
variants
Example
+tmva
+gsl
+math
tmva
gsl
math
single
variant
Python
R
packages
type=
'run
such
thing
ssl
virtual
concrete
package
Spack
Did
openssl
generic
SSL
implementations
case
support
Spack
ints
strings
suggestion
mkdir
prefix.modules
suggestion
install_tree
'modules
prefix.modules
suggestion
install
CMakeToolsConfig.cmake
prefix
dependencies
python
REQUIRED_PACKAGES
=
[
futures
backport
python
concurrent.futures
module
'futures
=
python_version
>
>
>
>
>
>
python3
python_version
>
=
python_version
https
//github.com/spack/spack/pull/15235
issuecomment-598604206
comment
:3.2~hydra+libxml2
@
:3.2~hydra+lixml2
same
mpich
installation
clearer
>
mpich
libxml2
versions
~hydra
prevent
users
~libxml2
case
identical
mpich
installation
comment
Update
url
kind
variants
bit
controversial
Spack
-allpkgs
+every_other_variant
different
spec
+allpkgs
-every_other_variant
+allpkgs
+some_variants
ideal
way
same
thing
variant
other
variants
many
suggestion
'quantum-espresso
@
spec
'^mkl
spec
intel-mkl
intel-parallel-studio+mkl
packages
MKL
libraries
Same
Drop
line
URL
comment
Same
part
worth
TODO
FIXME
comment
kind
tests
becker33
packages
Commented
code
Should
patch
Does
python
build
dep
IMO
worth
-style
comment
not-yet-existing
compiler
only
workaround
mind
symengine
trilinos+debug
build_type=Debug
trilinos~debug
other
cases
sense
comments
correct
way
blas
libraries
spec
line
new
package
use
case
v1.5.3
v1.6.3
good
substitute
Asking
v1.5.3
needs
real
use
case
latest
version
faiss
previous
ones
suggestion
setup_py
prefix=
+
prefix
single-version-externally-managed
extra
args
care
egg
problem
correct
way
python
conflicts
'+tests
when='~python
msg='+tests
+python
class
same
level
depends_on/variant/etc
comment
accurate
extends
python
prefix
spack
activate
command
suggestion
working_dir
'tests
make
'tests
run-time
suggestion
suggestion
working_dir
'test
suggestion
prefix
separator
lines
suggestion
working_dir
'test
make
target
patch
make
'demo_ivfpq_indexing_gpu
suggestion
args.extend
self.with_or_without
'cuda
works
builtin
Python
utility
Windows
support
near
future
comment
multi-line
string
suggestion
working_dir
'tests
_prefix_and_install
'tests
AutotoolsPackage
phases
code
Please
commented-out
line
setup_environment
checksum
same
users
own
tarball
Better
python
working_dir
'Avizo
suggestion
ver
=
something
sh
=
'sh
sh
'Avizo-
-Linux64-gcc44.bin'.format
ver
suggestion
depends_on
v1.1.4+
colon
equivalent
Update
url
Sorry
original
comment
way
mesa
last
commit
PR
‘
gl
’
virtual
dependency
Mesa
system
libs
2020-10-19
modules
rzcrayz
comment
var
detect
way
distinction
module-
non-module
cray
environments
Basically
cray
machine
linux
mkl
optional
dependency
package
case
Users
install
test=root
command
line
suggestion
args
=
'-DBLASPP_BUILD_TESTS
BOOL=
self.run_tests
'OFF
further
dependencies
example
test
builds
[
Catch2
]
https
//github.com/catchorg/Catch2
v2.6.1+
py
depends_on
type='test
Most
packages
openmp
parallel
ambigous
threads
vectorization
suggestion
variant
description=
OpenMP
backend
'Default
sequential
MKL
ESSL
syntax
non-empty
string
Python
>
>
>
bool
'Hello
World
correct
syntax
@
property
def
force_autoreconf
return
self.spec
force_autoreconf
additional
dependencies
m4
libtool
configure
file
lucky
patch
additional
dependencies
downside
new
release
configure.in
file
stable
configure
file
None
ffi
fabric
others
dependent
sst
spec
args.extend
[
Broken
dependency
package
'-DCMAKE_DISABLE_FIND_PACKAGE_BISON=TRUE
^
'-DCMAKE_DISABLE_FIND_PACKAGE_FLEX=TRUE
'-DCMAKE_DISABLE_FIND_PACKAGE_CrayDRC=TRUE
'-DCMAKE_DISABLE_FIND_PACKAGE_NVSTREAM=TRUE'
]
url
something
self.run_tests
args.append
build-tests
suggestion
spec
[
'qt
]
.prefix.bin.qmake
line
@
Sinan81
comment
simpler
explanation
feature_values
values
features
understood
package
build
system
values
special
meanings
features
e.g
none
importance
IMO
feature_values
documented
property
DisjointSets
PR
explanatory
comment
IMO
fine
unit
tests
worth
self-contained
clarity
core
functions
common
namespace
multi
things
error
message
point
PR
variant
function
multi-valued
variant
implementation
such
kind
variant
future
need
arise
flexibility
free
message
variant
object
argument
values
variant
directive
[
variant
name
pkg.name
fine
user
message
variant
functions
values
Just
thing
case
error
normal
user
guy
software
Spack
package
loop
test_package_sanity
unit
test
Travis
packagers
>
various
packages
default
boolean
variants
example
behavior
logic
explicit
mention
docs
e.g
https
//spack.readthedocs.io/en/latest/packaging_guide.html
problem
lines
case
default=False
boolean
variant
python
variant
True
False
default=False
way
clear
python
variant
fact
boolean
variant
>
more-thorough
unit
tests
true
feature
test_package_sanity
unit
test
old
releases
people
results
results
bugs
check
correct
tests
comment
sequence
typo
suggestion
Versions
HDF5
lead
QE
runtime
errors
license
following
possibilities
package
implements
package
flag_handler
=
approaches
worth
e.g
comment
Address
case
package
flag
handler
statement
flag_handler
=
url
patch
comment
msg=
argument
command-line
~mpi
blas
case
lapack
blas
different
libs
provider
ouch
type='test
+wrapper
following
clearer
constraint
directive
empty
spec
Spec
satisfied
True
values
part
unclear
Can
workaround
more
detail
hard-coding
versions
packages
Spack
packages
support
multiple
versions
same
package
perl
and/or
run
package
dependency
suggestion
'-DHSA_PATH=
self.spec
[
]
.prefix
Python
support
name
clone
developers
name
argument
option
spack
develop
command
docstring
name
change
second
round
edits
spec.satisfies
value
dev_path
comment
spec
'dev-build-test-dependent
dev_path=/path
spec
'dev-build-test-dependent
dev_path=/path
^dev-build-test-install
dev_path=/path
trouble
comment
SingleValuedVariant
static
method
AbstractVariant
superclass
list
elements
list
times
code
look
simpler
spack/spack
IMO
worth
comment
properties
variant
test
suite
build-time
self.run_tests
True
block
IMO
comment
clearer
example
>
Cray
systems
newer
CNL5
unset
CRAY_LD_LIBRARY_PATH
interference
Spack
dependencies
CNL5
e.g
Blue
Waters
variables
main
complaint
comment
exception
rule
rewording
good
rewording
good
rule
comment
CNL5
oldest
Cray
version
Please
add
comment
incompatible
boost
@
provide
URL
such
discussion
suggestion
version
checksums
line
length
checks
@
goxberry
reference
//github.com/spack/spack/issues/7061
thanks
line
FYI
change
interested
architecture
single
variant
self.spec.architecture.target
user
appropriate
variant
fan
meta-programming
approach
lot
complexity
benefit
users
instance
Gpg
class
non-zero
amount
time
effort
various
bits
mysterious
uncommented
wrap
decorator
class
list
global
instance
methods
Gpg
class
definition
subsequent
deletion
method
module
level
handles
stuff
decorator
Again
opinion
stuff
kind
pain
something
straightforward
explicit
definition
handful
module-level
methods
terms
singleton
Gpg
instance
simple-minded
Update
url
GitLab
API
endpoints
moment
API
endpoint
non-API
endpoint
function
regexes
things
bit
lot
things
break
Spack
packages
url
Might
Flang
package
confusion
dependency
Flang
package
list
possible
value
code
suggestion
version
'master
branch='master
submodules=True
PyPI
tarball
code
tarball
link
patches
GitHub
archive
link
suggestion
depends_on
@
:2
when=
@
:1.2
type=
'run
version
mark
preferred=True
Version
only
one
git=
rest
package-level
git
run-on
sentence
something
>
purpose=cluster
libraries
present
desktop
use
desktop
select
purpose=desktop
fbgemm
submodule
default
enough
steps
https
//github.com/pytorch/pytorch/issues/35149
issue
fbgemm
comment
explanation
something
clear
Avoid
imports
botocore
bc
s3
URLs
slashes
thing
https
//gpdb.docs.pivotal.io/43320/admin_guide/load/topics/g-s3-protocol.html
Boto
utilities
things
function
typo
Context
Fiber
typical
something
suggestion
self.spec.satisfies
line
suggestion
self.spec
left-over
comments
Update
url
check
Does
guarantee
C
compiler
fan
global
variable
lines
question
scope
_builtin
config
scope
Spack
effect
logic
easier
rewrite
wrong
logic
hard
jobs
spack.config.get
build_jobs
default=multiprocessing.cpu_count
pkg.parallel
comment
date
Maybe
matter
preference
code
more
clear
jobs
None
value
command
line
jobs
spack.config.get
build_jobs
jobs
None
default
config
set
jobs
=
multiprocessing.cpu_count
spack.config.set
build_jobs
jobs
scope='_builtin
jobs
command
line
command
line
scope
spack.config.set
build_jobs
value
Set
namespace
attribute
convenience
setattr
namespace
'jobs
jobs
suggestion
Check
compiler
AOCC
py-scikit-learn
something
hacky
default
unlikely
vermin
problem
level
code
analysis
issue
case
comprehensive
solution
knowledge
compatibility
package
import
collections.abc
module
vermin
command
as-is
need
Python
use
collections
abstract
base
classes
comments
docstring
check
LockError
acquire_write
try
block
nested
case
try/except/else
block
below
comments
least
requirements.txt
file
mock
unit
tests
package
line
comment
Other
compilers
>
relative
paths
paths
true
exe
name
absolute
path
something
>
exe
names
full
paths
best
which_string
method
isfile
os.access
checks
Please
upstream
bug
report
https
//bugs.llvm.org/show_bug.cgi
id=39696
upstream
patch
bug
pr
good
gcc
version
restriction
upstream
spec
pertinent
least
entire
branches
llvm
source
tree
more
appropriate
patch
when=
@
%
gcc
url
Sorry
@
more
thing
None
least
False
meaningful
comment
check
https
//github.com/spack/spack/pull/11372
issuecomment-537746532
other
instances
dynamic
schema
modification
schema
details
schema
files
suggestion
depends_on
'py-six
type=
'run
suggestion
depends_on
type=
'run
comment
spec
dependents
conflict
cmake_args
conflicts
'~node~proxy
conflicts
'~openmp~opencl~cuda
variants
dependencies
harder
full
list
dependencies
prefix.include
standard
location
available
See
rid
comment
comments
string
spack.environment.default_manifest
comments
Great
catch
Thanks
TODO
line
spack/spack
.so
suffix
version
identical
Comment
others
future
util-linux
libuuid
libuuid
libuuid
suggestion
othwerwise
Python
module
*
Python
module
list
comprehension
lot
heavy
lifting
comment
future
maintainability
first
glance
clear
list
necessary
format
start
r
raw
string
triple
quotes
nice
few
words
purpose
patch
Turn
line
comments
block
comments
conformant
ISO
C
Makefile2
Might
comment
necessary
typo
orignal
FIXME
stuff
license
use
word
cache
general
binary
cache
i.e
remotely-hosted
store
already-built
Spack
packages
index
i.e
object
index
*
cache
files
i.e
remote
index
files
object
BinaryDistributionIndexCache
docstring
distinction
clearer
word
cache
function
names
Could
comment
>
^openblas-with-lapack
builtin.mock
repo
flake8
package
lapack
package-level
check
fetch
strategy
issue
other
tests
Change
Same
Same
directory
self.rpath
typo
analysis
version
>
version
analysis
necessary
Fujitsu
way
version
version
compiler
versions
patch
expression
time
works
python
Does
work
comment
Please
@
%
gcc
order
comment
past
versions
patches
webpages
issues
greater
detail
gcc-7
patch
v1.1.0
v1.1.1
new
Spack
license
header
other
file
up
date
version
Spack
patch
available
issue
sure
hashes
prior
package
comment
necessary
fixme
comments
Please
official
version
tarball
download
https
//github.com/TUM-I5/ASAGI/archive/v1.0.tar.gz
reason
latest
version
official
release
Please
master
version
search
other
packages
version
master
version
version
version
made-up
interim
version
number
i.e
more
secure
master
version
v1.0
URL
https
//github.com/TUM-I5/ASAGI/archive/v1.0.tar.gz
need
download
need
preferred=True
Spack
newest
release
variant
description
'static
vs
libraries
'static
Multi-valued
variants
more
info
https
//spack.readthedocs.io/en/latest/packaging_guide.html
_some_
change
patch
redundant
i
comment
suggestion
depends_on
'py-six
+python
type=
'run
Spack
list_url
GitHub
method
name
environment
python
module
scope
None
former
Python
null
type
latter
string
default
None
'none
list
values
something
host_arch_args
clear
when=
%
gcc
os=rhel6
comment
OS
elderly
assembler
@
means
gcc
PR
sure
right
way
elderly
suggestion
patches
cases
Spack
build
time
dependency
i.e
type='build
conflict
@
:4.8.1
minimum
sense
minimum
spack
dependency/conflict
suggestion
gcc
OpenMP
atomic
same
structure
reference
suggestion
NOTE
symbolic
links
able
docutils
scripts
.py
file
extension
various
linux
distributions
compatibility
other
packages
run_after
'install
def
post_install
bin_path
=
Typo
>
longer
Boost
libraries
line
var/spack/repos/builtin/packages/aom/package.py:3
[
E302
]
blank
lines
var/spack/repos/builtin/packages/aom/package.py:16
[
E225
]
whitespace
operator
var/spack/repos/builtin/packages/aom/package.py:19
[
W391
]
blank
line
end
file
package
license
dependencies
python
depends_on
'py-protobuf
@
type=
'run
depends_on
'py-typing
@
:3.6.6
when=
@
:6
type=
'run
pkg_resources
setuptools
dependency
line
Please
comment
guess
verified
fact
other
Spack
package
variants
case
cuda_arch
variant
better
conflicts
way
things
concretization
installation
sure
additional
requirements
depends_on
when='+poppler
Okay
comment
code
hopes
someone
time
effort
rabbit
hole
things
unit
tests
name
log_path
failure
test_install_output_on_build_error
-d
spack-build-err.txt
file
errors
test
output
assert
last
lines
traceback
comment
likely
useful
package.py
able
directory
exists
need
comment
Change
case
C++11
package
variant
py
variant
default='11
'14
'17
C++
standard
building
use
e.g
suggestion
'-DCMAKE_CXX_STANDARD=
spec.variants
]
.value
'run
+python
suggestion
suggestion
LIBFLAGS=-fPIC
LIBFLAGS=
.format
self.compiler.pic_flag
Python
support
@
Sinan81
string
formatting
stable
weird
things
bazel
output_user_root
option
things
HOME
Sinan81
Should
prefix.lib
NCCL_LIB_PATH
anything
template
comments
FIXME
instructions
license
header
chance
writable
previous
script
issue
Speaking
script
version
older
stable
releases
exceptions
master
head
trunk
preferred
precise
hypre
variants
others
suggestion
TODO
way
external
mkldnn
installation
comment
only
case
causes
errors
example
acceptable
>
Avoid
real
spack
configuration
other
tests
cache
spack
test
configuration
configuration
\
package
Spack
pull
request
￼
please
boilerplate
FIXME
comments
roll_eyes
better
setup_environment
same
file
FileFilter
filename
big
assumption
😄
msg
variable
conflicts
for-loop
compiler
comment
last
parameter
least
comment
Does
explicit
timeout
problem
lines
comments
guarantee
Please
brief
comment
discussion
configure_directory
=
entire
function
obsolete
work
apr
direct
dependency
dependencies
transitive
dependency
Note
depends_on
other
package
attempts
cuda
conflict
part
concretization
useful
comment
relion
issue
next
depends_on
constraint
conflict
bit
associated
comment
comment
desirable
package
conflict
error
<
=
gcc
version
<
Did
comment
>
compiles
gcc
<
cuda
IMO
conflicts
constraint
conflicts
%
gcc
gcc
version
>
issue
Spack
URLs
checksums
flake8
line-length
checks
bit
Intel
compilers
own
ar
xar
sure
dependency
https
//spack.readthedocs.io/en/latest/getting_started.html
need
for-loop
single
directory
>
@
:6.07.99
error
https
//github.com/spack/spack/pull/14250
issuecomment-567969482
Suggest
ROOT
last
part
comment
stale
>
specific
closest
newer
version
default
url
*
version-specific
url
core
node
AFAIK
bcoin
JavaScript
full
node
implementation
Purse.IO
RPC-compatible
bitcoind
example
Bitcoin
Knots
Bitcoin
Core
Just
comment
raising
appropriate
read_var_int
argument
bytez
few
other
places
value
fixed
integer
other
places
attacker
input
changes
json_is_base
json_changebase
wallet
wallet
scriptCode
LegacyWallet
mixed
maker
test
test_coinjoin
general
bitcoin
operation
cryptoengine
question
layer
top
jmbitcoin
package
earlier
comments
ambivalent
above
call
same
wallet.get_script_code
wallet
particular
script
semantics
Does
'requested_marketing_optin
get
student
box
registration
'submitted_marketing_optin
get
batch
job
Marketo
A
couple
explanatory
comments
Honestly
variable
request
easier
code
=
do_successfull_request
request
=
do_failing_request
comment
below
docstring
def
test_deleted_course_with_preferences
Verify
SneakPeek
requests
course
comment
Content
redhat-everything
repo
many
pulp
repos
use
pulp_util.PulpHandler.upload
def
upload
filename
repo_id
layers=None
try
self.p.upload
filename
repo_id
TypeError
self.p.upload
filename
layers
copy
layers
descriptive
message
redhat-everything
comment
easier
great
comments
obvious
names
prescriptive
last
line
file
content
place
things
open
docker_ignore_file
r
f
Last
line
one
assert
f.readlines
-1
]
==
added_line
open
docker_ignore_file
r
f
Previous
content
place
assert
f.read
ignore_content
ignore_content
file
descriptor
duplication
bit
error
ValueError
I/O
operation
closed
file
good
reason
big
fat
comment
suggestions
only
questions
encoding
file
file
theory
same
file
descriptor
case
nice
warning
comment
intent
least
attempt
someone
things
future
Ah
good
idea
call
flexmock
binary
-in
-out
result
Fixed
params
error
-h
simplest
test
sure
go-md2man
case
response.json
line
long
good
place
noqa
worker_data
=
all_annotations
'worker-builds
]
[
]
grouped_manifests
self.get_worker_manifest
worker_data
yeah
acceptance
criteria
sure
increment
is_dotrel
good
idea
increment
first
self.get_patched_release
self.xmlrpc.getNextRelease
build_info
call
case
https
//github.com/projectatomic/atomic-reactor/pull/769
discussion_r132246260
safe
exists
getNextRelease
E501
line
characters
hard
cases
parts
=
original_release.split
+
[
None
None
]
release
suffix
rest
=
parts
:3
]
increment
Increment
part
number
release
=
str
int
release
Remove
second
part
number
suffix
None
suffix.isdigit
suffix
=
None
Recombine
parts
return
[
part
part
[
release
suffix
]
part
None
]
postfix
increment
True
such
Note
first
time
method
increment
getNextRelease
reason
build
Koji
case
enhancement
supposedly
scenario
E501
line
characters
E501
line
characters
Weird
noqa
safe
comment
useful
i.e
self.compose
bool
order
ODCS
composes
inspectable
issue
other
plugins
plain
image
name
registry
comment
plugin
scratch
builds
TODO
comment
None
'None
comment
parameters
overrides
platforms
stage
whole
dfp.structure
lines
stage
E261
least
spaces
inline
comment
E265
block
comment
E122
continuation
line
indentation
E303
many
blank
lines
E501
line
characters
much
sense
E501
line
characters
E202
whitespace
E302
blank
lines
F811
redefinition
unused
'docker_tasker
line
E501
line
characters
E202
whitespace
E202
whitespace
F811
redefinition
unused
'docker_tasker
line
*
Put
noqa
line
Add
comment
'docker_tasker
fixture
redefinition
E302
blank
lines
F811
redefinition
unused
'docker_tasker
line
E501
line
characters
E302
blank
lines
F811
redefinition
unused
'docker_tasker
line
thing
build
same
image
worker
builds
sure
chance
Question
worker
point
Done
background
result.wait
timeout
sure
logs
cleanup
worker
builds
need
testing
worth
limited
amount
time
SIGTERM
SIGKILL
good
idea
cancellations
parallel
assert-inside-raises
E501
line
characters
better
ValueError
ValidationError
exception
emsg
more
pythonic
E501
line
characters
logic
way
full
list
architectures
parametrization
F811
redefinition
unused
line
ok
E501
line
characters
double
//
broken
link
issue
constructor
plugin
*
*
*
*
slash
PathInfo
url
double
forward
slashes
instance
>
>
>
koji.PathInfo
topdir='http
//koji.example.com/kojiroot
//koji.example.com/kojiroot/work'
>
>
>
koji.PathInfo
topdir='http
//koji.example.com/kojiroot/
//koji.example.com/kojiroot//work'
real
problem
urljoin
URL
path
Regardless
string
PathInfo.work
contains
double
slashes
//
variation
following
problem
url
=
'/'.join
[
pathinfo.work
pathinfo.taskrelpath
self.koji_task_id
]
clear
Typo
pulpl
Typo
Can
omit
__init__
anything
other
nitpick
informative
assert
error
'Either
fail_reason
image_id
ok
Let
code
Delete
line
need
'wb
equivalent
docker
export
current
code
ties
docker
save
format
comment
specification
com.redhat.delivery.appregistry=true
operator
image
info
container
owners
something
dockerfile.labels.get
OPERATORS_LABEL
.lower
true
Labels
osbs-client
utils
label
constants
place
E265
block
comment
Could
comment
'log
stop-gap
appropriate
type
name
Koji
F811
redefinition
unused
'docker_tasker
line
+1
algorithm
errors
exception
Might
better
user
experience
fine
support
non-RPM
content
plugin
same
time
metadata
fetch_maven_artifacts
@
lcarva
exception
Seems
code
brittle
data
own
file
tests/files
data
own
file
tests/files
class
instance
.with_args
object
pkg_resources
internals
get_resource_stream
with_args
comment
clearer
Fair
enough
F811
redefinition
unused
'docker_tasker
line
requirements
PyPi
reluctant
change
non-temporary
basis
necessary
things
expert_demos
Again
comment
useful
Typo
base_config_update
=
base_config_updates
different
rename
something
more
distinct
list
strings
list
base_named_configs
sure
base_named_configs
FrozenList
Good
comment
set
False
sure
important
comment
Add
refers
AIRL/GAIL
density
baselines
episodes
horizon
Pendulum
Cartpole
Pendulum
early
comment
comments
disable
Sounds
good
backlog
issue
nice
able
script
default
config
Pendulum
CartPole
Windows
compatibility
os.path.join
data
rollouts
os.path.normpath
data/rollouts
May
type
annotations
arguments
24-27
rest
OK
algorithm
policy
rollouts
step
number
times
callback
rollout_save_interval
different
meanings
RL
algorithms
hyperparameters
RL
algorithms
e.g
DQN
callback
timestep
Others
e.g
PPO2
callback
batch
https
//github.com/HumanCompatibleAI/adversarial-policies/blob/master/src/modelfree/train.py
variable
name
multiplier
RL
algorithm
such
variable
value
locals_
times
multiplier
number
elapsed
training
steps
Stable
Baselines
steps_elapsed
parameter
OK
problem
current
callsite
scripts/expert_demos.py:105
most
code
reward
model
session
RewardVecEnvWrapper
close
d
Discrim
net
own
sess
necessary
experiments
session
functions
Acrobot
MuJoCo
params
least
comment
comment
more
explicit
Ray
TensorBoard
logs
default
matter
Ray
Tune
logs
metrics
case
feature
tb_dest_dir
new
symlink
file
unique
same
src/dst
convention
https
//docs.python.org/3/library/os.html
os.symlink
loops
searches
directory
tb
sb_tb
other
words
Tensorboard
directory
Sacred
directory
comment
Kind
filter_subdirs
type
subdirectory
sacred_util
sacred_util
part
default
number
units
incorrect
Make
hid_sizes
required
argument
default
docstring
empty
list
means
clear
Comment
coverage
line
assert
nocov
something
comment
Part
One
Part
sure
fine
hypothesis
comment
something
sure
comment
TrajectoryWithRew
next_obs
comment
edge
case
terminal
observations
n_steps
suggestion
Check
correct
size
point
different
featurisations
e.g
RandomMDP
options
one-hot
observations
identity
matrix
observations
Gaussian
MDP
important
one-hot
featurisation
point
anything
other
linear
model
reward
function
policy
example
envs
perfect
information
sense
observation
vectors
state
unique
better
worse
standard
Gym
interface
*
seed
seed
observation
action
spaces
benefit
property
observation_space
mutable
external
users
logic
though
constructor
reward
odd
complete
sense
state-action
reward
action
point
as-is
upgrade
path
state-action
state-action-successor
state
rewards
future
Major
nit
pass
unnecessary
docstring
Oop
right
comment
previous
version
code
Ziebart
infinite
horizon
soft
backup
Algorithm
thesis
bottom
p.111
exposition
distribution
termination
reward
encourages
agent
early
current
implementation
loose
checks
test
case
MDP
anything
sanity
last
few
lines
separate
test
case
previous
part
parameterized
test
different
reward
models
optimizers
combinations
simple
test
test
combinations
good
results
command_helper.Ssh.get_client
earlier
comment
vs
boolean
Duplicate
run
Run
script
director
Duplicate
run
Same
other
script
copyright
date
dot
License
approach
<
Server
r175-dell-compute-2
>
<
Server
r175-dell-compute-1
>
<
Server
r175-dell-compute-0
>
[
u'r175-dell-compute-2.r175.nfv.lab
u'r175-dell-compute-1.r175.nfv.lab
u'r175-dell-compute-0.r175.nfv.lab
part
=====Dell
NFV
dell_compute
enable_hugepage
True
True
hostos_cpu_count
Host
OS
CPUs
0-3,24-27
List
vCPUs
4-23,28-47
=================================
print
statements
master
dot
License
Can
copyright
date
suggestion
type
check
following
line
https
//github.com/python/mypy/issues/708
suggestion
type
check
following
line
See
https
//github.com/python/mypy/issues/708
Explanation
ignore
due
[
long-standing
issue
mypy
]
https
//github.com/python/mypy/issues/708
[
third
case
Guido
van
Rossum
]
https
//github.com/python/mypy/issues/708
issuecomment-405796865
issue
python
signac/syncutil.py:57
error
Incompatible
types
assignment
expression
Callable
[
[
dircmp_deep
]
]
target
Callable
[
[
]
None
]
documentation
same
thing
/
document
comment
*
parent
directory
comment
only
unit
test
above
bdice
Do
goal
same
values
valid_sp_values
add_jobs_homogeneous
add_jobs_heterogeneous
sense
valid_sp_values
functions
inputs
Similar
comment
*
[
]
Import
signac/version.py
previous
comment
tommy-waltmann
Please
TODO
check
performance
correctness
correct
sure
check
good
corresponding
comment
line
consistency
other
types
error
thrown
ValueError
error
contrib.filterparse
Same
comment
above
Split
comments
own
lines
comment
options
no-key
all-key
etc.
docstrings
different
classes
description
persistent
file
storage
high
level
SyncedCollection
level
class
needs
extensive
docstring
specific
collection
type
e.g
JSONCollection
backend
data
type
e.g
SyncedDict
core
Python
type
bottom
level
classes
e.g
JSONDict
short
descriptions
point
parents
documentation
*
*
implementation
comment
sufficient
explanation
suggestion
methods
share
common
implementation
data
structures
regardless
backend
correct
methods
common
implementation
SyncedAttrDict
SyncedList
start
file
name
purpose
test
more
suggestion
def
test_update_recursive
synced_collection
testdata
fixture
fixture
argument
sure
test
protected
attribute
suggest
other
way
explanation
purpose
test
part
response
questions
PR
anyone
piece
code
future
tests
self-explanatory
cases
sufficient
in-code
commentary
general
someone
more
context/explanation
regarding
specific
code
section
*
least
more
comments
explanation
code
clearer
kind
hidden
class
variable
serious
design
flaw
constructor
fixture
use
type
fixture
suggestion
Classes
validators
parent
classes
suggestion
Raise
exception
dot
mapping
key
issue
suggestion
Implement
validation
JSON
serializable
data
suggestion
Support
non-str
keys
version
See
issue
isinstance
key
str
int
bool
type
None
suggestion
f
Use
type
key
key
version
DeprecationWarning
short
comment
key
string
update
double
take
reading
test
synced_dict
[
key
]
==
test
key
variable
string
'update
suggestion
line
necessary
validations
loop
suggestion
Find
differences
list
jobs
state
points
relative
imports
Avoid
absolute
imports
import
signac
signac
package
directory
python
.contrib.collection
import
_traverse_filter
comment
@
priesgo
PR
Added
comment
python
convention
documentation
function
additional_files_to_upload
former
mechanism
last
PR
everything
folder
S3
single
AWS
CLI
request
latter
uploads
file
individual
request
thousands
thousands
files
hours
s
staticmethod
code
duplication
helper
general
m8
structure
Love
tests
codebase
“
”
functions
samtools
rid
complexity
ERCC.gtf
file
other
gtf
files
Please
comment
ksnp3
comments
valid
uploaded
stage
status
file
comments
possible
bit
additional
explanation
deadlock
CPython
file
bit
confused
list
cases
certain
scenarios
sure
function
Could
comment
reason
i
same
function
lot
input
file
processing
same
i
is_fastq
is_single_line_fasta
quick
check
first
fragments
sure
name
i
comment
explain
everything
function
pipeline
step
i
inclined
as-is
make
constants
PipelineStepRunPriceSeq
fq2fa
comments
Remove
previous
sentence
URL
same
comment
awesome
documentation
🌟
pythonic
dictionary
=
c
i
i
c
enumerate
sequence
reasonable
threshold
experience
interpreting
curiosity
validation
threshold
curious
examples
threshold
similar
comment
NT_MIN_OVERLAP_FRACTION
variable
unsure
HSP
briefly
comments
HSP
local
alignment
gaps
highest
alignment
scores
search
particular
reason
Huh
[
python
API
docs
[
https
//boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html
S3.Client.list_objects
option
python
API
pretty
weird
cleaner
python
API
REST
full
regex
file
extension
end
gtf
comment
part
colon
last
line
file
sed
command
function
my_test
sample
file
X
line
X
test1.txt
X
line
X
test2.txt
*
*
*
original
files
*
*
cat
test1.txt
test2.txt
sed
instruction
cat
test1.txt
test2.txt
|
's=
=
>
transformed.txt
*
*
*
dest
file
*
*
*
cat
transformed.txt
my_test
output
*
*
original
files
*
*
line
line
line
line
*
*
*
dest
file
*
*
*
line
line
line
line
line
case
Remember
additional_attributes
threads
]
function
line
comma
space
See
comment
pipe
comment
pipe
curried
map
Comment
incorrect
removed
constants
values
line
comment
systemd
service
leftover
child
PIDs
minor
nit
quoting
value
strings
different
lines
something
'programs
[
'list
'of
'programs
]
'docker_image
docker
image
Can
image
Job
docker_image
example
string
better
None
reason
other
imports
circular
dependency
comment
Path
specs
APFS
volumes
bit
TSK
volumes
index
start
offset
APFS
volume
child
node
TSK
volume
parent
node
partition
offset
line
parsing
bit
risky
equals
something
line
'NotebookApp.port
value
comment
something
second
part
line
code
regexes
output
split
difference
cases
password
Does
password
mean
empty
password
bit
report
comments
Ah
right
compression
folder
nested
directories
files
nested
directories
files
listdir
root
directory
absolute
path
example
directory
/usr/path/to/files/file_to_compress
directory
file_to
compress
previous
paths
usr
path
files
directory
listdir
base
folders
directory
structure
error
provided
path
'.tar.gz
extract_path
same
local_path
extract_path
tarballs
'.tgz
extension
fine
input
tar
'd
gzip
accept
files
.tgz
.tar.gz
future
PR
files
tar
down
line
input
evidence
meantime
output_evidence.local_path
output_file_path
output_file_path
evidence
class
suggestion
task_class=bulk_extractor.BulkExtractorTask
evidence_class=CompressedDirectory
plural
evidence
'evidence
Buckets
global
namespace
None
default
'turbinia
bucket
use
projects
way
SRC_DIR
var
real
production
environment
git
code
specific
path
more
one
meeting
GCS_MOUNT_DIR
same
relative
TURBINIAENV
same
concatenation
scripts
whole
file
Turbinia
part
common
config
cloud
Turbinia
Server
option
common
things
LOG_FILE
OUTPUT_DIR
section
Turbinia
Internals
sure
format
strings
config
file
harder
other
languages
kind
open
later
today
Does
cloud
functions
GCS
bucket
GCS
bucket
Minor
nit
'and
sentence
Maybe
s/
/
s/For
local/When
Turbinia
Same
comment
above
WRT
bucket
names
same
thing
nice
last_update
time
request
order
report
times
output
lot
useful
request_dict
object
more
things
request_dict
request_id
saved
paths
dict
saved_paths
requester
last_update
keys
need
tasks
requester
other
data
nice
task
count
request
instance
type
same
pattern
other
execute
method
pass
'shell
boolean
Popen
Cool
fine
evidence
types
example
https
//github.com/google/turbinia/blob/25c2101b96536c8310795356191af288f634891e/turbinia/workers/bulk_extractor.py
L68
anything
interesting
log
file
report
home
directory
manual
run
nit
case
sentence
stays
import
attributes
config
object
imp.load_source
list
sphinx
extensions
https
//www.sphinx-doc.org/en/master/usage/extensions/index.html
l2t
config
Could
optional
parameter
alternate
username
email
address
username
DEFAULT_EMAIL_DOMAIN
something
config
email
server
requester
username
person
request
way
user
processing
request
comment
docstrings
function
pass
statement
broad
exception
smtplib.SMTPException
base
class
smtp
exceptions
pass
statement
reason
first
log
empty
NameError
exception
variable
config
None
import
top
file
requirements.txt
thing
nice
parameter
function
sure
more
sense
code-wise
general
most
other
areas
code
TurbiniaException
objects
something
more
generic
sure
idiomatic
other
file
sure
gon
l
later
PR
TODO
TODO
timeout
method
parameter
dynamic
task
configuration
available
part
Recipes
design
own
PATH
decorator
subclasses
overrides
hook
E.g
TurbiniaTask
TurbiniaTask
object
def
stuff
decorator
self.do_run
def
do_run
return
implement
do_run
classes
other
comment
additional
log
file
volatility
log-file
related
tip
suggestions
https
//github.com/google/turbinia/blob/master/docs/developing-new-tasks.md
tips
minor
style
nit
newline
parenthesis
string
something
cmd
=
/bin/vol
-f
s
profile=
s
s
output=text
output-file=
s
evidence.profile
self.module
output_file_path
system
dependency
python
dependency
rid
python2
support
volatility
python3
'python2
'vol
/bin
FYI
issue
dependency
checking
https
//github.com/google/turbinia/issues/312
Minor
nit
TODO
something
small
likely
way
hand
nicer
user
other
hand
code
docs
change
add
/etc/turbinia/turbinia.conf
preference
execute
command
line
newlines
statements
same
logical
grouping
general
everything
line
bad
idea
hard
case
easier
overall
structure
harder
individual
details
table
TODO
Add
comment
TODO
fix
typo
TODO
Update
locations
DockerImageManager
new
representation
Comment
information
docker
API
TODO
Fix
typo
type
TODO
Fix
TODO
Make
arguments
future
confusion
lot
output
Update
comment
comment
comment
X
style
use
spaces
indentation
contents
comment
Better
code
more
explicit
self-documenting
editor
default
Python
Make
sure
tabs
Indentation
important
right
Python
typo
comma-separated
Do
DAY_SECOND
variable
user
configurable
example
competition
users
week
line
relevant
comment
statement
dictionary.get
function
Document
example
Comment
section
pretty
tricky
more
documentation
TODO
weird
cpuset
set
set
TODO
Return
ENOENT
file
Yup
Ok
TODO
things
right
thing
comment
effect
Iterator
path
comment
line
Nit
comment
line
explanatory
sys.platform.startswith
'linux2
useless
'linux
string
linux2
linux
contrastive_loss
pointing
result
array
Just
raw
values
Ah
before
exception
function
iterator
list
iterator
test
case
iterator
sure
cases
descriptive
name
variable
E.g
comment
self-explanatory
rename
res
better
name
explanation/comment
part
docstring
base
units
vector
xarray
object
Thanks
suggestion
few
comments
approximation
distances
km
earth
sphere
degrees
km
things
simple
Add
comment
logic
suggestion
Adjust
prints
exec
front
python
runner_remote_path
commit
ready
better
different
PR
diff
PR
large
good
cancel
timeout
parameter
branch
joblib
worker
client
anyways
comment
code
looks
class
method
_can_
own
register_pretrained_model
training
job
ID
function
signature
order
training
template
ID
bug
other
comment
register_pretrained_model
bit
easier
comment
superclass
PollableResult
author
parameter
current
user
People
someone
models
comment
include_header
False
change
work
isinstance
rid
line
fout.write
data
below
test
table_columns
parameter
different
m_process_cleaning_results
cleaning
job
job
sql
types
sql
types
table
valid
sql_type
entries
ValueError
example
post_files_csv
m_process_cleaning_results
table
api
client
test
name
table
]
https
//github.com/civisanalytics/civis-python/blob/6d632e4e71888bdc63aba7655442bdc715c5f04d/civis/tests/test_io.py
L224
@
mheilman
bit
caveman-like
thoughts
user
garbled
exception
much
sense
execution
whatever
user
something
wrong
stop
Please
error
line
rest
Do
something
issue
users
errors
explorer
apiviewer
testtapper
suggestion
FE_APPS
=
[
osparc
s4l
tis
pls
code
explanations
code
readable
others
suggestion
interested
last
task
last
exceptions
purposes
debug
log
more
adequate
comment
code
Everything
present
individual
test
response
exception
HTTPForbidden
X-Rate
reason=
API
rate
limit
way
error
b
middleware
care
error
middleware
[
]
https
//github.com/ITISFoundation/osparc-simcore/blob/a957016dc8765b0b851bb67cb1f81ed7decf4ff8/packages/service-library/src/servicelib/rest_middlewares.py
Please
use
[
IntEnum
]
https
//docs.python.org/3/library/enum.html
intenum
python
output
store
==int
Store.DATCORE
better
DATCORE_ID
[
settings.py
]
services/storage/src/simcore_service_storage/settings.py
adapt
thos
IntEnum
Store.DATCORE.name
==
DATCORE
contents
shouldn
exception
remoev
comments
purpose
loads
conftest
docker-compose
call
se
task
port
service
error
message
reliable
such
thing
python
api
docker-compose
https
//github.com/docker/compose/issues/4542
special
kind
concatenation
iwht
aiopg
https
//aiopg.readthedocs.io/en/stable/examples.html
usage-of-listen-notify-commands
issue
web/server
docker
due
changes
web/client
branch
FYI
variable
python
_
worker
celery_inspect.items
MINOR
i
constant
ids
readable
MONITORED_NODE
=
35f95ad4-67b8-4ed8-bd55-84a5d600e687
assert
MONITORED_NODE
data
present'
celery
=
data
[
MONITORED_NODE
]
<
<
NO
need
result
comment
method
mock_http_conversation
sense
mock_http_conversation
way
smt
.py
try
assert
==
actual.call_count
AssertionError
print
Numbers
+
fail_template
.format
version
actual.call_count
message
actual.call_args_list
raise
try
actual.assert_has_calls
any_order
=
True
FIXME
AssertionError
print
Calls
+
fail_template
.format
version
message
actual.call_args_list
@
sColin16
tests
great
couple
concerns
*
helper
functions
such
verify_response
help_message
test_bot
message
*
large
test_bot
function
everything
many
test
functions
command
easier
more
organised
early
return
main
logic
statement
Redundant
newline
Write
comments
phrases
first
word
dot
end
tests
access
internet
unreliable
mock_http_conversation
function
http
traffic
bot
test
fixtures
Once
function
shorter
API
key
e.g
assignment
line
comment
return
help_txt
pretty
self-explanatory
comment
obvious
config_file
[
]
means
other
arguments
call
more
explicit
variable
names
eg
text_to_translate
line
other
variables
actual
API
key
tests
file
mock_http_conversation
fixtures
http
traffic
bot
tests
dependant
internet
access
giphy
bot
example
scenario
users
queue
status
last
status
visible
cases
open
cases
queues
Done
comment
more
please
case_id
please
Manual
migration
current
sites
records
property
set
sites
licences
compliance
case
comment
pls
entire
flags
list
split
+
team
list
suggestion
previous
comment
itll
order
Remove
code
Remove
code
Example
strings
please
methods
asserts
self.assert_country
stakeholder
site.address.country.name
def
assert_country
name
self.assertEqual
]
name
need
comments
code
explicit
fussy
EU
non
EU
bits
separate
tests
get
statement
EU/Non-EU
applicable
Maybe
clarify
commercial
=
HMRC
comment
please
information
rows
comment
line
wrap
TODO
Please
out/unused
code
good
reason
comment
array
worth
isnt
comment
code
status
==
reactivate
return
type
Unnecessary
comment
line
comment
Delete
empty
Are
lines
code
Renamed
comment
units
services
key
malware
value
True
False
Mark
H
status
doc
point
way
dicts
pylint
function
complex
linting
logical
bits
separate
methods
better
fix
TODO
new
activity
model
new
states
applicable
goods
queries
Could
new
list
CaseStatusEnum
something
ApplicationStatuses
correct
list
PV
CLC
destination
i
parties
more
days
consecutive
holidays
weekends
empty
case
org
flags
comment
Group
flags
user
team
command
tests
list
seedall
only
place
efficient
Hopefully
chance
tests
fixtures
stage
Move
tests
list
seedall
CSV
future
hard
ID
fine
future
ID
hawk_credentials
parameter
None
helpful
error
HAWK_AUTHENTICATION_ENABLED
True
hawk
credentials
Sender
behave
credentials
Might
worth
retry
number
log
message
retry
attempts
Could
nowait
True
Do
django
background
process
method
own
code
MAX_ATTEMPTS
Make
comment
unit
Looks
more
clear
only
working
days
comment
comment
date
endpoint
parties
..
SLA
HMRC
summaries
way
additional
explanation
convenience
seed
internal
users
exporter
users
same
user
sites
comment
local.env
EXPORTER_USERS
empty
sites
seedcasestatuses
essential
seedcasestatuses
Remove
tag
comment
function
Could
aa
comment
lines
comment
belong
lines
please
comment
Please
extract
lines
20-
>
seperate
function
something
_apply_rule
docstring
Small
typo
loop
keep_status
case_types
set
dont
licence_risk_value
data
condition
Comment
needs
Comment
last
pre-terminal
status
Could
explanation
Add
ex
references
check
top
db
references
Please
test
successful
POST
document
comments
Extend
test
doc
post
check
similar
new
test
Stick
comment
system
status
clear
Todo
Todo
assemble/act/assert
comments
comments
/users/
....
Comment
please
user
queue
system
queue
team
queues
case
DB
duplicate
comment
dont
list
able
*
flags
risky
memory
sure
many
flagging
rules
few
years
live
huge
deal
type
QuerySet
flagging_rule
parameter
applicable
methods
comments
Please
comments
methods
way
same
other
duplicate
comments
certain
small
list
condition
current_attempt
>
=
current_attempt
>
settings.MAX_ATTEMPTS
MAX_ATTEMPTS
write
access
funny
error
message
error
message
Interesting
equivalent
[
]
blank
lines
default
continuous
testing
example
case
lc
example
little
add
doctest
+SKIP
line
testing
line
suggestion
>
>
>
df_sso
=
lc.query_solar_system_objects
cadence_mask=
lc.time.value
>
=
lc.time.value
<
=
doctest
+SKIP
suggested
change
lc.time.value
necessary
lc.time
AstroPy
Time
object
Lightkurve
v2.x
MAX_NUMBER_CBVS
vestigial
earlier
version
code
MAX_NUMBER_BANDS
cbvcorrector
class
__contains__
method
implements
Python
operator
same
more
Pythonic
suggestion
HDU
[
'PRIMARY
]
.header
suggestion
elif
'CAMPAIGN
HDU
[
'PRIMARY
]
.header
%
generous
SFF
%
minimum
let
%
plot
vs
ideal
light
curve
nothing
crazy
PLD
depth
%
machine
let
test
stringent
quick
plot
ideal
vs
light
curve
sure
nothing
crazy
able
better
factor
Please
comment
purpose
above
block
t
l
more
verbose
variable
names
above
statements
few
comments
purpose
little
easier
Zero
flux
aperture
self.aperture_flux
=
f
*
np.atleast_3d
aperture_vals
]
Sum
function
time
raw_flux
=
np.sum
self.aperture_flux
axis=
python
aperture_vals
np.atleast_3d
np.copy
aperture_mask
.astype
int
]
Zero
flux
aperture
self.aperture_flux
=
f
*
aperture_vals
Sum
function
time
raw_flux
=
np.sum
self.aperture_flux
axis=
comments
Smart
comment
division
Please
kjm2019JAN21
indented
version
control
track
time
author
changes
unit
tests
[
link
]
https
//ci.appveyor.com/project/mirca/lightkurve/builds/21781622/job/n9vnkif81k7xs64l
L591
quality_bitmask
string
'default
'hard
'hardest
number
quality_bitmask
>
quality_bitmask
quality_bitmask
line
Version
control
track
changes
need
old
lines
comments
code
@
nksaunders
line
file
similar
ra/dec
values
good
idea
close
match
.3f
match
arcseconds
correct
sure
comment
code
suggestion
matchstring
=
r
.3f
*
_
.3f
*
_
_astrocut.fits
.format
sector_name
few
more
lines
comments
future-proof
limit
optional
parameter
interact
function
default
parameter
source
=
>
lc_source
source2
=
>
tpf_source
test
cdpp
cadence
number
issue
suggestion
lc
=
lk.KeplerLightCurve
time=np.arange
flux=1
*
np.ones
np.random.normal
cadenceno=np.arange
+3000
np.isclose
rtol=2
suggestion
optional
dependency
fast
PCA
fbpca
import
slower
suggestion
PLDCorrector
pybind11
celerite
fbpca
short
Examples
section
docstring
great
spline
functions.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
variable
'images
assignment
]
https
//app.codacy.com/app/barentsen/lightkurve/pullRequest
prid=4004089
docstring
comment
line
threshold=1
code
threshold=3
good
reason
threshold=1
better
background
mask
suggestion
background_mask
=
~self.tpf.create_threshold_mask
reference_pixel=None
few
words
pld_order
pixel_components
different
default
Kepler
Are
certain
necessary
defaults
suitable
TESS
Could
way
defaults
generic
properties
e.g
amount
motion
number
pixels
TPF
number
cadences
mission
name
questions
way
expensive
KeplerPLDCorrector
TessPLDCorrector
classes
single
PLDCorrector
class
certain
necessary
class
hierarchy
Nevermind
comment
Might
good
comment
exception
reading
comment
Looks
chunk
documentation
license
worth
TODO
comment
submission
open
editable
type
something
fields.String
attribute='file.filename
fields
something
similar
obvious
need
Event.start_dt
Event.id
paste
comments
comments
revision
other
cases
e.g
names
etc
other
way
round
clearer
i.e
local
groups
disabled
BTW
comment
local
groups
disabled
way
acl
fields
cool
db.enforce_constraints
e.g
inconsistent-timetable
errors
missing
comment
docstring-ish
El
todo
el
recordset
Si
una
condición
al
dominio
anterior
sentencia
estaría
resuelto
también
también
puedes
el
prefetch
después
del
search
Por
qué
dos
veces
mismo
código
Coge
country_code
del
NIF
si
está
establecido
que
mismo
compruebas
simplemente
coges
dos
primeros
caracteres
cuando
se
debería
mirar
si
un
código
el
core
tiene
código
que
hace
esto
para
copiarlo
comment
string
literal
cyclic
See
previous
comment
suggestion
operation
function
instance
FlowCmdOperation
TODO
item
directive
suggestion
b-butler
suggestion
jobs
same
FlowProject
additional
comments
tests
line
unnecessary
suggestion
suggestion
assert
directive_copy.parallel
commented
function
clear
developers
_DirectivesItem
own
dummy
_DirectivesItem
above
comment
test_serial
sure
_aggregator
attributes
equal
_select
attributes
somebody
pull
request
event
Github
PRs
link
mention
grouper
recipe
function
link
technique
suggestion
Aggregates
jobs
set
group
size
comment
import
use
md5
sha1
suggestion
Create
actual
collections
jobs
operations
class
class
decorator
signal
operation
functions
aggregate
operations
information
aggregation
function
classes
sequences
jobs
operations
comment
groupsof
solution
pretty
hacky
fact
multiple
references
same
iterator
reference
sequence
chunks
original
efficient
way
copies
recipe
link
comment
suggestion
jobs
state
point
key
values
access
original
thread
discussion
new
comment
point
function
whole
__eq__
method
tag
tag
necessary
elif
clause
worth
remainder
method
co_code
hash
select
s
aggregator_function
s
equality
same
speed
equality
check
elif
co_code
object
creation
AFAIK
reason
clause
equality
checks
code
self_select
other_select
clause
list
conversion
jobs
]
.id
correct
representation
Job
project
id
information
docstring
comment
length
something
convenient
inclusion
aggregate
objects
default
length
false
true
variety
things
something
other
function
need
suggestion
assert
[
tuple
project
==
list
aggregate_instance
__hash__
__eq__
class
typo
suggestion
assert
job.sp.even
job
aggregate
size
aggregate
correct
values
job.sp.even
identical
worth
helper
function
comparison
function
_StoreAggregate
aggregates
FlowProject
Thanks
comment
Could
aggregate
members
equivalent
course
true
aggregates
size
clear
future
developers
comment
works
helpful
i.e
unique
aggregation
definitions
more
question
tag
id
better
name
arbitrary
comment
comment
obsolete
need
kind
logic
origin
configuration
value
Just
get_config_value
function
util.config
module
https
//github.com/glotzerlab/signac-flow/blob/master/flow/util/config.py
L44
Remove
line
suggestion
Comments
helpful
future
reference
valid
comment
latest
changes
yesterday
sure
comment
sure
>
handle_exceptions.handle_background_exception
new_err
length
=
underwhelming
response
serious
error
handler
runner
handler
App
developers
way
condition
background
exception
lack
handlers
feels
fatal
better
handler
runner
asyncio.CancelledError
[
]
length
=
comments
handler
constant
inbox
name
loop
various
items
same
inbox
reason
loop
Great
comment
much
>
[
]
length
=
u
mean
>
my_device
[
]
length
=
device
id
param
example
topics
teams
>
unencode
[
]
length
=
spell
decode
encode
+
file
other
big
test
file
comment
header
+
file
+
encode
decode
future
developers
+
encode/decode
test
run
list
'/
'+
yucks
'\
comment
line
key
able
dps
documentation
page
def
derive_device_key
[
]
length
=
Same
comment
other
Same
comment
other
file
Remove
merge
>
self.last_version_seen
[
]
length
=
class
inline
commentary
various
conditional
branches
code
clean
functionality
clearest
thing
easier
high
level
explanations
certain
code
blocks
loop
=
asyncio.get_event_loop
]
length
=
huh
async
setters
Random
comment
Longer
term
code
import
asyncio
favor
asyncio_compat
>
tp.submit
coro_wrapper
handler
retval
[
]
length
=
Please
code
line
errors
coro_wrapper
real
hassle
exceptions
threads
threadpool
easier
concurrent.futures.Future
object
asyncio.Future
object
wonderful
world
https
//stackoverflow.com/questions/2829329/catch-a-threads-exception-in-the-caller-thread-in-python
]
https
//stackoverflow.com/questions/2829329/catch-a-threads-exception-in-the-caller-thread-in-python
same
comment
lines
exceptions
>
Open
Question
fields
destination
[
]
length
=
personal
opinion
advantage
meaning
device_client.on_message_received
=
message_received_handler
[
]
length
=
handlers
connect
significant
handler
connection
sample
connect
many
developers
samples
off
comment
handler
assignment
samples
something
client
assignment
client
something
assignment
network
connection
broken
record
....
self_weakref
=
weakref.ref
length
=
explanatory
comment
scenario
relevant
Auth
Provider
understanding
transport
stage
authentication
comments
methods
confuse
things
i
garbage
clarity
>
gc.collect
[
]
length
=
comment
full
collection
oldest
objects
generation
>
device
=
iothub_registry_manager.get_device
device_id
[
]
length
=
line
comment
little
esoteric
specific
time
fixture
fixtures
other
autouse
fixtures
problem
particular
case
comment
below
source
comment
>
delayed_reconnect_delay
[
]
length
=
help
types
delay
other
>
this._complete_waiting_connect_ops
error
[
]
length
=
comment
operations
disconnect
somehow
disconnect
state
connection
failure
disconnect
operation
>
EnableFeatureOperation
[
]
length
=
feature
name
operation
hub
mqtt
pipeline
Except
comment
reason
'None
feature
single
item
necessary
necessary
samples
present
update
[
]
length
=
general
code
organization
thumbsup
>
patch
[
]
length
=
Suggest
short
comment
patch_documentation.py
places
Sure
easy
future-us
help
]
length
=
.....
see
comment
wrong
order
event
loop
current
thread
second
thread
second
thread
event
loop
second
thread
implementations
loop
policies
able
problems
way
feels
loop
thread
right
possible
cases
code
notion
loop
thread
case
documentation
event
loop
policies
[
https
//docs.python.org/3/library/asyncio-policy.html
]
https
//docs.python.org/3/library/asyncio-policy.html
policy
notion
context
separate
event
loop
context
default
policy
defines
context
current
thread
mapping
threads
event
loops
_default_
asyncio
implementation
talks
theoretical
policies
different
contexts
class
BaseDefaultEventLoopPolicy
AbstractEventLoopPolicy
Default
policy
implementation
event
loop
policy
thread
own
event
loop
event
loop
default
main
thread
other
threads
default
event
loop
Other
policies
different
rules
e.g
single
global
event
loop
event
loop
thread
other
notion
context
event
loop
brain-twisting
territory
event
loop
threads
safer
get_event_loop
current
current
context
new
event
loop
current
context
default
case
event
loop
threads
case
singleton
event
loop
threads
pytest-asyncio
accommodations
custom
event
loop
policies
policy
careful
asyncio
custom
policy
play
head
rocks
asyncio
rabbit
hole
damn
call
event
loop
file
customer
code
chance
bug
introduces
event
loop
user
chance
custom
event
loop
policy
azure.iot.device
import
AzureIoTDeviceClient
event
loop
default
policy
import
asyncio
asyncio.set_event_loop_policy
my_custom_policy
policy
current
thread
loop
asyncio.run
my_main_coroutine
user
code
loop
my_custom_policy
default
loop
kind
bug
__extremely__
hard
unrelated
import
statement
top
file
behavior
code
such
destructive
way
feature
async
client
handlers
user
event
loop
different
PR
bit
ok
/sys/kernel/config/target
targetcli
targetcli
separate
pull
request
commit
review
items
new
commit
change
targetcli
branch
PR
git
push
force
Note
'fixup
commits
master
branch
review
items
Nack
look
API
documentation
add_copy_spec
method
accepts
single
string
list
strings
pointless
make-work
reason
TODO
comment
question
Need
code
code
DRY
code
get_service_list
get_service_dict
place
easier
list
follow
ticket
reason
BRES
todo
comment
nice
fix
worth
own
function
Spelt
'still
wrong
Might
worth
email
code
previous
comment
context
threads
different
internal
ONS
user
message
thread
account
functionality
moment
something
comment
correct
load
balancer
messages
controller
template
comments
unnecessary
issue
internal
system
okay
user
information
valid
something
facing
site
something
site
little
info
possible
check
necessary
note
previous
table
uniqueId
google
resources
ONLY
unique
project
primary
key
case
mult
projects
opinion
next
block
case
check
first
check
tiny
efficiency
boost
authz
extra
conditional
checks
something
authz
has_authz
=
do_arborist_check
has_authz
thing
delete
uploader
exception
something
logging.error
exc
exc_info=True
bucket_name
bucket_name
storageclient
interface
slack
note
only
place
get_users_linked_google_email_from_db
IMO
GET
/link/google
linkage
amused
confused
TODO
C'est
déjà
simple
avec
ce
que
j'ai
fait
tu
préfères
tous
les
champs
Ce
ne
serait
pas
mieux
d'appeler
user
child
et
grandchild
pour
marquer
fait
qu'on
cherche
à
tester
une
chaine
création
>
child
>
grandchild
Ou
alors
pourrait
mettre
un
commentaire
au
début
du
test
pour
indiquer
création
cherche
à
case
comment
GUI
resources
parsec/core/gui/_resources_rc.py
avoid
low
level
transactions
self.unlink
source
fine
Ca
optimise
pas
vraiment
l
algo
faire
comme
tu
propose
vu
que
l'accès
à
est
moins
que
le
heappop
mais
j'ai
quand
même
inline
suite
à
un
commentaires
précédents
J'ai
l'impression
qu'on
bonne
partie
du
code
qui
va
suivre
ainsi
que
tout
_populate_tree_load
_populate_tree_list_versions
sont
là
que
populate
ce
dict
Du
coup
je
pense
que
ce
serait
une
classe
dédiée
à
ça
ça
permettrait
notamment
d'évîter
à
_populate_tree_list_versions
une
variable
tree
se
fait
ça
permet
aussi
d'éviter
passer
paramètres
à
chaque
appel
fonction
enfin
ça
permet
facilement
documenter
ce
bloc
code
dans
class
J'imagine
que
à
différence
VersionLister
cette
classe
aurait
une
durée
courte
du
genre
python
tree_builder
=
TreeBuilder
self.version_list_cache
self.manifest_cache
path
starting_timestamp
TODO
better
name
return_tree
=
tree_builder.build
tenté
la
classe
un
peu
infame
mais
c'est
dur
quelques
lignes
part
jsonschema
filter
test
coverage
lot
method
true
s3
api
s3
action
rest
style
PUT
subdocs
config
ie
sure
call
specific
comment
concurrent
futures
perm
errors
concurrency
max_workers
fine
importlib.import_module
Yep
comment
part
description
es
resource
comments
same
proxy
inherits
most
languages
standard
env
vars
additional
config
separate
connection
class
omit
standard
behavior
good
someone
redis
dependency
local
file
lambda
great
mailer
container
EC2
instance
methods
object
compatible
redis
memcache
redis
python
dict
objects
memcache
strings
wrapper
class
necessary
gets/gets
flow
redis
mac
fine
note
regex
easy
potential
queries
AD
example
UID
characters
long
numbers
[
0-9
]
underscore
UID
unique
schema
UID
load
AD
real
issue
unnecessary
logs
Found
resource
group
x.
fwiw
self.recording
conditional
consistent
sleeps
intentional
original
code
equality
False
matter
conditional
matter
anyways
self.kms_id
dacca8ea-f166-43af-aaaa-b35f8781035d
SSEKMSKeyId
arn
aws
kms
us-east-1
xxxxxxxxxxx
key/dacca8ea-f166-43af-aaaa-b35f8781035d
forward
slash
better
choice
code
easier
equal
sense
thanks
inline
comment
union
sets
null
empty
API
call
fields
tags
everything
full
update
field
resource
valid
copy
b
one
meantime
something
more
similar
code
Resource
Groups
structure
tags
nothing
code
something
ResourceGroupPatchable
sure
likely
nothing
vm
centric
things
generic
action
action
VM
specific
tags
other
resource
types
comment
extra
_
variable
name
sure
dictionaries
==
b
pretty
specific
VMs
guard
VMs
minor
style
stuff
worth
flake8
editor
i
comment
spaces
code
i
line
char
lines
docs
'slack
//owners'
same
message
obj
slack_messages
comment
comment
i
zone/type
grouping
reboot
started
instance
started
instance
capacity
allocation
issues
capacity
errors
noqa
F401
flake8
bypass
last
import
line
build
boto3
botocore
runtime
requirement
c7n_azure
functions
bug
happy
req
gcp
cloud
funcs
issue
details
block
necessary
elif
s
unneeded
properties
unneeded
reference
reference
security
group
AWS
sg-123456
allows
traffic
port
sg-123456
s/OnlyPorts/RestrictedPorts
block
lot
easier
imo
imo
cleaner
arithmetic
range
i.e
values
first
dest_port_range
]
port
<
dest_port_range
]
block
self.from_port
self.from_port
<
dest_port_range
]
return
False
same
idea
line
nice
use
composition
minor
note
attribute
annotate
=
False
value
filter
instance
extra
attribute
harmless
case
subscription
lambda
way
basic
caveat
macaroon
context
principals
permission
values
verify
function
something
def
verify_caveat
predicate
*
permission
function
entire
dictionary
possible
keys
try
data
json.loads
predicate
Exception
TODO
Better
exception
return
False
Check
unknown
predicate
keys
data.keys
permissions
TODO
Might
better
jsonschema
something
False
Go
caveats
permissions
data
permission
data
permissions
]
caveat
permissions
permission
NOT
False
True
return
True
v
=
Verifier
v.satisfy_general
verify_caveat
v.verify
suggestion
agreement
general
*
shape
*
caveats
json
dict
msgpack
dict
*
*
permissions
caveats
quick
macaaroon
mechanism
version
numbers
ID
caveat
language
setup
next
type
permission
Upload
tokens
special
ones
permission
scope
Thoughts
comment
GH-6345
comment
nit
typo
machinery
table
correct
unqiue
constraint
multiple
rows
same
user
model
unqiue
constraint
Did
migration
code
change
better
GB
comments
comments
out-of-date/wrong
legacy.MAX_PROJECT_SIZE
./warehouse/forklift/legacy.py:64:43
E261
least
spaces
inline
comment
./warehouse/forklift/legacy.py:64:44
E262
inline
comment
linter
line
better
MAX_FILESIZE
ONE_MB
ONE_GB
comment
comments
file
wrong
cache
single
view
sure
behavior
something
cache
big
deal
lines
least
marker
migration
right
thing
suggestion
latest
prep
template
file
first
[
]
tuple
bit
comments
Comments
lot
thanks
allocation
>
matter
result
eval
positive
integer
Same
comment
re
loop
suggestion
suggestion
study
type
EBI-ENA
suggestion
investigation_type
user
terms
Can
other
way
unnecessary
indentation
i.e
incident_created_time
<
=
last_fetch
type
ignore
necessary
error
Can
comment/INTEGRAITON
DEVELOPER
TIP
logic
local
development
sure
core
packs
Please
double
logic
Use
comment
Nice
comments
better
value
sys.exit
Same
Whats
purpose
ValueError
need
anything
url/file
declare
global
beginning
function
error
code
suggestion
raise
DemistoException
f'Error
JsonWhoIs
JSON
response
res.text
wrap
try-except
first
object
second
split
different
variables
image_name
image_path
entry_id_list
meanings
handle
proxy
beginning
main
graceful
way
comment
whats
comment
suggestion
extensions
[
extension.split
-1
]
extension
extensions
Place
comment
set_default_region
function
following
default
values
suggestion
region
=
demisto.params
.get
'region
'-
comment
good
Place
comment
set_default_project_id
function
suggestion
Update
incident
issue
Jira
server-side
last
sync
use
handle_proxy
docstring
google
style
please
suggestion
assert
context.get
'HumanReadable
Something'
suggestion
context
=
CommandResults
readable_output=
Something
default
value
base_url
params
empty
default
value
demisto.params
.get
'base_url
//api.domaintools.com
happy
string
doc
string
date
suggestion
whois
'demisto.com
temporary
fix
permanent
way
comment
link
relevant
issue
integration
logger
docstring
script
helper
user
add_repalce_strs
credentials
standard
next
need
comment
COMMON_SERVER_NO_AUTO_REPLACE_STRS
inorder
original
exception
data
suggestion
raise
reason
dict
entryTypes
anara123
check
single
condition
results
exists
list
first
item
type
CommandResults
@
anara123
comment
implement
inline
Le'ts
explaining
comment
suggestion
packs_dir_names
[
'pack_a
'pack_b
]
string_dir_names
'Packs/pack_a
Packs/pack_b
Packs/pack_c'
=
f'Packs/
Packs/
.join
packs_dir_names
function
Rony
comment
hack
suggestion
following
comment
comment
interface
clear
indicators
strings
dicts
CommandResults
List
[
IndicatorsTimeline
]
indicators
only
list
strings
indicators
message
mandatory
params
user
message
indicator
list
IndicatorTimeline
objects
rare
case
suggestion
Validate
integration
documentation
file
comment
clear
lets
condition
error
code
ignore
described
//github.com/demisto/content/pull/4665
json
json
whats
copy
defaultdict
Oi
lo
short
comment
line
suggestion
=
Demisto
Content
Beta
Release
Notes
version
version
asset_id
suggestion
=
Demisto
Content
Beta
Release
Notes
version
\n'.format
NEXT_VERSION
line
infinite
loop
regex
global
method
comment
key
yml
script
descriptions
Demisto
let
split
several
lines
assign
readable
names
rename
line
comment
TODO
suggestion
domain
*
value
type
DomainGlob
suggestion
*
domain
type
DomainGlob
version
const
condition
function
please
lines
suggestion
current_data
current_data
current_data
==
last_data
value
data
remove
batch
common
server
python
suggestion
much
time
first
fetch
incidents
param
incase
white
space
past
wrong
fetch
page
suggestion
Documentation
https
//github.com/demisto/content/tree/master/docs/fetching_incidents
name
broad
build_event_context
functions
list
event
contexts
incase
single
event
list
entry
query
parameters
new
line
fetch-incident
long-running
commands
suggestion
err_msg
=
f'Error
f
integration_name
Integration
[
e
]
need
change
https
//github.com/demisto/content/pull/4487
creds
redundant
empty
value
filtering
use
function
CommonServerPython
dont
default
value
error
case
use
urljoin
params.get
'url
'/api/v2/
first
init
params
Dict
=
demisto.params
params
suggestion
case
response
JSON
TODO
error
code
comment
delete
packs
default
else
@
abaumgarten
necessary
suggestion
Checks
passwords
replaces
*
*
*
*
*
*
*
suggestion
r'password=
[
^
password=
*
*
*
*
*
*
entry
[
'parentContent
]
suggestion
'auto_detect_type
'indicator_type
suggestion
'auto_detect_type
'indicator_type
something
CommonServerPython
functionality
booleans
Please
client
declaration
BaseClient
stuff
variable
names
similar
confusions
headers_list
incorrect
os
commonserver
right
case
way
current
logic
test
create_issue_command
error
pytest.raises
Exception
res
req
explanation
comment
case
field_type
indicator.get
'fields
previous
comments
split
function
code
test_content.py
right
comment
sense
more
accurate
update_content_cmd
better
name
support
code
documentation
way
results
last
page
less
records
comment
suggestion
logs
handlers
'execute_logs
method
suggestion
need
empty
string
resource
comment
suggestion
tenant_id
=
demisto.getIntegrationContext
.get
'current_refresh_token
comment
note
index_select
[
]
operator
pitfall
suggestion
overall
impression
GATLayer
module
module
Maybe
better
images
s3
buckets
suggestion
refer
PyTorch
example
<
https
//github.com/dmlc/dgl/tree/master/examples/pytorch/tree_lstm
>
suggestion
implementation
Child-Sum
Tree-LSTM
@
BarclayII
dropout
adjacency
matrices/edges
message
passing
preprossed
preprocessed
block
comments
Add
Add
Add
line
pylint
disable=C0111
CI
check
Add
Add
module
DistDataLoader
same
comment
better
code
functions
code
readable
forced
convention
dsttype
nodes
[
num_dst_nodes
Remove
negative
input
nonnegative
backend
interface
specific
problem
@
yzh119
Could
functions
glob
module
Remove
same
same
grad
is_no_grad
functions
Seems
I'am
Iteration
PPI
Consiter
RPCContext
suggestion
*
*
generative
models
graphs
In-addition
suggestion
sure
hard
constraint
Subgraphs
suggestion
new
node
feature
suggestion
action
returns
True
destination
suggestion
Action
destination
val
scalar
vector
something
python
g.ndata
[
]
[
idx
]
docstring
self-contained
example
KVStore
sure
correct
inheritance
Suppose
tensors
h
node
feature
tensor
w
edge
feature
tensor
same
KVStore
service
support
tensors
partition
book
i
PR
much
dependency
bug
kvstore
concept
KVStore
docstring
KVStore
user-facing
API
Bool
support
https
//github.com/dmlc/dgl/pull/1487
input
graphs
same
attribute
schema
scenarios
involves
complex
schema
issues
graphs
edges
graphs
same
schema
logic
easier
future
add
comments
function
function
weird
users
ctrl+c
program
exit
training
job
completes
user
ctrl+c
remote
processes
emb_u
=
self.u_embeddings
nodes
self.emb_dimension
.to
self.device
emb_v
=
self.v_embeddings
nodes
self.emb_dimension
.to
self.device
check
valid
column
storage
None
sentence
Column
docstring
key
dict
policy
name
graph_partition_book.py
same
comment
above
comments
split
data
way
comment
free
memory
many
code
duplicates
https
//github.com/dmlc/dgl/blob/master/python/dgl/distributed/partition.py
L123
support
save/load
JSON
reuse
dgl.distributed.partition.load_partition
dgl.distributed.partition.partition_graph
TODO
int32
ID
file
partition
metadata
Currently
edge_map
separate
files
ip_list
different
server_list
DistGraph
name
meta
data
ambiguous
Please
explicit
documentation
order
edges
comment
range
partition
future
line
one
caveat
softmax
correct
numerically-stable
softmax
example
pre-softmax
scores
]
results
whole
thing
maximum
absolute
value
comment
description
Remove
RelGraphConvHeteroEmbed
RelGraphConvHetero
inputs
learnable
parameters
def
__init__
snip
self.embed_layer
=
RelGraphConvHeteroEmbed
=
nn.ParameterDict
ntype
nn.Parameter
torch.randn
g.number_of_nodes
ntype
ntype
g.ntypes
snip
h
=
self.embeds
layer
self.layers
h
=
layer
self.g
h
return
h
code
suggestion
treat
class
community
largest
subgraph
suggestion
Binary
community
subgraph
Cora
test
dataset
suggestion
original
graph
e.g
binary
community
subgraph
Cora
Exchange
order
L130
L131-133
One-hot
H
C
N
O
F
S
CI
redundant
end
Just
curious
FloatTensor
labels
training
set
LongTensor
labels
validation/test
set
Maybe
comments
Use
recv_func
=
dgl.function.sum
'hidden
'neigh
code
Use
canidates
>
candidates
d
name
something
AdaptiveGraphSAGE
attensions
>
attentions
redundants
users
more
sender
Python
functions
lower-case
different
C++
time
@
BarclayII
@
zheng-da
PR
Thanks
effort
@
jermainewang
@
zheng-da
look
discussion
@
BarclayII
problem
GraphInterface.Reset
jermainewang
@
zheng-da
look
discussion
@
BarclayII
problem
GraphInterface.Reset
in-coming
degrees
>
NOTE
temporal
>
temporary
Use
TargetCode
dgl.function.base
note
>
NOTE
temporal
>
temporary
same
Apply
relational
graph
convolution
basis
regularization
graph
convolution
input
signal
Relational
graph
convolution
RGCN
<
https
//arxiv.org/abs/1703.06103
>
__
Remove
L156
wrong
L25-L29
nn.Linear
self.linear
=
nn.Linear
in_feats
out_feats
bias=bias
L87-L90
self.linear
=
nn.Linear
in_feats
out_feats
bias=bias
L44-46
python
h
=
self.linear
h
=
p=dropout
procedure
nn.init
example
ReLU
activations
following
runs
uniform
initialization
correction
python
nn.init.xavier_uniform_
self.linear.weight
gain=nn.init.calculate_gain
'relu
code
individual
parameters
hint
initialization
different
Xavier
uniform
original
implementation
Xavier
uniform
L104-106
nei
=
self.linear
nei
changes
L83-L86
nei
=
self.dropout
nei
suggestion
animation
probability
trained
model
correct
graph
type
animation
probability
trained
model
correct
graph
type
advance
task
node
classification
embeddings
weird
true
unsupervised
setting
embeddings
node
classification
task
embeddings
node
classification
task
second
implementation
scalable
weird
negative
edges
nodes
train_nids
nodes
training
nodes
local
partition
data
different
ones
script
suggestion
following
code
prints
statistics
paper-author
relationships
suggestion
relationship
later
sections
suggestion
paper-subject
relationships
reverse
suggestion
print
pa_g.number_of_edges
edge
type
edge
type
argument
inputs
type
change
comment
something
create
dgl
graph
etype
IMPORT_URL
=
community.git.webservices_url
'contrib
community.git.webservices_url
api_path
valid
URL
real
webservices
endpoints
fake
one
mess
correct
URL
webservices_url
business
logic
newcomer
issue
afterward
smile
Broken
unable
//pastebin.com/raw/GDMvzGjc
Origin
InvalidLinkBear
Section
all.links
variable
loop
variables
different
variable
name
frig
below
label
label_object
didnt
comma
work
comments
helpful
content
low
value
GDPR
information
person
git
history
Best
data
copy
use
.values
need
key
Participant.objects.bulk_create
participants.values
specific
comment
meta-review
negative
score
types
>
pyflakes
warning/error
Comment
method
check_comment_update
good
name
method
state
complex
logic
logic
review
comments
meta-review
separate
punishment
likely
other
apps
gamification
app
interested
list
comments
meta-review
system
multiple
ways
e.g
future
many
times
log
warnings
people
punishment
isnt
analysis
algorithms
business
logic
Create
extra
public
method
generator
modified-after-meta-review
comments
able
dataset
documentation
other
people
list
people
method
list
'modified-after-meta-review
comments
dict
author
count_of_edited_comments_after_meta_review
log
update
authors
re-use
generator
user
[
]
fetch
operation
separate
management
command
people
many
times
problems
enhancement
community.git
data
different
repo
method
generator
new
reactions
logic
sync
logic
items
methods
Comment
Participant
code
self-documenting
comment
redundant
neutral
term
words
punishment
LATE_EDIT_SCORE_OFFSET
redundant
comment
Python
favour
readable
code
next
lines
readable
store
CONSTANTs
top
module
CONSTANTs
class
level
participants
p.login
]
=
p
common
branches
comment
inaccurate
response
variable
response
variable
P
comment
useless
useless
comments
incorrect
comments
code
better
comments
comment
useful
comment
code
simple
obvious
something
name
start
Hah
tiny
comment
ONLY
Raspberry
Pi
lines
Remove
comment
comment
edit
content
self.lastObject
+
>
time
timeout
comment
opposite
methods
useless-super-delegation
helpful
logs
external
IP
address
other
logs
future
comment
TODO
bug
jax2tf
nit
TODO
jblespiau
C++
jit
jaxlib.version
>
=
operator
overloads
einsum
alternative
syntax
cleaner
=
np.arange
.reshape
b
=
np.arange
.reshape
np.einsum
jil-
>
kl
b
array
[
[
]
]
]
]
]
np.einsum
[
]
b
]
]
equivalent
above
array
[
[
]
]
]
]
]
important
comment
kernel
pass
filter
interpolate
max_row_cols
max
a.shape
[
-2
]
Python
builtin
max
max
arrays
shape
Note
function
NumPy
*
same
np.transpose
last
axes
version
appropriate
attribute
finfo
e.g.
suggestion
rcond
*
max_rows_cols
np.finfo
a.dtype
unit
tests
possible
passing
sure
redundant
docstring
indent
text
code
block
online
docs
suggestion
keyword
argument
strip_zeros=False
jit-compatible
variant
>
>
>
roots_unsafe
=
jax.jit
jax.partial
np.roots
>
>
roots_unsafe
[
]
ok
DeviceArray
[
-2.+0.j
]
dtype=complex64
>
>
roots_unsafe
[
]
problem
DeviceArray
[
nan+nanj
]
dtype=complex64
>
>
np.roots
[
]
no-jit
version
DeviceArray
[
-2.+0.j
]
dtype=complex64
extra
cautious
keyword
suggestion
def
roots
p
*
strip_zeros=True
curiosity
TODO
little
hard
types
uint32
uint64
better
undefined
types
test
easier
undefined
cases
int8
uint16
uint32
uint64
comment
atleast_1d
jax
something
numpy
inconsistencies
scalar
values
https
//github.com/numpy/numpy/issues/16477
jax
differs
cases
scalar
values
v
length-1
arrays
mark
TODO
Please
add
comment
float16
JAX
jax2tf
same
thing
code
element
indices
list
length
equal
number
devices
way
comment
helpful
alternative
implementation
efficient
everything
everything
vmap
select
arguments
efficient
case
partial
batching
rules
https
//github.com/google/jax/pull/2138
comment
stale
succinct
should_tuple
=
tuple_args
tuple_args
None
avals
comment
good
strategy
track
TODOs
comments
order=n
argument
meant
tests
orders
check_grads
implementation
[
Autograd
version
]
https
//gist.github.com/mattjj/56ccccce4c438eeecd5386496d0e947c
actionable
PR
todo
list
sure
order=n
checks
orders
line
redundant
Note
api
public
name
entire
thing
underscored
part
jax
shim
symbols
api
kwargs
default
value
comment
TPUs
SVD
OK
@
least
let
comment
higher
precision
matmul
TPUs
jtu.cases_from_list
test
cases
JAX_NUM_GENERATED_TESTS
small
Let
use
tuple
names
harnesses
unique
arr.shape
different
easier
one_array_
prefix
bit
gotcha
JAX
TPUs
default
matmul
precision
insufficient
linear
algebra
jnp.dot
precision=lax.Precision.HIGHEST
TPU
performance
matrix
decompositions
awful
least
correct
results
comments
eye
public
lax
towards
able
special
nature
function
correctness
efficiency
comment
good
tool
division
added
constant
i.e
c
*
poly
+
k
integer-divided
c
right
note
todo
able
case
_device_put_sharded
x
pytree
right
xs
same
shape
dtype
Please
comment
conversion
overkill
type
check
code
core.skip_checks
False
latter
true
Feel
free
TODO
value
as-is
fine
higher
derivatives
Please
polygamma
zeta
documentation
https
Rather
lax.rem
operator
pred
value
sure
point
function
Python
comment
real
bugs
dtype
np.float16
jnp.float16
same
suggestion
extension
logic
name
type
tf_dtype.name
bfloat16
return
dtypes.bfloat16
elif
possible
dependency
tf
module
important
big
dependency
little
benefit
hacky
name
type
update_shape
tuple
Python
integers
little
fishy
latent
bug
easier
easy
general
rule
lax
primitives
semantics
scalars
few
exceptions
XLA
more
common
broadcasting
jax.scipy.special
wrapper
comment
broadcasting
lax
primitives
broadcasting
rank
promotion
TODO
note
explanation
worth
sense
comment
first
place
check
authors
Golub
Van
Loan
positive
definite
symmetric
positive
real
eigenvalues
feeling
P
Sorry
obligated
logit
uniform
key
shape
dtype
minval=onp.nextafter
dtype
dtype
sp
generates
comment
Insert
placeholder
None
indices
logical
index
delete
suggestion
mix
axis
name
one
invocations
comment
rules
unclear
rest
comment
suggestion
class
DropVar
Var
underscore
pdb
sessions
like
bit
namespace
e.g
internal
classes
underscores
IMO
optional
Can
comment
queries
complete
Project
Managers
Data
Collectors
Project
Users
private
projects
permissions
Role
|
public
|
public
+
|
private
|
private
+
Org
Admin
|
x
|
x
|
x
|
x
Org
Member
explicit
project
membership
x
|
|
x
|
|
Project
Manager
|
x
|
x
|
x
|
x
|
Data
Collector
|
x
|
|
x
|
|
Project
User
|
x
|
|
x
|
|
All
other
users
x
|
|
|
|
So
least
more
filter
join
ProjectRoles
Project
managers
private
archived
projects
public
archived
project
archived=True
distinct
afterwards
archived=True
Q
expression
earlier
organizationrole
expression
user
project
role
member
project
organization
organization
role
backoff
time
settings
ACCOUNT_LOGIN_ATTEMPTS_TIMEOUT
Ah
comment
much
attention
aspect
temporary
files
PR
current
implementation
bit
error-prone
exception
open
write_path
'wb
f
os.remove
write_path
path
servers
cronjob
temp
files
risk
volume
saved
files
patterns
Use
python
open
write_path
'wb
f
f.write
file
try
mime_type
GPX_MIME_TYPES
raise
InvalidGPXFile
os.remove
write_path
b
context
manager
import
Create
tempfile
visible
path
FS
accessible
f.name
tempfile.NamedTemporaryFile
f
f.write
instance.file.open
mime-type
browser
detection
gpx
mime
type
reliable
mime
=
magic.Magic
mime=True
mime_type
=
str
mime.from_file
f.name
'utf-8
GPX_MIME_TYPES
processor
=
GPXProcessor
f.name
=
processor.get_layers
layer
layers.keys
layers
layer
]
SpatialResource.objects.create
resource=instance
name=layer
geom=layers
layer
]
raise
InvalidGPXFile
_
Invalid
GPX
mime
type
error
.format
error=mime_type
collection
files
something
tempfile.TemporaryDirectory
easy
directory
larger
operations
context
manager
developer
cleanup
above
examples
high
level
confidence
file
massive
failure
system
general
idea
os.path.join
settings.MEDIA_ROOT
'temp
bit
anti=pattern
cleanup
end
request/response
cycle
PR
code
pattern
Cadasta
Platform
codebase
PR
towards
tempfile
management
only
concern
typical
users
technical
details
standard
GPX
files
personal
preference
UI/UX
point
view
individual
GPX
resource
files
everything
GPX
file—waypoints
routes
tracks—are
layer
things
simpler
users
Leaflet
layer
control
shorter
customized
UI
map
layers
part
https
//github.com/Cadasta/cadasta-platform/issues/1476
grouped
layer
control
additional
issues
lots
gpx
resources
feeling
ok
changes
layer
control
separate
issue
better
structure
GPX
file
user
able
layers
UI
future
worried
query
logic
wrong
first
lines
query
Project
user
member
organization
b
organization
admin
Org
Admin
=
Project.objects.exclude
organization__organizationrole__user=user
Org
public
user
org
project
active
=
public_user_projects.filter
projectrole__role__isnull=True
organization__archived=False
'organization
concerned
nested
queries
method
related
orgs
org
lookup
user
org
role
org
role
==
'admin
lookup
org
projects
org
role
=
org
unarchived
projects
projects
lookup
user
project
role
bit
inefficient
likely
customers
part
many
organizations
loadtime
issues
members
Programs
team
general
rule
thumb
query
loop
room
improvement
beginning
rest
something
works
@
staticmethod
def
_get_orgs
user
itertools
groupby
Let
project
projects
org
user
admin
all_projectroles_user_is_admin
=
user.projectrole_set.filter
project__organization__organizationrole__admin=True
project__organization__organizationrole__user=user
Let
project
unarchived
projects
unarchived
org
user
admin
unarchived_projectroles_user_is_not_admin
=
user.projectrole_set.filter
project__organization__organizationrole__admin=False
project__organization__organizationrole__user=user
Combine
iterable
is_admin__qs
=
[
True
all_projectroles_user_is_admin
]
[
False
unarchived_projectroles_user_is_not_admin
]
is_admin
qs
is_admin__qs
qs
=
'project
'project__organization
def
get_org
pr
return
pr.project.organization
org
projectroles
groupby
qs
get_org
yield
is_admin
[
pr.project
pr.role_verbose
pr
projectroles
]
handle
projects
project
public_user_projects
=
Project.objects.filter
organization__users=user
.exclude
projectrole__user=user
'organization
def
get_org
proj
return
proj.organization
org
projects
groupby
public_user_projects
get_org
yield
False
[
pr
_
'Public
User
pr
projects
lookup
ProjectRole
objects
'project
'project__organization
user
project
projects
organizations
single
shot
user
admin
project
role
queries
admin
non-admin
cases
single
query
power
Django
object
project
role
information
cases
number
queries
fixed
amount
queries
user
numbers
organization
projects
look
same
logic
prettier
empty
line
suggestion
>
>
>
key
=
np.random.rand
key_elements
key_depth
suggestion
>
>
>
query
=
np.random.rand
query_elements
query_depth
suggestion
>
>
>
query
=
np.random.rand
query_elements
query_depth
suggestion
>
>
>
value
=
np.random.rand
key_elements
value_depth
suggestion
>
>
>
key
=
np.random.rand
key_elements
key_depth
cast
need
p_sum
self.true_positives
tf.float32
cast
comment
TODO
Add
support
calculations
lines
private
API
only
way
seanpmorgan
Sean
suggestion
pylint
enable=bad-continuation
suggestion
pylint
disable=bad-continuation
tf.control_dependencies
[
tf.debugging.assert_equal
query_shape
]
message=
Query
points
last
dimension
pylint
enable=bad-continuation
arguments
__init__
method
fine
current
implementation
same
comment
variables
test_
*
variables
able
variables
able
on_epoch_end|begin
method
inner
methods
on_epoch_
*
*
many
code
model.evaluate
epoch
progress
bar
evaluate
user
self.show_epoch_progress
opinion
comment
Typo
orifinal
>
original
Typo
matrxi
>
matrix
cast
necessary
fix
something
def
test_cohen_kappa_single_batch
obj
=
CohenKappa
regression=True
sparse_labels=True
obj.update_state
tf.ones
tf.ones
numeric
result
variable
train/eval/test
standard
ordering
Just
curious
'\n
tf.logging
same
format
other
TF
logs
training
magic
number
const
top
number
mind
future
regular
python
cond
eager
mode
box
graph
mode
autograph
internal
conversion
ops
Remove
print
s
ditto
Use
full
name
variables
tp
>
true_positive
comments
name
variables
wrong
]
batch
size
y_true.get_shape
]
print
statement
B
N
Dq
timestep
depth
query
code
user
plain
assserts
error
case
ValueError
appropriate
Assert
unit
tests
AssertErrors
general
similar
plain
Exception
bad
practice
None
default
int
dangerous
u
None
None
Question
einsum
code
simplicity
efficient
matmul
case
keras
supports
keyword
argument
necessary
values
list
long
line
chars
comments
tf.contrib
meaning
shape
info
arguments
function
great
improvement
other
code
readers
maintainers
functions
tf.function
max_seq_len
lot
batches
many
retraces
input
signature
least
current
TF
issue
graphs
input
shape
changes
https
//github.com/tensorflow/tensorflow/issues/29075
comments
tf.contrib
meaning
shape
info
arguments
function
awesome
good
def
_reset_noise
Create
factorised
Gaussian
noise
pylint
enable
suggestion
output_v
output_states_v
=
cell
state
limitation
issue
GPU
able
optimizers/test/run_all_tests.py
decorators
decorated
Class
sense
recursive
assignment
runs
default
variables
lr_mult
parent
layer
methods
clearer
open
alternative
ideas
object
access
name
weight
object
propagate
parameter
comment
short
graph
mode
causes
problems
access
variables
variables
initialized
ok
sorry
xxx
TF2.4
Thank
bbox
box
Comment
obvious
code
afraid
distance
y_pred
details
users
Sure
tolerance
loss
tests
1e-3
tolerance
1e-5
more
precision
@
WindQAQ
Hi
whole
block
broad
dangerous
cl_obj
=
conxxxxx.Conxxxx
pylint
disable=not-callable
assert_allclose_according_to_type
reasonable
statement
disabled
ambiguous
empirical
suitable
documentation
Same
comments
other
layers
statement
true
statement
next
layer
certain
types
e.g.
linear
layers
trained
model
scale
model
identical
inference
output
scale
disabled
fact
significant
negative
effect
training
comfortable
broad
statements
minimum
pre-condition
statement
__Empirically__
accuracy
__more__
stable
__than
batch
norm__
wide
range
__small__
batch
sizes
__if
rate
linearly__
batch
sizes
documentation
suitable
place
such
empirical
findings
disclaimer
author
paper
news
case
input
tensor
axis
C/G
H
W
Batch
G
definition
way
C
BatchNorm
layer
analogy
axis=
[
Batch
G
]
analogy
bit
better
way
axis
channel
dimension
clearer
documentation
layer
tensors
Same
comment
applies
other
norms
warning
user
pass
'groups
kwargs
Syntax
fix
good
different
result
..
https
//colab.research.google.com/drive/1jQ9rkZs9501AP8ADhzwuv_3pQaRzW9I2
FWIW
old
syntax
[
dtype
cast
loss
]
https
//github.com/tensorflow/addons/blob/master/tensorflow_addons/losses/focal_loss.py
L123
types
placeholder
test
case
decorator
test_utils.run_deprecated_v1
way
shape
None
graph
build
time
https
//github.com/tensorflow/addons/issues/260
issuecomment-494886404
output
values
pylint
comment
pylint
xxx
Thanks
decorator
test_
*
methods
class
false
alarm
pylint
python2
graph-level
seed
seeds
operation-level
seed
function
throw
ERROR
test_theoretical_gradients_float64
__main__.RreluTest
test_theoretical_gradients_float64
__main__.RreluTest
Traceback
recent
call
last
/usr/local/lib/python2.7/dist-packages/absl/third_party/unittest3_backport/case.py
line
testPartExecutor
yield
File
/usr/local/lib/python2.7/dist-packages/absl/third_party/unittest3_backport/case.py
line
testMethod
/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/test_util.py
line
f
args
*
*
kwargs
/usr/local/lib/python2.7/dist-packages/absl/testing/parameterized.py
line
bound_param_test
test_method
*
testcase_params
/root/.cache/bazel/_bazel_root/e051f2f195071208ea7f081f88730f4f/execroot/__main__/bazel-out/k8-opt/bin/tensorflow_addons/activations/rrelu_test.runfiles/__main__/tensorflow_addons/activations/rrelu_test.py
line
test_theoretical_gradients
theoretical
numerical
tf.test.compute_gradient
rrelu
[
x
]
/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py
line
compute_gradient
return
_compute_gradient_list
f
x
delta
/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gradient_checker_v2.py
line
_compute_gradient_list
xs
i
delta
i
range
xs
]
AttributeError
'Addons_Rrelu
object
attribute
'shape
suggestion
dynamic
shape
TensorArray
TFLite
tensor
shape
gamma
beta
batched
images
output
FC
ways
assert
input_shape
TODO
support
more
shapes
future
code
various
sizes
favour
scope
PR
case
channels
last
image
dimensions
case
N
H
W
C
docstring
image
arg
clear
tf.control_dependencies
https
//github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/check_ops.py
L1445-L1449
>
Returns
Op
InvalidArgumentError
rank
x
ranks
static
checks
x
matching
rank
no_op
tf.control_dependencies
tf.function
s
followup
computation
check
unit
tests
channes_num
uint8
images
float64
images
Please
unused
line
Thanks
WindQAQ
python
six.moves
xrange
pylint
disable=redefined-builtin
import
np
six.moves
xrange
pylint
disable=redefined-builtin
import
tensorflow
tf
tenxxxxx
A
googler
https
//github.com/huangyp
Remove
double
space
comment
line
testable
docstring
y_true
=
tf.expand_dims
y_true
more
succinct
ditto
rid
self.cached_session
Please
line
spaces
exception
invalid
tau
<
tau
raise
ValueError
tau
range
[
]
line
ditto
Seems
value
tf.math.maximum
tf.keras.backend.maximum
wrapper
https
//github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py
L2399
Use
backticks
tf.keras
eps
denominator
tf.math.log
numerator
/
denominator
+
eps
case
denominator
better
python
tf.matmul
weight_mat
tf.reduce_sum
keepdims=True
https
//www.tensorflow.org/api_docs/python/tf/linalg/matmul
version=stable
lot
duplicated
code
possible
necessary
test
valid
data
SAS
UUT
invalid
request
injection
necessary
test
code
fine
current
implementation
correct
input
function
cbsd_ids
grant_ids
tuple
option
fine
option
input
assertHeartbeatsSuccessful
tuple_of_cbsd_ids_grant_ids
operation_states
cbsd_ids
grant_ids
tuple_of_cbsd_ids_grant_ids
good
output
new
function
output
format
assertRegisteredAndGranted
tuple
cbsd_ids
grant_ids
change
same
PR
sense
output
format
assertRegisteredAndGranted
input
format
assertHeartbeatsSuccessful
sure
Thoughts
gut
reaction
assertRegisteredAndGranted
oddball
right
tuple
test
case
helper
implementation
assertHeartbeatsSuccessful
decision
implementation
assertRegisteredAndGranted
list
dicts
keys
'grantId
Sorry
options
Option
return
[
cbsd1
cbsd2
]
[
grant1
]
Option
return
cbsd1
grant1
cbsd2
grant2
fine
consistency
functions
code
functions
option
option
consider
namedtuple
Please
GWPZ
record
Lines
368-370
device_3
location
gwpz
zone
gwpz_record_0.json
Better
device_3
[
'installationParam
]
[
'latitude
]
device_3
[
'installationParam
]
[
'longitude
]
=
getRandomLatLongInPolygon
gwpz_record_1
double
other
device
locations
GWPZ
zone
Comment
applicable
GPR
Change
meters
>
Comment
applicable
GPR
in-band
out-of-band
CBSDs
comment
clearer
comments
meters
spec
Eg
Line
etc
..
same
EPR.2
Typo
'outisde
>
Same
EPR.2
devices
certain
radius
ESC
way
clear
respect
esc_record
lat
/
device_1
[
'installationParam
]
[
'latitude
]
=
[
'installationParam
]
[
'latitude
]
device_1
[
'installationParam
]
[
'longitude
]
=
[
'installationParam
]
[
'longitude
]
same
EPR.2
line
clearer
device_2
needs
Good
idea
cbsd
cluster
list
PPa
please
refer
SIQ3
alredy
SIQ3
Add
devices
cluster
list
PPA
ppa_record
[
'ppaInfo
]
[
'cbsdReferenceId
]
=
[
cbsd_ids
]
cbsd_ids
]
]
cbsdReferenceID
s
ppaInfo
Same
comment
Similar
comment
Check
presence
ppaRecordsN3
above
insert
condition
line
change
previous
comment
Kate
kate-harrison
Jan
Contributor
possibility
multiple
codes
acceptable
single
response
REG.11
list
sets
error
scenarios
parameters
invalid
parameters
different
SASs
different
response
codes
comment
grant_expire_time
current_time
heartbeat
request
response
Timer
necessary
worried
problems
use
later
licenseFrequencyChannelId
pal_record
[
'palId
]
=
/
.join
[
pal
same
date
code
fcc_channel_id
]
current
implementation
interesting
ways
PAL
ID
input
spec
A
PPA
SAS
ppa_record_1
list
field
name
singular
'ppaRecord
Same
PPR.2
meters
>
km
Same
PPR.2
getRandomLatLongInPolygon
ppa_record_1
better
choice
Same
PPR.2
diff
significant
differences
only
addition
Same
comment
other
file
exercise
tests
exceptions
safe
Utility
functions
fine
chardict.items
tuple
problem-specification
Tests
problem-specifications//canonical-data.json
@
v1.2.0
problem-specifications
Tests
problem-specifications//canonical-data.json
@
v1.0.0
mirror
stub
[
yacht
]
https
//github.com/exercism/python/blob/master/exercises/yacht/yacht.py
exercise
suggestion
'-v
flags
sure
current
test
function
names
test
descriptions
Example
def
test_robot_created_with_position_and_direction
name
paraphrase
paraphrase
possible
comment
clarification
detailed
explanation
tests
precedent
canonical
tests
sure
best
interpretation
canonical
data
callbacks
@
petertseng
[
]
https
//github.com/exercism/problem-specifications/pull/1194
issuecomment-367780745
callbacks
executable
code
anything
time
better
way
something
free
PR
Please
print
statements
Apologies
delay
canonical
data
tests
Stub
files
other
exercises
comment
first
exercise
students
familiar
stub
suggestion
pass
great
IndexError
reason
other
details
suggestion
tests
filter
suggestion
tests
map
Redundant
comment
new
format
version
name-change
x-common
problem-specifications
while
Tests
problem-specifications//canonical-data.json
@
v1.0.0
Canonical
data
v1.2.0
tests
ok
tests
version
update
problem-specifications
inputs
input
key
problem-specifications
ie
Tests
problem-specifications//canonical-data.json
@
v1.3.0
comment
line
sake
consistency
ie
blank
rows
redundant
tests
Queen
individual
position
redundant
parentheses
cause
exception
suggestion
permutation
result
None
following
Remove
code
return
sum
value
value
range
limit
value
%
multiple
==
multiple
multiples
multiple
>
version
number
wrong
canonical
data
version
extra
blank
line
order
flake8
tests
compliance
PEP8
examples
misstake
other
file
/
Redundant
comment
suggestion
focal
spot
shifts
divergent
beam
geometries
test
pass
comment
first
output
line
input
line
i.e.
write
>
>
>
comment
code
comment
period
timedelta
fine
plural
amenable
general
overlap
stdlib
names
timestamp
valid
thru
datetime
constructor
Timestamp
whoops
comment
np.add
little
expl
parametizations
obvious
e.g
flip
shuffle
obvious
Series.add
series
informative
name
new
test
exercising
confusing
same
terms
b
c
left_array
right_array
bit
readable
IMHO
left_series
right_series
Thanks
@
amy-graham-js
welcome
comment
error
arrays
BooleanArray
looks
more
comment
source
expected
error
comment
error
[
breakpoint
]
https
//docs.python.org/3/library/pdb.html
test_to_boolean_array_error
values
error
arrays
BooleanArray
breakpoint
pytest.raises
TypeError
pd.array
values
dtype=
boolean
test
pytest
pandas/tests/arrays/test_boolean.py
breakpoint
command
pd.array
values
dtype=
boolean
error
comment
last
sentence
relevant
bonner
short
eg
DST
type
ignore
mypy
github
issue
number
mypy
error
message
comments
tricks
>
libreduction
fastpath
happy
datetimelike
PR
freeze
Easy
cut/paste
DatetimeIndexOpsMixin
TODO
op
EA
Series
master
Same
other
one
file
much
compatibility
python
]
pd.MultiIndex.from_tuples
pd.date_range
periods=4
master
>
def
tuples_to_object_array
ndarray
[
object
]
tuples
cdef
Py_ssize_t
i
j
k
tmp
ValueError
dtype
'M
buffer
Cython
raise
pytb
TypeError
Traceback
recent
call
last
ipython-input-2-bf92ca748af3
>
<
module
>
>
pd.MultiIndex.from_tuples
pd.date_range
periods=4
~/sandbox/pandas/pandas/core/indexes/multi.py
from_tuples
cls
tuples
sortorder
tuples
tuples._values
>
arrays
=
list
lib.tuples_to_object_array
tuples
elif
isinstance
tuples
list
arrays
=
list
lib.to_object_array_tuples
tuples
TypeError
Argument
'tuples
incorrect
type
DatetimeArrayMixin
use
pytest.raises
fixtures
immutability
indexes
immutable
Fixed
indentation
xfail
other
changes
comments
same
comment
copy
occur
hypothesis
assume
dropna=False
comment
Fixed
indentation
skips
other
changes
comments
comment
values
current
state
PR
ordinals
codes
Period
case
Categorical
right
int64
copies
same
comment
test
None
np.nan
pd.NA
pd.NaN
pd.NaT
something
s
GH19406
mask
=
[
]
assert
mask
==
series.isnull
sympton
problem
comment
instructive
sympton
problem
object
dtype
NO
conversion
list
odd
list-ifying
*
*
constructor
case
engine
issue
number
necessary
point
repr
changes
Reference
PR
part
comment
e.g
add
gh-26381
end
comment
comment
internal
comment
useful
comment
empty
columns
empty
index
comment
issue
number
sure
meaningul
comment
explicit
_gen_mi
docstring
comment
suggestion
plots
]
]
=
fig.add_subplot
sharey=plots
]
]
]
]
=
fig.add_subplot
sharey=plots
]
]
suggestion
fig
=
self.plt.figure
=
fig.subplots
Create
*
axes
first
third
columns
plots
]
]
=
fig.add_subplot
sharex=plots
]
]
]
]
=
fig.add_subplot
sharex=plots
]
]
sure
i
comment
comment
filler
use
list
np.array
.T
necessary
reshape
method
boolean
indexing
document
part
expected
interface
__getitem__
setitem
*
inplace
mutable
object
Can
example
pandas
registration
sub-type
Please
drop
pass
methods
docstrings
suffice
valid
values
indexer
Does
fill
value
document
*
rid
_slice
default
implementation
comments
dimensionality
reduction
array
>
scalar
things
helper
function
easier
least
example
obvious
NumPy
user
expensive
difficult
example
numpy
array
dtype=object
OK
approximate
answer
lower
bound
number
required
bytes
method
benefit
memory_usage
Type
comments
docstring
http
//mypy.readthedocs.io/en/latest/python2.html
examples
document
clear
differ
same
length
self
least
requirement
constructor
object
user
types
comment
issue
number
PR
number
tests
fine
test
generated
values
dictionary
comment
flags=0
doc
decorator
template
formatted
string
__doc__
decorator
original
template
fake
code
example
@
doc
method='cummax
def
cummax
method
method
cumulative
operation
@
doc
cummax
method='cummin
def
cummin
pass
cummin
template
cummax
@
doc
cummax
__doc__
template
original
template
good
idea
code
least
intuitive
questions
better
explanation
code
block
example
type
ignore
comments
current
approach
slight
preference
way
behavior
consistent
easier
kinds
docstring
opinion
doc
decorator
friendly
other
doc
decorator
indeterminate
doc
decorator
friendly
docstring
format
such
function
doc
decorator
details
doc
decorator
indeterminate
doc
decorator
decorator
friendly
current
approach
template
__doc__
doc
decorator
function
doc
decorator
friendly
addition
user
docstring
consistent
behavior
comment
comment
GH
issue
number
blank
line
case
comments
lines
comment
doc-string
comment
deep=False
default
*
deep
copy
things
change
self.df
=
df
comment
dispatch
categricals
impl
such
type
annotation
terminology
user
facing
docstrings
fine
type
comments
docstrings
general
discussion
current
docstring
guidelines
everybody
Union
tag
use
is_period_arraylike
IIRC
rid
correct
way
next
comment
pd.Series
/
pd.Index
types
tested
below
’
https
//travis-ci.org/pandas-dev/pandas/jobs/411841573
pd.Index
[
]
dtype=object
comment
FYI
Same
comment
cases
get_loc
different
error
..
get_loc
code
few
places
TypeError
Separate
issue
end
impact
result
cases
correct
data
something
sure
GH
ref
places
result
obj.value_counts
test
valid
test
feasible
expected
sort
order
sort
order
behaviour
list
array
further
treats
such
_object_
indexing
array
bool
values
raises
case
nullable
boolean
comment
cbday_roll
syntax
future
reader
comment
doc-string
line
try-except
nicer
error
message
failure
Same
question
try-except
array
only
thing
pandas/array/__init__.py
pattern
i
Series/Index
non-string
/
NA
data
way
sure
None
NA
handling
consistent
future
impl
Dictionary
type
Categorical
different
day
IIRC
None
value
user
object
array
surprised
tests
weird
>
python
keyword
https
//github.com/pandas-dev/pandas/issues/28527
issue
number
comment
issue
number
comment
reason
special
case
IOW
concat_same_type
pass
copy
flag
IOW
block
same
code
@
jreback
values.base
None
test
merge
logic
concatenate_join_units
https
//github.com/jorisvandenbossche/pandas/blob/2125ac09726cfc720def79e836398ed04ecae04a/pandas/core/internals.py
L5332
sure
comment
issue
number
example
issue
.loc
alignment
case
testf.loc
[
mask
]
=
df.loc
[
mask
]
Parametrize
True/False
observed
fixture
top
level
conftest.py
setup_method
opaque
path
class
anything
classes
file
refactor
later
change
Stylistic
nit
bracket
notation
dot
notation
dict
way
Similar
comment
literals
Same
comment
stylistic
implicit
line
continuations
code
base
opening
paranethes
better
literal
values
expressions
easier
parametrization
local
dict
use
result=
tm.assert_frame_equal
df_row
looks
part
buf.write
lines
clinebuf
line
few
words
way
good
comment
TODO
easier
down
comment
other
note
reference
issue
comments
PR
margins
True
margins_name
last
row
column
assert
last
row.name
/
col.name
==
margins_name
blank
line
axis=
need
if/then
approrpaite
issues
numbers
comment
Could
comment
comments
enough
comment
*
*
try/except
sure
comment
comment
Can
github
issue
number
comment
Categorical.from_codes
@
pytest.mark.parametrize
data
bins
labels
expected_codes
expected_labels
[
[
]
]
A
B
]
]
A
B
]
[
]
]
]
]
]
]
def
test_cut_non_unique_labels
data
bins
labels
expected_codes
expected_labels
GH
result
=
cut
data
bins=bins
labels=labels
=
Categorical.from_codes
expected_codes
categories=expected_labels
tm.assert_categorical_equal
result
issue
number
comment
Reference
issue
number
comment
type
type
Union
[
Period
Timestamp
Timedelta
NaTType
]
>
None
note
docstring
NaT
OK
TODO
type
IMO
merge
other
commits
separate
test
expected
argument
Hmm
reduction
’
t
comment
comment
tests
next
person
idea
issue
number
Double-checked
new
comment
re
next_year.year
pls
blank
line
comments
comments
good
FYI
blank
line
indentation
same
from_product
from_arrays
needs
cases
separate
test
same
blank
line
unittest
classes
decorators
experience
anything
documentation
Unless
straightforward
way
comment
level
names
integer
ambiguous
issue
number
Nit
period
end
comment
second
change
version
reads
utc
=
len
dates
dates
]
.tzinfo
None
data
=
tools.to_datetime
dates
single
test
tests
bit
overkill
issue
number
non-performant
check
array
len
key
index
comment
bit
expected
result
entire
dataframe
assert_frame_equal
trivial
i
np.place
more
common
comment
next
line
sentence
issue
new
test
dtype
comment
/
pep
ref
Note
new
implementation
breaks
round-tripping
worthwhile
trade-off
clarity
new
repr
IMO
i
pet
peeve
1-letter
variable
names
e.g
cat
same
comment
separate
test
move
separate
test
function
move
maybe_box_to_native
native
argument
results
Timestamps
correct
full-docstring
type
small
comment
string
python
comment
temlate_first
definition
scoped
somebody
code
code
noqa
F401
similar
test
Series
periods
Timestamp
pandas/tests/series/test_timestamp.py
IIRC
test_period.py
series
sure
right
error
message
tm.assert_raises_regex
safe
unclear
ATM
recent
pytest
same
different
positions
NaN
correct
False
interesting
[
ins
]
idx
]
Float64Index
[
nan
]
dtype='float64
ins
]
idx.sort_values
ascending=True
Out
]
False
notes
[
options
documentation
page
]
https
//pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html
Pandas
point
+/-
inf
nan
values
default
behavior
point
big
help
pd.option_context
True
value
option
pass
isfinite=pd.get_option
'mode.use_inf_as_null
jreback
expected
behavior
s
=
pd.Series
[
-np.inf
np.nan
]
pd.option_context
True
s.argmax
s.argmax
skipna=False
nan
e.g
mode.use_inf_as_na
case
empty
series
OutOfBoundsDatetime
more
clear
error
So
similar
comment
preferable
base
class
vast
majority
copy
/
paste
indifferent
route
cleanup
follow
issue
sure
need
comment
one
L552
choice
parametrizations
Can
comment
smoke
test
reference
issue
other
new
tests
i.e
GH
context
manager
LINT
errors
inline
class
block
opening
preferable
nit
TODOs
docstrings
comments
ensure_clean_path
pytest
fixture
time
issue
many
occurrences
suggestion
attribute
fold
argument
dt
other
cases
fold
*
*
2020-01-01T00:00:00+00:00
datetime
tzinfo=datetime.timezone.utc
None
special
cases
integers
fold
worth
other
suggestion
semantics
Timestamp
problem
fold=1
perverse
API
naive
datetime
time
zone
fold
Timestamp
constructor
error
fold
*
*
places
datetime
constructor
Timestamp
constructor
sensible
fold=1
datetime
fold=0
Timestamp
exceptions
fold
anything
*
datetime
aware
datetime
real
cases
ambiguity
inside
test
issue
number
comment
comments
statements
comments
section
tests
top
curiosity
move
block
message
L911
tests
empty
EA
types
period
interval
categorical
good
place
result_values
*
above
issues
same
input
hard
Please
cases
comment
test
below
purposes
reverses
loop
move
condition
above
elif
appropriate
comment
little
room
flakiness
kinds
tests
<
something
same
blank
line
else
raise
TypeError
result
end
clear
cases
issue
number
comment
test
lot
nicer
comments
L2093
nested
try
/
coment
L2097
something
meaningful
comment
.to_numpy
GH
issue
reference
comment
comments
subtract
index
column
max_cols_adj
=
esnure
least
....
ok
pls
comment
what/why
general
routine
pandas
look
comment
>
blank
line
half-sentence
next
reader
gist
motivation
line
Could
Series
inputs
raise
alt
issue
reference
TODOs
issue
helpful
comments
Same
comment
check
beneficial
comment
imports
imports
top
part
cleaning/refactor
https
//github.com/pandas-dev/pandas/blob/250574eda5302b6941f8c766f520f67226aadad7/pandas/core/indexes/base.py
L194-L198
more
clear
parametrized
test
e.g
@
pytest.mark.parametrize
indexer
exp
[
....
slice
[
]
def
test_list_like
indexer
exp
....
familiar
look
todos
TODO
py27
similar
EA
t
comment
original
context
i
suggestion
GH34487
_convert
object
types
routines
pandas
test
exact
same
error
message
tests
other
non-existing
intervals
values==-1
definition
nan
comment
issues
closed
oh
'houston
problem
everything
pass
nit-pick
df
convention
GH37635
DTA/TDA/PA
e.g
NaT
>
look
meta
data
file
lots
_
define
things
pytables
helpful
comment
issue
How
h5dump
utility
size
files
test
compression
data
tm.makeDataFrame
similar
other
reduction
functions
test
straightforward
Seemed
strange
sum
NA
values
others
Prod
bugs
more
detail
few
days
specific
things
dtype
DtypeObj
>
DtypeObj
comment
out-of-context
TODO
same
comment
check_index_type
timedeltas
/
period
hmm
reason
np.nan
’
t
.values
property
followup
prob
format_object_summary
EA
method
yep
comment
TODO
unavoidable
generic
formatter
Index
EA
idem
nbytes
comment
*
*
validate
_simple_new
main
constructor
comment
doc-string
proper
doc-string
Can
>
>
>
line
doctest
+SKIP
line
read_csv
Minor
nit
full
GH
comment
>
>
df
doctest
+NORMALIZE_WHITESPACE
case
X
random
sense
>
>
>
np.random.seed
>
>
>
df
=
pd.DataFrame
A
quarterly
-2010
np.random.rand
A
quarterly
-2011
np.random.rand
B
quarterly
-2010
np.random.rand
B
quarterly
-2011
np.random.rand
X
np.random.randint
size=3
]
=
df.index
>
>
>
df
doctest
A
quarterly
A
quarterly
-2011
B
quarterly
-2010
B
quarterly
X
comment
Can
original
name
test
github
issue
number
comment
test
example
PR
comment
Same
other
tests
klass
numpy
object
array
list
test
array
pd.NA
w/o
issue
number
comment
Add
_raises
end
test
name
issue
number
comment
helper
methods
e.g
nested
loops
function
cell
@
detrout
method
bit
compat
other
readers
vertical
cell
merging
extensions
code
ideal
please
feedback
Minor
code
sample
format
specifier
print
statements
comment
docstring
comment
issue
number
comma
'difference
>
'difference
comma
single
string
operator
matches
exact
matches
string
python
]
'eren
'difference
]
True
]
'eren
'difference
]
False
comment
able
tests
duplicative
test_base
union
tests
other
files
mean
issue
impl
IOW
next
person
set_position
come
ref
issue
comment
b
Ipython
refernce
routine
multi-multi
joins
Generally
test
function
commentary
comparisons
sense
NA
logical
test
separation
Similar
comment
construction
TODO
outstanding
followup
fixtures
result
new
test
Parentheses
unnecessary
noqa
historical
artifact
flake8
type
comments
noqa
extra
things
IOW
offsets.pyx
necessary
Is
test
verifies
mixed
tz
example
issue
file
data
variable
orders
aware/naive
aware/aware
case
ride
obj
loop
i.e
@
pytest.mark.parametrize
'data
[
[
pd.Timestamp
]
[
pd.Timestamp
]
[
pd.Timestamp
tz=
US/Central
]
def
test_mixing_naive_tzaware_raises
arr
=
np.array
data
commentary
Series
case
Slight
preference
o.dtype.name
case
purpose
issue
number
comment
comments
fix
specific
fillna
things
shift
cumsum
list
/
operations
groupby.base
line
docstrings
neat
trick
last
piece
logic
private
function
pre-cursor
PR
couple
things
Add
newlines
tm.assert_frame_equal
easier
Construct
output
DataFrame
constructor
point
example
f
'sum
f
np.sum
same
actual
result
e.g
result
=
f
'sum
func_result
=
f
np.sum
=
DataFrame
tm.assert_frame_equal
result
func_result
consistency
tm.assert_frame_equal
result
correctness
~~~
May
something
able
suggestion
>
>
>
pd
func_name
'data.csv
doctest
+SKIP
need
note
>
>
>
extra
space
P
SKIP
/tmp/
clearer
user
data.csv
ok
future
PR
conditions
section
unweildy
document
possible
condition
MultiIndex
check
else
same
condition
bit
level
None
bespoke
condition
isinstance
check
MultiIndex
comment
below
many
special
cases
possible
issue
number
comment
comment
non-unique
case
blank
line
comment
[
previous
comment
]
https
//github.com/pandas-dev/pandas/pull/21515
discussion_r195999517
@
pytest.mark.parametrize
'index
[
[
]
]
]
pytest.mark.parametrize
'drop_labels
[
[
]
]
]
reason
combinations
>
approach
more
compact
OK
same
applies
comment
test
inplace=True
False
parameterized
test
Add
comment
error
error
i.e
encoding
argument
parameter
correct
relevant
shape
rowlike
comment
more
explict
master
CI
type
comment
syntax
compat
descriptive
name
comment
GH
mypy
message
comment
comments
test
comment
=
np.asarray
right
positional
indexer
column_op
something
today
business
day
other
=
other
+
sign
*
self.next_bday
self.n
*
sign
>
hour
minute
=
earliest_start.hour
earliest_start.minute
hour
minute
=
lastest_start.hour
latest_start.minute
.....
same
else
return
datetime
other.year
other.month
other.day
hour
minute
comments
meaningful
variable
names
fixture
GH25303
comment
clarity
NaNs
construction
clear
NaNs
something
=
Series
Categorical
b
]
categories=
[
b
]
sufficient
test
comments
conditions
top
logic
easier
Can
optional
List
/
Dict
callable
subtypes
Same
comment
comments
blank
line
loop
clear
Index
test
test
mplt_compat
behaviour
case
assert_produces_warning
added
warning
class
bit
cleaner
code
attribute
below
comment
comment
doc-string
return
None
empty
Index
attempt
actual
external
error
message
raise
TypeError
test
purposes
pytest.approx
vulnerable
unrelated
failures
e.g
pytest
comment
separate
test
_div_
test
tests
bit
wordy
following
clear
=
pd.Series
[
True
False
True
False
]
result
=
axes.apply
lambda
ax
ax.yaxis.get_visible
tm.assert_frame_equal
result
same
clearer
blank
line
cases
copy
necessary
DataFrame.append
new
object
result
df
reason
branch
IIRC
perf
issue
IOW
compat=False
code
long
time
comment
Series.sparse
SparseSeries
>
SparseSeries
>
Series
[
sparse
]
undesired
warning
Series.sparse.from_coo
Once
SparseSeries
keyword
comments
TODO
EA
repeated
values
looks
same
case
is_float
label
is_integer
label
self.values
@
jreback
test
sure
bug
intention
>
safe
builds
docstrings
general
func
docstring
func.__doc__
None
something
one-line
pandas/core/generic.py
docstring
_shared_docs
deprecation
nit-pick
comments
git/blame
track
changes
same
same
Could
docstring
function
familiar
helpful
comment
imports
top
file
need
*
refer
tests
first
assert
Similar
feeling
parameterization
parts
nice
others
comment
callable
Similar
comment
able
pd.isnull
list
comp
isna
*
ones
specific
Timedelta
TDI
actual
how=
params
rest
tests
ok
possible
tests
look
move
ignores
mypy
error
code
mypy
error
message
comment
case
relative
simple
cleanup
variable
type
declaration
args
error
prone
box_dtype
None
comment
possible
share
code
integer
implementation
numeric
base
class
copy
/
Need
ops
mix
extension
something
python
np.add
FloatingArray
IntegerArray
feasible
__array_ufunc__
base
class
FloatingArray
IntegerArray
copy=False
first
error
Nice
catch
other
tests
dtype
Float32
possible
result
FloatingArray
float
values
other
NaN
FloatingArray
power
issue
number
comment
base
class
ops
mixin
Index
Series
DataFrame
matter
Use
elif
separate
comment
Do
GH37566
res
Snappy
support
libparquet.so
library
snappy
separate
library
runtime
support
same
comment
below
cc
@
martindurant
thriftpy
trickiness
required
dependency
pyarrow.parquet
pq
self.api
=
least
pyarrow
required
dependency
snappy
able
most
Parquet
files
other
systems
most
Parquet
implementations
default
snappy
compression
basic
assumption
Parquet
file
likely
local
machine
snappy
compression
more
network
transferral
time
cost
CPU
time
Might
good
comment
brotli
new
format
results
GZIP
Parquet
implementation
supports
GZIP
Brotli
pyarrow
fastparquet
Presto
Java
Parquet
consumers
https
//issues.apache.org/jira/browse/HADOOP-13126
Brotli
compression
details
implementations
FastparquetImpl
PyarrowImpl
same
API
cc
@
martindurant
PARQUET-929
PARQUET-930
little
bit
work
serializable
pandas
level
something
impl
library
mixed-dtype
column
needs
*
something
*
decisions
IIRC
fastparquet
option
JSON
anything
error
/
NotImplementedError
Right
buggy
[
]
df
=
pd.DataFrame
[
]
]
df
]
[
]
pt
=
pa.Table.from_pandas
df
]
pt.to_pandas
]
None
None
https
//issues.apache.org/jira/browse/ARROW-736
@
wesm
sure
addressin
pa
user
level
@
last
pretty
sure
pyarrow
lots
options
fastparquet.write
pass
thru
Correct
column
names
unique
schema
definition
multiple
items
same
name
column
chunks
data
name
doable
yeah
helpful
errors
pyarrow
fastparquet
[
]
df
=
pd.DataFrame
np.arange
.reshape
columns=list
'aaa
[
]
df.to_parquet
'pyarrow
ValueError
Traceback
recent
call
last
/Users/jreback/pandas/pandas/core/common.py
_asarray_tuplesafe
values
dtype
result
=
np.empty
values
dtype=object
result
[
]
=
values
ValueError
ValueError
input
array
shape
shape
handling
above
exception
exception
ValueError
Traceback
recent
call
last
ipython-input-3-185ceaef9fe4
>
<
module
>
>
df.to_parquet
'pyarrow
/Users/jreback/pandas/pandas/core/frame.py
to_parquet
fname
engine
compression
pandas.io.parquet
import
>
to_parquet
fname
engine
compression=compression
@
Substitution
column
names
list
string
/Users/jreback/pandas/pandas/io/parquet.py
to_parquet
df
path
engine
compression
pyarrow
import
parquet
pq
>
table
=
pyarrow.Table.from_pandas
df
pq.write_table
table
path
compression=compression
ValueError
sequence
size
axis
dimension
[
]
df.to_parquet
'fastparquet
AttributeError
Traceback
recent
call
last
ipython-input-4-6b46c1abdc2f
>
<
module
>
>
df.to_parquet
'fastparquet
/Users/jreback/pandas/pandas/core/frame.py
to_parquet
fname
engine
compression
pandas.io.parquet
import
>
to_parquet
fname
engine
compression=compression
@
Substitution
column
names
list
string
/Users/jreback/pandas/pandas/io/parquet.py
to_parquet
df
path
engine
compression
Use
tobytes
catch_warnings
record=True
fastparquet.write
path
df
compression=compression
/Users/jreback/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/writer.py
write
filename
data
row_group_offsets
compression
file_scheme
open_with
mkdirs
has_nulls
write_index
partition_on
fixed_text
append
object_encoding
times
fmd
=
make_metadata
data
has_nulls=has_nulls
fixed_text=fixed_text
object_encoding=object_encoding
times=times
file_scheme
==
/Users/jreback/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/writer.py
make_metadata
data
has_nulls
ignore_columns
fixed_text
object_encoding
times
object_encoding.get
column
None
fixed
=
None
fixed_text
None
fixed_text.get
column
None
data
[
column
]
.dtype
'category
se
type
=
find_type
data
[
column
]
.cat.categories
fixed_text=fixed
/Users/jreback/pandas/pandas/core/generic.py
__getattr__
name
name
self._info_axis
return
name
]
>
return
object.__getattribute__
name
def
__setattr__
name
value
AttributeError
'DataFrame
object
attribute
@
martindurant
user
object_encoding
keyword
value
infer
JSON
representation
dicts
lists
first
ten
values
types
str
bytes
column
object
dtype
few
encoding
options
Most
typical
UTF8
strings
'infer
values
only
way
mixed
types
JSON
BSON
https
//issues.apache.org/jira/browse/PARQUET-930
https
//issues.apache.org/jira/browse/PARQUET-929
thru
kwargs
easy
@
martindurant
FYI
pyarrow
pandas
bash-3.2
pytest
pandas/tests/io/test_parquet.py
===========================================================================================
test
session
===========================================================================================
platform
darwin
Python
pytest-3.1.2
py-1.4.34
pluggy-0.4.0
rootdir
/Users/jreback/pandas
inifile
setup.cfg
plugins
cov-2.3.1
xdist-1.16.0
items
F
...........
..
ss
....
s
....
================================================================================================
FAILURES
=================================================================================================
_________________________________________________________________________________________
test_cross_engine_pa_fp
_________________________________________________________________________________________
=
<
[
AttributeError
object
attribute
repr
ParquetFile
>
fn
=
verify
=
False
open_with
=
<
function
default_open
>
sep
=
def
__init__
sep=os.sep
self.sep
isinstance
fn
tuple
list
basepath
fmd
=
metadata_from_many
fn
=
sep.join
[
basepath
]
effective
file
self.fmd
=
fmd
self._set_attrs
try
fn2
=
sep.join
[
fn
]
self.fn
=
open_with
fn2
'rb
f
..
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/api.py:60
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
=
'/var/folders/h3/mr_r3bkj5yg0pbx9fr3tk1r00000gp/T/tmpejvr00jj/_metadata
def
default_open
f
mode='rb
>
return
open
f
mode
E
NotADirectoryError
[
Errno
]
directory
..
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/util.py:42
NotADirectoryError
handling
above
exception
exception
df_compat
A
B
foo
foo
foo
pa
=
'pyarrow
=
def
test_cross_engine_pa_fp
df_compat
pa
fp
cross-compat
engines
df_compat
tm.ensure_clean
path
df.to_parquet
path
engine=pa
compression=None
result
=
read_parquet
path
engine=fp
compression=None
pandas/tests/io/test_parquet.py:96
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
pandas/io/parquet.py:179
read_parquet
return
impl.read
path
pandas/io/parquet.py:98
read
return
self.api.ParquetFile
path
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/api.py:66
__init__
self._parse_header
f
verify
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/api.py:95
_parse_header
self._set_attrs
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/api.py:108
_set_attrs
self.schema
=
schema.SchemaHelper
self._schema
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/schema.py:66
__init__
schema_tree
schema_elements
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
schema
=
[
<
class
'parquet_thrift.SchemaElement
>
children
OrderedDict
[
A
<
class
'parquet_thrift.SchemaElement
>
children
None
name
__index_level_0__
num_children
precision
None
repetition_type
scale
None
type
type_length
None
]
i
def
schema_tree
schema
i=0
root
=
schema
[
i
root.children
=
OrderedDict
root.children
root.num_children
i
>
s
=
schema
[
i
E
IndexError
list
index
range
..
/miniconda3/envs/pandas/lib/python3.6/site-packages/fastparquet/schema.py:23
IndexError
seconds
==============================================================================
spec
document
Python
metadata
library
key-value
metadata
anything
format
links
Parquet
timezone
information
specialized
key-value
metadata
silent
loss
data
cc
@
martindurant
warning
odd
btw
top
DataFrame
index=pd.DatetimeIndex
[
]
DataFrame
index=pd.DatetimeIndex
[
]
'1s
same
tests
expanding
time-aware
separate
issue
xfail
ref
suggestion
gh-26554
message
check
comment
test
new
issue
description
bug
reference
Done
reason
failing
test
RuntimeError
Compression
available
check_round_trip
sets
write_kwargs
'compression
None
fastparquet
snappy
compression
'compression
None
dict
comment
docstring
*
Reference
issue
number
comment
else
unecessary
comment
branch
comment
prior
line
sort_values
reset_index
unnecessary
case
necessary
test_mode_sortwarning
test
Check
warning
mode
results
expected
=
Series
[
'foo
]
s
=
Series
[
'foo
np.nan
]
tm.assert_produces_warning
UserWarning
check_stacklevel=False
result
=
s.mode
dropna=False
result
=
result.sort_values
.reset_index
drop=True
tm.assert_series_equal
result
result
=
s.mode
dropna=False
equal
Series
[
'foo
]
other
times
Series
[
]
sort_values
reset_index
result
Series
[
'foo
]
original
issue
DataFrame
sure
fix
test
Series.equal
Series
[
]
==
Series
[
Decimal
'NaN
]
example
pass
True
True
comment
warning
following
issue
number
comment
intuitive
user
window
entire
object
block
condition
freq
former
comment
test
indexes
NaT
Timedelta
Datetime
dtype
copy=
[
True
False
]
comment
body
function
Move
comment
test
definition
@
pytest.mark.parametrize
kwargs
[
dict
yticks=
]
dict
xticks=
]
]
def
test_integer_array_plot
s
=
Series
_check_plot_works
s.plot
*
*
kwargs
~~~
more
modular
testing
other
EA
integer
dtypes
i.e
dtype
possible
EA
integer
types
Nits
comma
+
period
end
comment
i
same
expected
=
s.iloc
[
[
]
]
exception
case
whole
test
..
@
pytest.mark.parametrize
[
[
]
[
]
empty
ok
[
A
]
slice
[
A
]
slice
[
'D
E
]
[
]
values
fine
[
'D
]
[
]
same
single
item
list
GH
pd.IndexSlice
[
]
]
slice
None
pd.IndexSlice
[
'foo
]
]
slice
None
]
def
test_loc_getitem_duplicates_multiindex_missing_indexers
indexer
GH
multi-index
indexers
=
MultiIndex.from_product
[
[
A
B
C
]
[
'foo
'bar
]
]
names=
[
'one
]
s
=
Series
np.arange
dtype='int64
index=idx
.sort_index
=
s.iloc
[
]
result
=
s.loc
[
indexer
]
tm.assert_series_equal
result
dtype
parameter
branches
issue
number
code
full
expl
i
duplicative
below
self._ndarray
only
difference
base
fillna
implementation
[
x._ndarray
x
to_concat
]
care
question
implementation
https
//docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.lib.mixins.NDArrayOperatorsMixin.html
comment
differences
comment
note
docstring
TODO
NumPy1.13
Compat
NumPy
NDArrayOperatorsMixin
operations
available
people
older
NumPys
bases=
class
Foo
*
bases
Python2
unpacking
tuples
class
statement
metaclass
_from_sequence
sequence
scalars
ExtensionArrays
comment
test
generic
extension
test
handle_args
comments
i
csv
reader
comment
Nit
fence
necessity
usefulness
comment
kind
op
type
error
bit
TypeError
case
combine
op
result
*
extension
type
e.g
int
someting
reason
pls
comment
comment
new
test
Same
comment
<
href=
https
//github.com/pandas-dev/pandas/pull/16996
discussion_r127768106
<
/a
>
None
object
dtype
comment
comment
sense
PR
nan
github
issue
label
PR
https
//github.com/pandas-dev/pandas/issues/34456
link
comment
comment
line
mask
behaviour
nitpick
call
result
nit-pick
GH
issue
test
name
enough
info
df_cols_in
data
df_cols_out
selected_data
nitpick
gb
nitpick
mi_tuples
np.asarray
anyhow
pls
check
perf
comment
bit
simpler
gh
issue
number
same
same
new
test_get_complex
change
comment
gh
issue
reference
Examples
section
./scripts/validate_docstrings.py
pandas.MultiIndex.from_frame
error
Make
sure
nothing
script
Better
paragraph
code
comment
blank
line
line
expected
frame
tm.assert_frame_equal
ok
reality
class
future
PR
comment
valid
entries
issue
number
comment
comment
more
line
expl
comment
except
test
case
smaller
minimal
example
error
possible
clearest
case
NaN
multiple
values
group
values
group
values
np.empty
values
values.fill
np.nan
isna
values
array
try
cls_name
=
cls_name
TypeError
kwargs
=
comment
timing
asv
timing
lint
error
reason
subprocess.run
much
simpler
issue
number
triple-quotes
description
test
prob
higher
level
elif
include
self.integer
e.g
same
case
L1474
tests
pandas/test/frame/test_analytics
part
round
comments
line
superclass
version
integers
actual
PeriodArray
comment
types
regular
comments
Users
docstrings
comment
developers
s
>
Series
Use
Series.index
Say
'Series.cat.categorical
attributes
'Series.cat
instead.
noqa
comment
e.g
object
array
non-strings
file_name.endswith
ext
ext
[
.pxd
.py
.pyx
.pyx.ini
]
rid
full_ext
function
something
failures
failures
set
status
codes
better
is_concatenated
generator
errors
wrong
same
page
TypeError
conditional
block
therein
pre-existing
behavior
comments
cases
such
todo
questions
TODO
better
=
left._left.dtype.kind
[
m
M
]
kwargs
[
'check_freq
]
=
False
....
comment
data
[
y
[
y
]
fragile
better
worse
worse
much
object
pandas
columns
e.g
df
=
pd.DataFrame
pd.Timestamp
'2017
]
code
y=pd.Timestamp
'2017
integer
iterable
is_list_like
test
Series
DataFrame
same
*
labels
positions
1-liner
expln
test
Nit
Serioes
>
Series
infer_nrows
number
rows
comment
categories
equal
Might
good
quick
perf
check
basic
case
categoricals
equal
categories
A
lot
tests
Series
Categorical
good
Series
number
something
fixed
list
[
]
set
[
name
name
dir
tslibs
_
]
]
'OutOfBoundsDatetime
'Timedelta
'Timestamp
'ccalendar
'conversion
'fields
'frequencies
'iNaT
'ints_to_pytimedelta
'localize_pydatetime
'normalize_date
'np_datetime
'offsets
'period
'resolution
'strptime
'timedeltas
'timestamps
'timezones
]
pandas._libs
import
indices
fixture
Index
types
line
Could
least
comment
comment
reload
minor
thing
comment
interpreter
rest
documentation
previous
explanation
data
normal
bit
more
compact
standard
line
descriptive
comment
next
line
c_is_column_not_containing_colors
comment
much
value
others
emm
i
something
plot
colorbar
colormap
c
column
numeric
values
=
self.colormap
c_is_column
cb
=
self.kwds.pop
colorbar
is_numeric_dtype
c_values
plot_colorbar
colormap
values
c
column
numeric
colorbar
sense
suggestion
plot
colorbar
colormap
c
column
numeric
values
case
black
long
line
lengths
original
code
black
\
=
line
continuation
black
noqa
similar
cases
long
term
code
bit
avoid
flake8
same
Same
comment
<
href=
https
//github.com/pandas-dev/pandas/pull/17099
discussion_r129979113
<
/a
>
comment
noqa
unnecessary
1-liner
test
issue
references
single
line
great
returns
array_with_unit_to_datetime
tuple
*
*
confusing
update
doc-string
pedantic
TODO
q1
different
q
test
interpolation
keyword
suggestion
property
mypy
return
Can
check_stacklevel=False
proper
doc-strings
comment
issue
refernce
comment
older
numpy
datetime
categories
comment
consistency
suggestion
gh-30740
old
comment
1-2
line
ops
PI
types
tests
separate
function
_tests
end
Comment
necessary
Can
message
test
cases
tm.assert_frame_equal
sure
floats
decimal
part
sas7bdat-file
decimal
part
bug
pandas
bug
https
//stackoverflow.com/questions/49059421/pandas-fails-with-correct-data-type-while-reading-a-sas-file
Memory
decimal
part
float
random
uninitialized
memory
Test
most
time
Memory
decimal
part
float
implicit
file
format
pandas
Test
ABCNDFrame
pandas.core.dtypes.generic
comment
AttributeError
AttributeError
come
things
try/except
top
function
add
axis
ok
object
type
IOW
axis=1
Series
=
self._get_axis_number
axis
Sure
comments
part
test
series
clip
tests
test
comment
=
pd.Series
threshold
index=self._get_axis
Hmm
self.simple
inplace=True
original
=
self.simple.copy
Sure
Thanks
=
len
header
have_mi_columns
expected
output
is_dtype_equal
suggestion
>
>
>
codes
uniques
pd.factorize
values
default
na_sentinel=-1
first
sentences
familiar
[
]
NOQA
pattern
TODO
rebase
comments
forwards
comment
contents
change
matter
doc-strings
Can
values
list
things
explicit
astype
list
setup
=
box
[
]
*
data_result
=
box
[
False
True
True
False
True
]
*
qcut
test
dtype
pass
list
ExtensionArrays
dtype
arrays_to_mgr
dtype
passed
arrays
init_array
comments
wha
tis
reason
fixture
DataFrame
pd.
prefix
single
deterministic
example
easier
following
example
issue
python
]
import
pandas
pd
[
]
[
]
df
=
pd.DataFrame
[
]
b
[
]
c
range
list
'abcd
]
df.set_index
list
'abc
.sort_index
level=list
'ba
]
d
b
c
b
c
d
master
python
]
import
pandas
pd
[
]
[
]
df
=
pd.DataFrame
[
]
b
[
]
c
range
list
'abcd
]
df.set_index
list
'abc
.sort_index
level=list
'ba
]
d
b
c
b
d
c
clear
example
comments
test
example
more
fluid
comments
cases
fill_value
tests
test
object
array
steal
cases
constructor
tests
suggestion
ParseDates
=
Union
[
DateGroups
List
[
DateGroups
]
resolution
other
issues
comment
necessary
obj
output
bit
type
obj
DataFrame
compare
dataframe
series
comments
line
umm
same
perf
okay
comment
list
cc
jbrockmendel
edit
Can
GH
issue
number
comment
something
reasonable
form
easier
file
migration
int_frame
ts_frame
reasonable
e.g
_
separate
word
frame
same
comment
>
test_set_index_pass_arrays
test_set_index_duplicate_names
several
combinations
cases
beefed-up
version
test_set_index_duplicate_names
duplicate
arrays
various
forms
various
kwargs
e.g
drop
tests
error
duplicate
column
keys
comment
test
behaviour
argmin/argmax
changes
sure
test
deprecation
issue
number
comment
future
PR
ok
expl
import
'str
form
import
Timedelta
Period
_libs
sure
mypy
cares
pragma
cover
type
ignore
something
last
line
comment
sense
useful
future
readers
code
test
magical
comment
Same
comment
anything
plt.clf
figure
suggestion
boolean
truth
values
len
value
isinstance
indexer
np.ndarray
indexer.dtype
==
np.bool_
len
indexer
[
indexer
]
==
value
diff
clear
comment
comment
comments
cases
Whoops
logic
explcity
min_count=1
tests
*
*
entry
w/o
min_count
e.g
default
comment
..
@
pytest.mark.parametrize
[
s
x
s
[
x
]
lambda
s
x
s.loc
[
x
]
lambda
s
x
s.xs
level=1
]
@
pytest.mark.parametrize
[
Series
[
]
index=
]
Series
[
]
index=
[
]
]
def
test_series_getitem_multiindex
access_method
level1_value
GH
series
regression
getitem
multi-index
s
=
Series
[
]
s.index
=
MultiIndex.from_tuples
[
]
result
=
access_method
s
level1_value
tm.assert_series_equal
result
OTT
issue
number
comment
comment
func
lambda
def
comments
block
call
df
reference
implementation
_check_all_orients
L254-L410
equivalent
orient
[
columns
records
split
index
values
]
use_np
rok
[
False
None
True
raise_ok
]
_check_orient
df
orient
dtype=dtype
convert_axes=False
raise_ok=rok
sort=sort
convert_axes
numpy=True
raise_ok
None
error
_check_orient
df
orient
dtype=dtype
raise_ok=rok
sort=sort
TODO
comment
special
case
higher
level
copy
0-len
objects
problem
original
PR
lot
code
things
e.g
case
statements
specific
test
file
hard
/
document
standard
conftest.py
infrastructure
want
share
much
code
possible
b
standard
well-defined
easy
locations
Was
necessary
Sequence
allowable
comment
anymore
lower
version
try
iow
move
bool/int
sure
bit
cleaner
comment
Sorry
bit
confused
change
is_bool_dtype
dtype
is_integer_dtype
dtype
elif
issubclass
dtype.type
return
result.astype
dtype
guard
checks
type
result.dtype
parameter
second
checks
dtype
parameter
type
bool/int
move
condition
parentheses
backward-slash
i.e
~~~python
issubclass
~~~
@
jreback
entire
block
i.e
elif
statement
logic
issue
number
comment
Could
comment
issue
number
small
explanation
NaN
object
dtype
inferred
bool
sides
NaN
comment
block
code
case
useful
similar
test
DataFrame
min
long
results
’
t
u
extra
look
part
smaller
way
thousands
benchmarks
suite
goal
time
Might
good
tests
other
return
types
tuple
lines
test
name
comment
Minor
reference
issue
number
comments
GH
comment
series
index
suggestion
def
test_to_period_raises
indices
https
//github.com/pandas-dev/pandas/issues/33327
index
=
ser
=
Series
index=index
dtype=object
isinstance
index
DatetimeIndex
msg
=
f
unsupported
Type
type
index
.__name__
pytest.raises
TypeError
match=msg
ser.to_period
separate
ensure_cleans
case
comment
case
behaviour
Series.at
other
option
error
key
way
scalar
problem
kind
indexer
case
scalar
ones
requirements
.at
comment
able
len
tup
self.obj.ndim
GH
\
line
continuation
pandas
parenthesis
same
comment
lines
Python
list
empty
list
docstr
len
list
docstr
Move
comment
line
reference
GH
Issue
number
comment
comment
next
line
kpapdac
merging
Does
*
use
bare
exceptions
try
....
Exception
error
reading
header
1-line
comment
wheat
suggestion
user
input
storage_options
dict
storage_options
storage_options
anon
]
=
True
test
comment
i.e
int_dtype
float_dtype
uint_dtype
conftest.py
fixtures
issue
number
comment
comment
out-dated
hmm
name
word
delta
_add_timedeltaindex
move
new
test
issue
number
comment
sure
PeriodIndex/Array
'normal
comment
reminder
Int64Index._append_same_dtype
[
ix.astype
int
]
numeric
indexes
_append_same_dtype
_concat_index_asobject
note
TODO
cases
original
issue
same
tests
IOW
first
works
Sort
works
s.sort_index
level=
[
'third
'first
]
sort
third
level
first
level=
[
'third
'first
]
ascending=
[
False
True
]
general
rule
thumb
numpy
comparisons
tests
own
custom
comparison
functions
e.g
own
ndarray
comparison
function
assert_numpy_array_equal
Series
output
list
output
sort_index
Series
function
assert_series_equal
sp
1-line
comment
purpose
loop
NA
values
comment
result=
dict
comprehenseion
issue
number
comment
1-liner
explain
Can
Function
word_list
]
Better
blank
line
docstring
blank
line
delete
part
next
loop
loop
check
word
proper
name
common
words
first
word
enumerate
loop
Python
convention
bad_title_dictionary
camel
case
variables
function
names
code
look
PEP-8
style
guide
Function
part
bit
confusing
function
Strip
non-word
comment
next
lines
immediate
lines
contex
manager
python
open
rst_file
r
file_obj
lines
file_obj.read
.split
\n
trick
side
note
built-in
python
function
variable
name
Better
comments
code
python
code
readable
init
other
functions
comment
goal
comment
hash
Probably
constant
top
file
list
words
fiixed
capitalization
Sorry
comment
first
occurrence
comment
worth
cat
b
vice
versa
tricky
*
is_object_dtype
True
first
place
point
scalar
ABCDateOffset
comment
addition
issue
number
comment
is_zip
pls
more
comments
return
dtype
Thanks
Could
tm.assert_produces_warning
[
warnings
]
https
//pandas.pydata.org/pandas-docs/stable/development/contributing.html
testing-warnings
fixme
comment
axis
axis='columns
axis='index
test
axis
=0
dont
long
names
easier
tocsc
scipy
implementation
detail
sure
indices
IntIndex
check_integrity=False
check
drop
Can
E
lists
bit
confusing
word
flat
single
level
lgtm
i
comment
perf
sensitive
issue
number
comment
*
*
null
values
same
test
function
input_s
mean
use
*
*
layer
paramterization
cases
total
series
x
[
None
]
reusable
property
possible
returns
function
method_returns_something
something
boolean
function
Returns
section
docstring
docstring
noted
previous
comment
walk
context
other
option
ast
NodeVisitor
subclass
context
deep
little
hesitant
good
recursive
calls
objects
tougher
reason
non-recursive
/
mutable
code
nodes
method
AST
tree
reason
cases
following
A
def
B
return
Hello
World
print
B
None
case
inner
function
string
function
None
Returns
section
docstring
nodes
happens
ast.walk
returns
nested
functions
returns
function
recursion
function
node
entire
subtree
possible
return
nodes
Could
github
issue
number
comment
pyreadstat
=
pytest.importorskip
'pyreadstat
need
skipifs
sure
comment
'Catches
disabled
relevant
reader
code
comment
top
test
names
packages
*
different
*
names
comment
same
Could
tz_convert
astimezone
use
.item
tests
thing
changing
b
column
paramters
1-line
comment
issue
suggestion
series_scalar_exc
=
TypeError
type
Optional
[
Type
[
TypeError
]
]
permissive
error
type
Optional
[
<
type
>
]
Union
[
<
type
>
None
]
opportunity
docstring
informative
function
name
sentence
wink
hmm
mypy
error
comment
IIUC
issues
method
xref
series
no-op
Panel
DataFrame
Series
NDFrame
issue
number
comment
TODO
comment
f-strings
i
base
pls
try
common
terms
dont
multiple
things
single
line
hmm
logic
general
necessary
extensions
tm.assert_frame_equal
/
tm.assert_series_equal
e.g
tests/arrays/test_integer.py
IOW
line
tm.assert_numpy_array_equal
impl
generic
series
ops
bit
hoops
tests
easy
generic
arithmetic
tests
case
integers
different
subdtypes
class
arithmetic
operations
custom
way
tests/arrays/test_integer.py
passing
bugs
corner
cases
issue
comments
useful
same
fixtures
parameterize
let
issue
OK
loc
pandas_vb_common
lib
multiple
files
comment
things
test_
Replace
test_dict
result
@
jreback
different
names
test
result
variable
same
line
work
higher
code
tests
multiple
columns
test
eg
left_index
right_on
Good
point
theory
impact
output
tests
reason
tested
behavior
syntax
pytest.raises
..
comment
result
values
better
call
_get_values
masking
type
conversion
only
routine
sem
skipna=False
matter
things
bit
e.g
first_name
second_name
expected_name
fine
notion
klass
place
box
necessary
prob
best
issue
side
note
test_base
multiple
files
big
separate
step
things
test_indexing.py
test_missing.py
test_set_ops.py
etc
essence
various
sub-files
series
ops
Kept
separate
test
test
same
topics
index
class
attrs
fixtures
more
detail
ok
*
comments
*
_coerce_to_type
IOW
infer_dtype
intp
constructors
bug
open
issue
reason
TODO
message
elses
return
way
test
weights
column
comment
sense
removed
line
nicer
comment
non-integer
MI
blank
line
comment
ensure_data
input
times
case
dprob
document
/
type
tests
reference
easier
def
test_bare_raises
fd
=
io.StringIO
pytest.raises
ValueError
raise
ValueError
result
=
list
validate_unwanted_patterns.bare_pytest_raises
fd
=
[
Bare
pytests
Please
pass
argument
'match
exception
assert
result
==
idea
test
suite
function
function
input
function
assertion
error
function
great
documentation
function
input
output
May
dedent
content
files
readable
class
Bad
something
sense
docstings
class
methods
docstrings
values
tests
Same
comment
acceptable
patterns
patterns
readable
issue
number
comment
1-liner
test
purpose
same
pls
gh
issue
number
comment
liner
triple-quotes
doc-string
fixture
thins
_get_axis
self.axis
length
same
ax.lines.get_marker
marker
comment
test
confusing
Github
bug
bit
vague
sure
value
comment
2018-05-10
dates
codebase
rebase
minor
comment
https
//github.com/pandas-dev/pandas/pull/33821
discussion_r426685765
green
line
lines
parametrization
i
example
color
style
something
ax
=
df.plot
color=
green
d
ax.lines.get_color
assert
ax.lines.get_marker
comment
case
comment
sub-section
tests
flow
others
IOW
cases
comment
lines
duplication
suggestion
https
//github.com/pandas-dev/pandas/issues/22205
pls
issue
number
comment
warnings
anything
artifact
cython+numpy
interaction
useful
comment
i
readers
top
day
decorator
/
context
manger
much
suggestion
@
pytest.mark.parametrize
values
exp_any
exp_all
exp_any_noskip
exp_all_noskip
[
[
True
pd.NA
]
True
True
True
pd.NA
[
False
pd.NA
]
False
False
pd.NA
False
[
pd.NA
]
False
True
pd.NA
pd.NA
[
]
False
True
False
True
GH-33253
True
/
False
values
skipna=False
[
True
True
]
True
True
True
True
diff
huge
comment
added
line
hard
cases
comment
construct_result
function
comment
Refer
GH
issue
number
comment
nice
comment
logic
future
readers
test
bit
long
use
=
=
tm.assert_frame_equal
result
frame
original
issue
NaT
right
test
date
datetime.date
datetime64
[
ns
]
function
doc-string
comment
most
comment
ref
relevant
numpy
issue
Thanks
suggestion
def
test_to_excel_with_openpyxl_engine
ext
tmpdir
GH
issue
number
comment
context
manager
literal
values
pct_change
result
unclear
annotation
only
thing
differs
original
code
nice
types
follow
Callable
right
comments
procure
issue
number
test
test_me
*
GH
worth
own
other
comments
changes
worth
Add
issue
number
.agg
[
'sum
'min
]
result
index
*
*
function
names
'min
]
sense
pls
noqa
functions
test
exception
everything
fine
exception
assert
type
datetime
understood
True
AssertionError
result
=
operation
expected
series
=
pd.Series
pd.to_datetime
[
'2011-12-26
'2011-12-27
'2011-12-28
]
tm.assert_series_equal
result
blank
lines
end
linting
error
https
//travis-ci.org/pandas-dev/pandas/jobs/245637992
L1393
Looks
lines
flake8
pandas/tests/series/tests_datetime_values.py
flake8
test
style
stuff
only
change
pandas.compat
iterator
py2
Should
reflect
cases
EA
IntegerDtype
docstring
comment
above
nan
values
last
copy=copy
index
cc
jbrockmendel
comment
cases
e.g
sr
pd.NA
indices
DataFrame
different
code
paths
values
index
labels
NdArray_encodeLabels
labels
Same
tm.assert_series_equal
test
let
whole
dataframe
tm.assert_frame_equal
reference
GH
issue
number
parenthesis
line
suggestion
zip
*
type
ignore
[
arg-type
]
tslibs.conversion.datetime_to_datetime64
v
to_datetime
hood
known
mypy
error
type
ignore
fine
comment
i.e
https
//github.com/python/mypy/issues/1153
error
Name
'json
import
.get_indexer
cases
*
use
.iloc
argument
column
order
older
pythons
recent
python
correct
suggestion
tm.assert_frame_equal
df
PY36
comment
sp
issue
number
comment
specifiy
local
time
comment
clear
something
comparison
NaN
False
cases
msg
variable
tm.assert_frame_equal
result
=
=
tm.assert_frame_equal
result
comment
case
future
PR
comments
integer
divide
function
tmp
something
f
y
comment
=
op.replace
'__
return
getattr
operator
op
commented-out
stuff
redundant
>
comment
Added
comment
comments
prior
line
suggestion
GH
null
slice
index
slice
columns
along
WillAyd
Can
comment
comment
tbh
current
behavior
comment
reference
GitHub
issue
OverflowError
except
out-dent
block
_get_string_slice
try/except
only
disadvantage
approach
python
pd.DataFrame
index=range
columns=pd.MultiIndex.from_product
[
[
]
]
]
KeyError
KeyError
more
correct
python
isinstance
key
tuple
key
obj
set
key
obj
expensive
key
long
array
column
sure
good
idea
message
dtype
None
default
dtype=self._dtype
dtype
parameter
part
comparison
consolidate
Ca
exact
location
assert
is_datetime64tz_dtype
col.dtype
line
superfluous
check
place
read_sql_table
clearer
check
result
read_sql_table
expected
result
comment
things
past
list
comprehension
use
enumerate
hard
TODO
cases
loop
use
parametrize
issue
number
comment
comment
line
causes
failure
line
blank
line
comment
remote
comment
Do
function
name
comment
Thanks
Minor
nit
period
gh
issue
number
comment
comment
blank
line
comments
easier
test
master
object
array
[
]
pd.DataFrame
np.array
[
*
]
dtype=object
]
[
]
pd.DataFrame
[
*
]
OverflowError
Python
large
C
long
one
list
comprehensiion
original
pop
reason
comment
skip
suggestion
__add__
=
cls._create_method
runnable
code
example
class
definition
>
>
>
prompt
i
less
sense
self
OK
possible
specific
error
something
noqa
F811
numpy
scalars
full
control
left
operand
other
behaviour
[
]
np.int64
==
pd.NA
/home/joris/miniconda3/envs/dev/bin/ipython:1
DeprecationWarning
elementwise
comparison
error
future
Out
[
]
False
[
]
pd.NA
==
np.int64
]
NA
[
]
np.int64
<
pd.NA
TypeError
Traceback
recent
call
last
ipython-input-29-87134fac2734
>
<
module
>
>
np.int64
<
pd.NA
~/scipy/pandas/pandas/core/na_scalar.py
__bool__
def
__bool__
>
raise
TypeError
boolean
value
NA
ambiguous
def
__hash__
TypeError
boolean
value
NA
ambiguous
[
]
pd.NA
>
np.int64
]
NA
first
case
sure
behaviour
change
numpy
pls
mark
big
FIXME
commented-out
code
anybody
Appender
Substition
sure
*
pandas
compression
local
http
code
Therefore
fine
fact
fsspec
part
open
everything
backend
rb
/
wb
TODO
point
fsspec
*
*
file
ops
likely
near
term
comment
filesystem
kwargs
check
obvious
suggestion
is_fsspec_url
path
filesystem
kwargs
use_legacy_dataset
True
TODO
use_legacy_dataset=False
work
available
assert
kwargs.get
use_legacy_dataset
False
False
use_legacy_dataset
True
code
branch
handle
fsspec
filesystems
comment
test
@
simonjayhawkins
mypy
to_csv
None
path
type
ignore
necessary
true
e.g
pyarrow.compute
min
version
StringArray
ArrowStringArray
pyarrow
https
//issues.apache.org/jira/browse/ARROW-9407
minimum
version
string
dtype
workaround
follow-up
wrong
behaviour
values
Pyarrow
None
[
]
dtype
=
ArrowStringDtype
]
arr
=
pd.array
[
pd.NA
b
]
dtype=dtype
]
np.array
arr
]
array
[
None
b
]
dtype=object
pd.NA
default
same
lib.ensure_string_array
StringArray
case
scalars
pyarrow
arrays
many
test
eg
conversions
float
etc
shallow
copy
same
base
class
implementation
Please
read_hdf
function
mode
other
r
returned
object
file
mmap
file
data
file
point
need
file
issue
mode
format='table
test
test
green
merge
pytz
prob
lots
skips
codebase
Okay
pytz
anything
breaks
nan
valid
fine
reason
@
gwrome
DatetimeLike
Type
Scalar
type
module
union
Scalar
blocker
worth
consideration
name
DatetimeScalarOrArrayConvertible
PR
number
reason
NOT
de-dupe
other
comparisons
file
e.g
TODO
comment
PR
code
parameterization
issue
number
comment
Just
comment
changes
obvious
signature
lib.no_default
PR
best
comment
check
user
sep
different
'\t
due
worth
actual
error
See
GH
enough
Spurious
double
quote
issue
test
PR
check
m
None
following
line
subsequent
raise
line
unnecessary
second
opinions
open
issue
different
fill
value
Using
nulls_fixture
care
Can
ABCIndex
pandas.core.dtypes.generic
pls
add
separate
test
gh
issue
number
comment
issue
number
comment
todo
type
parameters
Dict
comment
comment
difference
FrameOrSeries
FrameOrSeriesT
nitpick
blank
line
set
comments
easier
new
test
comments
statement
Series
wrapping
consistent
.unique
branch
[
]
pd.unique
pd.Series
pd.Categorical
list
'aabc
]
b
c
dtype
category
Categories
object
b
c
]
]
pd.Series
pd.Categorical
list
'aabc
]
[
b
c
]
Categories
object
b
type
ignore
stem
fact
attributes
wrapper
function
class
doc
decorator
help
name
_doc_args
context
function
sense
value
args
parameters
doc
decorator
_doc_args
attribute
example
pandas.Series.head
_docstring_components
callable
something
@
doc
pandas.Series.head
content
templates
pandas.Series.head
function
Last
thing
docstring_components
variable
type
ignore
wrapper._docstring_components
=
_docstring_components
end
Probably
cleaner
worth
comment
err
good
cases
ones
.loc
ones
.iloc
specific
hmm
i
_reverse_indexer
right
dict-comprehension
issue
comment
comment
decompress_file
contextmanger
tm.decompress_file
filename
compress
fh
......
suggestion
gh-10444
comment
pendantic
result
cases
variable
names
data._can_hold_na
True
actual
boolean
True
'
canoncial
issue
commented
code
xfail
test
same
comment
same
Remind
membership
self.values
blank
line
things
isna
....
try
....
....
is_scalar
np.array
first
keyerror
try
result
self._get_value
key
result
KeyError
isinstance
self.index
MultiIndex
return
self._get_values_tuple
key
course
*
*
_get_value
Minor
step
comment
comment
Her
“
noqa
”
specific
s
“
noqa
F401
”
comment
scenario
isinstance
r
type
NotImplemented
r
jorisvandenbossche
comment
[
callfunc
b
b
zip
lvalues
rvalues
libops.vec_binop
lvalues
rvalues
callfunc
equivalent
performant
uncomment
comment
sure
value
comment
more
explicit
Boolean
IntegerArray
inplace
operation
self._mask
inplace
xref
hmm
case
little
confused
mask
|
mask_values
values_object
i
potential
optimization
comment
Currently
work
coercion
routine
numpy
coercion
np.array
[
]
dtype=bool
works
bool-ness
values
question
more
strict
actual
bools
strict
Same
comment
blank
line
comment
comment
useful
pls
remove
next
pass
new
test
pls
parameterize
timedelta
np.timedelta64
wel
Lost
previous
comment
tm.assert_series_equal
separate
test
comment
Same
[
]
https
//github.com/pandas-dev/pandas/pull/30221
discussion_r357004201
first
part
comment
suggestion
TODO
parameterize
box
de-duplicate
single
tests
use
parametrize
args
issue
number
comment
somethings
path
EA/Series/DataFrame
ExtensionIndex
pls
FIXME
dont
commented-out
same
rest
construct
SDF
compare
’
s
odd
state
fixture
function
level
don
’
t
u
module
level
function
level
ok
state
inside
class
fixture
issue
number
result
result.equals
inplace
case
call
optional
inconsistency
code
TODO
comparison
future
readers
faster
comments
diff
issue
ref
rst
https
//sublime-and-sphinx-guide.readthedocs.io/en/latest/references.html
links-to-external-web-pages
flake8
next
line
example
more
frequency
strings
link
https
//pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html
offset-aliases
>
comment
blank
line
def
check_reduce
op_name
skipna
version
Better
top
function
definition
n
comment
blank
line
comment
[
None
False
None
]
pd.NA
comment
commented-out
code
reverse
add
issue
comment
backtick
SyntaxError
comment
name
comments
necessary
much
nicer
possible
arg
check
>
=
motivation
type
ignore
overlap
latter
errors
static
analysis
issue
number
comment
comment
sense
anyone
cognizant
particular
issue
issue
number
PR
number
comment
intp
accepts
indexers
Switch
order
fill_value
/
allow_fill
keywords
same
comment
allow_fill
default
external
documentation
pandas
behaviour
internal
Series.take
numpy
behaviour
EA.take
many
cases
take
na_value
boxed
scalar
NA
type
underlying
physical
NA
value
example
JSON
TODO
\
conuation
use
parens
others
instance
needs
context
manager
Sorry
😅
comment
args
functions
pass
ordered
categorical
comment
second
example
different
first
obvious
comment
dupe
df
df_sample
suggestion
GH
mi
m_index
prob
little
helper
function
DRY
maybe_localize_tz
point
freq
localize_args
point.tz
None
point.tz
None
point
=
point.tz_localize
*
*
localize_args
return
point
issue
number
slight
preference
possible
\
newline
=
Attributes
different
Attribute
dtype
different
\\
[
]
CategoricalDtype\\
categories=\\
[
u
b'\\
]
ordered=False\\
[
right\\
]
CategoricalDtype\\
categories=\\
[
u
b
c'\\
]
\
ordered=False\\
list
hyphen
first
line
type
comment
subsequent
line
description
Thanks
comment
iteration
first
values
concerned
number
mutations
variable
better
enumerate
direction
helpful
sure
initial
glance
conscious
comment
better
way
way
comment
situation
elements
test_header_inferred_from_th_elements
thead
element
design
cases
original
issue
work
comments
section
list-of-lists
comment
PR
Inevitably
something
specific
comment
from_sequence
raises
result
normal
numpy
array
issue
number
warning
cases
more
explict
sep=
default
case
delim_whitespace
False
necessary
sep
comments
cases
warning
tm.assert_produces_warning
context
manager
comments
function
FutureWarning
issue
number
comment
example
unused
variable
good
PR
comments
function
sure
comment
Might
wording
grammar
thing
check
Index
objects
subclasses
intentional
comment
test
com.is_bool_indexer
logic
is_bool_indexer
unecessary
import
same
>
setitem
int
B
column
data
general
comment
support
ModuleNotFoundError
change
'reindex
'reindex_axis
good
'todo
point
fact
index=index
columns=columns
generic
NDFrame
types
Panels
case
indices
fixture
ones
comment
previous
line
issue
user
data
user
read-only
array
expected
value
assert_frame_equal
dfm
result
version
notna
frame
wrong
.values
is_mixed_type
worthwhile
exceptions
tests
comments
compat
code
sure
correct
tests
numpy
compat
removed
command
'complex256
np.float128
c2f_dict
windows
machine
example
Reference
issue
number
new
tests
comment
comment
'section
test
future
reader
Can
comment
TODO
reconsider
current
behaviour
....
link
issue
Just
case
oh
behaviour
comment
behavior
IntervalIndex
empty
list
python
]
pd.IntervalIndex
[
]
Out
]
IntervalIndex
[
]
closed='right
dtype='interval
[
]
changes
PR
inferred
subtype
object
default
strong
reason
integer
comment
need
pd.Panel
Can
msg
=
typical
way
multi-line
strings
codebase
same
comment
above
fine
part
error
message
easier
comment
example
good
clear
b
failures
TODO
bpraggastis
TODO
issue
skipna
parameter
mask
own
mask
e.g
skipna
mask
assertions
warnings
Could
comments
TODO
DatetimeArray
composition
able
PeriodIndex
implementation
use
comment
same
comments
above
odd
reveal_type
default
mode=
w
order
b
difference
previous
test
Multiple
all-missing
levels
simpler
function
somebody
test
same
heck
UDF
function
Series
/
Series
same
shape
issue
number
comment
work
*
*
*
*
error
more
elements
True
False
True
True
]
case
hmm
import
order
_shared_docs
end
comment
helpful
kludge
..
clear
*
*
implementation
fill
object
dtypes
extension
classes
case
algos
THIS
one
reason
performance
such
preference
options
extension
implementation
MUST
base
class
bit
comments
cases
useful
=
DataFrame
....
df2
=
DataFrame
....
=
df1
result
=
df1.update
....
tm.assert_frame_equal
result
sorry
right
@
TomAugspurger
Hmm
bogus
kwarg
new
object
inplace
arg
https
//github.com/pandas-dev/pandas/issues/10730
update
inplace
expected
=
df1.copy
second
test
df1
=
DataFrame
[
None,3
]
B
date_range
periods=3
df1.update
df2
sure
original
issue
same
test
same
exected
dataframe
=
df1
=
DataFrame
[
]
B
date_range
periods=3
tm.assert_frame_equal
df1
sense
version
i
setup
method
>
different
ops
strong
opinion
harder
benchmark
suite
Yah
hassle
Best
guess
throw
hardware
problem
solution
local-running
troubles
function
module
complex
partialy
function
way
complex
operate_blockwise
sufficient
tm.assert_series_equal
empty
Series
DTI
comments
cases
ones
opinion
better
if/elif/else
statement
separate
function
best
name
comment
something
combine
way
big
deal
suggestion
newer
version
pyarrow
parquet
suggestion
newer
version
pyarrow
parquet
issue
number
comments
comment
FIXME
dont
commented-out
np.array
@
Series
__rmatmul__
either
list
np.array
same
i.e
np.array
@
DataFrame
np.array.__matmul__
decorator
response
comment
thats
i
meant
decorator
strict=False
better
comment
blank
line
comments
issue
number
comment
worth
single
build
most
docker
things
variable
GCB
variable
substitution
file
base-images
coverage
images
time
build
same
thing
fine
fuzzer-benchmark
builds
same
thing
bunch
times
same
file
understanding
correct
pretty
fragile
tempfile
code
template
template
YAML
file
variables
tempfile
code
gcb_build
time
something
substitutions
sure
substitution
stuff
PR
least
TODO
please
Single
strings
please
specific
benchmarks
fuzzbench-test
repo
BASE_TAG
list
benchmarks
comment
llvm-cov-11
llvm-cov
Comment
descriptive
form
comment
function
generates
fetch_profdata_files
Remove
-d
afl_fuzzer.run_fuzz
default
example
build
argument
comment
readers
constant
caller
environment.get
good
dynamic
vars
global
Shall
TODO
Change
@
pytest.fixture
def
use_gsutil
experiment
Mock
Google
Cloud
Storage
bucket
usage
experiment
use_local_filestore
experiment
os.environ
]
=
name
use_gsutil
comment
applicable
image
code
e2e
test
e2e
test
normal
behavior
configuration
different
other
comment
table
Include
everything
last
experiment
experiments.reverse
last_exp_name
=
experiments
]
result
=
experiment_df
[
experiment_df.experiment
==
last_exp_name
]
exp_name
experiments
[
]
Include
data
benchmark/fuzzer
pairs
covered_pairs
=
result
[
[
'benchmark
'fuzzer
]
]
.drop_duplicates
=
covered_pairs.apply
tuple
axis=1
.tolist
=
experiment_df
[
experiment_df.experiment
==
exp_name
]
=
exp
[
[
'benchmark
'fuzzer
]
]
.apply
tuple
axis=1
to_include
=
[
~exp_pairs.isin
covered_pairs
result
=
result.append
to_include
return
result
related
changes
separate
PR
PR
easier
queue
implementation
bug
nit
comments
capital
letters
end
periods
please
getenv
None
os.environ
same
thing
fuzzer_utils.get_fuzz_target_binary
nit
single
quotes
strings
other
docstrings
please
nit
comment
redundant
print
Same
comments
prepare_build_environment
code
comment
ankou
dicts
nit
weizz
printing
simpler
docker/generated.mk
experiment/build/generate_makefile.py
<
>
assert
Start
docker
content
nit
i
style
pylint
directives
entire
file
function
directive
line
complaint
nit
Load
Loads
style
bit
confusing
descriptive
style
s
]
https
//google.github.io/styleguide/pyguide.html
383-functions-and-methods
docstrings
regular
comments
nit
Let
change
comment
Use
local_filestore
gsutil
gsutil_options
way
future
PR
clean
other
functions
arguments
filestore_utils
gsutil
usages
priority
local
support
implementation
side
effects
current
cloud
computing
Please
-1
command
last
PR
ls
-1
number
Comment
sense
cp_arguments
|rm_arguments|
TODO
move
comments
others
line
block
test
comment
please
presubmit.py
anything
other
python
sys.version_info.major
sys.version_info.minor
<
=
reference
https
//github.com/google/pytype/issues/440
pytype
comment
trials
bad
perf
AFL_
prefix
WEIZZ_
Same
comment
docstrigns
Unless
youre
list
much
comment
line
possible
limit
line
stale
comment
Needs
other
imports
others
stdlib
packages
yaml
third_party
helper
function
open
summary_file
summary
coverage_info
=
json.loads
summary.readlines
-1
]
one
functions_data
=
coverage_info
[
data
]
[
'functions
]
function_data
functions_data
region
function_data
[
regions
]
region
]
region
[
-1
]
region
]
region
[
-1
]
'code
region
covered_regions
key
]
.add
tuple
region
[
:4
]
Remove
unneeded
comment
Great
job
Most
likely
config
file
config
<
name
>
Manul
root
folder
start
following
weights
mutator_weights=afl:3
rest
same
manul
needs
install
GCB
*
var
add
comments
branches
Always
benchmarks
always_build
Build
fuzzer
benchmarks
Build
fuzzer
benchmarks
skip
rest
things
OSS-Fuzz
benchmarks
oss-fuzz.yaml
dependency
other
file
directory
README
dependency
loose
directory
dependency
regardless
OSS-Fuzz
people
Add
comment
Modulefinder
modules
__init__.py
files
ways
route
use
something
other
modulefinder
edge
cases
such
functions
modules
style
guide
module
fuzzers
__init__.py
modulefinder
few
lines
code
fakefs
fake
__init__.py
hacky
duplicate
same
thing
run_coverage
please
source
truth
unexpected
typo
added
condition
explicit
pull
Please
arbitrary
app
easier
mulitple
tests
arent
leaks
broken
tests
pipelineId
key
context
hook
attribute
self
Which
pattern
preferable
Add
preconfig
steps
parameters
arent
defaults
default
values
possible
Dont
assume
external
values
e.g
name
subscription
teh
app/stack
public
repo
such
appengine
smoke
test
same
other
test
apps
kato
tests
different
+1
comment
parameter
Did
comment
HOST_PLATFORM
k8s
tests
real
sad
suggestion
way
rid
HOST_PLATFORM
least
need
None
check
False
kind
builder
identifier
bom
release
home-grown
default
identifier
kind
anonymous
thing
other
name
sort
identifier
something
hostname
timestamp
BOM
comments
Thoughts
little
nit-picky
hostname
important
top-level
timestamp
typical
consumers
changelog
weird
Jenkins
today
hostname
bottom
changelog
good
idea
date
top
version
reader
something
Spinnaker
May
contents
_This
change
log
auto
Jenkins
nit
unnecessary
comments
arg
change
None
problem
>
something
uncomment
sure
API
json
document
dictionary
name
value
pairs
e.g
priority
string
priority=100
big
string
bunch
individual
regexes
agent
able
string
dictionary
python
implementation
aws
agent
CLI
simple
simplistic
gcp
one
CLI
cant
give
route
CLI
one
multi
regex
solution
.contains_path_pred
'securityRules
jp.AND
jp.STR_SUBSTR
protocol='tcp
jp.STR_SUBSTR
priority=100
jp.STR_SUBSTR
destinationPortRange='80=80
reason
MATCH
better
simpler
reporting
more
straight
event
failure
feature
storage
API
name
blob
path
relative
root
bucket
basename
filter
.yml
extensions
Changed
hal
versions
color
false
halyard
Does
sort
optimistic
locking
careful
builds
other
services
gsutil
rsync
help
bucket
listing
consistent
careful
concurrent
tasks
same
bucket
same
time
job
GCS
file
question
comment
concurrency
function
Remove
line
nitpick
function
repo
path
internal
state
only
doc
comment
chars
Good
point
function
repo
path
comment
commit
script
name
current
script
__file__
global
constant
Nit
suggestion
counts
entire
program
mode
nit
code
standard
definition
roles
vertica_roles
derives
roles
Might
help
brief
comment
parameter
order
access
prose
description
comments
python
pycon
syntax
highlighting
>
>
>
little
more
def
everything_except
excluded_types
return
st.from_type
type
.flatmap
st.from_type
.filter
lambda
x
isinstance
excluded_types
.flatmap
from_type
need
lambda
comment
much
wink
python
hypothesis.strategies._internal.types
import
function
grin
issubclass
type
inst
protocol
inline
places
Python
long
time
nit
TODO
GCS
client
Same
comment
datetime.datetime.now
endtime
Same
example
TODO
unittest
delete
old
registry
info
app.yaml
new
name
kubeflow-0.2.0
Otherwise
ks
new
version
registry
same
name
=
coreV1.read_namespace
namespace
Shall
namespace
profile
CR
retry/sleep
case
namespace
Role
Role
binding
CR
k8s
resources
something
ditto
other
exceptions
level
EXCEPTION
message
err
user
formatted
error
lib
exception
@
skarekrow
prestop
jail
sense
jail_ip
indentation
multiple
comment
indentation
multiple
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Constant
name
backend_dir
A-Z_
]
[
A-Z0-9_
]
*
|
__
*
__
pattern
A-Z_
]
[
A-Z0-9_
]
*
|
__
*
__
pattern
]
https
//app.codacy.com/app/frank_10/quality-report/pullRequest
prid=1783266
block
comment
block
comment
<
br
>
line
characters
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
function
]
https
//www.codacy.com/app/frank_10/quality-report/pullRequest
prid=1025662
least
spaces
inline
comment
least
spaces
inline
comment
decision
Fixed
thanks
comment
original
query
Objs
inline
comment
example
input
output
suggestion
stream
=
DBSession
.query
Stream
.get
f.stream_id
suggestion
classification
page
refresh
driver.wait_for_xpath_to_disappear
f
//
*
[
text
[
contains
]
timeout=1
Sorry
@
more
thing
things
present
wait_for_xpath_to_disappear
try-catch
pattern
readability
performance
consistency
accessible_streams
simllar
suggestion
same
name
two-liner
shortands
subclass
method
stub
FollowUpAPI
subclass
method
SubClass.method
different
addresses
memory
FollowUpAPI.method
block
Ditto
fixed
Looks
DefaultDict
=
None
suggestion
Instrument.api_classname.isnot
None
flake8
noqa
tried
..
See
comment
Hrm
sure
Sure
source
view
sure
case
multiple
tensors
dict
tensor
names
tests
let
sure
tensors
docstring
nit
lines
every_n_iter
kwargs
files
data/
folder
short
somehow
better
nit
necessary
more
above
one
u
other
params
eg
vocabulary_size
num_class
FLAGS
input
run_model
important
part
nit
pylint
disable=g-bad-import-order
own
module
imports
log
info
incorrect
nit
sentiment_model
import
official.xx.xx
discrepancy
style
eval
helper
function
train
nit
doc
little
clearer
TODO
seemuch
Support
different
train
eval
batch
sizes
FLAGS.eval_batch_size
=
FLAGS.batch_size
logging.warning
Keras
implementation
NCF
=
eval_batch_size
eval_batch_size
.format
FLAGS.eval_batch_size
FLAGS.batch_size
FLAGS.eval_batch_size
=
FLAGS.batch_size
params
ncf_common.parse_flags
FLAGS
ncf_common
rounds
due
reshape
eval
params
]
=
params
[
'eval_batch_size
]
great
job
People
requirements
non-trivial
number
Conda
users
sense
people
good
reason
reason
lint
prefers
absl
methods
manual
flag
util
https
//github.com/tensorflow/models/blob/master/official/utils/flags/core.py
L38
L46
quick
comment
changes
comment
wont
device
strategy
e.g
right
comment
code
distribution
strategy
keras
big
comment
temporary
measure
better
support
type
synthetic
data
tf.data
distribution
strategies
Could
data
pipeline
tf.data.Dataset
nuances
trees
datasets
details
ispirmustafa
Mustafa
TODO
l2
example
changes
scale
WDYT
presence
top
N
classes
N
Sine
wave
only
major
effect
time
use
use
enum
flag
lot
'output
line
caveats
PR
message
comments
eager
flag
help
end
line
re-enabled
relevant
section
cleaner
inside
resnet_main
pass
shape
code
intuitive
IMHO
flags
enum
option
time
dataset
anything
model
tf.logging.warning
real
data
synthetic
dataset
function
util
model_helpers
lists
ints
input
shapes
Just
lint
warning
end
line
sufficient
split
metrics_to_log
per_batch_metrics
per_epoch_metrics
log
epoch
batch
choice
user
code
lot
use-case
@
yhliang2018
@
qlzh727
incorrect
stripping
lowering
unnecessary
set
constants
init
time
comment
bug
relevant
odd
something
special
Might
nice
comment
dist_strat
kind
learning
model
nice
people
Okay
constant
confusing
comment
sure
effort
tf.data
CSV
files
magic
number
clarification
fake
rating
interaction
user
item
user_id
item_id
fields
final
csv
file
needs
fields
'user_id
item_id
interaction
comments
something
random
seed
parameter
set
tuple
items
dict
list
items
line
consistent
other
return
params
data
files
different
formats
Will
details
explanation
batch
size
needs
multiple
batch
GPUs
fine
test
fails
tests
lot
sense
none
test
run
fine
folder
issue
same
path
comment
todo
code
layers
support
lint
exception
Ditto
bug
nit
typing.Optional
[
str
]
str
pylint
disable=g-import-not-at-top
glint
clear
comment
TODO
Hate
code
cleanup
next
person
able
FLAGS
Can
TODO
case
someone
TPU
team
second
step
Tests
please
Good
point
explanation
comment
TODO
cleaner/less
batchnorm
FC
layers
TODO
comment
good
explicit
keyword
args
params
readability
Would
good
Explicit
params
docstring
great
multiple
params
batch_denorm
inclination
single
param
learning_rate
function
learning
rate
tensor
python
tf.estimator.Estimator
model_fn=
FLAGS.batch_size
FLAGS.batch_denom
def
learning_rate
tf.estimator.Estimator
model_fn=
=
learning_rate
rate
decay
rest
model
easier
interested
fewer
parameters
Comment
action
likely
accurate
hook
graph
grappler
XLA
first
time
wrong
big
deal
nice
comment
necessary
others
environment
variables
efficient
default_flags
KerasBenchmark.local_flags
typo
Added
TODO
http
//pylint-messages.wikidot.com/messages
w0102
Done
Push
docstring
way
likely
helpful
helpful
goal
files
format
result
flat
directory
subdir
os.listdir
Comment
necessary
output
cases
part
process
data_dir
flag
error
shape
expected
input
nit
prints
Module-level
constants
IIRC
xrange
py3
compatible
range
six.range
nit
layer
sounds
Layer
obj
layer_counter
i
something
incrementer
xentropy
loss
tf.identity
name
confusing
error
num_gpus
nit
CIFAR-10
colon
align
other
comment
line
code
Keep
lines
chars
first
word
end
period
>
sort
flag
other
examples
Hmm
version
issues
logic
warmup
etc
same
i
more
step
keras_common
common
resnet
module
other
main.py
code
value
other
values
many
locations
python
read32
f
num_images
same
num_items
comment
ticket
i.e
Telemetry
systems
Firefox
Desktop
Telemetry
v4
Glean
limits
length
unique
identifiers
size
slugs
smallest
limit
Firefox
Desktop
Telemetry
comment
suggestion
yea
internet
right
fanciness
Eh
comments
clearer
code
list
namedtuple
tuple
tuples
access
index
test
hiding
routes
same
iface
same
iface
index
Could
add_linkaggregation_port
helper
sense
defined
properties
schema
i.e
mode
slaves
list
comprehension
E402
Thanks
comments
comments
last
resort
comment
code
clear
Merits
function
comment
case
pretty
clear
Sorry
small
nit
Please
full
URL
issue
easier
Thank
comment
new
condition
IMHO
single
error
class
good
thing
callers
ID/message
nice
dedicated
exceptions
base
generic
challenges
something
class
NmstateError
Exception
code
message
=
UNKNOWN
ERROR
def
__str__
return
self.message
+
str
self.args
def
code
return
self.code
class
MyError
NmstateError
code
message
=
Error
Description'
sleep
part
follwing
relevant
Assume
rollback
Checkpoint
rollback
need
finish
other
actions
comments
‘
six.PY2
’
try/except
more
clear
comment
redundant
Comment
comment
commit
message
code
IMHO
comment
code
virtual
interfaces
bridges
DHCP
timeout
maximum
value
unlikely
other
comment
available
nm.nmclient
module
reason
specific
address
important
commit
message
pytest
python
parametrize
module
import
global
import
function
function
problem
need
comment
matter
API
design
user
input
unexpected
API
KeyError
operation
something
subset
mp_iterator
=
dispatch_metapartitions
dataset_uuid=dataset_uuid
store=store
predicates=predicates
metapartitions
P
==
case
iterator
metapartitions
https
//github.com/JDASoftwareGroup/kartothek/blob/master/tests/conftest.py
L197
[
]
Assertion
schema
differences
partitions
Assertion
difference
=
MetaPartition
label=
some_label
core
pd.DataFrame
empty
df
=
MetaPartition
label=
test_label
data
dispatch_metapartitions
MetaPartition
data
df
dispatch
files
anything
exception
MetaPartition
Can
dedicated
test
important
feature
repartitioning
simple
assert
dedicated
test
explicit
parameters
use
case
easier
unit
test
feature
multiple
Same
different
case
FYI
optimize
call
sufficient
repartition
blocks
additional
configuration
reparititon_ddf
function
test
cases
bit
redundant
minimal
set
cases
work
large
datafame
test
case
different
suggestion
arrow
representation
index_dct
large
amount
memory
strings
abg
items
Just
comment
correctness
due
ods
Whether
needs
rents
matter
conventions
Note
official
inequaliy
aggregates
imputed
rents
benefit_checks
kiz
function
tax_transfer
while
uhv_since_2017
function
returns
positive
values
children
https
//www.buzer.de/gesetz/2978/al63880-0.htm
children
age
range
UV
Could
Delete
comments
good
way
things
clear
year
condition
source
code
enough
source
code
need
param
type
check
cases
law
obsolete
type
check
cases
law
few
years
Soli
comment
line
comment
if-condition
hard
numbers
Parameters
param.xls
excel
file
tb
dictionary
parameters
file
line
clearer
Input
query
bot
previous
message
bot
params
frozen
params
object
Could
comment
logic
lint
exemptions
examples
whole
directory
F401s
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
F841
local
variable
'traced_model
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
D103
public
function
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
<
br
>
D107
__init__
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
<
br
>
D101
public
class
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
<
br
>
D105
magic
method
🤔
provided
example
functionality
loaders=
[
]
loader
names
callback
ignore_loaders=
[
]
loader
names
callback
more
user-friendly
Could
[
Google
Style
Python
Docstrings
]
https
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
please
isort
skip
better
logging
verbose
flag
experiment
interface
datasets
only
reason
docstrings
CI
catalyst/dl/__init__
suggestion
_
range
noqa
WPS122
utils
module
other
places
catalyst.utils.tensorboard
import
SummaryWriter
local
file
function
something
https
//github.com/catalyst-team/catalyst/blob/9f97ad91c82322a18ac6a5764aaded7fc54720a4/catalyst/utils/seed.py
L27
comment
hack
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
WPS442
Found
scope
names
features_and_labels
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
WPS437
Found
attribute
usage
_sample
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
WPS442
Found
scope
names
features_and_labels
Comment
source
code
[
x
]
code
[
flake8
]
https
//pypi.python.org/pypi/flake8
high-quality
low-quality
video
file
available
video
ID
*
*
video
files
extractor
correct
Remove
pointless
comments
Bother
>
[
new
extractor
tutorial
]
https
//github.com/rg3/youtube-dl
adding-support-for-a-new-site
youtube-dl
coding
conventions
https
//github.com/rg3/youtube-dl
youtube-dl-coding-conventions
sections
Query
query
formats
Remove
pointless
comments
Correct
extractor
[
'files
'hq
]
keys
present
JSON
data
order
video
URL
s
case
something
server
end
things
scenario
extractor
new
ExtractorError
exit
Extraction
key
necessary
regular
expressions
TODO
work
fallback
URL
extraction
metadata
warning
credentials
correct
metadata
id
Id
something
video
article
whole
current
extraction
approach
incorrect
separate
extractor
iframe
URL
<
iframe
src=
https
//www.seznam.cz/zpravy/iframe/player
duration=241
serviceSlug=zpravy
src=https
%
%
%
2Fv39-a.sdn.szn.cz
%
%
%
%
%
%
%
itemType=video
autoPlay=false
title=Sv
%
C4
%
%
%
%
%
%
C4
%
%
C5
%
A1t
%
C3
%
AD
%
%
C3
%
A1ci
%
%
%
C3
%
ADch
%
%
C3
%
A1tk
%
C3
%
A1
%
%
C4
%
%
%
%
%
C3
%
A1vy
poster=
%
%
2Fd39-a.sdn.szn.cz
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
width=1920
height=1080
cutFrom=0
cutTo=0
splVersion=VOD
contentId=170889
contextId=35990
showAdvert=true
collocation=
autoplayPossible=true
embed=
isVideoTooShortForPreroll=false
isVideoTooLongForPostroll=true
videoCommentOpKey=
videoCommentId=
version=4.0.76
dotService=zpravy
gemiusPrismIdentifier=bVc1ZIb_Qax4W2v5xOPGpMeCP31kFfrTzj0SqPTLh_b.Z7
zoneIdPreroll=seznam.pack.videospot
skipOffsetPreroll=5
sectionPrefixPreroll=
%
article
extractor
iframes
delegates
extractor
addition
extractor
such
videos
site
duplicate
tests
non
duplicate
tests
comments
hints
better
work
minimal
file
size
tests
video
initializing
segment
bytes
[
test_download.py:219
]
https
//github.com/rg3/youtube-dl/blob/6d0630d8801fd3278a05fa7e55a73bd454403e5a/test/test_download.py
L219
size
least
Sorry
comment
method
least
extractors
comment
YouTube
video
new
extractor
HEAD
actual
request
v4
previous
regex
regex
v6
git
log
diff
compat_
*
functions
added
comments
toplevel
files
bokeh/application
files
actual
diagnosis
cause
wrong
test
case
same
theme
dict
instance
multiple
models
doc
comment
apply_theme
sure
nothing
haywire
theme
model
theme
dict
@
maxgamurar
comment
typo
typo
content
comment
wrong
forward
slash
comment
wrong
forward
slash
PR
work
progress
commented
code
block
wrong
PRs
*
type
issue
PRs
normal
PRs
separate
issue
type
repo
style
space
triple
quotes
comment
line
comment
general
API
users
callback
threads
server
Let
function
_setup_helpers.py
e.g
suggestion
idx
suggestion
plot
=
]
*
len
Vendors
initialize
list
Vendor
plots
most
codepen
anything
other
CDN
resources
resources
=
Resources
mode=
cdn
bokeh-api
Things
CDN
e.g
local
resources
simple
Indentation
Use
pytest.raises
doc
lgtm
comment
interesting
lgtm
other
cases
reliable
tool
general
comment
redundant
/
unnecessary
ambivalent
idea
code
function
bokeh.settings
conf
little
shorter/cleaner
e.g
check_google_api_key_env
comment
assignments
necessary
main
reason
single
inheritance
able
rid
clunkiness
worth
kind
comment
usage
demonstration
password
plaintext
CustomJS
password
Set
User
Password
Create
Texts
inputs
button
redundant
GH
comment
above
@
pzwang
Thanks
feedback
few
lines
example
docstring
look
bill
file
name
py
file
name
extension
tests
comment
Agreed
anything
could/should
security
purposes
important
documentation
example
docstring
class
liability
aspects
security
*
widget
various
ways
password
text
plaintext
various
potential
attack
vectors
SSL/non-HTTPS
connections
trivial
amount
work
super
extensive
..
user
impression
secure
issue
bug
GH
comments
Which
comments
title
Inputs
something
readable
e.g
=
CustomJS
args=dict
pwd=pwd
secret=secret
code=
pwd.value
%
s
user.value
===
%
s
secret.text
=
Password
Secret
secret.text
=
Wrong
Password
%
PASSWD
USER
worth
%
happy
ok
upshot
reported
signature
bound
methods
line
way
Py3
self
Jan
comments
CSS_SELECTOR
variable
name
😢
Move
constant
list
static
API
request
planning
comment
TODO
Add
docstrings
functions
please
slash
Wrong
example
lite-content
_ID
comment
Use
Typing
comment
method
https
//docs.python.org/3/library/typing.html
steps
better
conftest
Move
comment
line
Which
line
AttributeError
everything
before/after
Sure
reason
ID
Done
reason
ID
Jira
ticket
comment
comment
i
super
minor
variable
extra
white
space
comment
andy
avoid
xpath
possible
Suffix
constant
_ID
comment
clearance
same
comment
Are
TODOs
Please
better
selector
Please
ID
doesnt
look
Please
normal
style
variable
typing
comment
style
require
Python
more
Blast545
leftover
allow
values
=
tu
call
split
limit
restriction
noqa
comment
problems
ci
jobs
https
//github.com/ros2/launch/pull/274
noqa
F401
iff
context
helpful
little
bit
explicit
worth
docs
OpaqueFunction
consistent
regard
line
length
constraint
line
noqa
E501
suggestion
self.__additional_env
=
None
type
Optional
[
List
[
Tuple
[
List
[
Substitution
]
List
[
Substitution
]
]
]
]
noqa
E501
pbaughman
nice
XML
structure
@
pbaughman
nit
explanation
test
docstring
@
pbaughman
nit
explanation
test
docstring
completion
futures
shutdown
iuhilnehc-ynos
hmm
context.is_shutdown
self.__respawn
context.asyncio_loop.create_task
self.__execute_process
context
redundancy
shutdown_future
todo
platforms
higher
pytest
.from_parent
available
[
changelog
]
https
//docs.pytest.org/en/latest/changelog.html
deprecations
change
search
from_parent
>
functools.wraps
signature
inspect
module
[
inspect.getfullargspec
]
https
//docs.python.org/3.6/library/inspect.html
inspect.getfullargspec
function
ivanpauno
SIGINT
polite
suggestion
Next
line
hangs
https
//github.com/ros2/launch/issues/183
assert
==
ls.run
shutdown_when_idle=False
nit^N
comment
first
time
launch.logging.launch_config.log_dir
=
None
launch
config
environment
super
code
joy
nitpick
please
extra
leading/trailing
spaces
punctuation
example
Action
environment
variable
doc
nitpick
please
extra
leading/trailing
spaces
use
punctuation
worth
environment
variable
example
Action
environment
variable
nothing
appropriate
self.__current_state
=
ChangeState.valid_states
[
]
regardless
dict
ordering
suggestion
actions
validate
user
unknown
attributes
children
@
pbaughman
nit
comments
part
function
Note
crazy
case
single
substitution
list
substitutions
strings
PS
comment
list
only
substitutions
tests
ivanpauno
types_in_list
==
float
int
bool
Substitution
typed
substitution
intentional
@
ivanpauno
meta
safe
function
type
checks
data_type
None
simpler
wjwwood
nice
ExecuteProcess
construction
local
[
]
length
=
pattern
attribute
function
kind
desired
convention
pattern
hack
@
functools.wraps
decorator
docstring
[
]
length
=
function
optional
true
>
originating_module
[
]
length
=
difference
module
class
module
>
target_class
[
]
length
=
child
class
right
callback
>
self._trig_poll
event_data
[
]
length
=
thread
_trig_poll
function
start
run
careful
thread
paho
thread
thread
good
thing
post_connect_actions=
[
subscribe_action
]
[
]
length
=
sure
design
complex
own
actions
operation
LOT
more
edge
cases
knowledge
implementation
transport/request_response_provider
layers
code
additional
way
something
Subscribe
Connect
separate
APIs
chaining
option
irrelevant
codebase
necessary
right
solution
problem
[
]
length
=
callback
convention
>
def
[
]
length
=
TODO
callback
connack
something
happens
[
]
length
=
state-based
provider
subscribe
request
subscribe
state-based
machine
connect
>
[
]
length
=
on_disconnected_handler
on_registration_complete_handler
issue
comment
teamwide
sync
issue
ear
real
inconsistency
requirements
>
]
length
=
sentence
incomplete
layer
registration
state
responses
parsing
registration
state
layer
layer
anything
payload
>
TODO
MQTT
Transport
connect
post
connect
actions
]
length
=
>
callback_cancel
[
]
length
=
convention
callbacks
callback
thing
i.e
function
callback
on_cancel
callback
parameter
idea
word
callback
function
function
someone
i.e
term
callback
something
callback
rationale
stack
many
layers
callbacks
term
callback
function
layer
function
goal
term
callback
latter
case
Bert
way
past
few
weeks
transport
refactor
code
model
ongoing
effort
new
code
convention
forth
Ask
Bert
type
comment
course
jump
separate
comments
self.on_registration_complete
=
None
[
]
length
=
register
operation
completes
callback
parameter
register
function
api
version
historical
reasons
>
elif
registration_result.status
[
]
length
=
sure
other
SDKs
callback
intermediate
step
registration
successful
useful
default
behavior
register
return
registration
complete
customers
callbacks
progress
Given
progress
information
i
sure
useful
async
version
await
>
TODO
Generic
Args
case
[
]
length
=
TODO
SetSymmetricKeySecurityClientArgs
SetSecurityClientArgs
operation
stages
stages
harm
stages
pipeline
stage
X509
other
handles
SK
specific
registration
other
problems
way
comment
please
consolidate
method
result
status
new
object
[
]
length
=
nit
thought
later
please
TODO
>
True
[
]
length
=
hard
Python
valid
method
response
payload
valid
json
samples
>
method_call
[
]
length
=
i
more
i
full
object
>
exit
[
]
length
=
super
super
nitpicky
Press
Q
>
feels
spacebar
enter
q
comment
copypasta
correct
new
test
useful
[
]
length
=
phrase
Azure
IoT
Edge
Module
>
[
]
length
=
ValueError
Feature
names
length
=
opinion
sure
value
lot
potential
bugs
strings
way
function
transport
call
something
MessagingManager.c2d.disable
example
c2d
interface
ABC
enable/disable
methods
connection_string_format
[
]
length
=
reason
lines
>
loop
=
asyncio.get_event_loop
]
length
=
get_running_loop
i
same
comment
i
pattern
^^
early
something
APIs
multiply
>
future
=
asyncio.Future
]
length
=
possible
loop.create_future
log
SHOULD
error
>
op_connect.error
[
]
length
=
error
connection
complete
failure
method
something
post
connection
stuff
feels
successful
connection
call
>
operation_flow.complete_op
length
=
mean
operation
callback
callback
order
ORIGINAL
callback
odd
confusing
logs
issues
complete_op
more
callback
_sign
length
=
dot
._sign
static
function
confusion
past
code
comment
sweat_smile
empty
signal
across
least
echos
unstable
empty
huge
point
sure
clear
docstring
make_optcom
TODO
mask
something
visual
reports
suggestion
normalize
data
subtract
mean
divide
standard
deviation
last
dimension
standardized
parameter
estimates
multiple
regression
same
correlation
coefficients
possible
correlation
coefficients
step
values
<
-1
suggestion
matrix
mmix
values
approximate
correlation
values
conversion
valid
bug
opinion
something
mixing
matrix
following
mmix
=
axis=0
suggestion
subtract
mean
dividing
standard
deviation
suggestion
TODO
determine
tedana
suggestion
suggestion
KIC
option
suggestion
MDL
option
dictionaries
class
list
[
icon
color
]
Prebuild
section
little
loop
dictionary
Similar
same
dictionary
clearer
dictionaries
section
L175
loop
kind
mkr_dict
L185
Same
small
comment
snake
case
blocks
suggestion
var_expl
=
[
]
=
[
]
clf
[
]
var_expl
+=
np.sum
comptable
[
comptable.classification
==
clf
]
[
]
+=
comptable
[
comptable.classification
==
clf
]
.count
]
index
lists
bigger
question
mention
docstring
T1-like
effect
comment
variable
minimum
image
little
counter-intuitive
bold_ts
mid-elbow
high-kappa
comment
same
comment
variable
name
change
same
comment
same
variable
dates
general
method
basic
classes
*
properties
funny
broadcast_to
nice
find
sure
%
code
following
comment
get_H
get_H
G
[
E^\alpha
C
\beta
]
E^\alpha
=
R_1^\dagger
Q^\apha
R_2
C
\beta
=
Q2
Q^\alpha
=
Q1
Note
transpose
R
E^\alpha
absolute
value
z
=
m_\alpha
R
x
F
fourier
transform
Q
m_\alpha^\dagger
m
R_1^\dagger
R_2
Does
comment
Stickler
six.StringIO
migration
python
codebase
easier
'auto
scale
desirable
result
limited
area
maps
clause
s
code
*
invocation
_repr_svg
repr
wouldn
’
t
comment
file
pep8
Same
canonical
way
python
operator
import
itemgetter
return
schema
key=itemgetter
'name
canonical
way
python
operator
import
itemgetter
column
columns
]
key=itemgetter
'name
one
test_throttle_login
tests
LMK
better
test
sth
purpose
current
test
test
feature
test
b
sure
prod
feature
suggestion
extension
entry
point
type
value
different
entry
point
files
something
logic
callable
use
module
implementation
-1
default
compatible
values
enumerate
need
track
i
suggestion
i
sub_item
enumerate
value
reduced_item
[
key
]
=
value
key
non
string
values
strings
type
i
suggestion
reduce_item
reduced_item
u
key
i
sub_item
something
admins
fields
+
flags
list_data_sources
limited
set
fields
+
flags
others
flags
good
comment
logic
one-liner
easier
same
same
code
google_spreadsheets
query_results
query
runners
Could
code
redash.query_runner.guess_type
suggestion
results
error
=
self._run_query_without_warehouse
query
sync
previous
comment
suggestion
def
api_call
sql
better
error
results
value
error
suggestion
friendly_name
name
future
please
separate
pull
request
such
changes
main
concern
line
queries
select
current_time
Postgres
logical
assertion
test
Could
different
tests
following
sql
*
raw_events
comment
logic
possible
+
consistent
other
options
json_dumps
https
//github.com/getredash/redash/blob/37a6e70a4ae06923e156cbb0babf6afae9d933d0/redash/utils/__init__.py
L118-L123
kwargs.setdefault
True
redash.scheduler
docstring
schedule
function
Title
PR
>
=0.7
>
=0.6
So
typo
media
median
side
comment
fine
code
little
bit
readable
symmetric
assign_moving_target_wcs
input
model
status
None
better
mocked
superbias
reffile
intent
coronagraphic
TSO
sake
xxxints
products
casual
reading
bit
coronagraphic
TSO
additional
tests
data
way
data
other
source
old
reg
test
system
early
stages
master
step
sanity
checks
overall
algorithm
right
thing
i.e
result
hand
confident
design
algorithm
types
additional
tests
lot
extra
baggage
difficult
simple
tests
step
various
forms
output
products
truth
files
same
product
JWST
context
something
relevant
NIRCam
detector
first
list
list
members
ASN
table
input
calwebb_image3
pipeline
order
semi-random
nice
comment
significance
num_sources
negative
list
case
spaces
comments
understandable
spec
definition
step
May
other
JWST
pipeline
steps
formatting
skymatch
example
web
service
catalogs
other
Gaia
name
gaia
step
arguments
something
more
generic
comment
valid
Worth
comment
particular
clear
comment
problem
data
models
correct
assertion
pytest.raises
test
xfail
easier
issue
proper
fix
Same
applies
test
typos
comment
Minor
nit
period
end
phrase
thought
next
comment
line
block
code
sense
result
resample_input
resampling
confused
False
background
image
i.e
background
signal
image
need
Done
Good
point
empty
dictionary
param
=
get_rscd_parameters
typo
attriburtes
>
line
test
None
CI
testing
infrastructure
access
central
store
override_saturation
required
header
keywords
data
reffile
current
rmap
NIRCam
saturation
reffile
https
//jwst-crds.stsci.edu
following
keywords
data.meta.instrument.detector
=
data.meta.observation.date
'2017-10-01'
data.meta.observation.time
=
fragile
assert
reffile
correct
assert
output.meta.ref_file.saturation.name
==
'crds
//jwst_nircam_saturation_0064.fits'
comment
NIRCam
data
pixeldq
groupdq
zeros
correct
dtype
constructor
shape
tuple
data_model
=
MIRIRampModel
csize
data_model.data
Same
comment
line
@
jdavies-st
CI
tests
access
central
store
/grp
print
statements
lines
desired
values
case
use
[
]
=
np.bitwise_or
dqflags.pixel
[
'HOT
]
dqflags.pixel
[
'DO_NOT_USE
]
math
np
ready
bits
OUTLIER
outlier_detection
step
set
informational
flag
DO_NOT_USE
outliers
unique
flag
JUMP_DET
comment
running
pipeline
test
setup
RegtestData
object
variable
different
name
data
plural
data
file
<
grammar-police
>
Incomplete
comment
work
pixels
even
number
differences
Could
comment
dividing
little
confusing
arguments
order
tests
OK
%
sure
test
data
models
input
disk
files
dq_init
step
checks
existence
pixeldq
groupdq
arrays
data
model
err
array
only
err
input
disk
file
data
model
check
time
data
model
sure
data
model
wrong
flake8
nptest
unused
hence
Could
docstrings
tests
Check
value
reference
file
DQ
array
science
image
similar
one-liner
good
triple-quotes
print
statements
use
CI
environment
lines
longer
relevance
reason
comments
relevance
commented
print
statements
previous
comment
readability
blocks
new
code
future
rid
comment
boolean
extraction
height
params
names
such
tsgrism_extract_height
readability
datamodels.dqflags.pixel
group
meaning
value
Curiosity
question
loop
possible
outcomes
node
ctx
node
None
node
last
attribute
other
attributes
path
specific
exception
s
guess
AttributeError
TypeError
sure
Same
lines
68-71
test
xfail
@
pytest.mark.xfail
reason='Not
something
descriptive
generic
nirspec
routine
NRS_IFU
So
less
generic
name
method
_process_nirspec_slits
macro
modes
grism
e.g
GRISM_TYPES
WFSS_TYPES
+
pixmax
peakmax
Good
suggestion
thanks
higher-level
routine
i.e
step
class
routine
care
handling
different
forms
input
science/source
data
case
routine
single
data
model
instance
single
source
instance
input
step
MultiSlitModel
Slit
instance
time
function
original
code
places
ref
file
DQ
array
NO_SAT_CHECK
pixels
NO_SAT_CHECK
change
NO_SAT_CHECK
other
DQ
values
pixels
values
science
data
PIXELDQ
array
*
DQ
values
ref
file
logic
way
line
reason
values
array
NO_SAT_CHECK
flags
first
place
Done
Any
better
concise
way
counting
saturated
pixels
number
pixels
least
integration
group
i.e
multiple
counts
due
pixel
more
group
more
integration
May
test
input
DQ
bit
sure
output
bit
comments
test
lines
development
comment
reasonable
file
tests
other
jwst
modules
stdatamodels
sketch
*
*
stdatamodels
*
*
test_strict_validation_enum
test_strict_validation_type
test_strict_validation_date
*
*
jwst
jwst/datamodels/tests/test_models.py
*
*
test_mask_model
test_table_size_zero
*
*
jwst
file
specific
asdf
extension
*
*
test_datamodel_schema_entry_points
*
jwst
test_multislit.py
*
*
test_multislit_model
test_copy_multslit
test_multislit_move_from_fits
test_all_datamodels_init
*
*
*
*
test_data_array
sure
*
*
possible
duplicates
*
test_list
test_list2
tests
stdatamodels
test_invalid_fits
good
coverage
PASS_INVALID_VALUES
STRICT_VALIDATION
stdatamodels
comment
stsci.image.median
np.median
masked
array
masked
values
nans
np.nanmedian
data
median
np.nanmedian
less
memory
only
reason
stsci.image.median
case
several
images
stack
_might_
high
low
values
median
mode
pipeline
processing
hybrid
approach
use
stsci.image.median
cases
n
<
=
straight
median
np.nanmedian
>
case
chance
few
high
low
cases
>
images
stack
plain
np.nanmedian
stack
integrations
memory
footprint
high
image
full
arrays
same
comment
syntax
above
Should
comment
MIRI
LRS
comments
actual
processing
center
slit
picture
mind
physical
rectangular
slit
long
axis
spatial
direction
natural
spectrograph
spectral
dimension
slit
narrow
center
slit
refers
something
spatial
long
dimension
slit
center/middle
spectral
trace
wavelength
axis
lines
e.g
middle
spectrum
wavelength
spectrum
entrance
slit
exptype
last
branch
catch-all
random
exptype
E261
least
spaces
inline
comment
*
Origin
PycodestyleBear
E261
Section
Il
serait
probablemnet
intéréssant
faire
le
même
test
sur
un
chapitre
tuto
join
BASE_DIR
'assets
'tex
'template.tex
reaction
comment
Peux-tu
mettre
ce
commentaire
cohérent
avec
le
reste
du
code
Commentaire
à
J'avoue
que
je
suis
moyennement
convaincu
par
le
passage
des
compréhensions
liste
sur
plusieurs
lignes
Je
trouve
que
largement
lisible
sur
une
ligne
avec
limite
des
caractères
Je
pense
qu'il
manque
la
parenthèse
fermante
veut
dire
qu'on
se
donne
une
granularité
Le
cas
où
value
n'est
traité
par
aucune
des
conditions
Rounds
value
heure
minutes
écrire
completement
anglais
du
coup
rester
cohérent
avec
le
reste
j'ajouterais
même
python
django.core.validators
email_re
receiver.email
A~n~
user
s/adress/address
Outdated/incorrect
comment
matplotlib
somehow
Will
comment
default
edgepaths
.select
arrays
'data
i.e
multiple
elements
different
lengths
Small
suggestion
suggestion
hmap
=
HeatMap
[
A',1
B
]
.options
dilate=True
plot
=
bokeh_renderer.get_plot
hmap
glyph
=
plot.handles
]
self.assertTrue
glyph.dilate
Similar
comment
above
lengths
plural
length
dataset.data
Pre-allocating
memory
sounds
good
docstring
clear
format
values
relates
shape
None
None
only
sensible
option
float
thing
Sure
comment
docstring
data
components
unpacked
numpy
array
docstring
select
MultiInterface
select
components
result
list
IIRC
'level
contour
thing
true
something
Backwards
compatibility
'level
vdim
Contours
float
thing
range
list
inputs
empty
type
float
Same
comment
None
None
range
Contours
Polygons
*
Please
suggestion
repetition
comments
authentication_classes
*
new
file
teams
mixins.py
edx_rest_framework_extensions.auth.session.authentication
import
SessionAuthenticationAllowInactiveUser
openedx.core.lib.api.authentication
import
OAuth2AuthenticationAllowInactiveUser
class
AllowInActiveUserAuthClassesMixin
OAuth2AuthenticationAllowInactiveUser
unauthenticated
users
OAuth2AuthenticationAllowInactiveUser
SessionAuthenticationAllowInactiveUser
OAuth2Authentication
SessionAuthentication
inactive
user
course
team
=
OAuth2AuthenticationAllowInactiveUser
SessionAuthenticationAllowInactiveUser
new
imports
mixin
import
Add
AllowInActiveUserAuthClassesMixin
relevant
classes
authentication_classes
line
classes
AllowInActiveUserAuthClassesMixin
Or
better
way
repetition
same
broken
fix
https
//github.com/odoo/odoo/commit/a98d60cb11ceee31a6bd9d3734d0e4b565e5d677
line
reason
env.ref
meeting
need
actual
number
items
recordset
dictionary
literal
unnecessary
detrimental
keyword
parameter
resource
comment
possible
relation
table
custom
m2m
field
other
solution
exchange
move
filter
lines_to_keep
=
current_invoice.move_id.line_ids
lines_to_keep
+=
'full_reconcile_id.exchange_move_id.line_ids
rec_move_ids
lambda
r
+
r.credit_move_id
lines_to_keep
partial
reconciliation
invoice
exchange
rate
entry
full
reconciliation
comment
necessary
next
lines
diff
code
Do
moves
initial
demand
initial
demand
transfer
mechanism
==
'draft
'move_lines.product_uom_qty
call
model
comment
bit
rationale
choice
e.g
something
Cheaper
domain
False
everything
nonsensical
domain
tde-banana-odoo
first
element
id
dictionary
dict
headers
'Content-Type
exact
MIME
Type
bit
flexible
headers
contains
headers
https
//github.com/odoo/odoo/blob/11.0/odoo/addons/base/ir/ir_http.py
L346
dangerous
doubt
*
exceptions
name
attribute
fact
ImportError
name
attribute
P2
Extra
method
overkill
average
price
comment
current
module
models
module
schema
schema
extension
model
instance
require=True
field
schema
module
comment
clear
idea
purpose
hard
time
*
big
deal
final
field
relation
chain
entire
chain
record
lines
necessary
mandatory
brackets
p
more
test
cases
decimals
pain
several
cases
Remove
test
case
update
case
duplicates
eye
Rename
pythonscript
devs
second
part
sentence
clear
inherited
fields
user-provided
parent
record
translations
parent
record
copy
old
parent
record
style
try
something
elif
modules
set
[
None
]
suggest
xmlid
self._context
[
'module
]
present
self._context.get
'module
field._modules
xmlid
→
define
crap
instance
Just
local
variables
initialization
need_hintcount
__init__
method
comment
line
comment
accurate
empty
entire-space
smaller
pieces
overlay
requirement
boxes
entire
space
output-generation
box
substitution
rest
good
Thanks
things
good
idea
mention
docstring
ttFont
name
table
logical
html.escape
lsp_documentation
kind
lsp_documentation.get
kind
markdown
return
mdpopups.md2html
self.view
value
plaintext
return
html.escape
value
function
normalized_documentation
name
minihtml
suits
function
LSP-human-readable-text
ST-minihtml
Style
nit
need
liberal
line
breaks
comments
column
limit
vertical
space
good
typos
text
comments
MarkupContent
MarkupContent
statement
ifs
useful
MarkedString
MarkupKind
list
MarkedStrings
problematic
markup
content
problem
rest
lives
detailed
comment
nice
shorter
py
trim_trailing_white_space
=trim_trailing_white_space
False
none
shorter
suggestion
trim_trailing_white_space
=
settings.get
False
none
meta.mapping.key
string
constant.other.enum
Java
C
default
edit
region
situation
user
types
bbb
server
completion
item
range
foobar
aafoobar
code
aaa
bbbfoobar
guess
region
buffer
cases
self.view.erase
edit_region
Snippet
content
new_text
PlainText
content
snippet_escape
new_text
snippet_escape
replaces
signs
\
particular
completion
item
https
//github.com/sublimelsp/LSP/blob/2d7bed9bc58eb25fe670e472813cc810bf77852b/tests/test_completion.py
L351-L370
single
letter
buffer
completion
something
different
multiple
cursors
complex
multiple
cursors
cursor
location
completions
*
intersection
*
results
completion
items
valid
cursor
locations
insufficient
So
let
feature
math
solution
erase
+
insert
operation
single
operation
completion
snippet
erase
case
plaintext
completion
single
proud
do_resolve
function
only
part
PR
spec
text
edit
start
ragne
text
edit
end
range
following
reasons
|
curson
command
completion
item
pref|
typed
prefix
removed
prefix
range
end
position
end
position
wrong
region
prefix
length
end
range
eather
completion
request
textDocument/didChange
textDocument/didChange
debounce
completion
request
slow
only
solution
current
cursor
postion
command
completion
item
pref|
typed
prefix
^
end
range
position
completion
item
prefix|
complicated
only
way
good
time
try
block
right
instantiation
faulty
language
handler
*
language
handlers
capability
set_timeout
return
self.view.run_command
macOS
ancient
anybody
macOS
https
//superuser.com/questions/439440/did-mac-os-lion-switch-to-using-line-feeds-lf-n-for-line-breaks-instead-of
right
thread
issues
fine
Nitpick
please
commented-out
code
test
case
label
spaces
https
//github.com/sublimelsp/LSP/blob/87e98cf9d0a7d80f315dfb74d22b6c568a2a34b3/tests/test_completion.py
L237-L245
label
def
myFunction
Unit
def
myF
AC
auto_complete_preserve_order
AC
completion
item
AC
auto_complete_preserve_order
none
AC
example
https
//github.com/sublimelsp/LSP/blob/87e98cf9d0a7d80f315dfb74d22b6c568a2a34b3/tests/test_completion.py
L260-L261
Just
reminder
completion
tests
none
https
//github.com/sublimelsp/LSP/blob/87e98cf9d0a7d80f315dfb74d22b6c568a2a34b3/tests/setup.py
L175
if/else
st_details
=
html.escape
lsp_detail
self.normalized_documentation
item
comment
PES
incorrect
StreamsViewDivider
need
section
comment
ie
situation
worth
count
model
updates
unread_counts
model
values
something
case
controller
better
separate
tests
updated
version
op
comment
modern
version
op
comment
UI
notifications
comment
__
[
Flake8
]
__
[
W291
]
whitespace
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5778
issue-4415267
sub
>
Sider
<
/sub
>
please
update
test_keylist
order
default
value
number
comments
sync
better
comment
array
order
array
future
Please
example
such
paths
people
code
Invalid
escape
sequences
s
working
\s
valid
escape
sequence
raw
string
other
backslashes
un-escaping
\s
valid
regex
pattern
Unicode
str
Matches
Unicode
whitespace
characters
[
\t\n\r\f\v
]
many
other
characters
byte
string
b
different
rb
clear
rb
unknown
ones
different
Ah
\
rb'\\
==
b'\\\\
unknown
escape
sequences
such
\s
same
tab
'\t
mlog.error
AFAIK
MesonException
mesonmain.py
error
MesonException
case
error
similar
questioning
minstall.py
tbh
mix
IIRC
[
Flake8
]
__
'Tuple
Sider
]
https
//sider.review/gh/repos/19784232/pulls/6127
issue-4821072
sub
>
Sider
<
/sub
>
version
s/nolder/older
__
[
Flake8
]
__
[
F821
]
name
'MesonException
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5448
issue-4186287
sub
>
Sider
<
/sub
little
bit
text
configure_package_config_file
[
Flake8
]
__
whitespace
[
link
]
https
//sider.review/gh/repos/19784232/pulls/6076
issue-4738330
sub
>
Sider
<
/sub
comment
sense
initials
such
tags
code
git
blame
same
other
comments
better
get_target_dir
return
normalised
paths
way
issue
call
comment
os.path.realpath
comments
git
blame
confusing
output
failures
-pthread
present
meson
test
logic
[
flake8
]
__
*
[
W291
]
whitespace
<
Comment
[
SideCI
]
https
//sideci.com
>
more
sense
EnvironmentException
value
likely
someone
unexpected
results
__
[
Flake8
]
__
<
sub
>
Sider
<
/sub
>
[
W291
]
whitespace
__
[
Flake8
]
__
[
W291
]
whitespace
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5894
issue-4572106
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
W291
]
whitespace
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5894
issue-4572109
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
W291
]
whitespace
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5894
issue-4572107
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
W291
]
whitespace
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5894
issue-4572108
sub
>
Sider
<
/sub
fact
endswith
Please
comment
sysroot
prefixes
'/usr/include
'/usr/local/include
sure
default
C89
C99
initializers
set
tuple
membership
tests
sets
log
time
tuples
linear
time
lookups
[
Flake8
]
__
Sider
]
https
//sider.review/gh/repos/19784232/pulls/6437
issue-5040780
<
details
|
Rule
|
|
|
|
F821
|
<
>
<
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
Sider
]
https
//sider.review/gh/repos/19784232/pulls/6437
issue-5040779
<
details
|
Rule
|
|
|
|
F821
|
<
>
<
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
Sider
]
https
//sider.review/gh/repos/19784232/pulls/6437
issue-5040781
<
details
|
Rule
|
|
|
|
F821
|
<
>
<
sub
>
Sider
<
/sub
regex
sure
h
optional
something
r'-Wl-rpath
[
=
]
*
*
comment
Normally
[
native
true
]
https
//github.com/mesonbuild/meson/wiki/Reference
%
20manual
executable
use-case
exe
use
build
build
machine
case
compile_resources
sucks
something
ARM
Windows
machine
build
tool
resources
extreme
edge-case
case
https
//github.com/mesonbuild/meson/issues/1531
note
FIXME
native
true
executables
https
//github.com/mesonbuild/meson/issues/1531
error
visual
studio
command
prompt
Platform
var
64-bit
x86
32-bit
MSBuild
picks
correct
solution
msbuild
solutions
single
config|arch
Windows
complete
path
.exe
end
such
MinGW
dependencies.ExternalProgram
__
[
Flake8
]
__
[
F401
]
'.base.PkgConfigDependency
unused
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E114
]
indentation
multiple
comment
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5695
issue-4359071
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
E121
]
continuation
line
under-indented
indent
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5695
issue-4359073
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
E131
]
continuation
line
indent
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5695
issue-4359074
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
E111
]
indentation
multiple
[
]
https
//sider.review/gh/repos/19784232/pulls/5695
issue-4359072
sub
>
Sider
<
/sub
>
sure
meson
codebase
[
PEP8
]
https
//www.python.org/dev/peps/pep-0008/
id51
isinstance
idir
str
idir
current
directory
current
directory
sys.path
parent
script
comment
bit
clearer
docstring
caught
unused
delete
Add
comments
add
cleanup
envar
Please
comment
[
ARIA-429
]
https
//issues.apache.org/jira/browse/ARIA-429
follow
please
capital
letter
Python
Unicode
uppercase
YAML
Temporary
petty
HELP
line
deliberate
able
description
metrics
handy
python
where_clause
room_id
NOT
IN
%
s
%
.join
_
room_id_filter
pretty
common
idiom
comments
line
IP
>
true
get_file
SynapseError
plenty
other
reasons
wrong
last
sentence
comment
misleading
Could
rid
inline
comment
full
stops
sentences
suggestion
check
cross-signing
keys
good
comment
*
keys
federation
request
device
query
user
cross-signing
suggestion
users
list
federation
https
//github.com/matrix-org/synapse/blob/master/docs/code_style.md
>
top-level
config
option
Can
comment
self.delete_device
call
%
sure
suggestion
device_id
keys
dehydrated
devices
device
compatibility
older
clients
comment
account
dehydrated
device
suggestion
Validate
user
member
room
comments
mean
good
outbound_redis_connection
type
hs
SUBSCRIBE
bit
more
sense
better
names
connection
outbound_redis_connection
something
b
natural
ReplicationCommandHandler.start_replication
pass
result
place
hs.config.redis_
unclear
refers
suggestion
trusted_third_party_id_servers
scheme
assert
checks
comment
reality
particular
username
sure
tbh
particular
need
rid
HTTPStatus
params
ohh
gosh
HTTPStatus
subclass
int
>
>
import
http
>
>
>
isinstance
http.HTTPStatus.FORBIDDEN
int
docstring
correct
everything
access
logger
code
%
d
%
code
right
thing
change
http.client.
<
code
>
int
python
multiple
potential
solutions
*
HTTPStatus
reference
<
code
>
.value
tricky
many
different
ways
hold
HTTPStatus
reference
separate
problem
consistent
*
special-case
HTTPStatus
*
=
int
code
*
%
d
%
self.code
access
logger
code
sure
strong
feelings
uneasy
last
option
bit
fragile
b
%
d
%
code
code
.encode
something
way
comments
HTTPStatus
instances
int
s
magic
__str__
methods
outdated
comment
suggestion
Ensure
userinfo
endpoint
logic
get_all_updated_current_state_deltas
rows
stream
ID
sense
debug
finicky
part
comment
stale
RDATA
commands
*
POSITION
I.e.
pending_batches
POSITION
suggestion
identity
server
validation
suggestion
Copyright
Matrix.org
Foundation
C.I.C
suggestion
auto_join_rooms
flag
false
prevents
guest
accounts
rooms
Defaults
true
auto_join_rooms_for_guests
false
suggestion
PATH
Overridden
subclasses
regex
path
suggestion
admin
display
name
user
user
suggestion
target
user
suggestion
much
MAX
more
details
other
suggestion
parts
address.split
@
parts
logger.debug
parse
address
%
s
address
raise
ValueError
Unable
email
address
return
parts
]
.casefold
@
+
parts
]
.lower
Neat
hasattr
getattr
more
sense
preference
constructor
section
please
response
port
lookup
fails
reason
log
line
point
configuration
error
someone
well-known
nice
debuggability
Hmm
sort
understand
comment
sure
few
times
stronger
pretty
vague
sure
comment
value
bit
dubious
functions
depths
storage
layer
appropriate
other
HTTP
error
code
REST
call
least-awful
option
case
least
document
docstring
mark_ui_auth_stage_complete
suggestion
URI
session
couple
other
spots
sense
type
Thanks
keys
matches
situation
sender_key
device
other
device_id
way
inherit
class
function
tedious
least
avoids
spurious
NotImplementedError
stuff
ABC
metaclass
stuff
comment
earth
exception
comment
lie
suggestion
A
JSONEncoder
capable
frozendicts
whitespace
JSON
suggestion
topological
ordfering
e.g
server
timestamp
suggestion
current
event
state
set
statement
line
relevant
auth_id
event_to_missing_sets
comment
event
unreachable
state
sets
proven
suggestion
sorted
list
events
auth
suggestion
C
reachable
suggestion
silly
auth
graph
auth
difference
algorithm
helpful
bug
comment
comment
API
test
case
checks
API
data
store
cleaner
due
level
b
storage
APIs
tests
storage
APIs
OTOH
consent
API
nice
way
fine
suggestion
expensive
handling
PDUs
clearer
while
loop
len
pending_edus
_
val
=
self._pending_edus_keyed.popitem
pending_edus.append
val
right
way
room
rule
id
push_rules
case
point
temporary
list
<
rule
applies
room
>
continue
conversion
reason
multiple
user_ids
reason
way
function
copy_push_rules_from_room_to_room_for_user
whole
process
single
user_id
simpler
clearer
suggestion
thumbnails
process
media
conceivable
other
download
request
thumbnails
b
sure
thumbnails
comment
fact
frozendict
good
sure
comment
Copy/paste
error
few
more
[
documentation
IConsumer
]
https
//twisted.readthedocs.io/en/twisted-20.3.0/core/howto/producers.html
write-data
write
_send_data
proxies
>
method
producer
data
Push
producers
Pull
producers
time
old
implementation
correct
usage
suggestion
Retrieves
event
database
sentence
head
logic
room
id
server
notices
room
*
different
*
room
server
notices
room
anything
behaviour
docstring
suggestion
disabled
regardless
users
able
msisdn
identifier
account
due
Synapse
method
SMS
messages
own
suggestion
upload_name
updates
comment
update
one
suggestion
%
below
require_at_registration
require_at_registration
heap
require_at_registration
good
clearer
name
policy
users
meant
filename
please
comment
list
suggestion
list
text
content
types
charset
default
UTF-8
none
suggestion
Default
UTF-8
charset
text
content
types
charset
other
parameter
ie
nicer
way
password
writable
scope
function
suggestion
Uh
handler
exception
request
error
comment
date
suggestion
nice
link
XXX
something
action
something
specification
phone
field
Synapse
number
field
Accept
backwards
compatibility
suggestion
=50.0
Dict
[
str
List
[
Tuple
[
EventBase
str
]
]
]
queue
https
//github.com/matrix-org/synapse/blob/a35bf130381833a66bf8dce4cd4078259914528c/synapse/handlers/federation.py
L1439-L1440
suggestion
Note
rows
bit
initial
population
run_upgrade
rest
comment
table
better
run_upgrade
Typo
suggestion
Multiple
return
factor
ID
correct
sign
suggestion
Multiply
return
factor
ID
correct
sign
words
*
*
*
ones
checks
statement
Overall
big
improvement
suggestion
public-facing
domain
server
consistent
public_baseurl
suggestion
Connect
client
vice
versa
suggestion
None
Thumbnailing
non-deterministic
success
exact
output
None
suggestion
suggestion
MSC2190
MSC2264
black
wrong
one
suggestion
comment
suggestion
key
signatures
signature
structure
ed25519
key
suggestion
Third
optional
on_invalidate
argument
callable
input
returns
nothing
calltyp
=
CallableType
dummy-device
None
empty
string
sorts
silly
issues
e.g
db
actual
assert
bit
misleading
imho
suggestion
update
function
limit
updates
new
stream
position
future
shardable
bit
inconsistent
inputs
list
comment
suggestion
Allowed
clock
difference
seconds
homeserver
IdP
Uncomment
below
accepted
time
difference
seconds
style
needs
nice
default
uncommented
minds
options
point
pysaml2
docs
bit
simpler
users
suggestion
Allowed
clock
difference
seconds
IdP
Uncomment
below
accepted
time
difference
seconds
suggestion
efficiency
database
suggestion
Database
recursive
CTE
Mm
bit
explanation
option
other
option
Whether
users
displayname
Useful
users
contents
third-party
directory
Does
administrators
Defaults
enable_set_displayname
false
Whether
users
avatar
Useful
users
contents
third-party
directory
Does
administrators
Defaults
enable_set_avatar_url
false
suggestion
Whether
users
accounts
email
address
msisdn
suggestion
Defaults
suggestion
Setting
displayname
first
time
suggestion
Set
displayname
suggestion
Setting
second
time
forbidden
suggestion
Set
avatar
suggestion
Set
second
time
forbidden
suggestion
Setting
displayname
first
time
hs.get_instance_name
master
process
suggestion
suggestion
resolve_events_with_store
StateMap
new
comment
more
confidence
suggestion
events
current
position
suggestion
event_ids
type
List
[
Ingnoring
clarity
suggestion
None
new
state
events
joins
current
room
state
other
users
room
suggestion
Pull
configured
instances
shard
config
comment
hack
in-memory
SQLite
tests
comment
%
code
identical
additional
test-case
comment
wrong
suggestion
A
lock
above
set
dict
suggestion
Delete
group
last
user
quick
comment
temporary
power
levels
overridden
Synapse
worker
apps
odd
boolean
False
env
var
unset
str
bytes
=
SYNAPSE_USE_FROZEN_DICTS
os.environ
reliable
other
code
paths
address=None
easiest
solution
parameter
request
admin
API
smaller
functions
better
@
override_config
guts
object
better
override
default_config
docstring
HomeserverTestCase
comment
auth
blocking
comment
difference
tests
ones
line
etc
purpose
sync
comments
test
strategy
helpful
return
_handle_cas_response
returns
awaitable
None
clearer
return
servlet
return
call
comments
amiss
process
charge
stream
ids
events
instantiate
ID
generators
database
process
charge
events
stream
IDs
replication
IDs
style
doc
uncomment
metrics_flags
comment
subentry
top
block
metrics_flags
None
suggestion
Flags
prometheus
metrics
suitable
behaviour
get_relations_for_event
pagination
structure
different
contents
original_event
MSC
hard
safe
case
uneasy
unspecced
behaviour
clients
sure
https
//github.com/matrix-org/synapse/blob/32e7c9e7f20b57dd081023ac42d6931a8da9b3a3/tests/storage/test_redaction.py
L135
Might
best
method
is_event_redacted
sure
suggestion
JsonResource
HealthResource
suggestion
replication
replication
below
caches
bit
opaque
comments
odd
room
backup
session_id
problems
due
numeric
userids
guests
suggestion
OIDC
providers
integer
IDs
Synapse
external
IDs
strings
fields
POST
request
suggestion
Note
space
MXID
suggestion
Register
master
replication
listener
sure
sql
=
SELECT
token
FROM
threepid_validation_token
INNER
JOIN
threepid_validation_session
USING
session_id
WHERE
=
=
>
LIMIT
comment
top
something
=
[
RemoteHandler
TerseJsonFormatter
]
noqa
necessary
tests
method
someone
@
DEBUG
suggestion
Uncomment
user
share
room
user
order
days
uncomment
functionality
suggestion
limit_profile_requests_to_users_who_share_rooms
true
non-deleted
state
returned
event
None
Please
comment
ALPHABETICAL
alphabetical
size
name
joined_members
Thanks
StreamIdGenerator
suggestion
persist
events
suggestion
Jump
gaps
minimum
bit
brutal
least
info
most
people
debug
point
errors
EXIF
transpose
try
cover
less
code
log
message
comment
operations
exception
worth
logline
people
purposes
logger.debug
Error
image
EXIF
information
%
s
e
line
except
Exception
e
exception
check_host_in_room
*
expensive
*
users
server
room
whereas
search
appropriate
rooms
server
get_room_predecessor
NotFoundError
loop
room_id
historical_room_ids
get_room_predecessor
NotFoundError
certain
continue
Did
git
blame
show
anything
line
comment
unfinished
confusing
surprising
documentation
rate
limiter
init
ratelimit
can_do_action
optional
rate_hz
burst_count
parameters
init
sure
benefit
separate
variable
messages_per_second
/
burst_count
UI
auth
things
sure
nicer
context
manager
style
python
self.assertRaises
LimiteExceedError
e
limiter.rateLimit
Use
e
self.assertEquals
i
\
filename\
clear
\
filename
*
\
suggestion
various
state
events
state
arg
basic
checks
comment
same
thing
condition
non_joins
dups
newly_joined_rooms
*
happens
user
https
//github.com/IdentityPython/pysaml2/blob/59d6fa5df06989525d2d7e5b8762bbfa3485ab42/src/saml2/metadata.py
L268-L276
logo
list
dicts
flexible
reason
example
fine
comparison
functions
more
verbose
suggestion
rooms
users
user
sends
reports
room
event
suggestion
attributes
present
event
report
codebase
only
[
making
]
https
//github.com/matrix-org/synapse/blob/207b1737ee0acd226359d59ce3b7f7d46111b1c8/synapse/res/templates/notice_expiry.html
L33
p
validation
_provider_needs_discovery
load_metadata
bit
status
code
important
thing
error
key
response
true
response
form-encoded
data
arguments
necessary
post_urlencoded_get_json
necessary
need
additional
thought
minutes
arbitrary
standard
value
cookie
error
situation
certain
metadata
cached
version
nice
quick
comment
suggestion
user-configurable
suggestion
hiredis
optional
dependency
mxids
maxlen
chars
max
line
length
Half
comment
PY2
PY3
urllib
%
-encoded
%
-escaped
something
suggestion
Python
%
utf8
bytes
unicode
comment
documents
type
useful
map
unicode
bytes
Edit
below
clearer
terms
unencoded
overloaded
unclear
black
comment
useful
standard
python
logger
reason
suggestion
Be
sure
max
*
*
checking
outstanding
deltas
chance
updates
deltas
=
yield
self.store.get_room_max_stream_ordering
careful
schema
read
receipts
Ah
same
threepids
Deduping
good
idea
sense
hindsight
tbh
good
comment
generator
evaluated
sure
deliberate
first
context
devices
updates
comment
useful
callback
undefined
flow
return
easier
async
sync
cases
same
way
names
result
synchronous
render
non-blocking
thought
hasattr
getattr
https
//docs.python.org/3/library/functions.html
hasattr
nice
double-lookup
suggestion
isinstance
resp
comment
own
ID
unsure
_unfinished_ids
larger
first
suggestion
Assert
fetched
ID
greater
ID
third
time
please
comment
sir
condition
necessary
helpful
comment
please
comment
someone
caught
exception
valid
comment
_AsyncResource._get_handler_for_request
longer
Can
proper
pls
suggestion
jaeger
contexts
internal
slight
behavior
change
Authorization
header
empty
list
same
behavior
Twisted
values
https
//github.com/twisted/twisted/blob/twisted-20.3.0/src/twisted/web/http.py
L1152-L1154
code
User-Agent
header
incoming
request
sure
suggestion
Configuration
emails
Synapse
nice
much
documentation
everything
suggestion
File
'template_dir
HTML
user
comment
right
thing
helpful
suggestion
results
necessary
suggestion
results
necessary
something
new
comment
MSC
link
fixed
docstrings
suggestion
fields
absolutes
e.g
total
number
rooms
server
hs.config.worker.worker_app
None
master
comment
/
suggestion
export
ConfigError
find_config_files
read_config_files
somebody
comment
bit
pointless
tbh
suggestion
public
Matrix
network
configure
suggestion
query
room
members
May
more
clear
suggestion
Regression
test
state
event
key
matches
suggestion
get_joined_users_from_context
returns
correct
users
next
event
comment
[
]
https
//github.com/matrix-org/synapse/pull/4011/files
diff-6ee0c965f89a99e084e8500580e3ec17R908
useful
thing
suggestion
list
server
names
note
more
servers
batch
size
get_catch_up_outstanding_destinations
suggestion
raise
ConfigError
Tracer
user_whitelist
config
etc
everything
general
preferable
isinstance
list
subclasses
suggestion
position
points
row
correct
instance
name
suggestion
cert_days_remaining
None
suggestion
cert_days_remaining
None
redundant
good
reason
suggestion
settings
sso
configuration
configuration
section
little
confused
saml2_config
upside_down_face
id_access_token
None
case
IS
id_access_token
IS
comment
unclear
lists
presumably
notifications
unread
counts
comment
bit
place
row
version
reqs
while
suggestion
raise
comment
generated
config
big
comment
block
top
structure
commented-out
example
bit
https
//github.com/matrix-org/synapse/blob/b6ebef323e657c5413ac28d2dfb025b911e53cf1/docs/sample_config.yaml
L522
exceptions
federation
request
query_user_devices
everything
method
>
Fetch
cross-signing
public
key
storage
conflict
type
declaration
docstring
thing
worker
method
workers
suggestion
desired
key
type
ID/VerifyKey
cache
situation
changes
future
afraid
spaghetti
key_id
verify_key
key
=
yield
self.store.get_e2e_cross_signing_key
user_id
key_type
from_user_id
key
copy
key
database
XXX
try/except
key_id
verify_key
=
get_verify_key_from_cross_signing_key
key
return
key
key_id
verify_key
words
edge
case
user
key_type
[
master
]
key
self._retrieve_cross_signing_keys_for_remote_user
key_type
key
None
logger.debug
%
key
%
s
XXX
NotFoundError
%
key
%
s
%
key_type
user_id
return
key
key_id
verify_key
inlineCallbacks
functions
function
Generator
useful
information
Best
bet
Returns
comment
Returns
Deferred
[
Tuple
[
..
]
]
Windows
BSD-variants
ie
systems
RFC3493
comment
lines
updates
user
initial
sync
device
list
suggestion
unused_fallback_keys
=
[
]
type
List
[
suggestion
sid
whole
function
state
*
*
point
*
*
local
users
room
B
C.
First
A
entries
A
A
A
B
A
C
B
A
C
A
B
entries
B
B
B
A
B
C
A
B
C
B
C.
entries
C
C
C
A
C
B
A
C
B
C
most
entries
happy
problem
reasonable
time
least
comment
suggestion
entry
instance
name
suggestion
Exclude
app
service
users
sure
'native
user
trouble
config
yaml
bugs
past
config
config
dict
test
homeserver
proposal_review_discussion
concept_review_discussion
foul
is_final_stage
check
test
messages
exception
line
redundant
code
certain
cases
same
Vector
API
different
parameter
various
cases
eg
FD
non-FD
difference
vxlapi.xlOpenPort
self.port_handle
self._app_name
self.mask
permission_mask
<
vxlapi.XL_BUS_TYPE_CAN
<
vxlapi.xlOpenPort
self.port_handle
self._app_name
self.mask
permission_mask
vxlapi.XL_INTERFACE_VERSION
<
vxlapi.XL_BUS_TYPE_CAN
<
sense
arguments
situations
function
comment
IMHO
hardware
timestamp
messages
parameter
public
api
expected
types
other
blf
tools
comment
best
intentions
logger
Ehh
brief
comment
NB
important
relative
paths
..
comprehensive
verifies
behavior
correct
alternative
idea
Pex
distinct
wheels
Python
version
e.g
cp35m
cp36m
wheels
Pex
Py35
Py36
Py36
robust
same
thing
use-first-matching-interpreters
Py35
Py36
time
change
ability
pexrc
runtime
author
same
directory
pex
sense
least
directory-level
configurations
runtime
breakage
os.path.dirname
sys.argv
]
location
running
pex
different
os.getcwd
runtime
root
pex
project
tests
quirk
pytest
sense
users
.pexrc
pex
annoyling/problematic
absolute/long
relative
paths
pex
directory
pex
expectation
.pexrc
getcwd
runtime
config
reading
issue
+
TODO
scope
changes
specific
case
.pexrc
Thoughts
.pexrc
relative
output
pex
name
PPP
configuration
build
time
..
comment
tests
Did
TODO
issue
line
docstring
second
failed
string
cases
wild
important
IIUC
pep
refers
interpreter
names
Note
reordering
necessary
alternative
impossible
ignores
Might
comment
arbitrary
choice
long-running
job
something
suggestion
std
lib
Python
Python
better
way
structure
code
brief
comment
elif
error
None
i.e
exception
prior
exceptions
non-local
magic
link
code
bit
python
i.e
exception
prior
exceptions
blank
line
possible
comment
Handle
end
queue
things
Lines
logical
block
queue
whereas
line
queue
rename
redundant
only
use
Event
objects
inter-thread
signals
comment
suggestions
comments
'/
Nit
start
comment
prior
line
period
end
sentence
Thanks
opportunity
code
readable
concatenation—
.format
codebase
prefix_suffix
=
/
.format
relpath
relpath
pat
=
re.compile
self.prefix
+
prefix_suffix
pattern
free
better
approach
link
bit
https
//pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT
Comment
comma
suggestion
Python
None
error
vars
+
pex_info.pex_path
new
temporary
list
more
sense
self._vars.PEX_PATH
source
env
var
vs
self._pex_info_overrides.pex_path
prior
last
change
e.g
N.B
PEX_PATH
entries
PEX-INFO
precedence
environment
combined_pex_path
=
self._merge_split
pex_info.pex_path
self._vars.PEX_PATH
combined_pex_path
pex_path
combined_pex_path
red
CI
filename
stripped
block
sys.version_info
]
[
]
==
parent_interp
child_interp
parent
child
same
clause
opportunity
[
:6
]
line
other
words
time.struct_time
zip_info_from_file
date_time
parameter
None
constant
date_time
lie
PermPreservingZipFile.zip_info_from_file
time.struct_time
ZipInfo
6-tuple
year-month-day-hour-minute-second
s/respecing/respecting/
Re
reasoning
more
existence
variable
_reduction_
reproducibility
pex
platforms
variable
multiple
distributions
env
var
different
values
idiomatic
mypy
docs
var
=
val
type
X
variables
MyPy
happy
cast
Trace
parent
cast
List
[
Trace
]
parent.children
type
'children
[
has-type
]
suggestion
version
pip
updates
OrderedSet
optimization
necessary
duplicate
requests
brief
N.B
comment
important
comment
important
information
current
interpreter
*
others
AFAICT
only
actual
logic
change
other
changes
paths
normalized_paths
hard
possessive
contraction
ok
Force
subsequent
imports
.pex
directory
.pex
file.
question
update_module_paths
function
second
fine
Note
Python
mu
thanks
flexible
Unicode
string
storage
https
//www.python.org/dev/peps/pep-0393
okay
idea
possible
ABI
tags
_get_supported
ABI
tags
case
obvious
comment
fact
cp37
supports
0-6
link
PEP
suggestion
semver
PEP
https
//www.python.org/dev/peps/pep-0425/
id1
statement
acceptable
Pylint
using-constant-test
error
few
different
ways
logging
message
comments
bit
code
apiai
okay
comment
file
backwards
compatibility
Did
class
Same
thing
docstrings
purpose
final
merge
docstrings
function/method
order
lint
happy
lot
places
docstring
standing
docstrings
opsdroid
please
other
connectors
idea
suggestion
_LOGGER.debug
f
key
database
self.room_id
above
comments
data
tests
event
separate
helpers
suggestion
event
=
await
self.connection.decrypt_event
event
process
doc
strings
google
style
doc
strings
reference
new
code
core
style
docstrings
google
Does
work
GC
cycle
least
old
valid
old
comment
problem
logging
exception
_lot_
errors
most
spurious
easier
directory
example
next
comment
full
run
default
PYTHONPATH
system
comment
existence
proper
sentences
comments
capitals
punctuation
continuation
earlier
phrase
course
easier
trick
head
comment
reader
few
months
context
extra
hint
kind
comment
test
Python
docstring
method
different
kind
comment
next
line
course
global
conventions
project
everyone
charm
author
non-symlink
files
attempt
upgrades
reactive
charm
framework
complexity
problem
s/Event
entry/Path/
Event
entry
something
people
code
WIP
code
issubclass
bound_event.event_type
op.charm.HookEvent
event_dir
=
charm_dir
/
elif
issubclass
bound_event.event_type
op.charm.FunctionEvent
event_dir
=
Path
charm_dir
/
'functions
event_dir.exists
event_dir
=
Path
charm_dir
/
'actions
other
words
time
symlinks
meta
FunctionEvents
define_event
CharmBase
as-is
reason
s/to
pointing/pointing/
Note
worked
fine
issue
s/unable
to/
directory
symlink
good
reason
directory
place
Telegram
preference
hard-coded
CHARM_CODE_FILE
value
favor
os.readlink
sys.argv
]
charm
author
first
link
correct
reuses
target
other
symlinks
s/entry/path/
s/unable
to/
feels
sort
module
*
production
code
pattern
correct
dispatch
script
*
*
'install
hook
DEBUG
level
executable
exists
dispatch
symlink
target
symlink
script
target
script
reactive
creates
scripts
symlinks
Please
import
ast
top
encapsulate
code
function
test
case
test_infra.py
way
call
setup.py
version
sure
Pythons
Travis
error
people
other
units
local
unit
specific
case
RuntimeError
something
LocalUnitError
other
similar
case
same
error
comment
same
thing
error
text
value
peer
relations
remote
local
app
same
Params
Parameters
data
structure
[
JSON
Schema
specification
]
https
//json-schema.org/specification.html
[
docs
]
https
//discourse.jujucharms.com/t/actions-for-the-charm-author/1113
heading
options-and-format-actionsyaml
something
descriptive
python
self.parameters
raw.get
Mapping
names
JSON
Schema
definitions
something
weird
bugs
_function
raise
RuntimeError
function
event
name
event_name
_function
suffix
kind
mixing
data
user
file
data
lazy
code
data
functions.yaml
actions.yaml
exists
user
key
functions
metadata.yaml
earlier
PR
raw
data
things
convenience
SQLite
documentation
EXCLUSIVE
pragma
completeness
case
[
]
thanks
notices
case
explicit
readable
lot
one-line
repetition
logic
inside
Harness.__init__
logic
private
methods
harness
data
methods
harness
data
actual
piece
Justification
text
TODO
awful
behavior
suggestion
type
charm_cls
CharmBase
return
harness
charm
attributes
usual
private
attributes
class
docstring
Disable
events
charm
reference
background
charm
idea
charm
harness.charm
sprint
conversations
create_harness
class
parameter
design
constructor
Harness
testing.TestingHarness
create_harness
people
stuff
bit
fragile
..
blocker
external
behavior
one
details
people
self.model.unit
self.model.app
check
self.attr_name
None
self.attr_name
equal
condition
loop
self.attr_name
None
self.attr_name
parent.__dict__
True
method
returns
test_same_stored_state_multiple_attributes
class
Base
Object
state
=
StoredState
=
state
framework
=
self.create_framework
z
=
Base
framework
None
z.state.foo
z.stored.foo
self.assertNotEqual
z.state.foo
framework.commit
much
TODO
jam
2020-01-30
clean
way
dirty
False
use
case
better
ast.literal_eval
safer
losing
functionality
sure
question
python
package
something
something
findable
python
path
test
question
directory
__init__.py
something
things
most
use
otherthing.tools
something/opslib/otherthing/tools.py
sense
sure
path
something
logic
something
self.framework._track
_track
framework
obvious
way
obj
self
return
sense
next
above
something
Framework
root
tree
framework._objects
comment
top
function
unusual
construct
line
everything
comment
clean
hint
documentation
details
relevant
place
RelationData
such
things
constructor
worth
unusual
construct
FWIW
>
>
def
f
b=1
*
c
pass
>
>
>
f
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
TypeError
f
argument
c'
Note
comments
please
note
second
phrase
true
clearer
=
version.split
'-
variables
Extra
points
better
names
partN
p
version
everytime
other
value
generated
file\n\nversion
=
r
.format
version
Good
point
api
methods
teams
part
https
//openedx.atlassian.net/browse/EDUCATOR-4983
point
workflow_mixin_get_submission_uuid
TODO
TODO
aware
way
API
method
first
glance
files_name
*
*
*
*
vs
files_name
sense
TeamAssessmentWorfklowInternalError
vanilla
assessment
team
specific
issues
docstring
comments
test
nit
period
end
comment
tiny
nit
repeat
closing
paren
own
line
nit
is_supported_upload_type
lines
while
trickier
way
over-engineered
and/or
inflexible
particular
nice
thing
Structs
problem
subclass
views
own
data
utility
functions
data
class
obvious
solution
Env
class
View
subclasses
way
separate
branch
comparison
[
]
https
//github.com/nworden/personfinder/compare/djangoapp
nworden
djangoapp-envclass
work
way
lot
flexibility
example
subclass
env
variable
own
parameters
base
class
lang
parameter
params
better
idea
class
Nit
line
Main
entry
point
request-response
process
lot
details
test
value
utility
function
create_person
other
tests
Optional
anything
empty
string
constant
string
'dummy
terminology
admin
page
unlaunched
unlaunched
Add
TODO
comment
field
Delete
sentence
comment
per-repository
'deactivated
settings
Can
Again
admin
page
good
documentation
self.assertNone
Nit
comment
redundant
name
constant
case
nesting
levels
block
early
return
filter
block
>
AFAIK
Cloud
Storage
anything
right
Right
>
good
comment
line
default
bucket
bucket
lifetime
things
separate
buckets
problem
Done
way
lifetime
specific
objects
[
object
]
https
//cloud.google.com/storage/docs/bucket-lock
object-holds
>
Done
>
low-bandwidth
situations
slow
download
cases
big
files
minutes
https
//cloud.google.com/storage/docs/access-control/signed-urls
server
requests
timestamp
expiration
request
OK
download
enum_op
list
synonyms
please
distinction
different
default
other
few
comments
intention
assumptions
future
minors
comment
future
readers
nitpick
grammar
api
call
self.manager.retry
api
invoke
pass
ignore_err_codes=
'NotFoundException
try/except
block
bit
provider
registry
everything
sys.modules
duplication
python
k
el
itertools.chain
logic
separate
class
batch
multiple
resources
parameter
number
resources
parameter
webhook
pull
request
number
date
day
backwards
compatibility
statement
somehow
own
method
different
lists/
range/
len
checks
separate
method
descriptive
name
small
typo
s/reasion/reason
nit
lint
issue
comment
space
meant
future
implementation
baseclass
similar
filter
query.get
threshold
part
significance
len
ids
augment
bucket
account
dozen
api
diff
latest
revision
previous
source
config
previous
other
examples
augment
table
augments
interest
ie
bucket
replication
bucket
replication
client
fetch
attribute
resource
interesting
mitigates
least
extra
copies
augment
table
client
side
list
source
config
minimal
albeit
pre-condition
bucket
replication
present
hasattr
please
interface
resource
manager
validate
doc
string
mode
filters
actions
generic
exception
config=None
ditto
name/attr
check
use
self.manager.get_arns
resources
typo
s/used/use/
nit
cleanup
scenarios
separate
tests
comment
nit
logic-app-name
edge
cases
clean
resources
stack
trace
value
valid
field
failure
return
line
early
exit
method
useful
indirection
publish
message
Good
catch
rid
self.current_date
function-scoped
current_date
minor
comment
little
clearer
style
nit
s/type
[
]
/list
resource
tags
list
Key/Value
useful
custodian
annotations
key
c7n
specific
metrics
resource
case
tag
aliasing
value
filter
list
form
resources
minor
deepcopy
costly
large
message
shallow
copy
resources
deepcopy
remainder
messaging
corresponding
improvements
base_log
=
dict
msg
base_log.pop
'resources
base_log
=
deepcopy
base_log
style
nit
s/type
previous
comment
default
beginning
method
error
handler
implementation
little
odd
type
check
key
indirect
equality
equality
style
alternate
data
=
dict
self.data
data.pop
'type
data
data
=
k
config
[
k
]
k
data
return
False
data
configuration
setting
False
return
bool
[
True
k
v
config.items
v
False
]
comments
strange
columns
doc
strings
column
width
checks
not-null
Please
support
'.yaml'
https
//yaml.org/faq.html
validate
piece
update_policies
policy
unclear
validation
useful
post-finding
aws
resource
hmm
sleep
waiter
https
//boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html
waiters
table
taggable
only
default
permissions
many
cases
actual
permissions
dependent
configuration
..
starter
Same
longitude/latitude/elevation
mandatory
sc3ml
schema
..
warning
message
e.g
depth
None
msg
Channel
depth
information
warnings.warn
msg
depth
anything
NumPy/SciPy
lines
measurement_name
case
needs
issue
PR
only
reason
config_kwargs
empty
modifier_settings
check
positioning
comment
unnecessary
suggestion
f
keyword
argument
s
.join
config_kwargs.keys
suggestion
measurement_name
Workspace
:model
bug
track
suggestion
de-dupe
last-appended
result
index
self.fixed_vals
list
dict
fixed_vals
few
lines
public
API
pyhf.writexml.build_measurement
docstring
postprocess
function
smarter
way
bit
worried
moment
imply
ws
ws
side
effect
behavior
something
functional
suggestion
names
indices
_
=
list
starts
suggestion
order
parameters
FIXME
care
suggestion
default
_nominal_and_modifiers_from_spec
line
tests
]
https
//coveralls.io/builds/21033596/source
filename=praw
%
%
%
%
L134
unit
test
[
]
https
//github.com/praw-dev/praw/blob/394ac595b2ea099bd31bb514233bdf30693cdb1f/tests/unit/models/list/test_base.py
L25-L27
trick
F401
Please
comments
helpful
generator
need
bool
conditional
success
=
False
block
suggestion
code
lie
remark
>
Ensure
current
scheduler
thread
background
thread
sure
background
thread
chance
>
thread_suspend
right
compromise
comment
suggestion
opposite
problem
coroutine
ends
t
RHEL6
bug
compilers
C++11
support
suggestion
Make
PRI
*
macros
available
compilers
C++11
support
e.g
RHEL6
line
suggestion
@
cocotb.test
skip=cocotb.SIM_NAME.lower
.startswith
riviera
expect_error=cocotb.SIM_NAME.lower
.startswith
modelsim
fatal
hard
Questa
suggestion
TODO
[
gh-1829
]
investigate
os.add_dll_directory
work
Python
assert_raises
TestFactory
functionality
Just
decorate
run_tests
cocotb.test
test
tb_rescap.i_rescap.vout
tb_rescap.i_rescap.i_capacitor.p
https
//docs.python-guide.org/writing/gotchas/
mutable-default-arguments
user
cocotb
current
setup
suggestion
cocotb_package_dir
=
os.path.dirname
__file__
=
coverage.coverage
branch=True
[
.format
cocotb_package_dir
]
suggestion
TODO
cocotb
code
coverage
collection
specific
installed
user
packages
suggestion
self._cov
=
coverage.coverage
branch=True
[
*
site-packages/cocotb/
*
]
/
windows
bug
execution
useful
bug
fact
exception
suggestion
suggestion
handle
envvar
TOPLEVEL
entity
None
mod
cocotb
simulator
@
cmarqu
right
docs
newsfragment
suggestion
handle
envvar
TOPLEVEL
entity
None
mod
cocotb
simulator
https
//github.com/cocotb/cocotb/pull/1286
discussion_r364016538
changes
file
lines
helper
function
assign_matrix
dut.B
value
clearer
overall
tests
sets
simulator
support
behavior
helper
functions
readable
IMO
following
comments
full
suggestion
suggestion
dut.a_i
<
=
gen_a
lambda
x
dut.b_i
<
=
gen_b
lambda
x
unused
variable
nit
python
>
Python
pre-construct
triggers
performance
worth
obvious
prefix
suggestion
cocotb_build_libs
import
get_ext
suggestion
setup_build_libs
import
get_ext
suggestion
Note
cocotb
dependencies
binaries
other
files
MANIFEST.in
suggestion
strings
icarus
@
cocotb.test
skip=cocotb.SIM_NAME.lower
.startswith
icarus
suggestion
warnings.warn
str
future
t
._path
string
representation
value
str
t
.value
FutureWarning
stacklevel=2
isinstance
self.value
bytes
default
ASCII
StringObject
return
self.value.decode
'ascii
return
str
self.value
previous
suggestion
suggestion
default
ASCII
representation
values
self.value.decode
'ascii
suggestion
SPDX-License-Identifier
BSD-3-Clause
comment
someone
same
simplification
suggestion
A
dictionary
write_func
args
handle
final
write
timestep
propagates
simulator
rest
python
members
private
cache
suggestion
Python
class
invalid
queries
purposes
suggestion
package_data=
[
files
package_files
'cocotb/share/makefiles
package_files
'cocotb/share/include
package_files
'cocotb/share/def
file
files
comment
suggestion
single
file
build-time
need
newsfragments/
*
.rst
suggestion
Prevent
cocotb-test
suggestion
Prevent
PytestCollectionWarning
TestFactory
Test
*
Ir
important
versionchanged
mention
python
suggestion
..
lock
asynchronous
context
manager
keyword
statement
Python
newer
async
lock
stuff
lines
narrow
suggestion
..
lock
asynchronous
context
manager
keyword
statement
Python
onwards
async
lock
stuff
suggestion
..
lock
asynchronous
context
manager
keyword
async
statement
async
lock
stuff
suggestion
extra
bits
bits
suggestion
extra
bits
bits
Examples
>
>
>
yield
Timer
units='ps
time
float
>
>
>
yield
Timer
100e-9
units='sec
convenient
frequencies
>
>
>
=
MHz
>
>
>
yield
Timer
/
freq
units='sec
Other
builtin
exact
numeric
types
>
>
fractions
Fraction
>
>
>
yield
Timer
Fraction
units='ns
>
>
decimal
import
Decimal
>
>
>
yield
Timer
Decimal
'100e-9
units='sec
useful
durations
point
inaccuracies
suggestion
return
first_trigger
first
multiple
triggers
suggestion
user
await
yield
accident
cocotb.triggers.Timer
suggestion
@
cocotb.test
def
test_yielding_accidental_async_generator
dut
test
async
def
behavior
yield
check=True
exception
sort.check_returncode
subprocess.run
try/except
block
Could
stackoverflow
link
Shaurya
share
button
short
link
post
suggestion
logger.error
view.stderr
See
https
//stackoverflow.com/q/34147353/13118765
Popen
process
run
try
sort
=
cmd_sort
stdin=view.stdout
stdout=subprocess.DEVNULL
stderr=subprocess.PIPE
check=True
subprocess.CalledProcessError
logger.error
sort.stderr
shutil.move
sort_fpath
bam
suggestion
logger.error
view.stderr
See
https
//stackoverflow.com/q/34147353/13118765
Popen
process
run
sort
=
subprocess.run
cmd_sort
stdin=view.stdout
stdout=subprocess.DEVNULL
stderr=subprocess.PIPE
sort.returncode
logger.error
sort.stderr
return
None
shutil.move
sort_fpath
bam
length
url
lookup
suggestion
See
https
//stackoverflow.com/q/13332268/13118765
img
width=
alt=
Screen
Shot
2020-07-17
AM
src=
https
//user-images.githubusercontent.com/25933122/87782748-b7f00a00-c7f8-11ea-833a-0504606daf49.png
>
See
comments
is_valid_taxid
Similar
parameters
section
suggestion
Parent
taxid
nodes.dmp
comment
new
review
self.lineage
ancestor
time
taxids
suggestion
lineage_a_taxids
ancestor.get
ancestor
self.lineage
taxid_A
=
ancestor
self.lineage
taxid_B
common_ancestor
=
lineage_b_taxids.intersection
lineage_a_taxids
is_valid_taxid
method
anything
merged.dmp
other
comments
behavior
method
docstring
other
comments
trouble
merged.dmp
comment
true
cast
int
float
True
evaluates
False
evaluates
suggestion
boolean
check
cast
ints
taxid
str
int
Jason
casting
provided
taxid
int
functionality
checks
other
methods
input
taxids
str
vote
behavior
self.is_valid_taxid
comment
return
value
function
Basically
command
original
self.merged
problem
client
functions
valid
taxid
suggestion
new_taxid
=
self.merged.get
taxid
readable
function
taxid
type
integer
docstring
checks
checks
first
sentence
first
concise
use
function
details
wrong
.tar
file
function
comment
worth
parent
.tar.gz
file
disk
use
is_previous_revision
comparison
+1
is_previous_revision
more
generic
name
docstring
pk
previous
version
pass
late
Please
comment
previous_advisory
object
variable
refers
different
object
merge_advisories
previous_advisory_pk
=
previous_advisory.pk
merged_advisory
=
merge_advisories
previous_advisory
added_advisory
pulp_file
PR
Docstrings
e681427b4ff1b53eabeb2e7737cbcb2f2b095339
Mind
todo
comment
def
update
domain_name
*
*
kwargs
CRUD
reason
change
Does
someone
workaround
cases
subscription
fail
bug
blocker
confirmation
changes
insane
request
case
interested
indexes
PR
foreman
empty
header
Actions
https
//github.com/theforeman/foreman_discovery/blob/develop/app/views/discovery_rules/index.html.erb
decision
chance
someone
merges
comment
explanation
indentation
weird
same
level
return
black
fine
only
method
rest
update
update
way
ofter
extra
refresh
read
bit
refresh
package
rule
package
filter
errata/package
group
filters
page
returns
empty
values
table
new
row
comment
_get_saucelab_browser
sense
context
remote
browser
suggestion
Make
sure
F17
comments_since_karma_reset
list
PEP8
seq
seq
seq
sum
list
store
variable
example
variable
statement
default
builds
field
non-nullable
value
NULL
ambiguous
code
right
stable
comment
stable
context
something
decision
updates
updates
recent
updates
likely
first
chances
tests
Greenwave
end
list
chances
tests
%
sure
update.request
None
suggestion
update.release.composed_by_bodhi
handy
boolean
flag
release
object
]
https
//github.com/fedora-infra/bodhi/issues/2317
graphiql_enabled
value
configure
configuration
development
environment
False
production
comment
open
pull
request
@
jeremycline
Bodhi
fedora
pull
requests
https
//github.com/fedora-infra/bodhi/pull/2754
Let
docblock
utility
function
docblock
utility
function
line
Return
RPM
version
Returns
str
version
RPM.
return
type
Return
RPM
name
Returns
str
name
RPM.
RPMBuild
Build
superclass
Let
return
type
something
Return
N
V
R
components
dash-separated
build
Returns
tuple
3-tuple
name
version
release.
Return
release
RPM
Returns
str
release
RPM.
self._kojiinfo
[
]
self._kojiinfo
[
'version
]
self._kojiinfo
[
'release
]
comment
ModuleBuild
real
file
disk
builtin
open
function
example
empty
file
https
//github.com/fedora-infra/bodhi/blob/2.7.0/bodhi/tests/client/test_bindings.py
L98-L118
other
tests
class
substitute
other
data
file
nice
way
file
test
little
better
successful
completion
comment
true
more
code
undocumented
internal
APIs
feed
generator
problematic
API
getters
'comments
]
[
'title
]
best
comment
template
comment
text
consistency
Rather
special
code
comment
title
custom
getter
property
class
change
getters
'comments
]
[
'title
]
new
property
comment
style
[
k
]
False
value
former_update
kwargs
k
]
[
k
]
Flase
test
able
Munch
object
dictionary
sure
mock
code
correct
namespace
containers
test
Package
obect
type
attribute
mock
object
name
attribute
container
commit
first
commit
pull
request
separate
pull
request
separate
concerns
easier
comments
easier
changes
recommendation
[
PEP-8
]
https
//www.python.org/dev/peps/pep-0008/
other-recommendations
spaces
operator
space
empty
string
first
item
fixedin
bug
something
[
'fixedin
]
=
'.join
[
fixedin_str
version
]
hard
everything
smile
comment
good
idea
logic
suggestion
Ensure
nothing
user
human
readable
suggestion
Ensure
json
user
data
human
readable
suggestion
Ensure
info
user
human
readable
blob
digest
size
source
destination
digest
str
digest
blob
size
int
size
blob
Copy
manifest
info
source
destination
info
ManifestInfo
References
manifest
toplevel
bool
True
main
manifest
repository
Defaults
False
RuntimeError
referenced
media
type
client.
new
code
type
annotations
docblocks
types
things
above
def
rabbitmq_container
docker_backend
conu.DockerBackend
docker_network
str
>
conu.DockerContainer
Fixture
preparing
RabbitMQ
container
docker_backend
Docker
backend
fixture
docker_network
Docker
network
ID
fixture
Yields
RabbitMQ
container
[
asyncio.wait
]
https
//docs.python.org/3.6/library/asyncio-task.html
asyncio.wait
timeout
length
sleep
way
messages
sleep
statement
Bodhi
unit
good
bit
big
boost
d26d42a4468f07839ee649f4808c1ed45af7e382
☺
comment
wink
update
builds
release
Bodhi
i.e
Rawhide
Testing
comment
jeremycline
copypaste
crime
patch
diff
git
a/bodhi/tests/server/consumers/test_updates.py
b/bodhi/tests/server/consumers/test_updates.py
index
..
abacc7a
a/bodhi/tests/server/consumers/test_updates.py
+++
b/bodhi/tests/server/consumers/test_updates.py
@
@
-125,7
+125,6
@
@
class
TestUpdatesHandlerConsume
base.BaseTestCase
'topic_prefix
h
=
updates.UpdatesHandler
hub
h.db_factory
=
base.TransactionalSessionMaker
self.Session
bogus
bug
id
AssertionError
message
=
'body
u'bodhi-2.0-1.fc17
@
@
-148,7
+147,6
@
@
class
TestUpdatesHandlerConsume
base.BaseTestCase
'topic_prefix
h
=
updates.UpdatesHandler
hub
h.db_factory
=
base.TransactionalSessionMaker
self.Session
bogus
bug
id
AssertionError
message
=
'body
u'bodhi-2.0-1.fc17
@
@
-168,7
+166,6
@
@
class
TestUpdatesHandlerConsume
base.BaseTestCase
'topic_prefix
h
=
updates.UpdatesHandler
hub
h.db_factory
=
base.TransactionalSessionMaker
self.Session
bogus
bug
id
AssertionError
message
=
'body
u'bodhi-2.0-1.fc17
comment
bug
id
line
channel
assert
conditional
inputs
ValueError
condition
log
message
value
introspection
GPU
FP16
comment
previous
to_affine_nd
sr
target_affine
May
mode
selection
logic
mode
parameter
Thanks
error
fatal
issue
unsigned
alpha
masks
PNG
format
useful
MR
images
format
data
caller
data
array
compatible
format
PIL
incompatible
requirement
data
function
documentation
commented
line
RandCropByPosNegLabeld
label_key
one-hot
labels
foreground
background
channels
copyitem
workaround
comments/suggestions
Nic-Ma
members
metadata
dictionary
present
non-nifti
files
size
spatial
ranks
WHD
order
spatial_shape
=
list
image
spatial_shape.reverse
spatial_shape
self.img
=
img
ITKReader.read
data
data
string-like
filename
self.img
=
self.read_by_file_name
data
data
directory
name
self.img
=
self.read_by_dir_name
data
data
itk
img
object
self.img
=
current
constructor
specific
case
ITKReader.read
Consider
img_meta_dict
=
self.img.GetMetaDataDictionary
key
img_meta_dict.GetKeys
Ignore
legacy
members
issues
key.startswith
'ITK_original_
key
]
=
img_meta_dict
[
key
]
meta_dict
[
]
=
np.asarray
img.GetOrigin
meta_dict
]
=
np.asarray
meta_dict
[
'direction
]
=
itk.array_from_matrix
self.img.GetDirection
issues
problematic
legacy
metadata
origin
direction
sigmoidfocal
softmaxfocal
pytorch
repo
https
//github.com/pytorch/pytorch/blob/821b5f138a987807032a2fd908fe10a5be5439d9/modules/detectron/sigmoid_focal_loss_op.cu
L26
https
//github.com/pytorch/pytorch/blob/821b5f138a987807032a2fd908fe10a5be5439d9/modules/detectron/softmax_focal_loss_op.cu
L59
options
ref
https
//github.com/clcarwin/focal_loss_pytorch/issues/7
Pytorch
None
index
value
lines
77-8
=
[
None
None
]
dimension
line
becomes
=
[
]
style
choice
code
bit
readability
Variable
API
[
]
https
//pytorch.org/docs/stable/autograd.html
variable-deprecated
fine
Variable
original_affine
loader
clear
line
commented
code
line
commented
code
line
https
//github.com/horovod/horovod/blob/34baedf1257bbdc5de15e54723d6d7bc21409a87/examples/pytorch_mnist.py
L126-L130
Could
small
roi
test
gaussian
mode
Thanks
arbitrary
suggestion
occlu_im
[
tuple
slice
i
j
i
j
zip
min_idx
max_idx
=
pad_val
line
isinstance
m
conv3d_type
conv3d_trans_type
same
few
other
isinstance
usages
Fix
comment
inline
comment
clarity
safety
case
validation
statistic==MEAN
comment
Question
third
final
iteration
assemble
MEAN
current
behavior
course
MEAN
default
addition
code
brief
comment
surprised
max
dimList
works
familiar
pybind
something
great
commit
message
descriptive
inline
brief
possible
basic
reasoning
much
sufficient
explanation
maximum
dimensions
commit
message
inline
message
help
modelPsf
BBox
ModelPsfMatchTask
square
largest
Warped
Psf
BBox
confusion
subject
first
PSF
CoaddPsf
loop
true
comments
get_data_set_size
SchemaValidatorEvent
comments
event
type=start
beginning
end
check
parameter
comment
authenticator
password
docstring
CQL
please
comment
explanation
commit
message
issue
mix
cache_and_disk
please
change
terms
mix
mix
read
users
read
test
scenario
latency
load
latency
throughput
load
latency
latency
much
DEFINE
SOMEWHERE
test
first
Removed
progress
variable
necessary
cfstats
nodes
Let
print
log
threshold
issues
comments
comment
dead
code
please
docstring
test
todo
goals
copy-paste
trello
task
code
comment
number
docstring
function
write
something
sure
arguments
need
event
need
event
use
log
need
recursive
rm
directory
new
code
above
old
code
col_num
=
check_number_of_columns
col_num
big_sstable
url
=
x
url
=
y
elsif
col_num
>
=5
big_sstable
url
=
z
url
=
w
Schema
snapshot
list
min
Result
str.split
empty
strings
Pretty
sure
int
nodes_num
nodes_num
=
type='failure
start
finish
suggestion
class
ScyllaBenchStressExporter
StressExporter
preamble
sctool.run
attribute
verify_errorless_result
add
comment
change
class
PrometheusAlert
def
__init__
raw_alert
self.updated_at
=
raw_alert
[
updatedAt
]
=
raw_alert
[
generatorURL
]
self._raw_alert
=
raw_alert
+1
manual
kind
test
next
time
part
default
o
use
LWT
requests
read-before-write
decrease
60-90
sec
reminder
itertools.cycle
suggestion
TODO
move
skip
siren-tools
possible
self.log.warning
function
due
job
Siren
cloud
suggestion
No
need
system
tables
scylla-cloud
Alternator
scylla-cloud
CQL
access
cluster
difference
utils
functions
global
utils
functions
same
configuration
i.e
multiple
times
scylla.yaml
confusion
TODO
comment
support
job_name
upload
screenshot
test-id
dir
need
issue
double
parameter
code
original
file
examples
parameter
May
true
false
list
data
centers
per-datacenter
false
false
comment
code
seed
first
strategy
elif
seeds_selector=='first
....
Exception
unexpected
seed
selector
%
s
%
seeds_selector
commented
code
use
full
name
param
standard
sct
methods
connection
allow
fix
connection
issue
test
sense
cassandra
driver
list
nodes
constructor
Cluster
class
example
next
use
self.cql_connection_patient_exclusive
scylla_session
scylla_session.cluster.refresh_schema_metadata
=
scylla_session.cluster.metadata.keyspaces
self.KS_NAME
]
timing
better
separate
method
collect_data_for_analysis
cant
reboots
seconds
>
comment
wrong
example
file
name
cassandra
much
point
code
Too
black
magic
taste
hard
things
way
unnecessary
arguments
following
changes
def
_retry_message
msg
retry_num
def
args
retry_num
*
*
kwargs
return
self._retry_message
msg=
retry_num=retry_num
popping
retry_num
*
*
kwargs
same
assumption
original
code
keyword
argument
btw
root
cause
Python
driver
handlers
on_read_timeout
consistency
required_responses
received_responses
retry_num
isinstance
response
ReadTimeoutErrorMessage
self._metrics
None
self._metrics.on_read_timeout
retry
=
retry_policy.on_read_timeout
self.query
retry_num=self._query_retries
*
*
response.info
elif
isinstance
response
WriteTimeoutErrorMessage
pylint
disable=unused-argument
arguments-differ
comments
entire
section
method
something
configure_manager
params
necessary
params
test
yaml
self.params.get
'configure_manager
default=False
self._configure_manager
method
verbose=True
example
task
status
wait.wait_for
func=self.is_status_in_list
prefix
task
ID
something
comment
output
function
documentation
Wait
task
'final
status
done/error/stopped
check
return
final
status
above
comment
if/else
please
add
comment
errors
suggestion
python3
suggestion
return
False
[
]
BLOCKER
try
case
args
problematic
suggestion
def
qualifies_for_sponsorship
edition
param
edition
edition
infogami
book
edition
rtype
dict
return
dict
book
eligibility
edition
publishers
University
Wisconsin
Press
]
number_of_pages
publish_date
September
cover
https
//covers.openlibrary.org/b/id/2353907-L.jpg
title
Lords
Ring
price
scan_price_cents
book_cost_cents
total_price_display
total_price_cents
is_eligible
true
sponsor_url
https
//archive.org/donate
isbn=9780299204204
type=sponsorship
context=ol
campaign=pilot
subjects
endpoint
start
field
offset
sync
comment
code
sense
suggestion
convert
timestamp
API
[
[
timestamp
*
count
]
[
count
timestamp
]
graphite_data
]
results
iterator
point
api
call
try
block
https
//github.com/yoavaviram/python-amazon-simple-product-api/blob/master/amazon/api.py
L267
suggestion
more
product
first
lint
error
suggestion
type
bytes
str
>
Image
commented
line
Remove
line
gate
basis
unrolled
regular
X
Y
Z
instructions
QasmSnapshotProbabilitiesTests
class
function
suggestion
def
available_threads
Return
threads
simulator
result
=
execute
self.dummy_circuit
shots=1
backend_options=self.BACKEND_OPTS
.result
return
result
]
[
'total
]
basic_device_gate_errors
_device_depolarizing_error
basic_device_gate_error
depolarizing
channel
more
generic
noise
channels
higher
gate
errors
_device_depolarizing_error
generic
function
useful
other
non-basic
noise
models
challenge
phase
exists
comment
passed
challenge
argument
sure
challenge
phase
concerned
challenge
comment
re-phrased
better
words
idea
comment
less
code
more
further
comments
bad
code
self
explanatory
comments
+1
challenge
host
submissions
challenge
participant
particular
challenge
phase
May
reason
comments
comment
code
Comments
particular
piece
code
more
helpful
part
comment
part
point
comment
+1
yeah
comment
check
existence
participant
team
function
comment
own
words
better
way
python
django.utils
timezone
datetime
import
timedelta
datetime
time
timezone.now
date_tomorrow
=
today.date
timedelta
midnight
datetime.combine
time
=
midnight
Finally
user
time_left
code
sure
timezone
module
Timezone
Aware
Please
similar
type
comments
object
creations
mention
comments
same
KhalidRmb
starting
challenge
worker
challenge
docker
email
host
cases
default
value
current
running
challenges
issues
current
challenges
field
None
fields
Store
metadata
default
submission
meta
attributes
challenge
phase.
>
Store
default
metadata
submission
meta
attributes
challenge
phase.
__lt__
means
nice
meaningful
names
phase
challenge
active
challenge.is_public
check
import
lines
comments
good
reason
check
code
piece
code
comment
code
readable
case
code
good
great
reason
WHY
check
django.conf
import
settings
RABBITMQ_PARAMETERS
settings.RABBITMQ_PARAMETERS
comment
customer
>
customized
check
line
PR
database
many
times
second
number
submissions
sense
KhalidRmb
consistent
whole
codebase
Let
log
exception
comment
Please
conditions
host
access
API
=
challenge_phase_split.challenge_phase.challenge
is_user_a_host_of_challenge
request.user
challenge_obj.pk
response_data
=
error
Sorry
request
Response
response_data
status=status.HTTP_400_BAD_REQUEST
Allow
access
>
Allow
access
host
blank
something
slack
notification
>
slack
notification
message
=
text
*
new
submission
*
uploaded
.format
challenge_name
fields
title
Phase
value
phase_name
short
True
title
Participant
Team
Name
value
participant_team_name
short
True
]
slack
notification
host
>
slack
notification
Case
phase
submission
public
Can
docstrings
Typo
finctions
>
functions
challenge
host
code-upload-worker
related
comment
bootstrap
calculation
optional
fits
default
behavior
single
call
covariance
matrix
chi
errors
fit
parameters
name
Sorry
deleting
🙂
as-is
@
RobertLuptonTheGood
ticket
branch
DM-20940
effort
b
rebase
nightmare
invisible
TODO
DM-20940
progress
🙂
other
way
Which
How
past-Merlin
😄
OK
misfire
asserts
getBBox
wrong
bigger
problems
How
different
above
test
Please
docstring
minimal
test
Please
docstring
name
test
obvious
NB
means
code
comment
person
initials
Wait
something
Latin
NOTE
clearer
method
many
things
sorts
tests
clear
different
cases
different
aspects
code
asserts
same
asserts
superfluous
document
test
pixels
pixels
mand
forb
des
new
boardgame
Fantasy
Flight
Please
non-abbreviated
names
new
copyright
form
geom
package
good
soul
opts
keyword
args
function
way
documentation
docs
opts
faster
development
sure
useful
mpl
context
option
samples
function
necessary
Ditto
comment
superfluous
batch
scalars
log
probs
mean
dim
docstring
function
comment
ceremonious
i.e
function
comment
function
decision
space
line
docstring
loss
negative
log
prob
David
negative
log-likelihood
Great
thanks
minor
nitpick
ndim==2
image
comment
pass
Empty
line
need
database
Gym.get_gyms
gym
details
gym
name
app
case
instance
Flask
Add
comment
side
effects
effect
function
return
value
x
y
b
c
code
style
gyms
confirmed_ex_gyms
=
EX-eligible
gyms
confirmed_ex_gyms
b
point
set
EX-eligible
gyms
*
args
unused
*
args
=
get_args
empty
line
comment
Dot
Add
empty
line
comment
Add
empty
line
comment
filter
call
clarity
Retrieve
list
confirmed
EX
gyms
DB
confirmed_ex_gyms
=
nitpick
legendary
raids
eligible
ex
raid
*
Function
name
exgyms
descriptive
*
function
several
separate
steps
big
blob
everything
e.g
Assumes
.get_first_geofence
Geofences
def
update_ex_gyms
geofence
fence
=
Geofence.get_first_geofence
ex_gyms
=
ex_query
south
west
north
east
gyms
=
Gym.get_gyms
south
west
north
east
confirmed_ex_gyms
=
filter
gyms
Assumes
.set_gyms_in_park
Gym
Gym.set_gyms_in_park
confirmed_ex_gyms
True
def
__gym_is_ex_gym
gym
ex_gyms
ex_gyms
=
way
ex_gyms.ways
Copy
code
exgyms
True
return
False
Write
comments
>
//
Capitalized
sentence
punctuation
*
space
dot
*
reason
strange
login
process
time
account
jitter
strange
attempt
account
same
spot
original
map_request
much
account
plenty
time
uncaptcha
next
scan
login
process
above
block
code
Find
country
component
component
address
Look
country
component_is_country
[
t
==
'country
t
component.get
[
]
]
component_is_country
country_code
component
[
]
break
type
variable
name
type
built-in
function
Feel
free
t
fact
code
line
hashing
key
stats
database
values
hashing
server
previous
datetime.utcfromtimestamp
local
time
incorrect
functions
UTC
time
consistency
Status.js
moment
UTC
time
expiration
date
local
time
Dash
indent
following
line
initialisation
Make
sure
API
response
track
information
get_inventory
timestamp
inventory
content
requests
Compare
[
PGoClient
]
https
//github.com/RocketMap/RocketMap/pull/2060/files
diff-196fc76d2004b90f04582f0a09fc1f3cR143
look
[
PGoClient
]
https
//github.com/RocketMap/RocketMap/pull/2060/files
diff-196fc76d2004b90f04582f0a09fc1f3cR142
Monocle
problem
right
regular
users
request
least
Chrales
last
MITM
data
Apple
Watch
iPhone
vague
guess
kind
question
MITM
past
harder/impossible
Consistency
request
sure
no-matplotlib
same
error
anything
case
right
lot
line
f
line
=
line.strip
line
continue
Happy
feedback
multiple
instances
different
geofence
files
last
instance
geofences
geofences
instances
same
DB
file
new
flag
DB
geofences
other
ideas
dots
╯°□°）╯︵
┻━┻
please
descriptive
names
i
j.
pass
store
used
params
memory
usage
clear
ussing
separate
loop
list.pop
O
excluded_areas
coordinate
excluded_areas
returns
True
coordinate
areas
function
*
*
*
*
coordinate
geofenced_coordinates
line
efficient
comment
next
line
rest
sentence
punctuation
proper
length
IDE
atm
sure
negative
session/connection
thing
sure
mysql
doc
states
TEMPORARY
table
visible
current
session
session
different
sessions
same
temporary
table
name
other
non-TEMPORARY
table
same
name
fine
Remember
multiple
instances
RocketMap
same
database
sure
temporary
table
constant
name
random
string
table
name
Dict
more
sense
class
👍
comment
upcoming
PR
game
long
time
comment
date
comment
>
gym
details
position
distance
args.no_pokemon
disables
wild_pokemon
DB
disable
nearby_pokemon
warning
@
friscoMad
thoughts
true
second
enough
pokes
forts
log
bans
args.no_pokemon
log
possible
speed'
way
first
case
real
error
matter
pokes
second
case
warning
pokes
poke
search
other
End
comment
punctuation
people
time
past
Check
Unown
alphabetic
character
fancy
order
output
docstring
MemoryHandler
class
inline
comments
_arg_parse_setup
inline
comment
enough
comment
GH
happy
comment
time
present
dependence
minimum
version
setuptoools
https
//github.com/python/typeshed/tree/master/third_party/2/cryptography
x509
[
]
import
signal
]
signal.getsignal
getsignal
sig
>
action
Return
current
action
signal
return
value
SIG_IGN
signal
SIG_DFL
default
action
signal
effect
None
unknown
handler
effect
anything
callable
Python
object
handler
Type
builtin_function_or_method
issue
need
type
ignore
Same
comment
inline
pylint
disable
Is
issue
need
type
ignore
Same
comment
inline
pylint
comments
comment
error_handler.py
type
callable
nit
suggestion
Cryptography
drops
support
OpenSSL
reason
usual
paranoid
nit
mypy
possible
certbot.compat.os
method
os.replace
exists
fine
people
same
behavior
OSes
os.replace
Python
behavior
RuntimeError
former
standard
os
module
pylint
function
exception
Same
comment
https
//github.com/certbot/certbot/pull/6964
discussion_r283070863
nit
purpose
module
single
pylint
disable=function-redefined
function
definitions
top
level
file
suggestion
strategy
file
handlers
Windows
rename
environment
variable
value
true
environment
variable
point
tox
anything
special
Azure
Same
comment
server
block
default_server
suggestion
default
Nginx
point
whole
method
test
clientv1
good
test
todo
todo
suggestion
KeyAuthorizationResponseChallenge
JSON
default
suggestion
spec
KeyAuthorizationResponseChallenge
JSON
default
other
related
observations
other
assertions
Pytest
assert
superior
standard
unittest
module
kind
assertion
fails
complete
report
instance
content
array
emphase
row
difference
assertions
advantage
behavior
sense
context
import
*
__all__
fact
rational
approach
implicit
explicit
explicit
imports
test_main
Done
code
manual-auth-hook
test
certbot
binary
valid
shell
command
fact
generic
shell
command
Linux
windows
suggestion
Formally
certbot
version
test
context
value
several
places
test_main
exact
format
challtestsrv_mgt_port
part
integration
test
context
theses
strings
needs
integration
test
context
fixture
output
methods
fixture
useless
complexity
value
change
instance
fixture
suggestion
certbot
subprocess
lot
times
certbot
opinion
dependency
certbot
general
requirement
nit
comment
Azure
config
.azure-pipelines
name
name
suggestion
tempfile.mkdtemp
folders
restrictive
permissions
accessible
default
new
file
sites-enabled
sites-available
setup
sites-available/
*
nginx.conf
other
details
obvious
inline
issue
comment
nit
coverage
line
nice
big
deal
feel
free
comment
nit
comment
makedirs
least
referenced
function
comment
link
relevant
mkdir
]
https
//docs.python.org/3/library/os.html
os.mkdir
main
difference
v3
v4
API
keys
v3
API
keys
larger
character
a-zA-Z0-9
]
v3
API
key
_could_
numbers
lower
case
characters
regular
expression
user
unlucky
v3
API
key
v4
API
key
upgrades
Certbot
tries
backwards
compatibility
predictability
reasonable
API
version
API
version
convenient
people
credentials
files
v4
v3
API
version
—
safer
change
documentation
changes
link
documentation
problem
PASS
placeholder
value
unimplemented
ParserNode
variable
method
equality
assertions
breaking
implementation
sort
test
driven
development
approach
multiple
values
way
errors
actual
interface
implementations
complete
implementation
assertions
something
wrong
phrase
subcommand
X
bit
something
subcommand
shell
administrative
rights
link
documentation
minute
https
//docs.microsoft.com/en-us/cpp/c-runtime-library/errno-constants
view=vs-2017
Microsoft
EPERM
EACCES
errors.Error
better
https
//github.com/certbot/certbot/issues/6357
general
custom
error
types
Certbot
program
First
following
code
remark
try
os.remove
path
OSError
err
errno.EACCESS
errno.EPERM
Windows
specific
able
file
race
conditions
Linux
lockfile
next
Certbot
call
pass
os.close
fd
lockfile
lock
dirt
directories
Certbot
Python
libraries
issue
Linux
Windows
work
next
PR
locking
mechanism
relevant
PR
excerpt
Linux
current
locking
process
Certbot
leak
Windows
Certbot
unexpectedly
state
AppVeyor
VM
stale
file
lock
failed
tests
lock
mechanism
plateform-independent
context
manager
lock
file
similar
locks
file
descriptos
statement
approach
fall-backed
atexit
Certbot
lock
file
descriptor
exit
state
modifications
third
PR
code
mean
time
PR
suggestion
new
owner
DACL
ACEs
specific
user
nit
umask
definition
umask
https
//en.wikipedia.org/wiki/Umask
other
references
nit
true
bits
parenthetical
>
reliable
suggestion
pip
real
dependency
graph
resolver
constraint
suggestion
Check
https
//github.com/boto/botocore/issues/1733
resolution
botocore
suggestion
requests
urllib==1.25.2
explicit
dependency
issue
comment
suggestion
Remove
handlers
future
tests
logging.getLogger
.handlers
[
]
reason
latest
setuptools
version
available
close
things
approach
particular
default
value
field
problems
[
]
Registration
TypeError
Traceback
recent
call
last
ipython-input-3-48d171e81d05
>
<
module
>
>
Registration
acme/acme/messages.py
emails
def
emails
contact
field
return
self._filter_contact
self.email_prefix
acme/acme/messages.py
_filter_contact
prefix
def
_filter_contact
prefix
return
tuple
detail
[
len
prefix
]
detail
self.contact
pylint
disable=not-an-iterable
detail.startswith
prefix
TypeError
'NoneType
object
iterable
latter
default
same
problem
much
harder
problems
https
//github.com/certbot/certbot/issues/5129
approach
similar
acme/mixins.py
following
changes
messages.UpdateRegistration
__init__
method
checks
contact
arguments
private
underscore
boolean
variable
result
attribute
Add
to_partial_json
fields_to_partial_json
methods
parent
method
contact
field
user
default
value
complex
elegant
amount
unintended
changes
PR
valuable
Same
comment
contact
suggestion
'contact
kwargs
suggestion
Serialization
behavior
changes
contacts
constructor
suggestion
acc_contacts
=
type
Iterable
[
str
mocking
entire
span
method
]
https
//github.com/certbot/certbot/blob/860af81fef3042134b2b71a6b71b4240c75b1886/certbot/tests/main_test.py
L149-L158
excessive
nesting
nit
client
self._call
assert
mock
client
object
suggestion
Mock
registration
body
calls
suggestion
update
return
value
update_account
None
funny
documentation
old
functionality
“
everything
DSL
”
direction
didn
’
t
enough
value
way
experienced
Pythonistas
functions
favor
“
exception
”
useful
option
Invoke
’
Exit
exception
feels
Pythonic
thin
wrappers
sys.exit
SystemExit
SystemExit
own
code
>
Aborting
concept
exception
reasonable
end
user
Exit
See
Utilities
exception
check
code
following
notation
multiline
strings
code
consistency
readability
self.servers
Already
IPv6
logger.debug
Certbot
able
%
s
%
s
%
s
+
due
dual
stack
nature
IPv6
socket
implementations
new_address
]
new_address
]
IPv6
ip_version
IPv4
apologies
earlier
older
version
docutils
Newer
versions
Sphinx
work
fine
newer
versions
docutils
problems
date
distros
newer
versions
packages
available
older
version
Sphinx
older
version
docutils
good
way
general
bit
ugly
problem
other
dependencies
cases
nothing
user
package
manager/maintainers
compatible
versions
dependencies
elegant
issues
Distro
package
maintainers
test
packages
live
only
Python
package
issues
people
pip
pip
prefers
latest
version
everything
latest
bug
fixes
good
idea
comment
docutils
Sphinx
<
link
GitHub
issue
actual
dependency
unpinned
back
version
docutils
nit
following
signature
check
comment
line
more
clear
easier
cases
code
whole
lot
readable
comment
tests
bit
boilerplate
setup
beneficial
test
cases
different
tests
setup
separate
function
comment
coverage
hash
same
effect
preference
happy
hash
file
.new
file
same
time
live
file
same
effect
preference
special
value/version
file
file
original
contents/hash
visible
.new
file
hidden
file
hidden
file
/etc/letsencrypt
something
/var/lib/letsencrypt
latter
opens
other
problems
>
.new
fine
>
lots
noise
contents
field
file
different
updated
version
field
flag
good
point
user
file
updates
bad
idea
Basically
way
user
happy
current
state
file
clean
way
nginx-no-tls-updates-until-next-time
ridiculous
cruel
experience
user
thing
Certbot
Nginx
plugin
options-ssl-nginx.conf
file
version
same
base
file
users
behavior
Certbot
file
same
nginx-no-tls-updates
Certbot
number
ways
CURRENT_SSL_OPTIONS_HASH
original
file
different
current
file
.new
file
warning
/var/lib/letsencrypt
nice
awkward
fact
options-ssl-nginx.conf
configurable
directory
location
original
hash/contents
new
file/folder
/etc/letsencrypt
downside
things
runtime
hard/complex
original
plan
things
sane
state
OS
packages
certbot-auto
docker
pip
more
work
Certbot
different
behavior
current
experience
PR
cruel
user
serious
problem
attention
only
way
Next
time
cron
e-mail
look
logs
Certbot
message
message
people
e-mail
properly
attention
nice
noise
problem
user
file
tells
interested
updates
contents
.new
file
nothing
CURRENT_SSL_OPTIONS_HASH
only
per
time
file
warning
.new
different
.new
original
file
certbot
version
things
version
messy
.new
various
ways
version
number
hash
same
effect
preference
happy
hash
file
.new
lots
noise
contents
field
file
different
updated
version
field
flag
sure
copy
copy
disk
whenever
options-ssl-nginx.conf
way
file
new
version
file
security
updates
certbot
version
things
version
messy
.new
various
ways
version
number
hash
copy
file
version
number
problem
kind
hash
likely
update
approaches
fine
opinion
create
new
versions
file
much
noise
issue
user
way
number
ways
CURRENT_SSL_OPTIONS_HASH
original
file
different
current
file
.new
file
warning.
sure
copy
Same
comment
fields_to_partial_json
comments
tests
more
appropriate
other
location
comment
challenge
responses
other
file
nit
URL
port
values
global
modifications
places
suggestion
print
workspace
certbot_test
workspace
Done
simple
better
complex
Has
comment
same
instruction
first
call
error
second
ideal
work
whitespace
comment
plan
changes
tuple
ParserNode
objects
suggestion
umask
call
suggestion
https
//docs.python.org/3/library/os.html
approach
https
//github.com/certbot/certbot/pull/7330
issuecomment-522795095
sure
parameters
defaults
class
docstring
same
feeling
https
//github.com/certbot/certbot/pull/7308
discussion_r314111032
ancestor
default
uncommon
same
way
filepath
None
empty
string
comments
derived
classes
right
places
class
docstrings
Disclaimer
while
test
system
handy
sure
sleep
necessary
most
cases
validation
relative
TTL
order
months
order
minutes
records
end
execution
records
previous
challenge
absence
record
TTL
SOA
record
]
https
//tools.ietf.org/html/rfc2308
value
something
major
problems
workflow
SOA
TTLs
high
_wait_for_change
change_id
good
server
challenges
edge
cases
example
pool
machines
load
balancer
order
certificates
same
domain
similar
schedule
common
use
case
retrying
cases
something
generic
way
issue
DNS
provider
parameters
self
domain
validation_domain_name
validation
linter
happy
Parsable
nit
no-name-in-module
code
isinstance
UnspacedList
type
ignore
safe
x
list
UnspacedList
is_dirty
attribute
sure
little
specific
type
Dict
[
str
Union
[
List
nginxparser.UnspacedList
]
]
correct
@
jameshiebert
type
comment
curious
@
ohemorange
Dict
[
str
Union
[
List
nginxparser.UnspacedList
]
]
@
jameshiebert
type
comment
curious
@
ohemorange
aside
something
special
old
style
redirect
Otherwise
Certbot
users
redirect
redirect
comment
either
old
style
redirect
Certbot
comments
true
comments
elif
clarity
vhost
redirect
only
listen
server_name
directives
statements
true
case
error
fine
comment
no-name-in-module
lint
checks
Python
imports
Optional
suggestion
type
str
str
Optional
[
dict
]
>
Tuple
[
str
suggestion
test_copy_ownership_and_apply_mode_windows
https
//www.pyopenssl.org/en/stable/api/ssl.html
OpenSSL.SSL.Context.set_alpn_select_callback
connection
empty
bytestring
few
systems
problem
approach
rest
function
return
b
comment
return
value
approach
exception
BadALPNProtos
purpose
check
obvious
let
port
ACME
specification
Let
line
comment
important
pass
None
empty
UpdateRegistration
message
Good
idea
TODO
relevant
tests
update-registration
similar
TODO
test
nit
[
open
]
https
//docs.python.org/3/library/functions.html
open
universal
newline
mode
default
Python
behavior
Python
Windows
Python
U
interested
U
newer
versions
Python
safe
Support
TXT
record
name
comments
useful
point
meaningful
upgrade
nit
disabled
pylint
checks
line
Syntax
pylint
enable=unused-import
no-name-in-module
suggestion
Wait
appropriate
time
Retry-After
initial
wait
wait
idea
documentation
interface.py
unlikely
worried
machine
limited
resources
longer
second
test
optional
parameter
Retry-After
value
something
large
equal
value
greater
comment
code
parent
class
different
condition
request.config
'slaveinput
Smart
move
lot
Could
issue
improvment
issue
TODO
parallelization
problem
favor
unique
port
unique
DNS
server
configure
multiple
zones
workers
design
discussion
later
PR
complication
parse
IfModule
<
module
>
statements
issue
same
opinion
reasons
certbot
help
apache
apache-handle-modules
False
date
enabled
mod_ssl
user
systems
requests
small
subset
people
alternative
ssl
modules
such
libraries
other
openssl
reasons
LoadModule
ssl_module
directives
exclude=False
path
SSL
module
directives
error
clear
error
message
user
problem
way
Augeas
path
current
PR
Augeas
paths
same
path
last
issue
current
PR
curious
change
return
value
problems
code
base
paths
comment
end
lm
simple
function
name
multiple
places
comment
end
mods
]
simple
function
name
multiple
places
suggestion
permissions
respect
suggestion
Linux
Windows
file
creation
suggestion
None
lookup
local
system
suggestion
os.open
function
Windows
same
effect
call
file
suggestion
modes
modes
correct
control
permissions
file
comment
suggestion
case
file
creation
invokes
example
first
DNS
plugin
optional
parameter
quick
sketch
optional
credential
PR
repo
https
//github.com/bodgit/certbot/pull/1
structure
results
earlier
error
interactive
workflow
user
file
retry
beginning
interactive
workflow
Feel
free
algorithm
optional
logic
_setup_credentials
value
valid
nit
line
ocsp.OCSPResponse
line
boolean
Docstring
enforce_openssl_binary_usage
ocsp
None
clearer
reader
code
things
response
[
RFC
]
https
//tools.ietf.org/html/rfc6960
section-3.2
other
checks
ugly
way
OCSP
responder
failure
response
way
try
hash
other
SHA1
debug
verbose
command
line
Traceback
recent
call
last
File
/usr/local/bin/certbot
line
<
module
>
load_entry_point
'certbot
'console_scripts
'certbot
/home/bmw/src/certbot/certbot/main.py
line
main
return
config.func
config
plugins
/home/bmw/src/certbot/certbot/main.py
line
certificates
cert_manager.certificates
config
/home/bmw/src/certbot/certbot/cert_manager.py
line
certificates
_describe_certs
config
parsed_certs
parse_failures
/home/bmw/src/certbot/certbot/cert_manager.py
line
_describe_certs
_report_human_readable
config
parsed_certs
/home/bmw/src/certbot/certbot/cert_manager.py
line
_report_human_readable
certinfo.append
human_readable_cert_info
config
cert
/home/bmw/src/certbot/certbot/cert_manager.py
line
human_readable_cert_info
cert.cert
cert.chain
File
/home/bmw/src/certbot/certbot/ocsp.py
line
ocsp_revoked
return
_check_ocsp_cryptography
cert_path
chain_path
url
/home/bmw/src/certbot/certbot/ocsp.py
line
_check_ocsp_cryptography
_check_ocsp_response_signature
response_ocsp
issuer
/home/bmw/src/certbot/certbot/ocsp.py
line
_check_ocsp_response_signature
chosen_hash
=
x509._SIG_OIDS_TO_HASH
[
]
pylint
disable=protected-access
File
/home/bmw/src/certbot/venv/local/lib/python2.7/site-packages/cryptography/hazmat/backends/openssl/ocsp.py
line
wrapper
OCSP
response
status
successful
property
ValueError
OCSP
response
status
successful
property
value
nit
line
ocsp_lib.OCSPResponse
line
type
ignore
type
calls
functions
certbot.compat.os.path
case
great
easy
way
type
ignore
understanding
comment
check
rest
class
docstring
__init__
same
effect
classes
functions
future
wait
able
things
modify
comments
something
get-only
function
able
things
mock
object
frozen
practice
only
attribute
_func
unusual
user
function
value
reason
definition
__setattr__
something
__setattr__
name
value
Set
_mock
FreezableMock
frozen
cases
return_value
side_effect
attributes
instance
_mock.
name
self._frozen_set
raise
AttributeError
frozen
attribute
+
name
return
setattr
self._mock
name
value
name
=
self._frozen_set.add
name
name
'return_value
'side_effect
return
setattr
self._mock
name
value
return
object.__setattr__
name
value
approach
way
FreezableMock
object
works
consistent
return_value
side_effect
good
use
tools
available
wheel
ugly
hack
Note
approach
return_value
parameter
self.return_value
=
return_value
self._frozen
self._mock
TODO
code
worth
capability
<
=
ultimate
goal
pinned
dependencies
dictionary
redundant
necessary
a.body.identifier.value
domain
wildcard
certificates
true
comment
case
test
fact
dummy
plugin
setUp
HTTP01
https
//github.com/certbot/certbot/blob/04152c21b5726f9bf05ec4820f95b9ebe2423c64/certbot/tests/auth_handler_test.py
L76
supported
challenge
test
things
comment
choice
challenge
Ah
case
comment
oldest
requirements
oldest
requirements
nit
same
file
achievable
add_parser_arguments
classmethod
changes
actual
instance
way
list
dict
s
command
line
argument
class
constant
behavior
comment
reminding
list
_prepare_options
simple
test
suggestion
certbot-auto
failures
Python
enum34
comment
os.stat
symlinks
ownership
suggestion
letsencrypt-auto
/tmp
permissions
letsencrypt-auto
good
idea
example
self.config.renewal_configs_dir
Nice
catch
lines
suggestion
TODO
tls-sni
related
assertions
nit
above
line
purpose
obvious
port
None
future
readers
helpful
comment
case
s
Part
function
docstring
example
return
dict
shape
non
native
English
speakers
idiomatic
expressions
Done
docstring
responsibilities
function
process
Docstrings
other
functions
helpful
welcome
much
anonymity
track
intermediate
names
version
distro
versions
docstring
purpose
function
long
time
end
permissions
unspecified
actual
ACEs
current
general
temp
dir
directory
mkdtemp
own
directory
real
control
ACEs
permissions
nit
assert
isinstance
achall.chall
challenges.DNS01
line
TLSSNI01
same
thing
comment
error
something
wrong
addition
change
function
purpose
domain_in_names
correct
reason
ReferenceError
thought
best
effort
attempt
session
__del__
error
prone
tracebacks
strange
errors
bare
problem
other
errors
manifest
future
other
exceptions
possible
bug
reports
strong
preference
change
Feel
free
better
code
Tuple
[
str
int
]
fact
mock
completer.py
lexicon.display.dummy_readline
test
test
relevant
readline
available
KeyboardInterrupt
Same
comment
Yes
near
future
something
appropriate
frontend
other
sys.exit
suggestion
TODO
use
enum
correct_name
=
[
'peak
'jump
'drop
'general
]
comment
dataset
suggestion
TODO
implement
graceful
TODO
Let
TODO
PR
suggestion
self.__responses
[
request_id
]
task
request_id
self.__responses
Typo
'oauth
*
*
careful
bug
add_year
cases
test
certain
times
certain
years
explicit
testing
specific
dates
leap
day
date
+1
year
amir-qayyum-khan
sure
test
road
next
leap
day
day
next
year
test
assert
specific
behaviors
specific
dates
leap
day
Feb
Feb
Feb
crucial
good
comment
URL
rules
standard
social_django.urls
module
import
rules
custom
URL
rule
top
something
python
urlpatterns
=
[
pattern
pattern
social_django.urls.urlpatterns
pattern.name
=
'complete
]
+
[
url
r'^complete/
P
<
>
[
^/
]
+
complete
name='complete
]
helpful
more
explicit
line
library
code
custom
code
brief
comment
wondering
significance
backend_state
key
something
sets
point
logout
session
state
social_django
state
session
order
authentication
least
exception
docstring
Has
coupon
*
*
*
*
possible
runs
Line
filter
Order.status
fulfilled
expression
coupon
coupon
user_has_redemptions_left
opposite
case
failed
line
comment
changes
obvious
code
notes
docstring
inline
comments
fact
.audit
results
upload
b
file
test
case
docstring
😄
straightforward
test
exams.pearson.audit.S3AuditStorage
upload
test
ExamDataAuditor
functionality
true
other
S3AuditStorage
-specific
test
cases
list
query
sets
sure
actual
impact
performances
unnecessary
other
lists
sure
list
other
one
UNION
field
order
ORDER
BY
clause
order
SQL
Coupon.is_automatic_qset
needs
least
renamed
queryset
BUT
.filter
actual
filter
queryset
Removed
comment
relevant
@
giocalitri
revised
class-based
writers
comment
[
]
https
//github.com/mitodl/micromasters/pull/2221
discussion_r94607920
Done
transaction
try
..
comment
section
comment
wrap
lines
sure
implementation
atomic
transaction
good
thing
Django
transaction
entire
transaction
block
per-query
logging
traceback
query
valid_profile_ids
invalid_profile_ids
True
same
time
above
comment
comment
Done
comment
equal
length
elements
setup
something
identifiable
comment
necessary
Can
description
docstring
pages
results
second
page
smaller
first
page
comment
calculation
Ideally
comment
code
comment
code
clearer
dictionary
timestamp
session_timeout
digest
form
kind
nitpick
profile__id
_and_
profile__student_id
docstrings
test
test
short
function
name
descriptive
enough
pylint
requirement
happy
point
use
ddt
difficult
tests
ddt
best
piece
functionality
same
output
regardless
sort
input
tests
output
different
input
output
extra
parameter
ddt
arguments
docstrings
tests
test
methods
ddt
name
values
many
docstrings
Nit
cleaner
doc
falsey
doc
=
serialize_program_enrolled_user
program_enrollment
return
]
doc
[
'_id
]
message
action
test
username
null
next
test
docstring
Sounds
good
settings.EXAMS_SFTP_TEMP_DIR
/tmp
ORGNAME
placeholder
own
organization
name
function
FYI
Feel
free
worth
placeholder
TBH
naming
conventions
real-world
files
sure
depedency
Ok
deal
csv.DictReader
str
object
iterator
protocol
returns
strings
binary
mode
file
object
iterator
return
intermediate
code
data
=
[
str
line
line
extracted_file
]
code
bit
file
text
issue
file
way
Sure
error
binary
mode
shot
least
comment
error
Assert
user
profile
authorization
suggestion
union
dims1
dims2
dims
suggestion
use
dot
large
DataArrays
da
weights
share
dims
suggestion
return
da.fillna
.dot
weights
dims=dims
weights
additional
dimension
self.obj
large
memory
example
mask
weights
=
xr.where
self.obj.notnull
binary
mask
sum_of_weights
xr.dot
mask
weights
above
suggestion
mask
=
da.notnull
suggestion
mask
=
da.isnull
bool
works
dot
limited
checks
fujiisoup
suggestion
nice
str
repr
Weighted
object
code
E265
block
comment
TODO
repr
computers
large
datasets
dask-distributed
same
concern
suggestion
opposite
order
comment
test
string
list
sure
[
'chunksizes
]
iterable
length
variable.ndim
monotonically-increasing
index
assume_sorted=True
shoyer
bug
wrap_interpolator
partial
function
call
future
tests
pytest
parameterizations
coastlines
same
coordinate
system
image
https
//github.com/SciTools/cartopy/issues/813
tool
PROJ4
string
available
attribute
cartopy.Proj
instance
https
//github.com/SciTools/cartopy/issues/813
issuecomment-355051930
honest
Cartopy
choice
own
new
projection
classes
own
kwargs
system
topic
Let
refer
scipy
documentation
interp1d
full
details
coords
data
variables
Dataset
little
cleaner
follow-up
someone
slow
performance
comment
lower-level
Variable
API
things
method
repetition
little
unfortunate
good
alternative
self._obj.data
NotImplementedError
dask
array
indentation
Let
defer
patch
other
modifications
re-sampling
timezones
interpolation
code
unit
test
nearest
possible
constructor
object.__new__
comment
TODO
v0.10
required
version
patch
release
v0.9
release
minimum
version
pint
policy
latest
available
whole
check
unused
philosophy
codebase
minimum
version
tests
unused
philosophy
codebase
minimum
version
tests
pint
awareness
unused
moment
NEP18
whole
test
suite
line
import_or_skip
pint
redundant
TODO
note
Todo
afraid
coordinates
map_blocks
iterate
blocks
block
index
number
dimension
python
index
block
var.indexed_blocks
x
=
[
_x.block
[
i
i
_x
zip
index
_old_x
xx
=
[
_x.block
[
i
i
_x
zip
index
_new_x
res.block
[
index
]
=
interp_func
var.block
[
index
]
x
xx
interp_kwarg
reason
riods.coords
]
=
towards
function
example
simpler
accessor
overkill
problem
clarity
scalar
case
separate
.flatten
other
undesirable
consequences
DataArray
close-able
_file_obj
e.g.
result
=
DataArray
data=data
dims=
'band
y
x
=
riods
result
public
API
private
particular
order
==
np.arange
start
stop
dataset_join
=
'inner
docstring
helpful
join
argument
parts
join
[
indexes
]
https
//github.com/pydata/xarray/blob/4d36fe2e8a1f5504d776c2d69895bc4d5a9cd31a/xarray/core/computation.py
L340
join
[
data
variables
datasets
]
https
//github.com/pydata/xarray/blob/4d36fe2e8a1f5504d776c2d69895bc4d5a9cd31a/xarray/core/computation.py
L347
fillna
data_vars_join='left
equivalent
value
new
keys
advantage
isnull
data
other
data
logic
function
dask
arrays
sense
other
functions
argmax
median
var
std
cumsum
cumprod
Dataset.attrs
keep_attrs=True
pytest.mark.skipif
version
number
test
Travis-CI
Python
old
version
h5py
backend
logic
dimensions
time
Variable
comment
v1.10
>
v1.12
complex256
float128
available
integration
tests
Appveyor
Windows
PR
So
let
Good
point
docstring
@
fmaussion
comments
order
example
Import
matplotlib
xarray
try
import
matplotlib
mpl
different
backend
Travis
CI
work
mpl.use
'Agg
import
matplotlib.pyplot
plt
ImportError
pass
example
good
question
dax1
different
coordinate
labels
x
dax0
da
sortby
arguments
good
idea
good
dumb
question
case
da
x
values
dataarrays
dax0
dax1
dataarrays
x
right
length
able
sort
coordinate
labels
irrelevant
consistency
other
xarray
options
aligned
objects
Indexing
exception
objects
variables
object
most
cases
name
xarray.align
variables
join='left
Just
note
sort
labels
end
consistent
NumPy
sort
NaN
Quick
question
input
mean
input
N-D
left-join
matching
dims
course
possibility
input
dataarray
_multiple_
dimensions
Align
small
worms
left-join
nan
array
values
sort
state
datastore
everything
necessary
set_variables
Note
bunch
possible
stateless
state
file-like
object
Sure
easy
Done
E123
bracket
indentation
bracket
line
nit
complex
control
flow
tests
harder
different
tests
bit
copied
code
expert
reason
obvious
version
np.arange
nx
worth
comment
attribute
lookup
fallback
e.g.
try
transform
riods.transform
AttributeError
transform
robust
versions
big
fan
name
John
issue
__hash__
class
ReprObject
value
use
sentinel
__slots__
=
_value
def
__init__
value
str
self._value
=
value
def
__repr__
>
str
return
self._value
def
__eq__
other
>
bool
isinstance
other
ReprObject
return
self._value
==
False
def
__hash__
>
int
return
hash
ReprObject
self._value
subsetter
=
point
name
indexes
graph
nodes
dataset
inputs
function
example
following
results
different
names
python
ds.map_blocks
func
foo
ds.map_blocks
func
foo
result
=
Dataset
coords=indexes
Agreed
questions
work
other
branches
ones
related
_ensure_ndarray
method
Thanks
code
TODO
comment
TODO
CFTimeIndex
values
reference
index
values
appropriate
NaN
value
beginning
datetime_bins
labels
indexes
cases
precision
Conversion
ns
time
steps
<
Conversion
float
large
timedelta
]
values
example
[
]
np.float
np.float
]
loss
precision
worried
hence
confusion
concerned
bugs
better
coords
same
type
e.g.
dict
Variable
values
consistency
coordinates
inclination
same
keys
setitem
valid
getitem
Ideally
same
code
errors
multiple
indexers
inconsistent
alignment
line
necessary
OuterIndexer
better
simple
comment
suggestion
GH4074
wrapping
data
subclass
xarray.core.indexing.ExplicitlyIndexed
base
class
various
backend
arrays
example
NumPy
bit
isinstance
data
ExplicitlyIndexed
data
indexing.ImplicitToExplicitIndexingAdapter
data
indexing.OuterIndexer
reason
arrays
first
place
array
storage
backends
netCDF4
h5py
general
array
indexing
example
netCDF4
dimensions
independent
NumPy
Xarray
explicit
indexing
classes
BasicIndexer
VectorizedIndexer
track
desired
indexing
operation
everything
[
form
NumPy
]
https
//docs.scipy.org/doc/numpy/reference/arrays.indexing.html
lots
edge
cases
mixed
slice
/
ndarray
indexing
other
forms
comment
clear
fill
value
sentence
OK
unit
test
relies
correctness
date
fields
NumPy
arrays
other
tests
rid
fields
use
self.times_arr.dt.year
ideal
world
assertDatasetIdentical
attributes
bears
example
test
DAP
server
clear
relation
original
netCDF
file
Hyrax
DAP
server
extra
attributes
sure
possible
details
Hyrax
xarray
test
suite
best
comment
attributes
assertDatasetIdentical
test
DAP
extra
attributes
netCDF
file
loop
recursive
use
function
better
explanation/comment
text
formatting
logic
attribute
string
strange
things
attribute
number
array
Use
OPTIONS
[
'display_width
]
comment
https
//github.com/dask/dask/issues/1926
better
way
appropriate
fill_value
non-float
arrays
Use
default
value
sentinel
value
use
case
Otherwise
None
fill
value
last
case
lines
line
limit
tests
something
Thanks
review
assert
internal
private
function
Rather
let
ValueError
accident
safe
assert
user
code
good
upstream
bug
report
dask
dask
arrays
costly
much
warning
@
dcherian
@
mathause
suggestion
note
work
suggestion
non-standard
calendards
>
deprecation
useful
attribute
F401
sns
comment
useful
suggestion
xr.testing.assert_equal
ds
smaller
test
methods
e.g.
test_expand_dims_errors
easier
tests
thing
cases
dimension
coordinate
memory
pandas.Index
other
coordinates
sure
other
functions
file
work
numpy
level
necessary
colorbar
wrong
data
case
better
error
message
Again
comment
value
arbitrary
suggestion
def
_weight_check
w
Ref
https
//github.com/pydata/xarray/pull/4559/files
r515968670
np.isnan
w
.any
suggestion
assign
check
weights
weights.copy
data=weights.data.map_blocks
_weight_check
dtype=weights.dtype
dask
bag
xarray
datasets
dask
arrays
bags
array
values
good
comments
code
configuration
dict
something
cfgrid
forms
cfgrib
previous
commit
OUTER_1VECTOR
IndexingSupport
details
noqa
extra
level
indentation
lines
F401
sns
unused
Can
pandas
license
file
See
example
local
import
function
little
nervous
future
version
pandas
private
module
imports
errant
comment
Please
use
comments
strings
docstrings
Similar
comment
QuarterBegin
inclined
pandas
behavior
consistency
let
_default_month
=
_FREQUENCIES
dictionary
partial
QuarterEnd
month=12
Q
entry
to_offset
comment
other
priorities
own
test
way
test
failure
code
Has
dangerous
pandas
internals
sure
enc_chunks_tuple
tuple
length
nit
_DIMENSION_KEY
constant
something
more
generic
constant
value
'_ARRAY_DIMENSIONS
time
wrapper
zarr
objects
able
autoclose/opener/DataStorePickleMixin
Use
isinstance
value
np.generic
unit
tests
unclear
checks
above
logic
serious
tests
works
something
data
test_auto_chunk
test
BaseNetCDF4Array
sense
Did
anything
Feedback
api
graceful
error
message
dimension
key
comment
bit
confused
fill_value
zarr
fill_value
mechanisms
best
way
xarray
FYI
future
xarray.tests.assert_identical
better
interface
Reindexing
copy
dataset
let
object
coordinates
same
astype
np.float64
lines
need
help
better
design
methods
use
locals
sure
indication
functions
many
arguments
suggestion
xr.set_options
arithmetic_join=
suggestion
join
method
exact
comment
suggestion
def
drop
labels=None
dim=None
*
errors=
raise
*
*
labels_kwargs
noqa
F811
way
comment
more
sentence
please
detailed
explanation
Quantity
implements
__array_function__
xarray
treats
pint.Quantity
instances
arrays
correct
pint
python
scalars
ndim
shape
dtype
force_ndarray
means
Quantity
instances
numpy.array
s
AttributeError
s
hgrecco/pint
E261
least
spaces
inline
comment
more
tests
case
Django
channel
someone
hacky
way
Question
best
way
URLs
prebuilt
function
common
thing
smtplib.SMTPException
Nit
separate
comment
pattern
codebase
lot
*
Nit
line
python
user_full_name
=
user.profile.name
hasattr
'profile
None
_Please
destination
e-mail
address._
Goodnight
sweet
princes
DOP
DOT
metric
values
set_custom_metric
'dop
OAuth2AuthenticationTests
comment
Nit
sure
comments
example
route
useful
docstring
method
nit
Toggle
audit
certificates
differ
ecommerce
order
Nit
courses
code
more
upgrade
deadline
comment
verifiable
course
mode
upgrade
deadline
course
following
lines
Nit
courses
mapping
apps
NewRelic
edx
repos
owners
mapping
repo
list
spreadsheet
script
script
way
configuration
non-edx
owned
repos
ownership
spreadsheet
apps
repo
folder
ownership
cases
tuples
below
containing
repo
little
confused
context
repos
various
Github
orgs
Other
places
Mention
Github
org
map
squad
names
lists
dotted
module
paths
suggestion
Maps
theme
name
list
code
owners
theme
squad
full
code
owner
name
Code
owner
combining
theme
squad
information
Suggested
rewording
purpose
maps
>
Hmm
other
comment
PR
Whoops
comment
Anyway
pylint-disable
entire
file
class
scope
code
worth
@
symbolist
@
ormsbee
lieu
objections
plan
Monday
morning
EDT
doc-string
instruction
management
command
example
management
command
such
./manage.py
lms
link_program_enrollments
program_uuid
>
<
>
<
>
example
<
external_student_key
>
<
lms_username
>
nit
docstring
Nit
comment
iterator
Nit
clear
variable
other
dependencies
generic
name
true
is_microfrontend_embed=false
is_microfrontend_embed=pizza
intention
student_view_context
[
]
=
request.GET.get
potential
implications
i
people
cea
linkage
comment
Does
nested
test
condition
new
test
case
specific
scenario
Trivial
nit
variables
string
more
i.e
=
self.create_and_enroll_student
username=another_student_username
typos
NIT
comment
subsection_grade
object
please
username
comment
different
username
accidental
comment
name
flag
name
Same
request
name
toggle_key
something
likely
issue
other
linter
Future
idea
comment
certain
memberships
sure
comment
case
complex
failure
scenario
list
tests
fails
half
fails
half
necessary
ingredient
failure
final
test
reader
perspective
comment
error
error
Thanks
order-by
explanatory
comment
lot
debuggable
active
records
external
key
*
least
*
recent
inactive
record
inconsistent
something
python
pces
list
program_course_enrollments
active_pces
[
pce
pce
pces
pce.status
==
ProgramCourseEnrollmentStatuses.ACTIVE
]
try
active
program
course
enrollment
.....
next
active_pces
pces
StopIteration
None
multi-line
comment
isort
BlockInfo
declaration
comments
TestCase
import
pylint
warnings
least
TestCase
import
no-name-in-module
warning
Nit
superfluous
last
line
for-loop
body
stray
comment
Please
comment
result
copy/paste
usage
tag
direct
usage
enterprise_learner
print_function
__future__
comment
constant
top
file
uses
course
waffle
flag
rollout
Add
toggle
details
other
toggles.py
files
reference
need
u
isort
multi-line
comment
comment
lines
nit
better
name
Can
extra
implementation-specific
logic
_
db
global
flag
DynamicUpgradeDeadlineConfiguration
course-specific
global_config
=
DynamicUpgradeDeadlineConfiguration.current
delta
global_config.deadline_days
=
CourseDynamicUpgradeDeadlineConfiguration.current
self.course.id
course_config.opt_out
return
deadline
delta
=
continue
global
kill-switch
code
case
logic/implementation
issues
better
logic
classmethod
CourseDynamicUpgradeDeadlineConfiguration
config-checking
code
config
class/module
Are
temporary
toggles
ORA
[
different
value
toggle_use_cases
]
https
//github.com/edx/edx-toggles/blob/master/feature_toggle_annotations.yaml
L19
Open
ORA
users
explanation
Open
edX
operator
s/degredation/degradation
s/degredation/degradation
nit
valuable
comment
’
t
help
operators
debatable
owner
more
code
annotation
Drop
temporary
other
use
cases
long
term
..
interesting
[
repeatable-read
isolation
level
]
https
//stackoverflow.com/a/4036063
MySQL
Good
catch
Small
Nit
valuable
comment
general
purpose
line
specific
changes
Could
comment
docstring
docstring
more
explanation
test
context
PR
description
test
confusing
own
names
initials
code
Git
history
developers
ownership
unknowing
future
Rather
TODO
statements
JIRA
ticket
ticket
number
code
*
Reviewer
Note
*
*
sort
worst-case-scenario
test
acceptable
performance
imports
unused
parts
urllib2
NIT
Could
comment
reason
treatment
Please
comment
statement
ID
providers
SAML
more
comments
loop
ID
providers
oauth2
uid
shorter
characters
different
sense
little
difficult
different
variable
name
variable
detail
helpful
readable
lines
function
relevant
util
function
s/note/not
possible
function
arguments
arg
Stateful
modification
data
structure
loopy
most
data
structures
code
kernel
=
kernel.copy
options=options.copy
ignore_boostable_into=True
correct
idiom
https
//github.com/inducer/loopy/pull/128
no-op
anyway
code
function
*
faster
global
var
retrievals
dict
lookups
function-local
variables
efficient
numbering-based
mechanism
*
important
setting
size
arguments
kernels
size
accessed
footprint
stats
untransformed
program
addition
transformed
program
Numpy
masked
arrays
less
fuss
>
>
>
ary
=
np.ma.masked_equal
[
None
]
None
>
>
>
ary
masked_array
data=
[
mask=
[
False
False
True
]
fill_value=
dtype=object
>
>
np.mean
ary
>
>
>
ary
=
np.ma.masked_equal
[
None
None
None
]
None
>
>
>
f
np.mean
ary
.4g
>
>
>
Note
code
namespace
user
control
identifiers
prefixed
point
footprint_bytes
wrong
footprint_bytes
None
hard
whole
bunch
stuff
cache
hit
case
CACHE_HIT
return
cache
miss
stuff
stuff
stuff
return
import
side
effect
good
default
policy
mistakes
folks
env
var
job
script
warning
env
var
user
care
issue
f-string
code
hard
re.search
None
match
else
branch
match
None
assertion
goal
test
specific
message
better
[
self.fail
]
https
//docs.python.org/3/library/unittest.html
unittest.TestCase.fail
test
re.search
anything
better
little
=
re.search
r'\
[
I\|app\|\w
\
]
line
assert
match
Request
ID
match
proper
Match
object
self.logger.info
Request
ID
foreman
core
break
match
point
subsequent
lines
line_count_1
=
-l
<
source_log
break
backslashes
PEP8
path
times
test
variable
small
comment
regex
reviewer
regex
lines
common
test
functions
good
candidate
reusable
function
class
common
pattern
tests
[
setUpClass
]
https
//docs.python.org/3/library/unittest.html
unittest.TestCase.setUpClass
class
test
class
way
able
conditionals
SimpleLoggingTestCase.org
single
instance
class
share
data
instances
Move
variable
connection.run
result
=
connection.run
-20
/var/log/foreman/production.log
>
logfile_location
lines
test
case
good
candidate
common
reusable
function
same
previous
comment
module
steam
id
construct
time
creation
problem
more
note
function
API
calls
functionality
unit
tests
day
API
mock
def
create_role_permissions
role
permissions_types_names
pragma
cover
time
pragma
cover
API
mock
more
tests
new
local
variables
python
entity_name
entity
[
'name
]
entity.get
'setup
entity_setup
entities
organization
entity_setup
.create
comment
host_num
next
comment
half
PR
comment
correct
thing
Never
i
extra
comments
redundant
commands
method
simple
self-descriptive
need
comments
obvious
line
variable
name
=
[
line
line
result.stdout
message
line
shorter
noqa
split
least
FQDN
much
python
_
domain
=
settings.ipa.hostname_ipa.split
Proof
>
>
>
_
domain
=
settings.ipa.hostname_ipa.split
>
>
>
domain
==
settings.ipa.hostname_ipa
[
settings.ipa.hostname_ipa.find
'satqe
]
True
exception
TypeError
Did
something
cached_property
wheel
lots
properties
cached_property
requirement
airgun
anyways
robottelo
way
second
seconds
nothing
seconds
second
Y
time
wait_for
wrapper
success
criteria
something
robottelo.cli
hammer
Okay
sense
add
line
block
time
UI
please
API
call
same
lesser
time
'content_view_solve_dependencies
settings
adverse
effect
errata
count
test
many
earlier
value
API
e.g
UI
test
fails
solve_depedancy
case
problems
yield
test
module
level
earlier
values
add
try-catch
statement
dup
other
VirtualMachine
objects
ip
address
machine
suggestion
result
=
self.virtual_machines
]
.run
f'yum
erase
-y
self.CUSTOM_PACKAGE
Same
comment
VirtualMachine.run
above
comment
nitpick
i
line
python
results
=
Environment.list
'organization
org
[
]
command
strange
less
exit
code
Just
look
string
file
assert
exit
code
=
tuning
medium
/etc/foreman-installer/scenarios.d/satellite.yaml'
tuning_state_after_upgrade
=
ssh.command
cmd
.return_code
assert
tuning_state_after_upgrade
success
non-zero
suggestion
Add
skipif
markers
collection
BZ
option
suggestion
Add
issue
marker
e.g
Ahh
Just
same
optional
change
_assertdiscoveredhost
method
name
kind
wrong
host
multiple
iterations
other
PR
No
Python
Assertion
dont
good
return
code
everything
shell
groups
comment
emails
successive
dots
bug
CLOSED
NOTABUG
previous
comment
path
response
initial
virsh
qemu-agent-command
anything
subsequent
call
path
different
indentation
level
Let
wait
RedHatQE/widgetastic.core
airgun
side.
custome
yum
puppet
repositories
Makes
new
File
repository
self.setupScenario
test
case
case
element
class
something
new
host-status
pficon
pficon-info
yellow
status-warn
vsedmik
Settings
robottelo.cli.settings
code
result
=
Settings.list
search
'name=http_proxy_except_list
]
result
value
[
]
except_list
=
[
self.hostname
except_list
result
value
[
-1
]
+
self.hostname
Settings.set
'name
'http_proxy_except_list
except_list
comment
pulp
manifest
console
Note
overridden
search
methods
search
queries
overridden
search
methods
search
queries
PR
comment
example
pages
search
field
button
hence
search
queries
example
overridden
search
method
ui.Trend
https
//github.com/SatelliteQE/robottelo/blob/master/robottelo/ui/trend.py
L45
way
search
query
sleep
same
sleep
delay/4
line
Github
job
minutes
value
repo
sync
cv
publishing
promotion
nitpick
imo
empty
lines
redundant
test
nice
comments
commands
worse
empty
lines
comment
type
singular
form
builtin_resources
cloned_resources
plural
little
bit
confusing
fact
f-string
format
fit
single
line
Please
refactor
test
[
robottelo
products
]
https
//github.com/SatelliteQE/robottelo/blob/master/robottelo/products.py
Example
https
//github.com/SatelliteQE/robottelo/blob/master/tests/foreman/ui_airgun/test_errata.py
L68
correct
marker
same
way
others
other
scenarios
upgrade_tests
import
pre_upgrade
post_upgrade
single
shot
scenarios
..
.read
.update
value
variable
object
place
python
sync_plan
=
entities.SyncPlan
.create
sync_plan.name
=
name
sync_plan
=
sync_plan.update
[
'name
]
assert
sync_plan.name
==
name
pattern
occurrences
lot
work
approach
comment
future
lines
session
fixture
user
organization
location
fixtures
entire
comment
original
comment
let
make_fake_discovery_host
factory
method
similar
make_fake_host
other
host-related
tests
test
T2
tests
much
faster
same
thing
note
real
host
way
host
jsut
discovered
hosts
i
factory
blocker
order
host
fixture
setup
ocurrences
i
proper
provisioning
below
tests
custom
os
media
everything
make_host
kind
loop
Search
list
found
entities
id/name
particular
case
changes
environment
=
Environment
server_config
organization=
[
.search
]
.read
.read
end
case
other
entities
update
current
PR
changes
nailgun
i
ok
comment
separate
PR
OS
arch
ptable
comment
POST
Seems
monitoring
[
raise
syntax
]
https
//docs.python.org/3/reference/simple_stmts.html
raise
later
except
TypeError
exc
EmailRetrievalError
exc
messages
server.uid
yield
pytest
[
https
//docs.pytest.org/en/latest/monkeypatch.html
]
monkeypatch
pytest
fixtures
kind
setups
👍
Would
good
order
objects
consistent
file
public
API
top
middle
comment
grant_amount_offered
net_company_receipt
relate
investment
projects
grants
someone
graph.__getattr__
'missing_field
error
message
Hm
good
catch
norm-squared
reason
https
//github.com/stellargraph/stellargraph/pull/1522/commits/8922d19de94b98b5f4da68a64994445072b75805
sense
paper
code
L2
norm
https
//github.com/DeepGraphLearning/KnowledgeGraphEmbedding/blob/2442e8b9bb1a40e44edabcb3cc4f145ac24b1c7b/codes/model.py
L225
https
//pytorch.org/docs/master/generated/torch.norm.html
paper
L1
norm
e.g
explicit
expansion
Appendix
E
page
<
img
width=
alt=
image
src=
https
//user-images.githubusercontent.com/1203825/81892742-33fa8580-95ef-11ea-9c87-76951977fc28.png
>
difference
norm_order
parameter
tf.norm
ord=norm_order
Use
assert
enclosed
code
byte
code
StellarGraph
things
densification
fewer
asarray
/
suggestion
adj
=
np.asarray
self.G.to_adjacency_matrix
.todense
suggestion
assert
np.allclose
part
legacy
arguments
deprecation
warning
*
*
noticeable
impact
usability
auto-complete
sort
thing
shows
parameters
names
kind
sound
relevant
PR
experimental
other
PR
polish
work
PR
kernel_constraint
layers
good
documentation
function
docs/api.txt
hard
purpose
test
weeks/months
comment
e.g
suggestion
different
permutations
batch
numbers
same
seeds
comment
name
model
classes
methods
def
__call__
inputs
call
double-underscore
some_model
inputs
def
build
builds
appropriate
input
tensors
model
=
=
self
inputs
inputs
args
few
things
Consider
possible
security
implications
subprocess
module
different
line
x_out_dst
=
self.node_model
initializer
parameter
similar
other
models
input_initializer
generator
type
compatible
wrong
different
model
dst
nodes
src
dst
node
pairs
whereas
nodes
*
*
same
*
*
model
comments
target
node
input
context
node
output
terminology
standard
Node2Vec
bit
context
keras
model
input
output
meaning
i.e
input
tensors
model
output
tensors
target
context
similar
way
generator
comment
able
layer
subprocess
call
check
execution
untrusted
input
process
partial
executable
path
Err
yeah
meaning
sentence
🙈
someone
heterogeneous
graph
above
objection
suggested
change
part
https
//github.com/stellargraph/stellargraph/issues/1043
issuecomment-599840069
bit
code
ticket
required
action
issue
FIXME
comment
new
file
copyright
GC
tests
same
GC
disabled
GC
=
GC
bit
sloppy
>
gc.collect
worst
case
peak
Ah
>
Disabling
GC
beneficial
peak
memory
use
e.g
tracemalloc.get_traced_memory
worst-case
peak
case
GC
benchmarked-function
obvious
deallocations
more
sense
e.g
copy
anything
peak
memory
use
nice
timing
times
analysis
JSON
files
future
comment
assertion
future
changes
clear
prompt
test
weird
error
messages
networkx
internals
suggestion
assert
isinstance
G
NetworkXStellarGraph
XXX
Hack
NetworkXStellarGraph
instances
Gnx
=
G._graph
minor
change
restore
right
word
suggestion
Use
class
random
state
@
timpitman
>
extra
comment
overridden
derived
classes
shared
argument
Remove
useless
self-assignment
convert
strings
id
name
important
index
column
nodes
=
pd.DataFrame
index=np.unique
name
important
nodes.index.name
=
id
column
required
action
issue
FIXME
comment
issue
document
extra
functionality
graphs
suggestion
def
connected_components
connection=
weak
Compute
connected
components
graph
size
nodes
largest
component
nodes
next
graph.connected_components
node
IDs
method
corresponding
subgraph
graph.subgraph
nodes
Args
connection
str
optional
[
|
]
weakly
connected
components
case
directed
graph
Returns
iterator
sets
node
IDs
connected
component
largest
nodes
fewest
nodes
adj
=
self.to_adjacency_matrix
count
cc_labels
sps.csgraph.connected_components
adj
connection=connection
highest
element
test_external_id_index_to_iloc
test
np.min_scalar_type
argument
inclusive
iloc
equal
self._index
len
self._index
largest
import
np
np.min_scalar_type
dtype
'uint8
np.min_scalar_type
dtype
'uint16
elements
uint8
nice
suggestion
reserve
^
n-bits
sentinel
self._dtype
=
np.min_scalar_type
self._index
Note
comment
beforehand
black
complicated-ly
*
subtle
dtype
edge_ilocs
comment
real
purpose
argsort
results
integers
[
*
num_edges
dtype
larger
underscore-prefixing
great
class
properties
module-level
functions
accessible
users
necessary
variables/functions
function
no-one
function
access
suggestion
dtype
=
np.min_scalar_type
*
len
self.sources
process
partial
executable
path
subprocess
call
check
execution
untrusted
input
docstrings
new
methods
different
methods
similar
edge_arrays
sure
obvious
names
methods
different
something
collection
nodes
node
tuple
arrays
sources
targets
types
weights
weights
None
optional
parameters
Returns
sources
targets
types
weights
in_node_arrays
out_node_arrays
little
suspect
setup.py
individual
for-loops
same
python
ins
outs
self.in_samples
self.out_samples
=
[
ins
]
[
]
[
]
*
]
[
]
*
]
[
]
*
ins
]
[
]
*
]
]
i
dim
zip
range
assert
[
i
.shape
==
[
]
.shape
==
min
self.n_feat
something
..
test_DirectedGraphSAGELinkGenerator_unsupervisedSampler_sample_generation
bit
suggestion
j
first
elements
nf
head
nodes
bit
clearer
batch_dim
=
min
head
nodes
f
nf
[
:2
]
assert
f.shape
==
batch_dim
self.n_feat
neighbours
f
nf
[
]
assert
f.shape
==
batch_dim
self.n_feat
StellarGraph
StellarDiGraph
object
StellarGraphBase
abstract
base
class
objects
users
previous
comments
correct
type
graph
input
RelationalFullBatchNodeGenerator
input
graph
test
graphs
hmm
good
point
sure
decent
alternative
default
Maybe
*
N
eigenvecs
c
*
log
N
constant
thoughts
alot
nicer
reason
head
breaks
bad
Ah
paper
power
Laplacian
O
E
true
couple
powers
L^n
dense
look
references
methods
O
kE
use
sparse
matrix
vector
products
papers
least
closer
look
tomorrow
implement
methods
Reference
https
//arxiv.org/pdf/0912.3848.pdf
mentions
method
Arnoldi
iteration
eigenvalues
potential
alternative
worth
btw
section
something
different
polynomial
approximations
exp
-lambda
s
GraphWave
structural
properties
initial
search
vector
v0
eigs
deterministic
experiments
cora
case
stability
issue
bit
further
Chebyshev
approach
nice
engineers
constant
factors
joy
explaination
cool
self._node_lookup
safe
smallest
eigenvalue
possible
noise
eigenval
<
-1e-5
discussion
=
num_eigenvecs
use
np
matrix
operations
expensive
E
E
matrix
only
entries
set
n
times
E
*
E
times
E
i.e
O
n
E^2
matrix
multiplication
O
n
E
time
columns
n.exp
-s
*
eigen_vals
>
>
eigenvecs
=
np.array
[
[
]
]
]
]
>
>
eigenvals
np.array
[
]
>
>
eigenvecs
*
eigenvals
[
[
]
]
]
]
suggestion
self.eigen_vecs
*
np.exp
-s
*
eigen_vals
]
minor
thing
[
np.newaxis
]
array
single
dimension
due
sure
array
dimensions
[
np.newaxis
]
[
np.newaxis
array
dimensions
easier
performance
same
bc
tensorflow
computation
*
prev_eig_max
heuristic
cora
unecessary
slight
speed
less
eigen
vals
eigenvalues
prev_eig_max
*
prev_eig_max
1e-3
only
magic
number
/
good
found
eigenvalues
true
filtered
eigenvalues
Ah
things
float64
yep
giant
matrix
sensible
%
appropriate
threshold
ah
such
memory
arrangement
optimisation
tensor
suggestion
search
smallest
eigenvalue
initial
value
behaviour
eigs
sigma
random
eigs
nothing
solver
bad
spot
ah
nice
catch
worked
cheers
arrays
appropriate
https
//neo4j.com/docs/cypher-manual/current/clauses/match/
match-node-by-id
>
Neo4j
internal
ids
nodes
relationships
applications
internal
Neo4j
ids
brittle
risk
mistakes
recommended
application-generated
ids
discussed
class
StellarGraph
functionality
follow-on
work
PR
new
class
something
AbstractStellarGraph
StellarGraph
worth
issue
work
suggestion
FIXME
tensorflow
test
demo
failures
tensorflow
>
=2.0.0
suggestion
graph
StellarGraph
format
check
change
comment
node
features
single
node
more
little
confusing
Could
comment
Potentially
subset
feature
vectors
subset
fine
i
comment
suggestion
self.units
units
code
suggestion
code
required
action
issue
FIXME
comment
brief
comment
obvious
peculiar
thing
E.g
suggestion
identity
layer
name
tensor
node_feats
Lambda
lambda
x
x
name=self._unique_id
node_feats
method
latter
correct
model
information
base
model
GCN
unsupervised
full
batch
node
model
base
model
GraphSAGE
unsupervised
mini-batch
node
model
suggestion
config.assets_dir
=
Path
_static
*
*
Issue
*
<
whereitbelongs
more
something
<
module_name
>
function
suggestion
list
pre-defined
colors
Examples
preferred
way
colors
..
code-block
python
import
manim.utils.color
C
C.WHITE
>
FFFFFF'
Note
way
name
colors
UPPERCASE
Enum
members
use
code
color.value
way
name
colors
lowercase
..
code-block
python
manim.utils.color
import
Colors
Colors.white.value
>
FFFFFF'
suggestion
Note
Mobject.shift
mobject
non-empty
points
attribute
Mobject
VMobject
mob
child1
child2
=
VMobject
VMobject
VMobject
gchild1
gchild2
gchild_common
=
VMobject
VMobject
VMobject
VMobject
Circle
better
shapes
test
bug
_only_
Circle
*
Question
*
*
kwargs
addition
config
dict
attributes
quick
line
comment
good
Nitpick
example
Comment
black
indentation
*
*
Lgos
*
*
*
*
*
*
log
added
scenes
following
python
quality
m
manim
example_scenes.py
SquareToCircle
-p
Use
flag
quality
l
rendering
lower
quality
Use
-s
end
final
frame
Use
-p
preview
animation
image
-s
Use
-n
<
number
>
n'th
animation
scene
Use
-r
<
number
>
resolution
example
-r
video
docstrings
..
@
data
migration
necessary
convenient
Ocim
instances
developer
instance
entry
django
admin
fine
way
main
things
*
Avoid
different
places
things
.env
django
Watched
Fork
settings
django
create
none
approach
behavior
simple
predictable
Avoid
models
new
django
migrations
setting
model
defaults
way
default
Ocim
instance
manager
PR
sandbox
instance
manager
github
+1
Ocim
usable
whole
pr_watch
feature
@
giovannicimolin
sure
extra
settings
settings
variables
simple-theme
clear
below
suggestion
@
giovannicimolin
repository
skeleton
theme
betatest
instances
specified
theming
configuration
simple-theme
role
@
giovannicimolin
unused
import
Remove
null=True
default=
blank=True
lgp171188
Added
docstrings
See
comment
]
https
//github.com/open-craft/opencraft/pull/628/files
r470525805
@
Kelketek
[
comment
]
https
//github.com/open-craft/opencraft/pull/628/files
r469862596
comment
condition
check_deactivation
function
relevant
change
active
appserver
deployment
@
fox
comment
comment
specific
instance
Open
edX
instances
default
installation
guide
appserver_set
tests
results
entire
function
Nit
line
break
parenthesis
@
pcockwell
note
instances
more
active
appserver
returned
value
unique
hits
accurate
data
elasticsearch
@
pcockwell
check
error
message
successfully_provisioned
field
instance
active
appservers
playbook
@
pcockwell
better
suggestion
domain
'-d
pcockwell
cleaner
flag
management
command
single
instance
output
elasticsearch
data
suggestion
Copyright
C
OpenCraft
<
contact
@
suggestion
Launch
collect_activity.yml
playbook
file
playbook_output_dir
swalladge
nit
suggestion
suggestion
Email
production
instance
failures
nit
comment
Must
SWIFT_ENABLE
False
Could
comment
Might
PR
context
@
pcockwell
settings.py
overridden
settings.DEFAULT_FROM_EMAIL
suggestion
end_of_last_month
=
today
timedelta
days=1
explicit
@
pcockwell
good
idea
configurable
settings
string
time
default
@
pcockwell
line
cleaner
\
@
pcockwell
better
today
first
month
first
day
current
month
smallest
nits
comment
@
viadanna
test
pass
changes
place
body
try-except-else
block
FieldError
@
patch
def
test_migrate
Verify
command
instance
external
databases.
try
OpenEdXInstance.objects.create
sub_domain='test_migrate
use_ephemeral_databases=True
name='test_migrate
instance'
FieldError
print
use_ephemeral_databases
field
migration
test
LogCapture
captured_logs
call_command
'migrate_ephemeral
Verify
logs
actual
=
set
l
]
l
captured_logs.actual
=
instances
ephemeral
databases
new
app
server
test_migrate
instance
self.assertTrue
=
actual
self.assertTrue
[
skipUnless
]
https
//docs.python.org/3/library/unittest.html
unittest.skipUnless
check
information
use_ephemeral_databases
field
exists
[
example
]
https
//stackoverflow.com/q/29034721/1199226
bit
effort
approach
@
viadanna
Nit
name
instance
check
L64
generic
Instance
@
Copy-pasta
🍝
real
purpose
test
@
viadanna
addition
check
worth
management
command
right
number
instances
check
presence
log
entry
>
instances
ephemeral
databases
giovannicimolin
s/Untreated/Unhandled/
@
giovannicimolin
comment
place
'bucket
exception
previous
clause
@
giovannicimolin
[
Obligatory
reference
]
http
//regex.info/blog/2006-09-15/247
people
problem
regular
expressions.
problems
stuck_out_tongue
anything
better
man_shrugging
suggestion
terms
edges
terms
nodes
suggestion
Depth
quantum
circuit
longest
path
DAG
Better
full
list
args
suggestion
adjacency
matrix
complement
Pauli
graph
arguments
comments
function
previous
comment
rid
partition
pauli_word
pauli_word
Thanks
docstring
inaccurate
n_qubits
*
*
un
*
*
wire_map
dimensionality
vector
representation
highest
integer
wire_map.values
Several
attributes
methods
old
QNode
new
location
new
QNode/tape
tests
tape
non-tape
mode
running
list
changes
tests
tape
mode
default
Most
related
files
imports
beta
modules
example
qml.Identity
shorthand
bit
*
QueuingContext
defines
update_info
update_info
method
active_context
*
Queue
update_info
method
QueuingContext
update_info
method
active_context
resulting
infinite
recursion
*
AnnotatedQueue
defines
update_info
AnnotatedQueue
instance
active_context
infinite
recursion
use
solution
qml.QueuingContext.update_info
calls
minor
case
qml.PauliY
e.g.
_same_
observables
different
observables
same
wires
better
term
handwavey
+1
thanks
black
Yes
tape
QNode
construct
method
rid
original
something
mind
future
comment
_measurements
non-overlapping
observables
device
benefit
new
expand
measurement
block
e.g.
expand_measurements
obs_wires
=
len
obs_wires
QWC
diagonalization
non-overlapping
diagonalization
worth
comment
KeyError
ValueError
matches
qml.P
qml.NumberOperator
chance
small
Note
case
observable
form
python
PolyXP
np.array
[
c
]
identity
term
non-zero
ideal
device
cutoff
device
evaluation
c
<
PolyXP
np.array
[
c
]
=
c
interesting
position
analytic
gradient
*
hardware
*
same
CVQNode
wires
observable
=
op.heisenberg_tr
op.wires
thinking
fine
terms
result
matrices
entire
system
device
python
pennylane.wires
import
Wires
=
Wires
]
qml.Rotation
[
]
.heisenberg_tr
dev_wires
Outputs
Whereas
python
pennylane.wires
import
Wires
=
Wires
]
<
wires
qml.Rotation
[
]
.heisenberg_tr
dev_wires
Outputs
observable
transformation
Z
thinking
suggestion
queue
A^2
second-order
method
dependent
circuit
graph
cleaner
tape
tapes
measurements
equivalent
mutation
graph
graph
Minor
suggestion
suggestion
dim
*
*
self._reshape
self._pre_rotated_state
dim
dim
worth
tweak
standard
docstring
QubitDevice
state
density
matrix
circuit
QubitDevice
Density
matrices
tensors
such
entry
row
column
matrix
rho
[
]
rocket
*
sure
__init__
_create_basis_state
only
thing
__init__
DefaultQubit
self._apply_ops
harmless
Minor
thing
e.g
rho
=
np.zeros
*
*
*
*
dtype=np.complex128
rho
[
index
index
rho
=
self._asarray
rho
dtype=self.C_DTYPE
return
self._reshape
rho
]
*
*
self.num_wires
Might
worth
False
sure
device
example
capable
inverse
operations
reversible
differentiation
suggestion
def
__init__
wires=1
*
shots=1000
analytic=True
suggestion
operations
Looks
tests
nice
example
state
e.g.
mixed
state
GHZ
state
device
self._state
tests
future
PR
cool
method
Good
catch
suggestion
position
need
device
-the
constant
term
comment
one
helpful
thinking
suggestion
stored
final
state
original
circuit
suggestion
wires
device
differentiation
comment
suggestion
self._state
attribute
value
attribute
None
worth
[
]
https
//github.com/PennyLaneAI/pennylane/blob/781b322aba9a3f34353a2fc3a2db631b41870a15/pennylane/operation.py
L238
check
_user/developer_
input
internal
consistency
check
better
exception
assertion
suggestion
grad_method
validity
self.par_domain
R
None
F
raise
ValueError
Analytic
gradients
quantum
channels
method
thinking
Same
comment
validation
check
grad_method=
F
grad_method
suggestion
Kraus
matrices
quantum
channel
computational
basis
line
suggestion
equivalent
matrices
part
clear
time
state
[
sl_1
]
self.num_wires
axes
target
One-piece
first
wire
control
operation
equivalent
Might
worth
main
docstring
slices
axes
same
operation
text
suggestion
axes
]
larger
axes
]
state
[
sl_1
]
self.num_wires
axes
Minor
suggestion
following
python
trainable_idx
param_method
enumerate
diff_methods
param_method
trainable_idx
best
[
]
==
F
method
==
numeric
numeric
method
tapes
processing_fn
=
self.numeric_pd
trainable_idx
params=params
*
*
options
method
==
best
[
]
==
A
method
==
analytic
analytic
method
tapes
processing_fn
=
self.analytic_pd
trainable_idx
params=params
*
*
options
processing_fn
flat
list
device
all_tapes.extend
tapes
correct
result
parameter
number
tapes
tapes
change
logic
readability
extra
indent
Hmm
comment
outputs
way
hasattr
blind
tensor
deeper
dimension
subelement
Arg
module
tuple
onp.array
suggestion
Build
electronic
Hamiltonian
local
.xyz
file
suggestion
Compute
expectation
value
h
set
parameters
suggestion
return
self._obs_data
H._obs_data
pylint
disable=protected-access
suggestion
return
self._obs_data
==
H._obs_data
pylint
disable=protected-access
Same
comment
previous
comment
Observable
class
Same
comment
re
validation
suggestion
r
Hamiltonian
class
~.Observable
class
~.Tensor
class
~.Hamiltonian
object
equivalent
tf.reshape
grad_output
-1
]
conversion
necessary
suggestion
accepts
lists
*
Tensors
Variables
True
more
tf.squeeze
efficient
Does
convention
docstring
suggestion
https
//github.com/tensorflow/tensorflow/tree/master/tensorflow/python/eager/tape.py
L167
grad_output
grad_input
objects
reverse
thinking
Just
own
understanding
conversion
something
DefaultQubitTF
suggestion
gradient
tapes
False
Might
worth
reason
Oh
something
core
core
QNode
ragged
output
such
return
qml.probs
passthru
devices
edge
case
simple
solution
ragged
array
NumPy
ragged_array
.flatten
TensorFlow
above
_asarray
function
same
thing
change
test
passthru
devices
note
passthru
devices
tape
beta
Does
pytest
cli
test
suite
good
small
comment
comment
density
matrix
complete
system
second
comment
density
matrix
reduced
system
suggestion
autograd.core
import
make_vjp
_make_vjp
need
unused
import
roles
different
parameters
A
tape
parameters
jacobian
other
parameters
weird
artefact
eager
execution
setting
suitable
kind
computational
graph
inputs
placeholders
good
idea
Thanks
Tom
typo
suggestion
Evaluate
gradient
tape
respect
trainable
tape
parameters
provided
device
suggestion
analytic
mode
parameters
support
analytic
differentiation
method
analytic
numeric_params
ValueError
f
analytic
gradient
method
argument
numeric_params
Did
reason
suggestion
unwrap
constant
parameters
suggestion
re-importing
pkg_resources
slow
operation
systems
worth
comment
call
necessary
suggestion
logic
user's
case
Hermitian
involutory
question/comment
Oh
code
different
method
name
parameter_shift_exp_and_var
+1
mess
laughing
documentation
show
documentation
short
big
..
warning
box
deprecation
suggestion
qml.tape_mode_active
TODO
regarding
changes
restrictions
tape
mode
default
self._signature_validation_tape_mode
qnode
weight_shapes
=
qnode
self.qnode.to_torch
nodes_between
TODO
relevant
same
function
pattern
Qubit
CV
Reversible
tapes
tapes
ability
_first_
parameter
gradient
computation
Jacobian
redundant
device
executions
able
idx==0
parameter
gradient
idx
l
param_method
enumerate
zip
p_ind
allowed_param_methods
param_method
Independent
parameter
Skip
parameter
gradient
continue
best
[
]
==
F
method
==
numeric
finite
difference
method
g
=
self.numeric_pd
l
device
params=params
*
*
options
method
==
best
[
]
==
A
method
==
analytic
analytic
method
g
=
self.analytic_pd
l
device
params=params
*
*
options
first
parameter
check
idx=1
first
parameter
gradient
evaluation
anyone
elegant
way
knowledge
something
advantage
tape
approach
more
thinking
new
features
tape
example
great
able
something
between_ops
=
tape
[
+
]
tape
quantum
tape
generator
tape
apply_op
function
ADR
QuantumTape
diff_circuit
between_ops
.inv
qml.apply_op
generator
qml.apply_op
between_ops
device.execute
diff_circuit
matter
style
E.g.
python
tape
=
ReversibleTape
tape
AutogradInterface.apply
tape
tape
better
first
test
old
Variable
system
new
tape
system
Variable
class
_everything_
array
parameters
element
variable
list
differentiable
e.g.
b
qml.Hermitian
np.diag
c
d
>
[
b
c
d
]
value
parameter
c
e.g.
finite
difference
evaluation
tape
gate
arguments
unprocessed
b
qml.Hermitian
np.diag
c
d
>
[
b
np.array
[
[
c
]
d
]
]
only
way
vary
c
new
quantum
operation
qml.DiagonalHermitian
c
d
b
qml.DiagonalHermitian
c
d
>
[
b
c
honest
bad
thing
differentiable
operations
real
parameters
surprised
edge
case
_worked_
old
system
test
suggestion
Define
Hartree-Fock
state
suggestion
Build
electronic
Hamiltonian
local
.xyz
file
use
partial
Josh
templates
suggestion
state
suggestion
ParticleConservingU1
exception
parameter
array
Reshape
necessary
bc
fc
shape
num_series
prediction_length
ar
broadcastable
final
=
fc
+
ar
other
fc
dim
dim
x
num_series
better
docstring
method
output
networks
training
prediction
’
clear
nature
description
arguments
indented
new
line
estimator
mean
-1
axis
shape
loss
Shouldn
’
Note
ideal
shape
tensor
network
training
loop
average
batch
other
networks
convention
slicing
ret
relative
forecast
’
s
shape
point
time
purpose
this.
Just
FYI
[
]
>
train_model
case
right
reference
docstring
more
exposed
See
large
comment
models
DeepAR
Transformer
3-dimensional
tensors
binnings
dimensional
tensor
shape
pred_length
mean
scaler
output
pred_length
-shaped
tensors
different
dimensions
models
representation
tensor
expansion
input
mode
output
mode
larger
comment
more
large
comment
suggestion
[
target
np.array
[
]
start
pd.Timestamp
'2000-1-1-01
top
docstring
Data
test-cases
different
places
wrong
pytest.raises
test-case
suggestion
target
]
]
Great
thanks
datasets
FIXME
TODO
dynamic
features
static
categorical
features
suggestion
copyfile
docker_build_makefile_path
temp_dir_path
/
Makefile
docstrings
lot
👍
path
~/.mxnet/gluon-ts/feedforward/
expands
user
home
list
distribution
test
MultivariateGaussian
LowrankMultivariateGaussian
Uniform
instance
suggestion
TODO
work
means
stddevs
variances
similar
structure
cases
MultivariateGaussian
LowrankMultivariateGaussian
Uniform
’
documentation
difference
returns
new
Index
elements
index
other
forecast
end
time
series
middle
index
extracted
data
forecast
start
date
d
guess
consistency
iteration
comment
relative
imports
unaggregated
forecast
results
trivial
actual
forecasts
list
dicts
way
easier
convenient
aggregation
method
argument
right
evaluation
default
median
paper
specification
start_date
None
get
rid
mypy
complaint
https
//ci.mxnet.io/blue/rest/organizations/jenkins/pipelines/GluonTS-py3-cpu-unittest/branches/PR-553/runs/9/nodes/42/steps/66/log/
start=0
forecast
start
date
easier
way
suggestion
Prediction
sample
Shape
batch_size
prediction_length
axis=0
order
shape
docstring
correct
one
SampleForecast
class
idea
method
subclass
interpretable
modes
F.dot
dense
layer
generic
mode
comment
mechanism
different
block
subtypes
suggestion
list
empty
string
definition
same
sample
idea
sample_rep
able
samples
case
Gaussian
samples
generic
Gaussian
distribution
samples
standard
normal
]
https
//github.com/awslabs/gluon-ts/blob/fbcb244da611767ecf961955a27ad0f39b029133/src/gluonts/distribution/gaussian.py
L103-L107
derivative
samples
mu
sigma
sure
Gamma
beta
parameter
sure
alpha
suggestion
beta=1.0
/
self.beta
suggestion
num_samples=num_samples
al
nice
documentation
class
documentation
style
Could
docstrings
numpy-style
PyCharm
style
strings
triple-quotes
Could
type
annotations
functions
edge
case
theory
values
distributions
-inf
value
nan
proper
distribution
-inf
paper
docstring
mentions
regularization
L2
L2
norm
function
TAR
squared
L2
norm
state
vector
batch
something
use
output-data-dir
_
sure
distinction
dataset
suggestion
None
problem
code_bucket
im
something
penalty
Validation
pass
Training
phase
separate
TrainingData
loader
Basically
same
case
InferenceDataLoader
second
Inference
same
loader
values
main
idea
depleted
worker
many
times
Due
current
implementation
way
worker
new
batch
worker
example
same
ValidationDataLoader
epoch
process
new
pool
Validation
iteration
costly
etc
blanks
begin
lines
Please
paste
link
original
file
mark
lines
lines
TODO
comment
special
Please
nosec
comment
Please
unnecessary
comment
Please
comment
English
Please
comment
English
Please
unused
code
comment
step
instance
workload
score
workload
timestamp
timestamp
end.
enough
Deleted
def
get_all_nodes_where_jobs_where_run_in_stage
stage_index
int
list
[
task.node
task
self.get_all_tasks_in_stage_on_nodes
stage_index
]
felidadae
s/seperate/separate
variable
dd
Damian
need
variable
fragmented
code
code
Break
seams
Please
code
Delete
comment
Uncomment
Validate
file
full
sentences
comment
cpus
cpu_limits
kubernetes
suggestion
x
=
pm.DensityDist
pylint
disable=unused-variable
colon
pylint
disable=unused-variable
conversation
previous
comment
sense
presence
log
likelihood
group
values
waic
several
issues
test
possible
test
fails
example
default
scale
waic
loo
results
waic
log
likelihood
data
waic
tests
converter
tests
following
approaches
*
random
seeding
trustworthy
first
row
something
aganist
values
*
simpler
subject
quantity
mean
*
posterior
log
likelihood
samples
inference
data
samples
posterior
observed
data
fixture
first
row
log
likelihood
values
curiosity
attribute
access
different
posterior
sizes
_warmup_posterior
dims
number
chains
draws
cases
_
warmup
exception
type
vary
possible
great
pylint
exception
weird
expression
lines
docstring
fixture
other
PR
code
fixture
extend
create
idata2
=
create_
idata
different
fixture
line
comment
helpful
similar
comment
above
type
error
value
error
assertion
error
custom
message
Positive
integer/float
values
simplified
version
def
bw_check
bw
isinstance
bw
bool
return
Bool
isinstance
bw
int
float
return
bw
<
elif
isinstance
bw
str
return
string_bw
return
unrecognized
return
print
bw_check
True
print
bw_check
-1
print
bw_check
'abc
print
bw_check
[
]
print
bw_check
Bool
bw
string_bw
unrecognized
sure
numpydoc
lint
docstrings
same
line
Thanks
similar
case
list
numbers
kde_linear
kde_circular
functions
grid_len=512
user
pass
numbers
mention
docstring
reasonable
ranges
docstring
Use
os.makedirs
path
exist_ok=True
need
try-except
multiple
new
subdirs
comment
scope
diasable
curiosity
consistent
amount
bins
example
data
bins
N
data
auto
chains
maximum
bin_count
use
own
sturges
R
def
sturges
ary
return
int
np.mean
counts
counts.size
=
edges
correct
align=
center
bins=
]
[
-1
]
/2
[
image
]
https
//user-images.githubusercontent.com/13161958/54903670-1cd96f80-4ee5-11e9-812a-423938e7a9c0.png
comments
attribution
listify
validator
indentation
error
filename
end
function
touch
ambigious
directories
more
clear
backseat
coding
commented
code
@
mateumann
cleaner
required
services
list
target_service
target_services
service.restart
target_service
ignore_failure=True
amount
restart
readable
drop
commented
code
plz
note
rpms
comment
sources.py
python
side
suggestion
permissions
os.path.exists
ls
comment
else
add
naming
function
clear
todo
least
correct
thing
check
thing
external
rabbitmq
node
response
os.system
return
code
reason
built-in
run
utility
methods
ignore_failures=True
exit
status
error
way
regards
commands
place
simpler
way
return
returncode
e.g
response.returncode
return
response.returncode
way
return
response
==
warning
message
future
sake
Done
Во-первых
X
уже
и
так
строка
потому
что
функция
input
возвращает
строковый
тип
данных
чего
бы
там
пользователь
не
ввел
Во-вторых
это
символов
в
строке
А
как
проверить
длину
строки
Тела
циклов
*
*
file
files
*
*
и
*
*
directory
dirs
*
*
очень
похожи
смысл
сделать
код
чуть
более
универсальным
и
вынести
в
отдельную
функцию
было
проще
time.time
os.path.getctime
path
сразу
в
секундах
предыдущему
комментарию
эта
функция
не
относится
к
классу
Shuffler
то
она
должна
находится
с
ним
на
одном
уровне
это
как
раз
и
будет
функция
верхнего
уровня
Тут
уже
сложнее
Менеджер
контекста
блок
для
автоматического
освобождения
ресурса
данном
случае
этот
ресурс
файл
f.
При
выходе
из
блока
менеджера
контекста
файл
автоматически
закроется
и
нельзя
будет
использовать
внутри
блока
менеджера
контекста
должно
находиться
все
что
связано
с
использованием
f.
Как
я
вижу
использование
переменной
ограничивается
строкой
Логично
предположить
что
за
этой
строкой
блок
менеджера
контекста
должен
закончиться
mp3s
[
]
должна
лежать
вне
блока
менеджера
контекста
но
внутри
метода
restore
кстати
можно
сказать
и
про
циклы
в
и
А
эта
функция
относится
к
классу
Shuffler
Если
то
она
должна
находится
с
ним
на
одном
уровне
это
как
раз
и
будет
функция
верхнего
уровня
Если
функции
находится
внутри
определения
класса
т.е
является
методом
как
в
данном
случае
то
это
уже
не
функция
верхнего
уровня
класс
тут
похоже
уже
закончился
Не
согласен
строка
относится
к
блоку
предыдущему
комментарию
строка
относится
к
блоку
место
для
этой
нагрузки
строка
вместо
pass
Данный
ContextManager
предназначен
для
подсчета
временных
затрат
любого
кода
внутри
блока
restore_path
и
соответствующий
файл
никак
внутри
цикла
path
hashname
mp3s
не
меняются
логично
предположить
что
os.remove
restore_path
этому
циклу
относиться
не
должна
Скорее
отступы
лишние
т.к
mp3s
=
[
]
относится
к
блоку
менеджера
контекста
Вроде
и
так
многовато
отступов
Вызов
main
относится
ни
к
одной
из
функций
объявленных
выше
самостоятельный
блок
кода
Учитывая
что
parse_arguments
использует
self
эта
функция
вряд
ли
является
методом
класса
Shuffler
Поэтому
то
что
она
с
ним
на
одном
уровне
по
отступам
это
правильно
main
не
относится
к
классу
Shuffler
просто
функция
конце
строки
только
одна
лишняя
скобка
другая
лишняя
скобка
в
середине
вот
здесь
все
интересно
По
сути
и
это
открытие
файла
и
запись
в
него
содержимого
self.map
соответственно
мы
добавим
отступы
то
запись
в
файл
будет
выполняться
на
каждой
итерации
цикла
Если
уберем
то
один
раз
после
цикла
вариант
выбрать
rename
можно
считать
одним
словом
Не
проще
ли
было
бы
инвертировать
словарь
чтоб
искать
в
нем
по
ключу
а
не
по
значению
res.append
secret.get
ch
ch
Зачем
преобразовывать
полученное
в
список
Все
равно
в
последующем
вы
не
меняете
его
элементы
а
создаете
новый
список
alignment
style
rule
hashname
contradict
PyCharm
probable
mistakes
style
issue
Which
brackets
same
variable
name
Which
bracket
extra
И
функция
SUM
соответственно
в
SQL
есть
функция
MAX
что
пригодилось
бы
для
поиска
max
BG.Quantity
Желательно
было
бы
реализовать
эту
задачу
через
sqlalchemy
гарантировать
универсальность
решения
реализации
клиента
для
реляционной
БД
правильным
подходом
считается
имплементировать
все
операции
по
выборке
сортировке
и
фильтрации
в
самом
SQL
запросе
чтоб
они
выполнялись
сразу
СУБД
а
не
клиентом
подход
неэффективен
и
крайне
нежелателен
т.к
выполняет
эти
операции
гораздо
быстрее
К
примеру
для
подсчета
количества
товаров
прямо
в
исходном
SQL
запросе
можно
использовать
вложенный
запрос
с
функцией
COUNT
column_name
Мы
изменяем
атрибут
экземпляра
извне
используя
атрибут
этого
же
экземпляра
как
в
автоматическом
пистолете
патрон
из
обоймы
в
патронник
руками
перекладывать
как
нарушение
инкапсуляции
класса
standart_Charachter
должен
знать
что
такое
list
кстати
нехорошо
использовать
ключевые
слова
языка
в
качестве
имен
переменных
что
у
него
есть
0-й
элемент
если
он
есть
у
которого
есть
метод
use
....
Сработает
ли
это
для
такой
строки
Иван
Иванович
Лайфхак
для
Python
как
поменять
значения
переменных
[
i
[
j
]
[
j
]
[
i
Здесь
лишние
пробелы
т.к
блоке
переменная
mp3s
никак
не
используется
поэтому
нет
смысла
вносить
ее
в
этот
блок
дополнительными
отступами
С
все
ОК
вот
нужны
ли
здесь
пробелы
В
зависимости
от
их
наличия
запись
списка
map
в
файл
будет
осуществляться
либо
на
каждой
итерации
цикла
либо
однократно
после
цикла
когда
map
полностью
заполнится
При
этом
нужно
учитывать
что
операция
записи
в
файл
относительно
медленная
важный
вопрос
отступы
лишние
или
наоборот
недостающие
А
нужен
ли
здесь
отступ
Только
не
пробелы
а
скобки
ли
вносить
строки
в
цикл
Что
если
здесь
при
записи
в
файл
происходит
исключение
Например
если
отсутствуют
права
для
изменения
файла
скорость
непринципиальна
то
можно
протестировать
так
python
hero_list
=
[
po
shifu
tigress
monkey
viper
mantis
]
h
hero_list
h.move
some_speed
думал
о
таком
он
короче
конечно
же
но
в
лоб
и
прост
Что
безусловно
достоинство
мне
хотелось
потренироваться
на
срезах
же
я
его
туда
впишу
под
lines
21-25
more
pythonic
way
swap
list1
[
min_ind
]
list1
[
el
]
=
[
el
]
[
min_ind
]
task
u-element
place
min
element
test
example
significant
part
tested
code
better
elements
list
string
.join
res_list
troubles
spaces
symbols
end
string
incorrect
result
example
sss
ancient
city
>
Spartais
ancient
city
словарем
все
в
порядке
его
необязательно
копировать
т.к
не
менялся
i
данном
это
индекс
элемента
а
не
сам
элемент
такой
реализации
все-таки
лишний
просто
написать
s1
[
i
=
d
[
s1
[
i
]
better
del_find
function
updated
matrix
result
после
start
вы
сразу
вызываете
join
то
никакого
параллелизма
не
получится
запускали
код
под
Linux
или
Windows
Под
Windows
в
дочерних
процессах
будет
выполнен
весь
код
лежащий
в
глобальной
области
видимости
т.е
последовательный
расчет
и
потоки
Выражение
после
return
брать
в
скобки
необязательно
еще
для
интереса
при
решении
задачи
можно
использовать
транспонирование
матрицы
т.е
столбцов
в
строки
result
=
[
[
row
[
i
row
M
]
i
range
M
]
удалить
элементы
из
списка
result
теперь
достаточно
просто
=
[
result
[
j
]
j
range
result
result
[
j
]
]
ну
и
не
забываем
перед
выводом
транспонировать
отредактированную
матрицу
обратно
здесь
не
очень
понял
наследования
не
решает
этой
задачи
Я
должен
и
в
дочернем
классе
создавать
конструктор
Класс
Man1
это
отступление
от
задания.Сделал
просто
так
Обязательно
ли
делать
эту
проверку
Может
рекурсивный
вызов
del_in_dir
сам
разберется
есть
что
удалять
в
папке
или
нет
Worth
comment
connection
values
fine
future
PR
scope
ignore
suggestion
loader
=
SourceFileLoader
name
path
return
loader.load_module
type
ignore
comment
page
iterator
self._first_iteration
true
sense
set
updates
top
fresh
LBAModel
saves
update_item
update_item
issue
item
update
calls
change
change
update_item
TypeError
string
new
exception
type
such
AttributeDeserializationError
attribute
name
context
AttributeDeserializationError
attr_name=attr_name
e
msg
attr
name
init
AttributeDeserializationError
TypeError
new
exception
nice
test
path
new
pynamo
exception
attribute
name
context
SomePynamoExc
e
original
TypeError
context
ikonst
thoughts
comment
incomplete
type
ignore
comment
particular
bug
variable
flags
cleaner
solution
whole
thing
direct
path
file
Seems
much
simpler
Python
UTF-8
default
encoding
need
Exceptions
identifier
lowercase
+1
point
open_api
inconsistency
openapi_spec_validator
links
inline
reference
style
Lorem
ipsum
dolor
sit
amet
consectetur
elit
]
incididunt
ut
labore
et
dolore
magna
]
]
http
//google.com/
]
http
//github.com/
int64
whereas
string
names
Markdown
backticks
general
Markdown
code
comments
docstring
line
method
internal
linter
methods
Returns
sections
docstring
sure
purpose
comments
comment
line
continuation
Thank
detailed
comment
changes
Same
comment
test
name
something
testReferencesInCompositeTypesAreCorrectlyProcessed
something
lines
FYI
need
type-equality
functions
Almost
assertEqual
proper
function
https
//docs.python.org/3/library/unittest.html
unittest.TestCase.addTypeEqualityFunc
Same
comment
test
method
name
Same
comment
test
name
testRouteResultsArePresentInOpenApiSpec
something
lines
single
assertEqual
whole
schema
variable
slashes
non-empty
strings
Empty
path
components
meaning
ip
nearby
further
bug
nested
stack
creation
vpc
use
custom
node
only
thing
extra_json
due
recipes
conditional
Small
comment
var_name.upper
statement
log.warn
variable
comment
function
better
name
function
something
more
intention
test
single-sentence
docstring
function
elif
same
thing
comment
fact
user
known
hosts
file
comment
fact
user
known
hosts
file
documentation
-1
value
ToPort
FromPort
attributes
port_to_check
range
FromPort
from_port
to_port
variables
comment
regions
list
patch
WARNING
empty
string
valid
JSON
param
Thanks
same
global
variable
global
variable
single
place
bucket=Null
first
parameter
place
args
complex
structure
def
_get_bucket_name
region
bucket=Null
_get_bucket_name
region
args.bucket
global
sets
main
function
_aws_ls
function
errors
same
valid
bck
cp
functions
def
_aws_ls
s3
region
bucket_name
key
errors
=
s3.list_objects_v2
Bucket=bucket_name
Prefix=key
Contents
[
]
errors.add
region
return
errors
static
class
variables
locking
mechanism
general
code
simple
possible
tests
tests
code
standalone
script
snapshot
regions
snapshots
public
overhead
tests
execution
public
everybody
tests
snapshot
uncommented
typo
Could
comment
reason
region
enable_efa
comment
Create
__fail
function
print
exit
try/catch
blocks
nitpick
centos6
literal
places
fact
IMPI
available
sense
list
doesnt_support_impi
=
centos6
comment
matters
test
context
easier
conditionals
OS
list
comment
end
line
easy
unlikely
event
support
architecture
os.path.sep
different
separator
pytest
test
parameters
cluster
big
instance
something
c5.large
most
c5.2xlarge
pcluster
ami
vanilla
ami
pcluster
create
common
cases
AMI
standard
naming
comment
quick
assertion
wrong_os
=
os
case
dimensions
accident
future
architecture
validity
SGE
cfn_value
way
something
unexpected
comment
code
[
-1
]
logic
spot
let
pick
biggest
regions
such
us-east-1
let
leftover
copy/paste
fewer
compute
nodes
ideal
scancel
timeout
possible
free
addresses
Please
word
master
code/comment
Please
double
check
rest
code
issue
Minor
comment
clear
something
Do
master/compute_subnet_ids
inputs
pcluster
configure
subnet
config
file
default
test
subnet
config
desired
instance
type
result
pcluster
configure
first
subnet
list
subnets
Minor
comment
clear
test
code
other
rare
instance
type
information
clear
exact
case
something
test
other
rare
instance
type
AZ
example
case
future
maintainers
path
forward
test
expensive
rare
instance
type
Minor
comment
Comment
clear
goal
something
c5.xlarge
m6g.xlarge
use1-az3
test
code
case
specific
instance
type
available
chosen
subnet
check
improvements
valid
general
s3
uri
pre
post
install
script
parameters
short
comment
nested-loop
purpose
loop
hard
less
time
purpose
Get
paths
dockerfiles
patch
versions
framework
major.minor
version
TODO
p3dn
test
DISABLE_NON_EI_MODE
ENABLE_EI_MODE
function
bit
tough
condition
ei_dedicated
entries
DISABLE_FRAMEWORK_TESTS
non-EI
containers
robust
changeset-based
solution
warning
message
Build
more
EI
containers
non-EI
buid/test
note
i
rid
..
ls
-a
i
safe
other
files
present
/tmp
folder
file
robust
method
'stray_artifacts
list
regex
patterns
ignore
list
patterns
java
artifacts
/tmp
MMS/torchservce
start
Nit
comment
TODO
test
timeout
failures
p2.8xlarge
Nit
comment
TODO
test
timeout
failures
m4.16xlarge
image
uri
staticmethod
image_uri
others
leftover
something
comment
nit
fill
rest
docstring
None
required
marker
temporary
Could
bit
context
comment
nit
f
string
nit
future
PRs
case
latency/throughput
values
units
such
sec
samples/sec
dead
code
Let
plotting
accuracy
precision
recall
constant
top
Nit
comment
suggestion
latest
metric
point
%
lower
previous
warning
exit
Nit
constant
top
ninety_five_percent
generic
name
Ca
type
annotation
defaultdict
Nit
code
Let
assert
somebody
bad
dependency
type
annotation
sure
get_id
BugCoupleModel
tuple
bugs
all_ids
better
something
non_duplicate_ids
Nit
comment
line
variable
other
cases
second
part
comment
Remember
sets
slow
lists
lists
part
Assert
commits
e.g
Python
assert
ec01c146f756b74d18e4892b4fd3aecba00da93e
c
[
node
]
c
retrieved_commits
RCA
values
keywords
whiteboard
follow-up
whiteboard
feature
Nit
need
function
inline
outer
function
get_labels
Nit
inside
get_labels
comment
whiteboard
line
suggestion
Case
subcategories
rca
present
list
suggestion
Show
warning
route
comment
stepstoreproduce
model
key
labels
shap_sums
array
True/False
feature
positive
negative
test_bugs
combinations
comment
classification
m.classify
list
list
single
element
list
predictions
probabilities=True
probabilities
purge_expired_entries
way
last_purged_time
attribute
suggestion
thread
sleep
time.sleep
control
main
thread
test
new
URL
Nit
Detect
spacy
optional
dependency
point
Spacy
Gensim
separate
optional
deps
Nit
Detect
gensim
optional
dependency
point
Spacy
Gensim
separate
optional
deps
Nit
black-compliant
suggestion
Silence
clean
method
nice
test
parent
available
local
repo
available
remote
repo
spaces
previus
line
second
line
less
same
point
previous
line
continue
use
elif
next
line
Nit
TODO
comment
inconsistencies
bugs
passes
inconsistencies
bugs
inconsistent
first
pass
keywords
keywords
get_labels
suggestion
Store
task
ID
id_mapping
dictionary
dependencies
way
tasks
order
required
data
fixture
DB
test
useless
commented
lines
get_model
model_zoo.py
function
comment
c
s
classification
segmentation
models
confusing
name
better
docstring
wrong
Remove
unnecessary
comments
lines
explanations
code
Please
lines
quantization
code
hardcode
numbers
official
data
split
comments
links
param
Usually
numbers
function
typo
align
Add
sentences
%
ICNet
requirement
input
size
multiples
generate
id_rsa
id_rsa.pub
node1
copy
file
nodes
node
authorized_keys
content
id_rsa.pub
import
Add
model
name
command
videos
command
image
sequences
more
people
interested
unused
code
use
argparse
infinite
frames
Remove
lines
commented
block
reference
comment
code
block
commented-out
code
commented-out
code
value
standard
most
SiamRPN
values
future
better
arguments
users
values
hardcode
Please
lines
API
changes
rename
https
//github.com/apache/incubator-mxnet/issues/18046
effort
functions
parser.read
filepath
loads
workaround
readfp
python
version
code
clean
valid
empty
dirs
.pc
files
Remember
error
try/except
block
helper
function
little
bit
verbose
python
try
hKey
=
winreg.OpenKey
WindowsError
py2
EnvironmentError
py2
try
winreg.QueryValueEx
EnvironmentError
EnvironmentError
pass
Close
winreg.CloseKey
hKey
WindowsError
EnvironmentError
pass
context
manager
many
complexity
function
many
try/catch
blocks
normal
function
_system_registry_key
key
subkey
query
checks
try/catch
query
value
None
case
use
cases
installation_folder
is_64bits
vcvars
original
issue
Do
hidden
profile
files
python
filename
files
filename.startswith
continue
possible
Config
AFTER
project
set_vs_runtime
same
location
suggestion
toolchain
files
identical
multi-config
generator
information
build_type
available
'build
stage
suggestion
multi_filename
template
suggestion
file
configuration
variables
suggestion
multi_file
new
import
statement
concerns
diverge
early
difficult
common
parts
specialization
parts
fixes
other
platforms
others
isolated
differences
Android
toolchain
[
space
]
+
[
space
]
search_packages
slow
tbh
excited
approach
something
server
side
bug
Conan
API
meantime
client
side
try
search_packages
case
temporary
workaround
CXX
None
none_if_empty
necessary
os.environ
Pass
env
toolchain
constructor
something
point
abstraction
local
packaging
moment
issue
least
kind
disclaimer
block
code
link
issue
explanation
test
impossible
anyone
look
hack
@
staticmethod
idea
something
def
log_plugin
plugin_name
filename
=
plugin_path
=
try
self.plugins
plugin_name
]
=
self._load_module_from_file
plugin_path
NotFoundException
e
self.output.warn
....
re-raise
next
plugin
except
Exception
e
raise
ConanException
exception
classmethod
def
_load_module_from_file
cls
plugin_path
os.path.exists
plugin_path
raise
NotFoundException
performance
free
many
plugins
self.plugins
dictionary
different
way
python
self.plugins
defaultdict
list
def
_register_plugin
plugin_obj
method
dir
plugin_obj
functions
method
list_of_valid_methods_names
self.plugins
method.__name__
]
.append
plugin_obj
method
def
execute
method_name
*
*
kwargs
assert
method_name
list_of_valid_methods_names
plugin
method
self.plugins
[
method_name
]
method
output
*
*
kwargs
idea
centralized
place
set
functions
plugin
suggestion
Metadata
valid
package
revision
other
value
member
node
class
definition
value
meaning
sources
binary
self.package_revision
=
self.full_package_revision
PREV_UNKNOWN
sure
Conan
environment
script
env-vars
paths
test
need
Same
many
f.write
clean
template
folders
commands_file
content
matter
taste
fine
bit
confused
tests
same
environment
execution
checks
case
test
necessary
checks
setUpClass
except
module.__path__._path
[
]
comment
clear
assert
sure
concerned
performance
output
*
args/
*
*
kwargs
logger
handler
same
comment
other
levels
suggestion
ImportError
TODO
Python
fallback
old
Python
Conan
Yes
irrelevant
host
build_require
protoc
Build
profile
information
complete
scenario
gtest
package
something
useful
info
better
commented
default
False
others
scm_data
conanfile.py
file
nothing
dictionary
class
comment
advantage
regular
sort
order
reverse
Same
result
fine
Remove
print
/
methods
reasons
access
third
party
library
code
necessary
many
ways
._replace
Replace
original
string
new
url
parsed_url
fields
TODO
assignment
logic
cpp_info
environment
variables
RunEnvironment
common
place
recipe
reference
package
reference
behavior
conan-center-index
recipes
cmake_paths
generator
copy
paste
comment
original
source
apple_sdk_name
example
suggestion
line
output.splitlines
something
MSVC_TO_VS_VERSION
comment
meaning
numbers
misspelling
suggestion
UNKNOWN_COMPILER
=
CompilerId
None
None
None
None
Split
default
character
whitespace
suggestion
tokens
line.split
suggestion
elif
line.startswith
MSC_CMD_FLAGS=
something
cross_building
self._conanfile
cross
building
os_
cross-building
OS
ARCH
definitions
CMAKE_SYSTEM_NAME
]
=
.get
definitions
CMAKE_SYSTEM_NAME
]
Generic
CMake
warning
*
.cmake
file
sure
reason
straightforward
if/else
conditions
test
comment
nice
implementation
ARM
cross-compilation
os
host=Linux
os
build=Linux
arch
host=x86_64
arch
build=arm
[
CMake
docs
]
https
//cmake.org/cmake/help/v3.6/manual/cmake-toolchains.7.html
cross-compiling-for-linux
something
set
CMAKE_SYSTEM_NAME
Linux
test
CI
packages
binary
_defs_block_text
Installing
first
conan
requirements
constraints
suggestion
msbuild_version
>
=
http
//msbuildlog.com/
version
test
conan
config
install
offending
config
next
call
comment
hierarchy
ServerStore
revisions
bit
maintainable
ok
as-is
get_envs
lines
logic
bit
weird
comment
free
future
suggestion
fpic
self.info.options
comment
free
future
suggestion
other
self.info.options
link
docs
docs.conan.io
relevant
most
people
suggestion
'LibA
myoption
command
line
option
value
libb.lock
suggestion
def
partial_lock_option_conanfile_default_test
'LibA
myoption
other
packages
suggestion
'LibA
myoption
other
packages
https
//github.com/conan-io/conan/issues/4738
please
least
comment
code
new
new
corner
case
impossible
anyone
node.build_require
None
possible
stripped
version
signature=xxx
class
URL
real
case
artifact
disk
comment
checksum
file
cache
file
checksum
cache
definition
possible
invalid
checksum
cache
Please
Please
comment
trick
stderr
STDOUT
stout
PIPE
get_stream_lines
IMO
cppstd_default
iteration
useful
sure
other
issues
PRs
sure
function
implementation
stable
something
gnu
extensions
better
uploaded
method
_recipe_files_to_upload
policy
the_files
remote
remote_manifest
remote
snapshot
remote_snapshot
=
self._remote_manager.get_recipe_snapshot
ref
remote
lot
class
suggestion
Go
B
LibA/1.0
bit
risky
generator
only
modern
CMake
targets
generators
conan
cache
irrelevant
unused
elegant
solution
create
generators
end
consumer
package
creation
cache
Use
self.fail
....
test
nice
issue
Which
gcc
symlink
difficult
fine
as-is
feature
other
file
folder
known
ones
example
possible
python
files
recipes
legacy
possible
None
valid
value
many
recipes
functions
SCM
values
def
get_revision
try
return
Git
return
None
lines
layout
file
constructor
Workspace
object
LocalPackage
s
members
data
class
workspaces
definition
file
layout
Better
patterns
self.patterns
list
TODO
package_folder=base_path
local
folder
box
env-var
true
file
config_install_interval
default
conanfile
method
little
weird
static
method
conanfile
instance
triplet
generic
concept
building
course
pure
building
concept
triplet
function
tool
optional
compiler
parameter
exception
able
triplet
output
@
WDYT
same
None
empty
setting
value
profile
setting
setting
setting.yml
course
exception
generic
configurable
setting.yml
runtime
emscripten
https
//github.com/conan-io/conan/pull/1565
auto
good
values
setting
preprocessing
profile
thing
user
settings.yml
defaults
BadValue
exception
InvalidConanSettingField
smart
exception
sure
InvalidConanSettingField
unnecessary
Ok
related
question
opt-it
opt-out
sure
users
useful
profile
profile
runtime
=
auto
runtime
=
MT
auto
something
usage
Exception
type
bit
weak
safe
checks
settings
Exception
capture
Just
opinion
sure
best
approach
issue
message
json
right
way
application/json
header
present
risky
server
json
json
header
bug
protocols
own
test
server
server
old
servers
case
exception
json
decoding
please
imports
legit
besides
line
column
uncontrolled
exception
test
fail
try-except
Somewhere
lines
dirty
flag
file
download
get_package
call
dirty
flag
package
folder
folder
BaseException
possible
Lets
package
gcc
packageID1
compatible
gcc
packageID2
good
gcc
packageID2
fallback
IDs
conditional
packageID2
id
error
nothing
import
issue
issue
import
local
past
options
package
namespace
conan
install
reference
install
zlib/1.2.8
@
lasote/stable
shared=True
bad
copy
paste
options
profile
necessary
anything
pass
option
lines
necessary
test
fail
So
file
sense
json
output
empty
return
Totally
necessary
check
direct
requirements
indirect
TODO
version
semver
https
//docs.conan.io/en/latest/mastering/version_ranges.html
raw
string
r'\b
part
PR
check
update_object_on_enter
method
SimpleSliderEditor
LargeRangeSliderEditor
Idk
reason
tests
failure
self.control
None
check
problem
same
way
other
editor
style
change
test
change
separate
PR
reasonable
Sure
thing
comment
line
number
recommended
testing
practices
[
test
pyramid
]
https
//martinfowler.com/bliki/TestPyramid.html
[
trophy
]
https
//kentcdodds.com/blog/write-tests
speaking
tests
fast
cheap
developers
likely
test
feedbacks
errors
small
failure
help
source
bug
tests
different
behaviour
other
single
test
first
failure
rest
whole
picture
test
demo
own
slow
lot
things
traitsui.tests.editors
developers
editor
specific
tests
tests
demo
different
purposes
demo
script
writing
tests
demo
test
changes
demo
changes
educational
reasons
demo
separate
repository
TraitsUI
demo
tests
editor
behaviour
developer
code
BooleanEditor
test_boolean_editor
tests
BooleanEditor
one
demo
test
demo
integration
test
suite
integration
test
suite
lot
slower
Suggestion
Could
test
logic
demo
such
different
test
objectives
simple
editor
custom
editor
trait
change
>
GUI
change
GUI
>
trait
change
demo
test
Unrelated
comment
tests
afterthought
tests
backwards
bigger
characteristics
tests
behaviour
code
easier
small
bits
pieces
comment
result
union
actions
helpful
future
developers
tests
obvious
Rows
flag
Same
obvious
Rows
flag
comment
helpful
test
UITester
events
end
test
self.addCleanup
process_cascade_events
case
wrapper.perform
None
process_cascade_events
handler
same
comment
above
Could
docstring
method
block
comment
majority
important
information
docstring
good
consistency
good
measure
https
//doc.qt.io/qt-5/qwidget.html
original
implementation
https
//code.woboq.org/qt5/qtbase/src/widgets/widgets/qpushbutton.cpp.html
_ZNK11QPushButton8sizeHintEv
Orthogonal
skip_if_not_qt4
skip_if_not_qt
logic
Qt
helper
function
utils
module
something
code
bit
complicated
comments
more
clear
code
QGridLayout
wx.GridSizer
strange
loops
row
order
default/
standard
behavior
column
order
use
incr
array
population
row
major
order
column
major
ordered
elements
https
//github.com/enthought/traitsui/blob/81902cc48f0af498d4f0f1a980dc8074da4d8265/traitsui/qt4/enum_editor.py
L334
https
//github.com/enthought/traitsui/blob/81902cc48f0af498d4f0f1a980dc8074da4d8265/traitsui/wx/enum_editor.py
L357
sure
reverse
order
Just
own
understanding
concept
priority
registries
handlers
solvers
same
type_
reverse
order
documentation
docs
highest
priority
registry
registry
someone
interaction
location
type_
suggestion
Order
registries
priority
suggestion
C
Copyright
2007-19
Enthought
Inc.
Austin
TX
suggestion
editor
class
comment
Sphinx
auto-documenters
comment
feature
mode='spinner
Wx
better
tester
support
code
Wx
SimpleSpinEditor
Nit
FIXME
comment
something
Yesterday
tests
Linux
machine
mine
PyQt5
few
tests
last
call
argument
mock
icon
bottom
right_origin
@
icons
top
left_origin
close
inspection
images
cache
painted
first
GUI
fine
same
failures
Travis/Appveyor
own
OSX
machine
indirect
test
image
way
assertion
bit
indirect
inconclusive
implementation
details
platforms
platforms
Qt
build
test
unreliable
reasonable
way
image
checks
assertion
enum_edit.value
good
Exception
defensive
nit
refactor
nice_name
_get_placeholder_node
function
response
comments
nice
short
docstrings
classes
re-using
code
copy
paste
import
bit
harsh
script
nasty
exception
user
traits
version
less
TraitsUI
install
requirement
Traits
>
something
guess
def
somename
try
traits.api
import
Union
ImportError
traits
traits.api
import
Either
return
Either
Range
Enum
b
default=1
return
Union
Range
Enum
b
default_value=1
good
example
difference
downside
though
branches
CI
comment
Union
Traits
>
back
tell
line
https
//flake8.pycqa.org/en/3.1.1/user/ignoring-errors.html
in-line-ignoring-errors
wx
function
wx
documentation
GetNextItem
item
items
indices
items
comment
item
context
item
index
view
factory
comment
corresponding
trait
wrong
value
trait
unset
good
model
trait
view
editor
internal
states
inconsistent
subsequent
change
events
example
user
index
value
object
trait
everything
fine
last
assertions
test
temporary
inconsistencies
bug
comment
right_click_item
function
Qt
implementation
context
menu
high
priority
test
Qt
anyways
point
Oh
docstrings
🤦
clear_selection
wx
branch
Select
function
code
selection
strip
removes
characters
interested
right
end
bit
rstrip
trailing
whitespace
CI
unhappy
add
licence
module
other
utility
Please
docstring
chm_htmlescape
add
typehints
comment
issue
problem
Same
above
comment
suggestion
start
raise
com.IbisInputError
end
point
non-negative
end
None
good
suggestion
motivation
behavior
value
op
scope
time
context
implementation
'.value
Scope
class
users
get_value
clear
window
change
suggestion
ibis.backends
sqlite
noqa
F401
comment
useful
same
python
pytest.raises
ModuleNotFoundError
con_kerberos_no_hdfs.table
'tpch_lineitem
look
sure
test
dependencies
dependencies
CI
green
second
case
true
dependencies
connect
dependencies
kerberos
server
CI
match=
pytest.raises
error
message
test
reliable
test
clearer
short
comment
helpful
something
connect
ImportError
dependencies
AttributeError/TTransportException
kerberos
available
something
anything
result
line
exceptiion
whole
block
please
method
dispatcher
other
wise
impl
only
row
window
Does
force
flag
something
DROP
TABLE
foo
IF
EXISTS
exception
pd.Series
np.ndarray
reason=
issue
number
strict=True
helpful
message
window
translation
rule
IntervalScalar
rule
IntervalScalar
@
compiles
IntervalScalar
def
compile_interval_scalar
interval
return
execute
interval
timedelta
=
t.translate
interval
time
second_since_epoch
=
int
timedelta.value
/
suggestion
ibis.backends
spark
noqa
F401
Same
comment
test
mark
xfail
ShiftBase
issue
constants
ibis/compat.py
same
comment
error
message
trailing_window
*
ibis.interval
days=1
order_by
=
..
filtering
time
clearer
hard
reason
]
filter
index
name
TIME_COL
Do
timecontext
function
>
function
error
message
bit
verbose
bit
decorators
dictionary
way
copy
.copy
quick
test
sure
great
Better
base_sql
comment
comment
aggregation
type
aggcontext
isinstance
aggcontext
Window
elif
isinstance
aggcontext
AssertionError
f
type
type
asggcontext
name
*
*
e.g
result
Series
vs
scalar
better
dispatch
rule
e.g
cases
issue
i
track
TODOs
long
pre-commit
black
step
care
formatting
things
\
lines
Does
accept
pred1
pred2
-style
predicates
Hm
chain
op
accesses
.copy
mutations
original
removeable
pep8
space
pound
sign
start
comment
Ah
issue
call
MockAdvertisingBLED112
back
class
iotile_transport_bled112/hardware/emulator
unit
mock
hack
test
code
more
sense
list
sets
member
set
identical
comment
clarification
Looks
debug
comment
comments
test
seperate
file
integration
tests
new
pattern
suggestion
cache
=
dict_cache.DictionaryCache
Set
timeout
test
problem
jenkins
free
Commented-out
code
Reason
next
task
workflow
code
amazing
commented-out
code
bit
simpler
code
pretty
similar
fashion
different
files
paths
constant
certs
Nothing
special
terms
ldap
queries
interaction
id
object
code
ods
code
https
//nhsconnect.github.io/gpconnect/integration_spine_directory_service.html
Commented-out
code
minor
point
logic
reverse
same
thing
test_mhs_details_lookup
case
clearer
same
assertion
Fixed
response
type
same
comment
other
tests
commented-out
code
Need
FHIRReference
Practitioner
more
string
comment
comment
style
way
literals
variable
comments
PEP
prefers
block
comments
https
//www.python.org/dev/peps/pep-0008/
block-comments
TODO-maybe
comment
bit
clearer
flow
function
comments
separate
method
TODO-bung
comment
<
>
details
example
pycharm
environment
variables
format
address
'bare
url
http
prefix
postfix
README
integration
tests
easier
code
Comment
outstanding
module
level
disables
comment
nice
towards
misprint
correspongint
big
deal
@
unittest.skip
function
benefit
skip
tests
skipped
test
test
future
Dataframe
functionality
comment
test
Ok
cool
glad
faster
benchmarks
action
np.unique
much
faster.
[
screen
shot
2017-05-01
pm
]
https
//cloud.githubusercontent.com/assets/2944777/25600135/fb3be148-2eaf-11e7-81cb-f4418efad653.png
error
message
[
features
key
argument
matrix/
dataframe
columns
....
combo
row
'features
argument
able
column
names
statement
features_
X
dataframe
__init__
docstring
addition
fit
X
OR
bonus
functionality
m-width
X
documentation
nice-to-have
feature
something
other
feature
visualizers
Awesome
thanks
TODO
fine
np.unique
python
set
thoughts
happy
gah
stray
comma
CI
rid
Hehe
author
file
copy
paste
error
test
results
def
test_alpha_param
Test
user
alpha
param
instantiation
Instantiate
prediction
error
plot
custom
alpha
visualizer
=
ResidualsPlot
Ridge
random_state=8893
Test
param
assert
visualizer.alpha
TODO
mock
ax
test
alpha
scatterplot
sure
Matplotlib
error
ValueError
Axes
instance
argument
figure
Mock
ax
visualizer
visualizer.ax
=
mock.MagicMock
autospec=True
visualizer.fit
self.data.X.train
self.data.y.train
test_residuals.py:372
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
..
/
..
/yellowbrick/regressor/residuals.py:463
fit
self.score
X
y
train=True
/
..
/yellowbrick/regressor/residuals.py:498
score
self.draw
scores
train=train
/
..
/yellowbrick/regressor/residuals.py:553
draw
plt.sca
self.ax
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
=
<
MagicMock
id='4632511600
>
def
sca
ax
current
Axes
instance
ax
*
current
Figure
parent
*
ax
*
managers
_pylab_helpers.Gcf.get_all_fig_managers
m
managers
ax
m.canvas.figure.axes
_pylab_helpers.Gcf.set_active
m
m.canvas.figure.sca
ax
return
>
raise
ValueError
Axes
instance
argument
figure
ValueError
Axes
instance
argument
figure
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py:963
ValueError
xfail
certain
windows
lines
import
sys
linter
error
Should
DispersionPlotTests
find_knee
__init__
need
visualizer
fit
predict
estimator
issue
later
revision
exception
YellowbrickWarning
bit
more
detail
warning
Excellent
elbow
knee
amused
time
knee_locator.knee
bbengfort
several
changes
code
first
code
review
look
new
code
comment
relevant
Great
test
good
kwargs
work
test
[
X
variables
L38
]
https
//github.com/DistrictDataLabs/yellowbrick/blob/develop/tests/test_classifier/test_class_prediction_error.py
L38
fine
ClassPredictionErrorTests
integration
test
real
data
set
+
pandas
PR
general
comment
favor
assertion
Just
discussion
Slack
issue
LogisticRegression
coefs_
property
shape
[
n_classes
n_features
]
https
//github.com/scikit-learn/scikit-learn/blob/master/sklearn/linear_model/logistic.py
L1100
column-wise
mean
e.g
axis=0
average
coefficient
classes
feature
importances
future
comment
feature
importances
multidim
array
shape
n_classes
n_features
average
column
shape
n_features
LogisticRegression
future
interesting
feature
importance
visualizer
shape
array
stacked
bar
chart
feature
importances
class/feature
combination
issue
signature
def
_handle_universal
X
y=None
signature
fit
y
parameter
X
case
control
logic
appropriate
place
lot
duplicated
code
cases
stack/frequency
stack/no-frequency
no-stack/frequency
no-stack/no-frequency
code
cases
share
primary
differences
look
case
comment
case
duplicate
code
happy
number
tricks
sleeve
happy
comments
control
flow
logic
other
handle
method
complex
function
choice
huge
switch
control
flow
low
possible
becomes
important
first
function
able
only
additions
several
modifications
draw
control
flow
logic
appropriate
level
lot
duplicate
code
amount
duplicated
code
functionality
case
comment
case
Same
comment
signature
self
X
y=None
docstring
efforts
control
flow
logic
issue
control
flow
high
logic
lot
code
following
control
flow
logic
python
idx
tagged_doc
enumerate
X
tagged_sent
tagged_doc
_
tag
tagged_sent
tag
SPACE
counter
correct
counter
arguments
=
self.pos_tag_counts_
[
y
[
idx
]
]
self.stack
self.pos_tag_counts_
counter
[
jump.get
tag
other
Note
results
same
number
loops
original
code
modification
readable
cost
unnecessary
idx
case
self.stack
False
cost
more
worth
easier
code
future
number
bugs
possible
class
yellowbrick.exceptions
capture
suppress
warnings
visualizer
=
BalancedBinningReference
ax=ax
bins=bins
target=target
*
*
kwargs
line
code
comment
point
projection
@
Kautumn06
@
pdamodaran
contributor
use
self.set_title
default
title
users
custom
title
init
Hey
@
ndanielsen
mdash
quick
methods
towards
full
visualizer
object
users
access
other
attributes
instance
is_fitted
estimator
move
towards
visual
pipelines
More
😉
@
bbengfort
instructive
purposes
new
maintainers
parameter-setting
Awesome
learned
parameters
self.range_
self.classes_
_target_color_type
Ok
while
bug
report
sure
same
page
classes=
argument
lines
bug
legend
correct
reason
comment
tolerance
legend
case
legend
Alternatives
legend
object
assert
image
similarity
tricky
tolerance
legend
legend
part
bug
finalize
solves
things
route
shorter
X_prime
more
sense
sure
note
cax
required
_target_type
==
CONTINUOUS
sure
e.g
different
layout
call
relationship
colormap
color
documentation
minor
nit
lower
case
Sequence
Integer
int
consistency
other
docstrings
specific
class
primitive
types
interfaces
color
vs
colormap
hold
Pandas
current
version
color
colormap
lot
sense
feature
visualizers
target
discrete
classifier
clusterer
color
cycle
discrete
list
colors
continuous
regression
colormap
Ben
notes
color
resolve_colors
top
head
color
refers
discrete
sequence
colors
color
string
tuple
float
list
strings
list
floats
list
tuples
most
cases
list
strings
list
tuples
float
grayscale
value
tuple
RGB/A
value
string
color
name
reference
e.g
bgrmcyk
case
lists
string
name
palette
e.g
Set1
colormap
refers
continuous
sequence
colors
colormap
string
collection
string
name
colormap
e.g
RdBu
string
_r
end
colormap
e.g
RdBu_r
string
name
palette
ListedColorMap
collection
colors
ListedColorMap
distinct
n
colors
things
slice
discrete
colors
cycle
n
>
len
colors
colors
colormap
n
exact
color
values
heatmap
colormap
colorbar
color
legend
start
thoughts
less
Might
tiny
simplification
refactoring
computation
thresholds
python
uplots
=
uniform_precision_plots
uniform_recall_plots
uniform_queue_rate_plots
Compute
curves
precision
recall
queue
rate
uniform_plot
color
zip
uplots
color_values
lower
median
upper
plots
lower
median
upper
=
mstats.mquantiles
uniform_plot
prob=self.quantiles
axis=0
Draw
median
line
self.ax.plot
uniform_thresholds
median
color=color
Draw
fill
lower
upper
bounds
self.ax.fill_between
uniform_thresholds
upper
lower
alpha=0.5
linewidth=0
color=color
May
easier
changes
utils.helpers.py
support
structured
arrays
validations
__init__
bit
confused
while
dimensionality
y_pred
decision
binary
_get_y_scores
decision_function
predict_proba
array
possible
bit
comment
future
likely
note
len
y_pred.shape
equivalent
condition
ID
line
special
revision
master
something
ID
setup.py
[
]
benjamin
@
GitHub
username
email
email
commit
document
line
timestamp
Mon
Apr
-0400
pyflake
tests
rid
unused
imports
issue
tests
membership
legend
super
slick
new
input
ask
pandas
support
test
Might
nice
todo
docs
images
few
different
versions
JointPlot
e.g
hex
few
different
correlation
measures
feature-feature-target
heatmap
option
docstring
use
map
range
functions
memory
safe
generators
awesome
list
comprehension
points
stellar
fact
first
comment
points
np.array
job
issue
order
brilliant
comprehension
length
words
advance
list
X
line
ignore
case
list
str.lower
text
line
scary
X
large
case
text
generator
line
everything
memory
following
code
single
iteration
data
generator
element
memory
time
second
function
generator
yield
statements
def
_compute_dispersion
text
Enumerate
generator
text
x
word
enumerate
text
self.ignore_case
word
word.lower
NOTE
indices
duplicate
words
supplied
case
word
target
words
empty
list
data
y
self.target_words_
==
word
.nonzero
]
yield
def
fit
text
Create
index
e.g
y
position
target
words
=
np.array
self.words
self.ignore_case
self.target_words_
=
np.array
[
w.lower
w
self.target_words_
]
Stack
array
generator
points
np.stack
self._compute_dispersion
text
self.draw
points
draw
function
access
first
column
points
[
,0
]
second
column
points
[
,1
]
sad
code
comprehension
performance
visualizer
2-3x
Good
catch
Awesome
correlation
plot
look
great
option
False
features
coef
case
user
features
index
something
Good
catch
good
idea
discovered
target
type
learned
attribute
docstring
users
issues
target
types
binary
multiclass
RE
discussion
info
R
case
R
argument
method
self.scores_
scores
available
user
work
self.title
=
kwargs.pop
'title
None
Visualizer.title
property
attribute
default
title
See
comment
Thank
warning
more
explicit
components
plots
plots
future
n_components
requires_default_neighbors
'lle
'ltsa
'isomap
'hessian
'spectral
self.n_neighbors
None
transformer
requires_default_neighbors
transformer
==
'hessian
self.n_neighbors
+
n_components
*
+
n_components
self.n_neighbors
warnmsg
=
please
explicity
specify
manifold
.format
self.n_neighbors
transfomrer
warnings.warn
warnmsg
good
Yellowbrick
class
hierarchy
Nice
function
useful
GridSearchVisualizers
base.py
method
GridSearchVisualizer
user
metric
input
visualizer
mean_fit_time
Ok
sure
param
mask
cv
results
dictionary
real
values
unique
values
categories
grid
couple
notes
+
param_1
easier
variables
mask
array
results
store
parameter
grid
search
KeyError
better
yellowbrick
key
error
e.g
YellowbrickKeyError
YellowbrickError
KeyError
parameter
grid
search
obvious
user
motivation
intermediate
data
structure
possible
max
score
point
user
MultipleVisualzer.ax
current
axes
axarr
_ax
correct
behavior
akin
following
@
property
def
ax
Override
Visualizer.ax
current
axis
return
plt.gca
ax.setter
def
ax
raise
YellowbrickTypeError
new
axes
objects
multiple
visualizers
gallery
plt.tight_layout
tick
labels
reasonable
call
Happy
self.tag_map
learned
parameter
estimator
fit
user
access
data
Therefore
property
self.tag_map_
underscore
suffix
e.g
sklearn
convention
bit
self.pos_tag_counts_
Attributes
section
class
such
[
example
]
https
//github.com/DistrictDataLabs/yellowbrick/blob/develop/yellowbrick/features/importances.py
L86
Minor
notes
review
process
self._penn_tag_map
self._uni_tag_map
candidates
@
property
decorators
functions
mutable
data
structures
successive
calls
nice
handle
methods
extensive
larger
tagsets
manageable
number
larger
human-understandable
word
classes
use
visualizer
distillation
documentation
alternative
case
statements
jump
table
jump
=
proper
regular
nouns
NOUN
noun
PROPN
noun
ADJ
adjective
VERB
verb
particles
adverbs
ADV
adverb
PART
adverb
ADP
adposition
PRON
pronoun
CCONJ
conjunction
PUNCT
punctuation
DET
determiner
NUM
number
INTJ
interjection
SYM
symbol
tagged_doc
X
tagged_sent
tagged_doc
_
tag
tagged_sent
tag
SPACE
self.tag_map_
[
jump.get
tag
other
change
worst
case
everything
other
same
performance
best
case
everything
noun
change
noticible
much
larger
corpora
e.g
gigabytes
data
alternate
formulation
e.g
readable/maintainable
good
reason
technical
debt
case
visualizer
much
larger
datasets
note
fact
*
audio
correct
name
RVFileSource
TODO
specific
comments
EDL
transition
events
comments
Cool
curious
import
rv/plugins/Python
dir
aware
robust
RVs
less
seconds
sort
semaphore
reliable
comment
python3-style
format
method
formatting
OTIO
suggestion
raise
NotImplementedError
.format
type
segment
suggestion
import
aaf2
noqa
E402
lines
linter
imports
top
record_out
understand
different
license
text
rest
OTIO
Are
able
exact
same
license
other
files
note
B
None
Same
something
note
B
E
little
more
sense
exception
sys.exit
behavior
caller
special
media_linker
code
special
_FORMATTER
specific
field
¯\\\_
ツ
suggestion
json
outputs
non-relevant
information
dict.get
None
suggestion
clip.metadata.get
'cmx_3600
None
None
suggestion
'cmx_3600
None
precedent
file
¯\\\_
ツ
\_/¯
comment
pyaaf2
borks
reason
floats
borking
Mark
assertRaises
syntax
see
https
//github.com/PixarAnimationStudios/OpenTimelineIO/blob/f5a4480d7418cfbfea6b7604e9d28b46e4c683aa/tests/test_opentime.py
L88
Could
second
test
method
values
suggestion
internal
membership
_child_lookup
suggestion
children
unique
set
children
__contain__
checks
suggestion
membership
set
_child_lookup
nit
field
names
keyword
args
format
method
templates
sounds
good
small
change
sure
protocol
difference
current
link
chooser
validation
people
custom
link
choosers
invalid
links
test
filter
reason
zero-width
spaces
something
real-world
usage
example
content
Word
document
good
reason
document
multiple
zero-width
spaces
harm
case
non-essential
changes
building
m2m_dict
comment
block
Otherwise
m2m
dict
updating
Note
issue
exceptions
Django
ORM
Could
something
python
try
current_site
=
context
[
'request
]
.site
KeyError
AttributeError
page
None
page
=
Page.objects
important
character
words
backslashes
tsquery
documentation
]
https
//www.postgresql.org/docs/11/datatype-textsearch.html
backslashes
example
available
better
place
RawSearchQuery
please
PR
change
new
.replace
'\\\\
line
https
//github.com/wagtail/wagtail/blob/ddc5f1c21c74a1ea9a2ae819fe1dfce419655808/wagtail/contrib/postgres_search/models.py
L21
operation
weird
get
rid
comment
code
Could
[
RuntimeError
]
https
//docs.python.org/3/library/exceptions.html
RuntimeError
message
Page.copy
unsaved
page
[
RuntimeError
]
https
//docs.python.org/3/library/exceptions.html
RuntimeError
@
caronc
comment
test
case
monotonic
clock
test
real
clock
comment
constructor
backwards
compatibility
alternative
multiple
branches
sure
clearer
transformation
=
'MISSING
constant
ssl_string_to_constant
=
CERT_REQUIRED
CERT_OPTIONAL
CERT_NONE
ssl_cert_reqs
=
ssl_string_to_constant.get
ssl_cert_reqs
ssl_cert_reqs
==
ssl_cert_reqs_missing
raise
Other
warnings
code
comments
please
small
typo
consists
consistent
comment
suggestion
hack
issue
link
link_error
rest
chain
suggestion
options
sig.options.copy
sig.freeze
self.request.id
comment
helper
code
intentions
TODO
support
Python
blank
line
end
file
Above
comment
incorrect
values
brightness
adjustable
point
previous
comment
values
other
properties
review
shorter
line
characters
line
characters
above
comment
pytest
assert
https
//docs.pytest.org/en/latest/assert.html
many
blank
lines
suggestion
Main
class
lumi.curtain.hagl05
curtain
suggestion
Motor
rotation
polarity
docstring
one-liner
need
newlines
comment
track_position
Mind
comment
slice
Same
comparison
cond
True
cond
nice
sort
description
specific
byte
indexes
short
informal
description
protocol
possible
readability
Plesse
comment
name
'Updater
least
spaces
inline
comment
more
comment
empty
props
main
class
way
need
sort
checking
API
same
matter
sort
device
above
comment
error
handling
commentary
docstring
Get
current
status
light
Example
is_on
false
brightness
rgb
unclear
correct
mean
context
unnecessary
description
docstring
way
visible
apidocs
is_on
=
brightness
Same
night
light
comment
wrt
color
names
sort
explanation
class
docstring
great
least
night
light
whole
light
support
line
characters
redefinition
unused
line
line
characters
line
contains
comparison
False
cond
False
comparison
cond
True
cond
least
spaces
inline
comment
comparison
False
cond
False
least
spaces
inline
comment
naked
underlying
exceptions
least
TODO
style
guidelines
sense
map
separate
mapping
file
perspective
easier
visibility
point
view
clear
class_name
underscores
comment
useful
Good
point
comment
example
Done
further
reference
PipelineNode
class
bottom
link
anytree
documentation
class
nit
comment
buckets
plans
right
todo
documentation
service
accounts
methods
IAM
policies
important
inventory
resource
plans
IAM
policies
okay
CL
TODO
https
//cloud.google.com/iam/reference/rest/v1/projects.serviceAccounts
class
docstring
good
line
Args
__init__
part
match
next
line
good
catch
method
bit
bit
clever
Hopefully
comments
easy
nit
please
extra
newline
consistency
newlines
docstrings
actual
name
scanner
error
level
more
appropriate
LOGGER.error
scanner
undefined
%
s
scanner.get
'name
convention
previous
comments
ditto
nit
todo
line
pylint
disable
.format
string
tablename
'violations
Same
comment
section
information
canonical
source
denzel-morris
How
inserts
python
method
nit
comment
util
[
function
]
https
//github.com/GoogleCloudPlatform/forseti-security/blob/master/google/cloud/security/common/util/parser.py
L49
util
function
possible
user
wild
card
matching
resource_type
folder
following
resource
type
folder
resource_ids
*
open
issue
IAM
scanner
violation
type
easier
i.e
ADDED
REMOVED
ENABLED_APIS_VIOLATION
user
actual
rule
name
violation
return
statement
line
return
empty
dict
pylint
scenario
user-triggered
forseti
process
cron
job
server
log
second
cron
job
due
first
next
mocked
tests
time
module
test
changes
Please
mocks
rewrite
tests
code
way
transparent
changes
underlying
module
Nothing
way
bugs
code
comment
reference
Same
above
Andrew
module
class
variable
domains
groups
TODO
best
way
results
Same
comment
form
TODO
method
multiple
places
https
//github.com/GoogleCloudPlatform/forseti-security/search
utf8=
%
E2
%
%
common
util
method
regex_util.py
https
//github.com/GoogleCloudPlatform/forseti-security/tree/master/google/cloud/security/common/util
Yes
TODO
fine
care
later
Thanks
super
nit
Comments
complete
sentence
find_policy_violations
something
base_rule_engine
design
scanner
TODO
base_rule_engine
find_violations
more
sense
nit
necessary
TODO
TODO
Write
customer
methods
violation
type
TODO
specific
person
basic
testings
ACL
violations
email
domain
ACL
violations
important
tests
super-awesome
PR
nit
newline
nit
general
observation
nice
comment
tuple
test
condition
/
expectation
'\
ingress
rule
source
Can
comment
deprecated
API
legacy
data
customers
nit
comment
statement
backend_service.port_name
INTERNAL
backend_service.port_name
None
comment
valid
null
port
point
valid
backend
service
port
port
=
int
backend_service.port
good
comment
expected
error
anything
end
function
comment
re-enable
protected-access
checks
\
pylint
enable=protected-access
TODO
class
cloudsql
same
camelCase
>
snake_case
reason
class
module
level
class
abbreviation
sc
bit
more
easy
efficient
check
upstream
rule
book
exception
cycle
please
TODO
future
comment
use
function
i
yaml
rule
format
doc
nit
first
line
text
same
line
Raise
violation
IP
whitelist
Args
nit
pylint
enable=line-too-long
file
RuleViolation
definition
comments
ip
string
namedtuple
property
ips
single
IP
namedtuple
property
scanner
flattening
scheme
property
great
consistent
ip
case
None
upstream
clear
docstring
resource
rules
yaml
dict
little
confused
correlation
yaml
rules
name
rule
resource
project
network
self
is_external
true
whitelist
network
project
sure
comment
didnt
i
comment
didnt
same
following
lines
nit
extra
line
please
following
line
first
word
arg
description
Please
tests
violations
passing
error
cases
Networks
whitelist
projects
Network
project
whitelist
external
IP
Network
project
whitelist
external
IP
Network
project
nit
i
line
status
=
model_pb2.DeleteModelReply.Status.Value
'SUCCESS
lines
code
try
self.modeller.delete_model
model_name
status
=
model_pb2.DeleteModelReply.Status.Value
'SUCCESS
Exception
LOGGER.exception
'Unable
model
%
s
model_name
status
=
model_pb2.DeleteModelReply.Status.Value
'FAIL
return
model_pb2.DeleteModelReply
status=status
function
name
Done
@
ahoying
import
statements
consistent
module
class
approach
blueandgold
comment
TODO
separate
PR
proper
testing
Great
points
TODO
descriptions
Yup
TODO
clear
fix
pylint
error
tests
pipeline
same
time
Done
sure
reason
transform_util
attribute
pipeline
different
interface
sense
flatten
method
specific
pipeline
use
ABC
Ack
lists
list
run_states
True
success
False
failure
run_states
run_states
run_states
actual
states
logic
table
https
//stackoverflow.com/a/19389957
next
comment
helper
method
mark_scanner_index_complete
documentation
method
assumptions
method
doc
parameters
e.g
inventory_index_id
violations
scanner
runs
scanner_index_id
violations
specific
scanner
index
parameter
inventory_index_id
parameter
violation
etc
space
previous
comment
line
Hmmm
use
autocommit
default
https
//dev.mysql.com/doc/connector-python/en/connector-python-api-mysqlconnection-autocommit.html
magic
number
comment
resource_type
Please
error
@
matthewg
[
base_client
]
https
//github.com/GoogleCloudPlatform/forseti-security/blob/master/google/cloud/security/common/gcp_api/_base_client.py
L112
code
BaseClient._execute
error
error
handling
comment
future
improvement
Comment
sync
tests
'beta
'v1
anyway
Please
comment
mock_api_version
line
Can
line
comment
nit
Comment
date
change
v1
line
consistent
naming
comment
abbreviation
def
create_column
table
column
map
example
something
scanner_map
=
'IamPolicy
scanners.IamPolicyScanner
scanners.FooScanner
scanners.BarScanner
something
scanner
scanner_map
[
'IamPolicy
]
snapshot_timestamp
reason
False
nit
truth
table
necessary
someone
python
python
official
documentation
explanation
/all
nit
nice
comment
rate-limiter
point
code
data
database
format
other
fetch_cai_asset
call
project_id
format
results
call
project_number
format
results
Same
fetch_bigquery_dataset_policy
raw
API
representation
project
number
whole
entry
tests
TODO
practice
folks
different
zones
redundancy
QQ
more
abstractmethod
fundamental
step
notification
pipeline
spotify
pipeline
good
way
caller
notification
pipeline
pattern
def
run
Run
email
pipeline
notification
self._compose
self._send
notification
TODO
unit
test
unit
test
syntax
valid
loop
unit
test
major
change
value
hook
path
logic
same
other
paths
end
method
bug
inheritance
examples
base
hook
living
app
value
self
/foobar.py
config
/foobar.py
single
path
True
dict
id
]
sg_storage
sg_storage
sg_storages
compatible
version
mess
code
setup_project
command
new
class
enough
stuff
setup_project
method
specific
feature
general
use
class
block
comment
name
methods
Python
module
verbose
name
load_from_file
load_from_string
*
args
*
*
__init__
signature
pass
super
useful
one
use
case
dialog
easy
parent
dialog
__file__
base
class
location
location
current
hook
current
app
comments
comment
parent
object
fair
scenario
number
results
hard
coded
number
Due
inexperience
tests
sure
good
idea
schema
test
schema
whitespace
something
python
shotgun_status_row
=
[
s_row
s_row
shotgun_status_entries
path_cache_row
]
==
s_row
]
]
self.assertEqual
shotgun_status_row
whitespace
whitespace
<
br
>
whitespace
'TankTestBase
star
imports
tank_test.tank_test_base
<
br
>
blank
lines
blank
lines
class
function
definition
chance
more
comments
little
confusing
Huh
comment
kind
cache
issues
bootstrap
core
scenarios
right
@
jfboismenu
way
part
state
global
foe
typo
whitespace
assertEqual
sides
==
sign
console
sure
i
value
hook
compute
full
cache
hook
little
possible
more
flexibility
things
cache
env
files
descriptor
i
internal
system
scaffold
hook
illustration
bigger
i
helpful
similar
past
python
class
WebsocketsDispatch
Hook
def
get_site_state_fields
shotgun
page
list
Shotgun
fields
hash
computation
server
state
Shotugn
returns
list
Shotgun
fields
hash_records
=
[
]
hash_records.append
name
LastPipelineConfigModification
name
entity_type
PipelineConfiguration
filters
[
]
context
fields
updated_at
]
order_by
field_name
updated_at
direction
desc
]
name
LastSoftwareModification
name
entity_type
Software
filters
[
]
context
fields
updated_at
]
order_by
updated_at
updated_at
direction
desc
]
hard
sg
side
simpler
format
return
hash_records
compute_site_state_hash
sg_hash_data
data
get_site_state_fields
hook
methods
hash
hash
state
shotgun
point
time
account
relevant
fields
state
registered
commands
default
timestamp
software
entity
pipeline
config
entity
change
records
tables
change
hash
Customization
expert
case
reporting
app
list
registered
commands
list
available
reports
Shotgun
use
case
analogous
app
software
entity
case
sure
reports
entity
cache
hash
someone
report
setting
menu
returns
hash
input
example
sg_hash_data
=
LastPipelineConfigModification
LastSoftwareModification
return
hash
sg_hash_data
def
get_hash_fields
entity_type
shotgun
fields
entity
type
order
hash
data
example
set
cached
command
entries
tasks
assets
set
entries
tasks
Shots
entity
field
tasks
type
field
compute_cache_hash
hash
key
type
link
tasks
pick_environment
hook
configs
shot
tasks
asset
tasks
cache
compuation
granularity
cache
entries
invalidated.
entity_type
==
Task
entity
type
]
return
type
compute_cache_hash
sg_entity_data
Compute
hash
shotgun
object
hash
entry
cached
commands
lookup
hash
cache
full
command
generation
place
result
hash
method
input
parameter
sg_entity_data
data
object
registered
commands
Customization
Imagine
different
launch
entries
department
user
department
field
Shot
asset
etc
modify
get_hash_fields
data
compute
hash
method
department
hash
key
asset
shot
modify
pick
environment
distinct
envirionments
different
apps
different
departments
NOTE
hash
key
site
hash
compute_site_state_hash
state
pipeline
descriptor
configuration
complex
mutable
configs
sg_entity_data
[
type
]
Task
key
entity
type
entity
type
hash_key
=
%
s_
%
s
%
sg_entity_data
[
type
]
sg_entity_data
[
entity
]
type
]
hash_key
=
sg_entity_data
[
type
]
return
hash
hash_key
hard
i
kind
approach
parts
system
user
control
rest
internal
logic
internal
downside
clients
menu
entries
less
issue
suggestion
code
lot
complex
little
benefit
warning
bad
code
noqa
end
line
code
undefined
name
[
]
param
Worth
comment
bit
time
i
errors
warnings
Error
something
bad
sure
failed
deletion
bad
case
backup
example
bad
return
value
global
variables
method
worker
threads
Hey
Luis
fault
better
global
refers
scope
global
scope
mind
comments
brevity
def
delete_folder
path
delete_folder_success
=
True
def
_on_rm_error
func
path
exc_info
Python
variable
defined
scope
global
delete_folder_success
consistent
logging
message
couple
lines
log.error
%
s
%
s
%
path
e
i
%
s
Folder
%
constants
unit
tests
Unit
tests
detect
changes
API
contants
somebody
changes
constants
client
configurations
Ok.
self.assertEqual
os.listdir
config_install_backup_path
[
]
place
holder
file
directory
empty
Previous
code
directories
'not
typo
sorry
confusion
self.assertEqual
os.listdir
config_install_backup_path
[
]
simpler
directory
empty
benefit
test
unit
tests
values
folders
code
debugger
print
statements
core
backyup
folder
empty
dir
possible
self.assertEqual
os.path.exists
os.path.join
config_root_path
install
core.backup
enough
something
file
use
read-only
flag
Windows
parent
folder
Unix
better
coverage
purpose
metrics
method
great
example
sg
url
non-sg
s3
comment
great
significance
comment
nit
please
IdP
means
full
example
warning
something
wrong
line
files
garbage
collection
kicks
Might
better
context
managers
open
src
mode=
rb
windows_src
open
dst
mode=
wb
windows_dst
shutli.copyfileobj
Black
changes.
<
br
>
whitespace
arithmetic
operator
similar
little
misleading
i
something
lines
method
appropriate
configuration
path
disk
asset
Configurations
file
system
presence
templates/schema
path
configuration
nit
something
projects
templates/schema
system
project.Project.tank_name
old
exception
name
message
least
mention
QtWebKit
QtWebEngineWidgets
comment
comment
code
re-shuffled
previous
callback
_on_url_changed
much
other
error
subtle
i
comment
find
call
unclear
old
comment
little
clearer
Was
find/replace
thing
comments
people
new
code
way
'tank_test.tank_test_base.ShotgunTestBase
unused
<
br
>
'tank_test.tank_test_base.setUpModule
unused
continuation
line
under-indented
visual
indent
newline
end
file
block
comment
many
blank
lines
spaces
keyword
/
parameter
equals
blank
line
end
file
nitpick
terms
readability
easier
if/else
short
clause
clause
long
cluase
clause
bit
specific
WHY
path
shotgun.yml
values
id
mind
comment
property
engine
level
core
engine
list
blank
lines
<
br
>
'TankTestBase
star
imports
tank_test.tank_test_base
'TankTestBase
star
imports
tank_test.tank_test_base
suggestion
needed
components
present
tk-config-basic
core_api.yml
code
files
optional
someone
interested
core
folder
config
git
case
people
folder
placeholder
file
git
tank_test.tank_test_base
import
*
unable
undefined
names
br
>
'tank_test.tank_test_base
*
unused
'tank_test.tank_test_base.setUpModule
unused
unused
i
implementation
elegant
Yeah
leftover
paranoid
behavior
possible
great
info
context.entity
type
key
So
entity_type
=
new_context.entity
[
type
Same
comments
appropriate
local
variable
'config_uri_dict
Catch
exception
Travis
outdated
version
version
requirements
https
//github.com/home-assistant/home-assistant/blob/dev/requirements_test.txt
L5
continuation
line
indentation
.debug
…
work
things
webhook
restart
Home
Assistant
Dispatcher
.debug
comments
combine
undefined
name
function
None
whitespace
Please
constant
line
characters
Please
rename
all_lights
consistent
rest
variables
line
characters
br
>
whitespace
line
characters
br
>
whitespace
nice
way
communication
hardware
possible
users
broken
platform
many
blank
lines
line
characters
line
characters
unused
trailing
whitespace
blank
line
Pin
specific
version
piglow==x.y.z
configuration
setup
plex.conf
file
Please
stale
comment
assignment
new
session
everything
PR
lot
confusion
session
responsibility
code
query
smart
auto
close
sessions
Session
.close
execute
_commit
http
//docs.sqlalchemy.org/en/latest/orm/session_basics.html
when-do-i-construct-a-session-when-do-i-commit-it-and-when-do-i-close-it
>
GUI
interface-driven
application
scope
Session
scope
user-generated
event
such
button
push
scope
user
interaction
such
user
“
opening
series
records
great
pattern
context
manager
same
page
way
*
only
way
*
contextlib
import
contextmanager
@
contextmanager
def
session_scope
transactional
scope
series
operations
session
Session
try
yield
session
session.commit
session.rollback
session.close
def
run_my_program
session_scope
session
ThingOne
.go
session
ThingTwo
.go
session
new
behavior
NO_GAME
return
None
change
device_state_attributes
@
property
def
device_state_attributes
state
attributes
return
self._game
self._game
None
game
attribute
user
game
view
config.get
[
]
line
characters
line
characters
least
spaces
inline
comment
<
br
>
line
characters
same
signal
DiscoveryService
controller
package
private
@
callback
core.py
connect
init_controller
signal
climate
platform
entity
async_add_entities
hass.data
functions
entity
platform
platform
eg
https
//github.com/home-assistant/home-assistant/blob/7ff7c7b9f5b7fcac5483cb975fe88bd747bbe4e8/homeassistant/components/zha/fan.py
L55-L84
Please
name
async_add_entities
Does
Listener
constructor
super
constructor
period
end
line
characters
need
log
unique_id
entries
UI
_integrations
>
Minecraft
Server_
Depending
host
name
future
@
property
def
unique_id
>
str
unique
ID
return
f
self._server.host
_
self._sensor_name
unloads
‘
t
more
details
server_online_old
server_online
other
PR
yesterday
states
HA
care
rest
interval
async_track_time_interval
default
value
lot
other
integrations
last
coma
entry
config_entry.unique_id
https
//github.com/home-assistant/home-assistant/blob/3b14d9f3754ae3e31b1a3698a06b58b7498502d2/homeassistant/components/elgato/config_flow.py
L38-L40
way
unique_id
name
otherwise
entries
same
host
name
different
people
server
multiple
carrefull
need
host_exists
name_exists
already_configured
change
consequence
config
title
Do
checks
part
data
voluptuous
schema
Use
vol.Range
coroutine
overhead
coroutine
callback
Pass
user
input
errors
possible
voluptuous
schema
way
config
flow
UI
slider
number
input
able
rid
solution
happy
validation
schema
Done
form
end
method
else
case
connection
check
Make
host
lowercase
data
voluptuous
schema
Use
vol.Lower
sensor
Debug
platform
note
documentation
keeps
order
implementation
detail
introduces
language
feature
comment
Anyhow
idea
comment
self-documenting
code
next
push
speed
template
speed
script
speed
correct
least
spaces
inline
comment
Nothing
return
value
Most
comments
redundant
access
value
dict
iteration
keys
strings
config
schema
py
key
val
channel_config.items
blank
line
whitespace
blank
line
able
outside
device
feels
encapsulation
signal
device
available
suggestions
logic
object
better
update_available
@
available.setter
many
blank
lines
right
good
fit
blank
lines
line
characters
Stale
blank
lines
blank
lines
blank
lines
undefined
name
'namedtuple
undefined
name
'mqtt
line
characters
line
characters
entry
connection
device
case
data
user
step
key
error
form
field
item
key
error
message
next
option
field
CONF_PORT
Stale
line
characters
line
characters
line
characters
PR
built-in
panel
much
exceptions
continuation
line
under-indented
visual
indent
<
br
>
whitespace
blank
lines
line
characters
br
>
whitespace
block
comment
<
br
>
line
characters
menu
logs
weird
API
endpoint
auth
users
dump
menu
state
machine
Stale
comment
Please
constant
platform
'sensor
domain
core
async_setup_platform
async_setup_platform
credentials
valid
setup
fail
way
users
non-working
platform
Add
SCAN_INTERVAL
minutes
line
backslash
parenthesis
more
lines
logging
string
string
quote
next
line
quote
log
level
_time_after
yesterday
time_after
later/greater
current_datetime
>
_time_before
today
tomorrow
current_datetime
day
something
😅
Please
comment
bit
descriptive
everyone
day
_time_before
_time_after
self._time_after
-=
timedelta
days=1
self._time_before
-=
timedelta
days=1
true
e.g
real
test
desired
state
line
line
characters
whitespace
least
spaces
inline
comment
sane
default
company
people
aggressive
angry
companies
understanding
boolean
python
self._zone.data
[
_state
]
.get
self._zone.data
[
_state
]
.get
bOutRequestHeat
Sorry
second
please
check
dev
comment
Can
create_entry
call
comments
vars
value
original
value
something
None
better
least
spaces
inline
comment
<
br
>
line
characters
least
spaces
inline
comment
Pretty
sure
tests
file
isort
groups
important
imports
comment
ask
[
spec
]
https
//indieauth.spec.indieweb.org/
user-profile-url-p-1
>
MUST
NOT
port
hostnames
MUST
names
MUST
NOT
ipv4
ipv6
addresses
Same
iota_config
fourth
argument
original
config
fifth
argument
states
Configuration
discovery
info
dict
ie
fourth
parameter
load_platform
non
serializable
objects
hass.data
useful
appVersion
node
state
regular
base
attribute
line
characters
local
variable
'options
local
variable
'option
exception
log
level
single
log
message
entity
switches
available
unavailable
level
Modified
library
custom
exceptions
condition
method
least
spaces
inline
comment
exact
status
migration
hue/saturation
core
color
model
@
armills
saturation
class
least
spaces
inline
comment
<
br
>
inline
comment
too-many-instance-attributes
disabled
Stale
comment
default
polling
True
whole
property
duplication
update
method
Just
call
add_devices
covers
True
setup
method
update
right
update
method
name
None
inefficient
entity
state
accessories
Let
method
signature
same
other
platforms
rename
service
default
discovery_info
None
method
discovery
info
None
case
someone
platform
config
config
file
blank
lines
Same
comments
light
rename
Can
call
/accessories
devices
Call
schedule_update_ha_state
Same
comment
light
suggestion
Set
MWS
weather
platform
concatenation
line
characters
Docstring
blank
lines
Please
use
formatting
Please
constants
const.py
nice
credentials
valid
setup
fails
users
non-working
platform
setup
suggestion
platform
multiple
times
first
time
service
valid
non-CA
humidifiers
comment
docstring
line
devices
UUID
None
key
aioswitcher.consts
few
property
only
usage
device_state_attributes
property
little
confuse
_self_initiated
name
blank
line
way
metadata
specific
usage
template
possible
regex
match
line
characters
pylint
flake8
directives
line
way
easy
people
paste
line
links
bit
bit
links
links
broken
future
better
nothing
indexes
purpose
open-zwave
answer
documentation
answer
thread
enums
source
https
//groups.google.com/forum/
topic/openzwave/tqxQr5XbG2Q
https
//github.com/OpenZWave/open-zwave/blob/master/cpp/src/command_classes/SensorMultilevel.cpp
L50
fine
exception
urls
Use
flake8
Could
comment
link
OZW
source
brittle
OZW
change
indexes
internal
implementation
details
way
enums
links
idea
current
version
broken
link
Thanks
great
explicit
numbers
mistake
possible
per-cpp-file
line
group
enums
version
head
helpful
condition
entity
condition
entity
hass
entity
loop
condition
coroutine
request
result
async
self._condition
lock
able
lock
hass
entity
self.hass
entity
home
assistant
method
async_camera_image
Please
side
effects
init
method
comment
local
variable
line
characters
whitespace
Use
yield
action.async_run
response.parameters
Just
Alexa
https
//github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/alexa.py
L182
Yes
list
transitions
work
i
@
fabaff
>
logic
effects
yeelight
module
way
effects
place
way
list
transition
case
changes
yeelight
module
Remove
lines
whitespace
Please
variable
names
understandable
result
measurement
air_vs_road
something
<
INCLUDE
>
Measurement
+
'Air
self._type
==
'air
else
'Road
+
<
/INCLUDE
>
more
fail
safe
WeatherStation
response
timeout
internet
connection
request
requests
timeout
variable
name
data
similar
add_devices
True
second
argument
sync
methods
symptom
Move
brightness
assignment
effect
conditionals
logic
getRgb
I/O
nice
case
good
Better
effects
other
options
first
conditional
unnecessary
setRgb
call
current
code
calls
effect
effect
overrides
brightness
rgb
warning
parameters
users
hard
requirement
previous
code
changes
changes
elif
s
s
color
change
bulb
rgb
brightness
effect
white
set
rgb
brightness
whole
fetch
rgb
block
method
single
setRgb
looks
Simply
setRgb
way
Please
comment
lines
easier
reading
Use
sh_conf
[
CONF_EMAIL
]
value
Define
default
CONFIG_SCHEMA
Same
use
case
url
possible
config
schema
suggestion
Register
new
entities
available
entity.name
way
name
object
id
Empty
names
addressable
Alexa
Entity
entity
api
Python
multiple
inheritance
case
Please
pylint
disable
signal
entity
config
entry
unload
return
value
function
async_will_remove_from_hass
entity
coroutine
method
Please
assertion
states
base
climate
component
operation
mode
states
other
states
Code
comments
hash
comment
use
monitored_conditions
users
sensors
I/O
previous
loop
line
characters
hass.async_create_task
line
characters
least
spaces
inline
comment
<
br
>
line
characters
best
outcome
stdout
printout
easiest
*
UI
error
log
unlikely
error
stdout
Agreed
print
colour
context
server
stdout
helpful
dev
environment
function
calls
method
notification_id
previous
restart
hass
notifications
UI
code
notification
error
duplicate
code
title
id
communicate
subprocess
deadlock
import
persistent
notification
method
circular
imports
component/
bad
service
persistent_notification
component
checking
config
case
inline
order
_notification_id
methods
likethe
idea
complete
method
_LOGGER.error
print
persistent
notification
log
visible
UI
globals
object
hass.data
different
review
hass.data
[
data
least
interpretation
request
best
server
need
entity
setup_platform
component
setup
Stale
code
Same
server
error
event
worried
race
condition
entity
addition
server
start
server
platform
Ie
component
setup
Debug
level
function
rs_enabled
block
server.stop
Stale
docstring
assert
check
result
continue
unexpected
indentation
comment
Remove
None
I/O
self.hass.async_add_job
sorry
library
async
expert
underlying
library
thread
update
IO
Magic
values
constants
conversion
method
homeassistant
okok
hass
method
need
constant
future
partial
arguments
unsubscribe
listener
function
nonlocal
lastargs
lastargs
=
method
@
callback
event
loop
hass.async_add_job
func
*
lastargs
Create
properties
local
variables
meteofranceClient
def
get_data
Return
data
current
forecast
return
self._data
entities
BaseException
necessary
Exception
unknown
errors
disable
broad
pylint
warning
Preferably
connection
error
stale
comment
Use
comment
comments
first
comment
method
triple
string
pydoc
comment
line
characters
Please
first
devices
add_devices
list
entities
checklist
]
https
//home-assistant.io/developers/code_review_platform/
4-setup-platform
Please
first
devices
add_devices
list
entities
checklist
]
https
//home-assistant.io/developers/code_review_platform/
4-setup-platform
I/O
inside
properties
property
implementations
update
method
instance
variables
checklist
]
https
//home-assistant.io/developers/code_review_platform/
5-entity
Please
global
handle
hass.data
dict
purpose
Move
assignment
variable
Device
specific
I/O
data
parsing
standalone
library
pypi
https
//developers.home-assistant.io/docs/en/creating_platform_code_review.html
6-communication-with-devices-services
history
I/O
event
loop
async
method
mark
such
@
callback
@
asyncio.coroutine
name
async_
sleeps
event
loop
Yes
correct
way
property
returns
None
default
instance
attribute
init
camera_entity
undefined
name
'io
Whoops
return
async
context
async_setup_platform
async_notify_errors
Better
explicit
value
None
suggestion
w_m2_brightness_val
None
return
self._state
=
round
float
w_m2_brightness_val
self._state
=
None
brightness
efficient
load
platform
discovery_info
platform
entities
go
FYI
error
due
home
assistant
logger
library
module
library
modules
own
logger
granular
logging
docs
recommendations
_LOGGER
=
logging.getLogger
__name__
inside
HueBridge.setup
hue
bridge
ID
discovery
info
light
platform
right
bridge
entities
Light
platform
sure
setup
discovery_info
None
discovery
event
bridge
line
characters
unused
line
characters
Please
more
documentation
able
code
disabled
platform
schema
wrong
unused
<
br
>
PLATFORM_SCHEMA
unused
Please
library
specific
exceptions
library
errors
Please
suggestion
online
key
suggestion
disabled
suggestion
suggestion
guard
clause
checks
discovery_info
duplicate
Line
common
thing
home
assistant
attribute
keys
lower
case
case
ha-attributes
attrs
table
old
code
comment
list
ok
test
list
Xiaomi
code
test
Ok
fan
speed
list
Let
art
work
PR
new
PR
new
property
media_image
MediaPlayer
None
web
view
following
logic
python
image
=
player.media_image
image
None
return
image
image
=
…
fetch
image
player.media_image_url
Great
+1
base
class
Please
newer
access_token
implementation
example
[
]
https
//github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/media_player/__init__.py
L403-L409
Remove
docstring
things
docs
pull
such
things
code
timeout
resource
unavailable
reconnect
plan
@
MartinHjelmare
Convo
previous
PR
https
//github.com/minio/minio-py/blob/7107c84183cf5fb4deff68c0a16ab9f1c0b4c37e/minio/api.py
L491
Implementation
minio
library
wraps
everything
yields
events
access
underlying
request
way
listener
Please
disable
same
line
possible
character
line
use
words
error
broad-except
self._should_stop
comment
else
block
suggestion
Session
*
*
conf
IO
local
devices
session
await
hass.async_add_executer_job
partial
Session
*
*
conf
entity
coroutine
method
async_added_to_hass
Entities
platforms
fire
events
Entities
state
change
events
ok
component
event
device
id
entities
events
case
balloob
docs
line
characters
comment
homeassistant.util.dt.utcnow
time
event
sure
time
correct
lack
reason
flaky
test
fail
test_platform_not_ready
tests/helpers/test_entity_component.py
example
cached
time
value
utcnow
Please
platform
component
config
correct
states
state
machine
low
magic
constants
value
Docstrings
places
Travis
CI
E.g
C
function
docstring
missing-docstring
C
class
docstring
missing-docstring
C
class
docstring
missing-docstring
C:105
method
docstring
missing-docstring
C:110
method
docstring
missing-docstring
C:113
method
docstring
missing-docstring
docstrings
PEP257
ones
TravisCI
comment
docstring
couple
page
Comments
Could
comment
source
old
database
new
models
objects
actual
Index
sqlalchemy
metadata
objects
parameters
models.py
index
underlying
database
engine
indexes
present
table.indexes
list
[
next
]
https
//docs.python.org/3/library/functions.html
next
python
built-in
next
item
iterator
new
iterator
table.indexes
idx.name
==
name
index
iterator
metadata
object
index
models.py
reference
index.create
procedure
comment
only
thing
function
index
object
name
arguments
such
unique
index
reason
name
name
sqlalchemy
index=True
columns
while
right
work
update
PR
something
function
pattern
*
args
debug
messages
compound
index
individual
column
names
def
create_index
table_name
*
name
_
.join
_
.join
ix
table_name
column_names
index
types
python
create_index
recorder_runs
start
end
create_index
states
comment
migration.py
order
column
names
extra
arguments
e.g
unique=True
something
field1_field2_idx
non-unique
field1_field2_uq
unique
field1_fk
indexes
foreign
keys
MySQL
dependent
column
names
kinda
wonky
other
weird
bit
sure
column
name
models.py
HA
confused
fail
sure
way
index
name
models.py
function
name
places
index
=
bits
new
arguments
function
end
Index
constructor
Asking
columns
issue
instance
unique
index
Unique=true
arguments
problem
column
names
problem
code
point
way
Hmm
terms
index
naming
more
sense
literals
index
name
models.py
easier
something
create_index
'ix_recorder_runs_start_end
models.py
__table_args__
=
Index
'ix_recorder_runs_start_end
'start
'end
fan
literals
way
index
name
models.py
things
error-prone
folks
auto-naming
bits
migration.py
compound
index
recorder_runs
huge
table
least
own
DB
states
non-indexed
table-scan
create_index
function
single
multiple
indexes
Index
constructor
heck
time
case
sure
indexes
e.g
TABLE
ADD
INDEX
possible
types
tables
ENUM
performance
standpoint
flexibility
varchars
reasonable
compromise
small
pruned
index
space
decent
cardinality
scope
PR
sort
thought
process
bulb
Aha
things
bit
ok
above
explanation
in-line
comments
helpful
future
folks
OK
function
table
index
name
inputs
separate
function
balloob
index
names
single
column
indexes
first
function
concatenation
python
index_name
=
.format
table_name
_
.join
…
@
armills
function
def
_generate_name
*
Generate
name
arguments
return
_
.join
args
only
thing
create_index
multi-column
index
name
index
table
column
name
logic
name
=
line
able
multi-column
index
Ah
good
point
function
SQLAlchemy
docs
indexes
Index=True
naming
convention
more
clarity
above
create_index
table_name
index_name
Create
index
table
index
name
name
index
table
definition
models
table
=
Table
table_name
models.Base.metadata
_LOGGER.debug
index
table
%
s
table_name
Look
index
object
name
models
index
next
idx
idx
table.indexes
idx.name
==
index_name
_LOGGER.debug
Creating
%
s
index
index_name
index.create
engine
_LOGGER.debug
%
s
index_name
new_version
create_index
events
create_index
events
ix_events_time_fired
new_version
Create
compound
start/end
index
recorder_runs
create_index
recorder_runs
Create
indexes
states
create_index
states
ix_states_last_updated
create_index
states
ix_states_created
documentation
next
built-in
people
objects
pre-created
helpful
percentage
character
use
f-strings
formatting
credentials
incorrect
error
return
collect
entities
single
call
add_entities
unit
constant
property
instance
attribute
Please
single
character
variable
names
username
password
entity_id
auto
generate
internal
core/name
documentation
'pychromecast
unused
'typing.List
unused
Return
keys
entries_lookup
new
entities
self._feed_entries
dict
entries_lookup
store
get_feed_entry
method
Use
item
dict
entities
external_ids
set
dispatch
helper
correct
entity
methods
signal
id
external_id
entities
update
methods
corresponding
signals
home
assistant
Accept
external_ids
Anyone
happend
homeassistant.exceptions.ServiceNotFound
Unable
service
url
file
path
whitespace
dependency
imports
inside
functions
rule
modules
line
characters
line
characters
line
characters
bit
redundant
comment
code
code
something
weird
better
_why_
something
checking
HA
certificate
Sorry
blank
lines
least
spaces
inline
comment
Comment
good
sucks
library
logger
module
https
//docs.python.org/3/library/logging.html
logger-objects
schedule_update_ha_state
lambdas
python
self.device.statusEvents.subscribe
lambda
_
self.schedule_update_ha_state
able
sucks
sucks.STATUS_AUTO
set
faster
lookups
unused
<
br
>
'aioesphomeapi.CoverState
unused
redefinition
unused
line
<
br
>
redefinition
unused
'CoverState
line
new
server
HomeAssistantHTTP
class
base
aiohttp
server
class
https
//github.com/home-assistant/home-assistant/pull/15530
Just
error
return
debug
log
error
log
devices
syncworker
times
NotifyView
instances
hass.async_run_job
MainThread
able
sort
mutex/lock
problem
w/o
transport
closing
old
comments
pure
aiohttp
context
manager
such
cases
homeassistant
helper
..
@
balloob
idea
attributes
test
case
available
start
machine
state
state
attributes
entity
attributes
Good
catch
Will
disable
pylint
many
blank
lines
unused
<
br
>
'aioesphomeapi.BinarySensorState
unused
redefinition
unused
line
<
br
>
redefinition
unused
'BinarySensorState
line
line
characters
line
characters
local
variable
'trans
debug
log
output
comment
blank
line
contains
line
characters
minor
note
kwargs_transition
precedence
smaller
config_transition
present
ATTR_TRANSITION
kwargs
right
idea
Okay
Changed
line
characters
self.config
[
CONF_TRANSITION
]
turn_on
transition
argument
seconds
ms.
line
characters
set_temperature
method
ATTR_OPERATION_MODE
kwargs
idea
thermostat
requested
operation
mode
requested
temperature
Please
ATTR_OPERATION_MODE
kwargs
operation
mode
Please
refactor
entities
shared
dictionary
hass.data
Entities
respective
platforms
dispatch
helper
entity
methods
component
tuya
component
example
Stale
patch
dt_util.utcnow
beginning
setup
sure
flaky
tests
Make
sure
correct
place
ie
code
test
let
loop
servers
original
event
recurrence
rules
RFC5545
Which
calendar
🤔
nitpick
code
state
line
least
spaces
inline
comment
line
characters
line
characters
comment
line
characters
many
blank
lines
kind
code
logic
class
standalone
lib
undefined
name
'BLEError
<
br
>
name
'NotConnectedError
<
br
>
name
standalone
lib
homeassistant
such
issue
related
forum
convenience
copypasting
large
issue
connection
initiations
same
time
host
example
gatttool
devices
same
time
connection
connection
connection
attempts
bluepy-helper
Bluepy
fact
bluepy
connections
sure
bluez
limitation
OR
dongle
CSR
usb
leave-in
limitation
common
dongle
things
bluetooth_le_tracker
same
reason
service
large
issue
connection
initiations
same
time
host
example
gatttool
devices
same
time
connection
connection
connection
attempts
bluepy-helper
Bluepy
fact
bluepy
connections
sure
bluez
limitation
OR
dongle
CSR
usb
leave-in
limitation
common
dongle
things
bluetooth_le_tracker
same
reason
service
access
host
controller
access
host
controller
undefined
name
'CACHED_CHR
Eg
has_all_unique_files
mysensors
component
suggestion
Access
token
valid
setup
platform
error
Otherwise
users
non-working
platform
instance
hass.services.call
ones
other
types
async_dispatcher_send
devices
check
dispatched
signal
particular
entity
heos
updates
self.unique_id
parameter
async
def
async_update_state
unique_id
unique_id
await
self.async_update_ha_state
Note
False
default
force_refresh
parameter
Please
specific
exception
library
credentials
connection
failure
good
library
raises
different
exceptions
different
type
problems
traceback
credentials
wrong
device
present
Docstring
indentation
mixed
spaces
tabs
indentation
contains
<
br
>
indentation
mixed
spaces
tabs
br
>
unexpected
indentation
comment
whitespace
Remove
newline
end
file
unit
device
Use
hass_url
=
hass.helpers.network.async_get_external_url
url
webhooks
Method
None
Somfy
uncomment
Make
[
sure
]
https
//home-assistant.io/developers/development_validation/
lists
list
whitespace
blank
lines
Stale
docstring
reason
object
__init__
reference
time
Hi
thanks
input
single
session
frontier
silicon
device
new
connection
previous
session
sense
Internet
Radio
single
station
song
etc
time
reason
reference
'update
valid
session
Otherwise
case
someone
Undock
app
i.e
firmware
update
__init__
session
Python
developer
http
request
second
local
network
much
overhead
experience
pattern
more
robust
maintainable
request
exception
instance
request
Python
developer
first
platform
homeassistant
handling
issue
suggestions
comment
KISS
solution
async
component
time
fsapi
bottleneck
case
commented
code
needs
quick
dirty
fixes
repo
OK
behavior
few
more
thoughts
short
version
explanation
function
way
explanation
design
property
readability
way
place
request
details
usage
preference
Python
properties
favor
get_
*
method
patterns
@
property
def
fs_device
Create
fsapi
session
Explanation
text
fsapi
import
FSAPI
return
FSAPI
self._device_url
self._password
Example
def
media_play
Send
play
command
self.fs_device.play
exceptions
need
reason
google_config
client.async_initialize
comment
blank
line
contains
block
comment
option
config
yaml
Stale
comment
similar
guard
clause
line
characters
State
attribute
keys
lowercase
snakecase
comment
line
characters
Please
list
possible
modes
docstring
list
changes
noone
docstring
line
characters
Documentation
doc
PR
line
characters
ip_address
=
yield
self._hass.async_add_job
get_local_ip
IP
address
way
startup
code
throttle
track
timestamp
self._call_in_progress
dt_util.utcnow
this._next_call
return
self._call_in_progress
=
True
try
self.next_call
=
newinterval
other
fechting
stuff
self._call_in_progress
=
False
Stale
code
Stale
code
emtpy
mean
Membership
check
dict
keys
default
.keys
default
config
schema
check
check
true
status
Please
use
lowercase
snakecase
names
something
device
api
code
please
available
property
below
State
attribute
keys
lowercase
snakecase
Please
state
attributes
regards
dynamic
nature
lack
thereof
motivation
Constant
info
entity
state
attributes
essential
automations
State
attributes
dynamic
info
state
entity
Remove
unnecessary
debug
statement
Stale
comment
iterate
items
python
camera_serial
camera
camers.items
comments
clear
documentation
minimum
waiting
time
scheduled
repetitions
UPDcommand
t_COM_pause
s
https
//www.keba.com/download/x/fff263235e/kecontactp30udp_pgen.pdf
addition
offical
android
app
seconds
limit
line
code
service
handler
callback
@
callback
core.py
Change
def
version
ob
library
schedule
coroutine
past
sorry
today
meteo_france
component
weather
sensor
platform
depend
component
logic
data
functionality
discovery
things
whitespace
name
'mock_try_connection
undefined
name
'mock_finish_setup
suggestion
Icon
sidebar
suggestion
Title
sidebar
Sets
=
hass.config.components
set
translation_cache
dictionary
mapping
component
>
file
load_translation_files
keys
line
characters
pytest
fixtures
yield
teardown
code
suggestion
patch
homeassistant.components.apprise.notify.Apprise.add
library
notify
method
reason
\w
notice
whitespace
\w\s
alphanumeric
chars
practice
regexes
comment
code
outdent
comment
sure
Radarr
wanted
API
movies
comparison
False
cond
False
undefined
name
'hass
name
__configuration_source__
Unknown
state
None
pylint
error
suggestion
Add
devices
HA
add
devices
callback
suggestion
catch
exceptions
point
whitespace
backup
db
data
old
db
backup
db
First
time
part
script
data
old
db
old
db
wink
line
characters
key
state
strings
component
code
State
attributes
correct
key
boolean
asyncio.Event
Network
self.ready
=
asyncio.Event
loop=hass.loop
network
ready
self.ready.set
sleeping
python
yield
network.ready.wait
many
block
comment
<
br
>
line
characters
br
>
whitespace
line
characters
many
block
comment
many
block
comment
<
br
>
line
characters
br
>
whitespace
Please
global
manager
hass.data
dictionary
purpose
mutable
objects
default
values
least
spaces
inline
comment
<
br
>
inline
comment
latest
version
home
speakers
push
Thanks
main
thread
Hi
non
thread
hass.async_add_job
call
startup
HA
Any
ideas
component
startup
log
*
*
hass.async_add_job
*
*
2017-07-24
INFO
MainThread
homeassistant.setup
]
media_player
2017-07-24
INFO
MainThread
homeassistant.setup
]
2017-07-24
INFO
MainThread
homeassistant.setup
]
Setup
domain
discovery
seconds
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
component=discovery
2017-07-24
INFO
MainThread
homeassistant.components.media_player
]
media_player.bluesoundotepa
2017-07-24
INFO
MainThread
homeassistant.components.media_player.bluesound
]
URL
http
//192.168.1.132:11000/SyncStatus
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=turn_on
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=turn_off
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=toggle
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=volume_up
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=volume_down
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_stop
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_next_track
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_previous_track
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=clear_playlist
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=volume_mute
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_seek
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=select_source
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=play_media
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
homeassistant.setup
]
Setup
domain
media_player
seconds
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
component=media_player
2017-07-24
INFO
MainThread
homeassistant.components.media_player.bluesound
]
Bluesound
2017-07-24
INFO
MainThread
homeassistant.components.media_player.bluesound
]
Bluesound
offline
2017-07-24
INFO
MainThread
homeassistant.bootstrap
]
Home
Assistant
log
*
*
async_track_time_interval
*
*
2017-07-24
INFO
MainThread
homeassistant.setup
]
media_player
2017-07-24
INFO
MainThread
homeassistant.setup
]
2017-07-24
INFO
MainThread
homeassistant.setup
]
Setup
domain
discovery
seconds
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
component=discovery
2017-07-24
INFO
MainThread
homeassistant.components.media_player
]
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=turn_on
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=turn_off
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=toggle
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=volume_up
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=volume_down
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_stop
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_next_track
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_previous_track
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=clear_playlist
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=volume_mute
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=media_seek
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=select_source
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
service=play_media
>
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
domain=media_player
>
2017-07-24
INFO
MainThread
homeassistant.setup
]
Setup
domain
media_player
seconds
2017-07-24
INFO
MainThread
]
Bus
<
Event
[
L
]
component=media_player
2017-07-24
INFO
MainThread
homeassistant.bootstrap
]
Home
Assistant
2017-07-24
INFO
MainThread
]
Starting
Home
Assistant
core
loop
2017-07-24
INFO
MainThread
]
Starting
Home
Assistant
2017-07-24
INFO
MainThread
]
Bus
<
Event
homeassistant_start
[
L
]
>
2017-07-24
INFO
MainThread
]
Timer
2017-07-24
INFO
MainThread
homeassistant.components.http
]
Serving
/
auth
True
INFO
MainThread
homeassistant.components.http
]
/api/websocket
auth
True
INFO
MainThread
homeassistant.components.http
]
/api/websocket
auth
True
INFO
MainThread
homeassistant.components.http
]
Serving
auth
True
INFO
MainThread
homeassistant.components.media_player.bluesound
]
URL
http
//192.168.1.132:11000/SyncStatus
request
separate
thread
component
async
thread
startup
way
happy
other
way
comment
tasks
startup
task
time
thing
huge
hack
EVENT_HOMEASSISTANT_START
event
initialization
Home
Assistant
right
python
hass.async_add_job
self.async_init
True
method
startup
connection
second
new
job
comment
part
right
client
get_service
token
notification
service
instance
client
instance
enough
client.rooms.list
token
Wrap
try
ApiError
library
Log
error
None
except
block
line
characters
spaces
statement
enough
next
comment
unnecessary
line
characters
annotation
lines
http_error.response.status_code
==
pylint
disable=no-member
http_error.response.status_code
requests.codes.bad_request
pylint
disable=no-member
redefinition
unused
'hass_recorder
line
case
HTTP
request
pollution
retry
limit
time
delay
attempts
login
flow
track
user
input
ok
None
argument
FIXME
comment
clue
try
system
travis
@
balloob
fixing
test
instance
cleanup
issue
blank
line
contains
line
characters
br
>
many
block
comment
Import
sensor
base
component
lint
error
indentation
cache
blank
line
whitespace
self._connected
enough
Please
STATE_UNKNOWN
entity
self.async_schedule_update_ha_state
True
messages
period
Use
guard
clause
self.is_remote_active
return
end
=
Merge
parent
statement
suggestion
line
s
try
block
Product
auto
setup
comment
PRODUCTAUTOSETUP
Set
IHC
component
line
characters
line
characters
Leftover
undefined
name
'utcfromtimestamp
way
more
non
HA
set
vacations
safe
case
user
changes
SmartThings
device-type
handler
front-end
supported
features
Transition
float
min
value
device
new
state
access
state
async_update
suggestion
suggestion
aio_georss_gdacs.GdacsFeedManager.update
least
spaces
inline
comment
constants
place
_LOGGER.exception
stack
trace
Disable
re-enable
methods
least
spaces
inline
comment
above
asyncio_ensure_future
async_setup
blocks
sign
other
problem
Declare
__init__
Variables
class
static
instances
class
rid
_sesame
=
None
__init__
python
self._sesame
=
sesame
self._device_id
=
None
self._nickname
=
None
comments
comments
implementation
details
other
parts
system
today
Stale
code
line
characters
one
AbodeSystem
instance
hass.data
[
DOMAIN
]
=
AbodeSystem
username
password
cache
name
hass.data
[
DOMAIN
]
=
hass.async_add_executor_job
AbodeSystem
username
password
cache
name
AbodeSystem
instance
sure
something
simple
Unnecessary
comment
pretty
clear
Per
top
__init__
home
device
channel_index
dimmer
light
device
channel_index
super
.__init__
home
device
'Top
super
.__init__
home
device
'Bottom
parameter
name
property
end
base
class
comment
Remove
debug/test
things
productive
env
fine
local
test
official
PR
Remove
comment
least
spaces
inline
comment
session
stop
function
Please
blank
line
standard
library
party
imports
party
imports
homeassistant
imports
time
ota_secret
random_base32
insignificant
rest
validation
users
list
dicts
user
ids
unique
dict
dicts
more
sense
Code
input
input
schema
blank
lines
line
characters
line
characters
continuation
line
over-indented
visual
indent
line
characters
Let
file
camera/_util.py
own
library
pedantic
ALL
xml
stuff
Must
object
update
PyEssent
redefinition
unused
line
<
br
>
redefinition
unused
'FanState
line
'aioesphomeapi.FanInfo
unused
<
br
>
'aioesphomeapi.FanState
unused
Ehhhrrrrr
able
paths
continuation
line
under-indented
visual
indent
line
characters
line
characters
line
characters
line
characters
line
characters
easier
unittest.mock.call
call
mock
call
upper
limit
range
Comments
Python
start
stale
comment
Please
prefix
comments
doc
strings
first
comment
function
triple
quotes
comment
redefinition
unused
line
<
br
>
redefinition
unused
'SwitchState
line
'aioesphomeapi.SwitchInfo
unused
<
br
>
'aioesphomeapi.SwitchState
unused
bom
component
odds
comment
weather
component
CONF_NAME
CONF_NAME
DEFAULT_NAME
comment
other
name
property
review
least
spaces
inline
comment
blocks
bare
exception
filtering
device_tracker
base
component
py
client
self.last_results
many
blank
lines
least
spaces
inline
comment
newline
end
file
least
spaces
inline
comment
comparison
False
cond
False
local
variable
suggestion
Pi
module
CI
suggestion
Pi
module
CI
suggestion
Pi
module
CI
suggestion
Pi
module
CI
suggestion
Pi
module
CI
ATTR_BEFORE
whitespace
possible
look
Throttle
util
class
https
//github.com/home-assistant/home-assistant/blob/ad8fe8a93a45584515b36611f89feba336ea7816/homeassistant/util/__init__.py
L238-L243
code
async
async
test
code
hass
aioclient_mock
fixtures
[
Example
]
https
//github.com/home-assistant/home-assistant/blob/dev/tests/helpers/test_aiohttp_client.py
L151-L155
Replace
setup_component
async_setup_component
use
assert
X
==
Y
assertEquals
async
def
test_default_setup
hass
aioclient_mock
aioclient_mock.get
…
await
async_setup_component
…
change
code
cleanup
behavior
server
async_setup_entry
duplicates
user
config
error
duplicates
optimal
user
pick
list
plex
servers
track
servers
way
chance
duplication
user
enters
load_json
coroutine
regular
function
mock_coro
mock
file
contents
Multiple
patches
single
context
manager
https
//github.com/home-assistant/home-assistant/blob/dev/tests/components/deconz/test_init.py
L23-L24
redefinition
unused
'device_state_attributes
line
line
characters
line
characters
line
characters
line
characters
initial
call
salt
data
get_scanner
device
specific
interface
code
library
right
example
documentation
PR
documentation
https
//developer.automatic.com/api-reference/
webhook-discrepancies-from-rest
fuel_level_percent
wrong
tonight
extract_image_from_jpeg
]
https
//github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/camera/mjpeg.py
L53
somfy
api
support
asyncio
hass
entity
home
assistant
hass.data
[
DOMAIN
]
defined
DOMAIN
config
specific
exception
line
characters
Force
client
Return
library
name
media
Refresh
key
device
data
Instruct
Plex
client
media
above
comment
right
comment
Detect
local
client
adjust
url
control
Finds
TV
episode
Plex
media
suggestion
yank
position
frozen
detection
feature
documentation
evening
Thanks
explanation
patient
disabled
Guard
clause
device
None
return
entry
user
weird
own
instance
variables
ones
suggestion
MQTT
client/server/trigger
settings
comment
False
ALIASES
async_setup
CONF_ALIASES
suggestion
user
Spotify
Premium
undefined
name
'name
undefined
name
'add_devices_callback
Flow
manager
Use
mock_device_tracker_conf
fixture
https
//github.com/home-assistant/home-assistant/blob/24b25b89172930ddab03cad00ac3f0732a0db185/tests/conftest.py
L104
Use
fire_time_changed
helper
https
//github.com/home-assistant/home-assistant/blob/24b25b89172930ddab03cad00ac3f0732a0db185/tests/common.py
L281-L283
least
spaces
inline
comment
improved
logging
disable
logging
commented
statements
uncomment
commented
code
uncomment
Stale
code
handlers
method
base
config
flow
class
library
update
possible
auth
correct
False
incorrect
line
characters
line
characters
line
characters
Stale
comment
Let
least
spaces
inline
comment
point
....
leftover
platform
basis
.....
next
version
preferred
pattern
something
=
dt_util.utcnow
timedelta
minutes=X
async_track_point_in_utc_time
self.hass
this.async_update
nxt
value
next
success
min
failure
minutes
°C
TEMP_CELSIUS
const.py
Home
Assistant
Python
docstring
checks
PEP257
needs
[
update
]
https
//www.python.org/dev/peps/pep-0257/
line
characters
br
>
whitespace
platform
signature
comparison
None
cond
None
line
characters
br
>
whitespace
whitespace
Thanks
@
thecynic
much
cleaner
way
custom
component
sure
things
work
comments
@
cdheiser
reply
suggestion
.format
home.label
home.name
2-3
min
worker
pool
thread
time
sure
ok
comment
core
PLATFORM_SCHEMA
Yeah
better
much
documentation
people
it…
CONFIG_SCHEMA
defaults
None
event
bus
platforms
main
component
class
distribute
data
normal
function
command
buffer
returns
transport/protocol
care
asynchronous
write
IO
docstring
function
guard
clause
Use
PLATFORM_SCHEMA
PLATFORM_SCHEMA
property
self._icon
same
class
self._icon
least
spaces
inline
comment
proper
comparison
Please
keys
whitespace
Ok
true
dirty
code
update
construct
comments
unused
All
functions
own
iteration
items
list
inefficient
states
=
[
]
entity_id
self._entity_ids
state
=
self.hass.states.get
entity_id
state
None
continue
case
states
checks
state
Etc…
min_mireds
=
min
min_mireds
state.attributes
MIN_MIREDS
]
method
SUPPORT_GROUP_LIGHT
confusing
name
SUPPORT_
constants
features
entity
support
entity
children
support
need
SUPPORT_GROUP_LIGHT
line
=
rest
MartinHjelmare
Sorry
self-taught
Python
programmer
month
experience
code
climate\__init__.py
base
mode
def
turn_away_mode_on
Turn
NotImplementedError
turn_away_mode_off
Turn
NotImplementedError
logging
comment
elif
clause
i.e
significant
datetime.min
debug
message
_after_
STARTUP
line
characters
state
property
in_on
added
turn_away_mode_off
Turn
self._set_operation_mode
EVO_AUTO
def
_set_operation_mode
Set
new
target
operation
mode
TCS
_LOGGER.debug
_set_operation_mode
request
]
%
s
operation_mode
try
self._obj._set_status
noqa
E501
pylint
disable=protected-access
except
HTTPError
err
self._handle_requests_exceptions
HTTPError
def
set_operation_mode
self._set_operation_mode
HA_STATE_TO_EVO.get
comments
necessary
PR
data
available
evohomeclient
protected
access
Fixed
line
characters
comment
comments
hand
mean
anyone
0-indent
comment
lines
code
hard
only
platforms
log
statements
imports
Again
many
comments
comment
platform
load_platorm
function
False
component
Please
https
//github.com/home-assistant/architecture/issues/22
possible
states
different
states
single
climate
platform
scan
interval
sense
stick
weird
Fair
enough
PR
beta
I/O
executor
async_update_ha_state
True
one
run
huge
deal
big
concern
updates
service
methods
Sorry
miscommunication
confusion
async_update_ha_state
True
internal
attributes
ha
state
anything
right
self._template
self._level_template
None
updates
]
https
//github.com/home-assistant/home-assistant/pull/7657/files
diff-267a90626dbaaf2cf7ffef1cc928a482R166
reason
state
changes
templates
re-rendered
Presets
integration
Please
definition
climate
integration
radiotherm
integration
continuation
line
same
indent
next
logical
line
Indent
comment
code
comment
s
complex
something
work
python
all_classes
[
pyatmo.WeatherStationData
pyatmo.HomeCoachData
]
=
module_name
data.get_module_names
[
module_name
]
=
[
module_name
]
+1
module_name
not_handled
module_name
[
m
m
not_handled
[
]
==len
all_classes
]
_LOGGER.error
'Module
name
%
s
module_name
local
variable
'sensors
line
other
comment
other
comment
unexpected
indentation
comment
integration
faulty
case
symptom
PEP8
None
self._speed_template
None
previous
call
TemplateError
state
NameError
name
'state
EVENT_HOMEASSISTANT_START
code
loading/unloading
entities
look
light
group
platform
https
//github.com/home-assistant/home-assistant/blob/ca5f4709564773c8cebd6ee40aa7cc1095b19105/homeassistant/components/light/group.py
L72-L82
STATE_ON
point
people
enable
Same
comment
import
access
function
design
error
public
function
helper
function
undefined
name
'conf_util
unexpected
indentation
dict
services
commands
payloads
schemas
lookup
cover
component
example
lot
fewer
lines
code
SyntaxError
invalid
syntax
Move
above
line
comment
hole
deeper
music
playlist
media
mention
change
conversions
unit
device
temperature_unit
HASS
care
comment
other
conversions
platform
local
push
SCAN_INTERVAL
module
initialization
self._unique_id
init
method
attribute
pylint
disable
pylint
disable
Stale
comment
Use
self.set_target_temperature
self.set_temperature_debounced
Typo
line
characters
necessary
line
characters
comment
device
discovery
STATE_PLAYING
necessary
quirk
device
reports
branch
normal
fine
STATE_IDLE
None
unknown
line
]
https
//github.com/home-assistant/home-assistant/pull/6153/files
diff-80cd99321d808e4726a56be704e3085eR68
other
comment
nice
comment
line
else
returns
Hopefully
next
person
types
remote_button_turn_on_pressed
etc
Deconz
triggers
lot
different
device
types
OK
manager
class
data
new
library
copy
entries
entity
original
entry
async_update
values
Style
comment
hard
benefits
x
style
rid
pylint
issue
features
SUPPORT_OPEN
|
SUPPORT_CLOSE
self._covers
KEY_OPEN_CLOSE
]
.add
entity_id
self._covers
KEY_OPEN_CLOSE
]
.discard
entity_id
time
correct
place
correct
time
component
https
//github.com/home-assistant/home-assistant/blob/73f55757088709214f3498b56ebb8780dc5e8217/homeassistant/helpers/event.py
L20
entity
tests
interactions
core
entity
core
time
interval
ie
update
patch
time
fire
time
event
time
eg
https
//github.com/home-assistant/home-assistant/blob/93dfd613aa52d825ea97f8f1819a4bccbef3e385/tests/components/manual/test_alarm_control_panel.py
L83-L119
generated
triggers
change
homeassistant/components/automation/__init__.py
alternative
possible
domain
platform
case
resolver
https
//github.com/home-assistant/home-assistant/blob/e137572ce7487c08bd1312a521c69aeff732251b/homeassistant/components/automation/__init__.py
L408
=
importlib.import_module
conf
[
CONF_PLATFORM
]
__name__
=
importlib.import_module
..
.device_automation'.format
conf
[
CONF_DOMAIN
]
__name__
least
spaces
inline
comment
'.authed_api_client
unused
redefinition
unused
'authed_api_client
line
'.authed_api_client
unused
<
br
>
'.webhook_client
unused
redefinition
unused
'authed_api_client
line
'.authed_api_client
unused
<
br
>
'.webhook_client
unused
aggressive
configurable
right
amount
Home
Assistant
public
API
least
spaces
inline
comment
possible
sort
explanation
side
effect
Just
sake
time
someone
tests
reason
future
entity
main
component
Things
unused
possible
face
allone
many
things
https
//home-assistant.io/components/image_processing/
face
other
words
able
base
class
first
PR
suggestion
'homeassistant.helpers.config_validation
cv
unused
haha
guess
right
👍
'homeassistant.components.image_processing.PLATFORM_SCHEMA
unused
'homeassistant.components.image_processing.PLATFORM_SCHEMA
unused
>
async
safe
I/O
Ah
yeah
controller.ping
controller.get_board_information
executor
job
update
PR
tomorrow
🙂
Useless
log
interested
suggestion
except
Exception
err
_LOGGER.error
exception
%
s
err
Stale
docstring
expensive
config
entry
data
least
spaces
inline
comment
least
spaces
inline
comment
<
br
>
line
characters
Makes
sense
Done
nit
small
CONF_
constants
define
configuration
key
names
better
variable
something
ATTRIBUTION
unused
least
spaces
inline
comment
continuation
line
under-indented
visual
indent
least
spaces
inline
comment
<
br
>
line
characters
Roger
general
idea
descriptions
documentation
tests
lets
Please
service
descriptions
defaults
voluptuous
schema
Please
logging
constants
logging.WARNING
etc
separate
PR
dev
docs
particular
things
difference
difference
awning
shade
suggestion
position
=
kwargs
[
ATTR_POSITION
]
Position
argument
present
part
check
listener
entry
.const
import
DOMAIN
domain
name
keyword
argument
class
decorator
https
//developers.home-assistant.io/docs/en/config_entries_config_flow_handler.html
defining-your-config-flow
easier
top
user
step
zeroconf
step
zeroconf
confirm
step
handle
config
flow
method
module
part
similar
code
_handle_config_flow
helper
method
host
parameter
connection
_handle_config_flow
zeroconf
Patch
entity
interfaces
tests
tests
more
robust
behavior
self._state
[
STATE_UNKOWN
False
]
code
STATE_UNKNOWN
False
string
unknown
equal
value
list
value
list
items
Sorry
comment
thanks
great
idea
issues
scan_interval
camera
configuration
component
default
value
value
only
code
changes
default
scan
interval
python
SCAN_INTERVAL
=
timedelta
seconds=10
update
functions
standard
entity
functions
@
property
def
should_poll
mail
image
index
return
True
def
update
Update
mail
image
index
_LOGGER.debug
mail
index
self._mail_index
<
self._mail_index
self._mail_index
PLATFORM_SCHEMA
difference
necessary
interval
configuration.yaml
camera
platform
usps
scan_interval
stale
comment
backslash
redundant
brackets
least
spaces
inline
comment
line
characters
method
line
characters
configuration
stuff
PR
add_devices
hass.data
python
package
pypi
pypi
package
todoist
dict
Project
object
Todoist
API
assumption
dict
[
API
]
https
//developer.todoist.com/sync/v7/
projects
sure
object
API
todoist
import
Project
API
new
project
API
server
*
object
name
ID
project
try-except
block
key
method
flat-out
dict
Project
object
latter
hacky
suggestion
Check
config
load
dependency
available
line
characters
code
event
service
'n
match
unknown
state
None
comment
Please
blank
line
standard
library
party
imports
whitespace
least
spaces
inline
comment
Ok
second
dict
HASS_FAN_SPEED_TO_WEMO
HASS_FAN_SPEED_TO_WEMO
=
v
k
k
v
WEMO_FAN_SPEED_TO_HASS.items
if-check
loop
outcome
if/else
statement
getattr
_protected_event_id
default
value
Please
login
correct
fritz
box
multiple
switches
name
name
Webinterface
fritz
box
name
home
assistant
understanding
way
user
name
switch
use
actor.name
default
similar
behavior
https
//github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/switch/dlink.py
L77
intended
way
attributes
least
spaces
inline
comment
homeassistant.util.dt.utcnow
async_fire_time_changed
callback
tests/common.py
mock
time
event
Eg
https
//github.com/home-assistant/home-assistant/blob/dev/tests/components/alarm_control_panel/test_manual.py
L78-L82
Make
sure
time
component
first
update
happens
unused
<
br
>
'aioesphomeapi.SensorState
unused
<
br
>
'aioesphomeapi.TextSensorInfo
unused
<
br
>
'aioesphomeapi.TextSensorState
unused
comment
weird
code
suggestion
result
=
await
hass.data
[
DATA_MQTT
]
.async_connect
type
bool
comment
things
pypi
library
nicer
way
library
is_live
is_recording
red
dot
means
Ah
ha
PyCharm
usages
feature
full
text
search
Okay
logic
live
method
~States.domain.in_
IGNORE_DOMAINS
Ah
individual
commits
Good
catch
[
]
https
//github.com/home-assistant/home-assistant/blob/f43db3c615db00c578b03014136e5ddd2289e830/homeassistant/helpers/restore_state.py
L43
filters
place
restore_state
intentional
own
commit
domain
filter
query
due
fact
process
IGNORE_DOMAINS
only
method
double-logic
safe
things
tad
Interestingly
topic
refactor
logic
*
*
methods
production
unit
tests
only
code
scaffolding
methods
filters
object
async_added_to_hass
config
value
interval
statit
SCAN_INTERVAL
Just
options=None
options
None
options
record
fine
keepalive
part
stream
component
sense
part
play_stream
service
camera
component
component
keepalive/preload
other
type
config
future
PR
generalized
question
sure
token
sequence
parameter
brain
dead
Did
relative
urls
.ts
debug
code
suggestion
audio_bytes
b'\x00\x00\x00\x00\x00\x00\x00\x00
*
audio_frame
global
variable
least
outputs
several
lines
check
understanding
correct
new
buffer
key
frame
purpose
Home
Assistant
jobs
start
event
listne
EVENT_HOMEASSISTANT_START
rooms
Please
listener
HOMEASSISTANT_STOP
event
client
Stale
docstring
Stale
comment
Please
grammar
Unnecessary
comment
change
self.exclude_e
domain
self.exclude_d
lists
empty
python
self.have_exclude
=
bool
self.exclude_e
self.exclude_d
HA
imports
top
file
alternative
=
await
hass.helpers.device_registry.async_get_registry
able
API
valid
blank
line
end
file
config
parameter
PLATFORM_SCHEMA
okay
file
line
Python
life
👍
device
property
data
entity
updates
Home
Assistant
should_poll
property
entity
_device.update
fine
Throttle
care
whole
propagation
updates
global
RachioPy
own
creation
fact
classes
static
methods
useless
methods
fork
library
Home
Assistant
update
entity
turn_on
turn_off
global
use
hass.data
[
DATA_RACHIO
]
dict
purpose
class
RachioPy
light
switch
service
auto
start
False
comment
sense
Enable
sensors
Sensors
entity
home
assistant
dispatch
helper
case
Please
user
name
sensor
Hint
CONF_NAME
async
context
True
add_devices
care
events
component
platforms
local
push
rest
call
@
balloob
Would
static
attributes
i.e
ATTR_TAG_HW_REVISION
ATTR_TAG_FW_VERSION
ATTR_TAG_TYPE
static
Others
dynamic
actual
battery
voltage
helpful
end
user
battery
replaceable
user
description
specific
tag
end
user
helpful
end
user
many
issues
signal
etc
end
user
able
frequency
other
hw
settings
parameter
subject
automation
trigger
automation
ATTR_TAG_BEEP_DURATION
user
able
options
tag
service
hass
control
beep
duration
hass
future
versions
ATTR_TAG_OUT_OF_RANGE
nature
dynamic
helpful
end
user
tag
range
tag
vehicle
bag
kids
yard
notifications
range
range
....
ATTR_TAG_POWER_CONSUMPTION
changes
location
device
ATTR_TAG_SIGNAL_STRAIGHT
battery
life
user
i
sure
specific
tag
right
way
component
name
i
events
rest
call
wirelesstag
hw
endpoint
event
helper
data
components
platforms
whitespace
<
br
>
least
spaces
inline
comment
<
br
>
line
characters
old
comment
platform
integration
discovery_info
None
return
support
monitored
conditions
Let
group
breaking
changes
PR
sense
case
comment
automatic
license
plate
recognition
way
refers
plates
general
specific
platform
alpr
'Automation
licence
plate
regnorice
meaning
Log
error
possible
line
characters
comment
controller
documentation
Ecoalcontroller
whitespace
pylint
disable
Convention
comment
clear
Inherit
SwitchDevice
switch
component
😉
info
handle
store
hooks
suggestion
Unknown
sibling
service
part
step
part
empty
dict
input
user
submit
local
variable
_
Can
example
documentation
None
self.adb_lock.release
non
lock
threads
thread
pool
own
context
manager
lock
methods
lock
https
//docs.python.org/3/library/threading.html
threading.Lock.acquire
adbkey
more
pythonic
something
mind
https
//github.com/home-assistant/home-assistant/blob/69c04697d24470c90535410860472efc6cac6f36/homeassistant/components/media_player/vizio.py
L56-L67
https
//github.com/home-assistant/home-assistant/blob/69c04697d24470c90535410860472efc6cac6f36/homeassistant/components/media_player/vizio.py
L182-L184
Invert
None
true
return
returns
@
Throttle
MIN_SCAN_INTERVAL
def
update
idea
backoff
list
relate
time
tries
change
interval
next
update
call
hard
current
logic
party
imports
top
module
failed
suggestion
credentials
bad
efficient
reason
self.entities
set
classmethod
instance
class
common
use
case
classmethod
class
store
code
easier
reason
future
enhancements
track
states
cache
Typo
Enable
cv.ensure_list
expert
debug
log
entry
work
serial
number
unique
ID
initialization
host
part
saved
entry
data
same
entry
unique
id
point
import
patches
single
pytest
fixture
return
value
patched
class
mock
VizioAsync
instance
way
different
method
return
values
different
tests
class
@
pytest.fixture
name=
vizio_device
vizio_device_fixture
Mock
VizioAsync
device
patch
homeassistant.components.vizio.config_flow.VizioAsync
vizio_class
yield
result
=
await
hass.config_entries.options.flow.async_init
DOMAIN
parent
class
device
attributes
Comment
Please
code
comment
property
return
None
weird
parent
class
implementation
Python
comments
comment
proprety
>
property
doesnt
>
sure
comment
Are
throttle
time
argument
module
level
user
config
MartinHjelmare
sleep
update
_connect_api
API
call
station.get_data
method
server
requests
seconds
AmbientStationData
single
time
server
API
service
day
unknown
time
connection
stale
hours
way
best
solution
AmbientStationData
object
update
ideas
issue
line
characters
line
characters
line
characters
previous
step
Upsss
No
need
commented
code
pass
comment
anything
better
logger
someone
moment
someone
remote
platform
commands
disable
W0107
pass
statements
unnecessary
next
python-miio
release
version
line
characters
least
spaces
inline
comment
Docstrings
entity
entity
update
mechanism
call
entity
update
time
time
time
event
eg
https
//github.com/home-assistant/home-assistant/blob/b230562c76ce8c3b5c724ba89ee3f7cfb55ce1e9/tests/components/manual/test_alarm_control_panel.py
L75-L107
Device
info
device
registry
entity
ps4
instance
class
ps4
instance
Eg
pytest
fixture
ps4
class
mock
instance
return
value
class
access
mock
ps4
instance
tests
blank
line
whitespace
Please
functionality
setup_platform
entities
HOMEASSISTANT_START
comment
broad
line
code
Reason
other
places
please
W0703
text
broad-except
Log
error
enough
unused
<
br
>
'aioesphomeapi.LightState
unused
redefinition
unused
line
<
br
>
redefinition
unused
'LightState
line
list
buses
datetime
first
bus
component
Setup
device
EVENT_HOMEASSISTANT_START
action
startup
device
restart
sigterm/sighub/sigint
Temperatur
enough
device.
people
arguments
moment
platforms
API
documentation
simple
simple
wink
convention
arguments
class
numpydoc
style
exceptions
lib
relevant
states
properties
None
device
log
exceptions
platform
setup
Example
source
others
https
//github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/sensor
/darksky.py
L137
Or
simple
automation
automation
alias
Temperatur
Startup'
trigger
platform
Event
event_type
EVENT_HOMEASSISTANT_START
action
Service
climate.set_temperatur
data
temperature
user
invalid
username/password
error
setup
fail
@
users
non-working
platform
instance
chance
setup
successful
initialisation
connection
successful
right
thing
error
block
comment
optimal
current
operation
mode
temperature
arguments
better
device
available
options
logic
possible
Supported
features
entity
lifetime
Invert
guard
clause
Ie
return
true
False
resolutions
rephrase
Remove
search
item
search
results
vertices
graph
everything
hexadecimal
values
Mac
multiple
standards
Mac
implementation
Mac
own
standard
smallest
common
denominator
Please
new
supported
features
sure
device
support
specific
triggers
suggestion
self._hass.data
[
DATA_SURE_PETCARE
]
[
SureThingID.PET.name
]
=
task
platform
deadlock
py
hass.async_create_task
hass.helpers.discovery.async_load_platform
credentials
correct
setup
incorrect
error
return
False
Stale
Same
comments
other
entity
class
blank
lines
redefinition
unused
line
redefinition
unused
line
redefinition
unused
line
Make
loop
config
part
platform
'climate
load_platform
hass
platform
DOMAIN
suggestion
queue
full
random
item
suggestion
url
part
SimpleLazyObject
__class__
property
suggestion
values
collections
worker
re-patch
comment
new
block
sure
spans
]
.resource
value
test_traces_get_or_create_multi
check
hit
partial
case
print
debug
statements
order
cache
multi
case
order
arguments
multi
case
hit
tag
current
span
e.g
span
=
pin.tracer.current_span
span.set_tag
span.get_tag
'hit
asbool
span.get_tag
'hit
similar
necessary
expired
good
stance
things
signature
great
play
race
condition
e.g
threads
fork
Which
_fork_occured
necessary
worst
little
bit
Tracer
code
code
hook
much
machinery
cool
usage
sorry
ddtrace.utils.formats.get_env
helper
https
//github.com/DataDog/dd-trace-py/blob/master/ddtrace/utils/formats.py
L6
arguments
first
integration
name
second
config
value
get_env
'trace
default=True
Retrieves
variable
DD_TRACE_ANALYTICS_ENABLED
DD_ANALYTICS_ENABLED
little
weird
'analytics
Agreed
kind
inheritance
traversal
something
Pin
usage
.__mro__
approach
idiomatic
TODO
form
comment
problem/what
temporary/a
placeholder
better
solution
code
vertica
integration
situation
long
comment
tracing
configuration
vertica
library
good
comment
cases
mentions
type
corresponds
case
suggestion
self.override_config
pynamodb
dict
service_name=
cfg-pynamodb
@
brettlangdon
@
jdgumz
DD
DATADOG
_SERVICE_NAME
same
new
DD_SERVICE
compatibility
change
configurations
DD
DATADOG
_SERVICE_NAME
way
Thoughts
nit
reword
spans
producer
span
consumer
span
DD_SERVICE
sense
@
brettlangdon
Pin
Config
object
possible
huge
amount
issues
simpler
API
hey
great
catch
suggestion
Integrations
service
service_name
good
UX
patch
fails
log
nothing
awful
exception
safer
hey
user
try/except
approach
importlib
Py3
Curious
__import__
patching
versions
worth
log
entry
True
status_code
suspicious
comment
comments
DEV
anyone
developer
suggestion
ddtrace
import
patch
patch
logging=True
noqa
everything
*
*
*
*
python
ddtrace
import
patch
patch
logging=True
mock
@
MotoService
'lambda
botocore
patch
issue
due
library
test
Anyway
moment
aiobotocore
supports
s3
great
work
way
😄
services
botocore
supports
TODO
directory
more
sense
individual
files
big
deal
imo
-1
annoying
ta
live
something
True
False
function
Same
patch
isinstance
query_args
dict
harm
query_args
=
dict
false
block
fine
dict
pretty
harmless
stringify
value
span.set_tag
necessary
case
better
try-except
stacktrace
point
other
overhead
code
everything
_set_final_exception
component
case
stacktrace
Exception
object
something
python
try
exception
ongoing
exception
=
span.set_tag
errors.ERROR_MSG
exc.args
]
span.set_tag
errors.ERROR_TYPE
exc.__class__.__name__
Exception
log.debug
'Unable
error
better
message
span.finish
things
implementation
*
implementation
safe
statement
accessors
try
efficient
exception
general
exc
Exception
*
sure
span
tags
tests
fine
default
ES
[
]
default
client
transport_class
defaults
Transport
anything
comment
module
default
elasticsearch.transport
module
way
someone
own
Transport
reasons
aware
patch
transport
[
]
https
//github.com/elastic/elasticsearch-py/blob/master/elasticsearch/client/__init__.py
L156
TODO
mock.mock_open
*
suggestion
date=datetime.datetime.utcnow
.isoformat
good
catch
specific
reason
comment
important
enough
😆
change
issue
test
method
child
class
parent
method
results
invalid
_full_method_name
example
test
method
tests.contrib.gevent.test_patch.TestGeventPatch.test_patch_before_import
MROs
overridden
_full_method_name
invalid
comment
what/why
great
suggestion
DEV
default
global
tags
DD_VERSION
precedence
DD_TAGS=version
v
suggestion
url
parts
bytes
parts
suggestion
guess
wait
nit
small
typo
same
suggestion
env
tag
active
span
suggestion
Stop
background
worker
nice
complete
example
suggestion
ddtrace
import
tracer
tracer
instance
tracer.configure
context_provider=AsyncioContextProvider
same
[
Pin
]
http
//pypi.datadoghq.com/trace/docs/
ddtrace.Pin
e.g
https
//github.com/DataDog/dd-trace-py/blob/master/ddtrace/contrib/redis/patch.py
L51-L53
same
region
tag
region
unknown
ok
metadata
general
attribute
available
let
meaningful
error
code
downstream
stats
collection
error
better
candidate
fine
STATUS_CODE
meta
result.status
available
typo
HTTP
i
version
code
layer
patching
function
patchable
available
patch_all
i
logic
add_cleaned_api_params
function
unnecessary
layer
indirection
need
comment
correct
resource
something
similar
botocore
sure
check
span.name
test
comment
information
correct
line
code
e.g
following
....
provide
service
name
User
integration
service
name
Parent
service
name
exists
configured
service
name
config.service
/
DD_SERVICE
worth
short
comment
how/when
rpc_method_handler
future
maintenance
🙂
suggestion
r
=
func
response
suggestion
_update_span_from_response
response
return
r
return
type
harm
functionality
equivalent
original
function
😄
test
whole
thing
need
comment
suggestion
config.starlette
[
]
=
True
specific
placement
relative
comment
suggestion
Helper
Django
views
lifecycle/http
method
functions
class
MRO
view
False
comment
defaults/other
places
nothing
root
lol
good
comment
tho
comment
passthrough
TODO
fixed
seed
future
works
TODO
check
added
comment
Thank
Cosine
step
LR
max
steps
private
something
TorchAgent
Nit
next
line
black
docs
👍
little
part
i
*
necessary
*
worth
=
self.vectorize
%
intuitive
vectorize
modifies
obs
broken
gpu
class
constants
ParlaiLogger
parlai.core.logging_utils
module
constants
something
parlai.core.logging_utils
import
ParlaiLogger
INFO_LEVEL
check
self.altStreamHandler
None
i.e
function
error
background
work
portion
things
normal
assumption
console
logger
%
message
s
format
least
document
limitation
top
class
hmm
isinstance
console_format
tuple
unclear
formats
nit
spaces
period
sure
ready
default
logging-to-file
NFS
admins
Let
filename
None
nothing
right
way
place
dozens
commands
day
other
microsecond
stamp
able
necessary
thing
constant
top
DEFAULT_FILE_FORMAT
=
%
asctime
s
%
levelname
s
%
message
definition
__init__
default
parameter
file_format=DEFAULT_FILE_FORMAT
good
unmute
more
sense
nit
period
end
okay
level
int
habitat-api
mechanism
reasoning
file
sort
print
statements
other
modules
conflict
logger
objects
files
problems
class
own
logger
object
lot
logger
objects
confusion
file
bit
confused
multiple
places
example
great
Just
good
docstring
little
bit
more
documentation
functions
i.e
docstrings
docstring
confusing
things
example
agent
simple
bag
words
nit
TRA
code
abbreviation
bsz
batchsize
A
short
single-sentence
one-line
description
A
longer
descrpition
other
information
same
logic
convai2
test
dev
same
data
training
data
unadultered
right
move
official
test
access
test
training
set
alternative
teacher
constants
top
file
comment
sides
conversation
similar
nit
comment
nit
file
line
call
Ah
comment
part
frontend
Live
Chat
default
tries
specific
chat
title
task_config
task
chat_title
extra
comment
comment
❤️
AbstractTestSupervisor
Operator
configuration
setup
flow
test
writers
utilizing
different
information
runs
only
setup
inside
test
case
something
db
cfg
=
load_db_and_process_config
cfg
operator
=
Operator
db
operator.validate_and_run_config
cfg.mephisto
shared_state
server
=
operator.supervisor.channels
-1
]
.job.architect.server
rest
test
different
compositions
confs
different
kinds
tests
configuration
arguments
regular
conf/
*
.yaml
file
inline
comment
classification
layer
aesthetic
nit
open
logic
file
open
Remove
comment
Better
message
bunch
method
e.g
task_group_id
=
self.get_task_group_id
task_group_id
assert
nit
nit
exists
comment
args
[
]
bit
opaque
great
commentary
times
number
times
glance
bit
natural
arguments
code
values
script
default
values
difference
function
better
more
comments
code
flow
funciton
warning
hmm
hyphens
nit
rid
lines
=
random.choice
[
[
]
]
]
task_data
good
catch
argument
descriptors
docstrings
i
workers_to_onboarding_tasks_todo
error
stray
comment
huge
dump
text
comment
filename.vocab
finlename.merges
variable
opt
method
closures
let
CNN_URLS
constant
whole
file
okay
rebuild
part
class
closures
i.e
def
_rebuild
entries
def
_is_valid
entry
rid
comments
nit
invalid
datatypes
ParlAI
]
https
//github.com/facebookresearch/ParlAI/blob/master/parlai/core/params.py
L393
valid
ones
way
separate
teacher
set
[
ConvAI2
teachers
]
https
//github.com/facebookresearch/ParlAI/blob/master/parlai/tasks/convai2/agents.py
arg
appropriate
dataset
static
method
argument
specifies
[
]
https
//github.com/facebookresearch/ParlAI/blob/master/parlai/tasks/personality_captions/agents.py
L138
please
comment
something
true
gradients
dictionary
reason
needs
sort=True
default
behavior
@
vgonzalez88
something
batch
details
thank
thorough
types
field
Tensor
[
int64
]
text_vec
necessary
Data
Classes
]
https
//docs.python.org/3/library/dataclasses.html
module-dataclasses
comment
IMHO
changes/doc/comment
changes
Beam
different
PR
case
nit
import
subword_nmt
noqa
F401
False
Plan
lines
CC
@
stephenroller
i
examples
label
field
empty
let
comment
k
opt
[
k
]
=
v
print
Warning
overriding
option
[
k
old
=
>
v
]
indices
clearer
first_entry_idx
etc
sure
necessary
case
dataset
num
examples
ASSISTANT
utterances
example
conversation
USER
ASSISTANT
conversation
useful
USER
text
ASSISTANT
label
other
way
reply
ASSISTANT
statement
example
assistant
pass
index
usual
situation
able
anything
action
map
keys
contiguous
values
actual
conversation
indexes
data
usable
So
example
convo
U
convo
U
U
first
example
useful
ASSISTANT
pass
convo
episode_map
[
A
]
]
Hope
sense
assumption
docstring
comment
index
i
docstring
function
comment
]
https
//github.com/facebookresearch/ParlAI/blob/master/parlai/core/torch_agent.py
L806
example
function
file
self.add_start_end_tokens
comment
code
nice
TGA
copypasta
same
😸
nit
code
ditto
commented
code
ditto
remove
Could
helper
methods
private
add
docstrings
i
deepcopy
instructions
README.md
file
i
comment
inline
comment
amount
😂
casual
observer
magic
Nit
one
arg
nit
comment
block
prob
user
self.opt
=
os.environ
bit
surprising
logic
correct
comment
priorities
datapath
>
environ
[
PARLAI_DATAPATH
]
>
parlai_dir/downloads
default
next
line
default
example
lol
nit
comment
spot
awkward
@
klshuster
comment
yours
worker
comment
nice
suggestion
keys
models_needed_dict
unique
names
output
conversations
model
awesome
comment
rid
comments
check
comment
nit
formatting
bit
inconsistent
PR
class
Foo
line
description
Many
many
details
Great
point
Added
comment
TODO
-dt
train
stream
bit
confusing
first
act
list
line
dict
list
awful
chance
labels
eval_labels
possible
work
please
TODO
multiprocessing
tests
forced_parse
dictionaries
setup
sides
nit
comment
python
class
DefaultTeacher
Teacher
def
__init__
shared=None
raise
RuntimeError
'-t
self_chat
dummy
helper
first
time
BASICALLY
add_extra_args
comment
lines
clean_dir
function
sorts
clear
people
let
comment
block
remove_dir
standard
python
style
way
older
version
exists
outdated
files
format
comment
'spatial
image
mode
ha
negation
GitHub
diffs
worth
comment
let
>
=
==
comment
code
accident
ditto
nit
code
selected_15_1
nit
image
data
files
unzipped
call
instructions
time
build.py
longer
lines
python
implict
concatenation
URL_REGEX
=
r
i
\b
https
/
|
[
a-z0-9
%
]
[
a-z0-9.\-
]
+
[
]
r
com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|
r
museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao
first
wiki
page
knol
train
ones
i
guess
better
data
datatype
train
valid
test
string
numbers
’
t
vec2txt
couple
quick
questions
lines
lines
TODO
num_goal
int
comment
interactive_mode
Nit
comment
jq
nit
last_received_heartbeat
something
last_gotten
sounds
awk
comment
nit
unfinished
comment
readable
python
Multiline
Strings
r'/Applications/Google\
Chrome.app/Contents/MacOS//Google\
Chrome
prefix
r
raw
string
rid
flake
issue
dataset
good
available
test
set
validation
set
second
half
dev
test
set
suggestion
class
Text2TextTeacher
Text2API2TextTeacher
teacher
API
slots
nit
const
top
NO-OP
something
nit
extra
black
line
protip
[
i
i+1
start
end
]
unsqueeze
_private
ditto
let
kwarg
trim=True
self.remove_tail
self.resize_to_max
max
number
total
tokens
trim=False
number
comment
i.e
paper
put
http
Please
©
https
//github.com/OCA/maintainer-tools/blob/master/template/module/models/model_name.py
L2
https
//github.com/OCA/maintainer-tools/blob/master/template/module/models/model_name.py
L2
same
above
same
good
way
new
config
understanding
correct
new
config_DB
lack
METADATA
PORT
mgmt
interface
sure
switch
work
platform
issues
others
CLI
support
VRF
sonic-cfggen
possible
AnsibleHost.minigraph_facts
info
comment
code
way
config
reload
reboot
heavy
test
BGP
session
status
critical
below
test
reason
trigger
warm-reboot
swss
utilities
case
more
nice
look
https
//github.com/Azure/sonic-mgmt/blob/master/tests/platform/test_reboot.py
L107
critical
service
check
function
https
//github.com/Azure/sonic-mgmt/blob/master/tests/common/devices.py
L154
regx
split
'\s+
several
fields
line
>
paths
]
length
=
path
>
path
>
[
]
length
=
shoud
space
>
search_state
=
[
[
]
length
=
strings
constant
contant
example
HEADER_LINE=1
XXX_LINE=2
origin
weight
proper
documentation
module
such
requirements
options
sections
>
prifix
[
]
length
=
prefix
add
comment
valid
route
entries
hndle-
>
handle
Just
learnt
exec_template
command
*
.yml
fiel
q
number
inv
mapping
file
https
//github.com/Azure/sonic-mgmt/tree/master/ansible/group_vars/all
>
kvmCompatible
[
]
length
=
typo
following
PSU
PSU
thermal
sensors
available
if/elif
block
future
maintenance
conatiners
critical
processes
purpose
test
get_autorestart_container_list
smarter
basic
test
critical_processes
container
first
process
file
process
comment
critical
process
extended
mode
comment
comment
necessary
Comment
break
comment
container
rsyslogd
process
running
critical
process
function
general
idea
process
SIGKILL
signal
process
pytest
script
message
exit
critical
process
corresponding
container
seconds
wait_until
line
possible
function
line
is_container_running
container
function
get_program_status
container
such
scenario
command
docker
exec
<
container_name
>
supervisorctl
status
function
get_program_status
exception
wait_unti
container
critical
process
critical
process
container
wait_until
expected
behavior
critical
process
pytest
wait_until
line
container
hard
second
sleep
container
wait_until
service
test
most
containers
less
seconds
specific
sflow
container
containers
disabled
disabled
containers
Suggest
statements
readability
restarted
=
wait_until
CONTAINER_RESTART_THRESHOLD_SECS
CONTAINER_CHECK_INTERVAL_SECS
check_container_state
duthost
container_name
True
pytest_assert
container
reset-failed
.format
container_name
function
name
vague
function
*
*
*
*
autorestart
feature
supported
containers
various
common
import
various
test
cases
plugins
file
new
'topology
marker
Please
mark
tests
'any
topology
https
//github.com/Azure/sonic-mgmt/blob/master/tests/platform_tests/api/test_chassis.py
L14
example
verify_no_packet
PTF
hard
minigraph_facts
log
analyzer
case
[
qos
]
https
//github.com/Azure/sonic-mgmt/blob/master/tests/qos/qos_sai_base.py
L463
test
change
port
more
comments
behavior
src-mac
dst-mac
vlan-id
optional
hash
keys
platform
optional
hash
keys
options
user
hash
key
s/None
return/Can
return
None
/
comment
cir
cbs
>
[
]
length
=
neigh
IP
similar
interface
IPs
different
IP
[
]
length
=
number
performance
diagram
right
use
case
testcase
parameter
default
value
>
duthost.shell
[
]
length
=
function
ROUTE_JSON
[
]
length
=
file
container
docker
exec
-i
swss
swssconfig
/dev/stdin
<
filename
platforms
Ethernet72
platform
platform
platform_info
gather_facts
more
heavier
existing
infrastructure
maintenance
cost
future
https
//github.com/Azure/sonic-mgmt/blob/master/tests/common/devices.py
L132
>
sequence
test
different
parameters
way
more
helper
methods
setup
verification
test
cases
worth
packets
results
verification
code
helper
function
base_verification
L3
pkt
ptfadapter
duthost
ptf_tx_port_id
tx_dut_ports
dut_iface
]
Verify
packets
DUT
exp_pkt
=
expected_packet_mask
pkt
testutils.verify_no_packet_any
ptfadapter
exp_pkt
ports=setup
[
neighbor_sniff_ports
]
rest
unique
test
case
readable
case
body
>
except_port
[
]
length
=
ignore_ports
down_ports
port
>
all_ports
]
length
=
up_ports
i
works
platform
changes
vm
compatible
Add
space
=
line
Suggest
line
method
lines
comment
line
clear
Suggest
simplify
message
Telemetry
feature
test
case
Minor
suggestion
paths
filenames
global
variables
MAX_OPENFLOW_RULE_ID
comments
helpful
descriptive
variables
names
cleaner
high
CPU
utilization
sanmalho-git
type
duthost
methods
DutHosts._is_supervisor_node
DutHosts._is_frontend_node
public
definitions
methods
DutHost
class
Can
refactor
PR
None
necessary
bare
yield
OK
example
line
line
regex
wait_until
extra
time
wait_until
space
logger
unused
future
enhancements
minor
formatting
changes
suggestion
type
CompletenessLevel
str
example
CompletenessLevel.basic
method
basic
Arguments
level
enum
value
type
CompletenessLevel
few
suggestions
summary
line
example
description
little
bit
i.e
*
*
*
return
type
possible
interpretation
suggestion
normalized
completeness
level
test
instance
example
testcase
CompletenessLevel.basic
CompletenessLevel.thorough
specified
level
test
execution
confident
method
level
basic
Returns
CompletenessLevel
string
suggestion
Handle
mellanox
platform
second
parameters
ptftests
'/tmp
s/running
Suggest
common_
*
values
part
duthost.facts
chassis_truth
chassis_facts
same
https
//github.com/Azure/sonic-mgmt/pull/2209/files
diff-5d04a73b4b142807edb8c343db1d80dbR69
duthost_vars
unused
file
Suggest
fixture
PlatformApiTestBase
class
classes
access
platform.json
facts
inventory
facts
original
image
upgrade
path
testing
images
SONiC
switch
*
IMAGE_A
*
IMAGE_B
upgrade
IMAGE_C
images
switch
*
IMAGE_C
*
IMAGE_A
upgrade
IMAGE_D
images
switch
*
IMAGE_D
*
IMAGE_C
sonic_installer
set_default
<
IMAGE_A
>
comment
Test
data
traffic
background
traffic
different
TX
bytes
anish-n
pattern
tests.common.fixtures.ptfhost_utils
copy_ptftests_directory
lgtm
[
py/unused-import
]
anish-n
pattern
tests.common.fixtures.ptfhost_utils
change_mac_addresses
lgtm
[
py/unused-import
]
anish-n
pattern
tests.common.fixtures.ptfhost_utils
remove_ip_addresses
lgtm
[
py/unused-import
]
code
tag
HACK
quick
note
comment
summary
behavior
e.g
disable
copp
config
generation
modified
config
overwritten
suggestion
Copy
old
config
backward
compatibility
older
SONiC
images
sample
small
hash_key
ingress-port
comment
Restart
service
next
part
non-deterministic
set
random
image
more
sense
oldest
image
sure
zeros
gzip
file
rotate
logs
procedure
syslog
file
log
rotator
syslog
files
check
testcases
topology
t0
command
line
results
reason
marker
op_type
=
ARP_OP_REQUEST
op_type
way
config_facts
ansible
module
part
seperate
PR
method
SonicAsic
config_facts
care
'host
module
case
config_facts
multi-dut
DutHosts
value
'host
hard
node
def
config_facts
module_args
*
*
complex_args
complex_args
complex_args
]
=
self.sonichost.hostname
self.sonichost.facts
'num_asic
]
=
complex_args
'namespace
]
=
self.asic_index
return
self.sonichost.config_facts
*
module_args
*
*
complex_args
issue
above
call
Make
call
w/out
host
config_facts
SonicAsic
care
host
ansible
module
duthosts.frontend_nodes.config_facts
method
host
asics
above
last
commit
i
check
'num_asic
==
call
'num_asic
greater
comments
docstring
example
def
__getitem__
index
operations
duthosts
]
duthost
[
]
Args
index
int
string
Index
hostname
duthost
KeyError
duthost
supplied
hostname
IndexError
duthost
supplied
index
Returns
[
MultiAsicSonicHost
]
specified
duthost
duthosts
instance
MultiAsicSonicHost.
Comments
sad
opton
comments
comments
Add
comments
sad
option
comment
Few
general
comments
test
X
results
'show
techsupport
executions
available
switch
much
time
command
case
X
minutes
error
case
logs_since
minutes
ready
minutes
error
files
end
test
sure
much
test
disk
test
Add
space
add
example
entries
Could
comments
way
descriptive
name
partial_ptf_runner
sure
partial
good
alternatives
😅
spine
ports
non-T0
topologies
T1
lag
suggestion
important
Policer
test
case
regular
packet
easier
troubleshooting
tt
better
something
case
exception
comment
conditional
above
condition
meaningful
comment
values
part
duthost.facts
chassis_truth
chassis_facts
same
https
//github.com/Azure/sonic-mgmt/pull/2209/files
diff-5d04a73b4b142807edb8c343db1d80dbR69
Please
same
truth
variables
Suggest
chassis_facts
None
completeness
comment
function
kind
port
info
'=
suggestion
timeout=timeout
exp_pkt=exp_pkt
filters=
[
]
servers
same
IP
TODO
Parse_Lab_Graph
conn_graph_facts
module
conn_graph_facts
single
device
information
fanouthosts
fanout
switches
lab_graph
deviecs
hostname/type/mgmtip/
TODO
os
type
device
hwsku
mapping
file
sure
right
way
os
type
line
tests
sanity
check
port
part
lag
packet
port
port
root
INFO
packet
root
INFO
fe:90:5e:6b:04
>
b1:1c
f4
a8:53
>
root
INFO
packet
port
Test
case
tests
CPU
verifies
CPU
one
stuck_out_tongue
suggestion
bundles
index
empty
index
no-op
suggestion
bundles
index
empty
index
no-op
one
Could
comments
>
nit
comment
suggestion
param
packages
list
strings
names
packages
line
accessible
people
internal
network
Might
good
idea
length
auto
uuid
relatedImages
method
noop
case
time
code
curious
request
handler
something
place
request
handler
session
request
fragile
like
ValidationError
only
kind
error
appropriate
exception
others
text
https
//flask-sqlalchemy.palletsprojects.com/en/2.x/quickstart/
code
useful
>
session
’
t
end
request
Flask-SQLAlchemy
Could
auto
comments
file
consistent
rest
docstring
suggestion
param
list
deprecation_list
list
deprecated
bundles
target
index
image
tag
.\codespell_lib\_codespell.py:41:80
E501
line
characters
'for
corrections
en-GB
en-US
https
//en.wikipedia.org/wiki/Language_localisation
Language_tags_and_codes
key
to_en_US
to_en_us
lower
case
people
option
choice
stuff
https
//en.wikipedia.org/wiki/Locale_
computer_software
POSIX_platforms
non-US
spellings
Australian
way
something
suggest
ability
likely
rare
ambiguous
way
round
dictionary
typo
column
suggestion
replacement
Which
true
clear
interactive
mode
error
typo
easiest
error
correct
capitalisation
lower
case
Tim-
>
time
tim-
>
time
Tim
interactive
mode
downside
stops
case
changes
future
e.g
WI-Fi
Wi-Fi
bit
dictionary
work
order
suggestions
corrections
proper
names
possible
clear
whole
test
whole
thing
commit
case
loop
right
EX_OK
EX_DATAERR
EX_USAGE
same
value
BSD
years
mkfifo
Unix
Windows
test
platforms
template
script
prometheus
documentation
feeling
Prometheus
metrics
prometheus
resource
code
proper
exception
driver
s
https
//github.com/gnocchixyz/gnocchi/blob/master/gnocchi/storage/incoming/_carbonara.py
L47-L48
NUM_SACKS
value
drivers
None
//github.com/gnocchixyz/gnocchi/blob/master/gnocchi/storage/incoming/_carbonara.py
L45
int
None
failure
i
sure
error
drivers
None
https
//github.com/gnocchixyz/gnocchi/blob/master/gnocchi/storage/incoming/_carbonara.py
L45
https
//github.com/gnocchixyz/gnocchi/blob/master/gnocchi/storage/incoming/_carbonara.py
L49
Change
NumSackReadingError
e
better
name
sorry
patch
line
change
Exception
NumSackReadingError
way
sure
good
reason
WDYT
sure
super
user
likely
user
CLI
better
error
message
pass
tuple
names
rados
documentation
parameters
particular
Sorry
set
O
queries
kept_ratings
=
Rating.objects.filter
work_id=final_work.id
user_id__in=all_user_ids
iterate
tuple
better
right
Same
comment
variable
names
matrixT
type
Remove
code
parameter
different
row
column
variables
Parameter
Please
Ru
Vu
least
doc
function
Remove
code
please
fit_user
unused
matrix
context
type
np.array
dict
user
ID
need
make_matrix
defaultdict
dict
tuple
user
work
base
class
function
types
Yes
code
queryset
slugs
Role
s
objects
FIXME
cache
query
lang_cache
contents
lifetime
deployment
Tu
utiliser
Espaces
stp
morphism
[
-1
]
Mais
ce
que
tu
écris
est
correct
C'est
juste
lisible
Ce
serait
bien
nb_posters
TODO
marker
FIXME
someone
mangaki/
*
*
bias
sure
path
preferable
[
]
https
//docs.python.org/3.5/library/os.path.html
os.path.join
Done
row
Curious
same
self.V
*
version
due
NumPy
explicit
usage
Nit
false
obvious
serializable
p.
Nit
space
FM
FMA
model
fact
baseline
stupid
model
Could
exception
user
unexpected
errors
[
lowercase
version
parameter
comment
example
python
[
anime_category
[
'like
Work
'choice
Work
]
manga_ategory
[
'choice
'like
Work
complex
due
list
comprehensions
helper
function
Otherwise
comments
helpful
dict
list
simpler
dict
comprehension
dict.items
tuple
form
idea
performance
c'est
int_poster
qui
le
…
je
sais
vraiment
pas
quoi
pour
toi
*
*
Micro-optimization
/
Nice
*
*
evaluation
to_delete
afraid
bogus
operations
same
condition
short-circuit
case
to_delete
==
True
Python
documentation
short-circuit
operators
]
https
//docs.python.org/3/library/stdtypes.html
boolean-operations-and-or-not
*
*
language
example
short-circuiting
*
*
same
principle
C/C++
cpp
bool
=
is_he_really_sleeping
raito
raito
expensive
function
=
true
context
double
fallback
happens
comment
thanks
Done
Care
comment
D
everything
Good
candidate
list
comprehension
Good
candidate
collections.namedtuple
change
old
behavior
proper
way
dataset
algo
=
fit_algo
algo_name
triplets
end
algo_name
==
'knn
try
..
block
part
KNN
offline
backups
triplets
exists
complex
fragile
code
current
behavior
new
change
look
wrong
@
jilljenn
best
part
code
situation
simple
fix
triplets
exists
KNN
upfront
@
jilljenn
input
discussion
issue
First
KNN
neighbors
user
ratings
rating
database
works
Second
KNN
ratings
neighbors
order
recommendations
case
Elarnon
@
jilljenn
behaviour
second
KNN
part
part
behaviour
behavior
KNN
triplets
smaller
subset
algo
KNN
different
sets
ratings
understand
@
jilljenn
mind
look
Retire
ce
commentaire
pas
nécessaire
l'import
aussi
@
patch
line
something
more
explicit
E.g
'http
//example.com/kiznaiver.jpg
equivalent
assertEqual
Counter
list
posters
Counter
list
*
*
assertItemsEqual
equivalent
posters
course
assertItemsEqual
Python
Funny
unhashable
objects
e.g
dict
assertEqual
Counter
list
posters
Counter
list
assertEqual
posters
same
thing
error
first
case
more
explicit
unhashable
object
same
thing
Mock
implementation
top
head
def
assertCountEqual
first
second
items
first_counts
[
]
[
]
first_el
first
try
first_counts
items.index
first_el
ValueError
items.append
first_el
first_counts.append
second_counts
_
first_counts
second_el
second
try
second_counts
items.index
second_el
ValueError
raise
ValueError
%
s
present
second
first
%
second_el
el
first_count
second_count
zip
items
first_counts
second_counts
first_count
=
second_count
raise
ValueError
%
s
present
%
d
times
first
%
d
times
second
%
el
first_count
second_count
non-hashable
objects
.index
uses
==
comparison
Alright
right
number
poster
correct
values
correct
anything
order
list
acceptable
shallow
equality
mistake
assertCountEqual
b
b
same
elements
same
number
order
hell
good
name
dance
mocked_search.return_value
=
NonCallableMock
poster=None
simpler
manner
create
map
anidb_aid
list
works
anidb_aid_works
defaultdict
list
work
works
anidb_aid_works.append
list
anidb_aid_works
more
element
list
need
supplementary
queries
works
everything
nothing
more
O
works
speed
wrong
comment
use
help_text
supprimer
decimals
std
part
format
decimals
floating
point
expert
values
digits
digits
way
floating
point
imprecisions
Codacy
issue
[
indented
block
<
string
>
line
]
https
//app.codacy.com/manual/cvat/cvat/pullRequest
prid=5677001
enumerate
@
MalekMFS
code
points
polylines
azhavoro
Done
Hi
@
Happyzippy
thanks
contribution
Could
comment
change
known
issue
PIL
https
//github.com/python-pillow/Pillow/issues/2574
difficult
change
future
comments
property
segment_shapes
Could
comment
possible
shape
outside
==
True
Thus
shape
wrong
suggestion
def
has_overlap
b
return
<
=
min
b
stop
max
start
suggestion
azhavoro
performance
issue
point
view
Just
solution
good
bad
general
possible
solutions
[
'interpolated_shapes
]
=
[
]
interpolate
end
case
trivial
shape
till
end_frame
Please
comment
YOLO
format
code
future
sleep
agents
reconnection
necessary
nodecellar
blueprint
new
hostpool-plugin
version
tag
code
dir
plugin
side
Thanks
nice
touch
shot
difference
i
cluster
global
var
Need
second
bootstrap
comment
Aha
second
global
line
cluster
cluster
fixture
manager
neater
globals
able
cosmo_tester.framework.fixtures
bootstrap_based_manager
new
fixture
cute
P
May
force
force
test
snapshot
full
manager
leftover
module
diff
info
future
debugging
purposes
deployments
comment
comments
docstring
relevance
beginning
function
new
string.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
whitespace
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1877894
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Method
function
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1667059
b_init
self.all_params.extend
b_init
self.all_params.extend
[
bi
]
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
variable
'step
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=2273849
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
variable
'step
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=2273849
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
variable
'transform_matrix
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=2273849
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
statement
effect
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=2273849
scope
comment
users
description
comment
comment
comment
comment
comment
comment
comment
remove
comments
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Possible
password
'password
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1937730
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
import
time
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1937730
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Possible
password
'password
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1937730
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
variable
'y_train
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1995899
comment.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Argument
position
keyword
constructor
call
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1460721
something
comments
kind
annoying
least
numpy
expression
time
smile
percentage
format
returned
percentage
needs
line
able
/
able
suggestion
return
%
.format
able
/
able
weekday
datetime
uses
Monday
zero-index
others
script
Could
comment
suggestion
wed_ablock.activities.add
scheduled_activity
suggestion
now.hour
>
settings.BUS_PAGE_CHANGEOVER_HOUR
afternoon
behavior
other
pages
suggestion
dest_act
EighthScheduledActivity
duplicate_students
pylint
disable=unsubscriptable-object
Type
annotations
function
calls
past
type
annotations
parameters
User
eighth/models.py
depends
users/models.py
circular
import
issues
possible
circular
import
issue
matter
PR
comment
Nit-pick
Maybe
commas
uppercase
period
comments
memoization
Well
i
functions
module
first
time
memoization
sufficient
corresponding
list
comprehension
definition
constants
suggestion
various
ways
recommendation
FIPS
related
recommendation
L
available
FIPS
algorithms
different
user
government
safe
thing
silent
kind
information
other
/etc/pulp/settings.py
out
settings.py
safe
users
constant
somewhere
Artifact
https
//github.com/pulp/pulpcore/blob/master/pulpcore/constants.py
Black
single
quotes
suggestion
unnecessary
memory
allocation
rpm_remote_body
=
gen_remote
url=RPM_UNSIGNED_FIXTURE_URL
=
self.client.post
RPM_REMOTE_PATH
rpm_remote_body
py
rpm_remote
=
self.client.post
RPM_REMOTE_PATH
gen_remote
url=RPM_UNSIGNED_FIXTURE_URL
_body
variable
place
numbers
indexes
Mind
pks
]
suggestion
repeat
modulo
operations
input
unitary
re
brief
comments
branch
simple
1-liner
fine
future
developers
bugs
meant
PR
suggestion
Exactly-calculated
feature
vectors
graphs
MUTAG
dataset
suggestion
feature
vectors
graphs
MUTAG
dataset
suggestion
Monte-Carlo
feature
vectors
same
molecules
numpy.savez_compressed
multiple
arrays
compressed
manner
.npz
file
suggestion
Exactly-calculated
feature
vectors
randomly
molecules
unit
base_unit
type
unit
more
logical
name
construction
unit
portions
code
flask
module
proper
attribution
example
decomposition
Worth
suggestion
NOTE
deepcopy
copies
parameters
things
suggestion
Xunitary
compiler
default
devices
suggestion
dense
clusters
higher
probability
good
number
visualization
purposes
Bear
mind
sphinx-gallery
output
line
Jupyter
notebook
anything
print
statement
good
simple
terms
e.g
x
square
grid
points
standard
notion
outlier
more
usual
sense
word
outlier
point
cluster
suggestion
large
entries
permanent
matrix
sum
product
suggestion
standard
deviation
math
x
=
y
]
math
x
=
y
]
lines
better
flow
tutorial
hard
proportion
points
outliers
suggestion
kernel
matrix
samples
lines
code
n_mean
float
RBF
such
kernel
high-density
outlier
different
lines
creation
plot
plot.plot_points
actual
plotting
plotly.offline.plot
suggestion
frequent
points
majority
commonly
suggestion
other
matrix
elements
larger
entries
suggestion
standard
deviation
math
x
=
y
]
math
x
=
suggestion
standard
deviation
clusters
math
x
=
y
]
math
x
=
way
line
e.g
variable
grid
suggestion
sample
points
dense
regions
higher
probability
feature
GBS
point
suggestion
standard
deviation
math
x
=
y
]
math
x
=
line
better
more
detailed
information
blobs
.e.g
clusters
points
points
dense
clusters
standard
deviation
sure
difference
function
docstring
Really
nice
docstring
nice
docstring
cutoff
cutoff
max_val
docstring
worth
Lorentzian
function
docstring
graph
subpackage
apps
multiple
applications
graph-based
submodule
best
'frontend
SF
suggestion
Functions
dense
subgraphs
func
find_dense
function
module
useful
things
pylint
useful
lines
SF
syntax
Nice
terms
high-level
'wrapper
functions
one
clearest
docstring
short
essential
logic
Nice
Let
PR
new
issue
Yep
issue
sf.decompositions.rectangular_decomposition
function
best
approach
output
decomposition
parameters
%
*
np.pi
something
similar
range
*
pi
@
lneuhaus
range
angle
parameters
end
number
conversions
cumbersome
way
equality
programs
useful
feature
Program.__eq__
other
special
method
order
nx.is_isomorphic
check
CircuitSpecs.compile
account
parameter
values
prog1
==
prog2
tests
X12_1
X12_2
sure
len
modes
English
case
sample
sequence
integers
length
i.e.
len
modes
suggestion
fewer
samples
number
samples
good
explanation
suggestion
list
modes
list
modes
subgraph
practice
*
*
suggestion
threshold
sampling
enough
select
nodes
subgraph
suggestion
example
]
sample
GBS
]
classical
algorithm
quantum
process
suggestion
setting
GBS
subgraphs
likely
Subgraphs
graph
wink
sentence
bit
strange
mean
photon
number
number
samples
line
>
postselect
function
suggestion
plot_size
int
point_size
int
>
go.Figure
pragma
cover
case
other
functions
Strawberry
Fields
tf
backend
TensorFlow
suggestion
following
line
Strawberry
Fields
Sphinx
import
tf
backend
TensorFlow
__version__
suggestion
[
]
multiple
times
sense
c_1
[
]
node
subgraph
other
snippets
subgraph
clear
subgraph
clique
argument
function
clique
https
//github.com/XanaduAI/strawberryfields/pull/178
sure
things
consistent
suggestion
>
>
>
graph
=
nx.lollipop_graph
>
>
>
graph.remove_edge
>
>
>
graph.remove_edge
>
>
>
subgraph
=
[
]
>
>
>
resize.clique_swap
subgraph
graph
node_select=
degree
]
example
use
node_select
argument
Could
comment
determines
number
modes
+2
suggestion
test
different
numbers
modes
data
extra
quotes
difference
reason
separate
U0
U4
separate
calls
MZ
decomposition
single
U
matrix
identity
beamsplitters
rotation
gates
modes
Kind
reason
programs
MeasureFock
modes
hardware
simulation
output
matches
software
simulation
output
hardware
samples
modes
whereas
simulators
None
mode
same
compiled
program
different
values
different
backends
suggestion
suggestion
suggestion
suggestion
compilation
Chip2
circuit
specification
better
things
i
s2gates
multiple
times
same
mode
test
ii
s2gates
signal
idler
modes
test
docstring
clear
MZ
gates
docstring
come
suggestion
Test
compilation
interferometer
rectangular_symmetric
mesh
MZ
gates
suggestion
t
self._times_to_indices
below
statement
comment
direct
suggestion
state
mixed
suggestion
state
mixed
usage
res
print_fn
bit
tests
easy
flow
brief
explanatory
comment
useful
suggestion
sizes
specified
range
values
dictionary
top
subgraphs
items
dictionary-value
pairs
https
//www.geeksforgeeks.org/python-dictionary-items-method/
suggestion
graph
graphs
nodes
random
graphs
nodes
vertices
suggestion
func
~.subgraph.search
function
mod
~.gbs.subgraph
module
collections
dense
Kamada
Kawaii
deterministic
result
docstring
nice
suggestion
plot.ly
plot
input
subgraph
standard
colour
scheme
module
worth
more
information
exception
example
command
install
URL
useful
resource
something
SF
documentation
plot.ly
installation
guide
suggestion
l
dict
[
int
float
]
dictionary
nodes
respective
coordinates
NetworkX
<
https
//networkx.github.io/documentation/latest/
reference/drawing.html
module-networkx.drawing.layout
>
true
example
following
case
python
prog.context
q
Sgate
|
q
]
MeasureX
|
]
resets
]
vacuum
Xgate
q
]
.par
q
]
MeasureFock
q
]
Minor
suggestion
worth
small
comment
e.g
op
measurement
samples
test
dangerous
n_mean
number
modes
better
n_mean_vec_click
[
]
]
>
=
n_mean_vec_click
[
]
second
inequality
true
construction
comment
modes
variable
devicespec
arbitrary
number
modes
actual
circuit
modes
something
self.blackbird_template
template
curious
Dgate
parameter
suggestion
Test
compilation
device
topology
subheader
Steps
analytic
result
end
value
*
n_mean_by_mode
*
objectives
better
overview
code
structure
test
suggestion
TODO
add
validation
device
specs
dictionary
device.modes
get_available_config_paths
function
initial
docstring
summary
[
]
faster
documentation
building
good
consistent
examples
[
]
]
suggestion
pylint
disable=expression-not-assigned
[
image
]
https
//user-images.githubusercontent.com/49409390/66776959-a9557a80-ee95-11e9-8d22-dceb30c3ed72.png
something
new
postselect
function
order
line
largest
clique
print
'Largest
clique
=
DIMACS
http
//iridia.ulb.ac.be/~fmascia/maximum_clique/DIMACS-benchmark
flow
TACE-AS
graph
program
PHat
suggestion
cliques
graph
size
many
look
first
suggestion
TA
=
gbs.data.TaceAs
largest
samples
suggestion
adjacency
matrix
TACE-AS
graph
mod
~.gbs.data
module
suggestion
tutorial
samples
clicks
total
suggestion
graph
mod
~.gbs.plot
module
version
docs
avg
clique
size
_all_
cliques
maximum
size
max
clique
size
suggestion
TACE-AS
graph
small
large
cliques
difficult
suggestion
mod
~.gbs.clique
module
larger
cliques
graph
suggestion
use
pre-generated
samples
TACE-AS
graph
mod
~.gbs.data
module
post-select
samples
specific
number
clicks
suggestion
Note
processing
state-based
post-processing
previous
comment
suggestion
grad
=
tape.gradient
var
]
suggestion
quantum
free
parameter
engine.
sentence
Minor
suggestion
suggestion
gradient
tape
context
Minor
suggestion
comparable
specific
type
tensor
suggestion
Measurement
results
s
shape
suggestion
TensorFlow
variable
engine
suggestion
argument
backend_options
dictionary
[
]
_
e.g.
suggestion
test
gradient
variance
correct
example
picture
samples
funneled
orbits
funneled
events
suggestion
scikit-learn
Support
Vector
Machine
LinearSVC
<
https
//scikit-learn.org/stable/modules/generated/sklearn.svm
Better
frequencies
suggestion
graphs
feature
space
GBS
trained
SVM
link
function
good
first
three-dimensional
feature
vectors
function
choice
bit
more
motivation/explanation
true
other
tutorials
worthwhile
note
command
docs
user
plot_mutag_0.show
suggestion
second
method
Monte
Carlo
approximation
use
scenarios
data
way
1-sentence
explanation
reader
motivation
guidance
reading
example
example
features
relative
frequencies
certain
types
measurements
GBS
device
sure
measure
right
word
calculate
estimate
Nice
note
suggestion
point
high-dimensional
space
standard
approaches
machine
suggestion
Given
points
feature
space
target
labels
interesting
different
numbers
samples/
precisions
suggestion
compound
mutagenic
effect
graphs
labels
term
17-photon
event
math
photon
event
better
way
modes
suggestion
calculating
math
p_
k
challenging
number
samples
suggestion
likely
interested
coarse-graining
further
clear
kernel
methods
similarities
feature
vectors
something
power
feature
vectors
graphs
vector
space
real
numbers
similarities
graphs
useful
machine
learning
similar
labels
close
other
GBS
feature
vectors
rise
similarity
measure
graphs
way
GBS
feature
vectors
Support
Vector
Machine
hyperplane
classes
feature
space
combine
suggestion
random
resultant
probabilities
math
use
Reminder
import
structure
tutorials
suggestion
high-dimensional
feature
space
technique
machine
learning
long
sentence
bit
mouthful
coarse-graining
*
*
events
*
*
event
combination
orbits
same
photon
number
suggestion
Monte
Carlo
estimate
probability
alternative
Monte
Carlo
approximation
suggestion
Orbits
useful
way
samples
GBS
outcomes
suggestion
GBS
feature
vectors
labels
graphs
two-dimensional
suggestion
sampling
]
means
photons
separate
mode
sentence
bit
properties
feature
space
vectors
lines
data
module
bit
context
suggestion
plot
due
statistical
approximation
suggestion
structure
chemical
compounds
*
label
*
same
for-loop
single-shot
batches
first
index
val
suggestion
i
r
enumerate
cmd.reg
Retrieve
index
value
Values
nested
sequence
tup
=
reg.ind
val
]
[
]
self._all_samples.append
tup
batches
samples_dict
[
r.ind
]
=
val
[
suggestion
suggestion
MeasureFock
GaussianUnitary
checks
symplectic
matrix
identity
suggestion
parameters
GaussianUnitary
compiler
docstrings
other
args
DeviceSpec
snippet
DeviceSpec
target
X8_01
import
strawberryfields
sf
import
strawberryfields.ops
ops
strawberryfields.utils
random_interferometer
U
=
random_interferometer
strawberryfields.api
import
DeviceSpec
import
textwrap
test_spec
=
layout
textwrap.dedent
name
template_4x2_X8
version
target
X8_01
shots=1
n
spatial
degrees
n
signal
modes
n
idler
modes
phases
S2gate
squeezing_amplitude_0
|
]
S2gate
squeezing_amplitude_1
|
]
S2gate
squeezing_amplitude_2
|
]
S2gate
squeezing_amplitude_3
|
]
standard
interferometer
signal
modes
lower
ones
frequency
indices
correspond
internal
Mach-Zehnder
interferometer
phases
odd
phase
indices
correspond
external
Mach-Zehnder
interferometer
phases
MZgate
phase_0
]
MZgate
phase_2
]
MZgate
phase_4
]
MZgate
phase_6
]
MZgate
phase_8
]
MZgate
phase_10
]
interferometer
idler
modes
higher
ones
frequency
MZgate
phase_0
]
MZgate
phase_2
]
MZgate
phase_4
]
MZgate
phase_6
]
MZgate
phase_8
]
MZgate
phase_10
]
final
dummy
phases
unitary
template
photon
number
measurement
Rgate
]
Rgate
]
Rgate
]
Rgate
]
Rgate
]
Rgate
]
Rgate
]
Rgate
]
measurement
Fock
basis
MeasureFock
]
modes
compiler
[
]
gate_parameters
squeezing_amplitude_0
[
]
squeezing_amplitude_1
[
]
squeezing_amplitude_2
[
]
squeezing_amplitude_3
[
]
phase_0
[
]
]
phase_1
[
]
]
phase_2
[
]
]
phase_3
[
]
]
phase_4
[
]
]
phase_5
[
]
]
phase_6
[
]
]
phase_7
[
]
]
phase_8
[
]
]
phase_9
[
]
]
phase_10
[
]
]
phase_11
[
]
]
final_phase_0
[
]
]
final_phase_1
[
]
]
final_phase_2
[
]
]
final_phase_3
[
]
]
final_phase_4
[
]
]
final_phase_5
[
]
]
final_phase_6
[
]
]
final_phase_7
[
]
]
def
generate_X8_params
r
p
return
squeezing_amplitude_0
r
squeezing_amplitude_1
r
squeezing_amplitude_2
r
squeezing_amplitude_3
r
phase_0
p
phase_1
p
phase_2
p
phase_3
p
phase_4
p
phase_5
p
phase_6
p
phase_7
p
phase_8
p
phase_9
p
phase_10
p
phase_11
p
final_phase_0
final_phase_1
final_phase_2
final_phase_3
final_phase_4
final_phase_5
final_phase_6
final_phase_7
X8_spec
=
DeviceSpec
target=
X8
connection=None
spec=test_spec
<
X8
target
X8_01
params
generate_X8_params
prog
=
X8_spec.create_program
*
*
params
eng
=
sf.RemoteEngine
X8_01
device
=
eng.device_spec
=
eng.run
prog
shots=10
device
target
compiler
compiled
programs
check
bit
more
fine
example
program.compile_info
None
program
uncompiled
msg
=
f
program
device
device.target
compiler
compiler_name
self.log.info
msg
program
=
program.compile
device=device
*
*
compile_options
program.compile_info
]
=
device
program
different
device
ValueError
f
program
program._compile_info
]
.target
target
program
=
program.compile
device=device
*
*
compile_options
program.compile_info
]
=
compiler_name
program
device
different
compiler
compile_options
None
optional
validation
check
much
compilation
program.compile
device=device
compiler=
Xstrict
user
compile_options
engine
best
program
=
program.compile
device=device
*
*
compile_options
comment
remnant
part
compile_options
thinking
bullet
point
list
backticks
Do
get_layer
name
infinite
recursion
hierarchical
path
Rather
name.split
'/
]
self.layers
right
code
layer_name
comment
number
spaces
Python
statement
comment
line
long
such
cases
comment
line
Python
statement
inefficient
way
shape
sequence
mask
sth
suggestion
value
=
tf.reshape
value
tf.shape
self.loss.output.placeholder
:2
]
batch
time
time
batch
documentation/comments
consistent
Just
tuple
batch
write
same
way
wrong
scope=LayerBase.cls_get_tf_scope_name
layer_name
network.get_params_list
comment
size
lists
Just
reverse
order
sorted
axes
initializer
generic
shape
case
other
shape
sample_rate
*
length
num_channels
possible
check
assert
shape
==
reshape
Better
typing.TextIO
warning
suggestion
log_stream
=
sys.stdout
type
typing.TextIO
type
clear
code
suggestion
log_stream
=
type
type
io.TextIOBase
suggestion
tf.shape
input_placeholder
]
//
nr_of_channels
shape
B
x
T
x
C
x
F
/
C
sure
comment
accurate
Commented
code
super
init
event
ABC
implementation
reason
disable
comment
comment
lines
future
readers
sys
stuff
function
test
body
line
settings
snake-cased
pylint
disable
no-self-use
Interesting
parameter
function
Same
Same
avoid
list
comprehension
same
thing
..
Same
comment
above
AzdevExtension
AzdevExtension
AzExtension
module
ok
same
function
linter
AzExtension
function
sure
good
idea
cli
command
current
one
code
cleanup
Thanks
path
construction
way
nit
log
analytics
China
East2
region
Would
WebappsExtCommandLoader
azure-cli-appservice
module
name
sure
class
names
future
clear
Add
min_profile
command
available
Azure
Stack
users
https
//github.com/Azure/azure-cli/blob/dev/src/command_modules/azure-cli-cognitiveservices/azure/cli/command_modules/cognitiveservices/__init__.py
L22
typo
returs
nice
[
common
param
]
https
//github.com/Azure/azure-cli/blob/dev/src/command_modules/azure-cli-vm/azure/cli/command_modules/vm/_params.py
L122
azure-cli-vm
verbose
flag
more
values
configuration_type
future
name
config_count
fine
IMO
fix
robust
chars
first
char
resources
extension
many
sense
process
sense
blob
containers
tags
single
parallel_degree
==
min
target_locations_count
right
least
location
comment
is_update_allowed
tomorrow
TODO
mode
'Timestep
appropriate
weird
formatting
yapf
use
yapf
disable
helper
classmethod
TEPPO
painful
PEARL
RL2
examples
hmm
param
function
module
obj
type
i
protected
access
please
commented-out
code
completion
bonus
necessary
stability
completion
bonus
large
AverageReturn
positive
agent
environment
e.g
negative
path
rewards
goal
Please
commented-out
code
incorrect
comment
second
item
N
A
wrong
comment
blocks
tests
test
tests
more
test
methods
input
exception
test
case
sure
environment
present
pkl
file
iteration
e.g
F401
F811
pytest
requirements
tests/
*
setup.cfg
[
flake8.per-file-ignores
]
*
tests/garage/pylintrc
[
MESSAGES
CONTROL.disable
]
previous
comment
properties
i.e
attributes
previous
comment
properties
i.e
attributes
caller
docstring
caller
Plotter.enable
please
random
data
tests
difficult
deterministic
longer
necessary
justifcation
E501
pylint
warning
losses
separate
functions
write
tests
same
values
same
inputs
types
tests
strongest
performance
regressions
work
CPU
devices
sense
set_gpu
function
line
i
able
yapf_disable
right
@
params
statement
whole
block
form
yapf
disable
stuff
more_stuff
yapf
enable
comment
TimeLimit.truncated
False
wrong
Please
logic
correct
case
users
key
TimeLimit
use
fixtures
explicit
loop/assert
test
body
fixtures
functions
pytest
fixtures
resource
class
kind
metaprogramming
function
times
different
other
samplers
Please
more
documentation
function
pickle.loads
pickle.dumps
i
most
public
utilities
please
documentation
test
fixtures
old
policy
params
time
multiple
gradient
steps
old
policy
old
policy
sure
correct
@
krzentner
old
policy
object
copy.deepcopy
old
policy
last
gradient
step
iteration
@
yonghyuc
reason
private
method
inline
methods
rare
Python
FYI
_private
methods
docstrings
welcome
arguments
disable
something
arugments-differ
violation
line
whole
class
non-obvious
pylint
disable
nearby
comment
~
..
math
Y
~
\mathcal
N
\sigma
X
=
tanh
Y
excellent
opportunity
math
environment
sphinx
rendered
latex
docstrings
code
spaces
indents
please
interface
comments
sample
documentation
style
Returns
torch.tensor
Log
likelihood
Might
docstring
value
correct
easier
true
value
method
namedtuple
ordinary
method
multiple
return
values
pythonic
overhead
use
multiple
returns
tuple
Python
equivalent
returns
as-such
python
Returns
torch.Tensor
Samples
distribution
torch.Tensor
Samples
underlying
obj
torch.distributions.Normal
distribution
tanh
Ditto
@
krzentner
siblings
children
i
siblings/twins/clones
apt
description
children
tree
structure
hierarchical
mdoels
consistent
documentation
coverage
system
multiple
comments
double
quotation
single
quotation
unittests
suggestion
tf.variable_scope
'dist_params
default
GaussianMLPPolicy
build
interface
i
Foo
constructor
parameter
Bar
return
return
func
GaussianMLPPolicyWithModel2
interface
tf.exp
comment
blocks
different
test
cases
setUp
/
sure
common
code
test
executs
value
value
action
more
concise
way
inputs
outputs
output
simple
policy
policy.model.networks
]
trivial
reviewers
ok
single
quotation
Please
different
name
input
Comments
better
garage.torch
garage.torch.algos
rule
please
per-line
disables
per-file
per-function
exceptional
circumstance
stanza
per-line
disable
methods
def
__setstate__
state
self.__dict__.clear
top
update
self.__dict__.update
state
@
krzentner
WDYT
temporary
files
code
idea
location
writable
i
tempfile
library
comment
files
problematic
commented-out
code
MOCK_ABS
MOCK_SCALED
constants
top
file
f-strings
Python
Python
compatibility
format
_mock_counter
necessary
need
\
inside
f-expressions
python
compliant
please
consistent
use
most
garage
code
english
language
unnecessary
comment
f-expressions
unsupported
Python
superfluous
print
necessary
superfluous
prints
tests
news
good
news
\
comments
similar
statement
important
step
comment
line
line
length
i
line
length
noqa
E126
yapf
code
Flake8
E126
continuation
line
over-indented
indent
difficult
afoul
style
checker
cases
constants
top
file
parameterize
case
simpler
easier
large
static
numpy
arrays
top
file
np.repeat
/
np.expand_dims
couple
minutes
actual
inputs
delete
commented-out
code
commented-out
code
actual
returns
please
test
setup
phase
cases
major
assertions
easier
E122
i
block
formatting
reason
line
Remove
comment
Remove
comment
Remove
comment
tests
xunit
style
i
message
return
type
python
torch.Tensor
Reshaped
view
data
analogous
padding
kernel
size
need
restriction
value
addition
shape
CNN
correct
output
xunit
style
new
tests
pytest
style
anything
.train
meaningful
tests
flaky
provide
shape
documentation
dicts
something
outputs
please
commented-out
code
please
commented-out
code
way
stuff
primitives
algorithms
constant
PEARL
experiment
i
tuple
params
function
defaults
default
args
style
wrap_experiment
API
nose
anymore
disable
YAPF
lines
pragma
paths
util
sampler
parallel_sampler
Please
function
pylint
necessary
codebase
look
examples
suggestion
change
individual
response
page
broad
exception
comment
output
issue
message
logs
publish_and_resolve_message
Just
readability
preference
private
methods
public
class
flow
reading
code
_publish
comment
redundant
clear
code
current
list
name
incorrect
list
length
something
suggestion
list
add
blocks
list
item
id
available
list_item_position
position
list
method
name
consistent
generic
asserts
assert
e.g
_assert_last_viewed_question_guidance_not_shown
properties
property
methods
access
attributes
tests
navigation
test
class
name
appropriate
class
group
suggestion
page
test
file
needs
consistency
Given
comments
self.post
assert
HTTP
status
code
text
text
pages
tests
other
checks
following
tests
Page
suggestion
suggestion
address
suggestion
def
suggestion
individual
response
introduction
page
endpoint
better
url
content
name
compromise
clear
get_remaining_relationship_to_list_item_ids_for_individual
relationships
current
location
relationships
notion
ones
something
generic
get_list_summary_list_item_ids
indication
list
item
ids
comment
relevant
file
CDN
comment
action
assertion
test
assertion
error
GET
limit
loop
times
limit
assert
GET
SEND_FEEDBACK_URL
returns
error
assert
POST
SEND_FEEDBACK_URL
returns
error
top
level
var
url
send
sent
URLs
multiple
times
warrants
top
level
variable
line
characters
line
characters
code
cleaner
disable
True
default
tqdm_options
logic
verbose
tqdm_options.update
'disable
False
progress_callback
None
progress_bar
updates
tqdm_options.update
open
os.devnull
w
comment
block
something
Call
functions
other
libraries
featuretools
only
reason
make_time_index
exists
base
entity
better
explicit
assertion
install
primitives
tests
single
parameterized
test
TODO
TODO
bit
weird
method
run
time
self.primitive_function
None
self.primitive_function
self.get_function
return
self.primitive_function
data
comment
groupby
helpful
comment
case
primitive
multiple
inputs
cleaner
zip
[
vf
m
vf
m
zip
variable_filter
match
todo
primitive
input_types
[
Id
Numeric
]
entity
Id
columns
CUM_COUNT
matching
inputs
[
id_1
]
[
]
code
CUM_COUNT
id_1
id_1
CUM_COUNT
id_2
id_2
CUM_COUNT
id_1
id_2
CUM_COUNT
id_2
id_1
performant
added
question
stackoverflow
https
//stackoverflow.com/questions/55731149/use-a-function-instead-of-string-in-pandas-groupby-agg
Can
TODO
only
necessary
DateOffset
different
temporal
values
DateOffset
unit
i
secondary_time_index
reference
function
true
i
let
least
comment
i
self._create_variables
user
call
code
comment
code
line
@
adekusar-drl
multi-start
logic
COBYLA
wrapper
same
code
other
optimizers
copyright
brand
new
file
Use
List
[
type
]
list
*
List
[
element
type
]
list
*
optional
signature
orbsym
Optional
[
List
[
element
type
]
]
=
None
docstring
slightly_smiling_face
types
typing
i.e
import
List
Optional
first
import
*
sure
orbsym
list
int
*
default
value
present
signature
docstring
suggestion
def
dump
q_mol
QMolecule
outpath
str
orbsym
Optional
[
List
[
int
]
]
=
None
isym
int
>
None
Convenience
method
FCIDump
output
file
Args
outpath
Path
output
file
q_mol
QMolecule
data
HF
energy
QMolecule
instance
inactive
core
energy
orbsym
list
spatial
symmetries
orbitals
isym
spatial
symmetry
wave
function.
suggestion
]
*
len
norb
TODO
suggestion
FCIDump
output
fcidump
path
FCIDump
file
Returns
Dictionary
data
QiskitChemistryError
file
invalid
input.
raise
message
user
whats
wrong
possible
TODO
question
Note
Unitary
simulator
becomes
Quantum
Info
operator
comment
Minor
comment
x
list
[
float
]
ndarray
sense
ndarray
case
list
ndarray
e.g
type
setter
sense
suggestion
data
type
numpy
warning
message
implicit
conversion
suggestion
ragged
array
deprecation
comment
underlying
library
Grover
warnings
deprecated
quantities
recent
refactor
method
local
variable
original
instance
mypy
delete
type
ignore
Could
comment
proper
resorting
obvious
method
name
suggestion
new
MatrixOp
permuted
qubits
Sorry
comment
PR
suggestion
equivalent
state
function
type
VectorStateFn
solver
base
class
Please
code
solver
getter
access
solver
suggestion
weighted
pauli
operator
coeff
complex
type
irrespective
value
imaginary
part
many
operators
coeff
real
Hence
coeff
real
float
value
real
i.e
imaginary
part
potential
issues
complex
complex
coeffs
opflow
complex
imaginary
coefficients
UCCSD
evolution
hopping
operators
Terra
complex
TODO
support
Terra
real
part
w
complex
complex
pass
issue
complex
numbers
logic
real
part
complex
odd
suggestion
weighted
pauli
operator
coeff
complex
type
irrespective
value
imaginary
part
many
operators
coeff
real
Hence
coeff
real
PrimitiveOp
float
value
real
i.e
imaginary
part
potential
issues
complex
complex
coeffs
opflow
complex
imaginary
coefficients
UCCSD
evolution
operators
Terra
complex
TODO
support
Terra
suggestion
weighted
pauli
operator
coeff
complex
type
irrespective
value
imaginary
part
many
operators
coeff
real
Hence
coeff
real
PrimitiveOp
float
value
real
i.e
imaginary
part
potential
issues
complex
complex
coeffs
opflow
complex
imaginary
coefficients
UCCSD
evolution
operators
Terra
complex
TODO
support
Terra
@
adekusar-drl
further
use
convo
https
//github.com/Qiskit/qiskit-aqua/pull/1199
discussion_r470545272
Parent
VibronicStructureBase
init
molecule
way
comments
MoresPotential
intent
changes
deprecation
release
several
weeks
users
code
parameters
encode
🙂
comment
suggestion
self._src
=
copy.deepcopy
problem
suggestion
abstract
class
convert
suggestion
suggestion
binary
variables
sure
docstrings
private
method
penalty
people
code
easy
method
suggestion
error
message
presence
structure
code
flow
absence
docstring
base
class
significant
difference
multiple
places
less
ideal
docstring
base
class
comment
write_retry_commands
NIT
google.cloud
import
dataproc_v1
dataproc
Copyright
Google
LLC
comma
period
Does
product_name
region
tag
[
START
dataproc_create_cluster
]
sample
tracker
comment
row_filter
=
line
Move
sample
suggestion
GAE
Flex
TCP
logic
sample
method
code
methods
tutorial
off
Nit
helpful
worth
example
images
dense
less
dense
text
example
Python
docstrings
functions
short
description
arguments
+
value
info
https
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
tutorial
steps
step
tutorial
prev_lang
source_language_code
target_language_code
resource
>
parent
region
tags
translate_
translate_hybrid_imports
standard
library
imports
google
ones
Style
guide
order
imports
Standard
library
imports
third
party
imports
Local
application/library
specific
imports
https
//www.python.org/dev/peps/pep-0008/
imports
result
operation
sure
comment
worth
return
result
None
large
import
comment
first
result
languages
glossary_uri
args
function
useful
library
snippets
import
bigtable_reads_row
snippet
samples
backups
check
List
backup
operations
database
test
below
intentional
suggestion
Wait
databases
backup
optimizing
suggestion
List
progress
restore
client
library
retries
necessary
Node.js
Golang
flakiness
*
https
//github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/master/run/logging-manual/test/system.test.js
L20
*
https
//github.com/GoogleCloudPlatform/golang-samples/blob/master/logging/simplelog/simplelog_test.go
L63
Please
unit
modified
variable
name
comment
Same
comment
TODO
tag
Again
free
blocker
ii
i
descriptive
variable
sure
disable=no-member
directive
cases
re-run
lint
error
error
strange
Cloud
Client
certain
discovery
right
library
discovery
Google
LLC
def
synthesize_text_with_audio_profile
update
region
tag
Delete
lines
other
Django
samples
secret
key
replace-me
placeholder
something
lead
other
Django
samples
comment
block
more
detail
explanation
main
request
ambiguous
Set
CORS
headers
Set
CORS
headers
non-OPTIONS
requests
necessary
same
comment
similar
line
next
function
sure
clear
comment
meaning
Inline
Should
us-central1
location
variable
variable
inline
board
general
samples
possible
arguments
use
specific
values
provide
example
values
comments
possible
values
bit
suggestion
Extract
host
port
db_host
socket
address
host_args
=
db_host.split
db_hostname
db_port
=
]
int
host_args
]
init
examples
values
username=db_user
e.g
my-database-user
Fix
comment
signature
right
bytes
comment
strings
raw
bytes
Good
comment
teardown
behavior
timeout
comment
specific
timeout
unspecified
None
exception
method
TODOs
developers
values
sample
normal
comment
TODO
project
ID
main
functions
samples
place
logic
separate
subparsers
local
path
gcs
path
None
Let
use
consistent
casing
SQL
keywords
query
job
fine
schema
BigQuery
types
query
indent
same
library
fix
key
delete
snippet
clarify
same
check
comment
comment
user
e.g
current
version
subscription
comment
information
lot
output
full
text
confidence
score
Thoughts
exception
bubble
executor
whole
stack
trace
error
message
comment
complex
possible
command-line
tool
possible
parameter
least
argparse
custom
help
text
user
arbitrary
params
link
API
documentation
scope
capability
samples
link
documentation
comments
typo
dataflow_run_template
GitHub
PR
comment
TODO
comment
TODO
D
Java
method
purpose
java
>
response.get
TimeUnit.SECONDS
C
>
option
sec
timeout
language
explanation
ValueError
NotImplementedError
flame
graph
boring
sense
interesting
least
function
Explain
possible
important
https
//github.com/GoogleCloudPlatform/golang-samples/blob/master/profiler/profiler_quickstart/main.go
realistic
service
name
service
version
consistent
magic
number
client
library
constants
constant
sample
Nit
suggestion
Copyright
Google
LLC
constant
capital
inline
function
case
something
uncomment
line
launch_browser
explanation
nit
access
refresh
tokens
necessary
case
gunicorn
note
Done
dict
consistent
later
dict
entry
=
dict
Happy
literal
concern
NOTE
tests
unit
tests
logging
state
something
simpler
NOTE
unit
tests
Ditto
failure
ditto
list
failure
failure
line
line
cleanup
test
reliable
fixture
name
sure
test
Ditto
fixture
temporary
dataset
cleanup
different
dataset_id
fixtures
retries
unreliable
common
term
Linear
backoff
Comment
line
nit
first
time
pages
[
-1
]
Syntax
page
pdf
file
right
canonical
~
Thanks
*
_fixing_
*
Will
region
tag
beginning
import
s
end
def
sign_url
below
documentation
merge
conflict
indicator
leftover
face
detection
versions
bounding
boxes
smaller
other
vision
API
face
detection
objects
>
>
face
normalized
coordinates
x
y
=
upper
left
different
conventions
beneficial
comment
list
few
landmarks
comment
left_shoulder
right_knee
etc
thread
new
system
main
thread
possible
section
public
subscription
parameter
[
taxis
Dataflow
]
https
//cloud-dot-devsite.googleplex.com/dataflow/docs/quickstarts/quickstart-templates
comment
subscription_name
=
nit
_beta
nit
_beta
nit
_beta
nit
_beta
nit
_beta
Nit
Per
Google
LLC
rights
indent
suggestion
import
datasets
certain
DAC
subprocess
path
service
credential
client
same
function
code
sample
test
safeguard
beam.Pipeline
symbol
TestPipeline
beam.io.ReadFromPubSub
symbol
function
rest
options
example
other
functions
https
//github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/transforms/elementwise/pardo_test.py
something
@
mock.patch
'apache_beam.Pipeline
TestPipeline
mock.patch
lambda
_
TestStream
.advance_watermark_to
def
test_pubsub_to_gcs
PubSubToGCS.run
TestStream
output_path=
gs
//
/output
.format
BUCKET
UUID
minutes
[
project
PROJECT
temp_location
TempDir
.get_path
]
Check
output
files
GCS
Clean
need
DirectRunner
default
option
runner
Cross-product
reuse
google_auth
region
tag
nodejs
version
plan
GCF
sample
functions
region
tag
current
sample
docs
update
multiple
region
tags
first
last
order
suggestion
object
timestamp
frame
track
suggestion
Optional
attributes
object
bounding
box
suggestion
Optional
track
level
suggestion
video
segments
logo
suggestion
segment
logo_recognition_annotation.segments
print
u
\n\tStart
Time
Offset
.format
segment.start_time_offset.seconds
segment.start_time_offset.nanos
print
u
\tEnd
Time
Offset
.format
segment.end_time_offset.seconds
segment.end_time_offset.nanos
comment
link
docs
https
//cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs/update
Nit
link
comment
REST
API
docs
https
//cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs/list
update
double
quotes
low
.pub
few
variables
test
double
quotes
single
return
result
result
ssh.stderr.readlines
backoff
sample
comment
context
way
dataset
searchable
part
fixture
check
fixture
level
resource
searchable
fine
sure
max_time
max_tries
comment
enough
context
something
asset_dataset
searchable
time
snippet
Ditto
worst
practice
12-factor
app
developer
community
comment
_is_
appropriate
app.yaml
file
people
secrets
version
control
nit
types
Same
feature_element
same
other
samples
auto-generated
new
file
master
branch
default
organization
role
most
accounts
unlikely
environment
variable
comment
_clean_bucket
bundle
chain
code
exception
sense
details
confusing
anything
better
something
attestation
file
data
portion
bit
signature
portion
Seperate
components
least
s/can
to/can
Message
brief
comments
values
others
similar
values
future
step
base64
tests
SSML
Voice
Gender
values
google.cloud.texttospeech.enums
ssml_voice_genders
'SSML_VOICE_GENDER_UNSPECIFIED
'MALE
'FEMALE
]
Display
SSML
Voice
Gender
print
'SSML
Voice
Gender
ssml_voice_genders
voice.ssml_gender
]
same
Java
Simply
clear
possible
values
map
SSML
spec
Voice
element
https
//www.w3.org/TR/speech-synthesis11/
g13
big
deal
os.remove
call
clause
python
try
os.remove
tests
possible
fixture
store
Typo
suggestion
gcs_uri
=
'gs
//YOUR_BUCKET_ID/path/to/export/'
suggestion
Copyright
Google
LLC
All
Rights
Reserved
adjust
nit
link
docs
infoTypes
users
magic
strings
comment
user
test
flag
linter
suggestion
RETRY_MAX_TIME
*
minutes
seconds
Hmm
codelab
example
code
fine
pytest
style
sample
code
wrong
way
something
sample
local
filesystem
simplicity
Unix
Socket
connection
string
TCP
connection
string
i
word_time_offset
other
types
time
Please
descriptive
name
AddTimestamps
outer-most
pipeline
definition
users
windowing
preferences
track
hours
minutes
someone
PDT
conversion
UTC
streaming
pipeline
likely
run
days
months
years
convenient
entire
timestamp
window_start
window_end
next
window_start
format
%
Y
%
M
%
D-
%
H
%
M
%
S
free
different
one
Nit
hanging
indent
lint
PipelineOptions
pipeline_args
Nit
parameter
descriptions
python
samples
give
example
inputs
Please
comment
group
*
elements
window
empty
unused
key
element
GroupByKey
group
Unless
enriches
Dataflow-specific
term
composite
transform
groups
Pub/Sub
messages
windows
timestamps
messages
concern
windowing
batching
dictionaries
strings
sense
beam.Map
DoFn
Imports
run_quickstart
function
quickstarts
https
//github.com/GoogleCloudPlatform/python-docs-samples/blob/master/storage/cloud-client/quickstart.py
region
tag
outside
function
users
indentation
error
code
A
small
suggestion
dataset_id
provided
dataset_uuid
reader
code
comments
region
zone
pretty
please
f
Can
uuid
ids
unique
import
uuid
project_id
=
os.getenv
GOOGLE_CLOUD_PROJECT
client
=
bigquery.Client
project_id
dataset_id
f
.dataset-
uuid.uuid4
table_id
f
dataset_id
.average_weather
rule
import
order
case
import
uuid
google.cloud
import
bigquery
import
google.cloud.exceptions
pytest
little
bit
test
test
client
library
sample
code
test
functions
dataflowtemplateoperator_create_dataset_and_table_helper.py
behavior
comments
variable
names
modesl.Variable.get-
region
zone
different
region
airflow
variable
zone
quotes
double-quotes
http
//www.grpc.io/grpc/python/grpc.html
grpc.Server.stop
grace
duration
time
seconds
None
duration
time
seconds
time
RPCs
Server
’
None
RPCs
method
Server
default
comment
users
useful
nit
underlying
nit
underlying
present
other
comments
Nit
free
clearer
TODO
something
=
query_results_dataset
[
END
bigquerystorage_pandas_tutorial_create_dataset
]
Create
unique
dataset
ID
dataset_id
.format
uuid.uuid4
.hex
[
START
bigquerystorage_pandas_tutorial_create_dataset
]
variable
replacement
TODOs
tutorial
todo
tutorial
imports
client
initialization
snippet
sure
[
check=True
]
https
//docs.python.org/3/library/subprocess.html
subprocess.run
error
commands
nit
uncommon
test
structure
least
point
helpful
comment
top
file
test
goal
test
helpful
other
readers
context
situation
nit
comment
docs
hard
separation
things
part
training
code
own
client
requests
prediction
service
former
cloudml-samples
tf/garden
latter
python-docs-samples
better
form
docstring
clear
docs
necessary
get_ml_engine_service
link
doc
page
service
account
file
copies
tuple
wrong
Add
comments
authentication
work
true
script
fan
raw-input
valid
json
pain
interactive
input
python
predict.py
<
my_data.json
add
file-level
comments
ways
script
Done
service
snippet
indirection
cognitive
load
users
huge
fan
main
functions
docs
Nit
blank
line
license
docstring
file
path
census
example
cloudml-samples
file
part
census
sample
more
generic
online
prediction
sample
latter
better
warnings
model
model
part
census
sample
s/census/json/g
bad
question
familiar
python-docs-samples
copies
generator
generators
python
weird
code
favor
webapp
snippets
simple
reasonable
full
docstring
follow
Napoleon
style
Args
project
str
model
str
instances
[
str
dict
]
version
str
optional
Returns
Mapping
[
str
]
import
predict
individual
members
blank
newline
code
issue
bug
Construct
queue
consistent
other
comments
suggestion
Construct
create
queue
request
args
https
//github.com/GoogleCloudPlatform/python-docs-samples/blob/master/AUTHORING_GUIDE.md
documenting-arguments
indents
free
-S
blacken
Add
periods
end
comments
section
need
response
Python
more
please
free
Prefer
single-quote
strings
double-quotes
few
more
HTTP-triggered
functions
print
statements
Cloud
Logging
returns
contents
response
Ideally
example
values
instance_id
database_id
better
understandability
result
temporary
variable
result
=
language_client.classify_text
document
=
result.categories
six.iteritems
index
Example
open
text_file
r
f
raw_lines
f.read
.join
raw_lines
Can
loop
=
<
break
time=2s/
>
raw_lines
.join
raw_lines
=
<
speak
>
<
/speak
>
'.format
raw_lines.replace
break_
region
tags
different
tracking
tools
convention
like
product_name_snippet
]
tutorial
something
START
tts_ssml_addresses_imports
tts_ssml_addresses_
prefix
rest
region
tags
tutorial
try
default
IOError
nit
Could
check
part
test_ssml_to_audio
least
non-empty
string
part
args
definition
tutorial
address
pronunciation
special
characters
address
tutorial
edge
case
nit
lines
example.ssml
compare
same
input_ssml
fewer
places
future
nit
doc
strings
test
methods
Same
line
license
docstring
please
default
necessary
explicit
check
//github.com/GoogleCloudPlatform/python-docs-samples/blob/bb83cea15029f50e8f82c6c2d50c971b35b48c33/testing/test-env.tmpl.sh
need
blank
newlines
nested
fors
anything
clever
least
comment
need
enumarate
python
page
document.pages
ad
nauseam
sample
logic
get_pyspark_file
clearer
current
wording
bit
things
other
nit
Cloud
Pub/Sub
*
*
t
*
*
opic
word
topic
part
product
title
Pub/Sub
client
nit
handle
nit
handle
suggestion
Copyright
Google
LLC
suggestion
google.cloud
import
mediatranslation
get
string
Nit
variables
argument
object
name
speech_config
suggestion
audio_config
=
mediatranslation.TranslateSpeechConfig
Same
thing
config
>
streaming_config
object
name
same
suggestion
separate
variable
readability
Added
suggestion
Copyright
Google
LLC
Rights
Reserved
suggestion
Nit
Prefer
parentheses
multi-line
statements
preferred
way
long
lines
Python
implied
line
continuation
parentheses
brackets
braces
+
operator
line
https
//www.python.org/dev/peps/pep-0008/
should-a-line-break-before-or-after-a-binary-operator
suggestion
webserver_url
=
//'
+
webserver_id
+
+
dag_name
+
'/dag_runs'
Standard
library
imports
first
section
import
platform
import
flask
import
Import
modules
members
flask
flask.Flask
flask.request
Nit
Copyright
Google
LLC
idea
TODOs
users
concrete
example
variables
TODO
word
more
consistency
product
timeout
number
something
TODO
=
How
subscriber
messages
seconds
Done
Comments
program
.mp3
.wav
https
//cloud.google.com/speech-to-text/docs/reference/rpc/google.cloud.speech.v1
recognitionconfig
strange
conditional
comment
nit
Newline
dot
Graphviz
DOT
language
link
sample
i.e
https
//www.graphviz.org/doc/info/lang.html
/usr/bin/dot
machine
comment
defaults
function
signature
nit
Java
requirement
arguments
arguments
Configurables
source_language
target_langauge
default
value
link
API
docs
values
users
other
values
likely
Python
sample
requirements
nit
comments
additional
context
statements
useful
idea
glossary
value
snippet
region
sense
messages
devices/
MQTT
topic
Any
reason
GOOGLE_CLOUD_PROJECT
GCLOUD_PROJECT
environment
variables
GOOGLE_APPLICATION_CREDENTIALS
environment
variable
suggestion
shards_list
=
[
]
doc_ref
=
None
@
pytext.fixture
def
db_client
yield
firestore.Client
shard
shards_list
shard.delete
doc_ref
doc_ref.delete
suggestion
code
region
tag
JWT
string
parameter
properly
Go
*
variables
unused
attach
detach
symmetrical
symmetrical
other
languages
Hub
Gateway
Might
gateway
closing
tag
comment
little
possibility
segments
many
frames
face
face
segment
time
confusing
face
appear
multiple
segments
Face
Segment
>
>
face
frames
segments
results
score
Will
code
whole
segment
likely
emotion
frames
cool
simple
time_offset
same
frame
face
comment
first
result
result
way
videointelligence.enums
enum
changes
future
impressive
lambda
expression
-1
face
rewording
better
parameter
actual
text
confusion
user
variables
necessary
project
ID
Please
comment
constant
user
url
payload
same
order
function
args
indirection
sample
place
users
questions
list
event
types
documentation
eventType
comment
link
documentation
event
types
documentation
action
stuff
block
Lots
comments
redundant
removing
link
documentation
format
detail
Samples
supplementary
documentation
everything
documentation
Public
Google
style
snake_case
method
function
variable
names
same
format
Summary
summary
Bucket
bucket
Object
ID
Generation
generation
docstring
FHIR
resource
Regardless
operation
Nit
following
def
get_client
Returns
authorized
API
client
GOOGLE_APPLICATION_CREDENTIALS
environment
variable.
Short
summary
long
description
Ditto
ditto
Searches
resources
FHIR
store
code
exception
status
attribute
blob
full
URI
triggers
certain
events
e.g
file
writes
]
https
//cloud.google.com/functions/docs/calling/storage
object_finalize
code
Node
sample
event
docs
Rather
/tmp
tempfile.mkdtemp
random
guaranteed-temporary
directory
note
up
afterwards
there
in-Python
way
instance
Pillow
ImageMagick
binding
Python
subprocess
call
useful
logging
line
'Fixed-size
windows
>
>
beam.WindowInto
minute
argparse
logic
__name__
==
section
function
parameters
pipeline
input_subscription
output_table
flexible
approach
subscriptions
topics
code
sample
simplicity
flexibility/complexity
subscriptions
Java
sample
job
topic
automatic
subscription
instructions
SCHEMA
=
[
'url
STRING
'num_reviews
INTEGER
'last_date
TIMESTAMP
]
Copyright
Google
LLC
linter
py
sp.call
[
'python
'streaming_beam.py
project
PROJECT
runner
'DirectRunner
]
pylint
disable=
easier
Thank
code
setup
teardown
code
below
care
fixtures
safe
fixture
test
arguments
Long
tests
polling
results
ready
record
cleaning
fixtures
teardown
code
test
suggestion
Copyright
Google
LLC
same
nit
Indentation
comment
MemoryCache
instance
file_cache
unavailable
oauth2client
>
=
google-auth
descriptive
variable
name
c
Might
StreamingRecognizeRequest
generator
ie
python
requests
types.StreamingRecognizeRequest
audio_content=c
c
[
content
]
something
sleep
code
longer
necessary
Nit
code
write
instructions
developer
code
Publisher
client
Likewise
other
comments
samples
main
thread
background
message
processing
complete
Typo
Non-blocking
background
thread
messages
nit
general
technical
writing
developer
main
thread
subscriber
messages
background
background
little
redundant
exit
unrecoverable
error
subscriber
python
devices
=
client.projects
.locations
.registries
.devices
return
devices.create
parameter
unix_socket
unix_sock
adapters
necessary
error
code
HTTP
code
new
error
variable
variable
's3
variable
'files
TODO
Unable
'pytest
function
method
suggestion
Copyright
Red
Hat
Inc.
suggestion
environment
variable
data
JSON
string
form
Similar
dictionary
access
comment
group_by_value
parameters.parameters.get
.get
group_by_key
Health
http
//apidocs.cloudhealthtech.com/
account_enable-aws-account
region
ARN
https
//docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html
genref-arns
arn
partition
service
region
account-id
resource
arn
partition
service
region
account-id
resourcetype/resource
arn
partition
service
region
account-id
resourcetype
resource
Does
account
numbers
ones
unit
test
setup
self.fake_aws.account_alias
current
case
likely
cost
data
account
tenant
additional
accounts
following
steps
test
case
=
FakeAWSCostData
self.provider
account_alias='redhatisgreat
redhatisgreat_generator
=
AWSReportDataGenerator
self.tenant
redhatisgreat_generator.add_data_to_tenant
redhatisgreat_fake_aws
=
FakeAWSCostData
self.provider
account_alias='redhatisthefuture
redhatisthefuture_generator
=
AWSReportDataGenerator
self.tenant
redhatisthefuture_generator.add_data_to_tenant
redhatisthefuture_fake_aws
account_alias
values
URL
url
=
group_by
[
account
]
=redhat
group_by
[
account
]
=future'
So
important
test
case
*
*
condition
individual
group_by
query
redhatisthefuture
account
account
own
total
cost
url
=
group_by
account
]
=redhatisthefuture
url
=
group_by
account
]
=redhatisgreat
default
OR
case
url
=
group_by
account
]
=redhat
group_by
[
account
]
=future
condition
url
=
group_by
[
account
]
=redhat
group_by
[
account
]
=future'
total
redhatisthefuture
String
comment
use
uuid
method
dictionaries
meaning
key/value
update
comment
key/value
specific
meaning
suggestion
Re-enable
log
suppression
suggestion
suggestion
persistentvolume
=
models.CharField
max_length=253
nullable
suggestion
persistentvolumeclaim
=
models.CharField
max_length=253
nullable
suggestion
field
unit_of_measure
operation
icontains
parameter
GB-Mo
suggestion
OpenShift
Azure
self._delta
delta
bug
QueryParams
class
reason
commented-out
part
change
please
extra
comment
effect
real
foreign
key
provider
table
clearer
provider
uuid
comment
auth_header
pending_delete
offset
offest
suggestion
first
/cost-management/v1/reports/openshift/costs/
filter
%
%
filter
%
%
filter
%
%
5D=-1
group_by
%
%
%
limit=100
offset=0
noqa
E501
similar
comments
other
model
files
functional
indexes
loops
suggestion
overrides
[
]
trial
trials
param_name
distribution
search_space.items
trial._suggest
param_name
distribution
overrides.append
tuple
f
name
=
val
name
val
trial.params.items
sure
initial_job_idx
other
sweepers
https
//github.com/facebookresearch/hydra/blob/master/plugins/hydra_nevergrad_sweeper/hydra_plugins/hydra_nevergrad_sweeper/_impl.py
L159-L160
Can
links
user
valid
values
field
example
https
//optuna.readthedocs.io/en/stable/reference/storages.html
highlight=storage
standalone
diff
own
issue
news
fragment
case
python
foo.py
script
name
matches
__fish_seen_subcommand_from
potential
problem
user
directories
different
script
same
name
@
hydra.main
problem
scripts
hydra
absolute
path
safest
way
Please
scenario
[
application
]
https
//hydra.cc/docs/next/advanced/app_packaging
Test
example
application
[
]
https
//github.com/facebookresearch/hydra/tree/master/examples/advanced/hydra_app_example
suggestion
backend
incompatible
Hydra
enough
need
rest
comment
suggestion
session.run
*
pytest_cmd
modules
Dict
Dict
suggestion
ray_init_cfg
RayInitConf
=
RayInitConf
ray_remote_cfg
RayRemoteConf
=
RayRemoteConf
comment
autoscaling_mode
like
ObjectConf
content
comment
actual
text
feature
request
OmegaConf
s
enum_to_str
TODO
issue
code
comment
pylint
Hydra
comment
tests
overrides
interval
float
interval
>
int
interval
int
interval
>
expected
value
class
type
object
[
]
int
=
>
[
]
ng.p.Choice
values=
]
type=int
something
choice
blue
blublu
str
suggestion
A
plugin
parent
Plugin
class
suggestion
please
documentation
new
resolver
Great
Please
comment
imports
difficult
chance
regression
something
future
version
launchers
batches
Hydra
Hydra
Python
async
launcher
API
plausible
Please
i
same
issue
import
startup
timing
similar
explanatory
comments
benefit
integrate
comment
hints
test
example
app
chdir_plugin_root
master
directory
root
plugin
test
usage
joblib
test
validation
correctness
result
>
E
TypeError
_
positional
argument
config_name=None
submitit
configuration
derives
base
configuration
default
value
few
slurm
specific
parameters
sharp
signal
days
large
way
Redis
comment
other
diff
https
//github.com/facebookresearch/hydra/pull/531
pullrequestreview-393145289
One
step
scalar
specification
Union
spec
bit
errr
messy
comment
mem_limit
definition
launcher
GB
Inline
DRY
case
value
None
same
values
None
comments
code
value
multiple
times
variable
ex
author_info.get
'id
i
format
python
suggestion
author_info
=
try_get
lambda
x
list
x
[
'profiles
]
.values
]
dict
suggestion
float_or_none
clip_info.get
line
characters
comment
correct
docstring
docstring
docstring
land-sea
mask
needs
stage
data
land-sea
mask
land
points
sea
points
opposite
information
land-sea
mask
docstring
confusion
actual
equation
docstring
little
bit
other
more
technical
operations
something
e.g
lapse_rate_adjusted_temperatures
=
temperatures
lapse_rate
*
vertical_displacement
non-urgent
ticket
epic
documentation
more
information
methods
more
diagrams
descriptions
delayed
action
satisfy
overall
exemplar
documentation
more
doc-strings
argument
names
worth
class
tests
data
input
data
tests
someone
web
tests
other
tests
careful
arrays
input
tests
fine
clearer
amend_attributes
function
function
dictionary
correct
form
dictionary
works
information
CLI
interface
clearest
way
something
key
required_grid_attributes
key
target_grid.attributes
cube.attributes.update
key
target_grid.attributes
key
]
cube.attributes.pop
key
bit
clearer
happy
correct
standard
point
selection
stuff
e.g
true/false
array
points
equal
points
equal
offset
True
equal
points
False
integer
netcdf
masks
bools
comment
ok
template
cube
weird
coordinate
metadata
output
cube
probability
cube
copy
fg_cube
case
plugin
template
cube
equivalent
precip
probability
pretty
arbitrary
cube
cube
process
*
*
*
*
self.ltng_cube
probability_of_
*
*
lightning_rate
*
*
_above_threshold
self.fg_cube
potential
wrong
@
MoseleyS
nice
comment
numbers
time
correspond
My
concern
clear
location_parameter
scale_parameter
https
//en.wikipedia.org/wiki/Location_parameter
https
//en.wikipedia.org/wiki/Scale_parameter
[
scipy
]
https
//docs.scipy.org/doc/scipy/reference/tutorial/stats.html
highlight=location
%
shifting-and-scaling
specific
interpretation
unclear.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
Too
many
local
variables
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=4628948
suggestion
Accumulate
high
frequency
rate
extrapolations
desired
accumulation
intervals
reason
optional
argument
other
CLIs
parameters
new
line
please
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Module
'improver.cli
'create_constrained_inputcube_converter
member
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=4628948
importing
Please
commented-out
block
relevant
test
data
old
post
processing
system
check
belongs
CLI
km
grid
resolution
UKPP
topography
field
STEPS
grid
cell
direction
less-magic
number
something
short
term
metres
kilometres
thing
explicit
comment
comment
function
mask
True
orographic
enhancement
criteria
list
SHOULD
orographic
enhancement
references
class
doc-string
process
function
doc-string.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
statement
effect
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=2113091
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=2113091
better
@
clizefy
wrapped_with_output.cli
Test_with_output
result
=
wrapped_with_output.cli
[
]
output=foo
compression-level=0
least-significant-digit=2
way
type
conversion
PS
file
day
unittest.TestCase
style
nice
units
advection_perturbations
inconsistent
cube
possible
units
cubes
place
for/zip
docstring
style
dict
word
order
comment
level
set_up_variable_cube
level
Done.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3081527
Could
comments
loop
please
Eg
data
order
values
solar
method
obvious
fluent
numpy
slice
assignment
places
cube
diag_cube
comments
More
interpolation
method
difference
correct
condition
line
new
coordinate
float
hours
coordinates
time
frt
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Method
function
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3081527
case
cube
fact
interpolated_cube
place
cube
list
functions
same
structure
please
same
questions
solar_interpolate
above.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
variable
i
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3081527
linear
interpolation
data
night
points
obvious
Might
comment
lat/lon
grid
covers
UK
standard
grid
tests
comment
code
coordinate
_get_multiplier
variable
whole
coordinate
name
sense
class
attribute
Bruce
question
points
leave
week
part
discussion
main
purpose
plugin
visibility
risk
top
plugin
less
case
plugin
negative
weights
least
serious
problems
spatial_weights_cube
order
better
fuzzification
function
something
better
input
unmasked
trip
error
above
error
Again
blend_coord
x-y
order
y-x
IMPROVER
convention
worth
explicit
mention
comment
docstring
necessary
comment
more
detached
Others
group
clear
comment
reference
StaGE
conversion
GRS80
sections
comment
perfect
suggestions
comment
true
code
float64
data
correct
change
comment
bit
metadata
attributes
MergeCubesForWeightedBlending
plugin
bit
cycle
times
same
place
first
read
Good
question
init
fun
line
wrapping
undecided
design
safe
principle
certain
datatypes
plugins
worried
practise
downstream
impacts
changes
units
approach
moment
units
comments
docstrings
developer
rates
m
s-1
time
s
accumulations
m
point
plugin
advected
/
accumulations
Eg
rain
rate
fields
minutes
advection
components
minute
frequency
components
result
minute
accumulation
something
new
cube
information
available
input
cubes
calculation
accumulation
plugin
Metadata
updates
unnecessary
processing
comment
data
please
values
mm/h
shape
mask
different
values
value
different
rate
values
different
time
steps
half-weighting
end
points
case
setup
different
rates
different
times
plugin
identifies
weights
data
worth
long
snapshot
dump
larger
plugin
~GB
better
idea
default
sample
frequency
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
whitespace
]
https
//app.codacy.com/manual/metoppv_tech/improver/pullRequest
prid=5241672
thanks
heads-up
same
lines
np.ma.masked_invalid
e.g
all_forecasts
np.ma.masked_invalid
all_forecasts
suggestion
comment
something
suggestion
xy
slices
same
shape
chunksize
netCDF
eg
suggestion
xy
slices
same
shape
chunksize
netCDF
eg
points
night
UV
index
zero
CLI
cube
night
values
suggestion
cube.data
=
DayNightMask
.night
cube.data
comment
line
something
night
values
zero
comment
_add_threshold_coord
function
data
masks
way
reliability
tables
truth
present
python
threshold_reliability
=
np.ma.array
threshold_reliability.data
+
table.data
mask=mask
dtype=np.float32
case
threshold_reliability
table
numpy
arrays
data
attribute
mask
addition
unmasked
reliability
tables
bitwise
addition
masks
points
reliability
tables
masked
usual
behaviour
masked
arrays
mask
addition
masked
unmasked
point
masked
point
[
StackOverflow
question
]
https
//stackoverflow.com/questions/20539069/add-together-two-numpy-masked-arrays
general
idea
masked
arrays
way
number
points
reliability
tables
points
timestep
training
dataset
comment
zeroing
data
mask
x
other
places
code
little
clearer
x
physical
meaning
abstract
hashes
doc
string
update
comment
comment
-4
*
DALR
wording
LapseRate
doc
min/max
rate
values
_default_
lapse
rate
constraints
reason
constraints
higher
lower
values
optional
arguments
*
DALR
*
DALR
job
plugin
lapse
input
arguments
-3
*
DALR/DALR
_default_
arguments
quite
order
values
nothing
arguments
part
plugins
functionality
different
lapse
rate
constraints
line
characters
sure
grid
metadata
title
Diagnostic
>
forecast
km
standard
grid
descriptive
spot-extracted
data
cube
things
lapse
rate
adjustments
class
member
code
clearer
reset
example
general
comment
difficult
process
lot
class
members
hard
key
focus
points
variable
function
process
selective
class
members
sorting
grid
points
site
output
acceptance
test
KGO
new
code
KGO
old
=
iris.load
'nearest_uk_kgo.nc
old
KGO
new
=
iris.load
'nearest_uk_kgo.nc
new
KGO
Choose
other
wmo_id
example
old_ex
=
old.extract
iris.Constraint
coord_values=
lambda
cell
cell
==
'3111
iris.Constraint
coord_values=
lambda
cell
cell
==
'3111
print
]
]
print
new_ex.data
]
]
example
indices
data
site
different
unrelated
grid
Are
separate
class
only
place
class
class
attribute
_make_subboxes
function
hideous
abbreviation
process
function
configurability
plugin
different
grids
docstrings
hopefully
Known
iris
problem
version
iris
suggestion
pylint
disable=unsubscriptable-object
filters
data.variables
air_temperature
]
.filters
conform_metadata
mosg__
function
functionality
comment
little
way
such
mosg__
additions
cube_orig
set
tests
cube_orig
Codacy
issue
[
function
method
]
https
//app.codacy.com/manual/metoppv_tech/improver/pullRequest
prid=5718468
iris
functions
iris
ConstraintMismatchError
descriptive
TypeError
temperature
relative_humidity
pressure
=
tuple
CubeList
f
.extract_strict
n
n
air_temperature
relative_humidity
air_pressure
iris
functions
iris
ConstraintMismatchError
descriptive
TypeError
names
air_temperature
relative_humidity
air_pressure
tuple
CubeList
f
.extract_strict
n
n
names
unusual
global
variable
middle
alternative
test
class
others
class
local_test_dict
IrisTest
def
setUp
self.test_dict
=
time
unit
seconds
1970-01-01
dtype
np.int64
probability
unit
temperature
unit
K
rainfall
unit
s-1
rate
unit
s-1
class
Test__find_dict_key
local_test_dict
Test
method
suitable
keys
dictionary
@
def
setUp
Redirect
dictionary
super
.SetUp
=
self.test_dict
test
class
dictionary
local_test_dict
super
.SetUp
hold
dictionary
therein.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Method
function
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=4002005
staticmethod
Codacy
issue
keys
dictionary
easier
idea
significant
time
sink
conversion
change
calculation
cube
load
suite
likely
huge
calculation
time
many
times
units
cubes
enforce=False
sense
manifest
sensible
functions
comparison
function
discussion
Thanks
helpful
multiple
mistakes
manifest
good
idea
motto
anything
user
wrong
Fixed
Promotion
int
>
float
float64
float
check
path
worth
comment
Legacy
brackets_to_nested_list
better
name
unbracket
suggestion
help
shows
execution
python
-m
improver.cli
doc
str
original
input
obj
str
obj
flexability
docstring
more
explanation
current
logic
picks
suggestion
TODO
simplify
CLIs
current
logic
allows
legacy
argparse
new
clize
CLIs
legacy
interface
<
cli_name
>
.main
routine
new
<
cli_name
>
.process
routine
type
interfaces
available
IMPROVER_USE_CLIZE
environment
variable
default
legacy
environment
setting
import
improver.cli
Good
spot
whole
comment
useful
understanding
code
ratio
actual
potential
transitions
areas
original
diagnostic
value
greater
potential_transitions.data
*
potential_transitions.data
commented-out
code
comment
contributing.md
guidelines
comment
code
triblertablecontrollers.py
Pls
citaj
co
prislusne
uprav
Kde
tu
encodujes
names
Zislo
sa
trochu
podrobnejsie
vysvetlenie
co
ide
Napis
pls
strucny
suhrn
z
tohto
komentara
https
//github.com/martinmacko47/chcemvediet/pull/290
discussion_r449566566
Komentar
zacni
Workarround
bug
_sqlite_format_dtdelta
potom
vysvetlenie
v
com
je
problem
Aby
si
ten
komentar
precitas
dva
roky
tak
ti
z
bolo
jasne
preco
tu
ten
mame
Opravena
_sqlite_format_dtdelta
byt
metoda
povodna
_sqlite_format_dtdelta
je
funkcia
Definuj
ju
rovno
inline
vo
vnutri
ready
hned
aj
pouzi
Funkcie
mozu
byt
pythone
definovane
kdekolvek
aj
v
tele
inej
funkcie
Z
pohladu
pythonu
je
funkcia
ako
ina
premenna
Tak
ako
vzdy
doteraz
*
*
nikdy
necopypastujeme
kod
z
kniznic
*
*
Namiesto
toho
v
opravenej
funkcii
zavolame
povodnu
funkciu
vysledok
vratenim
fixneme
ready
original_sqlite_format_dtdelta
=
django.db.backends.sqlite3.base._sqlite_format_dtdelta
def
new_sqlite_format_dtdelta
*
res
original_sqlite_format_dtdelta
*
return
res.strip
u'+00:00
django.db.backends.sqlite3.base._sqlite_format_dtdelta
=
je
zhruba
napisane
zhlavy
Este
treba
doladit
Napriklad
ak
povodna
funkcia
vrati
None
martinmacko47
Mozem
pouzit
tento
jeden
konkretny
timezone
alebo
spravit
viac
vseobecne
FIXME
.get
name=value
Obligees
duplicate
names
Je
aktualne
Obligee
instancie
s
rovnakym
field
name
je
definovany
ako
models.CharField
max_length=255
unique=True
Lepsie
bolo
jednotlive
ukony
v
ready
vydelit
self.init_admin_site_plus
self.workaround_sqlite_format_dtdelta_bug
typo
s/marded/marked/
like
comment
last
wod
imo
configurable
typo
comment
idea
means
auth.db
error
password
None
case
Keycloak
enough
copyright
file
last
afterwards
new
files
copyright
type
same
type
comments
eqc
eqv
eqb
something
briefly
@
additional
detail
helpful
people
code
first
time
comment
things
isapc
support
default
variant
last
match
use
default
values
bit
overhead
mapping
conditional
non-default
machine-types
general
mapping
way
simpler
=
aobject
pci.0
=
std
VGA
cirrus
cirrus-vga
vmware
vmware-svga
=
vga_dev_map.get
vga
vga_dev
vga_use_legacy_expression
fallback
=
True
'-mmio
machine_type
bus
None
vga_dev.endswith
'-pci
vga_dev
%
s
%
s
%
vga_dev
[
-4
]
-device
fallback
=
True
machine_type
==
isapc
bus
None
vga
std
vga
cirrus
fallback
=
False
vga_dev
fallback
=
True
fallback
return
StrDevice
return
Device
negative
testing
vga=None
extra_params
isa/pci/mmio
VGAs
*
custom
vgas
case
foo
exists
compiling/matching
default
scenario
pci
simple
matching
pci-devices
case
isa/mmio
machine
priority
frequency
use
btw
anyone
mapping
right
approach
@
luckyh
mapping
cfg
file
sense
drawback
config
file
future
devices
regex/pci_bus/isa_bus
configuration
file
share
thoughts
Typo
pollution
big
deal
PEP8
Comparisons
singletons
None
equality
operators
Image
None
comment
relevant
paths
absolute
Config.RelPath
conversions
paths
explanation
method
beginning
Comment
Revise
anyone
revise
purpose
test
least
comment
suggestion
class-based
fixtures
=
os.open
os.O_WRONLY
|
os.O_CREAT
|
os.O_EXCL
try
WinError
System.getdirinfo
os.close
fd
suggestion
Python
version
shape
comment
bit
misleading
parent
dir
remotes
exception
same
information
comment
Pylint
hdfs
library
better
pylint
config
line
specific
error
Let
comment
weird
thing
good
PR/issue
hdfs
library
wink
suggestion
theme
value
Maybe
let
regular
files/dirs
dvc
outputs
other
way
comment
test
False
__init__
nice
comment
test
better
exception
logic
code
Exception
bad
thing
faulty
test
more
explicit
unnecessary
hack
dvc_gen
sure
unnecessary
code
link
issue
etag
something
part
webdav
standard
method
great
walk_files
pressure
library
progress
bars
download/upload
ui
helpful
least
dummy
progress
bar
comments
useful
obvious
things
comment
message
start
capital
letter
only/recommended
way
smth
dir
Please
comment
code
way
fname.startswith
dir_path
above
@
mroutis
mock_s3
@
mock_s3
decorator
way
regular
unpatched
boto3
need
tests
unnecessary
code.
Let
note
suggestion
See
https
//github.com/iterative/dvc/pull/4879
informative
url
comment
PR
issue
checkboxed
failures
PR
Let
use
consistent
comments
link
github
issue
https
//github.com/iterative/dvc/pull/4469/files
r482911109
Btw
entry
present
check_ignore
symlink/hardlink/reflink
cheap
links
symlink
reflinks
indistinguishable
copy
self._is_cache_type_copy
\
path_info
checksum_info
\
System.is_hardlink
path_info
\
System.is_symlink
path_info
protecting/unprotecting
cheap
reason
self.protect
path_info
self.unprotect
path_info
msg
=
File
change
logger.debug
msg.format
str
path_info
self.exists
path_info
self.safe_remove
path_info
force=force
self.link
cache_info
path_info
comment
current
state
obvious
blank
line
harder
eye
hacky
first
step
Ideally
explicit
way
completion
https
//github.com/iterative/dvc/pull/2017/files
diff-2eeaed663bd0d25b7e608891384b7298R118
Already
https
//github.com/iterative/dvc/pull/2017/files
diff-2eeaed663bd0d25b7e608891384b7298R118
suggestion
Pygments
collective.checkdocs
safe
cli
test
test
gc
cli
test
codes
cache.py
[
]
Python
<
[
]
Works
Python
<
sure
configs
DVC
directory
oops
suggestion
Add
default
cache.dir
try
src_repo
get
closed
Nitpicky
slightly_smiling_face
pretty
weird
repo
times
new_path
rev=rev
something
lot
logic.
Per
PEP
]
https
//www.python.org/dev/peps/pep-0008/
id23
>
blank
line
group
imports
please
move
dvc.version
import
__version__
noqa
F401
underneath
import
dvc.logger
something
action.target
None
args
=
args
=
cmd
=
=
actions.args
cmd
=
.send
same
permissions
.get
Otherwise
.send
.get
issue
test
WebsocketServerWorker
possible
unit
test
websocket
server
worker
test
fine
pytest.skip
flag
test
operations
LPT
data
tests
sure
everything
fine
reminder
end
test
protobuf
schema
StorableObject
StorableObject_PB
PB
issue
comment
nit
comment
line
Same
translations
fine
anything
PR
stuff
Plan
understood
methods
Plan
convenience
suggestion
PR
point
concept
State
Protocol
Role
course
Plan
keeps
complications
ready
case
different
above
*
*
kwargs_fix_prec
work
empty
dict
Extract
mpc
nicer
typo
blacHomomorphic
move
first
worker
example
local
worker
values
other
workers
public
value
Could
short
comment
difference
crypten_to_auto_overload
crypten_plan_hook
role
crypten_plan_hook
obvious
crypten_to_auto_overload
clear
first
sight
particular
get_plain_text
first
dict
crypten_to_auto_overload
method
object_storage
message
is_tensor_none
message
object
id
parameter
Ok
same
comment
same
piece
code
AbstractTensor
bit
stuff^^
Call
AbstractTensor.__init__
more
clarity
Hacky
use
get_obj
ObjectNotFoundError
use
.get_obj
pop
consistent
next
lines
ok
owner
local
.get_obj
_objects
debug
purpose
.get_obj
comment
MAYBE
original
PT
GC
comment
TODO
print
sizes
[
input_size
*
_
range
self.num_layers
clearer
opinion
clearer
hc
same
place
hc
=
[
hc
]
instance
hc
None
hc
=
[
hc
]
self.batch_first
hc
=
[
torch.transpose
item
item
hc
]
top
function
i
_
range
clear
assertions
changes
PR
x.id_at_location
bob._objects
intuitive
semantics
move
sk_power
list
power
interations
update
need
update
>
[
c0
c1
docstring
list
comment
more
explicit
comment
specific
function
remote
tensors
comments
lines
Nope
FPT
>
wrap
>
torch.tensor
forbidden
FPT
>
wrap
>
AST
correct
AST
comment
correct
registry
types
nothing
int
float
etc
inheritance
check
simple
set
let
no_simplifiers_found
=
KeyError
type_obj
=
type
no_simplifiers_found
classes_inheritance
=
inspect.getmro
type_obj
]
inheritance_type
classes_inheritance
inheritance_type
forced_full_simplifiers
inheritance_type
forced_full_simplifiers
next
time
type
serde
forced_full_simplifiers
current_type
]
=
forced_full_simplifiers
inheritance_type
]
result
=
forced_full_simplifiers
current_type
]
[
]
forced_full_simplifiers
current_type
]
[
]
obj
result
no_simplifiers_found.add
type_obj
return
_simplify
Same
bug
Autograd
model
parameters
/
Q
Could
description
sure
j
TODO
print
point
more
test_serde_simplify
%
clear
indices
tuple
way
compare
function
custom_detailed_values_comparison_function
other
custom_simplified_values_comparison_function
None
last
Q
Could
tests
operators
FPT
Q
Could
Q
spelling
anamalous
>
anomalous
>
list
comment
words
typos
torch.narrow
method
job
Could
form
primitive_stacks
docstring
something
^^
later
PR
First
i
automatic
generation
preprocessing
more
FSS
numpy
PR
unit
test
step
size
greater
Other
PySyft
side
great
suggestion
def
detail
worker
AbstractWorker
tensor_tuple
tuple
>
ReplicatedSharingTensor
function
ReplicatedSharingTensor
attributes
form
tuple
worker
worker
deserialization
tensor_tuple
tuple
attributes
ReplicatedSharingTensor
Returns
ReplicatedSharingTensor
ReplicatedSharingTensor
check
loop
suggestion
Find
first
placeholder
args
ph_arg
=
None
arg
args
isinstance
arg
PlaceHolder
ph_arg
ph_arg
None
SomeException
inherited_simplifiers_found
E222
multiple
spaces
operator
E124
closing
bracket
visual
indentation
Nit
good
idea
notes
good
context
code
bugs
good
lines
'Use
reporting_metadata.last_submission
users
selected_app_id
something
error
message
old
>
throw
error
message
older
SQS_MSG_LIFETIME
Could
docstring
Parameters
Returns
sections
worth
=
delimiter
same
manner
typo
PR
sense
ALL_SYNTAXES
common
UNSUPPORTED_SYNTAXES
logic
ALL_SYNTAXES
^
SUPPORTED_SYNTAXES
repetition
test
files
PixelRepresentation=2
invalid
DICOM
TypeError
Could
docstring
consistent
other
functions
Same
other
functions
errors
argument
nit-pick
name
dataset
example
closer
real-world
use
comment
top
block
point
issue
fewer
lines
easier
val
=
data_element.value
line
length
boolean
fp.is_little_endian
starts_with_item_tag
=
val.startswith
starts_with_item_tag
False
beginning
multiple
'+=
implied
string
concat
brackets
easier
pythonic
form
\
fffe
e100\
regex
name
brackets
fixture
def
future_setter
request
monkeypatch
setup
yield
config._use.future
=
False
More
comments
general
good
minor
comment
tests
bit
stronger
correct
value
correct
place
type
last
block
'123.4
course
Done
tests
test_RLE_transfer_syntax.py
test
suite
rle
images
MR_small_RLE.dcm
emri_small_RLE.dcm
general
test
pattern
RLE
image
pixel
values
original
MR_small.dcm
emri_small.dcm
Feel
free
test
decoder
test_JPEG_LS_transfer_syntax.py
test
suite
decoder
Add
+1
byte
ii
range
number_of_planes
plane_start_list.append
unpack
<
L
[
*
ii:4
*
ii
+
]
]
keeing
rle_start
future
PixelData
frames
first
frame
proper
docstrings
+
space
operators
convention
copyright
notices
filename.py
line
files
cleaner
copyright
LICENSE
file
code
somewhere
case
Python
version
agreement
copyright
notice
discussion
debug
code
correct
comment
alias
ascii
dict
above
ISO_IR
B
good
chance
same
line
>
*
pydicom
*
list
comprehensions
map
filter
recommended
way
general
modern
Python
python
first
=
[
rr
rr
records
getattr
rr
'DirectoryRecordType
]
first
API
entry
point
reasonable
data
module
pydicom.data
import
download_all
memorable
doc
string
Ideally
Getting
Started
install
documentation
give
people
option
files
DHE-RSA-AES128-GCM-SHA256
DHE-RSA-AES256-GCM-SHA384
Firefox
Chrome
confusion
list
https
//wiki.mozilla.org/Security/Server_Side_TLS
HTTPS
server
configuration
use
browser
ECDHE-ECDSA-AES128-GCM-SHA256
ECDHE-RSA-AES128-GCM-SHA256
ECDHE-ECDSA-CHACHA20-POLY1305
ECDHE-RSA-CHACHA20-POLY1305
ECDHE-ECDSA-AES256-GCM-SHA384
ECDHE-RSA-AES256-GCM-SHA384
Firefox
Chrome
moment
little
bit
code
duplication
following
next
statements
line
line
:18
]
==
GRADIENT
line
:22
]
==
final
MP2
gradient
lines
413-424
comment
comment
comment
Let
sense
Commented-out
code
install
elephant
[
extras
clear
message
other
users
message
blah-blah
Please
install
extras
import
elephant
only
solution
print
import
parallel
__init__.py
ecosystem
modules
__init__.py
exception
Anyway
max_spikes
redundant
significance
testing
alpha
clear
int
sue
>
sure
[
]
https
//github.com/NeuralEnsemble/elephant/issues/253
issuecomment-539903686
@
apdavison
epoch
labels
durations
array_annotations
Neo
commend
redundant
brackets
sure
advantage
recarray
classic
list
dict
[
y
]
]
recarrays
trial
preferrable
[
]
[
y
]
list
dicts
trial
user
perspective
cross-validation
seqs_test
Discussion
raises
section
Raises
documentation
ValueError
KeyError
fex
comments
code
sure
comment
line
=
time_index
>
cp_index
int
/
dt_temp
mask_back
=
time_index
<
cp_index
+
int
/
dt_temp
differences
[
mask_fore
mask_back
]
fim.so
spade
module
Nevertheless
elephant
package
branch
python
setup.py
fim.so
install
directory
spade
opinion
desired
behavior
user
write
privileges
install
folder
installation
e.g
system
wide
install
sure
download
install
corresponding
lines
setup.py
due
massive
importing
modules
__init.py__
download
install
problem
imports
option
zero-padding
problem
zero-padding
total
energy
spectral
estimate
cases
energy
important
quantity
efficient
Morlet
wavelet
k-space
time
domain
fft
following
example
Torrence
Compo
code
available
github
https
//github.com/chris-torrence/wavelets
def
wave_bases
mother
k
scale
param
n
=
len
k
=
np.array
>
dtype=float
mother
==
'MORLET
Morlet
param
-1
param
k0
=
np.copy
param
expnt
scale
*
k0
/
*
kplus
norm
=
np.sqrt
scale
*
k
[
]
*
np.pi
*
*
-0.25
\
np.sqrt
n
total
energy=N
[
Eqn
]
daughter
=
norm
*
np.exp
expnt
daughter
daughter
*
Heaviside
step
function
fourier_factor
=
*
np.pi
/
k0
+
np.sqrt
+
k0
*
*
Scale
Fourier
[
Sec.3h
]
coi
=
fourier_factor
/
np.sqrt
Cone-of-influence
[
Sec.3g
]
=
Degrees
freedom
return
daughter
fourier_factor
coi
Errors
Raises
section
looks
strange
spade
devs
Please
comment
comment
effective
duration
logic
procedure
pay
super
efficient
regex
stuff
C
go
real
fun
years
Perl
issues
basic
idea
maintainable
*
Declare
parts
BLOCKED_DOMAINS
BLOCKED_SCHEMA
*
horrible
regex
stuff
*
Test
hell
urlparse
result
scheme
netloc
path
params
query
fragment
_query_
_params_
section
swap
/
change
Was
Note
path
URL
query
empty
https
//bbc.com
practical
scenario
problem
TODO
PR
Ditto
TODO
TODO
results
Ah
dictionaries
useful
🙂
Possibly
TODO
list
comment
tags
param
list
[
foo
]
foo
bar
]
bar
foo
]
searches
tag
foo
question
way
fields
_
suggestion
Process
iterable
Command
objects
varitions
batch
[
]
.__class__
etc
point
different
*
pain
suggestion
Pass
_execute_batch
CommandBatch
batch
ready
SQL
text
_normalise_username
STAKE_PER_BLOCK
easier
use
int
time.time
readable
comment
parameters
previous
comment
commit
status
token_trie
token_trie
None
_balances
=
_non_zero_entries
sure
balance
further
comment
token_trie
NULL_TRIE_HASH
comment
update
comment
comment
method
prefer
more
explicit
types
=
self.txs.pop
i
type
TypedTransaction
chain
id
>
full
shard
key
chain
>
comments
May
comment
Skip
block
old
code
number
plan
production
use
list
tokens
token
string
easier
number
nit
comment
comma-separated
string
tokens
nit
name
balance_gauge
division
numbers
integer
division
nit
token_name
ts
balance_dict
total_balance.items
nit
same
naming
note
parameters
script
normal
command
line
arguments
nit
naming
upper
case
constants
use
blocks
update
state.gas_price_suggestion_oracle
different
scenarios
tests
line
longer
necessary
defaultdict
list
unused
comments
methods
full_shard_id_list
chain_mask_list
part
Decay
comment
python
token_id
tx.transfer_token_id
tx.gas_token_id
token_id
balances
raise
InsufficientBalance
comments
nodes
QuarkChain
team
prevent
second
thought
caller
intrinsic
gas
tx
origin
data
layer
intrinsic
cost
@
qizhou
new
raw
field
documents
mapping
case
only
one
script
current
value
text
field
[
update
query
API
]
https
//www.elastic.co/guide/en/elasticsearch/reference/6.8/docs-update-by-query.html
[
Painless
script
]
https
//www.elastic.co/guide/en/elasticsearch/painless/6.8/painless-examples.html
same
other
new
fields
free
something
scope
feature
nice
limitations
Archivematica
documentation
field
names
indexes
comment
https
//github.com/archivematica/Issues/issues/404
Same
Typo
Maximum
approach
comment
’
t
check
existence
AIP
file
¯\_
ツ
larger
audit
task
tests
tox/pytest
more
comfortable
line
happy
way
test
inconsistency
environments
able
mock
line
anticipated
*
https
//github.com/artefactual/archivematica/blob/6946cb55158ca3fe33e2504c358ace79b1be1ed5/src/archivematicaCommon/lib/databaseFunctions.py
L39-L49
stick
assert
False
close_old_connections
test
handle_batch_task
clause
Whereas
interaction
decorator
handle_batch_task
function
close_old_connections
something
completeness
transaction
error
Slack
=
<
django.db.backends.mysql.base.DatabaseWrapper
object
>
def
get_autocommit
autocommit
state.
>
self.ensure_connection
E
RuntimeError
Database
access
django_db
mark
db
transactional_db
fixtures
MCP
Client
tests
test
own
clean
virtual
environment
tox/pytest
warning
Django
NB
same
sudo
docker-compose
run
workdir
/src/MCPClient
rm
entrypoint=py.test
archivematica-mcp-client
-p
cacheprovider
warnings
reuse-db
-v
tests/test_archivematicaClient.py
pytest
versions
briefly
platform
differences
output
>
handle_batch_task
gearman_job_mock
supported_modules_mock
src/MCPClient/tests/test_archivematicaClient.py:57
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
=
<
Mock
id='140345534660560
>
<
Mock
id='140345534660496
>
wraps
f
wrapper
*
args
*
*
kwargs
try
return
f
*
args
*
*
kwargs
>
assert
False
E
AssertionError
@
pytest.mark.django_db
decorator
test
function
incorrect
calls
db
Otherwise
*
https
//stackoverflow.com/a/43213188
*
https
//pypi.org/project/undecorated/
work
person
mega
insights
decorators
*
https
//hynek.me/articles/decorators/
Python
handle_batch_task.__wrapped__
helper
db
mocks
Comments
sentences
https
//nedbatchelder.com/blog/201401/comments_should_be_sentences.html
guy
coverage.py
like
documentation
module
level
case
docstring
module
L2
worth
way
Shall
True
original
line
true
more
information
user
need
enough
information
Failure
complete.
Given
@
jhsimpson
[
comment
]
https
//github.com/artefactual/archivematica/pull/894
issuecomment-359978178
original
unsanitized
name/path
METS
file
case
transfer
files
sanitizable
names
File
rows
index
command
originallocation
value
incorrect
minor
issue
archivematicaCommon/lib/namespaces.py
Same
xlink
True
haha
actual
logging
SVN
tearDown
https
//docs.python.org/2/library/unittest.html
unittest.TestCase.tearDown
assertion
additional
value
few
lines
Nitpick
style
verbose
lot
Archivematica
recent
code
concise
more
Pythonic
Holly
Joel
E.g
lines
code
response
'Content-Disposition
]
=
\
preview_file
else
content_disposition
other
places
lot
inline
e.g
https
//github.com/artefactual/archivematica/blob/4e84fa7bf4392b8cecf7bce8abb6009ed71d50ea/src/archivematicaCommon/lib/bindpid.py
L307-L357
line
import
ignore
line
char
LineLength
pep8
yell
coalib.results.SourceRange
import
SourceRange
Ignore
PyUnusedCodeBear
line
right
thats
chars
same
comment
comment
self.check_message
LOG_LEVEL.WARNING
confuses
time
test
case
right
P
code
number
functions
nice
explanation
tests
IRL
impossible
list_of_bears
empty
file
bears
user
action
impossible
exception
rise
>
raise
bit
P
bear
test
case
other
crashed^^
log
core
emits
👍
Check
exception
handling
example
wrong
case
sure
lowercase
*
fundamental
upper
case
letters
D
comment
stmt
\+
Better
use
platform.system
==
+1
sorry
comment
useless
anything
warning
Google
Teapot
https
//github.com/coala/coala/issues/5628
issuecomment-404678858
background
W291
whitespace
*
Origin
PycodestyleBear
W291
Section
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpgm4j5zxm/coalib/misc/Compatibility.py
+++
b/tmp/tmpgm4j5zxm/coalib/misc/Compatibility.py
@
@
-1,6
+1,6
@
@
import
json
try
JSONDecodeError
class
available
Python
+
JSONDecodeError
class
available
Python
JSONDecodeError
=
json.decoder.JSONDecodeError
AttributeError
pragma
Python
cover
JSONDecodeError
=
ValueError
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpuqp_p4s4/coalib/misc/Compatibility.py
+++
b/tmp/tmpuqp_p4s4/coalib/misc/Compatibility.py
@
@
-1,6
+1,6
@
@
import
json
try
JSONDecodeError
class
available
Python
+
JSONDecodeError
class
available
Python
JSONDecodeError
=
json.decoder.JSONDecodeError
AttributeError
pragma
Python
cover
JSONDecodeError
=
ValueError
available
available
D
Line
inconsistencies
Trailing
whitespaces
*
Origin
SpaceConsistencyBear
Section
python
issue
following
patch
diff
a/tmp/tmpgm4j5zxm/coalib/misc/Compatibility.py
+++
b/tmp/tmpgm4j5zxm/coalib/misc/Compatibility.py
@
@
-1,6
+1,6
@
@
import
json
try
JSONDecodeError
class
available
Python
+
JSONDecodeError
class
available
Python
JSONDecodeError
=
json.decoder.JSONDecodeError
AttributeError
pragma
Python
cover
JSONDecodeError
=
ValueError
Line
inconsistencies
Trailing
whitespaces
*
Origin
SpaceConsistencyBear
Section
python
issue
following
patch
diff
a/tmp/tmpuqp_p4s4/coalib/misc/Compatibility.py
+++
b/tmp/tmpuqp_p4s4/coalib/misc/Compatibility.py
@
@
-1,6
+1,6
@
@
import
json
try
JSONDecodeError
class
available
Python
+
JSONDecodeError
class
available
Python
JSONDecodeError
=
json.decoder.JSONDecodeError
AttributeError
pragma
Python
cover
JSONDecodeError
=
ValueError
side_effect
plain
Bear
comment
implements
splitlines
value
python
lines
=
output.splitlines
self.assertEqual
lines
]
'-
>
yield
´
double
space
more
tests
please
Iterable
generator
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/coalib/bearlib/aspects/__init__.py
+++
b/coalib/bearlib/aspects/__init__.py
@
@
-32,6
+32,7
@
@
>
>
>
[
'shortlog.colonExistence
]
<
aspectclass
'Root.Metadata.CommitMessage.Shortlog.ColonExistence
>
+
def
__init__
module
members
original
module
object
opinion
manual
imports
automatic
function
https
//github.com/coala/aspect-docs/blob/master/generate
L192
better
aspect
indexing
self-update-able
other
aspect
module
appear
something
bears
E225
whitespace
operator'
*
PycodestyleBear
E225
severity
NORMAL
section
autopep8
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/tests/coalaDebugFlagTest.py
+++
b/tests/coalaDebugFlagTest.py
@
@
-52,7
+52,7
@
@
prepare_file
[
fixme
]
None
lines
filename
RaiseTestBear
independency
bears
status
stdout
stderr
=execute_coala
+
status
stdout
stderr
=
execute_coala
coala.main
debug
json
'-c
'-f
re.escape
filename
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/tests/coalaDebugFlagTest.py
+++
b/tests/coalaDebugFlagTest.py
@
@
-63,7
+63,7
@
@
mocked_ipdb.launch_ipdb_on_exception.assert_called_once_with
def
test_bear_run_raises
mocked_mode_json
mocked_mode_json.side_effect=None
+
mocked_mode_json.side_effect
=
None
mocked_ipdb
=
self.ipdbMock
bear_test_module
prepare_file
[
fixme
]
None
lines
filename
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/coalib/coala_main.py
+++
b/coalib/coala_main.py
@
@
-128,7
+128,7
@
@
counter
handler
errors
handler
logger.handlers
handler.name
==
counter
handler.name
==
counter_handler
=
handler
break
cover
comment
https
//github.com/coala/coala/pull/4339
pragma
cover
specific
exceptions
other
comment
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/tests/core/CircularDependencyErrorTest.py
+++
b/tests/core/CircularDependencyErrorTest.py
@
@
-15,6
+15,7
@
@
def
test_message_with_causing_bears
class
FakeBear
object
+
def
__init__
name
self.name
=
name
CircularDependencyError
__init__
/
default
arguments
start_comment
end_comment
=
list
]
start_comment
end_comment
=
multiline_comment_delimiter.items
]
case
use
start_comment
end_comment
=
next
iter
performance
version
whole
dict
first
element
Line
inconsistencies
Trailing
whitespaces
*
SpaceConsistencyBear
severity
NORMAL
section
python
issue
following
patch
diff
a/coalib/results/result_actions/IgnoreResultAction.py
+++
b/coalib/results/result_actions/IgnoreResultAction.py
@
@
-85,7
+85,7
@
@
>
>
>
import
>
>
>
logging.basicConfig
stream=sys.stdout
level=logging.DEBUG
>
>
doctest
+ELLIPSIS
IgnoreResultAction
.get_ignore_comment
Bear
Dothraki
IgnoreResultAction
.get_ignore_comment
Bear
Dothraki
WARNING
root
coala
Ignore
Dothraki
https
//attrs.readthedocs.io/en/stable/examples.html
nvm
@
attr.s
magic
class
comparison
operators
bear
comparable
dependency
results
complete
refactor
attr.ib
PR
attrs
bit
good
fit
functions
proxies
dependency
dict
_dependency_results
attr.ib
init=collections.defaultdict
list
force
constructor
dependency_results
stderr
bug
unknown
error
good
thing
good
thing
comment
output
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/coalib/parsing/LineParser.py
+++
b/coalib/parsing/LineParser.py
@
@
-80,7
+80,7
@
re.match
[
^
]
[
^
]
line
None
logging.warning
'The
comment
whitespace
+
line.replace
\n
+
line.replace
line
comment
=
self.__separate_by_first_occurrence
line
self.comment_separators
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/coalib/parsing/LineParser.py
+++
b/coalib/parsing/LineParser.py
@
@
-80,7
+80,7
@
re.match
[
^
]
[
^
]
line
None
logging.warning
'The
comment
whitespace
+
line.replace
\n
+
line.replace
\n
line
comment
=
self.__separate_by_first_occurrence
line
self.comment_separators
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/coalib/parsing/LineParser.py
+++
b/coalib/parsing/LineParser.py
@
@
-83,7
+83,7
@
@
line
logging.warning
'This
comment
whitespace
+
repr
line.replace
+
line
+
repr
line.replace
+
line
+
'be
+
<
comment
>
line
comment
=
self.__separate_by_first_occurrence
something
comment
backslash
case
C
right
comment
comment
comment
use
repr
line.replace
internal
quoting
way
context
manager
thing
SWIP-ey
pseudo-code
way
easier
method
Class
AnomolyMonitor
feature_thresholds
list
None
def
__enter__
return
def
_final_thresholds
_scaled_mse_timestep
collect
true
fold
self.feature_thresholds.append
_feature_fold_thresholds
true
def
__exit__
calc
calc
aggregate
class
def
cv
AnomolyMontior
am.collect
true
fold
self.aggregate
=
am.aggregate
comment
y
X
equal
equal
_length_
Comment
bad
Comment
much
good
comment
example
enough
workflow
type
bigflow
run
workflow
internationalports
commands
Log
GCP
Google
Cloud
SDK
gcloud
auth
application-default
login
GCP
Google
Cloud
SDK
Squish
Requirements
Preparations
single
section
w
ogóle
nie
opisuj
jak
instalować
bf
tylko
zalinkuj
dokumentacji
[
Installing
BigFlow
]
https
//github.com/allegro/bigflow/blob/master/README.md
installing-bigflow
będzie
taka
[
Cloud
Composer
]
Create
[
Cloud
Composer
]
instance
Nit
inline
comments
purpose
module-level
strings
variables
reassignment
opt
own
if-statement
params
e.g
Explain
hasattr
'optimizer
opt
=
opt.optimizer
Log
optimizer
attributes
hasattr
'_name
reason
name
same
branch
clarifying
comment
e.g
name
outer
optimizer
inner
optimizer
rate
epislon
name
opt
afterwards
clearer
fit
call
least
start/end
times
@
cosmincatalin
Can
conda_env
parameter
save_model
method
check
argument_type
valueless
inputs
acceptable
argument_type=A
valueless
inputs
project
parameters
separate
PR
documentation
project
parameters
changes
https
//github.com/mlflow/mlflow/pull/3061/files
r451860120
special
casing
logic
t
code
prints
fn
file
lgtm
work
types
sql
database
backends
error
new
one
older
style
nit
triple-quoted
block
newlines
string
textwrap
standard
library
module
unwanted
indentation
e.g
Add
import
textwrap
top
file
import
textwrap
text
=
textwrap.dedent
Unable
MLflow
UI
landing
page
index.html
likely
MLflow
server
source
installation
Python
MLflow
package
stored
r.name
full
path
blob.core.windows.net/
wrong
answers
>
>
os.path.relpath
a/b/c/
p/q/r
..
/
/
..
/a/b/c'
..
>
>
os.path.relpath
a/b/c/
b/c/p/q/r
..
/
/
..
/
..
/
..
/a/b/c'
code
unit
test
case
future
Could
usage
loaded
base
values
shap
values
e.g
explanations
new
input
model
@
shrinath-suresh
thanks
feature
request
https
//github.com/PyTorchLightning/pytorch-lightning/issues
/
improvements
callback
Pytorch
Lightning
MlflowLogger
long-term
ideal
Pytorch
Lightning
MlflowLogger
test
mlflow.pytorch.autolog
mlflow.start_run
run
insert
code
model
assert
mlflow.active_run
==
run.info
suggestion
autolog
insert
code
model
assert
mlflow.active_run
None
test
patched
pl.Trainer.fit
auto-created
run
nit
assert
callbacks
data.params
passes
data.params
unwanted
parameters
parameter
foo
way
pretty
cool
nice
test
verifying
results
timestamp
value
second
append
order
file
i.e
[
Metric
key=
timestamp=0
Metric
key=
timestamp=0
Metric
key=
value=-1
timestamp=1
Metric
key=
timestamp=0
]
Metric
-1
etc
nit
comparison
timestamps
values
numeric
types
general
right
answer
numbers
something
python
metric_data
=
[
]
line
read_file_lines
parent_path
metric_name
timestamp_string
=
line.split
metric_data.append
int
float
ordering
logic
fact
Python
builtin
tuples
first
entry
second
>
>
>
[
]
>
>
>
tuples
]
logic
python
max_timestamp
max_value
=
metrics_data
-1
conversion
strings
numbers
TODO
Assert
run
state
successful
TODO
Assert
child_params
CV
params
best
estimator
params
better
approach
Certain
models
predict
example
https
//scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html
sklearn.cluster.SpectralClustering.fit
case
predict
undefined
tomorrow
conjunction
other
comment
below
correct
input
most
metrics
functions
best
option
metrics
regression
/
classification
Nit
specific
comment
_SklearnMetric
metric
routine
particular
model
type
GridSearchCV
case
comment
input
Hm
old
MLflow
flask
server
ENDPOINT_NOT_FOUND
INTERNAL_ERROR
INTERNAL_ERROR
s
model
client
PR
server
print
statement
error
code
output
>
>
import
mlflow
import
mlflow.pyfunc
mlflow.set_tracking_uri
http
//localhost:5000
mlflow.pyfunc.log_model
abc
mlflow.pyfunc
/Users/sid.murching/miniconda3/envs/mlflow-python3/lib/python3.6/site-packages/pyspark/cloudpickle.py:47
DeprecationWarning
imp
module
favour
importlib
module
documentation
alternative
uses
imp
@
SID
error
code
INTERNAL_ERROR
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
File
/Users/sid.murching/code/mlflow/mlflow/pyfunc/__init__.py
line
log_model
registered_model_name=registered_model_name
/Users/sid.murching/code/mlflow/mlflow/models/__init__.py
line
log
raise
e
File
/Users/sid.murching/code/mlflow/mlflow/models/__init__.py
line
log
mlflow.tracking.fluent._record_logged_model
mlflow_model
/Users/sid.murching/code/mlflow/mlflow/tracking/fluent.py
line
_record_logged_model
MlflowClient
._record_logged_model
run_id
mlflow_model
/Users/sid.murching/code/mlflow/mlflow/tracking/client.py
line
_record_logged_model
self._tracking_client._record_logged_model
run_id
mlflow_model
/Users/sid.murching/code/mlflow/mlflow/tracking/_tracking_service/client.py
line
_record_logged_model
self.store.record_logged_model
run_id
mlflow_model
/Users/sid.murching/code/mlflow/mlflow/store/tracking/rest_store.py
line
record_logged_model
self._call_endpoint
LogModel
req_body
/Users/sid.murching/code/mlflow/mlflow/store/tracking/rest_store.py
line
_call_endpoint
return
call_endpoint
self.get_host_creds
endpoint
method
json_body
response_proto
/Users/sid.murching/code/mlflow/mlflow/utils/rest_utils.py
line
call_endpoint
response
=
verify_rest_response
response
endpoint
/Users/sid.murching/code/mlflow/mlflow/utils/rest_utils.py
line
verify_rest_response
raise
MlflowException
%
s
Response
body
%
s
%
base_msg
response.text
mlflow.exceptions.MlflowException
API
request
/api/2.0/mlflow/runs/log-model
error
code
=
Response
body
<
DOCTYPE
HTML
PUBLIC
-//W3C//DTD
HTML
Final//EN
>
title
Found
<
/title
>
<
h1
>
Found
<
/h1
>
<
p
requested
URL
server
URL
spelling
again.
<
/p
>
code
comment
import
mlflow.keras
only
code
changes
example
https
//github.com/mlflow/mlflow/blob/master/mlflow/store/tracking/sqlalchemy_store.py
L627
Please
comment
%
test_fo
..
step
parameter
range
things
e.g
def
chunks
lst
n
Yield
successive
n-sized
chunks
lst
i
range
lst
yield
lst
[
i
i
n
]
Credits
//stackoverflow.com/a/312464/11952869
dictionary
list
Metric
objects
comment
e.g.
old
file
store
data
number
comment
change
similar
isinstance
@
dbczumar
sense
code
similar
setup
keras
tests
iris
dataset
dataset
onnxruntime.get_inputs
returns
input
[
'dense_1_input_01
]
whole
dataframe
input
tests
dataframe
feed_dict
=
input_name
dataframe
[
input_name
]
.values
input_name
self.input_names
fails
dataframe
'dense_1_input_01
column
reason
requirement
input
predict
accepts
dataframe
input
thoughts
parameter
mlflow.onnx.save_model
[
onnx.save_model
]
https
//github.com/onnx/onnx/blob/51b6ecce7a6f7bfc3b7944e77614bc0c38d0db96/onnx/__init__.py
L168
method
keyword
arguments
signature
save_model
proto
f
format=None
type
Union
[
ModelProto
]
Union
[
IO
[
]
Text
]
Optional
[
Any
]
>
None
ModelProto
path
@
params
proto
in-memory
ModelProto
f
file-like
object
write
function
string
file
name
format
future
use
sense
kwargs
parameter
large
marks
tests
@
suggestions
easy
tests
python
approach
concern
get_registry_uri
equivalent
default
values
uri
set_tracking_uri
use
MlflowClient
important
registry
URI
registry_uri
parameter
value
get_registry_uri
tracking_uri
parameter
value
get_tracking_uri
get_registry_uri
context
stand-alone
method
_final_
registry
uri
logic^
familiar
get_tracking_uri
option
function
get_registry_uri
tracking_uri=None
current
registry
URI
return
URI.
global
_registry_uri
return
_registry_uri
tracking_uri
get_tracking_uri
bit
convoluted
logic
tracking_uri
sync
other
places
tracking_uri
unlikely
bit
comment
py4j
errors
high
level
e.g.
something
sure
princ_exc
comment
azureml-defaults
necessary
description
https
//pypi.org/project/azureml-defaults/
pretty
vague
azureml-defaults
metapackage
Azure
Machine
Learning
Similar
comment
regards
order
tests
good
i
additional
test
None
token
calls
search
models
max_results
round
results
backend
RMs
Micronit
nice
comment
updated
validation
e.g
Regex
valid
run
IDs
alphanumeric
string
BTW
intentional
zero-length
run
IDs
Empty-string
run
IDs
FileStore
IMO
users
sorry
discussion
point
case
Capitalize
comments
code
style
Nit
repo_url
[
]
necessary
output
pyfunc_loaded.predict
x
pandas
DataFrame
shape
N
predicted
N
Wrapping
DataFrame
such
behavior
docstring
state
assumption
work_dir
git
repo
comment
quick
comment
name
good
'default
bit
suggestion
first
len
args
elements
all_param_names
names
arguments
positional
arguments
user
default
values
suggestion
default
values
user
kwargs
non-default
TODO
docstring
hosted
API
docs
e.g
docs
]
https
//mlflow.org/docs/latest/python_api/mlflow.tensorflow.html
mlflow.tensorflow.load_model
mlflow.tensorflow.load_model
[
code
]
https
//github.com/mlflow/mlflow/blob/0539a16f841f990717b3d1260e9670074e30a71c/mlflow/tensorflow.py
L181
Hm
purpose
__dir__
__getattr__
lazy
loading
interface.py
suggestion
[
experimental
]
Deploy
MLflow
models
targets
Downstream
functions
plugin
idea
deployments
commands
different
experimental
users
mlflow
help
following
models
deployments
CLIs
sound
similar
Usage
mlflow
[
OPTIONS
]
COMMAND
[
ARGS
]
Options
version
Show
version
exit
message
exit
Commands
artifacts
Upload
list
download
artifacts
MLflow
artifact
Serve
models
Azure
ML
Commands
MLflow
tracking
database
deployments
Deploy
MLflow
models
experiments
Manage
experiments
gc
..
models
Deploy
MLflow
models
Run
MLflow
project
URI
Manage
sagemaker
Serve
models
SageMaker
server
Run
MLflow
tracking
server
ui
Launch
MLflow
tracking
UI
local
viewing
run
something
Usage
mlflow
[
OPTIONS
]
COMMAND
[
ARGS
]
Options
version
Show
version
exit
message
exit
Commands
artifacts
Upload
list
download
artifacts
MLflow
artifact
Serve
models
Azure
ML
Commands
MLflow
tracking
database
deployments
[
experimental
]
Deploy
MLflow
models
targets
experiments
Manage
experiments
gc
..
models
Deploy
MLflow
models
Run
MLflow
project
URI
Manage
sagemaker
Serve
models
SageMaker
server
Run
MLflow
tracking
server
ui
Launch
MLflow
tracking
UI
local
viewing
run
suggestion
click.echo
Deployment
IDs
target
\n
.format
target
ids
suggestion
click.echo
deployment
model
flavor
Deployment
ID
model
.format
deployment.flavor
deployment.id
suggestion
click.echo
deployment
target
.format
_deployment_id
target
sense
suggestion
help=
ID
deployment
option
command
vs
help
string
sense
delete
command
update
ID
deployment
more
sense
Agreed
/
right
syntax
URI
thanks
Personally
reserved
keyword
better
name
list
Appreciate
help
Make
sense
KeyError
target
MlflowException
required
error
message
work
KeyError
plugin_store
re-raising
MlflowException
pythonic
try
block
interface
functions
able
check
Python
support
test
shorthand
form
flavor
model
URI
URI
arguments
e.g
-f
flavor
-m
model_uri
-t
target
error
case
only
flavor
exception
suggestion
search_runs
example
suggestion
print
results
[
run_id
params.child
tags.mlflow.runName
]
.to_string
suggestion
results
=
mlflow.search_runs
filter_string=query
print
results
[
run_id
params.child
tags.mlflow.runName
]
]
obvious
results
santosh1994
Can
comment
May
https
//github.com/googleapis/google-cloud-python/issues/5163
reference
new_cluster_spec
[
fields
https
//docs.databricks.com/dev-tools/api/latest/jobs.html
clusterspec
valid
libraries
e.g
logic
suggestion
'new_cluster
cluster_spec
'libraries
cluster_spec
libraries.extend
cluster_spec
[
'libraries
]
cluster_spec
=
cluster_spec
[
'new_cluster
]
unit
test
similar
]
https
//github.com/mlflow/mlflow/pull/2845/files
diff-e5f3a2fbd5bd330b3069ea935f1718eeR273-R296
libraries
open
support
follow-up
PR
route
exception
user
specifies
libraries
object
new_cluster
REST
API
job
thanks
Small
parameters
Databricks
asynchronous
local
runs
run
client
second
time
mlflow
run
Databricks
cluster
latter
async
local
runs
twice
ok
params
log-all-params
logic
_create_run
branch
params
creation
time
mlflow.start_run
mlflow.start_run
mlflow.end_run
suggestion
mlflow.pytorch.log_model
scripted_model
model
Nit
default
model
path
model
need
model
path
rules
suggestion
model_path
=
mlflow.get_artifact_uri
model
model_path
model
suggestion
__future__
import
print_function
suggestion
Log
text
file
run
root
artifact
directory
suggestion
Log
HTML
suggestion
Log
text
subdirectory
run
root
artifact
directory
suggestion
TODO
Unskip
parameters
https
//github.com/h5py/h5py/issues/1732
nit
TODO
easier
later
Mind
brief
class
comment
responsible
Speaking
throw
true
no_conda
true
TODO
follow-ups
comment
backwards-compatibility
comment
sorted_joins
order
columns
needs
OUTER
JOIN
semantics
runs
keys
order
columns
end
order
last
regardless
order
ASC
DESC
previous
behavior
filter
push
downs
cc
@
dbczumar
micronit
multiple
Python
context
managers
single
statement
repeated
indents
e.g
mock.patch
x
mock.patch
y
use
x
comment
correct
familiar
Spacy
worth
limitation
save_model
log_model
docstrings
Seems
good
idea
functionality
minimal
initial
PR
idea
other
types
Spacy
pipeline
components
future
able
tracking_uri_mock
fixture
tests.projects.utils
URI
https
//github.com/mlflow/mlflow/blob/360c0cada0174b71500a83ded72260b6b6942d90/tests/sklearn/test_sklearn_model_export.py
L159
Yeah
sense
comment
sleep
duration
odds
runs
Keras
models
tests
chance
Spark
datasource
info
failure
Spark
Travis
slow
nit
standard
def
test_name
Number
runs
less
max_results
page
@
tomasatdatabricks
good
example
public
APIs
metrics
past
runs
great
store.get_metric
public
API
Could
Tracking
Service
API
metrics
pretty
public
API
example
internal
API
Airflow
https
//github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py
L297
Set
migration
script
directory
DB
URL
URL
command
[
Alembic
API
]
https
//alembic.sqlalchemy.org/en/latest/api/commands.html
commands
Airflow
wheel
python
bdist_wheel
relative
paths
such
work
wheel
installation
Ideally
something
mlflow.data.download_uri
files
S3
other
cloud
storage
systems
great
API
HTTP
code
TODO
here.
comment
validation
run
tag
default
experiment
id
suggestion
.trash
folder
artifact
URI
location
top
suggestion
Create
experiment
suggestion
.trash
folder
artifact
URI
location
top
suggestion
Set
tag
fetch
info
comment
default
experiment
suggestion
Create
run
experiment
ID
self._registry_uri
=
registry_uri
final_tracking_uri
self._tracking_client
=
TrackingServiceClient
final_tracking_uri
registry
client
APIs
_get_registry_client
resolution
temporary
csv
file
iris_training.csv
suggestion
@
pytest.mark.large
def
test_lgb_autolog_continues_logging_even_if_signature_inference_fails
tmpdir
signature
input
example
inference
dataset
file
path
tmp_csv
=
tmpdir.join
tmp_csv.write
=
lgb.Dataset
tmp_csv.strpath
manual
munging
dictionary
experiments
next
[
]
bug
server
ints
unit
test
accordance
comment
mlflow/__init__.py
consistency
other
modules
code
discoverability
Just
TODO
reference
URIs
//tracking-server-hostname/run-id/path/to/run
[
RFC
doc
]
https
//docs.google.com/document/d/1gSoDFncrBxFe3kBrFEc8zhBG-JhE0QvNuictB4aG6vY/edit
heading=h.8piqid4eb5v6
good
place
test
typed
objects
python
bit
weird
execution_script_file.name
_create_execution_script
filename
execution_script_filename
something
=
model_path
multiple
signs
suggestion
regressor
classes
samples
classifier
classifier
values
pred
predicted
probability
class
IN
query
conditions
conditions
IN
queries
choice
Ah
interesting
xgboost
available
default
conda
channels
P
conda
install
xgboost
Mac
conda_env_path
able
private
load_conda_env
true
variable
self._conda_env_path
class
suggestion
Exclude
mlflow
system
precise
Nit
@
t-henri
six.moves
import
urllib
https
//six.readthedocs.io/
module-six.moves.urllib.request
function
dict
keys
bytes
size
variable
name
_MIN_SKLEARN_VERSION
sense
fixture
try_mlflow_log
tests
Nit
test
function
test
scenario
test
function
validate
multiple
scenarios
Sorry
earlier
suggestion
infos
infos
]
.is_dir
False
infos
]
.path
==
path
directory
single
file
list_artifacts
path=directory
function
[
FileInfo
file_size=
<
some-size
>
path=
<
directory
>
/
<
file
>
>
]
path
comparison
function
empty
list
incorrect
Thanks
@
dbczumar
isinstance
value
string
getattr
DataType
type
Datatype
e.g
getattr
DataType
boolean
DataType.boolean
map
doc
comment
helpful
type
constructor
data_type
type
json
ColSpec
*
*
json.loads
ok
cause
context
constructor
unit
tests
cases
good
variety
ndarrays
confirm
work
numpy
documentation
Nit
comment
class
constructor
information
clazz
allow_children
parameters
should_log
method
information
behavior
information
lack
thread
safety
guarantees
class
okay
I.e.
use
cases
allow_children=True
list
pop
operations
thread-safe
session
stack
SklearnTrainingSessions
exit
future
multithreaded
backends
Minor
file0
>
=
i
same
thing
TODO
performance
due
amplification
suggestion
AVG_PARQUET_CELL_BYTES
=
heuristic
flooding
memory
comment
preview
endpoint
variable
correct
False
environ.get
string
useful
type
introspection
group
group
df
df
bad
user
vs
good
user
bad
package
name
possible
package
loader
returns
success
failure
messages
cases
different
error
messages
test
harness
proper
errors
fixed
comment
None
suggestion
_source
=
[
'key
'version_id
'user_meta
'comment
'handle
'hash
'tags
]
data
search
cards
patch
Simpler
guarantees
old
value
end
Suggestion
parameter
queue
send
queue
certain
size
way
lambda
able
large
batches
memory
respond
load
code
nice
boto3.session.Session
credentials
Session
.get_credentials
recursion
bothers
bit
everything
error
helper
function
errors
self._send_all_helper
self.queue
errors
error_queue
=
self._send_all_helper
error_queue
kinda
weird
O
N^2
better
way
iterate
errors
doc_id
s
iterate
self.queue
docs
call
send_again
empty
good
code
errors
suggestion
size
aggregates
results
comment
assert
imports
i
comment
dimaryaz
comment
connection
i
older
copy
setup.py
suggestion
device
file
timestamp
unchanged
=
>
cache
see
//docs.python.org/3/library/os.html
os.stat_result
stat.st_dev
==
dev
stat.st_ino
==
ino
stat.st_mtime_ns
==
mtime
TODO
pyarrow
change
part
PR
till
pyarrow
i
get_free_space
PR
cleaner
prints
case
function
other
CLI
hard
comment
wrong
while
Prefer
list
comprehension
filter
bit
safer
X
DEFAULT
FORBIDDEN_PREFIXES=
everything
dangerous
suggestion
FORBIDDEN_PREFIXES
=
[
int
x
x
os.environ.get
FORBIDDEN_PREFIXES
suggestion
issuer=
https
%
s/
%
Pythonic
aiohttp
Client
]
https
//docs.aiohttp.org/en/stable/client_quickstart.html
make-a-request
reason
Python
hipster
goroutines
synchronous
call
whole
server
thread
suggestion
return
User
*
*
resp
free
rid
self.batch_size
code
little
bit
fact
0th
column
<
s
>
comment
0th
column
stripped/not
end
comment
perspective
_beam_search
block
fact
different
finished
argument
block
NormalizeAndUpdateFinished
assign
return
values
anything
flags
specific
class
arguments
ARGUMENTS
something
similar
suggestion
def
convert_weights_cpu_dependent
params
mx.gluon.parameter.ParameterDict
test
minimal
example
order
actual
outputs
comment
RNN
model
different
hidden
states
general
list
hidden
decoder
comment
dimensionality
date
comment
string
confirmation
https
//github.com/OpenNMT/VisTools/issues/2
PR
@
hyandell
recommendation
licences
file
typo
test
tmpdir
set
temporary
directory
test
HybridBlock
TopK
vocabulary
selection
static
shape
scores
TODO
better
solutions
features
hybridizable
blocks
better
performance
lexicon
lookup
methods
TODO
implementation
MXNet
better
support
set-like
operations
Minor
ok
frozen
config
something
aware
k
=
self
previous
PR
dark
commits
child
config
reference
parent
__dict__.items
'ourselves
Right
_populate_bucket_batch_sizes
_assign_to_buckets
little
convoluted
data
substantial
refactoring
comment
docstring
old
TODO
behavior
changelog
docstring
TranslatorInput
data
translator
preference
input
data
same
key
explicit
call
comments
when/where
data
instance
docstring
ParallelBucketSentenceIter
corpus
disk
stores
sentences
NumPy
array
code
process
code
comment
refer
asscalar
conversion
offset
batch
*
beam
=
int
offset.shape
]
/
k
=
scores.reshape
reshape
-1
beam_size
shape
batch
beam
target_vocab_size
=
scores.reshape
-3
shape
batch
beam
*
target_vocab_size
redundant
comment
line
sense
logic
embedding
matrix
vocabularies
embedding
separate
function
file
mxnet
initializer
output
numpy
normal
distribution
initialization
sockeye/initializers.py
use
case
initialization
code
sockeye.train
call
vocabulary
part
PR
code
reusable
easier
test
type
ignore
mypy
comment
states
first
elements
metric
corresponding
loss
loss
batch
size
wrong
number
non-pad
tokens
batch
denominator
available
label.shape
[
]
mxnet
[
CrossEntropy
]
https
//github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py
L918
metric
back
MXNet
long
term
Ignore
pad
symbols
generic
modification
dependency
LossConfig
easy
TODO
computation
update
intermediate
values
batch
checkpoint
objective
common
method
warning
Eve
constructor
i.e
rescale_gradient
etc
present
kwargs
Eve
l1/l2
regularizations
Section
weight
decay
error
Optional
type
annotation
type
member
variable
=
None
type
Optional
[
BatchState
]
FYI
[
PEP
]
https
//www.python.org/dev/peps/pep-0526/
variable
annotations
python
>
=3.4
Optional
[
BatchState
]
=
None
Optional
variable
None
variables
None
MXNet
standard
Adam
update
rule
C++
afaik
https
//github.com/apache/incubator-mxnet/blob/master/python/mxnet/optimizer.py
L649
variance
term
d
eps
var
variable
update
C++
backend
nd.zeros_like
weight
ctx=weight.context
https
//mxnet.incubator.apache.org/api/python/ndarray.html
mxnet.ndarray.zeros_like
lists
fixed
size
sense
tuples
comments
mx
NDArray
good
catch
izip
longest
models
None
Could
comment
wondernig
self.models
i
different
max
output
lengths
yes
max
pep8
spaces
@
Did
something
lines
mind
filename
version
unnecessary
usage
part
argparse
description
argparse.ArgumentParser
description=
proper
doc-string
method
def
benchmark
doc
other
functions
MODEL_TEST_ARGS_TRANSFORMER
MODEL_TEST_ARGS_GNMT
MODEL_TRANSFORMER
MODEL_GNMT
dgnmt
>
gnmt
self.length_ratio_task
None
TODO
memory/speed
options
many
performance
optimization
TODOs
>
cuDNN
clear
step
note
symbol
comment
nice
trick
worth
comment
matrix
lower
triangle
main
diagonal
set
upper
triangle
[
nit
]
spaces
code
inline
comments
self-explanatory
comment
offset
mask
function
function
batch_size
_beam_search
example
pad_dist
scores
arrays
pylint
disable=unbalanced-tuple-unpacking
line
pylint
happy
sure
afterwards
block
test_vocab.py
fine
Add
comment
+2
return
[
random.randint
+
_
range
length
float
booleans
i.e
false
true
safe
np.isclose
Yep
docs
implicit
object
collides
built-in
function
i
_
id
Felix
comment
type
List
[
X
]
specified
X
type
checking
case
statements
try
block
something
specific
try
/
/
pass
construction
brief
comment
Update
docstring
main
function
attributes
output
object
comment
line
@
ahuang11
ideas
method
compute
functions
dictionary
+
attrs
function
end
separate
private
function
module
things
cleaner
decorator
@
lot
arguments/variables
function
circular
imports
PR
Add
python
hindcast
observational
data
hindcast
experiment
Attributes
hind
xarray
Dataset
observations
xarray
Dataset
m2o
comment
clear
circular
imports
caps
sure
dim='bootstrap
function
head
comment
Delete
comment
above
my_quantile
works
bootstrap_compute
first
dimension
bootstrap
time
axis
=0
nans
small
demo
runs
asserion
errors
python
a.dims
q
=
.05
chunk_dim
dim
=
'lon
ac
=
a.chunk
chunk_dim
=
a.quantile
dim=dim
q=q
acp.shape
%
time
acp2
=
my_quantile
ac
dim
q
.compute
acp2.shape
xr.testing.assert_allclose
acp
acp2
acl
=
ac.load
%
time
acp
=
my_quantile
acl
dim
q
.compute
acp.shape
xr.testing.assert_allclose
acp
acp2
chunk_dim
dim
=
'time
acp
=
a.quantile
dim=dim
q=q
acp.shape
ac
=
a.chunk
chunk_dim
%
time
acp2
=
my_quantile
ac
dim
q
.compute
acp2.shape
xr.testing.assert_allclose
acp
acp2
acl
=
ac.load
%
time
acp
=
my_quantile
acl
dim
q
.compute
acp.shape
xr.testing.assert_allclose
acp
acp2
following
comment
function
name
self-explanatory
suitable
example
skipna
ideas
area
member
compute
skipna=False
compute
skipna=True
delete
headers
prominent
doppyo
===================================================================================================
Methods
probabilistic
comparisons
unnecessary
comments
sure
spaces
second
lines
docstring
docs
Make
sure
instances
docstrings
.rst
/
sphinx
uses
code
logic
comment
comment
POP
grid
e.g
CESM
support
explicit
support
other
models
CMIP6
archive
inplace
area
comment
equivalent
==
list
smooth_dict.values
]
more
straightforward
lines
dict
comprehension
time_dims
smooth_dict
=
dim
smooth
dim
[
'time
]
dim
ds.dims
’
t
care
other
temp
resolutions
Goddard
paper
decadal
predictions
standard
checks
checks
https
//github.com/bradyrx/climpred/blob/master/climpred/checks.py
useful
origin
labels
prediction
skill
expected
results
Does
higher
resolution
interp
comprehension
cleaner
readable
except
Exception
e
e
error
statement
Please
docstring
Just
Bootstrap
hindcast
skill
init
dimension
member
dimension
additional
dimension
iteration
entire
dimension
parallel
members
same
way
knowledge
init
dimension
iteration
I.e.
looped
fashion
alignment
initializations
target
dates
unique
iteration
explanation
inputs.
resample_dim='init
signature
function
readable
init
argument
clear
function
name
docstring
thought
behind
self._datasets
issue
comments
other
sub-dataset
self._datasets
dictionary
dimensions
subset
self._datasets
E.g
other_datasets.dims
dataset.dims
operation
course
.values
memory
.data
memory
init
[
dim
]
example
errors
following
works
member
dimension
init
=
np.arange
member
=
np.arange
lead
=
np.arange
da
=
xr.DataArray
np.random.rand
init
member
lead
dims=
[
'init
'member
]
coords=
[
init
member
lead
]
_resample_idx
da
concise
line
python
select_from
=
np.arange
init
[
dim
]
.size
np.vstack
[
np.random.choice
select_from
init
[
dim
]
.size
replace=False
_
range
bootstrap
]
yours
much
faster
let
way
mean
comment
import
issues
future
developers
something
ordering
imports
reference
part
docstring
wikipedia
article
https
//en.wikipedia.org/wiki/Scoring_rule
Calculate
right
Person
typo
documentation
purposes
many
optional
arguments
possible
https
//en.wikipedia.org/wiki/Scoring_rule
climpred.__version__
suggestion
Process
function
daemon
worker
function
importable
Note
actual
running
.ci/test_daemon.py
suggestion
node
=
submit
add_multiply
x=orm.Int
z=orm.Int
isinstance
node
WorkFunctionNode
import
file
basic
docstring
true
assert
comment
true
=
Data
entry
point
class
=
get_entry_point_string_from_class
node.__class__.__module__
suggestion
Returns
None
inclusion
list
logic
complex
prefix
case
group
%
case
*
exists
other
cases
complex
query
labels
abc
Decision
logic
add
comment
direct
tests
get_or_create
hand
rule
intrinsic
following
entry
points
valid
aiida.data
plugin.base.int
aiida.data
plugin.complex.int
aiida.data
plugin.
%
.int
valid
filter
Comments
tests
delete_all
class
exact
method
filters
QueryBuilder
possible
alias
DEFAULT_DBINFO
name
suggestion
separator
entry
point
string
wild
print
Good
deprecation
message
hookup
docstring
glorious
operator
joining
filepath
=
str
dirpath
/
filename
Add
comment
suggestion
Collect
data
node_data
main
iterable
one
memory
generator
sure
progress
bar
clearer
suggestion
*
applies
*
single
*
jobid
more
jobids
squeue
jobs=123,234
squeue
stops
valid
returns
exit
code
job
ids
other
effect
output
suggestion
reliable
way
squeue
command
jobs
output
error
empty
output
AiiDA
jobs
exit
code
squeue
squeue
non-zero
exit
code
*
single
*
invalid
jobid
squeue
comment
discussion
comments
other
function
suggestion
def
test_migrate_v8_to_v9
comment
line
previous
iteration
other
errors
something
EntryPointError
class
ValueError
tests
work_chain
process
context
workchain
side
note
context
something
modifiable
workchain
methods
anyways
intended
way
other
hand
things
sure
workchain
error
code
submits
workchain
instantiate_process
runner
generate_work_chain
case
sure
workchain
familiar
way
stuff
whole
note
sense
autogrouping
front
end
feature
explicit
definition
queries
comment
more
solution
problem
code
folders
remote
file
explanation
original
problem
copy_list
filename
file
subfolder
subfolder
first
create
empty
folders
appropriate
comments
attributes/extras
calculations
Log
entries
actual
test
namespace
tree
whatsoever
unsure
idea
global
dict
single
case
internal
variable
class
ocassions
many
layers
generalization
something
clear
HOW
i.e
future
ignored
nodes
different
class
lighter
version
current
defaults
function
optional
flag
current
implementation
Did
particular
reason
way
rid
global
dict
other
line
other
comment
name
change
self._ignored_node_style
=
'lightgray
'white
Note
conditional
states
CREATED
same
color
WAITING
fine
comment
pencolor
rid
code
sub
class
constructor
user
passes
filename
line
set_file
overridden
version
filename
switch
value
signature
fragile
filename
argument
TypeError
non-ideal
only
option
signature
method
fragile
suggestion
warnings.warn
method
hostname
property
AiidaDeprecationWarning
pylint
disable=no-member
error
zip
module
callable
module
zip
same
folder
module
Could
group_qb.iterall
further
improvement
results
batches
subsequent
code
time
time-to-solution
suggestion
match
=
re.match
r
[
\.\d
]
+
part
element
count
suggestion
match
None
suggestion
elif
re.match
r'^\d+
integer
number
quantity
=
int
quantity
float
suggestion
group
None
block
parentheses
suggestion
group
=
re.search
r
[
\
\
[
\
]
.+
\
\
]
\
]
[
\.\d
]
*
block
idea
_scan_type_default
class
attribute
_scan_types
use
constructor
leftover
comment
suggestion
idea
point
I.e
AiIDA
AttributeError
sure
people
NotExistent
exception
composed
exception
case
Same
NotExistentKeyError
quick
comment
special
exception
similar
fixture
Code
instance
localhost
Code
fixture
impossible
reference
@
pytest.fixture
def
generate_code_localhost
Code
instance
calculations
entry
point
localhost
Computer
_generate_code_localhost
entry_point_name
computer
aiida.orm
import
Code
plugin_name
=
entry_point_name
remote_computer_exec
=
[
computer
]
return
Code
input_plugin_name=plugin_name
remote_computer_exec=remote_computer_exec
return
optional
executable
physical
executable
machine
ambivalent
local
computers
hand
remote
computers
greatest
idea
other
hand
codes
option
open
performance
cpu/memory
CLI
other
PRs
merging
something
useful
something
beneficial
new
format
suggestion
def
migrate_v3_to_v4
metadata
data
*
args
method
same
subsequent
migration
version
test
classes
others
suggestion
Add
new
empty
list
BaseRestartWorkChain._considered_handlers_extra
name
case
condition
clauses
alternative
shorter
legible
Error
option
result.output
opt
result.output
suggestion
Make
sure
ArchiveMigrationError
out_id
Data
Nodes
process.calculation.
process.workflow.
data.
suggestion
Parameter
values
valid
Python
entry
point
strings
https
//packaging.python.org/specifications/entry-points/
suggestion
Parameter
values
strings
alphanumeric
characters
dashes
underscores
suggestion
Parameter
values
valid
email
address
format
..
note
format
email
address
parts
@
full
stop
segments
characters.
suggestion
Parameter
values
valid
hostname
string
Regex
https
//stackoverflow.com/a/3824105/1069467
PR
Actually
large
comment
class
addition
non-python
kernels
notebook
same
way
processor._
attempts
notebook
error
more
'visit
_sort_operation
Nonetheless
comments
help
string
Could
type
hints
things
Dict
List
typing
package
Optional
[
]
issue
canvas
kind
help
respect
nodes
inputs
first
smile
method
name
intuitive
_sort_operations
_get_sorted_operations
straightforward
intuitive
Please
help
string
AssertionError
FileNotFoundError
message
Invalid
'xyz.ipynb
implies
invalid
format
sorts
file
present
nit
'name
comment
EDIT
required
field
required-ness
fine
comment
suggestion
lowercase
replaces
spaces
underscore
Curious
issue
more
verbose
combined_result.loc
[
,improvements
=
minute
whats
comments
fd
lowest
error
same
above
comment
suggestion
color
case
repeat
n_vals
times
suggestion
assign
color
non-clustered
indices
comment
Add
[
]
https
//media.tenor.com/images/755955f366a1d9a82edae28a107457b3/tenor.png
everything
function
setup
pytest
fixture
suggestion
cries
documentation
possible
param_names
problem.get_reduced_vector
problem.x_names
use
vector
functionality
get_shear_matrid2d
similar
same
padding
something
convert_matrix2d_to_homogeneous
better
option
[
K.normalize_pixel_coordinates
]
https
//kornia.readthedocs.io/en/latest/geometry.conversions.html
kornia.geometry.conversions.normalize_pixel_coordinates
docs
r
values
volumetric
tensor
Implements
Equalize
function
sequence
images
PyTorch
ops
uint8
format
https
//github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py
L352
Args
input
torch.Tensor
image
tensor
shapes
math
C
D
H
W
math
B
C
D
H
W
Returns
torch.Tensor
image
images
same
shape
input.
mronta
aware
https
//github.com/kornia/kornia/issues/321
Tuple
[
torch.Tensor
]
bit
function
someone
JIT
return
type
variable
problem
whole
library
@
shijianjian
Could
torchscript
@
ducha-aiki
norm
sure
sense
@
priba
latest
PR
expected
values
functional
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
variable
'interface
]
https
//www.codacy.com/app/Taurus/taurus/file/4972500113/issues/source
bid=3661446
fileBranchId=4075202
l77
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Try
Except
Pass
detected.
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=850881
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Final
newline
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=572156
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Arguments
number
differs
overridden
method
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=572156
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Arguments
number
differs
overridden
method
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=572156
Path
variable
pattern
middle
enough
JMeter
variable
correct
variable
code
comment
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
variable
'iterations
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=794753
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Consider
enumerate
range
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=794753
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Consider
enumerate
range
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=794753
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Consider
enumerate
range
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=794753
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Consider
enumerate
range
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=794753
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Unnecessary
pass
statement
]
https
//www.codacy.com/app/Taurus/taurus/pullRequest
prid=833613
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Line
]
https
//app.codacy.com/app/Taurus/taurus/pullRequest
prid=1330195
Ah
something
+
symbol.cmeta_id
new
method
something
following
suggestion
example
units
UnitStore
=
units.add_unit
*
1e-6
pA
=
units.add_unit
*
1e-12
=
units.add_unit
*
1e-6
pF
=
units.add_unit
*
1e-12
cm2
=
units.add_unit
*
=
uA_per_cm2
=
units.add_unit
/
cm2
=
units.add_unit
/
cm2
A_per_F
=
units.add_unit
/
farad
Cm
=
units.Quantity
pF
Cs
=
units.Quantity
uF_per_cm2
units.add_conversion_rule
uA
uA_per_cm2
lambda
ureg
rhs
rhs
*
Cs
/
Cm
units.add_conversion_rule
uA_per_cm2
A_per_F
lambda
ureg
rhs
rhs
/
Cs
Test
print
units.convert
units.Quantity
pA
A_per_F
print
units.convert
units.Quantity
uA_per_cm2
A_per_F
long-winded
approach
var_oxmeta
=
simple_ode_model.get_variable_by_name
sv1
var.cmeta_id
==
assert
simple_ode_model.get_display_name
var
ontology=OXMETA
suggestion
.format
error_description
_
'Variant
Items
_
'Attributes
block
data
suggestion
country_codes
US
CA
FR
IE
NL
ES
GB
]
range
case
connection
drop
etc
separate
function
Average
function
size
lines
case
negative
'margin
Are
next
magic-wormhole
release
Similar
comment
wormhole
interaction
separate
function
readability
helper
*
type
node
more
way
introducer
fURL
helper
@
moylop260
_cache
[
]
python
variable
write
sum
variable
subtotal_wo_discount
=
sum
[
'subtotal_wo_discount
]
@
josemoralesp
code
reasons
invoice
ID
accessible
NewId
object
invoice._cache
[
]
groupby='invoice_id
result
lines
belongs
same
invoice
wrong
possible
method
filtered
job
i.e
subtotals
efficiency
filtered
method
good
account
read_group
values
database
invoice
e.g
new
line
value
invoice
good
point
Thanks
read_group
Hello
@
moylop260
same
way
fastest
solution
test
copy
apex
similar
invoice_line
fields
PSQL
desktop
screenshot
]
https
//user-images.githubusercontent.com/5271213/29133486-401b1012-7cf9-11e7-8b6c-8f4ea188664b.png
read_group
odoorpc
[
desktop
screenshot
]
https
//user-images.githubusercontent.com/5271213/29134756-634a8fe6-7cfd-11e7-90d1-0ec6dca849c3.png
case
something
line
=
self.env
[
'account.invoice.line
]
invoice
self
results
line.read_group
[
'invoice_id
'=
invoice.id
]
[
'discount_amount
'subtotal_wo_discount
]
[
'invoice_id
]
invoice.subtotal_wo_discount
=
results
results
]
.get
'subtotal_wo_discount
invoice.discount_amount
=
results
results
]
.get
'discount_amount
important
question
fields
database
read_group
method
useful
fields
database
panda
@
hbto
So
able
method
read_group
library
job
@
field
invoice
model
field
invoice
Did
test
@
luisg123v
Could
TODO
@
josemoralesp
read_group
values
Add
license
TODO
@
moylop260
TODO
Same
comment
index
condition
new
variable
depreciation_date
depreciation_date
=
posted_depreciation_line_ids
posted_depreciation_line_ids
-1
]
.depreciation_date
setdefault
value
exists
object
pointers
value
=
res.setdefault
sm_id
account_id
value
|=
avoid
double
indexed
<
img
width=
alt=
screen
src=
https
//user-images.githubusercontent.com/6644187/29104843-8bd9c018-7c8e-11e7-844c-e69b422418f8.png
>
test
hard
part
reason
added_content
repo
version
content
repo
version
added
content
content
repo
versions
create
repo
version
repo
=
self.create_sync_repo
version_1_content
=
get_content
repo
self.assertIsNone
get_versions
repo
]
[
'base_version
]
create
repo
version
self.client.post
repo
[
'_versions_href
]
'remove_content_units
[
version_1_content
]
[
'_href
]
]
=
self.client.get
repo
[
'_href
]
create
repo
version
version
self.client.post
repo
[
'_versions_href
]
'base_version
get_versions
repo
]
[
'_href
]
=
self.client.get
repo
[
'_href
]
version_3_content
=
get_content
repo
self.assertEqual
version_1_content
version_3_content
ok
as-is
good
brief
explanation
math
magic
numbers
distinction
worker_failover_time
process_timeout_interval
fine
Thank
links
possible
identical
links
option
similar
urls
dis-similar
plugins
pulp3
strings
same
easy
good
string
replacement
only
difference
urls
project
name
single
%
s
replacement
true
reasons
platform
release
name
custom
field
different
projects
python
ostree
future
different
plugins
versioned
different
platform
same
GET
parameters
platform
version
different
fields
url
urls
conf.py
files
different
pulp_rpm
versus
pulp_puppet
different
sphinx
^
extlinks
'redmine
%
s
url
string
conf.py
platform
>
rpm
url
string
pulp_rpm
conf.py
>
ostree
url
string
pulp_rpm
conf.py
>
s/nests/
s/is/
methods
file
docstring
error
linting
files
suggestion
Careful
items
placeholder
suggestion
plugin_type=
CoursePlugin
suggestion
Program
cover
present
line
true
able
course
wink
empty
course_runs
field
common
Good
point
accesslog
configuration
access
logs
error
logs
Docker
documentation
]
]
https
//docs.docker.com/config/containers/logging/
Same
proposal
>
Ensure
first
level
English
pages
suggestion
Every
available
language
present
suggestion
^
resp
beginning
resp
end
pattern
suggestion
Terms
aggregation
n
top
facet
counts
values
suggestion
full
template
path
Value
path
suggestion
Queries
diacritics
insentive
suggestion
Index
diacritics
insensitive
suggestion
Index
diacritics
insensitive
suggestion
Index
diacritics
insensitive
suggestion
Queries
diacritics
insentive
suggestion
Queries
diacritics
insentive
suggestion
Index
diacritics
insensitive
suggestion
course
page
access
anonymous
users
courses
courses
page
view
page
detailed
view
course
suggestion
present
draft
page
draft
markup
comment
point
current
version
docs
https
//www.elastic.co/guide/en/elasticsearch/reference/6.7/analysis-lang-analyzer.html
suggestion
third
condition
filters
public
course
suggestion
fourth
condition
sure
Rephrase
comment
need
sure
multiple
minibatch_size
calculation
MeanMetricWrapper
comment
Add
comment
worker
chance
evaluation
task
training
task
TODO
new
PS
online
non
variables
PS
master
possible
error
messages
Please
comments
exception
standards
cases
communication
Please
comments
inequality
_rendezvous_id
rendezvous_id
master
communication
task
task.
line
TODO
memory
leak
tf.py_function
eager
execution
tf.py_function
graph
mode
comment
Please
add
comments
test
case
result
value
parameter
value
checkpoint
parameter
values
checkpoint
tearDown
afraid
test
fails
operations
comment
Name
constant
cap
EMBEDDING_SIZE_THRESHOLD_FOR_PARTITION
more
comments
steps
First
pull
dense
parameters
PS
node
more
ps
uninitialized
dense
parameter
worker
pod
Pservers
partition
parameters
warning
comment
’
t
necessary
code
pretty
self
explanatory
s
word
function
constructor
comment
reason
comment
docstring
line
Thanks
comment
doc
string
function
online
documentation
more
vt_ratio
script
stuff
documentation
right
thing
Do
example
output
comment
logic
ie
'pivot
ifo
side
others
PyCBC
set
ifos
list
[
[
'H1
]
[
'H1
'L1
]
[
'H1
L1
L1
V1
]
great
numpy
array
explicit
comment
analysis
Hanford
Livingston
principle
GEO+Virgo
result
method
incorrect
workflow
*
*
output
HDF
file
attribute
metadata
detectors
@
dfinstad
second
thought
fine
ns_likelihood
prior
functions
class
methods
sampler
new
class
last
statement
functions
functions
definitions
functions
logposterior
>
loglikelihood
issue
right
equation
get_imr_length
duration
f_lower
/
maxm/2
duration
inline
comment
weighting
sum
step
weighted
ratio
PSDs
frequency
comment
comment
eg
signal
rate
uniform
mchirp
background
rate
propto
mchirp^
-11/3
due
bank
density
indicate
triggers
closer
time-delay
window
slide
step
values
silly
example
H1
V1
detector
pivot
fixed
detector
time-delay
trigger
H1
V1
maximal
errors
GW
line
H1
V1
third
detector
same
location
H1
H2
time
delay
H2
V1
*
negative
*
time
delay
H1
V1
physical
stat
class
comment
need
function
level
import
self.events
step
self.events
'chisq_dof
]
....
chisq_dof
step
self.events
=
self.events
[
]
suggestion
e_copy
=
self.events.copy
commenting
required
format
easier
code
[
]
easier
Delete
lines
constraints
arxiv
number
Berti
al
few
papers
easier
higher
order
modes
day
worth
things
old
way
self.mask.sum
least
%
full
set
please
comment
ie
differences
logic
self.mask
None
case
init
class
results
self.mask
*
*
None
sure
test
self.mask
None
rewrite
comment
'rate
data
number
time
arbitrarily
normalized
number
anything
total
number
threshold
add
comment
following
lines
bunch
unexplained
magic
values
cases
comment
case
templates
bank
f_ref
equal
approximants
different
comment
*
definition
'outlier
float
i
outliers
averaged
value
comment
PEP8
indent
issues
stuff
nice
hard-code
parameters
kwargs
numbers
clear
'benchmark_sigma
singles
information
ifo-dependent
benchmark_sigma
function
template
ifo
way
coinc
method
template
reasonable
workaround
bit
docstring
function
Remove
lines
comment
emcee
kwargs
rid
comment
print
statement
comment
lines
Uncomment
logpost_function
anything
None
cpnest
more
work
error
estimate
float
Add
something
verbosity
level
class
initialization
caps
local
variable
check
checkpoint_file
line
unclear
change
anything
clearer
interior
brackets
things
other
add
comment
time
shift
eg
time
coinc
time1
greater
time2
timeslide_id
*
slide
/
quantity
mean
coinc
time
time1
function
times
mean
times
coincs
cluster_over_time
docstring
'Cluster
events
times
statistic
values
code
point
something
NotImplementedError
able
more
ifos
'todo
>
'subsets
recursion
comment
calculate
iteration
spaces
operators
other
places
i
different
layout
sets
ifos
consistent
comment
next
function
point
trigger
newsnr
duration
rchisq
thresholds
thresholds
rewrite
comment
exact
match
mean
masses
different
triggers
detectors
combinations
coverage
circuit
physical
qubits
=
OneQubitShorsCode
circuit
=
cirq.Circuit
code.apply_gate
cirq.X
*
*
print
cirq.dirac_notation
circuit.final_state_vector
initial_state=0
circuit
+=
cirq.Circuit
code.encode
print
cirq.dirac_notation
circuit.final_state_vector
initial_state=0
create
error
circuit
+=
cirq.Circuit
code.apply_gate
cirq.X
random.randint
code.num_physical_qubits
print
cirq.dirac_notation
circuit.final_state_vector
initial_state=0
correct
error
decode
circuit
+=
cirq.Circuit
code.correct
print
cirq.dirac_notation
circuit.final_state_vector
initial_state=0
Set
summary
line
docstring
inline
Rabi
oscillation
experiment.
Empty
line
Summary
inline
data
future
granular
probabilities
individual
samples
People
e.g
bursts
too-many-1s
good
plot
Summary
line
inline
Circuit.from_ops
Class
redundant
Just
Results
Rabi
oscillation
experiment.
fine
comments
numbers
match
next
clause
<
=
>
=
input
someone
knowledgeable
open
source
licensing
appropriate
test
anything
loop
break
innermost
loop
generator
function
values
string_op
i
right_node
python
best_string_op
best_index
best_node
=
max
extracted_function
key=lambda
e
]
]
nice
module
docs
intent
IIUC
idea
protocols
work
python
builtin
functions
special
__methods__
particular
object
mypy
Protocol
objects
protocols
explicit
implicit
implementation
protocols
single-underscoe
_methods_
python
built-in
special
methods
Just
mark
coverage
ignore
comment
code
nit
private
_expand_unicode_fractions
dead
code
Fine
usage
generic
PermutationGate
other
comment
good
safe
way
formulae
other
comment
Done
_qasm_
qasm
output
code
auto
gate
comment
parallel
operation
Ah
exponent
gates
much
logic
_circuit.py
utility
code
CircuitDiagramInfo
example
rendered_symbols
curiousity
cool
plans
kind
abstract
class
expectations
respect
specific
runs/sweeps
special
case
nit
purpose
cell
makers
obvious
comment
file
warning
correct
r-string
warning
correct
r-string
Nit
Unnecessary
indentation
previous
branches
code
else
branch
method
nothing
gate
operation
error
etc
Add
_assert_not_implemented_vs_unknown
item
method
method
call
_verify_ascending
ClassSmallerThanEverythingElse
item
_verify_ascending
item
ClassLargerThanEverythingElse
use
pytest.raises
TypeError
possible
ways
_Incomparable
method
items
use
_assert
usual
syntax
works
cases
different
methods
different
orders
python
assert
v1
<
v2
assert
v1
<
=
v2
assert
v2
>
v1
assert
v2
>
=
v1
assert
v1
>
v2
assert
v2
>
=
v1
assert
v1
<
v2
assert
v1
<
=
methods
different
code
python
__lt__
/
__le__
/
__ge__
/
__gt__
methods
works
values
correct
thing
returns
NotImplemented
present
correct
implementation
sufficient
incorrect
implementation
A
<
B
<
C
bug
C
>
A.
method
asserts
comparisons
outcomes
correct
behavior
new
helper
method
_assert_not_implemented_vs_unknown
relevant
Add
test
cases
common
mistakes
implement
binary
operators
such
unknown
type
implementing
__ge__
Test
cases
InconsistentWithOthers/AlwaysTrue/AlwaysFalse
/
__ge__
/
__lt__
/
__gt__
__le__
__ge__
returns
returns
true
__lt__
__gt__
return
returns
types
cirq/optimizers/merge_single_qubit_gates_test.py:36
error
object
attribute
optimize_circuit
cirq/optimizers/merge_single_qubit_gates_test.py:37
error
object
attribute
optimize_circuit
@
Strilanc
Depolarization
probability
Pauli
error
probability
equal
approximation
good
large
number
qubits
single-qubit
quantities
different
example
equation
p.11
[
supplement
quantum
supremacy
paper
]
https
//arxiv.org/abs/1910.11333
single-qubit
case
depol_prob
=
sq_pauli_error_prob
nit
let
empty
lines
consistency
Better
issue
reference
place
username
=
>
weird
use
case
c/
different
c/2
+1
sure
behavior
case
something
Nit
equivalent
non-global
phase
zero-qubit
ops
anyways
cirq.circuit_diagram_info
globa_phase
==
Same
comment
above
bugs
circuit
diagrams
'\n\nglobal
phase
'\n\nglobal
phase
untagged
GlobalPhaseOperation
global
phase
TaggedOperation
returns
tagged
global
phase
operations
circuit
work
circuit
global
phase
single
op
Use
pytest.raises
manual
try-except
tests
nit
comment
unnecessary
comment
differs
code
nice
test
cases
own
functions
easier
full
test
easier
pytest
-v
better
parallelization
old
values
operations
same
index
decompose
strategy
decompose
redundant
decompose
unitary
apply
unitary
logic
strategies
_apply_unitary_
look
_unitary_
docstring
changes
behavior
function
Could
problems
future
hard
limit
qubits
Oh
partial_reduce
function
Optional
nit
direct
link
commit
reader
small
copy-paste
dance
Note
specified
concurrency
limit
collector
large
chunk
jobs
next_job
better
backpressure
work
pool
concurrency
work
pool
creation
something
await
pool.ready
pool.include_work
_start_async_job
number
outstanding
work
items
specified
limit
course
case
separate
coroutines
work
pool
send
results
collector
better
single
loop
jobs
self._loop.create_future
loop
idea
anext
test
failures
due
lack
ensure_future
caller
side
Any
type
type
checking
other
way
Could
concrete
types
trial_results
lot
knock-on
effects
type
annotations
effort
nit
comment
list
Clifford
states
type
annotation
single
optional
state
measured
state
comment
comment
consistent
above
feels
strange
ambiguous
grid
qubit
definition
python
treats
ints
underscores
suggestion
code
split
_
parts
int
cast
grid
qubit
part
attempt
line
qubit
other
cases
case
named
qubit
moments
Add
documentation
xy_turn
range
[
-0.5
]
thanks
_signed_mod_1
function
equivalent
abs
xy_turn
close
way
function
single_qubit_matrix_to_phased_x_z
bit
confusing
math.isclose
condition
sub-conditions
block
first
third
sub-conditions
imply
second
condition
controlled_qubits_lists
num_parallel_xy
num_parallel_z
rewrite
fact
empty
list
fact
style
guide
x
x
method
change
categorized_ops
=
collections.defaultdict
list
op
operations
assert
isinstance
ops.GateOperation
ops.ParallelGateOperation
[
GATE_CATEGORIES
[
type
op.gate
]
.append
op
k
[
Z
'XY
]
op.gate
op
categorized_ops
[
k
]
raise
ValueError
Non-identical
simultaneous
gates
.format
k
categorized_ops
'XY
]
num_parallel_z
=
len
categorized_ops
[
Z
]
has_measurement
=
len
categorized_ops
[
'measure
]
controlled_qubits_lists
[
op.qubits
op
categorized_ops
[
]
]
python
GATE_CATEGORIES
=
ops.ZPowGate
Z
ops.XPowGate
'XY
ops.YPowGate
'XY
ops.PhasedXPowGate
'XY
ops.CNotPowGate
ops.CZPowGate
ops.CCXPowGate
ops.CCZPowGate
ops.MeasurementGate
'measure
docstring
method
private
underscore
htype
line
comment
heading
empty
cases
clear
section
Empty
cases
algorithm
much
detail
documentation
algebraic
properties
user
such
fact
wavefunction
form
A
tensor
B
A
pure
state
kept
qubits
B
pure
state
discarded
qubits
test
DO
test
cirq.testing.random_superposition
method
wavefunctions
swaps
factoring
[
]
principle
implementation
python
expressions
None
point
same
reference
caller
ascii-only
test
2-qubit
test
Note
matches
regex
*
*
text
i.e
re.match
'ab
match
[
documentation
]
https
//docs.python.org/3/library/re.html
defense-in-depth
regex
exact
match
re.match
r
[
0-9
]
+
\
0-9
]
+
token_id
way
someone
code
float
token_id
raises
ValueError
check
gates
Clifford
operations
such
cirq.ISWAP
clifford
protocol
decompose_into_clifford
protocol
line
circuit
supported
gates
list
single
operation
Makes
sense
thanks
explanation
test
negative
amplitude
change
value
test
np.abs
amp
*
*
unnecessary
parens
least
bit-strings
character-strings
numpy
integer
python
hog_bitstrings
np.array
[
[
]
]
]
case
useful
integers
ie
idx
set-testing
easier
samples
HOG
set
docstring
comment
case
code
use
program.all_operations
explicit
atol=
tolerance
arguments
Use
yapf
disable
yapf
enable
matrices
entropy
diag
[
]
space
Replace
Use
modulo
addition
symbol
+
Replace
Flag
Use
modulo
addition
symbol
+
space
comment
coverage
tags
Prefer
.format
%
consistent
rest
code
base
type
ignores
cast
call
.x
property
Import
ops
ops.EigenGate
TODO
requirement
requirements.txt
file
Import
ops
values
ops
chance
cyclic
dependency
Import
study
debug
print
Remove
print
line
object
_has_unitary_
_unitary_
_decompose_
returns
empty
list
comment
unitary
True
unitary
same
object
example
case
DummyOperation
qasm_output_test.py
line
Acknowledged
exact
canonicalization
important
relevant
equality
user
front
imports
false
method
gate
instances
variable
necessary
Add
space
Add
Args
documentation
Returns
use
micros
duration
coverage
ignore
docstring
Travis
times
day
device
time
check
sure
API
works
Anyway
job
Cirq
fidelity
XEB
data
estimators
[
fidelity_estimation.py
]
https
//github.com/quantumlib/Cirq/blob/master/cirq/experiments/fidelity_estimation.py
none
requirements
own
able
code
fidelity
estimator
*
disjoint
incompatible
sets
machinery
related
tasks
*
good
reasons
different
estimators
different
circumstances
e.g
estimators
different
variance
subtlety
periodicity
absolute
value
theta
=
pi/4
-pi/4
=
equal
current
code
python
theta
np.pi
/
theta
-np.pi
/
_near_mod_2pi
phi
separate
clauses
sqrt
iswap
inverse
sqrt
iswap
Nit
comment
type
checking
clear
mypy
TYPE_CHECKING
test
public
class
serializable
bad
idea
inspect
getmembers
QASM
Just
pull
request
comments
suggestion
numpy
varies
representation
different
versions
equation
global
shift
Distinguish
linear
algebra
meaning
chemistry
meaning
applicable
function
rotation
angle
radians
theory
team
prefers
functions
Rx
radians
statements
something
op
[
ZPowGate
H
ZPowGate
H
]
args
case
failure
return
False
state.omega
*
return
True
comment
true
comment
assert_equivalent_reprs
multiple
values
possible
cases
e.g
loop
booleans
ton
redundancy
comment
type
annotation
specific
docstring
keys
type
IIUC
error
_any_
tuple
q
something
python
valid_target_sets
self._find_operation_type
set
target
_should_
qubit
device.proto
valid_qubits
q
target
valid_target_sets
q
target
q
valid_qubits
q
operation.qubits
raise
ValueError
follow
issue
IIUC
client
code
contents
generator
sub_cell_cols_generator
composite
cell
places
instantiation
_parse_cols_into_composite_cell
functionality
list
_transform_cells
arguments
new
line
whole
call
Avoid
\
\
measure
q0
q1
message
entanglement
Same
comments
phase
flip
method
Add
Args
documentation
arguments
non-trivial
nit
space
bools
ints
int
union
circuit
+
cirq.measure
comment
comment
wrong
single-qubit
measurements
default
behavior
TypeError
gate
Z
operation
bad
nothing
value
reference
identity
impossible
caller
same
value
[
]
simple
example
value
[
]
mutable-default-value
alarms
singleton
[
]
[
]
common
thing
abs
builtin
np.abs
fallback
Nit
comments
sentences
capitalization
periods
not-equal
cases
code
int
True
test
equality
due
tolerance
higher
due
values
different
grammar
consistent
repr
test
method
not-gated-to-python-3
test
default
behavior
exception
other
protocols
likely
someone
b
print
[
MISTAKEN
CONCLUSION
]
Force
keywords
atol
default
suggestion
Type
[
'cirq.Operation
]
'Classifier
]
local
variable
names
extended
documentation
comments
suggestion
compatible_init_state
=
new_max_weight_state
None
compatible_observable
=
new_max_weight_obs
None
=
compatible_init_state
compatible_observable
suggestion
entire
dict
compatible
group
new
group
comment
rho_i
*
*
sigma_i
rho_i
sigma_i
former
expressions
present
paper
confused
Thanks
comments
paper
rho_i
sigma_i
Tr
[
rho
P_i
]
Tr
[
sigma
P_i
]
resp
rho
and/or
sigma
density
matrices
P_i
Hermitian
operators
case
s
secret
Tr
[
rho
P_i
]
expectation
value
P_i
state
rho
function
cirq
PauliString.expectation_value_from_density_matrix
course
state
actual
quantum
computer
access
density
matrix
sampling-based
estimate
operator
estimation
values
follow-up
PR
function
cirq
master
comment
function
dictionary
tuple
dataclass
components
3-tuple
list
Need
n
helpful
comments
paper
variable
case
more
programmer-friendly
names
n_qubits
n_trials
Nit
space
person
issue
URL
TODO
Sweep
Iterator
[
Params
]
consistent
other
types
example
list
list
single
index
sweep
Iterator
[
resolver.ParamResolver
]
__init__
latter
self.param_tuples
first
arg
@
overload
decorator
types
mypy
single
index
returns
type
slice
Sweep
reference
[
Circuit
]
https
//github.com/quantumlib/Cirq/blob/3bb71d11042543e26d3e6e4d0dc784f03eef4a5d/cirq/circuits/circuit.py
L177
square
brackets
single
items
randomness
circuit
gate
sequence
Hadamard
Measure
random
bit
depolarizing
channel
qubit
unnecessary
parens
familiar
double
comment
convention
code
insidious
trap
Basically
different
data
structure
graphs
various
reasons
natural
track
edges
different
way
dictionary
keys
edges
qubits
cirq.LineQubit
i
cirq.LineQubit
j
edges
i
j
error
GreedyExecutionStrategy
gates
exception
something
error
edges
wrong
clear
clear
problem
code
dictionary
entries
GreedyExecutionStrategy
demo
se
reason
int
case
tuple
pass-through
types
module
level
variable
thoughts
private
function
e.g
_sympy_pass_through
short
docstring
inline
function
nested
functions
global
sentiment
Google
style
guide
least
Avoid
nested
functions
classes
closing
local
value
triple
quote
doc
line
comments
Debug
line
prints
similar
\s
*
add
tests
cases
Sycamore
Sycamore
Gate
Maybe
comment
dict
comprehension
obvious
Case
Case
prefix
comments
useful
document
good
Just
s
note
correct
None
case
value
null
distinct
values
document
good
Just
s
note
comment
clear
mark
migrated
needs
>
apps
migrations
sure
comment
line
same
__init__
thinking
Bypass
validation
view-only
inline
form
form
data
request.POST
form
deleted.
style
guideline
write
comments
'we
>
formset
fine
period
Add
tests
Valid
POST
name.
period
comment
Valid
POST
new
article.
'New
Article
message
comment
enough
separator
blank
lines
redundant
GET
inlines
comment
inline
tests
RuntimeWarning
subclass
exception
due
warnings.simplefilter
runtests.py.
good
comment
effect
warning
points
Paginator
caller
i.e
stacklevel
appropriate
appropriate
something
default_alias
property
TypeError
....
AttributeError
sure
second
sentence
means
hasattr
arg
'default_alias
exception
'default_alias
string
Might
whole
make_interval
cleaner
self.condition
None
return
query
=
Query
model=model
query.add_q
self.condition
compiler
=
query.get_compiler
connection=schema_editor.connection
WhereNode
interest
partial
index
sql
params
=
query.where.as_sql
compiler=compiler
connection=schema_editor.connection
base
schema
editor
same
map
params
it's
outside
class
work
return
WHERE
+
sql
%
tuple
map
schema_editor.quote_value
params
comment
version
support
details
≈4.x
happy
inspect
usage
cute
comment
run
old
version
check
compatibility
import
single
block
main
import
obvious
TODO
support
PY37.
comment
previous
review
@
jdufresne
worth
seq
unused
need
new
ticket
number
assertion
post
response
issue
proper
assertion
Please
wrap
true
uniqueness
validation
checks
new
unsaved
object
Necessary
correct
validation
new
instances
objects
explicit
non-auto
PKs
validation
effect
actual
error
database
>
Comment
date
get_template
>
select_template
comment
personal
pronouns
alfred
part
data
set
separate
self.superuser
consistent
other
tests
=
method
Who
>
supported
interface
fair
mistake
literal
py
allowed_hosts
allowed_hosts
assertPostCondition
better
name
future
test
writers
new
tests
executemany
update
query
Make
sure
nothing
false
condition
WHERE
clause
response
comment
setuptools
<
=
Python
character
coding
comment
python
line
statement
issue
IMO
block
comment
....
Deactivate
translations
something
repetitive
wordy
version
comment
Evaluating
form.changed_data
translations
fields
localization
e.g
date
formats
such
MM/DD/YYYY
vs
DD/MM/YYYY
form.changed_data
alias
Tim
non-docstring
comment
convention
Translations
*
*
*
alias
used
comments
characters
tests
method
test
test
fix
comments
capital
letter
section
[
creation.py
L38-L41
]
https
//github.com/django/django/blob/master/django/db/backends/oracle/creation.py
L38-L41
db
need
below
return
keepdb
return
same
exception
hiding
test
user
creation
https
//github.com/django/django/commit/dacef9137f43fff88b527d1c02f6fe6a81e975aa
separate
PR
concerned
only
situation
_execute_test_db_creation
exception
flag
[
line
]
https
//github.com/django/django/blob/master/django/db/backends/oracle/creation.py
L198
ORA-01543
Tablespace
string
[
Pyrex
]
https
//en.wikipedia.org/wiki/Pyrex_
programming_language
.pyx
unfortunate
name
May
.pyc-tpl
codebase
tests
test
methods
test_db_database_exists
test_access_denied
comments
version
django_engines
engine
engine
engines.all
isinstance
engine
DjangoTemplates
django_engines
raise
ImproperlyConfigured
DjangoTemplates
backend
first
Engine
instance
DjangoTemplates
django_engines
]
.engine
original
Script
.format
py_script
>
%
s
%
py_script
bit
exe_entrypoint
=
py_script.with_suffix
'.exe
exe_entrypoint.exists
sys.executable
return
[
exe_entrypoint
*
[
]
script_entrypoint
=
py_script.with_name
%
s-script.py
%
py_script.name
script_entrypoint.exists
usual
return
[
*
args
script_entrypoint
*
[
]
]
raise
RuntimeError
%
s
%
py_script
>
better
someval
nullable
column
comment
Fail
arg
iterable.
Render
template
substitutions
context
tests.
sure
comment
first
query
SELECT
queries_note
id
queries_note
note
queries_note
misc
queries_note
tag_id
queries_note
WHERE
NOT
queries_note
tag_id
IN
SELECT
U2
tag_id
queries_annotation
U2
WHERE
U2
name
queries_note
note
queries_note
tag_id
NOT
NULL
ORDER
BY
queries_note
note
ASC
second
SELECT
queries_note
id
queries_note
note
queries_note
misc
queries_note
tag_id
queries_note
INNER
JOIN
queries_tag
ON
queries_note
tag_id
queries_tag
id
INNER
JOIN
queries_annotation
ON
queries_tag
id
queries_annotation
tag_id
INNER
JOIN
queries_annotation
T4
ON
queries_tag
id
=
T4
tag_id
WHERE
queries_annotation
name
AND
T4
name
NOT
queries_note
tag_id
IN
SELECT
U2
tag_id
queries_annotation
U2
WHERE
U2
name
queries_note
note
queries_note
tag_id
NOT
NULL
ORDER
BY
queries_note
note
ASC
multi-table
inheritance
MTI
acronym
failing
test
instance
test
regression
comment
block
code
useful
circumstances
self-evident
brief
comment
structure
python
fields
fields_for_model
opts.fields
opts.exclude
opts.widgets
formfield_callback
opts.localized_fields
opts.labels
opts.help_texts
opts.error_messages
opts.field_classes
limit_choices_to
ModelForm.__init__
method
name
clear
sure
comment
py
base_action_names
name
_
name
_
filter
None
base_actions
readable
base_actions
list
3-tuple
second
element
name
other
Minor
point
couple
blank
lines
docstrings
sure
Avoid
use
comments
[
style
guide
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
Use
getattr
field.model._meta
None
exception
model
concrete_model
previous
comment
incorrect
grouping
Django
condition
target_last_modified.replace
microsecond=0
=
source_last_modified.replace
microsecond=0
self.symlink
full_path
full_path
full_path
B
B
C
correct
grouping
comment
logic
tests
incorrect
groupings
thanks
explanation
new
Index
property
special
treatment
BrinIndex
universal
solution
i.e
sth
@
property
def
max_name_length
return
connection.ops.max_name_length
idea
length
indexes
different
databases
third-party
app
author
PostgreSQL
example
index
names
app
usable
Oracle
indexes
contrib.postgres
limit
usable
PostgreSQL
value
non-ASCII
chars
force_bytes
s
encoding=SYSTEM_ENCODING
bare
str
Windows
expert
similar
handling
data
localization
tools
_
other
alternative
analysis
migration
files
FWIW
set
literals
better
easier
cases
set
many
element
set
[
]
boilerplate
accounts
length
whole
statement
migration
files
auto
code
syntax
errors
discussion
form
isort
migration
files
sake
migration
files
auto-generated
Furthermore
lines
migration
files
lines
way
characters
lines
other
tool
Users
migration
files
IMO
projects
migrations
more
auto-generated
code
True
many
auto-generated
code
schema
tweaks
data
migrations
plenty
code
reason
projects
success
migrations
directories
flake8
runs
>
precedent
migration
files
runs
flake8
See
exclude
rule
migrations
]
https
//github.com/django/django/blob/master/setup.cfg
L6
reason
change
flake8
set
literals
something
regards
migrations
*
Change
migrations
literals
PR
Ignore
migrations
flake8
alternative
merit
flake8
migration
files
code
Due
other
reasons
addition
flake8-comprensions
time
need
change
agreement
PR
goal
pattern
set
<
generator
expression
>
set
comprehension
pattern
creeps
time
regular
maintenance
preferred
comprehension
syntax
time
problem
@
possibility
static
analysis
tool
[
flake8-comprehensions
]
https
//pypi.python.org/pypi/flake8-comprehensions/1.2.1
patterns
snag
tool
migration
files
suboptimal
syntax
set
[
]
literals
goal
change
SetSerializer
friendlier
static
analysis
change
nice
literals
verbose
less
brackets/parenthesis
Josh
concern
strong
opinions
precedent
migration
files
particular
line
code
_slightly_
harder
second
line
comment
_I_
benefit
¢
general
specific
case
issues
branch
noisier
syntax
codegen
path
nicer
output
likely
messier
input
objections
code
look
worse
particular
case
tangible
benefit
migration
files
auto
code
syntax
errors
usage
set
literals
likely
syntax
errors
consolidate
bit
file1.seek
response
=
self.client.post
file1
self.assertEqual
response.status_code
PY37
TODO
PY37
least
search
biggie
nice
blank
line
comment
regex
verification
reference
IMO
note
ticket
]
https
//code.djangoproject.com/ticket/18867
open
PR
PyYAML
more
appropriate
tuple
faster
worth
own
test-case
ref
similar
tests
ln70
chop
chop
trailing
duplicated
code
MySQL
backend
need
refactoring
right
PR
suggestion
details
please
refer
documentation
following
link
https
//www.bk.admin.ch/bk/de/home/dokumentation/sprachen/hilfsmittel-textredaktion/schreibweisungen.html
database
Please
use
periods
Add
support
SameSite
attribute
obsolete
PY37
unsupported
link
PR
comment
much
value
something
assertions
self.assertEqual
c
[
]
[
'samesite
]
'lax
self.assertIn
c.output
single
line
tricky
comment
error_list
contains
ValidationError
instances
sortable
key
extra
check
message
other
'message
ValidationError
[
'error
]
ValidationError
'error
Chop
unnecessary
blank
lines
Use
hash
__hash__
e.g
suggestion
self.assertNotEqual
hash
exception_str
hash
exception_list
Similar
simpler
dictionary
comment
fells
overkill
logic
simple
test
HTTP_X_CUSTOM_HEADER_2
loop
subTest
separate
methods
example
https
//github.com/django/django/blob/f021c110d02fd7ca32ae56f511b46e5d138b6c73/tests/utils_tests/test_http.py
L156-L158
comment
worth
additional
complexity
sure
comment
few
teaks
QuerySet
Manager.
Wrap
comments
characters
Klass
model
data
json.loads
checks.urls
isort
imports
other
_actual
imports_
alphabetical
PostgreSQL
environment
variables.
comprehension
single
line
much
value
comment
=
Decimal
=
DecimalValidator
val
x
throws
int
x
comments
chars
code
explicit
comment
comment
correct
comment
unnecessary
final
review
Please
wrap
comment
chars
i.e
MySQL
VARCHAR
characters
more
max
length
AuthenticationForm
default
user
model
Backticks
unnecessary
IMO
Populate
fields
SEARCH_VAR
variable
database
limit
number
query
parameters.
ModelState.fields
dict
suggestion
prev_state_base_model
curr_state_base_model
removed_base_fields
prev_state_base_model.fields
.difference
curr_state_base_model.fields
.intersection
model_state.fields
field
name
scenario
problematic
MTI
field
collision
None
case
match
appropriate
below
expression
suggestion
prev_state_base_model
=
self.from_state.models.get
base_app_label
base_name
curr_state_base_model
=
self.to_state.models.get
base_app_label
base_name
_
Ensure
last
element
field
transform
_
thinking
Avoid
comments
options
shallow-copied
operations
such
AddIndex
option
e.g
'indexes
None
Empty
Empty
Blank
semantic
empty
string
supports_explaining_query_execution
None
[
style
guide
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
TRADITIONAl
→
TRADITIONAL
shift
early
Add
TEXT
alias
TRADITIONAL
consistency
other
backends.
python
try
import
MySQLdb
ImportError
pass
warnings.filterwarnings
non-boolean
value
isnull
lookup
True
False
stacklevel
comment
easier
Django
e.g
isinstance
self.rhs
bool
deprecation
ValueError
QuerySet
value
isnull
lookup
True
warnings.warn
non-boolean
value
isnull
lookup
True
False
RemovedInDjango40Warning
sure
preferable
reason
add_index
field
model
diff
diff
git
a/tests/schema/tests.py
b/tests/schema/tests.py
index
..
d80d98380a
a/tests/schema/tests.py
+++
b/tests/schema/tests.py
@
@
-292,7
+292,11
@
@
class
SchemaTests
TransactionTestCase
'can_create_inline_fk
'allows_multiple_constraints_on_same_fields
@
isolate_apps
'schema
def
test_add_inline_fk_index_update_data
+
class
Node
Model
+
class
Meta
+
app_label
=
connection.schema_editor
editor
editor.create_model
Node
Add
inline
foreign
key
update
data
index
@
@
-302,17
+306,9
@
@
class
SchemaTests
TransactionTestCase
parent
=
Node.objects.create
connection.schema_editor
editor
editor.add_field
Node
new_field
Node._meta.add_field
editor.execute
'UPDATE
schema_node
SET
%
s
[
]
editor.execute
editor.sql_create_index
%
'table
editor.quote_name
Node._meta.db_table
'name
editor.quote_name
'new_parent_inline_fk_idx
editor.quote_name
'new_parent_fk_id
'condition
editor.add_index
Node
Index
fields=
[
'new_parent_fk
]
self.assertIn
self.get_indexes
Node._meta.db_table
skipUnlessDBFeature
'supports_foreign_keys
Docstring
trailing
space
sentences
period
lines
possible
databases
empty
list
tests
database
check
hacky
previous
day
TO_CHAR
%
'D
%
field_name
Sphinx
enough
Workaround
word
dash
Added
Better
docstring
cleaner
triple
string
SQL
whitespace
sensitive
try/except
case
failure
difficult
traceback
allow_relation
worried
routers
failures
systems
Django
digging
create_permissions
ContentType
objects
default
database
alias
db_manager
'other
router
related
objects
'other
database
relation
check
different
databases
proper
fix
create_permissions
function
routers
Short
least
invasive
solution
other
systems
wild
hidden
bug
fix
Warp
comments
docstrings
characters
change
necessary
most
cases
assertTrue
passes
bool
value
LIMIT/OFFSET
clause
Avoid
use
comments
[
style
guide
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
compare
columns
python
old_field.column
=
new_field.column
db_column
kwargs
e.g
def
_
old_path
old_args
old_kwargs
=
old_field.deconstruct
_
new_path
new_kwargs
=
new_field.deconstruct
Ignore
db_column
db_column
it's
same
field
name
old_kwargs.pop
None
new_kwargs.pop
None
field
name
return
old_field.column
=
new_field.column
old_path
old_args
=
new_path
__icontains
ArrayField
inefficient.
obj
=
sure
rest
test
necessary
usage
worth
assertion
way
test
Book
DerivedBook
Might
bit
simpler
mixin
share
BrinIndex
repetitive
comment
Done
comment
older
version
patch
recent
alias
table
many-to-many
relation
multiple
times
try
docstring
guidelines
expected
behavior
nice
comment
use
wrap
comments
characters
_should_delete_form
self.can_delete
comment
sense
validation
form
👍
cleaned_data
_we_
dot
MAX_GET_RESULTS
=
code
comments
maximum
number
less
max
precise
results
>
maximum
number
results
clone.query.set_limits
high=MAX_GET_RESULTS
+
>
clone.query.set_limits
high=MAX_GET_RESULTS
num
<
=
MAX_GET_RESULTS
>
num
<
MAX_GET_RESULTS
temporary
variable
split
loop
python
part
field.split
LOOKUP_SEP
asgi
async
reserved
word
asgi
sort
misleading
synchronous
environments
isinstance
value
str
empty
string
strings
scheme
more
explicit
value
//
value
ValidationError
self.message
code=self.code
backwards
compatibility
Django
get_FOO_display
method
class
methods
inheritance
inherited
choices
complex
inheritance
users
contribute_to_class
Single
quotes
comment
behavior
cpython
shell
error
PYTHONSTARTUP
exception
items
dependencies
part
graph
first
topological_sort_as_sets
function
comment
clearer
sure
comment
accurate
rewriting
point
PRAGMA
index_list
additional
information
inline
constraints
caioariede
Can
comments
temporary
variables
[
proposition
]
https
//github.com/django/django/pull/11413/files
r287684740
fault
earlier
version
colorama.init
module
level
everyone
good
placing
>
use
color_style
Makes
sense
sure
sense
registry
guarantee
terminal
blanket
better
ctypes
approach
actual
terminal
use
I'd
assertNotIn
sql
method
name
self
current
docstring
much
value
record_migration
s
lines
docstring
class-level
Python
scalars
isinstance
value
list
tuple
query_val
=
[
item
isinstance
item
bytes
str
item
item
value
]
query_val
value
comment
language
cookie.
pk
last
suggested
comment
Force
newlines
POT
files
https
Please
use
single
quotes
Set
attr
property
defined.
thinking
more
options
Oracle
co
set
supported
options
cases
single
feature
e.g
python
supported_geojson_options
'bbox
'crs
'precision
hook
similar
_field_should_be_indexed
3rd-party
backend
behavior
e.g
def
field
name
return
old_field.column
=
new_field.column
old_field.deconstruct
]
=
new_field.deconstruct
]
name
same
much
value
check
responsibility
Select2
documentation
days
deep
links
new
location
link
https
//select2.org/configuration/data-attributes
nested-subkey-options
von
@
apollo13
comment
SHA
database
functions.
change
branch
unnecessary
IndexError
Specify
unicode
DSN.
Maybe
better
>
conn_params
conn_params
something
user_params
kwargs
name
Sorry
back
forth
simple
patch
obvious
comment
more
important
Client
encoding
OPTIONS
get_total_ordering
method
sure
other
way
calls
more
sense
get_queryset
chain
new
ticket
feature
continue
work
PR
single
line
fields
]
multiline
previous
comment
comment
order
people
self.tokens
=
[
:-1
]
much
difference
new
empty
instance
related
model
proper
solution
set_cached_value
available
e.g
def
local_setter
from_obj
from_obj
f.remote_field.set_cached_value
from_obj
Dot
source
expression
>
source
expression
expression
WHERE-clause
blank
lines
attributes
comments
expression
WHERE-clause.
bit
doubt
backend
specific
test
salary
Oracle-specific
test
scenario
null/the
empty
string
remark
documentation
fact
correct
convert_value
comment
round
Oracle
😉
test
integer-field
name
empty
string/null
remark
empty
strings/null
nth_value
documentation
build
commit
lead
lag
default
null
constructor
Shallow
copy
i.e
self.non_field_errors
IMO
ErrorList
subclass
UserList
def
copy
copy
super
copy.error_class
=
self.error_class
return
copy
link
cached
property
check
schema.py
e.g
@
cached_property
def
_support_default_on_limited_data_type
return
self.connection.mysql_is_mariadb
self.connection.mysql_version
>
i.e
self.connection.mysql_version
>
=
return
True
return
self._is_limited_data_type
field
link
columns
list
comment
trouble
alternative
Hahaha
comment
regex
similar
standard
sure
instance
legal
parts
standard
duration
postgres
interval
maximum
number
days
h
m
s.ms
section
comment
format
test
failure
FAIL
test_order_raises_on_non_selected_column
queries.test_qs_combinators.QuerySetSetOperationTests
set
boolean
something
return
clean_lookups.isdisjoint
valid_lookups
shorter
lines
readability
clean_lookups
LOOKUP_SEP.join
relation_parts
LOOKUP_SEP.join
relation_parts
[
part
]
Make
sure
trouble
comment
logic
naming
clean_lookups
valid_lookups
relation_parts
part
intuitive
_should_
verbiage
tests
e.g
Closing
file_to_stream
FileResponse.close
file-like
object
close
method
sure
valuable
comment
Grab
>
Use
tests
change
test
better
comment
and/or
block
case
*
__eq__
*
complete
match
block
search
easy
tests
failure
diff
diff
diff
git
a/django/test/html.py
b/django/test/html.py
index
a/django/test/html.py
+++
b/django/test/html.py
@
@
-86,7
+86,6
@
@
class
Element
self.children
element.children
return
i
elem_child_idx
child
self.children
child
text
content
element
text
content
simple
text
text
@
-100,16
+99,10
@
@
class
Element
Look
complete
sequence
element
children
Refs
isinstance
element
RootElement
elem_child
=
element.children
[
]
+
=
]
start
match
elem_child
child
elem_child_idx
complete
match
elem_child_idx
==
len
element.children
i
elem_child_idx
elem_child_idx
+
i
i
+=
child._count
element
count=count
count
i
return
c.f
_
Better
comments
comment
opaque
fresh
reader
Might
attribute
lookup
prepare_value
=
super
return
[
prepare_value
v
v
value
]
current_year
assumed_year
contains
current_century
hence
implementation
e.g
readable
current_year
=
datetime.datetime.utcnow
current_century
=
current_year
%
year
current_year
%
year
more
years
future
past
year
+=
current_century
year
+=
current_century
RFC
docstring
comment
Cache
namedtuple
@
lru_cache
slow
QuerySet
evaluation
Silence
Truncated
incorrect
CHAR
value
Reasonable
test
SQL
deferred
SQL
DB
parameters
tests
something
IMO
round
e.g
Round
result
distance
PostgreSQL
uses
greater
precision
transform=lambda
instance
instance.field
round
instance.distance
Person
Political
e.g
test_create_new_instance_with_pk_equals_none
c1
=
Congressman.objects.create
state='PA
title='senator
=
Person.objects.get
pk=c1.pk
.congressman
Create
new
congressman
pk
=
None
c2.pk
=
None
c2.name
=
c2.title
=
c2.save
self.assertEqual
Congressman.objects.count
self.assertEqual
Person.objects.get
pk=c1.pk
.name
'John
self.assertEqual
Politician.objects.get
pk=c1.politician_ptr_id
.title
Support
ATan2
SpatiaLite
tests
======================================================================
FAIL
test_decimal
db_functions.math.test_atan2.ATan2Tests
Traceback
recent
call
last
File
/usr/lib/python3.6/unittest/case.py
line
testPartExecutor
yield
File
/usr/lib/python3.6/unittest/case.py
line
testMethod
/home/nick/Sources/django/tests/db_functions/math/test_atan2.py
line
test_decimal
self.assertAlmostEqual
obj.n_atan2
Decimal
math.atan2
/usr/lib/python3.6/unittest/case.py
line
assertAlmostEqual
raise
self.failureException
msg
AssertionError
Decimal
=
Decimal
'-1.135829375749316749732997777755372226238250732421875
places
======================================================================
FAIL
test_float
db_functions.math.test_atan2.ATan2Tests
Traceback
recent
call
last
File
/usr/lib/python3.6/unittest/case.py
line
testPartExecutor
yield
File
/usr/lib/python3.6/unittest/case.py
line
testMethod
/home/nick/Sources/django/tests/db_functions/math/test_atan2.py
line
test_float
self.assertAlmostEqual
/usr/lib/python3.6/unittest/case.py
line
assertAlmostEqual
raise
self.failureException
msg
AssertionError
=
-1.5575970933707572
places
order
arguments
similar
issue
Log
float
test
passes
integer
test
passes
inputs
floats
following
method
needs
def
as_sqlite
compiler
connection
connection.ops
'spatialite
False
return
self.as_sql
compiler
connection
connection.ops.spatial_version
<
return
self.as_sql
compiler
connection
function
ATan2
x
inverse
tangent
y
/
x
other
backends
function
ATan2
x
y
addition
integer
inputs
need
floats
spatialite
backend
inherits
sqlite3
backend
spatialite
function
precedence
create_function
clone
=
self.copy
clone.set_source_expressions
[
Cast
expression
FloatField
isinstance
FloatField
expression
expression
self.get_source_expressions
[
:-1
]
]
return
clone.as_sql
compiler
connection
previous
comment
change
[
comment:9
]
https
//code.djangoproject.com/ticket/28643
comment:9
function
Ceil
more
Pythonic
math.ceil
function
change
lookup_name
Sorry
connection.ops
'spatialite
False
connection.ops.spatial_version
<
return
self.as_sql
compiler
connection
Chop
blank
line
wording
django_migrations
table
present
migrations.
place
dict
params
SQL
injections
suggestion
self.query.order_by
order_by_sql
=
[
]
[
]
_
sql
params
is_ref
self.get_order_by
order_by_sql.append
sql
order_by_params.extend
params
+=
BY
+
order_by_sql
+=
tuple
Comments
state
behavior
omit
prefixes
Ensure
Test
tests
things
guideline
[
Python
style
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
default
constant
field
reference
e.g
F
'integer
My
instinct
sub_
prefix
names
sub_params
name
other
code
subquery
>
left-hand
Does
Explicit
value
values
'id
i
comment
comment
self.opclasses
same
length
self.columns
Index
class
comment
list
Hello
@
timgraham
Could
advice
special
attribute
class
class
name
Thanks
query
limit
distinct
operations
comment
chars
s
end
support
redundant
suggestion
MariaDB
>
=
MySQL
>
support
comment
Clear
foreign
keys.
part
stale
true
super
sure
comment
functools.partial
work
python
functools
import
partial
bound_method
=
partial
method.__get__
type
real
docstring
way
tests
file
comments
docstring
lines
separate
commit
other
methods
line
economy
proper
line
overhead
simple
comments
docstrings
AFAIK
semantic
difference
spaces
commas
new_field.unique
sufficient
optimization
loop
suggestion
new_field.unique
old_type
=
new_type
getattr
necessary
round
trip
val
None
val
=
data
[
field_name
]
data
[
field_name
]
=
val
line
]
https
//github.com/django/django/pull/13036/files
diff-1e7fc0d7d1b36358e371fab97bd1ddb1R152
thinking
sure
links
comment
thinking
ticket
Please
comments
assertions
something
something
easier
GROUP
BY
HAVING
expressions
expressions
tables
primary
key
grouped
columns
better
comments
code
comment
less
wordy
something
main
model
primary
key
query
new_expressions
field
group
HAVING
expressions
expressions
way
meaning
new_expressions
thing
Django
comment
date
original
commit
comment
pk_field
variable
comment
clarification
sure
specialized
fields
means
str
value
setUp
python
translation.override
language
activate
Write
comments
Patch
select
tests
Store
message.
python
self.output_transaction
=
migration.atomic
getattr
connection
True
try-except
little
tighter
[
k
]
=
converters
k
]
.to_url
v
extra
moving
parts
nested
loop
comment
withouts
consistent
style
suggestion
json.dumps
json.loads
custom
decoder
JSONField.from_db_value
sure
best
approach
assertion
reporter_id
assignment
save
self.assertEqual
self.a.reporter
self.r2
comment
little
bit
explicit
Django
general
style
changes
code
case
enough
tests
change
undone
defaults
utf-8
change
chance
regression
default
file
only
possible
file
optimization
connections
db
]
.features.supports_foreign_keys
self.target_field.null
count
test
way
optimization
doable
sure
filters
%
s__isnull
%
self.target_field_name
]
=
False
manager
filters
useless
comment
merge
Oracle
parameters
query
better
max_query_params
comment
same
suggested
comment
bulk_create
docstring
simpler
efficient
empty
querysets
self
other_qs
qs
]
.self._combinator_query
'union
[
]
all=all
accounting
case
qs
elements
nonempty
querysets
use
q
comprehension
variable
alternative
_combinator_query
'union
stuff
qs
return
qs
self
other_qs
=
qs
]
qs
]
love
current
version
least
change
qs
qs
need
length
descriptive
variable
names
e.g
nonempty_qs_index
nonempty_qs
=
Please
ticket
numbers
tests
script_with_inline_function
[
comment
]
https
//code.djangoproject.com/ticket/31275
comment:10
same
effect
heuristics
def
sql_flush
style
tables
sequences
tables
return
sql
=
[
FOREIGN_KEY_CHECKS
]
tables
tables
faster
tables
sequence
reset
ALTER
TABLE
AUTO_INCREMENT
slower
TRUNCATE
sql.extend
%
s
%
s
%
style.SQL_KEYWORD
self.quote_name
table_name
table_name
tables.intersection
sequences
Otherwise
issue
simple
DELETE
faster
TRUNCATE
preserves
sequences
sql.extend
%
s
%
s
%
s
%
style.SQL_KEYWORD
'DELETE
'FROM
self.quote_name
table_name
table_name
tables.difference
sequences
sql.append
'SET
FOREIGN_KEY_CHECKS
=
sql
sequence_reset_by_name_sql
addition
sql_flush
necessary
TransactionTestCase.reset_sequence
feature
sure
comment
much
value
Please
explanatory
comment
similar
other
methods
unchecked
>
unselected
comments
chars
to_python
current
backticked
version
meant
readability
boolean
constants
readability
settings
alternate
behavior
comment
foreign
key
constraints
open
transaction
similar
—
Dark
Arts
signposts
future
handy
🙂
brief
comment
problems
standard
reverse
function
>
comment
fits
line
maximum
>
max
Please
wrap
chars
Use
utc
=
datetime.timezone.utc
Python
accurate
statements
comment
similar
other
comments
method
comment
skipUnless
supports_foreign_keys
feature
comment
Foreign
key
support
SQLite
point
https
//code.djangoproject.com/ticket/14204
feature
https
//github.com/django/django/pull/8118
issuecomment-284325682
test
pg-specific
bunch
boolean
logic
forgive
wrong
_is_terminal
value
system
check
error
non-string
*
values
patch
document
=
MyDocument
myfile='test_file.py
self.assertEqual
document.myfile.field.model
MyDocument
new
models
test
e.g
@
isolate_apps
'model_fields
def
test_abstract_filefield_model
class
AbstractMyDocument
models.Model
myfile
=
models.FileField
upload_to='unused
unique=True
class
Meta
abstract
=
True
class
MyDocument
AbstractMyDocument
pass
document
=
MyDocument
myfile='test_file.py
self.assertEqual
document.myfile.field.model
MyDocument
null=True
County
new
model
new
models
possible
tests
suggestion
Windows
registry
correct
mimetypes
suggestion
sys.platform
==
key
==
b'Content-Type
good
idea
comments
translators
https
//docs.djangoproject.com/en/2.0/topics/i18n/translation/
comments-for-translators
hints
literal
literal
own
line
suggestion
args
parameter
path-like
Windows
Python
first
subprocess.run
parameter
[
]
https
//docs.python.org/3/library/subprocess.html
subprocess.run
meta.parents
context_manager
transaction.mark_for_rollback_on_error
context_manager
transaction.atomic
using=using
b
alternative
def
check_field
field
*
*
kwargs
errors
[
]
hasattr
Ignore
related
fields
getattr
field
'remote_field
None
Ignore
fields
unsupported
features
getattr
self.connection.features
feature
False
feature
field.model._meta.required_db_features
field_type
=
field.db_type
self.connection
Ignore
non-concrete
fields
field_type
None
errors.extend
self.check_field_type
field
field_type
errors
strong
opinion
approach
comments
Backends
check_field_type
method
hasattr
Ignore
related
fields
getattr
field
'remote_field
None
same
errors
[
]
return
errors
approach
similar
methods
use
Please
wrap
comment
chars
Alternative
import
operator
functools
import
def
all_valid
formsets
return
operator.and_
f.is_valid
f
formsets
True
reason
work
fine
generators
list
comprehensions
str.join
list
self.subTest
namedtuple
self.script_name_test_cases
variable
python
tests
SCRIPT_NAME
slash
settings
slashes
'/static/
'/somesubpath/static/
'/media/
'/somesubpath/media/
SCRIPT_NAME
slash
settings
slashes
'static/
'/somesubpath/static/
'media/
'/somesubpath/media/
script_name
initial_static_url
final_static_url
initial_media_url
final_media_url
tests
self.subTest
namedtuple
encapsulation
type
value
*
values
anything
top
module
later
suggestion
]
character
sure
branch
objects
wow
surprised
total_bill
name
mention
monkey
IDs
[
Path
Node
]
NodeToPath
visible
hoverlabels
nice
Path/To/Node
IMO
def
lambda_discrete
x
_
backwards
right
[
id
=
[
path
[
j
]
]
.copy
.astype
str
/
+
df_tree
[
id
]
reason
correct
order
comment
Python
NullHandler
comment
line
expected
exception
*
code
dep_classes
list
tuple
TODO
text
something
end
TODO
text
check
begin
order
promise
KeyError
non-existing
classes
classes
invalid
equal
First
time
return
vs
output
parameters
variable
name
rtn_params
closer
look
code
different
name
variable
eg
out_param_list
word
means
context
https
//travis-ci.org/github/zalando/patroni/jobs/717510167
L1347
patroni/dcs/__init__.py:503:121
E501
line
characters
nest
self.has_lock
data
directory
empty
self.state_handler.data_directory_empty
return
self.bootstrap
new
node
data
directory
empty
self.state_handler.data_directory_empty
instance
leader
self.has_lock
return
leader
key
data
dir
empty
leader'
return
self.bootstrap
new
node
block
line
double
call
self.state_handler.data_directory_empty
Everything
good
version
null
value
key
ConfigMap
wrong
postgres
pg_rewind
pg_rewind
new
version
postgres
successful
pg_rewind
suggestion
Do
HA
loop
leader
leader
object
update
event
combination
dataset
video
columns
something
clearer
names
indices
IMO
Docstring
init
future
nice
able
fly
computed
embeddings
load
librosa
least
anything
fancy
loading
other
lines
code
output_layer
N,8,298,257
N,8
*
time
freq
axis
Row
column
major
wrong
mistake
print
statements
useful
metrics
invariant
case
good
reason
normalization
sf.write
yeah
right
Remove
suggestion
DEFAULT_TIMEOUT
=
seconds
different
pattern
bad
Add
comment
first
instance
from_str
Hi
@
hunt3rkillerz
thanks
PR
reasonable
string
metadata
heavy
string
parsing
E.g
cwe
self.metadata
yield
self.metadata
[
'cwe
]
owasp
self.metadata
yield
f
OWASP-
self.metadata
[
'owasp
]
Note
OWASP
convention
CWE
javascript/lang/security/audit/path-traversal/path-join-resolve-traversal.yaml
owasp
'A5
Broken
Access
Control'
cwe
'CWE-22
Improper
Limitation
Pathname
Directory
Path
Traversal
javascript/lang/security/audit/non-constant-sql-query.yaml
owasp
'A1
Injection'
cwe
CWE-89
Improper
Neutralization
Special
Elements
SQL
Command
Injection
javascript/lang/security/audit/unknown-value-with-script-tag.yaml
owasp
'A7
Cross-site
Scripting
XSS
cwe
CWE-79
Improper
Neutralization
Input
Web
Page
Generation
'Cross-site
Scripting
sort
semgrep-core
side
order
Sorry
note
comment
function
name
safe
comment
point
good
yaml
wrong
DRF
stubs
Fine
type
ignore
summary
comments
numbers/sectioning
implies
checks
steps/sections
more
pain
new
section
previous
numbers
available
Thanks
easier
solution
filtering
Prefetch
line
Prefetch
queryset=Action.objects.filter
deleted=False
.order_by
]
wrong
comment
calculate
event
volume
least
usage
count
Agreed
test
category
param
Do
variations
libraries
worth
comments
sure
best
approach
users
app
Maybe
distinct
ID
previous
comment
end-users
persons
persons
event
period
reason
_gen_lateral_bodies
good
comment
sure
intent
case
dashboard_do_not_cache
Might
easier
module
same
try/except
pattern
case
someone
DEBUG
live
single
comment
same
thing
range
near
%
range
BTW
%
acceptable
values
=
>
acceptable
Please
setUp
wx.App
rest
function
something
_prepare_streams
fluo_res
sem_res
function
streams
.streams
more
changes
original
test
cases
comment
comment
correct
comment
add
comment
_checkReference
Please
string
ints
easier
[
sum
iterator
.items
.keys
duplication
targets
BTW
axes
case
sum
max
love
int
wfm
stands
accurate
value
code
stepsize
encoder
counts
>
motor
counts
hardware
value
EEPROM
case
closed
loop
control
encoder
counts
conversion
other
hand
open
loop
control
amount
steps
approximate
approximate
stepsize
good
lot
trouble
parameter
yaml
file
mistakes
other
instances
easier
axis
name
e.g
doMoveRel
other
attributes
axis
name
number
easier
consistent
way
accuracy
high
likely
nm
other
reason
move
eg
error
doc
clear
way
U0
good
start
targetMode
targetLimit
running
status
possibility
Y23
Most
likely
only
way
sure
Please
commands
dedicated
function
easier
command
current
axis
number
new
address
generic
setParam
axis
param
value
status
hardware
U0
least
move
move
timeout
moveToIndex
reference
procedure
several
seconds
TODO
update
encoder
stepsize
few
wfm
steps
count
divide
yaml
file
stepsizes
same
encoder
same
type
bit
model
first
hardware
power
sure
small
limit
µm
bit
ascii
timeout
crude
addition
s
short
long
moves
closed
loop
better
use
tmcm
driver
distance
speed
axis
rough
estimation
long
axis
longest
time
confusing
steps
argument
integer
precision
other
hand
conversion
time
sure
best
way
.position
VA
least
move
.referenced
VA
least
empty
nice
logging.info
message
connection
sonic
stage
driver
int
resp
update
docstring
Integration
count
TODO
Please
comment
explain
parameters
Erics
old
code
converter=list
special
case
Please
==
comparison
md_key
Most
likely
same
string/constant/object
case
code
instance
case
string
model.MD_
set_metadata
write_metadata
metadata
word
previous
function
Please
-D
get_status
confusing
name
append_value
append_metadata
prepare_
least
get_
value
status
close
state
current
default
behaviour
True
means
empty
string
False
default
value
default=
callers
default=0
other
values
BTW
docstring
clarity
integrationCounts
more
document
_what_
integrationTime
Pick
integrationTime
stream
optical
case
ebeam
pos
short
acquisition
integration
time
comment
line
docstring
canvas
comment
positions
view
coordinates
drag
asserts
moment
movements
stops
target
position
pop
trick
key
dict
pop
model.MD_WL_LIST
self._metadata.keys
part
write
del
self._metadata
[
model.MD_WL_LIST
]
BTW
key
dict
key
dict.keys
event
type
rest
content
ev
different
event
type
state
meaning
type
progress
event
something
ev
=
self.WaitForEvent
t
TimeOut/CancelledError
SA_PS_AF_ADJUSTMENT_PROGRESS_EVENT
lowest
16-bits
adjustment
state
state
=
ev.devEventParameter
elif
ev.type
==
SA_SI_STREAM_ABORTED_EVENT
raise
SA_SIError
ev.error
logging.debug
Skipped
event
%
x
%
ev.type
same
other
drivers
linux
kernel
driver
version
python
driver_name
=
driver.getSerialDriver
self._port
self._swVersion
serial
driver
%
s
%
driver_name
change
random
value
setpoint
simulated
system
temperature
hot
couple
minutes
range
comment
exception
=
>
comment
logging.exception
exception
string
need
something
sensor
temperature
strings
=
>
update
Please
device
answers
something
fine
*
IDN
many
devices
serial
port
example
see
piezomotor.py/_findDevice
dangerous
real
hardware
values
....
test
revert
previous
value
safety
hardware
kind
use
simulator
value
+-
simulator
stable
while
temperature
change
larger
value
eg
+6
equal
absolute
tolerance
Note
_metadata.py
MD_POS_COR
tuple
length
>
MD_POS_COR
Centre
position
cor
m
m
MD_POS
Just
FYI
matters
extra
comment
code
nice
more
explicit
comment
lab
frame
frame
shuttle
frame
underscore
hard
Docstring
TupleContinious
max
value
VA
something
idx_done
little
bit
symetrical
idx_queue
set
little
faster
fact
order
check
presence
MD_TIME_LIST
and/or
MD_WL_LIST
Anyway
data
CT1YX
temporal-spectrum
views
best
>
Drop
TODO
something
TODO
caller
move
complete
GUI
function
separate
thread
comment
caller
ie
GUI
axis
GUI
value
separate
thread
Mark
line
TODO
draw_image
function
image
BGRA
only
format
Cairo
accepts
alpha
channel
garbage
data
draw_image
argument
other
metadata
function
same
time
comment
viewports
more
none
HW
available
same
monochromator
available
more
clever
exists
So
TODO
log
warning
main_data.streak_ccd
main_data.monochromator
exists
comment
larger
comment
vpv
definition
behaviour
monochromator
streak_ccd
whole
inside
block
Hopefully
step
super
funky
Andries
comment
correct
spot
positions
positions
grid
iterative
closest
point
algorithm
order
spot
positions
order
points
grid
GridPoints
comment
comment
way
line
determinant
smaller
transformation
matrix
right
transformation
matrix.
RH
transformation
matrix
line
description
primary
secondary
axis
general
little
safer
dtypes
numpy.float64
string
case
typo
more
main
parenthesis
suggestion
reduce_sum
f
fine
tf.ensure_shape
check
documentation
Thanks
suggestion
suggestion
suggestion
same
experiment
priors
unconstrained
space
exponential
transform
positivity
kernel
parameters
set_default_positive_bijector
log-normal
prior
constrained
parameter
corresponds
normal
prior
unconstrained
space
suggestion
GPflow
Parameter
class
options
prior
constrained
tensors
computation
gradient
respect
unconstrained
transformation
tensor
user
prior
either
*
*
*
*
space
*
unconstrained
*
*
space
typo
line
readable
editor
confusing
helpful
suggestion
%
%
[
markdown
]
gpflow.optimizers.SamplingHelper
sure
prior
density
space
prior
suggestion
same
experiment
priors
unconstrained
space
exp
transform
Log-normal
prior
constrained
parameter
corresponds
Normal
unconstrained
space
suggestion
default
prior
Parameter
_constrained_
space
prior
following
suggestion
GPflow
class
Parameter
class
options
prior
class
Parameter
constrained
tensor
suggestion
prior
*
*
space
gpflow.optimizers.SamplingHelper
prior
density
Jacobian
transformation
parameter
priors
*
*
space
gpflow.optimizers.SamplingHelper
adjustments
prior
density
suggestion
K_r
K_r2
IsotropicStationary
class
docstring
Stationary
anisotropic
kernels
gpflow.kernels.AnisotropicStationary
K_d
suggestion
return
self.K_r
r
pylint
disable=no-member
suggestion
return
test_broadcast_no_active_dims
suggestion
return
separate
test
test_broadcast_no_active_dims_periodic
suggestion
self.image_tensor
=
tf.image.decode_png
self.buf_placeholder
None
suggestion
Lengthscale
SquaredExponential
kernel
isotropic
change
]
*
C
ARD
one
suggestion
different
lengthscale
input
dimensions
[
Manipulating
kernels
]
..
/advanced/kernels.ipynb
more
information
suggestion
little
changes
input
space
more
dimension
default
lengthscales
isotropic
scalar
parameter
different
lengthscale
dimension
Automatic
Relevance
Determination
ARD
lengthscales
array
length
D
input
dimension
X
suggestion
raise
TypeError
Closure
argument
callable
object
pragma
cover
suggestion
pragma
cover
suggestion
original
prediction
later
comparison
needs
tensor
tf.function
single
graph
suggestion
Y_i
=
f
X_i
+
\varepsilon_i\
full_output_cov
suggestion
mean
cov
=
self.predict_f
Xnew
full_cov=full_cov
full_output_cov=full_output_cov
[
N
P
]
[
P
N
N
]
[
N
P
]
note
best
autoflow
gpflow2
suggestion
grips
maths
code
bit
daunting
documentation
[
in-depth
review
arXiv
]
https
//arxiv.org/abs/2003.01115
unified
mathematical
framework
high-level
description
software
design
choices
GPflow
suggestion
framework
[
arXiv
paper
]
https
//arxiv.org/abs/2003.01115
suggestion
https
//github.com/GPflow/GPflow/issues/1434
helpful
full
link
click
bunch
suggestion
Collection
tensor-like
types
implementations
multipledispatch
dispatchers
TensorLikeTypes
=
object
np.ndarray
tf.Tensor
tf.Variable
Parameter
object
performance
consequences
full
set
https
//github.com/GPflow/GPflow/issues/1434
suggestion
Collection
tensor-like
types
implementations
multipledispatch
dispatchers
notebook
helpful
comment
general
demonstration
purposes
_variational_expectations
one
training
others
prediction
suggestion
log_prob
quadrature
fallback
variational_expectations
predict_log_density
suggestion
continue
parametrized
tests
suggestion
possible
model
gpflow.base.Parameter
s
tf.constant
same
value
suggestion
present
tensorflow
custom
variables
instances
gpflow.base.Parameter
class
TensorFlow
github
issue
]
https
//github.com/tensorflow/tensorflow/issues/34908
good
links
suggestion
TensorFlow
saved_model
Y
suggestion
f_mean
=
rng.randn
N
f_var
=
rng.uniform
N
positive
clear
shape
positive
suggestion
f2_mean
=
np.full
N
f2_var
=
np.zeros
N
F2_mean
=
f_mean
f2_mean
]
[
N
]
name
suggestion
equivalent_f2
=
np.log
np.sqrt
g_var
g_var
clearer
more
robust
value
values
special
number
bugs
suggestion
rng
=
np.random.RandomState
N
Y
=
rng.randn
N
code
obvious
shape
comment
applicable
self.ARD
=
False
pass-through
property
self.base.ARD
suggestion
set_trainable
kc.variance
False
variance
Coregion
kernel
suggestion
Ks
=
tf.tile
K
[
None
]
]
[
N
N2
P
]
suggestion
case
number
latent
GPs
L
output_dim
P
Minor
typo
Tensoreflow
suggestion
bijector
=
tfp.bijectors.Chain
[
shift
bijector
]
line
callable
model
parameters
worth
docstring
zero-argument
callable
worth
little
comment
suggestion
filter
rc
beta
releases
releases
numbers
dots
filter
meant
release
candidates
comment
robust
re.search
[
0-9
+
commented-out
code
reasoning
small
comment
something
tf.nn.moments
returns
factor
unbiased
comment
TODO
comment
necessary
/
intent
method
Second
opinion
@
jameshensman
James
renaming
square_dist
warning
time
result
negative
due
point
precision
Could
docstring
implementation
wrong
delete
getattr
parent
attr_str
index
]
thinking
Could
comments
issue
extra
delattr
thanks
suggestion
delattr
tensorflow
internal
reference
suggestion
delattr
tensorflow
internal
reference
suggestion
delattr
parent
attr_str
docstrings
assign
necessary
transformation
inverse
bijector
gradient
w.r.t
variable
lucky
transformation
reshuffling
elements
gpflow
gradient
w.r.t
tensor
forward
transform
suggestion
natgrad
L
w.r.t
ξ
=
∂ξ
/
∂θ
[
∂
[
q_μ
q_sqrt
]
/
∂η
∂L
/
∂
[
q_μ
q_sqrt
]
^T
necessary
extra
blank
token
problem
master
branch
necessary
names
model.parameters
comment
incorrect
/
type
ignore
self._dataset_features
i
calls
__getitem__
_dataset_features
user-defined
function
stuff
mypy
__getitem__
List
[
T
]
returns
T
nothing
self._dataset_features
i
local
variable
None
check
ignores
Added
links
AdaptDL
documentation
few
unused
logging
example
few
unused
comments
example
few
unused
logging
example
lot
TransformerEncoder
Executor
multiple
times
whole
hyper
process
multiple
runs
output
logs
same
log
file
good
log
file
reuse
behavior
special
tokens
tokenizer
input
vocab
input
vocab
tokens
clear
docstring
@
例子里区间没合并，按要求应该要返回2。
这种情况
bisect_left
[
[
]
]
]
]
]
merge
和
注释有个例外：没理解错
heap
的实现话，
的
iterable
也可以返回
Empty。
Please
comment
line
comment
nothing
Bezier
curves
comment
degree
important
_how_
code
n
comment
unclear
basis
t
time
value
inclusive
basis
curve
x
y
values
basis
function
time
t
Wrap
lines
characters
comment
line
comment
second
ìth
ì-th
codespell
test
suggestion
Filter
less
replaceable
digits
=
x
x
set
sieve
str
x
len
str
x
more
doctests
CONTRIBUTING.md
Great
progress
Please
doctest
printMaxActivities
function
CONTRIBUTING.md
details
doctests
>
>
>
=
[
]
>
>
>
finish
=
[
]
>
>
>
printMaxActivities
start
finish
following
activities
wrap
lines
characters
suggestion
error
table
size
+4
columns
+1
row
greater
input
image
lack
statements
suggestion
greyscale
value
FFFFFF
=
int
self.get_greyscale
suggestion
print
digit_sum
===
suggestion
return
job.result
.get_counts
circuit
suggestion
def
convert_currency
str
USD
INR
amount
float
api_key
str
=
API_KEY
>
str
https
//www.amdoren.com/currency-api/
=
requests.get
URL_BASE
data=locals
.json
return
str
amount
]
res
error
else
res
error_message
]
nice
advantages
requests
locals
function
parameter
names
API
suggestion
assert
gain
Pytest
boilerplate
code
tests
negative
integers
zeros
floats
numbers
negative
user
situations
Please
test
sure
d
empty
sys.maxsize
huge
number
necessary
use
descriptive
variable
names
single
letter
names
CONTRIBUTING.md
changes
variables
cool
ideas
imagination
morning
coffee
Thanks
PR
current
form
_but_
python
random
import
choice
import
ascii_letters
digits
punctuation
def
password_generator
length=8
>
>
password_generator
>
>
>
len
password_generator
length=16
>
>
>
len
password_generator
>
>
>
len
password_generator
length=0
>
>
>
len
password_generator
-1
chars
tuple
ascii_letters
tuple
digits
tuple
punctuation
return
.join
choice
chars
x
range
length
logic
suggestions
*
Change
__max_length__
length
output
*
Give
sensible
default
value
users
value
higher
*
Add
doctests
code
__python3
-m
doctest
-v
other/password_generator.py__
*
tuples
faster
lists
less
memory
*
__random.choice
__
lighter
weight
operation
__random.shuffle
*
__password_generator
__
password
need
variable
rid
following
line
suggestion
re.compile
function
pattern
z
A
Z'
'regexp
variable
General
comment
Please
comments
self-explanatory
CONTRIBUTING.md
above
comment
pseudocode
reference
bad
x
=
x
+
trivial
Comments
explanatory
separate
function
doctest
indent
lines
https
//docs.python.org/3/library/__main__.html
highlight=__main__
Please
add
doctests
search
method
result
result
suggestion
>
>
>
get_bitcode
edge_array
get_distinct_edge
edge_array
'this
]
Python
type
hints
suggestion
import
List
def
get_distinct_edge
edge_array
List
[
List
[
]
]
>
List
[
]
suggestion
i
nodes
doctest
docstring
function
first
test
second
suggestion
>
>
>
get_distinct_edge
edge_array
[
b
c
e
f
g
h
]
>
>
>
get_distinct_edge
edge_array
[
z
b
c
e
f
g
h
]
suggestion
format
cluster
WT
bitcode
nodes
same
WT
suggestion
return
list
DE
avoid
unneeded
parens
variables
last
line
def
get_bitcode
edge_array
List
[
List
[
]
]
distinct_edge
List
[
str
]
>
str
bitcode
str
Return
bitcode
distinct_edge
>
>
>
get_bitcode
edge_array
get_distinct_edge
edge_array
DE
EA
reader
reader
real
variable
names
CONTRIBUTING.md
Uppercase
_constants_
Python
Python
type
hints
doctest
CONTRIBUTING.md
function
normal
comments
suggestion
Store
[
Distinct
edge
WT
Bitcode
Bitcode
]
Descending
order
suggestion
key
value
nodes.items
cluster.setdefault
key.count
key
]
=
value
good
change
practice
docstring
first
thing
function
doctests
CONTRIBUTING.md
suggestion
print
.join
str
row
row
solutions
axis
others
wrap
angle
suggestion
isinstance
axis
str
raise
TypeError
Axis
str
=
locals
del
axis
]
isinstance
val
float
int
val
input_variables.values
raise
TypeError
Input
values
axis
float
int
f
list
input_variables.values
%
=
wrap
angle
>
<
=
angle
raise
ValueError
Angle
suggestion
return
first_term
/
common_ratio
*
common_ratio
*
*
num_of_terms
Readability
Please
spaces
code
comment
comment
sequence
sequence
length
print
f
Mean
Absolute
Error
func
\t
mean_absolute_error
y_test
predictions
print
f
Mean
Square
Error
func
\t
mean_squared_error
y_test
predictions
suggestion
def
solution
n
int
>
int
suggestion
suggestion
True
suggestion
group
=
+
i
i
range
n
suggestion
numbers
list
equal
increment
success
variable
docstring
intent
file
docstring
[
pydoc
]
https
//docs.python.org/3/library/pydoc.html
command
python3
-m
pydoc
data_structures/stacks/evaluate_postfix_notations.py
comment
PR
documentation
suggestion
return
None
test
GitHub
Actions
min_numerator
descriptive
one
long
run
Please
change
l
r
noqa
comment
Thanks
suggestion
def
__init__
row
int
col
int
graph
list
Class
constructor
Python
type
hints
CONTRIBUTING.md
suggestion
[
i
[
j
]
False
self.graph
[
i
[
j
]
<
space
>
please
+=
print_stack
Pythonic
__is_empty
__
Pythonic
Insert
doctests
>
>
>
stack
=
Stack
>
>
stack.isEmpty
True
>
>
>
i
range
stack.push
i
>
>
stack.isEmpty
False
>
>
>
stack.printstack
stack
elements
3-
>
2-
>
1-
>
0-
>
>
>
>
stack.top
>
>
>
>
>
>
stack.pop
>
>
>
stack.printstack
stack
elements
2-
>
1-
>
0-
>
-m
doctest
stack_using_dll.py
python3
-m
doctest
-v
stack_using_dll.py
sure
doctest
pass
suggestion
node
=
lr_rotation
node
new
node
right
child
left
child
suggestion
def
get_json
>
dict
changes
function
Include
type
hints
doctest
function
suggestion
def
format_ruleset
ruleset
int
>
list
>
>
]
>
>
>
format_ruleset
]
>
>
>
format_ruleset
return
[
int
c
c
f
ruleset:08
[
:8
]
]
suggestion
def
generate_image
CELLS
list
>
Image
Convert
cells
PIL.Image
caller.
function
Image
caller
caller
.show
easier
generate_image
larger
program
image
web
page
Jupyter
Notebook
etc
abs
sum_moments
comment
separate
line
Please
lines
function
’
s
function
’
s
docstring
suggestion
def
create_sparse
max_node
int
parent
List
[
List
[
int
]
]
>
List
[
List
[
int
]
]
Thanks
graph
line
few
more
test
cases
edge
cases
variable
next
line
Lines
characters
Replace
lines
return
distance_from_centre
<
sum
+=
rem
*
*
number_of_digits
Remove
line
f-string
Combine
transitory
variable
better
function
name
lowercase
CONTRIBUTING.md
Ambiguous
function
name
lines
dedent
line
__return
[
k
_
range
instance_count
[
k
]
k
range
class_count
__
Pick
great
function
names
variable
names
comments
transitory
variable
Better
function
name
def
gaussian_distribution
def
generate_gaussian_distribution
line
list
comprehension
thru
__return
[
gauss
mean
std_dev
_
range
instance_count
__
list
comprehension
Using
math.pow
slow
pythons
*
notation
powers
unit
measure
great
circle
calculations
Google
miles
kilometers
road
distance
as-the-crow-flies
distance
readers
value
submission
answer
script
lines
repo
legacy
Python
Please
__print_function__
__raw_input__
file
open
ed
suggestion
Does
constraints
neighbour
==
colored_vertices
i
==
color
i
neighbour
enumerate
neighbours
noqa
comments
Python
dead
Please
unecessary
comments
Code
readable
tuple
list
suggestion
lowercase
letter
capital
case
grammatical
fix
good
word
blank
lines
functions
better
reformat
__black__
suggestion
collection
=
int
item.strip
item
user_input.split
collection
assertion
logic
way
type
Callable
[
[
float
]
float
]
type
call
parameters
suggestion
upper_bound
>
current
<
=
limit
suggestion
current
Please
lines
readability
Please
add
doctests
functions
CONTRIBUTING.md
details
AWESOME
WORK
Just
more
ask
def
test_end_to_end
msg
str
Hello
modified
Caesar
cipher
>
>
>
test_end_to_end
Uncomment
code
function
doctests
end-to-end
roundtrip
test
better
global
constant
TOKEN
default
value
empty
string
user
token
TOKEN
constant
empty
ValueError
fact
token
authenticated
user
Type
hint
__int__
__float__
suggestion
request.method
=
POST
return
render
request
login.html
’
fail
fast
suggestion
client_key
=
request.POST.get
g-recaptcha-response
Python
variable
naming
suggestion
lines
function
suggestion
requests
suggestion
captcha_data
=
secret
secret_key
response
client_key
comment
captcha_data
json
Python
dict
function
import
suggestion
def
login_using_recaptcha
request
Python
function
Python
type
hints
function
parameters
return
types
grid
top
file
automated
testing
Lose
parens
__if
grid
[
row
[
i
==
n
__
>
__if
grid
[
row
[
i
==
n
__
Python
=
JavaScript
Parens
Python
Define
[
]
https
//docs.python.org/3/reference/datamodel.html
object.__str__
more
self
variable
names
order
things
variable
names
reader
seasonal_order
variable
name
s_order
Please
self-documenting
variable
name
list_data
list
Are
stock
quotes
flu
patients
food
orders
reader
data
analysis
worth
Please
comment
SRV
suggestion
print
today
data
safe
<
=
not_safe
safe
’
use
Python
list
compréhension
lines
line
suggestion
def
depth_of_tree
tree
Node
>
int
Recursive
function
depth
binary
tree.
suggestion
def
is_full_binary_tree
tree
Node
>
bool
Return
True
full
binary
tree
doctest
automated
tests
def
test_disjoint_set
>
>
>
test_disjoint_set
Let
__x.parent__
__x.p__
comment
Single
character
variable
names
old
school
__union_set
__
more
Pythonic
string
sample
easier
user
code
Thanks
suggestion
coin
coins
relate
comment
code
comment
comment
function
docstring
>
checks
elements
equal
Please
wrap
lines
characters
line
<
space
>
please
lines
comment
lines
>
>
>
decimal_to_hexadecimal
doctest
+ELLIPSIS
Traceback
recent
call
last
AssertionError
CONTRIBUTING.md
better
emails
[
__set
]
https
//docs.python.org/3.8/library/stdtypes.html
set-types-set-frozenset
duplicates
bare
Please
type
hints
doctests
CONTRIBUTING.md
element
entity
error
Please
real
variable
name
reader
valid_emails
CONTRIBUTING.md
line
indented
CONTRIBUTING.md
Let
move
definition
reader
formula
*
+
n-1
*
d
Please
documentation
parameters
return
value
function
Please
doctests
function
Please
value
printing
suggestion
all_sum
=
sum
my_dic_fir.values
use
https
//docs.python.org/3/library/collections.html
collections.Counter
suggestion
char1
my_alphas
suggestion
open
path_src
f
suggestion
suggestion
def
read_dicts_from_file
path_src
str
>
dict
dict
[
x
]
More
self-documenting
function
name
*
[
x
]
Remove
parameter
*
[
x
]
Python
type
hints
CONTRIBUTING.md
suggestion
text
=
f.read
suggestion
char0
my_alphas
_
variable
name
case
_
char
better
use
key
value
first_dict.items
use
my_
variable
names
helpful
variable
names
readability
learners
*
Solved
*
*
code
arithmetic_analysis
👍
💯
suggestion
self.head
=
fan
change
duplicate
state
many
locations
variable
updated
bugs
difficult
please
[
.__iter__
]
https
//docs.python.org/3/reference/datamodel.html
object.__iter__
method
len
tuple
other
methods
__repr__
__str__
examples
method
repo
doctests
suggestion
def
delete_head
suggestion
new_node
=
Node
data
suggestion
div
divmod
num
base
https
//docs.python.org/3/library/functions.html
divmod
suggestion
isinstance
base
str
Bad
input
exceptions
None
>
>
int
base=0
>
>
>
int
base=1
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
ValueError
int
base
>
=
<
=
suggestion
>
>
>
float
base
exception
text
exception
int
base=6
https
//docs.python.org/3.4/library/functions.html
highlight=open
int
suggestion
>
>
>
decimal_to_any
doctest
+ELLIPSIS
improved
readability
__f__
__with__
context
manager
_f.close
line
comments
<
space
>
<
space
>
<
space
>
line
automated
__name__
__main__
CONTRIBUTING.md
>
>
all_rotations
^BANANA|
doctest
+NORMALIZE_WHITESPACE
backslashes
way
want
PEP8
preferred
way
long
lines
Python
’
implied
line
continuation
parentheses
brackets
braces
Long
lines
multiple
lines
expressions
parentheses
preference
backslash
line
continuation
reverse_graph
reversed_graph
comment
unnecessary
Variable
name
comments
rename
variables
Please
comment
line
above/
Please
use
__get_data
__getdata
__
readability
Same
other
functions
set_left
get_left
suggestion
myMessage
=
common
things
life
uncommon
way
attention
world
suggestion
charsA
=
LETTERS
mode
decrypt
key
charsB
=
key
mode
decrypt
else
LETTERS
=
comment
separate
line
helpful
traversal
list
caller
comment
code
Please
comment
line
command
useful
suggestion
c
genes_list
c
sentence
raise
ValueError
f
c
genes
list
evolution
readable
c
characters
i
integers
suggestion
score
=
len
[
g
position
g
enumerate
item
==
main_sentence
[
position
]
]
suggestion
genetic
algorithm
combine
evolve
string
suggestion
Evaluate
similar
item
sentence
char
right
position
>
>
>
evaluate
Helxo
Worlx
Hello
World
Helxo
Worlx
]
suggestion
small
string
lot
fewer
generations
suggestion
Verify
sentence
genes
ones
genes
suggestion
import
random
import
List
Tuple
isort
imports
comments
PR
suggestion
def
is_empty
True
list
empty
list
empty
logic
insert_at_head
suggestion
def
insert_at_tail
data
new_node
=
Node
data
self.head
=
new_node
self.tail
=
new_node
self.tail.next
=
new_node.previous
=
self.tail
self.tail
=
define
__str__
caller
print
log
parameterized
queries
time_format
cleanest
way
DATETIME_FORMAT
set
language
files
aplus
folder
Many
exercise
API
endpoints
word
points
current
best
points
student
submission
detail
endpoint
grade
sense
grade
object
submission
detail
URL
comment
code
something
required
pmap
difference
jit
no-jit
significant
difference
tests
test_mcmc
use
mac
os
Could
updated
COERCIONS
pattern
https
//github.com/pyro-ppl/pyro/pull/2641
contrib.epidemiology
same
COERCIONS
mechanism
Numpyro
Pyro
easier
contrib.epidemiology
Numpyro
first
state
init_prob
prior
sample
'init_state
dist.Categorical
init_prob
]
work
float32
precision
example
comment
nit
=
real
FIXME
further
investigate
hard-to-sample
potential_fn
current
approach
problem
implementation
comment
sense
part
files
notebooks/source
directory
files
documentation
Could
comment
script
step
PR
reason
hmc
init
implementation
kind
gross
cry
Can
labels
title
plot
ax.set
xlabel=
X
Y
title=
Mean
predictions
X
%
CI
quantities
step
constraints
bijectors
Could
comment
logic
TypeError
@
neerajprad
following
csv
file
.txt
file
cloud
pandas
pd
URL
=
http
//people.whitman.edu/~hundledr/courses/M250F03/LynxHare.txt
data
=
pd.read_csv
URL
sep=
year
hare
lynx
]
index_col=0
engine=
python
data.to_csv
LynxHare.csv
Thanks
reader
file
pandas
requirement
example
test
fail
comment
maintainability
[
swapaxes
https
//docs.scipy.org/doc/numpy/reference/generated/numpy.swapaxes.html
numpy
result
self.event_shape
use
np.broadcast_to
self.batch_shape
+
self.event_shape
ditto
use
np.swap_axes
NumPy
transpose
behavior
different
PyTorch
correct
shape
batch_shape
=
sample_shape
+
self.batch_shape
W_shape
=
batch_shape
+
self.cov_factor.shape
[
-1
]
D_shape
=
batch_shape
+
self.cov_diag.shape
[
-1
]
eps_W
=
random.normal
key
W_shape
=
random.normal
key
D_shape
distribution-specific
properties
general
properties
such
variance
mean
entropy
examples
batch
sure
more
batch
edge
cases
dimension-wise
batch
predictions
vectors
predictions
1-hot
vector
form
batch
consistent
caps
file
shape
tensor
impossible
test
tests
self-explanatory
nice
catch
sure
crucial
nice
weird
comment
logic
AutoregressiveLMTask
class
confused—is
leftover
comment
normal
LM
code
true
appropriate
MLM
sure
refers
span_extractor
comment
_make_span_extractor
comment
pretraining
sense
search_phase
argument
comment
average
MSE
MSE
quick
comment
logits
=
None
predictions
None
TODO
nit
expand
comment
Always
project
pooling
transformer
little
weird
transfer
paradigm
_structure_
model
parts
TODO
AllenNLP
@
UNKNOWN
@
@
tokens
OOV
words
sentencepiece
model
BERT
assert
Index
BERT
WPM
own
unk
token
level
assert
ids
.all
_
Quick
comment
magic
numbers
pernicious
nit
add
comment
obvious
immediate
context
tokens
=
boundary_token_fn
tokens
add
model-appropriate
padding
e.g
[
CLS
]
[
SEP
]
BERT
TODO
config
check
dumb
question
segment
IDs
test
single
input
case
worried
something
PR
something
likely
fault
checkpoint
best
checkpoint
best
checkpoint
checkpoint
newline
comment
piece
code
people
most
_to
death_
block
code
least
comment
lines
_blindingly_
obvious
comment
target_tasks
do_full_eval
diagnostics
names/comments
distinguish
vars
e.g
bert-base-uncased
bert-large-uncased
same
tokenizer
wordpiece
exact
same
vocabulary
cache
files
data
experiment
directory
runs
bert-base-uncased
other
bert-large-uncased
moment
level
cache
file
management
jiant
problems
cache
files
lot
confusion
reruns
projects
own
external
users
thanks
ivanpauno
=
info
]
comment
Nipick
CLI_
prefix
variable
ROS2CLI_NODE_NAME_PREFIX
package
name
symbol
namespace
ros2cli
+1
declaration
HIDDEN_NODE_PREFIX
linter
[
character
wide
lines
]
https
//index.ros.org/doc/ros2/Contributing/Developer-Guide/
id4
need
stderr
worth
comment
failure
mode
Fast-RTPS
part
build
more
sense
cyclonedds
comment
necessary
attribute
existence
same
nit
categories
cats
Same
comment
uses
report_class
try/except
block
nit
\n
report
Skip
print
ros2-dev0|sloretz
@
c70527c77758
~
comma
leading
space
intentional
INFORMATION
distribution
name
eloquent
reports
class
instance
class
Report
dictionary
hard
NAME
special
key
reports
documentation
class
definition
docstrings
spot
future
questions
report
ros2doctor
@
emersonknapp
consider
stdout
emersonknapp
nit
suggestion
print
'WARNING
nodes
graph
exact
name
consistent
other
CLI
warnings
format
sure
warning
result
nothing
user
result
softer
category
Neither
above
API
None
checks
unnecessary
expose
client
own
documentation
platform.dist
[
python
]
https
//docs.python.org/3/library/platform.html
platform.dist
check
same
comment
dist
Python
Same
comment
case
unset
roswtf
own
checks
same
behavior
ros2
doctor
check
default
someone
problem
tool
commented
code
git
username
good
fallback
normal
firstname
+
lastname
nit
term
'command
comment
docstring
something
List
interfaces
types
available
docstring
docstring
format
types
rosidl
TODO
logic
rosidl
related
package
comment
organization
view
file
functions
ros2interface.api
verb
test
own
file
test_cli.py
fact
test_cli.py
test
invalid
path
generic
RuntimeError
API
actual
CLI
RuntimeError
stacktrace
API
helpful
specific
exceptions
try
/
logic
verb
API
good
breaking
behavior
bazel
https
//bazel-review.googlesource.com/c/bazel/+/48211
TODO
access
lines
unclear
i
field
access
second
field
while
others
comments
course
participant
variables
=
instance
course
=
instance
branches
documentation
m2m_changed
pretty
clear
mechanic
additional
help
reader
@
He3lixxx
opinions
questionnaires
general
contribution
i
target_points
>
granted_points
RewardPointGranting.objects.create
value=target_points-granted_points
True
return
False
further
comments
early
return
False
line
rest
fine
following
work
init_from_dataset_and_submissions_write_to_datastore
dataset_batches
attack_submission_ids
....
line
length
intentation
M
default
true
Please
description
argument
function
comment
name
argument
confusing
name
M
value
matrix
variable/argument
names
self
explanatory
variables
arguments
python
style
guide
naming
https
//www.python.org/dev/peps/pep-0008/
function-and-variable-names
value
argument
function
route
comment
route
comment
following
*
arguments
number
iterations
proper
function
*
argument
max_iter
function
equal
something
tf.cond
use_warm_starts
lambda
tf.constant
lambda
tf.constant
route
arguments
num_iter_full
First
possible
legitimate
non-zero
b
most
point
computations
errors
sure
bunch
zeros
non
better
case
following
compare
b
None
None
new
random
vector
non
None
disadvantage
tf_lanczos_smallest_eigval
time
b=None
b
None
subgraphs
boolean
flag
function
value
flag
re-initialize
b
def
tf_lanczos_smallest_eigval
use_warm_start
use_warm_start
==
False
few
variations
condition
autograph
happy
b
=
tf.random_normal
mind
such
use_warm_start
flag
Tensor
type
tf.bool
i.e
tf.placeholder
tf.bool
shape=
norm
b
something
boolean
argument
None
tf.norm
b
TOLERANCE
E999
SyntaxError
invalid
syntax
W291
whitespace
try/except
user
specific
error
message
and/or
use
[
df.equals
]
https
//pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.equals.html
single
line
intersect.empty
ignore_meta_conflict
elegant
sanity-check
first
operation
function
pivot
necessary
if-then
statement
self.time_col
year
time
int
msg
time
argument
integer'.format
time
ValueError
time
Added
side
error
faster
pivot
check
PS
change
consistency
favour
comment
test
interpolation
duplicates
added
easier
next
person
test
E501
line
characters
notice
similar
word
previous
line
column
index
name
W292
newline
end
file
models
@
many
other
non-public
database
instances
such
snapshot
files
one-liner
=
df
[
~df.model.str.contains
Public
Database
suggestion
iterate
variables
subcategories
sub_variables
[
]
suggestion
iterate
variables
subcategories
E121
continuation
line
under-indented
indent
E501
line
characters
comment
relevant
future
devs
suggestion
pyam.utils
ConfigPseudoHandler
ambiguous
variable
name
l
meaningful
name
find_n_pipes
sorry
list
data
None
np.nan
False
-1
cleaner
_pipe
calls
lambda
defs
list
test
data
E127
continuation
line
over-indented
visual
indent
E127
continuation
line
over-indented
visual
indent
E251
spaces
keyword
/
parameter
equals
line
years
[
]
start
function
obvious
next
person
different
ways
same
years
one-line
docstring
variable
years
section
checking
variable
years
next
E501
line
characters
W293
blank
line
whitespace
E266
many
block
comment
E261
least
spaces
inline
comment
clear
comment
suggestion
cast
value
nan
nan
other
cols
whitespace
arithmetic
operator
conversion
C
CO2
CO2-eq
context
https
//github.com/IAMconsortium/units/issues/23
todo
reminder
test
suggestion
TODO
context
IAMconsortium/units
C
bit
fancy
changes
try
append_by_idx
=
[
'model
]
.issubset
_meta.index.names
append_by_idx
=
False
name
meta
'name
raise
ValueError
'Must
pass
name
pd.Series
name
=
name
_meta.name
_meta
=
list
meta
self.meta
[
name
]
=
complicated
bit
normal
indentation
documentation
metadata
magic
meta.csv
file
Hard
e.g
license
newcomers
E222
multiple
spaces
operator
E501
line
characters
suggestion
https
//www
random
.google.com'.format
random=randomness
mistake
earlier
moment
rule
modification
file
road
actual
processing
domain
lookup
bug
hosts
domains
URL
Thoughts
tweaks
suggestion
LICENSE_HEADER
Copyright
Elasticsearch
B.V.
and/or
Elasticsearch
B.V.
more
contributor
license
agreements
Elastic
License
file
compliance
Elastic
License
.strip
LICENSE_LINES
=
LICENSE_HEADER.splitlines
PYTHON_LICENSE
\n
.join
+
line
line
LICENSE_LINES
JS_LICENSE
f
/
*
*
+
line
line
LICENSE_LINES
.strip
suggestion
cloud
id
elasticsearch
Lambda
poisson
likelihood
R_t
increase
t-1
cases
comment
comment
something
case
logic
right
case
frontend
future
PR
possible
new
sum
cases
counties
more
old
sum
cases
unlucky
bunch
counties
new
case
count
same
direction
comment
possible
Use
libs.us_state_abbrev.ABBREV_US_UNKNOWN_COUNTY_FIPS
state
total
covid
patients
covid
patients
wrong
general
sure
helpful
comment
estimation
front
next
code
return
value
types
kinda
loose
exact
/
formatting
actual
types
Does
easy
/
possible
actual
type
definitions
actual
enum
names
comment
prose
rest
comment
trouble
line
docstrings
tools
TODO
code
parts
MultiRegionTimeseriesDataset
output
MultiRegionTimeseriesDataset
easy
seconds
entire
world
laptop
API
generation
hours
massive
pain
point
development
try
many
slow
things
possible
API
code
MultiRegionTimeseriesDataset
set
values
API
output
Fixed
Originally
test_positivity
old
comment
-/
easier
comment
fragment
lot
value
pydantic
base
model
normal
python
class
https
//github.com/covid-projections/covid-projections/blob/1c15ef642eaa1247baa913c646fdf22590d0bf03/src/common/metrics/contact_tracing.tsx
L38
clearer
point
everything
below
=
comment
bit
concise
_get_object_sha_from_lfs_pointer
LFS
file
lfs
something
return
subprocess.check_output
[
'git
'lfs
'smudge
]
input=pointer_text
Please
comment
returned
values
Oh
comments
PR
bit
subtraction
Could
comment
mechanics
subtraction
something
effect
negative
Can
note
understand
posteriors
initial
prior
start-up
artifact
posterior
restabilizes
current
best
solution
edge
cases
X
Let
give
future
selves
others
more
hints
quirks
system
data
bit
simpler
output
function
CSBA
dataset
input
Are
logic
metric
aggregation
i.e
current
hospitalizations
area
group
comment
previous
line
references
fifth
case
ghop02
cases
true
build
latest
special
cases
possible
oh
orient='records
list
dictionaries
same
thing
type
right
thing
general
patch
switch
hospitalized
deaths
ICU
others
artifact
bit
trouble
my_ts
ts
pandas
Series
DataFrame
multi
index
comment
timeseries
set
<
date
value
>
tuples
<
variable
fips
tuple
rm
line
docstrings
Added
TODO
geodata
timeseries
comments
たしかにというのがありつつ、files.uploadだとurl展開できなかった記憶。chat.post_message
そういえば。
os.path.isdir
present
prod
issues
version
simple
proxy
instance
end
view
config
redundant
something
RecordCitations.query.filter_by
citer_id=self.id
cited_id=self.id
WDYT
Good
point
better
different
data
case
nested
session
end
commit
is_error_caused_by_invalid_cache
=
original_urls
None
comment
suggestion
@
freeze_time
'2019-09-15
today
September
test
value
🆙
dot
end
sentence
whole
thing
versions
complex
following
cnum
record
pidstore
pid_value
compatible
metadata
>
exception
record
deleted
pid
registered
suggestion
record_author_identifiers
author.get
ids
[
]
loop
object_
data
better
Inspire
prefix
>
AttributeError
'NoneType
object
attribute
self.session
key-value
map
readability
reasons
None
match
case
URL
regex
programm
type
checks
comment
docstring
def
get_stream_info
html
list
stream_url
stream_quality_url
stream_quality_name
occurrence
JS.
_i
uk
ip
redirections
same._
geo
script
exact
opposite
old
script
works
http
urls
old
works
https
history
url
last
url
res.url
sh
streamlink
http
//www.bbc.co.uk/iplayer/live/cbeebies
res.history
[
-1
]
.url
=
http
//www.bbc.co.uk/iplayer/live/cbeebies
=
https
//www.bbc.co.uk/iplayer/live/cbeebies
login
wrong
url
sh
streamlink
https
//www.bbc.co.uk/iplayer/live/cbeebies
res.history
[
-1
]
.url
=
https
//session.bbc.co.uk/session/callback
code=
......
res.url
=
https
//www.bbc.co.uk/iplayer/live/cbeebies
login
error
name
type
'cronos-auth-token
cookies.get
'cronos-auth-token-signature
need
such
long
comments
video
[
]
HLSStream.parse_variant_playlist
https
//secure-service.canal-plus.com/video/rest/getVideos/cplus/1469050
format=json
better
list
api
tabs
use
spaces
live
channels
drm
i
support
Did
comment
Chinese
comments
late
replying
statements
prior
general
area
good
documentation
lines
'peaks
routine
new
interface
file
consistent
set
tools
user
more
tools
on-the-fly
entry
constructor
comment
code
case
line
code
ci_watson.get_bigdata
use
runtime
@
pytest.mark.bigdata
inside
branch
Import
top
module
Length
filelist
course
mistake
various
commands
Python
session
Fixed
Yes
Might
easier
asnid
=
None
None
end
NONE
due
python
input_item
input_list
filelist
=
aqutils.retrieve_observation
input_item
archive=archive
clobber=clobber
filelist
python
filelist
=
aqutils.retrieve_observation
input_item
archive=archive
python
filelist
=
aqutils.retrieve_observation
input_item
archive=archive
list
IMHO
stylistic
Files
open
-statement
way
code
file
function
returns
filelist
fitsfilenames
Done
Agreed
Exception
same
try/except
block
due
aqutils.retrieve_observation
works
exception
i.e
aqutils.OhNoes
value
use
value
multiple
condition
groups
Dead
code
traceback
blocks
prevent
pytest
meaningful
tracebacks
failed
test
Fail
exception
SomeExceptionHere
pytest.raises
SomeExceptionHere
code
Pass
exception
type
SomeExceptionHere
pytest.raises
SomeExceptionHere
code
other
cases
traceback
record
\n
meant
suggestion
catalogIndex
catalog_name
enumerate
catalog_list
loop
astrometric
catalog
need
line
only
entries
catalog_list
strings
need
strings
line
either
suggestion
line
debug
message
line
code
Line
computation
Line
debug
statement
'if
statement
values
'legend_group
'legend_label
single
call
thought
'ImageName
'Inst/Det
list
plot
'Inst/Det
definition
glyph
color
user
image
supplemental
plots
available
image
previous
comment
line
copy
product
list
nothing
line
variables
column
names
code
definitions
datasetIDs
asnIDs
un-necessary
need
variable
numStartTests
original
definition
variable
Line
print
statement
instance
enumerate
dataset_list
datasetKey
variable
change
function
less
room
mistakes
variable
suggestion
appropriate
additional
logic
variable
specific
method
useful
other
runs
date-time-stamped
filename
fixed
generic
filename
time-unique
name
test
pytest
suggested
issue
time
suggestion
imgid
asnid
zip
tableName
[
'observationID
]
tableName
[
'asnID
]
[
status
fit_qual
delta
rot
scale
]
sure
previous
line
attribute
private
method
variable
variable
name
self.out_dict
Update
comment
comments
photometry_graphics.py
comment
pixels
'.lower
dangerous
Linux
filenames
upper-case
dataset
names
lower
code
mis-interpret
directory
names
suggestion
ci_lower_limit
=
float
param_dict
[
'quality
control
]
[
filter
]
[
proc_type
]
[
'ci_lower_limit
]
comment
reason
copy
comments
calls
version
first
call
Align
images
correct
WCS
invocation
astrometric
catalog
call
input
images
relative
way
first
input
image
reference
group_id
Set
group_id
values
same
various
images/chips
astrometric
reference
catalog
ensemble
BEWARE
additional
iterations
solutions
group_id
values
\
assert
single
task
tasks
=
..
assert
..
.format
%
s
old
style
good
StorageServerError
deletion
service
registry
INFO
North
service
task
task
instance
FYI
message
'South
Service
[
%
s
]
use
filter
pipeline
self._name
comment
Please
comment
C
path
vs
install
C-plugins
location
wrong
make
FOGLAMP_ROOT/cmake_build/C/plugins/
different
build
process
check
please
use
FOGLAMP_ROOT/plugins
directory
C-plugins
same
location
clear
suid
script
shell
script
id
execution
i.e
chmod
..
way
script
limited
snapshot
snapshot
directory
External
Services
Arg
foglamp-service-
*
e.g
foglamp-service-notification
add_filter
filter_plugin
filter_branch
filter_name
filter_cfg
foglamp_url
SVC_NAME
remove_directories
/tmp/foglamp-south-
.format
SOUTH_PLUGIN.lower
remove_directories
/tmp/foglamp-filter-
.format
filter_plugin
False
Just
+
.format
%
s
great
better
error
.format
%
s
+
better
.format
%
s
sure
specs
FoglampSnapUpdater
intuitive
status_message
=
execution
.format
status_message
HTtp
Internal
error
reason=status_message
yes
atleast
values
avg
int
float
valuable
thanks
//github.com/odoo/odoo/pull/30768
view
tour
Customize
tour
admin
OK.
view
demo
data
test
suggestion
contour
level
meth
method
contours
suggestion
set
contours
level
simple
example
docs
line
fs=1
correct
data
false
alarm
probability
example
examples
meaningful
variable
cols
xrays_short
=
]
change
cols
]
xrays_short
code
readable
python
code
GOES
signal
analysis
data
time
time
step
problems
signal
analysis
tricky
etc
impression
analysis
signal
periodogram
FFT
limitations
requirements
methods
people
methods
signal
Astropy
unsure
version
Astropy
documentation
last
sentence
Wait
signal.periodogram
same
signal.lombscargle
previous
series
side
links
Lets
RHESSI
TimeSeries
SunPy
sample
data
data
idea
input
Similar
Astropy
~astropy.stats.LombScargle
unit
Try
Sphinx
setup
last
sentence
alterantive
version
....
something
final
result
i
SciPy
~scipy.signal.periodogram
Line
break
consistent
data
SciPy
~scipy.signal.lombscargle
link
documentation
Make
link
astropy
version
available
SciPy
first
column
suggestion
Astropy
GeocentricTrueEcliptic
aberration
nutation
suggestion
Astropy
GeocentricTrueEcliptic
aberration
nutation
hek
code
optional
dependencies
property
meta
custom
something
someone
suggestion
sunpy.map.MapSequence
channel
imager
correct
angle
P
angle
Earth
solar
north
Earth
Earth
GCRS
north
suggestion
reference
coordinate
HPC
spatial
possible
info
header
Might
good
P
angle
suggestion
plot
map
contours
Questions/comments
sure
coordinates
GCRS
ICRF-based
frame
ICRS
shifted
origin
critical
difference
stellar
aberration
due
motion
coordinates
~20
arcseconds
GCRS
fact
correct
GCRS
keyword
arguments
obsgeoloc
observer
location
argument
equinox='J2000
anything
GCRS
frame
transformation
path
Helioprojective
suggestion
image
solar
north
submap
field
view
interest
units
cunit
degrees
other
words
python
lofar_pos
lofar_vel
lofar_loc.get_gcrs_posvel
obstime
reference_coord
=
SkyCoord
frame='gcrs
distance=sun.earth_distance
Sun-observer
distance
same
Sun-Earth
distance
something
lofar_gcrs
=
SkyCoord
lofar_loc.get_gcrs
reference_coord
=
SkyCoord
frame='gcrs
obsgeoloc=lofar_gcrs.cartesian
obsgeovel=lofar_gcrs.velocity
distance=lofar_gcrs.hcrs.distance
distance
component
HCRS
distance
Sun
suggestion
Lets
new
header
suggestion
orientation
HPC
coordinate
grid
GCRS
north
same
direction
HPC
north
convenience
func
relative
rotation
angle
due
subtleties
definitions
value
inaccurate
arcmin
equivalent
worst-case
shift
arcsec
HPC
disk
modification
space
comment
text
lines
comment
new
line
line
code
many
operations
line
comment
good
comments
line
code
line
doctest
+REMOTE_DATA
little
confused
comment
right
suggestion
Dimensions
data
suggestion
orig
array-like
Original
data
dimensions
tuple
suggestion
Sanitise
input
'type
input
corresponds
different
suggestion
fixture
tests
fix
master
rest
module
str
suggestion
suggestion
PEP
https
//www.python.org/dev/peps/pep-0565/
compliance
suggestion
files
Fido.fetch
qr
path=tmpdir.strpath+
./
Wouldnt
data
'alarms
]
.update
update_alarms
something
way
subscriptions
files
long
running
operation
task
hang
everything
same
behavior
dir
CallError
arguments
ToS
link
UI
point
IMO
implications
cryptic
way
root
uid
=
APIs
docstring
public
methods
pool
plugin
please
feels
strange
user
input
critical
code
messages
exist
B
mtime
>
mtime
B
elif
exist
B
better
way
file
open
w+
f
pass
write
syscall
Log
exception
please
cross-platform
different
way
Please
src/middlewared/middlewared/assets/account/builtin
Seems
couple
lines
defaultdict
collections
defaultdict
alarms
defaultdict
dict
key
alarm
listed_alarms.items
alarms
alarm.get
'read_path
[
key
]
=
alarm
method
public
docstring
Exisitng
comments
else
clause
sufficient
Comment
sysctl
module
synchronous
functions
sorry
last
comment
min
thread
workers
process
worker
excessive
pool
main
process
rare
possible
more
process
worker
Licence
comment
part
documentation
Add
attributes
Documentation
build
html
[
docs
]
https
//github.com/eora-dialog-systems/DeepPavlov/tree/master/docs
directory
wrapper
nice
example
.xml
.aiml
files
structure
docstring
need
local
import
[
uuid
module
]
https
//docs.python.org/3.6/library/uuid.html
id
generation
Return
path_to_aiml_scripts
required
argument
error
warning
scripts
self.path_to_aiml_scripts
idx
Are
skill
same
confidence
types
responses
May
test_quick_start.py
documentation
script
consultation
particular
iteration
test
first
fifth
component
returns
particular
responses
particular
user
Well
hello
history_of_responses
]
]
test
such
tests
hard
simple
test
suggestion
case
model
returns
highest
probability
whole
distribution
suggestion
TODO
better
def
train_model
config
[
str
Path
dict
]
download
bool
=
False
recursive
bool
=
False
>
Chainer
comment
different
variable
model
sounds
requirement
user
something
suggestion
way
intermediate
checkpoints
helpful
breadcrumbs
permission
setup
service
account
work
int64
wire
string
more
header
rows
understanding
suggestion
client.batch_write_spans
project_inside
[
]
raise
thing
sample
motivation
list
sample
Makes
sense
get_table
call
part
sample
suggestion
labels
time
redundant
call
tests
sample
sure
color
label
line
changes
source
list
return
value
additional
API
requests
suggestion
dataset
datasets
error
messages
gRPC
unexpected
HTTP/2
stream
termination
same
language
Nit
descriptive
names
set
comprehensions
m
leaks
local
function
scope
type_
something
monitoring
way
tests
CI
repo
separate
CI
setup
VPCSC
tests
Additional
setup
VPCSC
system
tests
os.environ.get
GOOGLE_CLOUD_TESTS_IN_VPCSC
=
true
Unset
PROJECT_ID
VPCSC
system
tests
project
VPCSC
perimeter
=
PROJECT_ID
GOOGLE_CLOUD_TESTS_VPCSC_OUTSIDE_PERIMETER_PROJECT
os.environ.get
PROJECT_ID
name
client
comment
lower
threshold
coverage
TODO
reminder
wheels
available
None
causing
problems
Link
GitHub
issue
more
context
Typo
beme
become
namespace
namespace
none
namespace
ancestor
value
curious
app
same
check
namespace
sure
argument
ancestor
value
track
variable
type
old
code
new
datastore
library
sequence
strings
new
library
variable
name
comment
errors
pass
broken
progress
bar
results
comment
total
cases
number
total
rows
populated
first
page
rows
progress
bar
total
accurate
count
pbar.total
=
pbar.total
comment
unnecessary
next
line
Comments
codebase
state
*
something
wrong
comment
pbar
intermediate
variables
line
more
self-explanatory
frames.append
self._to_dataframe_dtypes
page
column_names
dtypes
|
|
V
current_frame
=
self._to_dataframe_dtypes
page
column_names
dtypes
current_frame
progress_bar.update
current_frame
Nit
Import
built-ins
group
google-cloud-bigquery
Nit
linter
trailing
comma
assertion
expected
value
E.g
python
run_query_patch.assert_called_once_with
sql.format
num=17
Arrow
type
objects
dictionary
keys
factory
functions
describe
instances
data
types
https
//arrow.apache.org/docs/python/api/datatypes.html
factory-functions
equality
/
consistent
hash
Arrow
data
types
sure
alternatives
function
whole
bunch
statements
type
functions
https
//arrow.apache.org/docs/python/api/datatypes.html
type-checking
dirty
slow
more
guaranteed
correct
pandas
string
name
dtype
equivalent
Arrow
good
little
more
context
TODO
comment
support
change
try/except
pattern
maybe_import
*
function
tuple
modules
maybe_import
*
modules
[
]
arg
args
try
modules.append
__import__
arg
ImportError
return
tupe
[
None
]
*
len
tuple
modules
TODO
original
years
thing
nothing
TODO
Let
demonstrate
fields
name
index
suggestion
print
count=
.format
]
count
]
get_table
get_dataset
unnecessary
TODO
developer
Set
source_table_id
ID
original
table
source_table_id
=
your-project.source_dataset.source_table
TODO
developer
Set
destination_table_id
ID
destination
table
=
your-project.destination_dataset.destination_table
changes
FlowControl
BatchSettings
END
@
busunkim96
Let
talk
offline
such
service
account
Kokoro
environment
same
convenience
developers
actual
service
account
.json
key
file
course
os.environ.get
'false
snippets
work
WatchStream
Watch
client
first
request
response
request
FWIW
open
feature
request
method
https
//github.com/googleapis/google-cloud-python/issues/4553
method
something
line
load_table_from_json
consistent
load_table_from_dataframe
code
Are
developers
pre-existing
data
step
something
test
setup
test
accurate
public
object
public
Bucket
Policy
Only
correct
bucket
public
default
read
permissions
allUsers
allAuthenticatedUsers
bucket
policy
workaround
today
suggestion
logging
service
grpc
transport
channel
size
grpc
message
default
uncomfortable
use
None
semaphore
nothing
possibility
validator
value
None
general
kinds
scenarios
explicit
unambiguous
semaphore
method
def
_from_base_type
value
_nope
Base
value
strict
user
value
isinstance
value
SomeBaseType
return
SomeUserType
value
return
_nope
better
name
_nope
backwards
compatibility
considerations
point
posterity
anything
else
public
issue
tracker
internal
external
comms
suggestion
thing
==
suggestion
thing
=
order
possible
misunderstandings
method
self.api
object
SourceClass
instance
practice
suggestion
method
instance
Source
Class
api
attribute
wrapped
class
pragma
branch
code
coverage
check
branches
order
branches
different
subsequent
responses
rewrite
alright
tests
locations
_name
type
str
check
BQ
storage
client
sure
sample
errors
same
sandbox
version
sample
*
Edit
*
*
related
unit
aspect
comment
doubts
future
readers
Please
list_clusters_in_project
def
test_bigtable_list_clusters_in_project
[
START
test_bigtable_list_clusters_in_project
]
google.cloud.bigtable
import
Client
client
=
Client
admin=True
clusters_list
failed_locations_list
=
client.list_clusters
[
END
test_bigtable_list_clusters_in_project
]
assert
clusters_list.__len__
suggestion
[
END
bigtable_list_clusters_on_instance
]
suggestion
[
START
bigtable_list_clusters_on_instance
]
Comment
Nit
comments
capital
letter
consistent
@
thanks
review
PR
release
VMCI
little
bit
previous
comments
CLIENT_VERSION
VM
plugin
SERVER_VERSION
ESX
driver
Please
previous
comments
more
detail
feedback/response
comments
VMCI_VERSION
confusing
different
VMCI
versions
PROTOCOL_VERSION
little
bit
protocol
client/server
protocol
version
client
plug-in
version
server
driver
So
term
protocol
version
control
client
plugin
server
driver
internal
version
number
name
property
build
infrastructure
client
plugin
constant
CLIENT_VERSION
driver
constant
SERVER_VERSION
client
requests
server
CLIENT_VERSION
server
VMCI
CLIENT_VERSION
own
SERVER_VERSION
version
mismatch
Comments
confusion
PROTOCOL_VERSION
value
nothing
release
number
-please
comment
something
Server
side
understand
protocol
version
VMCI
PLEASE
DO
NOT
FORGET
TO
CHANGE
IT
FOR
CLIENT
file
<
file
name
>
Suggest
method
sys.exit
ony
main
thread
other
comments
os.signal
os.getpid
signal.SIGKILL
previous
comments
copy
==========================================
further
check
SIGTERM
signal
vmci_get_one_op
call
error
[
MainThread
]
[
DEBUG
]
lib.vmci_get_one_op
returns
-1
buffer
b
cmd
list
details
Name
version
[
MainThread
]
[
WARNING
]
vmci_get_one_op
ret=-1
Invalid
argument
errno=22
Retrying
Above
error
workflow
continue
vmci_get_one_op
call
above
check
loop
vmci_get_one_op
Please
note
exit
main
thread
wait_ops_in_flight
child
thread
comment
useless
real
estate
Could
comment
DB
schema
change
version
comment
commit
Sqlite3
execute
begin
transaction
sure
end
result
default
tenant
ALL_DS
something
point
design
quick
comment
change
e.g
default
tenant
ALL_DS
single
SQL
script
script
clear
end
result
Nit
tense
consistent
=
>
reach
rest
file
mean
nit
template
Nit
=
Just
code
flow
piece
section
vdvs
tag
file
function
section
vdvs
tag
new
section
old
section
newline
functions
behavior
Nit
empty
line
Nit
neach
=
>
Sure
suggestion
lines
more
python-ish
way
python
matching_datastores
[
d
d
get_datastore_names_list
d.lower
ds_name.lower
@
pdhamdhere
previous
comment
script
following
code
block
script
loss
i.e
volumes
datastore
docker_host
second
ESX
vmfs
vsan
accessible/visible
previous
comment
..
please
look
code
block
IMO
control
need
vmdk
data
111-111
folder
i.e
_DEFAULT
tenant
folder
old_dir
print
Skipping
.format
os.path.isdir
new_dir
print
Skipping
.format
<
====
modified
part
Prashant
previous
comment
print
Renaming
.format
comment
file
bin
proper
place
comment
nit
constrants
>
constraints
service
stores
None
anything
service
proper
modules
pwd
begining
comment
clear
example
comment
easier
logic
....
rsplit
]
Same
suggest
example
comment
logic
nit
new
line
end
json
text
log
print
kv_str
json
file
whole
code
simpler
something
mode
DBMode.MutiNode
arg.local
err_out
move_to_backup
return
mode
DBMode.SingleNode
args.unlink
err_out
rm
return
other
cases
Noting
Mode
=
<
mode
>
bad
idea
exception
way
command
line
main
proper
error
message
behavior
catch
connect
DBAccessError
blocker
time
free
comment
Ok
set_policy_to_vmdk
comment
set
call
VMDK
erro
Sure
VMDK
better
cases
error
VMDK
VMDK
set_policy_to_vmdk
call
VMDK
cases
error
eg
VSAN
policy
Pls
use
handle_stale_attach
vmdk_ops.py
relevant
fine
curious
exit
thread
new
thread
start_vm_changelistener
comment
correct
new
thread
start_vm_changelistener
thread
listen_vm_propertychange
function
call
rt
Did
Listener
restart
notifications
Listener
notifications
hostd
restart
new
SI
property
collector
listening
test
hostd
thread
thread
updates
hostd
restarts
Other
comments
code
behavior
hostd
restart
thread
updates
handle_stale_attach
stale
attach
check
separate
issue
Agree
codewise
good
function
return
thru
init
setup
wait
fact
code
function
init
si
filter
setup/prop
collector
wait
events
return
case
top
level
function
Could
VM
object
Fine
low
priority
issue
HOSTD_RECONNECT_INTERVAL
backoff
docstrings
sounds
good
Please
unreadable
current
one
good
IMO
good
docstring
lipingxue
feel
free
better
name
reasonable
length
Same
comments
comment
original
one
clear
rpath
sense
r
stands
rpath
fact
same
thing
symlink_path
Line
symlink_path
extension
present
comment
start
function
command
NOT
tenant
folder
Docker
volumes
<
datastore
>
/DOCK_VOLS_DIR
original
commenter
tenant_name
none
args
Nit
tenant
rm
=
_tenant_rm
consistency
Nit
tenant
=
tenant
Done
Please
Done
Done
govint
meant
api
tenant_update
default
DS
due
other
reason
PRIVILEGE_ALREADY_EXIST
default
DS
IMO
default
DS
_tenant_access_add
function
default
DS
default
DS
FWIW
length
line
code
simple
partial
fix
ErrCode
import
Error
code
ErrorCode
import
ErrorCode
generate_code_error
error_code_to_message
'from
ErrorCode
import
*
drop
error_code
prefix
set_default_ds
good
need
details
name
correct
info
datastore_url
clear
Could
more
Please
message
default
<
value
>
new
default
<
value
>
datastore
datastore
URL
datastore_url
valid
datastore_url
None
get_datastore_url
None
validate
call
None
magic
number
constant
SERVER_PROTOCOL_VERSION
sure
app
Ids
possible
frorm
dependencies
self.assertRaises
SystemExit
sufficient
other
tests
command
module
clean
telemetry_core.py
later
module
separate
process
az
process
traces
second
process
azure
cli
modules
later
module
separate
process
az
process
traces
second
process
azure
cli
modules
comment
limitation
TODO
searchable
Generic
comment
print
use
comment
Please
check_style
module
cognitiveservices
code
style
issues
file
pylint
blank
lines
first
level
entities
comments
obsolete
Do
command
help
doc
way
source
code
commented
code
pylint
rules
file
scope
follow
style
rules
pylint
disable
statement
legacy
code
base
process
Same
'azure.mgmt.cognitiveservices.operations.cognitive_services_accounts_operations
CognitiveServicesAccountsOperations
.format
python
+
custom_path
=
.format
python
+
leverage
.format
+
confirmation
mechanism
first
case
warning
user
consumption
message
print
logger
logger
troydai
/
@
tjprescott
other
recommendation
mechanism
fine
comment
Please
better
elaborate
test
name
more
test
cases
>
CLI
inconsistent
PS
API
ambiguous
RP
extension
RP
resource
scope
swagger
API
parts
ARM
resource
ID
separate
parameters
impossible
multiple
nested
level
resources
API
board
review
CLI
contract
names
multiple
levels
namespace
resource
type
arguments
API
unusable
inconsistent
PS
API
Feel
free
swagger
specs
PS
API
other
details
extra
line
help
lines
name
resource_group
other
relevant
resource
id
arguments.
resource-group
different
argument
group
comment
nicer
message
'Add
more
examples
custom
non-trivial
commands
kind
scene
//
uri
resource
=
resource
cli_ctx.cloud.endpoints.active_directory_resource_id
scenario
test
lock
scenario
something
lock
foo
Attempt
foo
lock
place
lock
foo
foo
lock
preferable
past
situation
someone
resource
lock
resource
group
lock
type
test
type
logic
error
due
regression
subscription
level
locks
TODO
fix
test
CLI
error
SDK
error
anything
minimum
call
test
subscription
other
locks
example
test
live
test
run
subscription
unpredictable
artifacts
test
other
new
tests
list
'show
command
right
level
good
time
TODO
checks
necessary
comment
TODO
line
line
issue
check
error
message
contains
specific
string
error-prof
case
CLIError
enough
information
code
source
issue
CLIError
more
information
new
exception
hierarchy
HTTP
response
errors
issue
https
//github.com/Azure/azure-cli/issues/1627
problem
comment
PR
better
solution
new
changes
cli
core
Will
concurrency
issue
command
table
initialization
thread
thread
file
issue
Dead
code
OSError
IOError
load_exception
OSError
/
IOError
file
issues
fresh
runs
e.g
build
agents
new
systems
parse
error
invalid/bad
data
file
files
data
get_logger
__name__
.info
%
s
default
settings
self.filename
t_JSONDecoderError
get_logger
__name__
.warning
file
%
s
default
settings
self.filename
project
pylintrc
files
max-line-length
disable
comment
lines
need
anything
curious
good
point
@
qwordy
_UserFault
_
prefix
telemetry
service
error
client
error
failure
suggestion
Command
Azure
CLI.
many
empty
class
definitions
MutuallyExclusiveArgumentError
>
pylint
disable=unused-argument
[
]
length
=
strange
argument
*
scopes
other
*
args
print
reason
information
information
please
use
logger
None
lines
file
long.
util
function
import
top
file
import
error
source
intention
comment
new
output
format
output
option
configure/_consts.py
Configure
yaml
format
output
option
behavior
introspection
methods
complex
object
comment
typo
expension
>
expansion
parameters
complex
type
descriptive
name
module
names
_
private
symbols
packages
IDE
PEP8
warnings
paper
bad
behavior
general
many
classes
functions
private
members
catch
login
login
password
parameters
method
method
parameter
argument
type
model
property
arguments
arguments
*
create
*
operation
[
]
https
//github.com/Azure/azure-sdk-for-python/blob/master/azure-mgmt-sql/azure/mgmt/sql/models/server.py
L39
better
way
parameters
mechanism
'parameter
argument
sdk
function
signature
base
type
object
parameters
command
line
c.expand
'parameters
Server
command
SDK
method
method
parameter
complex
type
value
type
initialize
properties
parameters
CLI
command
approach
readable
concise
patches
information
CLI
able
SDK
method
comments
command
definition
norm
other
command
module
better
approach
example
full
commands.py
commands
SQL
SDL
._util
import
get_sql_servers_operation
get_sql_database_operations
get_sql_elasticpools_operations
get_sql_recommended_elastic_pools_operations
ServiceGroup
create_service_adapter
server_operations
create_service_adapter
'azure.mgmt.sql.operations.servers_operations
'ServersOperations
ServiceGroup
__name__
get_sql_servers_operation
server_operations
s
s.group
server
c
c.command
'create
'create_or_update
c.command
'delete
'delete
c.command
'get_by_resource_group
c.command
'usage
'list_usages
c.command
'list
'list_by_resource_group
c.generic_update_command
'update
'get_by_resource_group
'create_or_update
s.group
service-objective
c
c.command
'list
'list_service_objectives
c.command
'get_service_objective
s.group
c
c.command
'create
'create_or_update_firewall_rule
c.command
'update
'create_or_update_firewall_rule
c.command
'delete
'delete_firewall_rule
c.command
'get_firewall_rule
c.command
'list
'list_firewall_rules
database_operations
create_service_adapter
'azure.mgmt.sql.operations.databases_operations
'DatabasesOperations
ServiceGroup
__name__
get_sql_database_operations
database_operations
s
s.group
'sql
database
c
c.command
'create
'create_or_update
c.command
'get
c.command
'list
'list_by_server
c.command
'usage
'list_usages
c.command
'delete
'delete
c.generic_update_command
'update
'get
'create_or_update
s.group
'sql
database
rl
c
c.command
'list
'list_replication_links
c.command
'get_replication_link
c.command
'delete
'delete_replication_link
c.command
'failover_replication_link
c.command
'force-failover
s.group
'sql
database
dw
c
c.command
c.command
s.group
'sql
database
rp
c
c.command
'list
'list_restore_points
s.group
'sql
database
tpe
c
c.command
'create
'create_or_update_transparent_data_encryption_configuration
c.command
'get-configuration
'get_transparent_data_encryption_configuration
c.command
'list-activity
'list_transparent_data_encryption_activity
s.group
'sql
database
sta
c
c.command
'list
'list_service_tier_advisors
c.command
'get_service_tier_advisor
elasticpools_ops
create_service_adapter
'azure.mgmt.sql.operations.elastic_pools_operations
'ElasticPoolsOperations
ServiceGroup
__name__
get_sql_elasticpools_operations
elasticpools_ops
s
s.group
elastic-pools
c
c.command
'create
'create_or_update
c.command
'delete
'delete
c.command
'get
c.command
'list
'list_by_server
c.generic_update_command
'update
'get
'create_or_update
s.group
elastic-pools
database
c
c.command
'list
'list_databases
c.command
'list-activity
'list_database_activity
c.command
'get_database
recommanded_elastic_pools_ops
\
create_service_adapter
'azure.mgmt.sql.operations.recommended_elastic_pools_operations
'RecommendedElasticPoolsOperations
ServiceGroup
__name__
get_sql_recommended_elastic_pools_operations
recommanded_elastic_pools_ops
s
s.group
elastic-pools
c
c.command
'get
c.command
'list
'list
c.command
'metrics
'list_metrics
s.group
elastic-pools
database
c
c.command
'get_databases
c.command
'list
'list_databases
context
definitions
groups
corresponding
SDK
class
command
groups
cascades
indentations
statement
readability
provider
easier
approach
command
definition
Same
parameters
definition
ParametersContext
c
import
Server
patches
administrator_login
administrator_login_password
server
creation
parameters
default
value
create_or_update
function
signature
arguments
c.expand
'parameters
Server
ParametersContext
command='sql
database
create
c
azure.mgmt.sql.models.database
import
Database
c.expand
'parameters
Database
paradigms
same
readability
code
organization
hood
same
cli_command
register_cli_argument
different
>
catch
login
login
password
parameters
method
method
parameter
argument
type
Server
Server
model
property
arguments
arguments
create
operation
process
method
complex
object
constituent
parts
registers
parameters
command
reassembly
constructor
complex
object
default
values
parameters
defaults
parameters
complex
object
constructor
CLI
party
contributors
>
patches
>
administrator_login
administrator_login_password
server
creation
>
parameters
default
value
create_or_update
function
>
signature
arguments
default
values
sufficient
SDK
sufficient
CLI
command
registration
cleanliness
perspective
long
crazy
strings
present
many
modules
@
johanste
perspective
project-wide
refactoring
justifiable
upcoming
deadlines
warnings
Such
WARNING
Error
config
file
/xyz/.docker/config.json
stat
/xyz/.docker/config.json
permission
ignore_errors
false
error
case
people
changes
constant
somewhere
nit
Obtain
too-many-instance-attributes
R0902
many
instance
attributes
%
s/
%
s
class
many
instance
attributes
simpler
easier
class
concern
_ensure_service_principal
grants
scope
contributor
spn
Suggest
[
code
]
https
//github.com/julienstroheker/azure-cli/blob/ba59b596ce4e1ff1d00276f37bf8c59145eea00b/src/command_modules/azure-cli-acs/azure/cli/command_modules/acs/custom.py
L1500
_ensure_service_principal
role
_add_role_assignment
'Contributor
service_principal
logger.warning
service
principal
right
permissions
Owner
project
Optional
bit
[
'windows
]
'Windows
'Both
constants
case-insensitive
comparison
comment
wrong
Same
comment
above
need
'Error
prefix
CLIErrors
CLI
red
color
available
ERROR
prefix
logger
whole
docstring
help
params.py
_help.py
docstring
commands
os-type
params.py
choice_list
param
possible
values
[
'Windows
'Linux
]
chart-url
params.py
default
value
string
default=
params.py
default
Please
avoid
doc
string
test
method
automation
process
Please
use
comments
same
Add
comment
regex
Should
exception
message
wrong
comment
exception
user
comment
own
line
Insert
space
following
character
scenario
baz
foo
az
foo
bar
foo
bar
inner
command
more
level
nestedness
discussion
Args
something
az
foo
az
baz
=1
regex
better
choice
such
API
later
SDK
values
indent
everything
structure
instance.notifications
return
instance
logic
notifications
return
instance
suggestion
method
accurate
needs
improvement
instance
shells
Windows
return
'cmd
common
logics
https
//github.com/Azure/azure-cli/blob/cfa31a7439e3d7dd4ff38fe03afd8a753a9cb19b/src/azure-cli/azure/cli/command_modules/storage/_validators.py
L1347
Might
private
key
safe
Way
setUp
tearDown
pair
same
logic
test
method
need
share
construction
test
methods
able
AttributeError
ValueError
CLIError
case
new
agent_poller
theory
delete
agent
pool
error
response
longrunningoperation
tests
better
least
message
troydai
work
.format
Python
long
line
string
lines
sample_str
=
'this
long
line
'string'
print
sample_str
Output
long
line
least
corrupt
Cloud
Config
debug
log
config
corrupt
comments
open
new
CI
issue
work
item
completer
server
name
nit
blank
line
sorry
test
vnet-rule
vnet-name
param
personal
todo
handle
links
dict
title
links
dictionary
CLI
links
azhelpgen
script
title
present
url
command
space
PEP8
length
list
results
more
properties
commented
code
Same
f
suggestion
self.assertEqual
Microsoft.Sql/servers/dbserver
candidate
ways
skip
sure
fine
suggestion
generation
history
notes
enum
Swagger
Yup
[
VALUE
]
]
construct
REST
endpoint
value
lab
secrets
double
bracket
service-side
construct
way
validation
user
admin-password
AND
saved-secret
usage
string
error
message
Same
SSH
resource_group_name
resource
group
name
list
subscription
string
empty
expression
resource_group_name
None
True
endregion
Again
useful
VS.
end
points
other
clouds
such
China
cloud
reason
Did
particular
reason
clarity
sake
Regular
import
straightforward
reasons
suggestion
azure.cli.command_modules.acr.import
import
_split_registry_and_image
Note
nice
comments
comments
redundant
Comments
logics
straightforward
code
verbose
code
readable
comments
Typo
KeyVaul
*
*
t
*
*
parameter
sense
same
keyvault
encryption
key
case
point
open
suggestions
sure
better
poor
readability
original
exception
benefit
original
exception
cli_ctx.data
'safe_params
]
resource_group_location
resource_group_name
backend
able
location
resource_group_name
resource_group_location
something
user
kind
exception
Same
line
module
grows
cumbersome
Most
modules
entry
line
disable
pylint
line-too-long
warning
Opinions
mine
favor
long
lines
types
method
None
good
way
something
values
[
db_name
db_type
]
values
first
case
values
error
return
None
part
todo
example
JSON
translate
painful
UX
Feel
free
time
options
params.py
file
top
license
header
THen
good
examples
command
_help.py
examples
possible
json
input
file
schedule-entries
@
entries.json
See
role/_help.py
example
@
Search
@
ad-role.json
cc/
@
tjprescott
conclusion
parameter
tags_type
int
something
-id
GUID
sort
JSON
strings
Tags
syntax
foo=bar
key=val
tenant
settings
complex
better
alternatives
name
ID
conventions
https
//github.com/Azure/azure-cli/blob/dev/doc/authoring_command_modules/authoring_commands.md
supporting-name-or-id-parameters
JSON
parse
space-separated
list
zones
integers
built-in
zones_type
able
help
text
clear
address
nit
typo
lambda
variable
use
function
definition
Same
thing
user
annoying
parameters
CLI
comment
Error
actual
message
logger.error
fatal
error
CLIError
Might
better
comment
stronger
Stack
profile
Please
name
message
more
clarity
move
_load_local_context_file
Let
comment
clear
purpose
comment
suggestion
LOCAL_CONTEXT_ON_OFF_CONFIG_SECTION
=
pylint
wrong
help
suggestion
def
check_for_new_examples
help_file
pylint
disable=unused-argument
pass
self.kwargs
.format
self.cmd
.format
kwargs
test
documentation
i
suggestion
key
=
self.cmd
digitaltwin
key
create
-e
endpoint
-r
role
user_role
repo
[
'id
]
clarification
comment
Clean
tearDown
pass
many
people
Windows
system
test
test
scenarios
sure
CI
system
tests
Linux
system
fine
test
CI
system
Linux
@
haroldrandom
awareness
addition
system
Windows
test
exception
consistent
message
enable
Better
comments
consts
cleaner
portable
specific
code
comment
consistent
https
//github.com/Azure/azure-cli/blob/dev/src/azure-cli/azure/cli/command_modules/acr/build.py
L66
feature
minimal
possible
change
original
code
ignore_list_size
redundant
least
catch
Exception
code
keyboard
interrupt
Same
>
[
]
length
=
silent_auth_only=True
tenant_id
need
code
ext_name
None
username
password
reason
exceptions
please
comment
points
test
beta
stamp
files
/
variable
files
reverse
order
files
infrequent
operation
bulk
unnecessary
commands
tune
stuff
top
auto-gen
template
Otherwise
everything
pre-filled
values
placeholders
kind
thing
someone
N'T
sensitive
information
oh
week
problem
safer
sanitized
values
user
actual
values
vice-versa
JasonRShaver
@
yugangw-msft
more
risks
same
risks
telemetry
line-too-long
warning
blank
line
statement
end
function
definition
good
idea
[
decorator
]
http
//thecodeship.com/patterns/guide-to-python-function-decorators/
function
assign
proxy
function
docstring
string
constant
'current
line
code
neat
suggestion
Unify
ISO
2020-06-30
short
same
line
Sorry
sense
instance
method
member
self._creds_cache
pattern
rest
code
place
pylint
disable
places
file
scope
way
pylint
checks
Add
pass
statement
syntax
error
runtime
errors
place
statement
next
line
function
statement
Please
empty
skeleton
Otherwise
please
short
description
method
style
skipping
legacy
code
base
good
practice
process
line
next
line
statement
wrong
something
container_name
None
container_group.containers
CLIError
container-name
container
group
more
container
comment
comments
comments
help
better
service_principal
pythonic
way
identity
comparison
None
test
is-enabled
parameter
value
Make
sense
feedbacks
customers
next
CLI
release
Azure
CLI
telemetry
az
find
command
past
month
percentile
~4.5s
response
services
percentile
same
time
period
<
lot
network
latency
timeout
most
users
>
way
az
next
project
scenario
error
>
PR
Link
[
click
]
https
//github.com/hackathon-cli-recommendation/cli-recommendation/blob/master/Docs/CLI_recommendation_design_doc.md
1-solution
>
similar
features
future
project~
😊
sure
Will
better
candidate
next
CLI
release
confidence
plan
logic
feedbacks
good
suggestion
Advice
disable
lines
Include
type=int
type
int
command
function
int
Same
need
comment
params
timeout
param
Great
test
good
coverage
helpful
test
method
smaller
one
few
benefits
Test
failure
accurate
test
body
small
accurate
test
report
large
test
execute
assertion
fails
following
test
logic
fewer
tests
test
logic
smaller
tests
Overall
unit
test
stages
Arrange
Act
Assert
files
>
objects
TODO
Install
libraries
>
library
other
options
@
click.option
helpful
tip
argument
case
name
secret
scope
options
required=True
same
comment
below
Just
bit
secret
scope
line
input
requirements
Azure
documentation
AWS
short_help
punctuation
end
consistent
databricks
help
info
%
databricks
[
PM
]
✭
Usage
databricks
[
OPTIONS
]
COMMAND
[
ARGS
]
Utility
Databricks
workspace
Workspace
paths
absolute
/
Options
-v
version
profile
TEXT
CLI
connection
profile
default
profile
DEFAULT
-h
message
exit
Commands
delete
objects
Databricks
workspace
rm
delete
export
file
Databricks
workspace
exports
directory
Databricks
workspace
import
file
local
Databricks
workspace
directory
Databricks
workspace
list
List
objects
Databricks
Workspace
ls
list
ls
List
objects
Databricks
Workspace
ls
list
mkdirs
directories
Databricks
Workspace
rm
objects
Databricks
workspace
rm
delete
comments
class
other
tests
comments
nit
let
indent
successful
~~list~~
*
*
mkdir
*
*
operation
Maybe
easier
operation
type
comment
sure
special
case
necessary/possible
RMM
available
DeviceBuffer
]
https
//github.com/dask/distributed/blob/4a8a4f3bce378406e83a099e8a12fc9bc12ef25c/distributed/comm/ucx.py
L50
]
https
//github.com/dask/distributed/blob/4a8a4f3bce378406e83a099e8a12fc9bc12ef25c/distributed/comm/ucx.py
L188
ok
code
preventive
measure
case
things
comment
obsolete
curious
use
Numpy
buffers
little
surprised
something
memoryview
s
harder
pure
Python
comment
suggestion
Client
communication
scheduler
default
global
client
way
multi-line
suggestions
self._events
collections.defaultdict
asyncio.Event
wrong
possible
event.clear
sort
thing
race
conditions
clear
great
clear
Seems
fine
unicode
string
prefix
dask
codebase
defaults
valuable
test
operations
dask-scheduler
bad-keyword
informative
arguments
cases
preload
mention
unknown
keywords
value
def
test_defaults
loop
popen
[
'dask-scheduler
no-bokeh
]
proc
@
gen.coroutine
def
f
Default
behaviour
addresses
[
assert_can_connect_from_everywhere_4_6
main
port
assert_can_connect_from_everywhere_4_6
HTTP
port
<
<
<
<
]
loop.run_sync
f
useful
start_services
argument
host
empty
change
ok
listen_ip
better
name
host
disclaimer
comment
least
comment
unreliable
hack
import
top-level
error
more
details
snippet
@
quasiben
point
pair
debugging
import
test
someone
better
way
free
python
distributed/utils.py:138
_get_ip
sock.connect
host
port
OSError
[
Errno
]
Network
unreachable
details
====================================
ERRORS
====================================
_____________
ERROR
distributed/comm/tests/test_ucx.py
______________
distributed/utils.py:138
_get_ip
sock.connect
host
port
OSError
[
Errno
]
Network
unreachable
above
exception
exception
distributed/comm/tests/test_ucx.py:15
<
module
>
.test_comms
import
check_deserialize
<
importlib._bootstrap
>
:983
_find_and_load
<
frozen
importlib._bootstrap
>
:967
<
frozen
importlib._bootstrap
>
:677
..
/
..
/miniconda/envs/rapids13/lib/python3.7/site-packages/_pytest/assertion/rewrite.py:152
exec_module
exec
co
module.__dict__
distributed/comm/tests/test_comms.py:48
<
module
>
EXTERNAL_IP6
=
get_ipv6
distributed/utils.py:169
get_ipv6
return
_get_ip
host
port
family=socket.AF_INET6
cytoolz/functoolz.pyx:476
cytoolz.functoolz._memoize.__call__
distributed/utils.py:148
_get_ip
socket.gethostname
port
family
socket.SOCK_DGRAM
socket.IPPROTO_UDP
..
/
..
/miniconda/envs/rapids13/lib/python3.7/socket.py:752
getaddrinfo
res
_socket.getaddrinfo
host
port
family
type
proto
flags
E
socket.gaierror
[
Errno
-5
]
No
address
hostname
error
collection
error
===============================
/details
walks
tasks
recomputes
things
ok
metrics
TaskPrefix
task
scheduler
normal
operation
numbers
necessary
general
dashboard
plots
better
little
work
data
possible
same
things
humans
things
scheduler
better
scheduling
decisions
future
work
scheduler
cheaply
more
cheaply
case
duration
TaskGroup
snippet
code
distributed/scheduler.py
startstops
L
=
[
[
start
]
[
]
startstop
startstops
startstop
[
action
]
compute
]
L
compute_start
compute_stop
=
L
]
rare
compute_start
=
compute_stop
=
None
compute_start
compute_stop
=
None
Update
Timing
Information
compute_start
ws.processing.get
ts
True
Update
average
task
duration
worker
old_duration
=
ts.prefix.duration_average
new_duration
=
compute_start
old_duration
avg_duration
new_duration
avg_duration
*
old_duration
*
new_duration
ts.prefix.duration_average
=
avg_duration
ts.group.duration
+=
new_duration
something
similar
transfers
other
components
manage
state
way
Might
nice
comment
import
time
problem
reasons
import
time
small
things
full
dashboard
code
user
prometheus_client
__init__
function
documentation
string
http
//docs.dask.org/en/latest/develop.html
docstrings
comment
good
state
comment
approach
test
function
OK.
Or
indentation
issues
Feel
free
top
level
imports
Sorry
confusing
comment
main
purpose
PR
windows
Maybe
OK
safety
net
crash
condition
suggestion
self.leases
lease
semaphore
client
latest
refresh
timestamp
Structure
client_name_1
lease_id_1
lease_timestamp_1
lease_id_2
client_name_2
=
defaultdict
dict
asyncio.wait
linear
iteration
things
gen.convert_yielded
Tornado
semantics
different
normal
async-def
semantics
gen.coroutine
objects
true
future_connect
lines
single
yield
connect
statement
convenient
nice
asynchronous
function
sync
synchronous
one
APIs
complete
Future
collection
check
key
=
tuple
key
list
msgpack
Single
line
break
duplicate
following
>
>
>
future
=
c.submit
div
>
>
>
future.status
>
>
>
future
ZeroDivisionError
division
zero
IPython
opportunity
pdb
>
>
>
%
pdb
Automatic
pdb
ON
>
>
>
future
ZeroDivisionError
division
zero
def
div
y
>
return
x
/
y
ipdb
>
Themes
changes
simplest
possible
example
users
input/output
pairs
comments
such
>
future.status
ZeroDivisionError
example
case
main
point
suggestion
bit
listener
side
timeout
handshake
tests
validate_state
fake
occupancy
figures
AssertionError
validate_state
Akshay-Venkatesh
do
same
https
//github.com/Akshay-Venkatesh/ucx-py/issues/69
different
sure
*
https
//github.com/Akshay-Venkatesh/ucx-py/issues/79
host
port
ucx
port
build
run
good
true
assert
handle_comm
compression
sure
comment
sure
test
suite
behavior
sure
comment
date
//github.com/Akshay-Venkatesh/ucx-py/issues/61
wrong
sure
TCPConnector
https
//github.com/Akshay-Venkatesh/ucx-py/issues/61
open
comment
abc
Listener.__init__
sure
Ideally
Dask
nbytes
function
works
bytes-like
objects
frames
Dask
further
XXX
leftover
previous
version
reasonable
mean
stray
unused
import
reason
separate
function
specific
need
normal
code
asynchronous=False
keywords
normal
Client
context
managers
sleep
nervous
specific
event
enough
small
computation
await
client.submit
inc
something
processes=True
LocalCluster
couple
seconds
time
test
tests
possible
self.cluster
awaitable
backend
Maybe
important
clear
suggestion
necessary
first
default
stream
start
default
stream
UCX
stream-ordered
default
stream
other
non-blocking
CUDA
streams
Note
sufficient
data
use
non-blocking
CUDA
streams
suggestion
default
stream
buffers
least
works
yes
case
invalidate_cache
upload_file
method
cases
same
way
sleep
call
upload_file
tests
tests
ext
'.pyc
logger.info
Reload
module
%
s
file
name
name
=
name.split
'-
]
reload
import_module
name
ext
==
import
pkg_resources
out_filename
pkgs
=
pkg_resources.find_distributions
out_filename
pkg
pkgs
logger.info
Load
module
%
s
egg
pkg.project_name
reload
import_module
pkg.project_name
pkgs
logger.warning
Found
packages
egg
file
ext
==
logger.info
Reload
module
%
s
.zip
file
name
out_filename
sys.path
sys.path.insert
out_filename
invalidate_caches
reload
import_module
name
invalid_caches
code
try
name
ext
=
os.path.splitext
filename
names_to_import
=
[
]
'.pyc
names_to_import.append
name
'.zip
sys.path
sys.path.insert
out_filename
ext
==
import
pkg_resources
=
pkg_resources.find_distributions
out_filename
pkg
pkgs
names_to_import.append
pkg.project_name
ext
==
names_to_import.append
name
names_to_import
logger.warning
Found
nothing
%
s
filename
invalidate_caches
name
names_to_import
logger.info
Reload
module
%
%
s
file
name
ext
reload
import_module
name
sleep
test
case
fine
call
invalidate_caches
test
'test_upload_file
case
.py
.pyc
files
same
way
pure=False
other
upload_file
test
i
other
tests
answer
http
//stackoverflow.com/questions/8122734/pythons-imp-reload-function-is-not-working
Ok
i
bigger
original
change
way
code
Python2/Python3
Is
good
way
forums
something
hasattr
importlib
invalidate_caches
importlib.invalidate_caches
distributed.compatibility
module
invalidate_import_caches
function
second
resolution
filesystem
importlib.invalidate_caches
https
//docs.python.org/3/library/importlib.html
importlib.invalidate_caches
Python
pure=False
case
cached
bytecode
file
Python
https
//docs.python.org/3/library/importlib.html
importlib.util.cache_from_source
Python
function
present
Done
Many
coroutines
private
list
reconnect
handle_report
Metaclass
first
approach
@
pitrou
method
asyncio/tornado
coroutine
easy
magical/implicit
scheduler
worker
metaclass
coroutine
classes
nice
way
asyncio
coroutines
due
ones
necessary
internal
use
fine
Client
public
API
Ditto
complex
suggestion
nodes
client_name
client
scheduler
scheduler
*
*
workers
suggestion
maximum
amount
memory
things
bit
cost
scheduler.semaphore_close
suggestion
>
>
>
def
access_ressource
s
sem
>
>
>
lease
semaphore
available
>
>
>
context
manager
>
>
sem
>
>
>
pass
>
>
>
>
>
>
futures
=
client.map
access_ressource
range
sem=sem
>
>
client.gather
futures
>
>
Once
semaphore
state
scheduler
side
>
>
sem.close
example
usage
semaphore
client
side
worker
usage
cleanup
more
straight
non-zero
value
client
get
semaphore
such
case
complete
duration
timeout
context
example
context-manager
api
resources
suggestion
return
self.client.sync
self.client.scheduler.semaphore_close
name=self.name
result
async
mode
asyncio.Future
caller
Suggest
small
typo
issue
further
discussion
suggestion
GitHub
https
//github.com/tornadoweb/tornado/pull/2008
issuecomment-312982780
relevant
stackimpact
sys._current_frames
profiler
similar
issues
integration
test
something
comment
@
jsrodman
bump
general
python
practice
function
expectation
exception
None
string-formatter
super
weird
reasonable
user
message
log-and-continue
programmer
error
likely
assert
valid
runtime
condition
caller
DCOSException
baseline
exception
CLI
exceptions
message
point
view
user
situation
programmer
error
logger.debug
.....
continue
None
presumed
value
OK
i
expected
usage
pattern
less
clear
sort
argument
tuple
icky
way
N/A
OK
private
function
tests
case
N/A
envvar
programmer
error
API/network/error
tests
code
least
N/A
feedback
user
ValueError
exception
s/name/envvar_name
Thanks
good
small
syntax
nits
CI
shipit
]
[
Step
]
dcoscli/config/main.py:195:80
E501
line
characters
]
[
Step
]
dcoscli/config/main.py:215:80
E501
line
characters
lets
check
exception
lets
DCOSHTTPException
wich
similar
error
message
Ah
sorry
comment
request
function
request
thought
good
something
similar
first
problem
everything
case
task_obj.dict
container
]
type
]
=
MESOS
Meaning
container
task_obj.dict
type
task_obj.dict
container
]
better
way
semantics
👍
lets
comment
lets
check
task_obj.dict
container
]
type
]
=
MESOS
ValueError
little
cleaner
nesting
ifs
username
ubuntu
train.csv
file
Could
example
user-specified
train/validation
split
errors
More
documentation
parameter
examples
logic
such
dtypes
columns
model
much
memory
model
Typo
SPLITTER
How
advantageous
different
dicts
AG_ARGS
dict
options
hyperparameters
argument
deep
amount
dictionary/list
nesting
postprocess_augmented
function
much
nothing
duplicate-removal
call
postprocess_augmented
function
original
function
case
duplicate-removal
future
50-50
duplicate
removal
all-categorical
datasets
data
distribution
number
epochs
maximum
number
epochs
Trainer
trainer
evaluation-metric
user
Can
TODO
comment
functions
Seems
opportunity
code
reduction
other
models
weight
decay
maintainers
import
lot
things
other
uses
libraries
torch
versions
criteria
call
model
variable
model
leak
make
HPO
infeasible
model
Note
NN
smaller
num_epochs
small-size
NN
something
'NN
'embedding_size_factor
'refit_full
version
Add
TODO
future
configs
hyperparameter_tune=True
training
time
inference-latency
matters
quality
>
predictive
accuracy
comments
more
clear
Yes
mxnet
training
loss
neural
network
file
ditto
comment
normalization
check
current
scheduler/reporter
nan
unclear
best
behavior
case
nan
good
idea
TODO
case
unified
way
nan
reporters
hours
minutes
states
AG
variable
consistency
hyperparameters
comments
separate
file
hyperparameters/
subdirectory
other
non-sklearn
models
standardized
lot
easier
users
hyperparameters
hyperparameter
'LR
dict
user
choose
'ridge
'lasso
undocumented
Trainer
code
hyperparameter
'penalty
option
LogisticRegression
'l1
something
informative
'penalty
'regression_option
'l1
'l2
options
Lasso
Ridge
thoughts
additional
hyperparameters
affect
categorical
non-language
features
ditto
self.model
.fit
.fit
self.model
=
model.fit
X_train
Y_train
Example
KNN
Should
=
super
.preprocess
X
code
crashes
line
self.features
solver
init
class
__init__
docstring
class
Py2.7
u
line
characters
E501
line
characters
E501
line
characters
kwargs
code
parse_options
]
https
//github.com/python-visualization/folium/blob/master/folium/plugins/polyline_text_path.py
L60
Please
docstring
defaults
None
Hi
@
Conengmo
thanks
review
commented
values
same
example
leaflet
plugin
ll
variable
coords
unpythonic
code
Cool
test
sure
offset
options
test
fail
E261
least
spaces
inline
comment
E262
inline
comment
good
docstring
user
GeoJsonTooltip
plugin
folium.py
copy-paste
error
previous
behavior
comment
order
change
values
color
first
last
color
bin
maps
example
color
scale
step
value
same
color
bin
warning
good
idea
warning
such
circumstances
behavior
last
option
unit
tests
fails
notebooks
branca
split_six
functions
*
weird
*
intervals
example
import
pandas
pd
folium
import
threshold_scale
=
branca.utilities.split_six
series=pd.Series
]
produces
]
color
threshold_scale
bit
simpler
if-else
statements
if-statements
something
wrong
happy
path
unindented
example
value
comment
suggestion
color_data.keys
return
value
if-statement
np.isnan
rest
fine
problem
finishing
touch
No
need
comment
E501
line
characters
E501
line
characters
F401
unused
F401
'folium.utilities._validate_location
unused
use
constants
virtualenv
official
way
😄
feels
hard
branches
various
shells
group
logic
per
shell
need
ifs
use
auto
number
character
list/dict
comprehension
👍
hmm
c
keyword
html
attribute
keyword-only
argument
verbose
name
f
filename
spec.origin
__init__.py
typo
Can
comment
characters
elif
absolute
undocumented
bpo-29688
]
https
//bugs.python.org/issue29688
check
bit
hackish
*
>
*
checks
Python
64-bit
[
platform.architecture
]
]
==
*
PROGRAMFILES
X86
os.environ
someone
environment
variable
32-bit
Windows
version
64-bit
32-bit
versions
]
https
//docs.python.org/3/library/platform.html
platform.architecture
link
prospector
issue
tracker
value
comment
context
Rather
_msgs_state
internal
concern
linter
private
variable
checker
number
jobs
fine
last
time
PR
warning
function
function
problem
function
definition
application
visit_functiondef
file
message
good
examples
instance
integers
strings
whatnot
Let
move
dict
construction
__init__
level
function
lot
large
projects
Trivial
line
return
sum
return_stmts
line
line
return
len
return_stmts
https
//github.com/PyCQA/pylint/blob/75a68fb5be105e138ca9527b0fc5c7e02b1a15e5/pylint/test/functional/too_many_boolean_expressions.py
L16
Let
couple
additional
test
cases
function
call
RHS
string
function
call
RHS
integer
functional
RHS
multiple
types
unknown
import
Unknown
place
Unknown
RHS
exceptions
same
exception
corresponding
message
situation
reasoning
nobody
exceptions
pragma
uppermost
base
class
comment
bit
confusing
function
__import__
ImportError
comment
bit
sure
responsibility
checker
variables
false-positive
suitable
term
simple
omit
short
macros
words
six.PY2
comment
grep
teh
time
comment
updating
Do
general
purpose
env
var
CRYPTOGRAPHY_OPENSSL_110
above
names
older
names
way
compiler_type
msvc
CRYPTOGRAPHY_OPENSSL_110
course
flag
affect
windows
line
longer
char
max
linter
happy
sig.count
comment
deal
info
initial
PR
comment
smile
indices
secret
key
bytes
public
key
bytes
public
key
bytes
message
bytes
signature
bytes
message
bytes
djb
vectors
bit
weird
concatenate
info
ways
key
wrong
length
OPENSSL_EC_NAMED_CURVE
constant
Please
magic
comment
syntax
grep
Same
thing
Follow
condition
key_to_wrap
r
branch
easier
padding
key_to_wrap
Tiny
nit
please
highlight
querystring
private
module-level
constant
ValueError
valid/acceptable
test
case
happier
language
quadratic
residue
quadratic
nonresidue
SO
good
everything
/12961/
Note
Rest
explanation
fine
happier
comment
someone
git-blaming
heck
_me_
different/better
suggestion
nid_key
=
OpenSSL
default
LibreSSL
RFC
anything
valid
revoked
extension
single
response
extenion
case
comment
fixed
length
assert
obnoxious
comment
other
AEAD
internal
error
comment
comment
ASN.1
parsing
everyone
hand
comment
reason
issue
PyInstaller.compat
sophisticated
method
base_prefix
different
kinds
virtual
environments
reason
yu
Did
code
conda
+
virtualenv
resp
conada
+
pyvenv
honest
aware
PyInstaller.compat.base_prefix
Nevermind
lines
chars
travis
happy
comment
command-line
hooks
user_hook_dirs
highest
priority
list
priority
order
lower
index
higher
priority
Next
PyInstaller
hooks
code
entry
points
hooks
code
building/build_main.py
line
entry
points
need
abspath
get_package_paths
returns
absolute
paths
later
part
something
GNU/Linux
external
dependency
libsndfile
Please
PyInstaller.compat.is_win
resp
….is_darwin
old
code
py_2
block
new
code
else-part
easy
old
code
Py
EOL
support
PyInstaller
care
Py
course
Py
accepts
teh
syntax
exec_statement
hook
hiddenimports
names
modules
str
s
case
suggestion
hiddenimports.append
Just
fun
comment
[
:1
]
Allow
match
something
Exclude
compat.ALL_SUFFIXES
https
//github.com/pyinstaller/pyinstaller/issues/5115
issuecomment-686970098
explanasion
More
suggestion
ALL_SUFFIXES
excludes.append
*
*
/
*
.pyo
ALL_SUFFIXES
excludes.append
*
*
/
*
.pyc
depending
version
PyInstaller.utils.hooks.is_module_satisfies
e.g
PyInstaller/hooks/hook-botocore.py
Please
something
variable
setup.py
hard
obvious
one
libdir
preferred
Please
short
comment
overlay
only
short
comment
overlay
present
ndb.Model
classes
id
field
typeinfo
list
list
type
element
list
other
docstrings
examples
>
Please
TODO
issue
GitHub
comment
swap
present
comment
future
readers
context
cli
>
CLI
first
time
command-line
interface
CLI
verb
methods
verb
verb
phrases
documentation
function
Returns
possible
path_to_delete
lot
trouble
function
.lower
Needs
explanation
previous
comment
file
names
dir
names
name
directory
means
one-liner
[
name
directory_names
name
possible_file_names
]
change
==
=
next
lines
comment
line
comma
commands
Should
whole
dir
case
loop
combine
general
condition
loop
isdir
beginning
private
methods
tests
https
//github.com/oppia/oppia/wiki/Writing-backend-tests
common-testing-scenarios
guidance
private
methods
Ditto
file
get_all_contribution_reviewers
list
objects
reviewers
contribution
rights
name
users_contribution_rights
wrong
use
constants
build.py
comments
Nit
consistency
comment
period
consistent
other
comments
method
comments
collection
version
collection
model
collection
objects
backend
latest
schema
version
update
schema
version
last
comment
deletion
function
summary
exploration
order
special-casing
test
summary
object
deletion
function
exception
exploration
summary
collections
sure
summary
explorations
summary
explorations
collections
Typo
Please
comment
need
pragma
something
'summary
exceeds
'the
character
limit
Try
pragma
possible
work
job_id
=
feedback_jobs_one_off.FeedbackSubjectOneOffJob.create_new
comment
future
devs
update
docstring
other
noteworthy
aspect
constant
pseudonymization
lines
altchars
b
characters
remain
type
unicode
idea
altchars
last
chars
base64
charset
LOL
Fixed
imghdr
new
line
square
bracket
lint
pragma
good
idea
comment
bit
info
lines
TODO
pranavsid98
clear
TODO
seanlip
test
_init_
function
tests
save_new_exploration_from_yaml
_Create_exploration
job
creation
v1
dict
comment
first
code
block
function
test_creation_of_jobs_and_mappings
good
integration
test
end-to-end
flow
unit
tests
later
comment
classifier_services_test
Done
logic
_not_
pseudocode
way
simple
clear
reader
possible
Let
try
something
@
anmolshkl
@
prasanna08
order
sure
same
page
couple
other
comments
exploration
earlier
version
classifiers
earlier
version
new
ones
above
point
kind
important
classifiers
version
possible
sure
v1
job
way
v1
job
queue
v2
output
v1
job
Otherwise
job
something
further
queue
@
anmolshkl
sort
mess
bit
pseudo
code
entire
logic
flat
AFAICT
version
mapping
version
job
ad
hoc
implicit
info
version
code
code
unmaintainable
correct
version
get-go
get_classifier
exp_id
exp_version
state_name
state_name
fact
exp
version
attributes
bit
misleading
as-is
context
version
classifier
seanlip
new
job
incremented
exp
version
classifier
job
right
version
little
confused
code
exp_version
exploration
job
code
exploration
part
save
process
able
correct
version
number
code
jobs
right
version
number
StoreJobResult
controller
code
clear
exploration
version
save
save
suggestion
exp_id
necessary
states
version
job
exploration
states
version
incrementing
version
numbers
misleading
docstring
Creates
new
ClassifierExplorationMappingMode
....
names
seanlip
exp_version
function
old
new
one
version
very
end
save_exploration
function
function
old
classifier
context
add_to_training_queue
function
save_exploration
part
model
checks
save_exploration
version
increment
issue
version
increment
function
job
Done
part
code
btw
next
commit
dont
>
worth
point
comments
dict
suggestion
@
seanlip
possible
job
right
version
classifier
same
version
StoreJobResult
controller
classifier
controller
exp_version
job
commits
comment
more
information
Just
information
new
states
old
classifiers
Sorry
previous
version
previous
state
@
pranavsid98
Sean
solution
correct
clean
add_to_training_queue
jobs
exploration
correct
explanation
classifier
job
old
version
obsolete
Ditto
try
single
*
_multi
Thanks
docstrings
tests
job
id
job_id
Just
write
docstring
function
client
responsible
job
ID
valid
valid
TrainingJobExplorationMappingModel
instance
clients
lot
extra
GET
datastore
Done
fine
problem
training_data
size
all_jobs
Ignore
previous
comment
way
Done
first
assert
job
self.assertEqual
all_jobs
all_jobs
element
id
@
anmolshkl
all_jobs
utterable
data
type
list
Iterables
length
attribute/function
updation
>
update
Updation
word
seanlip
EDIT
comment
issue
mapping
creation
get_trainable_states_dict
method
_save_exploration
function
access
change_list
list
Exploration
changes
change_list
sub
functions
arg
able
State
renaming
case
way
GET
operation
bit
iffy
Anyone
reading
mapping
new_states
old_states
old_state_name
old_states
people
confused
clear
comments
@
pranavsid98
fine
small
change
significant
change
comment
comment
account
other
scenario
point
comments
new
state
state
change
answer
groups
old
renamed
state
change
name
comment
Wrap
next
comment
line
todo
Done
Same
comments
non-happy-paths
clearer
names
tests
Per
comments
oppia-ml/26
case
function
function
docstring
need
more
comment
line
oppia_tools/
available
dev
mode
GAE
production
server
oppia_tools/
available
default
PIL
third-party
library
DEV_MODE
possible
Oppia
production
mode
built-in
PIL
available
Hence
check
oppia_tools
Add
comment
skill
IDs
comma-separated
list
GET
request
Use
line
comments
triple-quoted
strings
latter
method-level
docstrings
codebase
None
correct
Update
comment
superclass
field
overridden
comment
format
queries
types
component
parts
previous
generation
user
last_logged_in
=
None
Might
part
simulation
None
start
test
drop
comment
top
line
docstring
newline
format
line
docstring
more
details
Args/Returns/Raises/Yields
sections
while
super-generic
variable
names
value
item
sub_item
union
bunch
lists
something
Combine
values
multiple
lists
single
list
error
type
yield
key
.union
*
values
Reference
https
//stackoverflow.com/a/2151553
last-minute
thing
comment
clear
Please
comment
type
LGTM
change
Ah
concepts
admin
oppia
access
skills
user
ROLE_ADMIN
is_super_admin=True
Ditto
collection_editor
non
collection_editor
tries
access
page
status
decorator
can_access_admin_page
status
sure
same
exception
acl_decorators.py
topic
admins
>
admins
Might
topic
manager
Break
[
coding
style
guide
]
https
//github.com/oppia/oppia/wiki/Coding-style-guide
python
Ditto
Just
actual
value
variable
repetition
updated_dict
]
.to_dict
bit
naming
_convert_states_v32_dict_to_v33_dict
list
non-dicts
worth
name
'=
line
way
additional
'question_id
'skill
parameters
step
necessary
test
name
collection_services.get_acquired_skill_ids_of_user
type
information
End
period
comma
comment
return
statement
part
docstring
lines
584-589
Ack
blocking
comment
approval
Thanks
great
note
spelling
pr
>
PR
SECURITY
isort
skip
Minor
nit
complete
sentence
aks681
TODO
check
sure
other
fields
subtopic
TODO
actual
migration
function
pattern
stuff
more
explain
detailed
clear
comment
list
explanation
separate
paragraph
NOTE
TO
DEVELOPERS
more
files
list
questions
talk
srijanreddy98
classes
import
something
Maybe
extract
//
constant
interpolation
%
%
access_token
import
apb7
linter
possible
better
CMDs
correspond
actions
UI
E.g
story
node
update
story
property
fine
story
properties
e.g.
strings
lists
dicts
stuff
much
update
update
tiny
part
frontend
args
cls
story_id
docstring
brand-new
story
save_story
story_domain
story_domain.CMD_CREATE_NEW
sure
search
functionality
stories
search
functionality
necessary
stories
topics
user
perspective
docstrings
version
usual
way
dummy
name
front
realistic
avoids
possible
shadowing
errors
types
IDs
distinct
superclass
docstring
Ditto
Docstring
wrong
re
notes
argument
unused_
unused
Docstring
wrong
schema
version
sub-dict
topic_id
story
contents
TextProperty
character
limits
reader
pointer
definition
story_contents
domain
layer
domain
object
StoryContents
higher
schema
version
next
field
Docstring
wrong
collection
canonical_story_count
additional_story_count
reasonable
former
sort
requirement
latter
optional
Vague
Just
description
topic
Note
StringProperty
limits
GAE
docs
TextProperty
Docstring
wrong
json
fields
previous
line
similar
comments
required=True
Might
index
story_count
skill_count
See
comment
re
comment
tolerance
second
models
created_on
same
time
milliseconds
other
such
cases
created_on
greater
second
thoughts
tolerance
second
sufficient
rule
complete
block
single
line
suffice
lint
checks
possible
least
naming
part
other
question
comment
threads
rte
rich-text
editor
comment
sense
Please
Please
docstrings
files
format
particular
first
line
docstring
newline
break
implementation
detail
caller
internal
mechanism
perspective
someone
outside
code
file
clear
succinct
summary
method
one-line
summary
docstring
Imports
storage
models
model_names
Add
line
comments
context
newline
line
lines
111-116
block
first
other
words
please
comment
first
one
Added
comment
None
entities
target
comment
speedup
X
%
querying
individual
fields.
Hi
@
vibhor98
space
indentation
Raises
InvalidInputException
Inputs
invalid
exploration
updation
PageNotFoundException
exploration
data
user_id
exploration_id.
constant.SUPPORTED_AUDIO_LANGUAGES
such
voiceovers
translations
sure
generic
name
OR
is_valid_language_code
SUPPORTED_AUDIO_LANGUAGES
method
exploration
language
method
sure
translation
Hinglish
exploration
Hinglish
translated
text
exploration
player
future
functionality
comment
difference
deletion_complete
former
cached
value
latter
if/elif/else
outer
parens
Please
human-readable
name
warning
W0212
Add
comment
Just
exception
text
descriptive
text
frontend
frontend
deal
error
separate
error
class
comment
Python
code
detail
Might
actual
i.e
edge
cases
evaluate
true
example
content
literal
text
oppia-noninteractive-collapsible
actual
tag
collapsible
tabs
convert_tag_contents_to_text_angular
nothing
if-check
add
comments
docstring
convert_tag_contents_to_textangular
function
content
tabs
collapsible
*
components
*
nothing
check
get_text
comment
cases
href
attribute
link
empty
text
comment
headers
own
test
case
Please
Add
comment
user
IDs
usernames
Oppia
Bot
usernames
>
usernames
dict
make
>
dict
make
>
Replace
comment
Disallow
system
strings
admin
oppia
comments
current
situation
sure
bit
more
explanation
profiles
gae_id
field
empty
way
profiles
migration
job
PR
release
migration
gae_id
way
user
way
gae_id
points
things
future
migration
job
modifications
necessary
others
opinion
@
vojtechjelinek
TODO
+
issue
job
migration
instructions
job
post-check
number
models
various
different
types
same
suggestion
self.assertItemsEqual
output
]
expected_output
self.assertItemsEqual
[
]
TODOs
imperatives
I.e
Deprecate
gae_id
UserSettings
UserAuthModels
user
need
last
sentence
comment
info
model
first
glance
nothing
auth
*
Minor
nit
previous
code
add
period
end
class
level
standard
construct
way
UserSubscriptionsModel
@
property
method
class
external_id_relationships
such
validator
validate_external_id_relationships
method
validator
dict
Nit
>
Let
domain
something
learner_dashboard_activities
learner_dashboard_activities
=
learner_progress_services.get_learner_dashboard_activities
similar
activity_ids
list
activity
IDs
other
contexts
current
formulation
Add
context
optional
TODO
+
issue
change
migration
job
repeated=True
sign-in
Let
newline
above
logic
sense
method
such
.export_data
model
list
User
data
takeout
Models
loop
export_data
data
dict
way
future
new
model
class
User
data
takeout
Models
list
lines
paren
more
line
break
Ditto
fake
deterministic
comment
everything
good
idea
creation
start
method
whole
bunch
definitions
test
data
test
middle
definitions
bit
weird
Bring
single
line
creator
explorations
typo
space
Reword
explorations
dashboard
query
load
explorations
Similar
replied
quantity
exploration
response
=
self.get_json
response.DASHBOARD_DATA_URL
self.assertEqual
response
[
'explorations_list
]
,2
Ditto
linter
shivanXI
linter
@
shivanXI
line
greater
chars
multiple
lines
sure
lines
comments
char
limit
@
seanlip
linter
Move
comment
line
Ditto
private
API
class
tests
unexpected
situations
such
implementation
API
something
new
interface
behaviors
same
most
places
code
single
line
pylint
pragma
char
line
limit
pragma
such
occurrences
single
line
Ditto
explanatory
test
names
tests
long
well-written
comment
check
code
possible
parent
roles
actions
Test
get_all_actions
works
+1
necessary
default
defaulting
storage
layer
seanlip
multiple
filters
different
params
single
query
sophiewu6
other
ideas
references
index
-1
bit
messy
general
way
reader
significance
-1
dict
question
data
Indent
previous
line
Ditto
ID
collection
question
use
ID
capitals
PR
id
Docstring
wrong
question
data
default
value
careful
validation
client
correct
format
test
meaningful
updates
stats
confident
v3
stats
v1
stats
v2
ones
worth
string
constant
comment
constant
able
app
engine
third
party
code
Add
comment
comments
apply
following
stanzas
size
logging_info
comment
]
code
clear
developers
surface
reading
non-moderator/admin
start
comments
capital
letters
end
full
stops
full
path
use
os.getcwd
similar
DIR_PATH
FILE_PATH
name
list
tests
Explain
relative
path
mention
dtslint
cwd
path
absolute
path
os.getcwd
Change
GitPython
imported.
difficulty
value
easy
questions
similar
docstrings
other
newline
newine
middle
hard
constants
reason
docstring
other
thread
Please
change
original
plan
one-off
job
correct
value
open
one-off
job
PR
lines
pragma
._convert_states_v30_dict_to_v31_dict
[
voiceover
]
.keys
langauge_code
things
something
original
data
type
integer
format
frontend
UI
next
milestone/PR
value
integer
anyways
pre-download
timer
type
integer
problem
JS
number
float
int
JS
defaults
keys
content
Id
Solution.
solution
card/question
draft_upgarde
service
Please
reason
duration
audio
value
Explicity
explicit
=
explicitly-defined
capture
group
much
exact
match
possible
e.g
RUN_E2E_TESTS_
TESTS_
Ditto
=
line
lengths
=
contents
protractor.conf.js
string
Again
more
precise
docstring
previous
function
string
dict
confusing
e2e
jobs
jobs
function
get_e2e_suite_names_from_travis_yml_file
similar
extract
travis
job
section
entire
section
case
Ditto
other
functions
careful
naming
precise
possible
positive
lookahead/lookbehind
stuff
something
r'RUN_E2E_TESTS_
[
A-Z_
]
*
\=
suffice
Same
thing
regexes
simple
possible
capture
group
regex
order
part
regex
capture
groups
way
-5
intention
clear
code
I.e
regex
RUN_E2E_TESTS_
=true
part
module-level
constant
function
TEST_SUITES_NOT_RUN_ON_TRAVIS
scripts
unclear
suites
scripts
Please
precise
possible
docstrings
Ditto
previous
function
docstring
sound
element
list
kind
job
object
reality
suite
names
e2e
test
jobs
Say
something
alphabetical
order
result
Ditto
Break
line
way
line
contents
Drop
period
js
Hm
suite
object
suite
object
list
strings
string
name
name
bit
weird
something
matching
general
whitelisted
charset
[
A-Za-z-_
]
*
regex
specific
possible
cleaner
conveys
intention
more
use
regex
capture
groups
clear
contains
v2
stats
v2
fields
Might
comment
name
domain
object
dict
dicts
_dict
domain
objects
preliminary_exp_stats_dict
something
similar
comment
Generate
preliminary
stats
version
events
notification
good
more
applicant
language
Could
TODO
TODO
core/tests/protractor_desktop/embedding.js
pointing
same
issue
future-proofing
constant
several
lists
tuples
type
interaction
id
rule
type
name
E.g
[
x
]
backend
test
constant
extensions/rule_templates.json
correct
method
iterate
constant
assembly
html
list
trouble
original
comment
pretty
sure
branch
MR
job
worth
TODO
Did
add
TODO
'else
bit
sure
thread
message_count
comment
long
function
anything
code
good
Added
TODO
GETs
loop
PR
get_multi
job
results
models
ClassifierDataModels
I.e.
latter
rid
Ah
thanks
case
time
PR
classifier_data
job
model
single
get_multi
classifier
jobs
nothing
important
learner
view
fast
seanlip
get_multi
jobs
jobs
ClassifierData
models
ClassifierData
classifier_data
front-end
classifier_data
field
job
get_multi
job
sufficient
Yep
Lets
deprecate
ClassifierData
individual
GETs
loop
merge
ClassifierDataModel
PR
seanlip
first
Prasanna
PR
frontend
Code
classifier
service
GSOC
project
general
ClassifierDataModel
deprecation
blocker
more
optimisation
certain
GETs
loop
better
deprecation
Ah
OK
info
comment
inline
other
self.swaps
Thanks
new
approach
check
creation
time
playthrough
everything
comment
object
index
pop
invalidate
Nit
more
line
index
line
number
line
numbers
config_line_parts
]
splitting
'\s
*
=\s
*
spaces
writelines
let
print
convention
TODO
your_name
blah
NOTE
name
TODO
commitment
name
person
todo
next
field
ROLE_ACTION_UPDATE
ROLE_ACTION_VIEW_BY_USERNAME
ROLE_ACTION_VIEW_BY_ROLE
action
ROLE_X
ROLE_MODERATOR
ROLE_ADMIN
ACTION
name
ROLE_UPDATE
ROLE_VIEW_BY_USERNAME
ROLE_VIEW_BY_ROLE
fine
intent
Suggest
first
values
case
patterns
particular
class
case
specific
jobs
first
X
representative
expressions
explorations
constant
above
class
level
entire
module
specific
particular
job
naming
sound
generic
ambiguity
exploration
vs
expression
individual
strings
constants
ALLOWED_ISSUE_TYPES
=
[
ISSUE_TYPE_EARLY_QUIT
]
constants
feconf
multiple
modules
controllers
sense
territory
usage
narrow
stats_models
comment
strings
list
typo
comment
num
represent
code
comment
last
lines
sense
English
sentence
Please
reword
list
'\n'.join
error_messages
similar
general
plural
names
lists
last
lines
Comments
apply
new
method
necessary
information
regex
general
stuff
:1
-1
hard
numbers
re
naming
conditions
lines
Same
comment
above
sure
key
occurrence
Btw
stuff
hold
case
successful
linting
Ditto
other
classes
time
docstrings
style
args
TODO
fault
suggestion
PopulateMessageCountOneOffJob
names_of_ndb_model_subclasses
names
models
Please
specific
whole
test
suggestion
TODO
RatioExpressionInput
consistency
Drop
space
lesser
>
less
increase
>
increases
Latex
>
LaTeX
expression
Ditto
condition
field
true
valid
image
present
prod
validation
jobs
Probably
required=True
default
model
everything
required=True
force
callers
methods
Set
>
List
unique
latex
>
LaTeX
part
docstring
latest
value
svg
*
better
name
svg
images
corresponding
exploration
internal
structure
property
list
strings
ndb.StringProperty
repeated=True
Same
prod
validation
correct
size
IntegerProperty
images
wise
upper
limit
bit
room
e.g
MB
max
number
entities
time
OK
admin
button
bit
network
latency
number
items
problem
Could
detail
comment
Ditto
pylint-disable
comment
break
many
handlers
AddActivityToLearnerPlaylistHandler
RemoveActivityFromLearnerPlaylistHandler
Pass
activity
type
activity
ID
frontend
EDIT
see
comments
main.py
line
next
comments
redundant
Hi
@
prasanna08
comment
Please
issue
reference
external
folder
consistency
naming
system
comments
variable
names
pylint
disable=protected-access
function
name
self.user_id
Hi
@
apb7
i
understood
[
link
]
https
//docs.google.com/document/d/1HvfFCaKokGNiCkudrVfZCZ9N08wOGGDfYKsvgUQEgK4/edit
need
>
needs
frontend
file
similar
comment
frontend
file
Btw
TODO
TODO
second
sentence
language
preferences
sentence
one
useful
context
suggestion
Name
user
Android
UI
Unlike
username
unique
profiles
account
profiles
useful
fields
category
use
profiles
accounts
info
comment
different
preferred_language_codes
comments
user2
deleted=True
User3
different
user1
sense
more
attributes
None
attributes
None
deletion
more
storage
models
separate
tests
comment
Thanks
profile
users
tests
convention
https
//github.com/oppia/oppia/wiki/Writing-backend-tests
guidelines-for-writing-good-tests
Point
order
action-withCondition-outcome
Which
Same
[
]
https
//github.com/oppia/oppia/pull/10105/files
r464722524
comment
Done
memcache
comment
consecutive
mean
Consecutive
*
*
comment
more
clear
comment
relevant
line
single
space
style
draft
change
list
id
>
draft_change_list_id
property
Strike
user_id
unclear
ID
model
ID
person
name
Please
clearer
extra
clarity
admin
user
different
user
username
user_id
unclear
follow-up
discussion
@
varun-tandon
@
seanlip
Varun
clearer
alternative
MODEL_TO_USER_ASSOCIATION
constants
reference
something
MODEL_TO_USER_ASSOCIATION.NOT_CORRESPONDING_TO_USER
suggestion
below
more
detail
takeout
ID
term
value
field
key
Takeout
dict
comment
item
example
DELETION_POLICY
seanlip
while
names
happy
docstrings
Sean
thoughts
My
original
names
much
different
same
page
line
comment
Add
line
comments
applicable
ditto
next
field
nodes
node
IDs
Mention
docstring
instance
datastore
returns
instance
class
docstring
create
function
names
semantic
meaning
expr1
expr2
node
tree
leaf
nodes
case
children
list
empty
docstring
abcd
identifier
greek
letters
time
form
next_token_index
private
relevant
comments
lifecycle
other
functions
parse
private
relevant
modifications
tests
methods
tests
such
checks
production
rules
functions
functions
test
scenarios
function
production
rule
docstring
expected
output
detailed
comment
criterion
valid
future
constraints
such
change
script
test/assert
Better
comment
backend
test
scripts/release_info_test.py
fine
someone
directive
indents
everything
spaces
right
constants
Same
note
tests
sections
adjacent
release
summary
file
backend
tests
comment
check
script
pylint
pragmas
multiple
lines
Please
comment
dict
invalid
Maintainers
Please
clear
comment
lines
refer
next
line
comment
Use
utils.is_supported_audio_language_code
translation
languages
part
audio
languages
Note
utils.is_valid_language_code
error
Hinglish
language
translation
TopicSimilaritiesModel
singleton
id
top
class
line
comments
field
enough
flow
bit
suspect
dict
mapping
old
state
names
corresponding
state
stats
commit
list
dict
state
stats
correct
end
new
version
dict
new
state
names
keys
moment
clear
cases
state
identity
account
>
accounts
word
mapping
iffy
state
renames
loop
bunch
add/delete/rename
commands
other
things
E.g
state
single
changelist
Compute
=
new_to_old_state_names.values
loop
same
computation
N
times
models
date
new
learner
events
release
models
PR
tests
careful
comments
main
code
important
tricky
cases
multiple
actions
changelist
care
stuff
stuff
setup
function
sense
creation
setup
function
individual
tests
model
>
models
pathes
>
paths
pathes
>
paths
end
paths
file
URLs
url
interpolation
service
filepaths
>
whole
message
special
characters
..
comment
Wait
special
characters
error
message
filepath
anything
File
problematic
perspective
comment
necessary
Please
comment
need
above
cases
controller
oppia-internal
thing
care
comment
clear
new
developers
file
conventions
Spelling
python
Please
comments
system
stdlib
different
location
os
things
weird
places
clear
comment
reason
other
places
nit
space
relative-import
entire
file
line
/cc
@
apb7
@
kevinlee12
worth
list
lint
checks
fair
amount
overuse
lint
pragmas
PRs
test
need
audio
extension
sure
Okay
check
more
audio
extension
reason
audio
file
accepted
filename
extension
different
accepted
audio
format
raw
data
invalid
request
test
skills
representative
cases
ones
post-deletion
cases
subtopic
topic
subtopic
topic
comment
transaction
try-catch
block
bit
i.e
valid
Android
tests
generic
something
pseudocode
python
all_interaction_ids
=
fetch_all_interaction_ids
=
android_validation_constants.VALID_INTERACTION_IDS
web_only_interaction_ids
=
all_interaction_ids
set
android_interaction_ids
TODO
Verify
len
android_interaction_ids
len
web_only_interaction_ids
android_interaction_id
android_interaction_ids
init_state.update_interaction_id
android_interaction_id
TODO
Add
message
interaction
ID
self.assertTrue
init_state.interaction.is_supported_on_android_app
web_only_interaction_id
web_only_interaction_ids
init_state.update_interaction_id
web_only_interaction_id
TODO
Add
message
interaction
ID
self.assertFalse
init_state.interaction.is_supported_on_android_app
generic
tests
necessary
interactions
crisper
way
python
_checked_interaction_ids
=
def
_create_init_state_for_interaction_verification
exploration
=
exp_domain.Exploration.create_default_exploration
return
[
exploration.init_state_name
]
def
_verify_interaction_supports_android
interaction_id
init_state
=
self._create_init_state_for_interaction_verification
init_state.update_interaction_id
interaction_id
self.assertTrue
init_state.interaction.is_supported_on_android_app
self._checked_interaction_ids.add
interaction_id
def
_verify_interaction_does_not_support_android
interaction_id
init_state
=
self._create_init_state_for_interaction_verification
init_state.update_interaction_id
interaction_id
self.assertFalse
init_state.interaction.is_supported_on_android_app
self._checked_interaction_ids.add
interaction_id
def
all_interaction_ids
fetch_all_interaction_ids
missing_interaction_ids
all_interaction_ids
self._checked_interaction_ids
TODO
Add
assertion
message
results
missing_interaction_ids
developer
interaction
IDs
self.assertEqual
missing_interaction_ids
def
test_interaction_validation_for_android
self._verify_interaction_supports_android
'AlgebraicExpressionInput
self._verify_interaction_does_not_support_android
'CodeRepl
solution
more
explicit
sure
comment
way
list
necessity
elements
list
question
elements
hashable
right
query
most
inequality
filter
Great
comment
btw
question
counts
skill
comments
skill
difficulty
Same
comment
random
functions
applies
comment
skill_model
external
id
checks
Refer
other
functions
continue
multiple
lines
pragma
Done
Optional
>
InteractionName
UpperCamelCase
comment
more
explanation
other
devs
need
wrong
order
Add
space
docstring
incorrect
default
value
empty
non-empty
rewrite
meaning
better
default
value
validation
checks
e.g
Image
component
required
field
default
value
empty
default
value
schema
custom
validators
updated_hint_dicts
comments
activity_list
=
summary_services.get_displayable_exp_summary_dicts_matching_ids
splash_page_featured_exploration_ids
comment
separate
variable
clear
name
break
[
linter
everything
right
arounn
Please
comment
similar
//github.com/oppia/oppia/blob/170bdeae5912ced0abc71257f5b0e5ca98fd1418/core/domain/activity_jobs_one_off.py
L167
process
flush
tasks
job
comment
>
overlay.html
extensions/gadgets/AdviceBar/
next
constant
single
set
glob
patterns
something
FILEPATHS_TO_HASH
something
scripts/pre_commit_linter.py
more
straightforward
Ideally
point
single
list
care
_directive.html
_modal.html
bit
strict
familiar
frontend
conventions
Ah
OK.
list
main
status
part
static
files
gadget
suffix
overlay.html
anything
particular
relevant
files
_modal.html
briefly
bit
cryptic
files
.eot
.woff2
files
codebase
bit
confused
need
needed
dont
>
more
comments
file
difference
fonts
webfonts
dirs
style
args
docstrings
Please
fix
Thanks
comment
assert
exploration
latest
state
schema
version
version
result
check
exp_services.py
swap
latest
schema
version
one
change
name
point
test
future
viewers
file
various
cases
try_upgrading_draft_to_exp_version
existence
private
method
implementation
detail
relevant
important
test
Hm
case
comment
raise
statement
subclasses
super
call
values
status
final_reviewer_id
own
initialization
methods.
Add
docstrings
args
job_request_id
separate
field
ID
instance
self.id
=
job_request_id
tests
job_request_id
alphanumeric
string
function
IDs
instance
doubt
second
self.id
Im
file
name
*
dot
whole
thing
parens
order
pragma
Ditto
FYI
comment
useful
prod
safer
cases
lot
setup
various
tests
setUp
function
general
comment
tests
nit
lint
tests
CircleCI
due
TypeScript
compilable
spec
file
.ts
test
Drop
comment
skill.
Note
period
end
newline
parity
above
clear
test
blocks
action
+
checks
skill
name
Full
sentence
start
capital
letter
period
end
suggestion
First
pattern
cases
'
Second
pattern
last
character
previous
line
line
type
suggestion
pattern
cases
previous
line
line
type
suggestion
pattern
cases
[
CollectionMigrationJob
]
https
//github.com/oppia/oppia/blob/develop/core/domain/collection_jobs_one_off.py
L53
line
exp_models
question_models
skill_models
story_models
topic_models
=
models.Registry.import_models
[
models.NAMES.exploration
models.NAMES.question
models.NAMES.skill
models.NAMES.story
]
other
case
None
DEV_MODE
==
true
Hi
@
bansalnitish
exploration
relevant
comments
comment
new
explorations
addition
old
ones
XXX
domain
objects
bulk
put_multi
end
explorations
versions
put_multi
faster
individual
puts
exp_completed_session_ids
notion
state
completion
dict
version
values
dicts
state
name
inner
values
state
event
first
time
track
event
largest
timestamp
dict
version
session
ID
value
dict
state
name
largest
timestamp
full
list
events
first
time
value
get_multi
outset
incremental
get
operations
above
calculation
branch
something
point
things
timestamp
explanation
sounds
reasonable
more
comment
versions
exploration
get_multi
outset
thought
states
>
>
>
>
state
state
counts
lower
weird
hit
counts
case
user
perspective
Done
Please
add
comment
wrong
condition
number
states
key
exp_id
state_answer_events_for_this_version
store
revert_to_version
None
non-None
revert
actual
event
Worth
value
[
'submitted_answer_list
]
O
operation
Python
fact
counts
pass
info
map
stage
Answers
big
comment
dict
stores
cumulative
statistics
version
version
N
exploration
seanlip
Doc
string
mapping
versions
>
state_name
>
set
sessionIDs
use
e
'event_dict
lambda
function
Drop
max
Please
justify
specific
name
dummy
variable
comment
dict
entry
list
state
names
event
dict
Er
sec
data
case
compute
first
place
above
subsidiary
functions
is_revert
subsidiary
functions
else
branch
Pull
[
versioned_exploration.init_state_name
]
separate
variable
init_state
general
try
pylint
pragmas
possible
values_state_hit_sessioned
[
-1
if/else
if/else
values_state_hit_sessioned
[
-1
]
case
Drop
nested
loop
Group
version
outset
code
time
production
millions
events
Ditto
state_hit_events_for_this_version
explorations
state
rare
possible
sure
case
_published_
explorations
Might
worth
possible
1-state
exploration
dev
server
worth
one-state
exploration
unlikely
much
use
nit
add
spaces
+
possible
first
answer
group
same
state
something
robust
Check
groups
different
state
sum
max
Justify
comments
way
key
exp_version
specific
iteration
multiple
times
session
ID
inefficient
things
lot
better
way
single
pass
list
data
session
ID
single
pass
back
exploration_stats_by_version
list
order
reverts
v2
stuff
v1
future
v2
values
code
target
value
event
state
name
defaultdict
int
Keep
v1
keys
collections.defaultdict
other
clauses
Refrain
pragmas
something
yield
'Completions
%
exp_id
exp_version
comment
timestamp
case
last
element
complete
exploration
event
states
user
complete
exploration
event
events
represent
valid
hits
max
fine
only
thing
event
dict
track
counter
outset
need
list
start
event
dicts
Similar
comments
other
fields
space
fewer
times
entire
dataset
better
try
data
structure
much
stuff
possible
on-the-fly
single
pass
data
outset
set
value
_v1
keys
total_answers_count
something
different
aggregation
v1
subsequent
versions
>
Consider
spaces
>
individual
test
functions
separate
tests
particular
deletion
easier
issues
specific
tests
fourth
test
various
operations
check
deleted
status
same
versions
check
outset
Nit
traceback
key
value
vars
something
descriptive
Edit
value
list
dictionary
comments
lines
necessary
function
Change
comment
libraries
script.
PACKAGE
VERSION
caps
necessary
comments
encode
'utf-8
other
jobs
auxiliary
vars
much
sentence
suggestion
source_maps
least
CI
check
source
maps
prod
env
issues
oppia
th
reasonn
random
number
len
'-
file
lines
app_dev_linter.py
private
methods
pragma
newline
code
sepratoin
readability
Incorrect
comment
'previous
state
stats
backquotes
E.g
returncode
exit
status
child
process
cases
[
]
https
//github.com/oppia/oppia/blob/develop/appengine_config.py
L76
]
https
//github.com/oppia/oppia/blob/develop/core/domain/state_domain.py
L770
comments
small
letter
similar
cases
solution
update
suggestions
update
b
look
update_last_updated_time=False
last-updated
timestamps
content-edit
suggestion
models
clue
name
docstring
inline
comments
better
function
name
something
several
times
line
multiple
lines
break
function
function
return
diff.getbbox
better
return
images
same
negation
brief
note
getbbox
function
lengths
assertion
some_file.js
checks
specific
possible
comment
log
message
general
reviewer
something
comment
useful
future
readers
code
TODO
....
comment
sure
storage
possible
disable
pragmas
query_criteria_satisfied
logic
clauses
clue
Verification
single-line
comment
suggestion
pkg_resources.get_distribution
'google-cloud-tasks
.version
issue
comment
hack
note
lines
Note
order
important
Handling
state
deletions
renames
additions
order
corresponding
pylint
enable
Consider
comment
comment
default
events
current
schema
version
def
check
non-None
event
schema
version
newly-put
models
superclass
put
Ditto
put
=
feconf.CURRENT_EVENT_MODELS_SCHEMA_VERSION
superclass
method
way
clients
newly-put
models
ones
Ditto
fine
details
feconf.py
class-specific
Ditto
Everything
historical
data
better
description
v1
data
Nov
fine
feconf
general
sure
sufficient
docstrings/detail
future
dev
future-you
year
time
Maybe
document
schema
versions
reasons
schema
version
alternative
BaseEventModel
core.storage.statistics.gae_models
other
event
models
way
constant
class
put
single
place
cleaner
comment
number
ALLOWED_ENTITY_TYPES
Okay
@
seanlip
idea
docstring
implementation/signature
method
Please
various
things
created_on
argument
function
Do
docstrings
Ditto
respond
inline
comments
review
Could
deletion
BaseCommitLogEntryModel
set
comment
reason
bit
line
breaks
models.
Deindent
comment
line
Please
attention
punctuation
capitalization
etc.
comments
crisp
e.g
mean
learner
user
redirect
behavior
learner
learner
user
explorations
Be
Ditto
comments
>
Please
pay
attention
punctuation
capitalization
attention
punctuation
capitalization
etc
comments
45-48
line
45-48
specs
explorations
library
page.
English
first
language
comments
haste
better
future
actions
obvious
code
comment
Use
comments
_why_
things
code
comment
pretty
clear
method
name
test
name
please
general
code
tests
case
able
PR
tests
@
jaredsilver
yes
exploration
deleted
contribution
user
contribution
list
ids
user_services.get_user_contributions
self.user_id
id
contribution
dashboard
name
user_contributions
user_is_creator
fact
Travis
checks
PR
look
wiki
documentation
tests
seanlip
sorry
different
base_test.py
file
case
user
exploration
exploration
user
Shall
change
test
same
PR
users.login
@
privileges.com
general.openEditor
explorationId
Eve
homepage
.toEqual
general.SERVER_URL_PREFIX
+
'/dashboard
snippet
fail
homepage
/dashboard
feature
request
assumption
please
test
sure
Great
user
creator
dashboard
situation
Thanks
@
thedeveloperr
pattern
reasonable
write
backend
tests
order
behaviour
base_test.py
>
backend
test
files
self-explanatory
>
write
backend
tests
order
behaviour
base_test.py
seanlip
links
documentation
newbie
kind
stuff
starting
point
tests
order
new
features
sure
modification
sense
Tests
behaviour
expected
one
behaviour
changes
logical
tests
new
behaviour
extra
blank
lines
comments
unnecessary
user
exploration
user
deleted
exploration
database
user
creator
dashboard
likely
creator
bit
weird
more
granular
separate
message
check
concern
e.g
state
name
separate
method
other
stuff
juncture
Otherwise
errors
bit
weird
message
reviewer_id
reviewer
SuggestionValidationBot
something
Please
TODO
list
Suggestion
list
Ditto
above/below
sure
docstrings
typeinfo
full
stop
description
exception
descriptions
user
ID
user
TODO
nithusha21
related
comment
Incomplete
docstrings
please
docstrings
methods
consistent
following
format
args
returns
raises
many
methods
docstrings
codebase
pattern
old
ones
comment
descriptions
Ditto
general
indexed
default
arg
None
general
error
import
Please
detailed
comment
punctuation
>
punctuation
symbols
phrases
docstring
comment
punctuation
capital
letter
checks
comment
docstring
comment
*
*
start
space
Great
comment
Please
reason
important
capital
letter
examples
v2
version
ExplorationStatsModel
particular
exceptions
comment
capital
letter
rule
Sorry
late
reply
last
weekend
more
detail
logic
previous
checks
logic
comment
line
OK
further
checks
line
version
info
bit
something
bit
whole
method
something
lines
docstring
args/returns
section
sure
arg
current
implementation
bit
line-by-line
check
error-prone
context
file
bit
ad
hoc
addition
other
typeinfo
present
ones
DATA_TYPES
check
incomplete
general
trouble
code
meeting
Add
comment
can_translate
managers
editors
edit
rights
Again
test
name
clearer
state
expected
outcome
comment
comments
docstring
more
lines
sure
audio
language
codes
exploration
opportunity
object
match
ones
constants.SUPPORTED_AUDIO_LANGUAGES
cause
backend
error
link
[
]
https
//stackoverflow.com/questions/12449197/badargumenterror-multiquery-with-cursors-requires-key-order-in-ndb
Sorry
something
importing
pylint
Everywhere
code
pylint.testutils.X
pylint.testutils.X
only
thing
pylint
testutils
fine
pylint
import
testutils
testutils.X
everything
pylint
import
testutils
code
use
testutils.CheckerTestCase
Never
import
classes
lint
check
Flag
comment
necessary
try/except
potential
errors
sure
Ditto
sure
reverts
only
actions
issue
Might
indexed=True
unfinished
jobs
note
required=False
optional
skill
ambiguous
ID
skill
one
skill
duplicate
one
edit
suggestions
docstring
changelist
change_list
repeated
property
indexed=True
others
explorations
single
category
sure
topics
skills
many
relation
method
add
question
type
suggestion
aks681
seanlip
skills
topics
cases
single
domain
thought
target_entity_id
target_id
thing
target
suggestion
Ditto
version
Target
specific
entity
sure
meaning
intuitive
kind
fence
feel
free
call
content
changes
exploration
apt
parameter
subject
category
algebra
algorithms
architecture
etc
translation
changes
language
apt
parameter
images
necessity
domain
graphic
designer
subject
constraints
questions
skills
parameter
best
one
topic
skill
cases
concrete
cases
string
fine
domain
more
string
type
contribution
translation
graphic
content
question
possible
choices
type
correct
i.e
name
approver_id
similar
comment
design
doc
Feedback
thread
IDs
contain
exploration
ID
dots
issues
delimiter
thread
ID
couple
other
things
ambiguity
bit
weird
entity
type
ID
adjacent
Add
info
models
user
ID
author
Ditto
reviewer_id
thread_id
general
careful
IDs
objects
load
confusion
vague
name
something
purpose
related
comment
design
doc
docstring
bit
name
description
need
clearer
version
number
target
entity
time
suggestion
suggestion_metadata
change
True
only
issue
list
categories
languages
skills
second
part
score_category
string
case
list
Nit
comment
line
indent
backend
schema
many
editors
min_value
SchemaBasedEditor
editors
frontend
validation
place
number
choices
less
TODO
case
clear
feasible
way
issue
feature
request
bit
confusing
separate
test
system-ID-related
usernames
system
username
same
ID
comment
main
code
feconf
constant
only
way
quot
font-family
attribute
style
tags
sure
font-family
check
specific
better
question
current
code
data
quot
Interesting
content
look
frontend
frontend
similar
json
conversion
process
due
extra
double
quotes
change
extra
double
quotes
double
quotes
style
tag
invalid
boolean
value
sure
care
valueError
general
comments
lines
filter
matching
collections
collections
Ditto
separate
role
I.e
dict
something
owned_collection_ids
[
]
editable_collection_ids
[
]
Ditto
Ditto
good
INTERACTION_IDS_WITHOUT_ANSWER_DETAILS
TRIVIAL_INTERACTION_IDS
Though
new
constant
Search
is_linear
codebase
same
concept
use
Interaction
IDs
answer
details
function
signature
comment
line
design
rationale
things
creator
dashboard
future
explorations
e.g
basic
math
collections
property
names
Changed
field
newline
mistake
parens
line-too-long
pragma
ExpUserLastPlaythroughModel
docstring
last_state_played
edit
last_played_exp_version
last_played_state_name
last_played_state_name
Do
certain
list-of-blobs
property
future
similar
IncompleteExplorationsModel
comment
possible
way
time
Epoch
docstring
correct
as-is
value
time
blobs
possible
schema
changes
future
e.g
history
answers
previous
session
alternative
approach
ExpUserData
model
timestamp
version
state
name
actual
ndb
properties
exp_id
user_id
get_by_user_id
call
such
models
user_id
indexes
alternative
list
ids
ExpUserData
maintain
last
playthrough
information
way
least
parity
models
track
ids
sure
other
concerns
Which
version
last
current
version
Does
old
version
newer
version
domain
layer
name
state
translations
@
anmolshkl
Yep
TODO
comment
Done
comment
message
verification
function
order
signature
please
above
line
comment
def
generate_signature
NOTE
TO
DEVELOPERS
bit
decorator
requests
next
job
case
docstring
Done
PTAL
new
way
nit
*
*
*
*
sync
nit
*
*
*
*
oppia-ml
Ah
clear
controllers
thin
Most
core
logic
logic
layer
much
logic/freedom
controller
narrower
interface
logic
layer
particular
only
thing
able
status
function
interface
nothing
technical
design
thing
Happy
more
seanlip
job
thats
issue
Nothing
job
class
mutable
status
update
function
purpose
mapping
classifier_services.save_classifier
classifier
classifier
higher
level
mapping
table
classifier_services
Everywhere
functions
mapping
possible
Agreed
Thats
Done
Nope
wrong
secret
config
property
vm_id
few
days
code
something
config_domain.vm_id_config_property.get
'vm_id
similar
one
controllers
admin.py
more
config
properties
clear
idea
seanlip
other
function
function
sync
oppia-ml
good
idea
signature
generation
separate
function
good
idea
generate_signature
function
message
secret_key
other
comment
next
line
Ahh
Done
General
suggestion
try
TODO
comments
things
possible
hard
track
TODOs
unacted
longer
seanlip
@
pranavsid98
@
own
algorithm
part
GSoC
last
milestone
newcomers
good
TODO
list
milestone
track
check
current
job
status
]
>
[
complete
]
valid
transition
General
note
new
error
cases
comments
Please
Done
few
more
tests
more
cases
errors
seanlip
sure
function
[
image
]
https
//user-images.githubusercontent.com/16653571/53747916-4a289400-3eca-11e9-8a7c-e057607f07b6.png
unit-test
perspective
fine
confirmation
newline
separate
chunk
test
comment
>
action
get_sent_messages
>
Ditto
below
guidelines
backend
tests
possible
Makes
easier
reader
variable
head
wrong
messages
list
'bcc
attr
test
pattern
bulk
email
correct
sender
check
behavior
bulk
email
invalid
sender
email
error
ditto
other
places
sorry
last
review
Done
Thanks
Avoid
much
logic
tests
possible
sender
email
expected
error
string
Ditto
Drop
outer
parens
need
additional
variable
head
code
similar
things
code
examples
Ditto
reply_to
>
reply_to_id
to=self.RECIPIENT_EMAILS
]
readable
emails
self.RECIPIENT_EMAILS
Nope
hardcoded
string
expectation
Test
interface
implementation
reply_to
email
reply_to_id
tests
explicit
setUp
method
latest
commit
Thanks
line
place
reply_to_id
line
Max
char
line
Drop
outer
parens
Thanks
general_suggestion_models
usage
message_model
naming
wrong
possible
something
%
s
%
s
]
%
set
difference
I.e
list
feedback_thread_ids
.difference
nice
adjustment
cells
na
placeholder
docstring
function
case
calculation
finite
answer
great
start
@
jlpalomino
tests
travis
results
https
//travis-ci.org/earthlab/earthpy/builds/464008139
L1389
earthpy.spatial
import
normalized_diff
imports
spatial
module
better
fix
time
es.normalized_diff
Similar
lines
2-dim
fixture
lines
2-dim
fixture
fixture
altitude
value
returns
ValueError
Docstring
azimuth
value
returns
ValueError
suggestion
title
=
arr.shape
]
minor
suggestions
error
messages
plot_bands
Plot_bands
first
word
sentence
error
message
same
capitalization
function
Tim
handy
trick
multiline
error
messages
io
module
little
cleaner
awkward
tabs
use
indendation
https
//github.com/earthlab/earthpy/blob/master/earthpy/io.py
L163
example
idea
something
ValueError
plot_bands
error
message
suggestion
Determine
filetype
file
name
extension
comments
capital
letter
first
word
Add
short
Python
comment
plot
Plot
histogram
bins
columns
best
separate
Python
comments
colors
titles
list
Python
comment
title
names
order
order
Landsat
bands
further
histograms
something
Customize
Bin
Size
Arrangement
Histograms
arrangement
plots
short
Python
comment
lists
colors
parameters
Please
test
docs
prs
docs
comment
>
>
test
user-facing
function
try/except
logic
assert
statement
more
typical
pytest
test
e.g.
def
test_colorbar_height
Test
colorbar
ax
height
image
axis
height
fig
ax
plt.subplots
figsize=
=
ax.imshow
np.random.randint
size=
cb
=
es.colorbar
im
assert
cb.ax.get_position
==
im.axes.get_position
comment
test
global
variable
tuups
e.g.
def
test_arr_parameter
Raise
AttributeError
array
pytest.raises
AttributeError
es.plot_bands
arr=
appropriate
additional
commentary
file
goal
comments
file
structure
function
PR
band
order
code
REMOVE
change
wold
change
discussion
package
maintainers
issue
discussion
[
]
https
//github.com/earthlab/earthpy/issues/2
issue
@
mbjoseph
problem
area
early
panels
data
workaround
plt.show
part
rgb_bands
extent=extent
ax.set_title
title
ax.set
xticks=
[
]
yticks=
[
]
Delete
code
Delete
code
\
lines
code
import
top
Please
tests
SymmetricBackend
applicable
cost
memory
requirement
tensor
contraction
tensor
shape
shape
contract
dimesion
axes
tensor
shape
cost
square
contracting
axes
axes
memory
requirements
*
/
*
sure
best
measure
cost
reasonable
easy
estimate
greedy
contractor
tests
skip
shell
weird
set
dir
hack
difficult
new
test
nodes
dangerous
behavior
future
Same
comment
use
backend.shape
code
Remove
\
Delete
Delete
code
Nit
space
several
places
error
user
ordering
error
assert
leftovers
pylint
happy
comments
code
rest
file
l
direction
l
tensors
comment
see
comment
del
corresponding
list
connects
connect_list_in
>
network_structure
connects
>
network_structure
consistent
ncon
iterate
unique_connects
c1
=
connect_list.pop
locs
]
c2
=
connect_list.pop
locs
]
dim1
=
tensor_dims.pop
locs
]
dim2
=
tensor_dims.pop
locs
]
connect_list
tensor_dims
del
connect_list
[
]
input
list
loop
Args
names
different
actual
names
cont_order
>
con_order
consistency
convention
iterate
tensors
enumerate
connects
>
network_structure
range
loop
N
same
name
wrong
pytest.raise
ValueError
match=
error
string
checks
right
error
naked
try
except
little
sketchy
linter
real
error
legs
dimensions
error
end
nodes
try/excepts
Keras
object
serialization
logic
register_keras_serializable
custom
object
dicts
layer
get_config
method
node
set
get_all_dangling
method
error
output_edge_order
number
output
edge
>
difference
sets
non-deterministic
order
subtle
bugs
list
None
code
check
check
nodes
useless
Delete
code
cost
memory
usage
contraction
default
something
larger
~2
*
*
block
comment
critical
suggestion
except
Exception
ex
pylint
disable=broad-except
weird
CLI
module
train
CLI
script
spacy.gold.loggers
feels
kind
unintuitive
reasoning
loggers
|
Thanks
test
Python
dicts
values
key
different
order
fault
btw
intuitive
lists
sure
order
same
ents-specific
generic
method
sents
sure
separate
score_ents
method
ents
sents
work
as-is
kind
bad
way
able
generic
scoring
method
kind
many
special
cases
hard
scorer
backwards
suggestion
token.ent_iob
token
g_span
svlandeg
Sorry
nitpicky
comment
consistency
editor
newlines
end
files
[
black
]
https
//github.com/python/black
auto-format
save
default
least
Python
right
pala
normal
list
exceptions
fact
months
branch
master
https
//github.com/explosion/spaCy/pull/5265/files
discussion
https
//github.com/explosion/spaCy/issues/5255
additional
lists
exceptions
various
incompatible
lists
subjective
list
reasonable
rules
proper
/official
language
constructs
people
slang
other
traits
specific
language
own
exceptions
least
private
i.e
_attrs_unnormed
part
API
naming
logger
Best
practice
literal
list
entries
[
]
other
log
messages
redundant
entry
bit
redundant
extra
additional
dict
values
suggestion
params.update
extra
extra
'internal
'doubleup
config.get
extra
generator
need
list
comprehension
requests
need
redundant
entry
Could
error
class
html
plugin
errors
requests.exceptions.RequestException
error
correct
exception
error
Too
broad
more
pythonic
data
_last_
modify
phase
client
name
things
simple
additional
slash
intentional
id_timeframe.proper_count
messages
weird
mapping
config
values
proper
tense
on_lower
portion
better
if-blocks
something
other
something
other
stuff
elif
third
something
third
stuff
action
entry
msg
shouldnt
first
entry
Minor
thing
dict
identifier
ones
else
part
..
personal
preference
flow
control
leaner
identifier
log.debug
identifier
entry
[
'title
]
continue
grouped_entries
identifier.lower
entry
suggestion
reminder
variable
_never_
True
No
need
pop
useless
comments
PluginError
%
s
%
str
e
forgot
comment
verbosity
comment
first
line
snake
case
case
keyword
integer
way
line
limit
chars
closed
list
right
Please
enum
meant
last
row
first
row
[
]
Callable
input
types
list
first
argument
return
type
second
function
str
None
type
good
assumption
something
changes
Please
import
top
__future__
Delete
suggestion
random
indentations
log
scenario
things
util
plugins
InputGazelle
separate
files
sure
InputGazelle
utils
parentheses
redundant
plugin
though
https
//flexget.com/Plugins/headers
necessary
user_agent
task.requests
https
//github.com/Flexget/Flexget/blob/develop/flexget/utils/requests.py
L184
check
redundant
default
many
linebreaks
instance
constants
initial
setup
class
static
point
task.requests
possible
meaningless
vars
python
compatible
path
butler.getUri
file
name
datastore
return
value
ns
confusing
namespace
name
None
anything
other
param
params
param
logic
parsing
method
something
python
base_url
namespace
=
_parse_db_url
namespace
None
base_url
//
.firebaseio.com'.format
namespace
use_fake_creds
=
False
=
use_fake_creds
=
True
=
ns
parsing
method
WDYT
reply
comment
_parse_emulator_url
throw
errors
url
parsed_url
parsed_url
url
sake
errors
wording
awkward
something
clearer
Construct
password
reset
email
template
link
custom
SMTP
server
doc
strings
types
comments
status
proto
file
whole
thing
file_name
=
os.path.basename
model_file_name
Windows
environments
requirement
case
whole
method
lines
side
note
branch
other
day
socket
result
Stream
active
while
lines
session
db
module
instance
google.auth.transport.requests.AuthorizedSession
required
Authorization
header
above
headers
self.request_kwargs.get
'headers
required
values
headers
self.request_kwargs
[
'headers
]
=
headers
comment
couple
lines
comment
requirement
directory
try-finally
=
ml.create_model
model
try
assertions
ml.delete_model
firebase_model.model_id
https
//docs.python.org/3/library/tempfile.html
tempfile.mkdtemp
Most
fixtures
bit
@
pytest.fixture
def
name
=
_random_name
=
ml.Model
display_name=name
tags=
[
'tag1
]
model
=
ml.create_model
args
yield
model
ml.delete_model
model.model_id
call-site
proper
clean
_if_exists
rpc
first
lines
try
block
semantics
easier
fixture
test_create_simple_model
name_and_tags_model
Just
assertions
random
display
name
predictable
prefix
test_model_
*
part
tempfile
package
Use
https
//docs.python.org/2/library/tempfile.html
tempfile.mkdtemp
Should
random
identifier
display_name
unique
key
API
part
sleep
helper
method
_exponential_backoff
current_attempt
stop_time
calculate
delay
validate
smaller
value
please
e.g
unit
Sleeper
type
tests
mlkit.py
class
Sleeper
object
def
sleep
time.sleep
duration_seconds
=
Sleeper
Unit
class
TestSleeper
def
sleep
pass
mlkit._SLEEPER
=
TestSleeper
comment
method
name
descriptive
propagate
Silly
nitpick
blank
lines
Per
Pep
Use
lines
functions
logical
sections
test
logical
section
setup_method
parameter
value
precise
suggestion
test
analytical
MLEs
close
optimized
MLEs
assertions
assertion
analytical
value
<
value
test_fixed_parameter
appropriate
name
fixed
parameters
test_fit
purpose
test
pattern
precise
right
thing
need
separate
comment
call
pytest.raises
ValueError
match='some
suitable
regex
case
pytest.raises
ValueError
array
B-splines
understanding
interval
closed
open
intervals
numerical
methods
Notes
docstring
b
fact
initial
point
t
[
k
]
length
t
[
-k
]
t
[
k
]
such
return
many
if-else
branches
suggested
approach
if-else
comment
mine
PR
briefly
comment
problematic
sparse
arrays
operation
matrix
array
problematic
bug
annoyance
comment
good
array
sparse
warning
[
R
]
R
sparse
sense
speed
operation
R
dimension
only
sparse
matrices
comments
Typo
suggestion
Test
k
boundaries
issue
suggestion
>
>
>
fft
[
]
registered
backend
global
backend
returns
space
comment
style
checker
requirement
line
interpreter
section
code
comment
comment
*
p0
look
isinstance
bins
int
numpy
integers
e.g
integerness
value
operator.index
operator.index
bins
TypeError
bins
integer
minimum
current
line
try
bins
operator.index
bins
TypeError
bins
integer
pass
bins
integer-like
object
actual
Python
int
test
isinstance
bins
int
prettier
way
suggestion
suggestion
big
fan
supposedly
hidden
argument
function
definition
documentation
precedence
Scipy
kind
thing
diff
whitespace
line
surprised
CI
artifact
github
UI
nesting
comment
analysis
threshold
able
case
=
indptr
[
-1
]
indices
np.fromiter
x
y
self.rows
x
y
dtype=idx_dtype
count=nnz
data
=
np.fromiter
x
y
self.data
x
y
dtype=self.dtype
count=nnz
nice
readability
nnz
=
indptr
[
-1
]
Cruft
comment
docstring
reference
docstring
init_weight
specifies
float
range
]
value
None
ValueError
need
calc_score
suggestion
Algorithm
Step
direction
Q
Eq
superfluous
comment
rows
cols
variables
unpacked
suggestion
Algorithm
Step
compute
gradient
f
P
-tr
APB^tP^t
suggestion
]
Algorithm
Step
end
main
loop
different
inputs
partial_match
complete
permutation
number
FW
iterations
Shall
case
start
function
zero-size
inputs
real
restriction
algorithm
suggestion
def
split_matrix
X
definitions
Seeded
Graph
Matching
]
upper
lower
=
X
[
n
]
X
[
n
]
return
upper
[
n
]
upper
[
n
]
lower
[
n
]
lower
[
n
]
A11
A12
A21
A22
=
split_matrix
[
perm_A
]
[
perm_A
]
n_seeds
B11
B12
B21
B22
=
split_matrix
B
[
perm_B
]
[
perm_B
]
n_seeds
suggestion
step
size
alpha
=
minimize_scalar
f
bounds=
suggestion
P_i1
=
*
P
+
alpha
Q
Update
P
suggestion
]
Algorithm
Step
Update
P
P_i1
=
*
P
+
alpha
Q
strict
score
intuitive
score
score_new
consistent
2-opt
suggestion
Step
compute
step
size
FAQ
paper
own
steps
paper
lines
Algorithm
bit
confusion
code
paper
page
comments
Algorithm
*
Line
etc.
docs
denominator
n
n_unseed
sure
denominator
consistent
docs
x
*
P
+
x
Q
intermediate
variable
np.transpose
suggestion
return
np.sum
A
*
B
[
perm
]
[
]
old
PR
correct
score
%
faster
unclear
number
Franke-Wolfe
iterations
Rename
permutation_cost
permutation_dist
perm_B
suggestion
]
Algorithm
Step
project
set
permutation
matrices
suggestion
]
Algorithm
Step
Update
P
suggestion
@
implementation
https
//github.com/btaba/sinkhorn_knopp
Sinkhorn-Knopp
algorithm
https
//projecteuclid.org/euclid.pjm/1102992505
suggestion
]
Algorithm
Step
choose
initialization
np.array
[
x
+
n_seeds
x
col
]
>
col
+
n_seeds
Azure
32-bit
Ubuntu
AttributeError
'mtrand.RandomState
object
attribute
'random
AttributeError
'numpy.random.generator.Generator
object
attribute
'rand
order
=
np.random.rand
B11
=
np.random.rand
C1
=
np.trace
A11.T
@
B11
C2
=
A11
*
B11
.sum
C1
C2
suggestion
_
col
=
linear_sum_assignment
-P
suggestion
P
=
P_i1
https
//github.com/scipy/scipy/pull/12775
discussion_r478844080
suggestion
]
Algorithm
Step
loop
criteria
suggestion
Project
set
permutation
matrices
col
linear_sum_assignment
-P
suggestion
]
Algorithm
Step
direction
Q
Eq
delta
misleading
variable
name
gradient
FAQ
paper
grad_fp
integer
FAQ
paper
grad_P
gradient
change
delta
np.linalg.norm
P
P_i1
tol
rid
variable
loop
n_iter
range
maxiter
=
np.random.rand
B21
=
np.random.rand
xP1xQ
=
np.random.rand
C1
=
np.trace
xP1xQ.T
@
A21
@
B21.T
C2
=
xP1xQ.T
@
A21
*
B21
.sum
C1
C2
@
suggestion
]
Algorithm
Step
compute
gradient
f
P
-tr
APB^tP^t
seed_cost_c
>
seed_A
Same
comment
msg
approach
costs
lines
suggestion
_
=
linear_sum_assignment
grad_fp
maximize=maximize
Q
=
np.eye
[
]
comment
inappropriate
descriptive
reader
bearings
paper
suggestion
Algorithm
Step
main
loop
suggestion
]
Algorithm
Step
end
main
loop
FAQ
paper
f
quadratic
function
α
exact
solution
lot
*
faster
minimize_scalar
iterative
suggestion
]
Algorithm
Step
compute
step
size
suggestion
]
Algorithm
Step
project
set
permutation
matrices
suggestion
Algorithm
Step
choose
initialization
docstring
top
class
comment
purpose
comment
x
array
comment
parent
function
case
lot
small
requests
last
one
short
comment
context
test
suite
context
easy
type
cast
extraneous
cleanup
Esp
most
devs
*
nix
tests
comment
minor
comment
third
order
polynomial
model
Sorry
sure
SciPy
versions
NumPy
older
comment
Unless
@
jnothman
mind
something
self.data
[
start
end
]
where=
minor_index
==
[
start
end
]
dtype=self.dtype
where=
kwarg
ufuncs
methods
above
Blame
year
younger
version
comment
worth
trouble
code
last
week
P
format_tag
comments
u1
raw
bytes
V1
type
out
NotImplementedError
suggestion
_ftypes
checks
None
space
end
line
Could
Bounds
https
//docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.Bounds.html
scipy.optimize.Bounds
new
classes
documentation
list
comprehension
+
np.stack
background_in
background_out
utility
function
Python
def
_reshape_nd
x1d
axis
Reshape
x1d
size
axes
range
ndim
axis
shape
]
*
ndim
shape
[
axis
]
=
x1d.size
return
x1d.reshape
shape
e.g
background_out
=
_reshape_nd
background_line
[
]
+
background_line
[
]
*
rel_len
y.ndim
axis
fixes
TravisCI
suggestion
[
np.array
[
.62
]
-.97
.55
]
]
[
[
-0.4191
]
line
suggestion
p-value
calculation
same
variants
p-value
con_minus_dis
please
comment
origin
number
chi2.rvs
spaces
commas
please
]
ncx2.pdf
ncx2.logpdf
rid
getattr
please
use
something
lines
assert_allclose
result
atol=1e-14
floating-point
comparisons
combinbation
tolerances
numbers
chi2
distribution
nc=0
ncx2
nc
=
tolerances
way
tighter
close
such
suggestion
@
pytest.mark.parametrize
]
test_heequb
fails
gh-11902
Typo
suggestion
fft_ops
*
N
*
np.log
N
separate
FFTs
size
full_out_shape
comment
_indices
tracks
order
item
true
x
=
parents
x
]
=
hash
parents
x
]
Obvious
OrderedDict
necessary
iter
self._indices
python
domain
==
Note
double
whitespace
PEP8
perspective
check
np.linalg.norm
simplicity
alternative
normalization
Ok
indications
end
docstring
warning
possible
ambiguity
lower
1e-7
order
1e-15
checks
line
handles
violation
Nitpick
recommended
formatting
line
thorough
explanation
reason
np.linalg.norm
stable
computation
bottleneck
tolerance
proper
normalized
array
equal
machine
epsilon
*
EPS
example
Mention
D
greater
Mention
unit
unit
norm
normalization
optional
normalization
pycodestyle
line
correct
spacing
over-indent
under-indent
issues
pycodestyle
case
entire
decorator
line
@
pytest.mark.parametrize
k
np.logspace
-1
x-axis
values
iv_ticks
comment
bit
clear
doe
test
cases
@
WarrenWeckesser
assert_allclose
assert_array_almost_equal
documentation
[
image
]
https
//user-images.githubusercontent.com/6570539/90555214-dfb1f500-e14b-11ea-91fc-270d3870ba15.png
R
Looks
good
tests
bugs
R
implementation
Similar
comments
things
own
test
cases
comment
new
class
names/test
names
describing
test_inf
np.inf
IEEE
inf
np
part
own
case
something
own
test
case
test_m_zero
test_pdtr_np_inf
accident
Might
signature/naming
weird
binnumbers
unique_bin_numbers
necessary
information
reason
RLock
f2py
reentrant
Import
suggestion
_logpdf
correct
result
alpha
=
suggestion
use
cdf
_cdf
issue
gh-12640
suggestion
use
logpdf
_logpdf
issue
gh-12640
safe
comments
lines
comment
exclusivity
second
argument
range
standard
comment
formatting
uncommon
literal
in-code
commentary
same
comment
main
order
other
sub
orders
step-7
detail
unindented
comment
same
dkim
last
lines
+comments
call
app_listlists
code
duplication
Please
concept
usage
namespace
name
key
Okay
list
real-life
settings
Imho
better
feeling
namespaces
future
things
such
notifications.mail
>
kload
@
yoloswag.com
security.allow_ssh_users_by_default
>
True
security.fail2ban_harshness
>
low
mid
high
]
security.ssl_security
>
low
high
]
Would
key
size
certificates
DH
parameters
fixed
list
settings
code
good
way
OrderedDirect
impossible
json
yaml
yaml
slow
problems
day
engineered
code
situations
later
modification
trivial
problem
day
day
wording
choices
one
real
code
Please
comment
usage
unknown_settings
Please
verbose
equal
*
part
applies
floats
common
container
types
dicts
lists
tuples
entities
data
current
entity
sample
>
entity
type
sample
Use
generic
file
extension
generic
process
type
path
slash
relative
Resolwe
resolwe-bio
specific
settings
https
//github.com/genialis/resolwe/blob/640bda7f97c2afca1d2223dc038352e8364f9331/tests/settings.py
L147
resolwe-bio
specific
common
object
Data
object
least
Resolwe
Python
comment
comments
line
dot
end
resolwe-bio
use
resolwe/base
fedora-31
similar
field
inconsistent
state
better
error
try
/
block
block
Same
connections
hard
fields
>
fields
comment
more
lines
Write
something
container
start-up
time
comment
work-around
Please
comment
work-around
comments
same
wrap
limit
code
characters
Same
comments
same
wrap
limit
code
Mention
data
lock
guarantee
storage
location
more
sense
condition
base
None
issubclass
base
runtime.Process
break
robust
inspect
import
isclass
isclass
base
issubclass
base
runtime.Process
break
self-explanatory
comment
all_docker_requirements
Change
i
[
]
+
+
i
]
+
'\n
name
tag
\n'.format
i
[
PyYAML
]
http
//pyyaml.org/wiki/PyYAMLDocumentation
yaml
image
required
field
docker
dict
Move
closing
parenthesis
new
line
first
file
need
s
.travis.yml
Ignore
errors
Docker
images
'list_docker_images
pull
command
something
Docker
images
environment
variable
project
settings
need
function
Vagrant
context
lack
documentation
available
Resolwe
settings
]
https
//github.com/genialis/resolwe/issues/189
sorry
clear
change
Validator
argument
skip_on_failure
e.g
check_fields
suggestion
SKIP_ON_FAILURE_KEY
=
'__validator_skip_on_failure__
Applies
RootValidators
comment
same
line
Literal
type
package
places
code
built-in
available
cls
GenericModel
preferable
.display
order
PRs
good
reason
suggestion
>
SimpleModel
password=SecretStr
*
*
*
*
*
*
*
*
*
*
password_bytes=SecretBytes
b
*
*
*
*
*
*
*
*
*
*
below
cast
type
hints
type
ignore
better
suggestion
PositiveInt
precedence
suggestion
print
Model.schema
alternative
constraints
Field
class
Model
BaseModel
constraints
schema
foo
int
=
Field
gt=0
lt=10
print
Model.schema
elif
issubclass
Type
type
ignore
pass
suggestion
simple
check
value
callable
Note
complete
matching
argument
type
hints
return
types
multiline
suggestion
line
Duplication
suggestion
someone
Config
class
sure
comment
sense
suggestion
__args__
generics
cleaner
something
errors
return
v
errors
self.shape
Shape.SET
result
=
set
result
elif
self.shape
Shape.SEQUENCE
isinstance
v
tuple
result
=
tuple
result
elif
isinstance
v
<
case
result
=
set
result
return
result
None
case
v
generator
accurate
iter
new
generator
mad
mypy
devs
something
little
convenience
function
github
issue
fork
copy-pasted
line
convention
NoneType
mypy.types.NoneType
type
None
*
different
alias
type
None
variable
types
finish
comment
suggestion
def
cls_kwargs
cls
Type
[
T
]
kwargs
Dict
[
str
Any
>
T
type
ignore
something
mypy
type
hints
classes
appropriate
alternatives
references
non-test
code
consensus
__bool__
handling
lot
dict
loads
ifs
py
attribute_lookup
name
'minLength
field_name
schema_name
attribute_lookup.items
field_value
=
getattr
field.type_
None
field_value
None
f_schema
[
schema_name
]
=
kind
iterable
loop
better
bash
flake8
pydantic/
tests/
tests/test_main.py:676:17
E731
lambda
expression
def
make
*
*
*
[
lint
]
Error
suggestion
fields
=
k
v
getattr
cls
k
k
v
new_type_hints.items
need
__
*
__
local
variables
suggestion
raise
TypeError
'Invalid
value
suggestion
non-annotation
attributes
line
Best
method
logic
suggestion
types
unchanged
deepcopy
better
use
assert
comment
line
suggestion
equivalent
json.dumps
MainModel.schema
indent=2
better
Thanks
fix
string
str
bytes
string
python
representation
bytes
encoding
payload
creation
time
right
timestamp
definition
execution
time
something
similar
normalized_product_name
docstring
back
None
comment
value
subclass
capital
C
PyParsing
Components
=
>
PyParsing
components
+
start
line
end
Please
change
consistent
description
other
parsers
syslog
parser_mediator
ParserMediator
mediates
interactions
parsers
other
components
such
storage
dfvfs
separate
PR
other
syslog
docstrings
Please
end
line
additional
space
continuation
indentation
consistent
other
definitions
dict
_GetTimeElementsTuple
style
guide
Please
Args
returns
sections
move
todo
merge
SG
return
types
line
indentation
space
beautiful
soup
extra
dependency
deployment
bit
easier
Done
Maybe
comment
page
Please
comment
something
name
field
function
field
value
continuation
indentation
comment
relevant
use
dict
Please
comment
exit
time
Please
comment
idea
user
registry
artifact
registry
hive
files
logic
belong
artifact
filter
helper
artifact
filters
Please
status
thoughts
users
operating
system
name
e.g
OS
artifacts
processing
look
Append
=
>
Appends
name
method
description
method
docstring
wrong
method
benefit
different
name
Boolean
docstring
redundant
format
Returns
section
bool
True
key
compatible
False
Which
dfwinreg
issue
white
space
str
Curr
repeat
other
docstrings
find_specs
dict
[
artifacts.artifact_types
]
Dictionary
containing
brief
look
arg
weird
specs
dfVFS
class
type
information
artifacts.artifact_types
Please
tests
BuildFindSpecsFromFileArtifact
_CheckKeyCompatibility
_ExpandRecursiveGlobs
_BuildRecursivePaths
last
methods
hard
time
code
HELPME
wrong
nit
year
suggestion
Document
request
status
message
NOTHING
TO
DO
many
document
request
document
f.e
enough
copies
many
rejections
type
catalogue
code
ext_status
BorrowingRequest.EXTENSION_STATUSES
is_valid
wrong
many
Documents
Serial
many
safe
items
few
fields
*
Please
TODO
*
Increase
invenio-app
CORS_SUPPORTS_CREDENTIALS
instructions
comment
suggestion
change
invenio.cfg
more
https
//invenioils.docs.cern.ch/quickstart/
invenio-backend
year
updates
part
clean
tasks
codebase
super
unimportant
date
sure
early
return
exceptions
end_date
exception
location
opening_exceptions
]
start_date
=
exception
start_date
]
.date
=
arrow.get
exception
end_date
]
.date
date_in_range
=
start_date
<
=
date
<
=
end_date
date_in_range
return
exception
is_open
]
return
False
sure
None
False
suggestion
exceptionally_open
return
Great
👍
Minor
suggestion
params
suggestion
raise
IlsException
description=
maximum
iterations
loan
date
location
open
date
Please
dates
.format
location
pid
]
date.isoformat
Wrong
date
Make
docstring
Alembic
comments
migration
code
Use
isnot
string
date
datetime
good
occasion
JSON
code
f
string
grants_via
lower
case
default
Email
case-sensitive
possible
comment
function
comment
CSRF
check
comment
NOQA
query
statements
None
column.isnot
None
exception
code
NOQA
A003
hard
delete
from_
state
draft
_unpublished_
delete
method
single
API
callers
Never
use
NOQA
code
line
QA
problem
getitem
needs
field
=
getattr
field_name
event
different
data
structure
others
Appears
accidental
Replace
.filter
ProposalSpace.state.CURRENTLY_LISTED
function
tests
Just
explicit
suggestion
WARNING
pattern
inference
suggestion
transformers
tensors
pad
data
comments
parameter
number_of_dimension
comment
bit
confusing
shape
other
print
commands
such
init
wrap=False
call
[
documentation
]
https
//pypi.org/project/colorama/
init
wrap=True
feature_dimension
confusing
name
features
multiple
dimensions
sure
better
name
keras
number
units
add
comment
comment
first
dimension
example
correct
update
tag
someone
HCA
interested
dataset
constraint
table
foreign
constraint
other
tables
alter
cascade
constraints
alternative
drop_contraint
commands
order
dependency
above
enum
autoincrement
necessary
other
locations
PR
something
INTEGER
type
Columns
suggestion
_columns
=
dict
*
*
columns
*
*
add_columns
keys
columns
add_columns
key
value
add_columns
suggestion
Expire
local
object
DB
sure
transactions
suggestion
Expire
local
objects
DB
sure
transactions
new
development_stage
mock_generate_presigned_url.side_effect
=
ClientError
Ah
little
warning
+1
necessary
tests
better
way
environment
variable
CORPORA_HOME
top
level
project
maintainable
pkg_root
=
os.path.abspath
os.environ
[
CORPORA_HOME
]
suggestion
@
unittest.skipIf
True
runnable
local
dev
env
bastion
tunnel
line
suggestion
project
=
Project.get
self.uuid
self.status
add
comment
populate
result
relationships
suggestion
result
=
column.key
getattr
attr
column
self.__mapper__.c.items
populate
result
columns
Sorry
comment
comment
field
primary
department
institution
user
belongs
case
multiple
departments
future
primary_department
w/o
extra
comment
good
idea
__MACOSX
file
comment
related
fields
understanding
pagination
fix
Elastic
records
appropriate
records
correct
inefficient
way
paginator
default
query
[
size
]
https
//www.elastic.co/guide/en/elasticsearch/reference/current/search-request-body.html
request-body-search-from-size
comment
Could
mechanisms
more
source
tags
nodes
impossible
node
multiple
source
tags
bit
criteria
Courtney
supplemental
node
time
range
determine
supplemental
node
'plain
node
preprint
supplement
Courtney
lookup
prod
db
number
such
nodes
significant
ones
logic
airtight
closest
information
unclaimed_records
field
OSFUser
model
user
unclaimed
record
record
db
second
thing
node
logs
Same
Source
tags
possible
ways
user
system
user
multiple
sources
small
amount
legacy
log
entries
dozen
prod
db
different
format
entries
BrianN
nodes
early
days
OSF
negligible
QuerySet.count
better
Please
tests
normalization
prereg
changeover
date
possible
Preprint.add_unregistered_contributor
Product
new
providers
info
provider._id
provider.readable_type
product
provider
docs
way
rfc3986
hand
host
portion
URI
current
implementation
IPv6
addresses
Reference
UTS
flag
https
//github.com/kjd/idna
compatibility-mapping-uts-46
comment
Nitpick
IDNA
comments
No
idea
mypy
error
line
httpx/_content_streams.py:332
error
string
related
//github.com/encode/httpx/issues/328
comment
b
last
chunk
Transfer-Encoding
chunked
response
level
HTTP
construct
Copy-pasted
asyncio
backend
kind
itches
comment
necessary
typo
🤷‍♂️
Cc
@
tomchristie
write
data
annotations
correct
file
optional
filename
file/str
optional
filename
file/str
content_type
python
typing.Union
[
file
typing.IO
[
typing.AnyStr
]
filename
file
typing.Tuple
[
typing.Optional
[
str
]
typing.Union
[
typing.IO
[
typing.AnyStr
]
typing.AnyStr
]
]
filename
file
str
content_type
typing.Tuple
[
typing.Optional
[
str
]
typing.Union
[
typing.IO
[
typing.AnyStr
]
typing.AnyStr
]
typing.Optional
[
str
]
]
]
other
comments
file
str
suggestion
request/response
stream
invalid
manner
benefit
relative
path
usages
full
one
comprehension
note
—
m
condition
window
max
limit
data
link
appropriate
section
HTTP/2
standard
useful
general
comment
“
data
”
window
sure
value
h2
documentation
[
maximum
value
]
https
//python-hyper.org/projects/h2/en/stable/api.html
h2.connection.H2Connection.max_outbound_frame_size
[
https
//python-hyper.org/projects/h2/en/stable/api.html
h2.connection.H2Connection.send_data
cause
error
form
h2
state
machine
Oops
sorry
suggestion
setattr
_locals
name
]
__module__
httpx
noqa
suggestion
Make
sure
methods
exceptions
check
stage
CI
.authenticators
[
str
str
Optional
[
]
]
i.e
password
non-
None
type
ignore
comment
assert
python
username
_
password
=
netrc_login
assert
password
None
return
BasicAuthMiddleware
username=username
password=password
Nit
suggestion
cases
such
authentication
classes
request
body
comment
other
test
case
RedirectMiddleware
responsibility
response.history
response.next
redirect
requests
possible
current
state
things
comment
different
capitalization
older
versions
different
distros
proxy_app
slave_public
topology
test
comment
test
topology
looks
state
machine
test
comment
more
clarity
future
comment
accurate
race
condition
task
health
process
more
health
check
readiness
check
readiness
check
sure
file
app
ready
task
available
poor
assumption
dcos-vagrant
host
resources
oversubscribed
slower
AWS
cluster
work
bummer
ticket
comment
problem
Thanks
expanduser
express
purpose
cleaner
message
garbled
config
Note
catch
specific
test
case
curious
benefit
[
]
Ditto
assignment
file
same
pattern
assignment
Local
consistency
nice
go
style
other
occurrence
RETCODE
commit
PR
other
site
LGTM
code
intent
alternative
try
assert
'summaryErrorsReport.txt
archived_items
AssertionError
log_data
=
_read_from_zip
z
log.info
summaryErrorsReport.txt
.format
log_data
s/lxlan/vxlan
link
Jira
comment
short
description
problem
way
magic
numbers
code
people
code
CentOS
image
ah
kk
Just
please
comment
Ok
doctoring
comment
@
vespian
line.lstrip
.startswith
possible
lines
ssl_protocols
whitespace
change
obscure
test_default
change
Look
perspective
simple
soldier
Somebody
time
future
same
problem
docstring
least
obvious
decorator
bit
more
doc
object
plain
plain
Fixed
@
Gilbert88
test
field
comment
method
name
indicative
current
pattern
test_if_marathon_pods_can_be_deployed_with_mesos_containerizer
comment
intuitive
comments
file
question
Nice
comment
tuple
fields
single
tuple
name
value
fact
tuple
fields
list
single
tuple
header
name
header
value
second
element
value
header
xfs_info
old
code
/sbin
enough
values
worthless
Comment
.lower
template
input
params
arbitrary
dictionary
assignments
Resource
group
https
//github.com/dcos/dcos/pull/914/files
diff-62f8a6125c076a8784110f740fc8a8d3R68
azure
test
same
fix
https
//mesosphere.atlassian.net/browse/DCOS-12772
tests
green
https
//mesosphere.atlassian.net/browse/DCOS-12772
case
next
push
last
couple
builds
PR
tests
TC
overall
test
successful
https
//teamcity.mesosphere.io/viewLog.html
tab=buildLog
buildTypeId=ClosedSource_Dcos_IntegrationTests_CloudIntegrationTests_DcosOssAzureIntegrati_2
buildId=536571
_state=290
same
thing
https
//github.com/dcos/dcos/commit/1a35a34b395f98527795f50a93acdc8af5702008
AuthInfo
other
PR
annotation
comment
future
addition
noqa
/
link
stand-alone
comment
logic
way
people
link
understanding
code
standard
library
link
code
CPython
repo
link
issue
findable
PR
commit
sample
2-line
outputs
code
comment
people
full
output
looks
py_version
py_version
equal
str
py_version_info
[
:2
]
same
indentation
style
suggestion
pip._vendor.pkg_resources
import
noqa
F401
Distribution
Requirement
bool
Optional
[
bool
]
return
value
List
[
str
]
unbuffered_output
param
unbuffered_output
docstring
comment
place
separate
test
please
single
test
thing
docstring
forgot
None
comment
previous
review
Reason
type
ignore
Reason
type
ignore
IIUC
type
SpinnerInterface
first
spinner
variable
assignment
fine
AuthInfo
alias
Tuple
[
Optional
[
str
]
Optional
[
]
]
use
noqa
Again
line
noqa
suggestion
prompt
=
i
gnore
w
ipe
b
ackup
i
w
b
type
ignore
reason
obvious
anyone
future
good
comment
lesson
list
https
//github.com/pypa/pip/issues/6194
issuecomment-459117736
okay
PR
possible
everything
outrows
mixed
types
sentence
code
comment
approach
PR
nice
comments
worth
comment
environment
displayed
timestamp
local
timezone
same
comment
check
different
file
Hmm
concern
@
pfmoore
https
//github.com/pypa/pip/issues/6587
issuecomment-500651566
comparison
simple
PR
look
Python
versions
feature
box
enhancement
comment
allow_stderr_warning
build
deprecation
Hmm
IIUC
os.getlogin
username
environment
variable
Windows
Let
use
USERNAME
tests
https
//github.com/python/cpython/blob/c4cacc8c5eab50db8da3140353596f38a01115ca/Modules/posixmodule.c
L7112-L7120
Probably
comment
backslashreplace
exists
earlier
versions
usable
version
IIRC
script
script.pip
method
style
following
style
more
common
pip
def
make_requirement_preparer
directory
type
TempDirectory
comment
accurate
comparison
value
properties
last
updated
time
respect
last
time
twin
TODO
comment
Please
uncomment
sure
az
iot
central
device
twin
other
hub
SDK
Basically
connection
strings
subscription
Id
out
box
pattern
SDK
Autorest
versions
nit
A
short
comment
access
body
status
code
response
Add
more
documentation
line
lets
list
something
names
containers
maps
mean
output
layers
method
docstring
good
other
developers
o
Please
comment
field_group
method
Same
auto-connect
slots
explicit
connections
decorator
@
Gustry
entire
area
ie
selection
area
[
flake8
]
__
*
[
E501
]
line
characters
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
F821
]
name
'unicode'
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
F821
]
name
'unicode'
<
Comment
[
SideCI
]
https
//sideci.com
>
shp
line
data_store.default_vector_format
=
jsut
case
default
behaviour
data_store.add_layer
self.output_layer
file_name
indent
line
time
l104
Pull
/
separator
mac/linux
windows
issues
os.path
QFileInfo
QDir
QFile
nothing
mix
legacy
code
pretty
sure
QgsApplication.qgisSettingsDirPath
few
months
function
+1
😋
sorry
root
directory
self._root_directory
QgsApplication.qgisSettingsDirPath
self._root_directory
empty
QgsApplication.qgisSettingsDirPath
QGIS
bug
function
code
QgsApplication.qgisSettingsDirPath
.qgis2
code
error
root
directory
empty
QGIS
bug
code
someone
histroy
bug
code
+0
remove
get_
set_
common
code
base
prefix
correct
name
problem
[
flake8
]
__
*
[
F841
]
local
variable
'cancel_button
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
W391
]
blank
line
end
file
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
E501
]
line
characters
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
W391
]
blank
line
end
file
<
Comment
[
SideCI
]
https
//sideci.com
>
pro
None
empty
list
empty
list
consistent
other
allowed_geometries
list
one
analysis
extent
impact
extent
correct
default
qgis_context.extent
report
generation
correct
approach
analysis
extent
right
ah
comment
sure
logic
L278
L286
extent
extractor
example
different
extractor
other
default
analysis_extent
default
map
extent
default
extent
layers
extractor
dock
use
case
else
part
useful
realtime
headless
custom
extractor
default
consistent
other
names
Evacuation
Centre
comment
@
mpenkov
comment
true
smart_open
methods
code
latin1
iter
built-in
name
good
name
variable
document
poor
comment
obvious
code
Get
rid
t.
suggestion
Windows
OSX
python3.8+
spawn
mode
issues
platforms
simpler
serial
processing
See
https
//github.com/RaRe-Technologies/gensim/pull/2800/files
r410890171
Sorry
wrong
link
suggestion
See
https
//github.com/RaRe-Technologies/gensim/pull/2800
discussion_r410890171
clear
well-sourced
comment
@
jayantj
few
weeks
review
comment
@
piskvorky
statement
white
space
multiple
statements
comment
]
https
//github.com/RaRe-Technologies/gensim/pull/1200
discussion_r116380522
bytes
case
something
more
explicit
clear
i
nwords
i
vocab_size
assert
word
__label__
continue
word
@
piskvorky
meant
multiple
lines
python
logger.warning
mismatch
vocab
sizes
model
other
pretrained
vector
wiki.fr
Please
report
Gensim
comment
PR
format
comments
docstrings
Regular
comments
preferable
PEP8
space
text
new
copy
underlying
array
wasteful
large
vectors
proper
type
consistency
type
float32
weights
empty
initialization
'vectors
specifies
right
type
passed-in
weights
necessary
proper
type
Per
comment
keyedvectors.py
better
float64
arrays
*
*
*
obvious
suggestion
>
>
>
new
model
initial
data
>
>
model
=
PoincareModel
initial_relations
helpful
definition
online_relations
defined
suggestion
>
>
>
online
training
vocabulary
continue
>
>
>
online_relations
[
'striped_skunk
'mammal
>
>
>
model.build_vocab
online_relations
update=True
Magic
comment
+
load
+
infer_vector
%
sure
persistent
Make
sure
/tmp
directory
gensim.test.utils
needed
functions
same
w2v
model
w2v
Please
astype
np.float32
>
np.float32
>
np.float64
>
np.float32
suggestion
Copyright
C
Radim
Rehurek
<
radimrehurek
@
seznam.cz
>
initializer
lot
work
helpful
top
whole
pattern
initializer
good
opportunity
def
_create_source
index
dictionary=None
tfidf=None
symmetric=True
heavy
lifting
matrix
initializer
deal
old
positive_definite
arg
source
source
=
_create_source
source
dictionary=dictionary
symmetric=symmetric
=
source.tocsc
reason
queue
list
diff/convergence
metric
input
ex
different
distance
measures
queue
track
epoch
count
sequence
order
model
topics
Coherence
*
*
kwargs
assignment
name
error
other
variable
*
*
kwargs
info
name
please
parameter
CLI
executable
script
special
case
__doc__
..
program-output
https
//github.com/RaRe-Technologies/gensim/commit/117d447087b2e9a36fda1279d837e045fefd1558
same
lsi_worker
Dtto
docstrings
blank
lines
please
Comment
clear
comments
great
Super
useful
future
maintenance
opposite
generator
more
*
elements
case
thrown-exception
user
docs
length
–
So
logged
warning
–
documents
excess
declared
'length
_length
*
*
greater
*
*
number
items
stream_
exception
user
less
n
docs
Note
length
greater
actual
length
corpus
exception
own
exception
triggers
documents
stream
case
length
smaller
actual
corpus
length
anything
problem
documentation
warning
length
elements
unnecessary
enough
elements
lines
temporary
variable
comment
[
]
better
tuple
variables
score
least
warning.warn
user
much
exception
critical
try
block
exception
problem
TODO
Add
comment
line
example
indexes
documents
input
corpus
useless
method
comment
line
size
limitation
comment
line
full
stops
capitals
sentence
lower
case
method
names
suggestion
sphinx-gallery
dep
need
default
value
trivial
case
docstring
better
something
vectors
entities
vocabulary
True
vectors
old
vectors
TODO
need
please
use
indents
vertical
same
testPersistence
better
gensim
version
model
name
old
comment
informative
please
line
strange
part
test
part
code
script
script
assert
<
CONDITION
>
<
MESSAGE
>
suggestion
NmslibIndexer
instance
file
pattern
class
method
e.g
model
=
FastText.load
'/path/to/file
model
=
FastText
model.load
load
function
documentation
class
method
example
module
docstring
more
method
load
save
thought
combination
other
comments
duplication
word-vecs
KeyedVectors
word-vectors
doc-vecs
necessary
word-writing
vocab-writing
code
KeyedVectors
file
append
doc-vectors
sure
front-of-file
vector-count
correct
KeyedVectors.load_word2vec_format
new
parameter
count
factor
caller
writing
method
possible
cleaner
file
second
time
append-mode
BUT
later
comment
way
method
able
writing
re-open
append
better
something
gz
https
//github.com/numpy/numpy/issues/13470
<
new_custom_code_same_as_in_pr
>
<
old_code
comments
value
source
code
requests
obj
list
obj_iter
obj
iterator
such
iter
[
[
]
[
]
]
special
case
such
iterator
else
obj
lines
Gensim
library
py2/py3
chinmayapancholi13
please
author
baby
Hehe
smile
warnings
comments
comment
line
long
nice
buffer
separate
class
complexity
class
iter
collides
built-in
function
iterations
better
IMO
Minor
thing
IMO
better
main
class
file
helper
last
Please
rename
hypernym_pair
something
more
generic
such
relation
order
conditions
indices
duplicates
line
performance
numpy.array
PoincareRelations
appropriate
IMO
len
redundant
Please
merge
branch
lines
gensim.test.utils
datapath
yesterday
tests
tests
save/load
Please
topn
Dtto
abs
entire
matrix
row
docstrings
work
Agreed
comment
least
spaces
inline
comment
constructor
DAG
poke
operation
runtime
Could
comment
please
comment
Flake8
error
suggestion
sure
times
sync
code
line
comment
Sounds
AnonymousUserMixin
attribute
None
final
logs
comment
undone
same
Can
tests
hook
method
static
static
noinspection
PyTypeChecker
evaluated
true
false
True
Python
style
point
call
http_status_code
single
line
suggestion
self.client_request_token
=
kwargs.get
'client_request_token
comment
regex
other
stoppedReasons
Just
sure
other
reasons
line
sure
DTs
right
cos
local
ambigious
time
sure
pre-condition
time
correct
local_tz
=
pendulum.timezone
'Europe/Zurich
local_tz.convert
datetime.datetime
dst_rule=pendulum.PRE_TRANSITION
self.assertEqual
str
start
2018-10-28
Pre-condition
start
date
DST
timezone.convert_to_utc
start
dag
=
DAG
'tz_dag
start_date=start
schedule_interval=
*
/5
*
*
*
*
=
dag.following_schedule
utc
next_local
=
local_tz.convert
next
self.assertEqual
str
next
2018-10-28
str
next_local
2018-10-28
=
dag.previous_schedule
utc
prev_local
=
local_tz.convert
prev
self.assertEqual
str
prev_local
2018-10-28
=
dag.previous_schedule
next
prev_local
=
local_tz.convert
prev
self.assertEqual
str
prev_local
2018-10-28
prev
utc
Sure
comment
suggestion
frame=
x+ltemperature
r
y+l\260C
]
+Lvelocity
x+lvelocity
more
sense
suggestion
fig.colorbar
cmap=
roma
[
x+lvelocity
y+lm/s
]
suggestion
Colorbar
map
coordinates
g
longitude/latitude
suggestion
frame=
x+lElevation
y+lm
]
suggestion
part
GMT
few
PyGMT
exclusive
savefig
method
nice
able
contents
text
file
quick
way
text
file
python
long-form
arguments
start
differences
documentation
https
//www.pygmt.org/dev/api/generated/pygmt.Figure.text.html
https
//www.pygmt.org/v0.1.1/api/generated/pygmt.Figure.text.html
pygmt.Figure.text
v0.1.2
release
PR
other
documentation
changes
GMT
end
June
nothing
short
aliases
additional
functionality
Better
way
alias
G=color
example
suggestion
*
Vertical
anchor
T
op
M
iddle
B
ottom
*
Horizontal
anchor
L
eft
C
entre
R
ight
fig
=
pygmt.Figure
fig.basemap
region=
[
]
projection=
X10c
[
WSne
af0.5g
]
position
TL
TC
TR
ML
MC
MR
BL
BC
BR
fig.text
text=position
position=position
font=
Helvetica-Bold
black
justify=position
fig.show
whitespace
arithmetic
operator
suggestion
fig.plot
x=
[
x_pos
x_pos
]
y=
[
]
pen=
red
@
commits
section
x/y
pair
position=
TR
text
Top
Right
fig
=
pygmt.Figure
fig.basemap
region=
[
]
projection=
x1c
frame=
position
TL
TR
BL
BR
fig.text
position=position
text=position
offset=
j0.5c+v
fig.show
produces
corner
text
plot
]
https
//github.com/GenericMappingTools/pygmt/raw/187a733d72fc552284bdad3d5c2b81ad5c6d878d/pygmt/tests/baseline/test_text_position_offset_with_line.png
Please
few
comments
meanings
angle=True
font=True
justify=True
columns
input
file
sure
good
idea
*
x
*
*
y
*
string-type
US
spellings
suggestion
size
family/weight
color
annotation
mention
lists/arrays
shorthand
degree
symbol
suggestion
fig.text
text=f
i
@
x=2
y=2
justify=
LM
angle=i
[
image
]
https
//user-images.githubusercontent.com/3974108/96062031-b0c1b200-0e62-11eb-81c3-5cb2338541ad.png
justify
plot
nice
gallery
other
GMT
commands
legend
let
suggestion
fig.plot
x=
[
]
[
y_pos
y_pos
]
pen='3p
red
@
meth
text
method
documentation
suggestion
Text
annotations
map
meth
pygmt.Figure.text
method
Pylint
lowercase
names
classes
Will
comment
meaning
comment
[
source
]
contains
Ok
arguments
x2sys_cross
good
names
[
D
]
https
//docs.generic-mapping-tools.org/6.1/supplements/x2sys/x2sys_cross.html
d
[
Z
]
https
//docs.generic-mapping-tools.org/6.1/supplements/x2sys/x2sys_cross.html
z
Other
functions
PyGMT
output
file
use
>
>
>
suggestion
arg_str
.join
[
build_arg_string
kwargs
f
>
]
suggestion
First
shift_origin
projection
region
long
alias
whole
test
projection
region
J
R
frame
B
suggestion
fig.plot
pen=
black
fig.plot
pen=
white,20p_20p
lines
code
suggestion
Plot
line
different
line
styles
while
Just
few
docstring
suggestions
suggestion
data
netCDF
grid
xarray
change
line
numpy
array
ASCII
NetCDF
works
Python
standard
library
[
itertools.combination
]
https
//docs.python.org/3.8/library/itertools.html
itertools.combinations
function
import
itertools
top
first
following
lines
suggestion
dtypex
dtypey
itertools.combinations
iterable=dtypes
r=2
Thanks
change
old
commit
CI
different
pylint
verison
test
[
flaky
tests
https
//docs.pytest.org/en/stable/flaky.html
test
suite
https
//github.com/GenericMappingTools/pygmt/pull/327
issuecomment-534318735
test
much
time
pytest
verbose
mpl
pygmt/tests/test_grdimage.py
pytest
verbose
mpl
pygmt/tests/test_grd
*
.py
test
test
wrong
rabbit
hole
much
[
pytest
plugins
flakiness
]
https
//docs.pytest.org/en/stable/flaky.html
plugins
pytest-xdist
pytest-flakefinder
much
test_grdimage_over_dateline
issue
tests
trouble
failures
intermittent
semi-random
brief
comment
runfirst
suggestion
coding
utf-8
Sphinx
documentation
configuration
file.
pylint
disable=invalid-name
line
https
//github.com/GenericMappingTools/pygmt/blob/b2a1758555ce94465a29ab7318ca944c4074833c/doc/conf.py
L99
f-strings
redefined-builtin
pylint
warning
copyright
=
f
year
PyGMT
Developers
pylint
disable=redefined-builtin
section
examples
suggestion
libnames
clib_name
os_name=sys.platform
e.g
libgmt.so
libgmt.dylib
gmt.dll
libpath
=
env.get
GMT_LIBRARY_PATH
e.g
HOME/miniconda/envs/pygmt/lib
newline
end
file
way
meca
implementation
pandas.DataFrame
s
building
DongDong
answer
https
//forum.generic-mapping-tools.org/t/accessing-gmt-test-suite-files-using-syntax/655/3
data
files
[
pandas.read_csv
]
https
//pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html
df
=
pd.read_csv
https
//raw.githubusercontent.com/GenericMappingTools/gmt/master/test/seis/fullmt_ipts1_iref1
\s+
header=None
use
[
pd.to_csv
]
https
//pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html
output
file
GMT
cache
options
other
fancy+
graph
graph
maps
suggestion
possible
default
parameters
reST
syntax
double
backticks
inline
codes
suggestion
session
Python
users
likely
familiar
open
file
snippet
suggestion
shift
plot
origin
map
fig.shift_origin
-10c
figure
default
fancy
frame
fig.basemap
region=
[
]
projection=
M10c
frame=True
fig.coast
land=
black
water=
skyblue
Figure.shift_origin
easier
suggestion
single
command
sequence
commands
application
pygmt.config
context
true
global/default
setting
fancy
example
fig
=
pygmt.Figure
fancy+
frame
pygmt.config
MAP_FRAME_TYPE=
fancy+
fig.basemap
region=
[
]
projection=
M10c
frame=True
fig.coast
land=
black
water=
skyblue
figure
default
fancy
frame
fig.basemap
region=
[
]
projection=
M10c
Y=
-10c
frame=True
fig.coast
land=
black
water=
skyblue
suggestion
file
context
manager
way
parameter
suggestion
>
>
>
load
default
grid
degree
resolution
pixel
registration
>
>
grid
=
load_earth_relief
>
>
grid
gridline
registration
>
>
>
grid
=
load_earth_relief
registration=
gridline
load
high-resolution
grid
specific
region
>
>
>
grid
=
load_earth_relief
[
]
suggestion
def
shift_origin
yshift=None
seisman
self._preprocess
sure
right
figure
great
design
other
figure
module
metaclass
eager
more
information
great
explanation
None
False
good
obvious
column
names
specific
baseTables
My
previous
comment
pointers
Hey
@
mozbhearsum
thank
context
comment
wording
comment
bit
larger
previous
new
complex
logic
more
detail
Sorry
comment
couple
small
clarifications
>
Primary
Key
columns
Integer
Autoincrement
nullable
nullable
base
table
scheduled
changes
possible
nullable
base
table
part
key
Non-Primary
Key
columns
baseTable
become
nullable
non-unique
>
deletion
null
values
non-PK
non-nullable
>
unique
baseTable
%
right
nullable
part
uniqueness
subtle
case
rules.alias
Rules
table
place
rule_id
places
uniqueness
necessary
field
alias
business
logic
Rules
business
logic
things
uniqueness
place
rules_scheduled_changes
things
different
base
table
columns
part
business
logic
Scheduled
Changes
table
values
real
job
Scheduled
Changes
place
new
versions
base
table
row
certain
conditions
job
Changes
needs
track
conditions
signoffs
base
table
columns
simple
data
storage
info
comment
update
helpful
background
None
property
column
some_column.unique
returns
None
unique=False
sqlalchemy
afaik
database
turn
column
database
unique
False
bit
convoluted
comment
explicit
Ah
difference
nullable
True
None
None
right
thing
case
updated
comment
resoures
utf-8
-https
//docs.python.org/2/howto/unicode.html
encodings
UTF-8
several
convenient
properties
Unicode
code
point
//flask.pocoo.org/docs/0.12/unicode/
Today
look
werkzeug
docs
https
//github.com/pallets/werkzeug/blob/0bc61df6e1ae9f2ffdf5d066aa3cd9d5ebcb307d/docs/unicode.rst
unicode-in-http
Seems
open
PR
strings
UTF-8
connexion
zalando/connexion
sure
Werkzeug
docs
talk
UTF-8
concerned
non-ASCII
data
URL
garbage
best
'val.encode
ascii
ignore
unparseable
characters
field
usable
state
Ah
non-ASCII
chars
garbage
OK
more
tests
parameter
chars
Werkzeug
UTF-8
data
@
catlee
utf-8
great
thing
sorts
different
encodings
idea
correct
Werkzeug
Flask
behaviour
necessary
bug
rid
now-unnecessary
rule
Same
comments
agent/setup.py
response
body
bug
return
useful
information
comment
update
*
ready
sense
~8
lines
comment
applies
comment
Line
sentence
typo
heistory
vs
history
production
case
other
design
protection
someone
local
agent
dev
admin
cookies
ssl
local
dev
real
value
marginal
hashes
rid
first
part
statement
new
part
Thanks
Nit
please
use
multiple
lines
easier
rules
Hm
idea
Rules
code
interesting
one
worth
future
TODO
own
single
line
item
own
TODO
indexed
short
line
update
comment
method
below
arguments
explicit
secret
config
file
need
ways
same
thing
multiple
processes
confused
comments
quick
GVC
Which
user
command
default
option
error
message
user
local
docker
similar
parameter
circle
ci
config
file
case
document
help
string
good
comment
value
rate
value
environment
variable
/
similar
nit
at_at
kind
event
Make
condition
leader
None
leader
set
label
check
_current_leader
none
method
check
method
method
is_resource_expired
something
model
label
multiple
nodes
leader
election
oldest
nodes
drawback
label
set
nodes
label
method
something
kind
name
namespace
method
many
lines
place
readability
comment
limit
factors
obvious
documentation
branch
little
confusing
self.__target_pids
string
cases
list
numbers
Add
comment
path
equal
[
'path
]
comment
multiplier
bucket
size
comment
docker
docker
module
container
image
Sorry
exact
text
good
Did
newline
characters
separate
lines
particular
reason
raw
strings
2-
>
migration
careful
string
usage
something
though
sure
query
events
test
instance
other
events
other
tests
same
Scalyr
account
line
lines
authorization
problem
i.e
misconfigured
service
account
exception
line
lines
=
k8s_api_events.stream_events
last_event=last_event
generic
exception
message
detailed
message
authorization
issues
other
generic
API
errors
comments
Eh
fine
TODO
Add
comment
bug
todo
old
implementation
code
Hmm
yeah
purist
character
check
code
readable
overhead
place
right
deterministic
behavior
JSON
libraries
case
test
failures
thing
more
explicit
test
case
last
character
serialized
dict
tests
common
behavior
JSON
libraries
test
important
Overkill
Add
comment
different
form
bad
checkpoint
file
comments
example
case
bad
checkpoint
file
agent
checkpoint
file
logfiles
end
case
lines
..
TODO
imron
something
try
label_exclude_globs
=
label_exclude_globs
label_include_globs
=
monitor.label_include_globs
use_labels_for_log_config
=
monitor.use_labels_for_log_config
label_prefix
=
monitor.label_prefix
=
monitor.labels_as_attributes
=
label_exclude_globs
self.label_include_globs
=
self.use_labels_for_log_config
=
use_labels_for_log_config
self.label_prefix
=
label_prefix
=
labels_as_attributes
Exception
e
exception
anything
self
values
monitor
comment
live
upstream
Libcloud
statement
six.ensure_str
https
//six.readthedocs.io/
six.ensure_str
suggestion
return
uuid.uuid3
namespace
six.ensure_str
name
comment
JsonObject.__num_to_bool
functionality
Hmm
key
environment
none
configuration
file
api_key
gem5
system
executed
command
/s
exceptino
>
exception
point
check
platform_tools
None
*
*
utils/android.py
*
*
code
HostError
directory
Right
tempfile
A
V
W.
Code
power
data
instrument
data
loss
precision
concern
practice
noisy
power
measurements
wrong
issue
milli
updating
other
energy
instrument
same
output
dict
Instrument
output
channels
such
<
probe
>
/
<
site
>
_
<
kind
>
p
channel
name
function
channel
able
output
way
<
site
>
<
probe
>
/
<
site
>
IIOINA226Instrument.reset
corresponding
method
parent
something
obvious
drawback
design
choice
Instrument
Instrument
s
multiple
active
probes
dictionary
MeasurementCsv
s
parent
interface
probes
single
CSV
probes
different
rates
CSV
probe
more
samples
*
i.e
more
lines
CSV
probe
single
run
solution
user
different
rates
bit
extreme
probe
own
timestamps
samples
different
probes
same
sampling
frequency
same
times
CSV
multiple
probes
multiple
timestamp
columns
past.builtins
map
change
list
comprehension
order
compatible
Py2
Py3
http
//python-future.org/compatible_idioms.html
map
super
Sorry
suggestion
setup
intial_trace
simpler
solution
initial_trace
setup
end
small
change
z
name
node
value
.detach
name
node
self._iter_latent_nodes
*
*
self.initial_trace
*
*
....
initial
trace
much
simpler
overall
validation
checks/nan
warnings
grad
Could
case
tests/test_examples.py
example
testing
diff
def
discover_examples
root
dirs
files
os.walk
EXAMPLES_DIR
basename
files
num-epochs
text
args
=
[
num-epochs=1
]
elif
num-steps
text
args
=
[
num-steps=1
]
+
elif
num-samples
text
+
args
=
[
num-samples=1
]
main
file
couple
lines
docstrings
martin
happy
spin
tuples
Could
comment
super
added
upstream
comment
variational
family
true
posterior
Prefer
torch.distribution.constraints
e.g
torch.distributions
import
constraints
sw_param
=
pyro.param
guide_scale_weight
w_sig
constraint=constraints.positive
constraint
Does
tensor
comment
vectorized
non-vectorized
case
n=1
weight
immaterial
familiar
score
parts
computation
use
non
case
nit
.sum
nit
epsilons_sqr.sum
nit
surprised
log_sum_exp
nit
scale_product
=
scale.prod
cuda-compatible
torch.arange
invocation
Use
math.log
*
math.pi
unnecessary
numpy
depencency
numpy
float
datatypes
n_unsqueezes
comment
trouble
anything
particular
len
sample_shape
-1
locs.expand
which.shape
+
dim
correct
GPU
device
placement
py
zero_loc
=
K.new
]
.expand
self.input_dim
best
idea
noise
*
kernel
*
own
hypers
way
comment
inefficient
gesv
NxN
matrix
GPML
book
Gaussian
Processes
Machine
Learning
correct
pseudocode
same
comment
@
look
comment
way
typing
PR
same
comment
line
uncomment
comment
lines
issue
depends
args
global
variable
main
little
cleaner
lazy
global
pattern
ok
lazy
global
version
jittable
itd
nice
user
posterior
itd
useful
paper
description
topic
model
details
short
summary
model
side
enumeration
problem
benefits
note
comments
nan
logic
direction
encounter
nan
step_size
current
behavior
works
good
comment
comment
nit
purpose
torch.tensor
wrapper
places
surprised
tensor
init
arg
lambda
later
iterations
nit
initializing
pair
@
offline
@
poutine.broadcast
def
model
=
x.size
pyro.iarange
w_top_iarange
self.top_width
*
self.mid_width
w_top
=
pyro.sample
w_top
Gamma
self.alpha_w
self.beta_w
w_top.shape
==
self.top_width
*
self.mid_width
similar
w_mid
w_bot
pyro.iarange
data
z_top
=
pyro.sample
z_top
Gamma
self.alpha_z
self.alpha_z
.expand
[
self.top_width
]
.independent
z_top.shape
==
self.top_width
mean_mid
=
torch.mm
z_top
w_top.reshape
self.top_width
self.mid_width
z_mid
=
pyro.sample
z_mid
Gamma
self.alpha_z
self.alpha_z
/
mean_mid
.independent
z_mid.shape
==
self.mid_width
similar
z_bot
git
aware
something
git_head_is_tag
version
=
git_tag
major
versions
version
=
git_commit
:8
]
dev
nit
lazy
py
torch.distributions.utils
lazy_property
class
PermuteTransform
Transform
lazy_property
def
inv_permutation
result
=
self.permutation
result
[
self.permutation
]
=
torch.arange
device=self.permutation.device
return
result
Assumption
implicit
scale_tril
dependent
Done
whitelist
Thanks
self.cleanup
logic
need
pieces
code
cleanup
sense
LGTM
possible
TODO
comment
easy
pattern
hard
alicanb
doctest
docs
failure
prints
output
tests
help
fixing
e.g
>
>
lsh.nearby
set
[
b
]
cheaper
simpler
cache
pairs
pair
caches
nit
simplfy
.items
py
ordinal
log_prob
leaves_log_probs.items
nit
.items
py
target_ordinal
log_prob
self.log_probs.items
continue
log_factors
self._get_log_factors
target_ordinal
target_ordinal
]
=
+
sum
log_factors
empty
frozenset
empty
tuple
py
self.root
=
frozenset
bit
confusing
py
target_ordinal
log_prob
self.log_probs.items
target_ordinal
<
other
other
self.log_probs
continue
leaf
predecessors
log_factors
self._get_predecessors_log_factors
target_ordinal
target_ordinal
]
=
sum
log_prob
+
log_factors
nit
parametrized
test
@
pytest.mark.parametrize
]
def
test_dynamic_lr
scheduler
steps_per_epoch
epoch
range
scheduler.set_epoch
epoch
_
range
steps_per_epoch
svi.step
@
fritzo
attribute
=
epoch
curious
site_filter
version
kind
method
forms
pattern
Distribution.reshape
Distribution.mask
@
eb8680
.add
.mul
methods
default
usage
@
fehiepsi
Let
commented
code
codebase
lots
false
positives
nit
noqa
F403
flake8
import
error
other
modules
same
idiom
Cap
evals
numerical
instability
Commented
code
useful
test_examples
matplotlib
example
code
Somewhat
arbitrary
cutoff-
necessary
overflow
LBFGS
informative
output
print
bob
marginal
probability
sum
]
same
message
print
alice
true
marginal
probability
sum
]
python
..
best
output
check
doctest
+SKIP
comments
=
value.dim
X
only
difference
other
GP
models
parameter
unit
normal
prior
variational
guide
MAP
guide
literature
MAP
guide
poor
results
nit
np.random.randint
=
]
Thanks
comments
walkthrough
torch.eye
jitter
much
slower
sorry
comment
function
ambiguous
ambiguous
more
tests
pyro.__version__
PyPi
local
file
system
install
similar
rtd
conditional
rtd
complicated
bit
few
more
comments
following
version
idx
=
self._categorical.sample
sample_shape
sample_shape
x
batch_shape
correct
samples
shape
batch_shape
x
num_samples
>
num_samples
batch_shape
x
event_shape
samples
empirical._samples.unsqueeze
.transpose
.squeeze
self._aggregation_dim
+
idx
shape
compatible
samples
shape
idxs
=
idx.reshape
-1
empirical.batch_shape
+
empirical.event_shape
=
idxs.expand
-1
empirical.batch_shape
+
empirical.event_shape
return
samples.gather
idxs
.reshape
sample_shape
+
samples.shape
]
same
comment
Add
comments
how/why
predictions
way
Add
comment
kernel
Add
comment
pyro.module
way
Add
comment
likelihood
model
latent_shape
whitening
Nice
suspicious
mean
cov
MultivariateNormal
different
shape
Did
dist.MultivariateNormal
S.new_zeros
S.shape
[
-1
]
S
torch.t
compatibility
Numpy
operator
x.t
x.transpose
broadcasting
x.transpose
-1
-2
.t
.transpose
-1
-2
closer
able
broadcasting
.squeeze
.view
diff
logits
torch.stack
logits
logits
torch.stack
logits
.contiguous
.view
-1
comment
special
case
comment
special
case
variable
name
unintuitive
multinomial
sampling
case
comment
multinomial
slice
case
comment
nit
order
conditionals
more
natural
==
float
-inf
other_half_tree
==
float
-inf
return
-inf
return
logsumexp
torch.stack
[
half_tree.size
]
dim=0
above
comment
else
block
entire
sequence
occurrence
negative
element
case
elements
easiest
interface
args
Bernoulli
def
__init__
loc
covariance_matrix=None
scale_tril=None
covariance_matrix
None
scale_tril
None
raise
ValueError
least
covariance_matrix
scale_tril
scale_tril
None
covariance_matrix
=
elif
covariance_matrix
None
scale_tril
=
comments
interface
clearer
alternative
arguments
sigma=None
chol_sigma=None
derive
other
single
sigma
flag
is_cholesky=False
consistent
other
distributions
classes
Bernoulli
Categorical
probs=False
logits=False
other
common
first
common
compatibility
Tensorflow
Distributions
preferable
mu
>
loc
sigma
>
covariance_matrix
sigma_cholesky
>
scale_tril
reference
https
//www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/distributions/MultivariateNormalCholesky
https
review
comment
helpful
code
future
Could
comment
useful
matrix_inverse_compat
.loc
.scale
super
fourth
value
Could
TODO-igoldan
TODO
right
sense
scheduler
django
command
suggestions
good
Did
jobs
comment
wrong
nit
extra
spaces
indent
lines
extra
spaces
indentations
Please
*
separate
*
TODO
nonnullable
PERHERDER_DATA
dumps
unit
field
Could
TODO
comment
handling
.json.gz
>
.json
change
way
trains
local
file
Redis
load
initial
runtime
id_token
python-jose
access_token
jwt
[
docs
]
http
//python-jose.readthedocs.io/en/latest/jwt/api.html
module-jose.jwt
>
access_token
str
“
at_hash
”
claim
claim
set
access_token
“
at_hash
”
claim
Please
wrong
understanding
access
token
email
address
Agreed
more
noise
useful
success
exceptions
warnings
better
function
comments
tripple-quotes
docstrings
lets
ignore
=
[
[
taskcluster
error
]
'Assertion
failure
Error
'runjunit.py
]
callback
ValueError
check
localhost
function
_2FA
skip
GITHUB_CLIENT_ID
GITHUB_CLIENT_SECRET
environment
variables
comment
meant
Could
comment
empty
queryset
empty
array
comment
Buildbot
bridge
BBB
Please
uncomment
delete
current
value
PULSE_PUSH_SOURCES
production
exchange
exchange/taskcluster-github/v1/push
routing_keys
]
exchange
exchange/taskcluster-github/v1/pull-request
routing_keys
]
exchange
exchange/hgpushes/v1
routing_keys
]
PULSE_PUSH_SOURCES
environments
*
*
*
changes
ingestion
safe
merging
defaults
value
moment
deployment
fixed
constant
environment
variable
configuration
list
time
people
file
PR
defaults
master
Thoughts
comment
data
variable
purpose
clearer
shell
.venv
@
Armens-MacBook-Pro
treeherder
%
python
version
Python
.venv
@
Armens-MacBook-Pro
treeherder
%
python
-c
import
sys
Traceback
recent
call
last
File
<
string
>
line
<
module
>
AttributeError
module
attribute
.venv
@
Armens-MacBook-Pro
treeherder
%
python
-c
import
sys
hasattr
sys.real_prefix
Traceback
recent
call
last
File
<
string
>
line
<
module
>
AttributeError
module
attribute
works
os.environ.get
VIRTUAL_ENV
worth
prod-replica
actual
production
database
global
vars
function
least
suites
one
single
extra
options
field
ValidationError
clearer
message
helpful
secretary
work
bugs
TODOs
variables
production
tests
extraction
JSON
push
BigQuery
same
question
'Can
Django
ORM
comment
latest
commit
appropriate
comment
Look
user
username/clientId
email
s/should
overridden
tier/
similar
@
imskr
changes
preference
look
easier
Somewhere
settings.COMMENTER_API_KEY
None
errors
stage/dev
API
key
duplicate
bug
comments
check
caller
submit_bug_comments
check
dry_run
dry
run
load
print
statements
Papertrail
lot
noise
used
right
point
use
variable
name
files
add
comments
value
constant
eg
https
//github.com/sarah-clements/treeherder/blob/b652af0f1635989475038d426ff211a00130aad2/treeherder/intermittents_commenter/commenter.py
L63-L64
reporter
tool
generates
reports
BackfillReport
Just
flow
consistency
approach
Basically
BackfillReport
s
frozen
mature
Iterate
PRELIMINARY
children
READY_FOR_PROCESSING
reports
frozen
function
anything
todo
item
bug
dead
code
INFO
settings
JSON
dump
Typo
settings
windows
comment
more
human
readable
reasonable
thing
comment
hack
something
trees
e.g
comm-central
decision
task
taskcluster
jobs
comment
licence
header
files
licence
file
root
repository
necessary
boilerplate
Could
header
files
much
over-complex
regexes
email
regex
way
Client
IDs
forms
email/foo
@
bar.com
mozilla-ldap/foo
@
bar.com
Email
regex
http
//emailregex.com
CLIENT_ID_RE
=
re.compile
r
^
email|mozilla-ldap
/
[
a-zA-Z0-9_.+-
]
+
@
[
a-zA-Z0-9-
]
+\.
[
a-zA-Z0-9-
+
match
=
CLIENT_ID_RE.match
client_id
match
return
match.group
raise
NoEmailException
email
clientId
.format
client_id
CLIENT_ID_RE
module
function
happy
value
query
get
failures
data
structure
destination
production
sense
projects
projects
[
]
projects
default
Destination
default
exchanges
sense
moment
production
logging
level
higher
https
//github.com/mozilla/treeherder/blob/ae0f12f5ba9540f7998d3fcfbb52f956ca06dbae/treeherder/config/settings.py
L212
warning
logger.warn
line
characters
worth
wrapping
self.weekly_mode
intermediate
variable
conditional
removed
comment
code
only
callsites
update_after_verification
user
request.user
user
conditional
TODO
item
settings
file
TODO
Review
code
sure
comments
sense
expected_task_count=1
lone
mysterious
named_constant
something
similar
L117
sdk_utils
method
in_strict_mode
[
]
https
//github.com/mesosphere/spark-build/blob/master/testing/sdk_utils.py
L118
env
var
dispatcher
file
same
approach
descriptive
private
method
comments
code
readable
comment
useful
clear
subsequent
line
dashboard
E265
comment
*
Origin
PycodestyleBear
E265
Section
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tests/xml2/XMLBearTest.py
+++
b/tests/xml2/XMLBearTest.py
@
@
-89,7
+89,7
@
@
output
case
xmllint
Test
case
re-enabled
XMLBear
handles
output
uncomment
line
invalid_files=
invalid_xml_relaxng
+
invalid_files=
invalid_xml_relaxng
settings=
escape
relaxng_file_path
'\\
tempfile_kwargs=
'.xml
E501
line
characters
*
PycodestyleBear
E501
severity
NORMAL
section
autopep8
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/bears/__init__.py
+++
b/bears/__init__.py
@
@
-36,7
+36,7
@
@
coala
coala-bears
latest
version
'pip3
install
-U
coala-bears
.format
coalib.__version__
__version__
ImportError
pragma
cover
ImportError
pragma
cover
logging.error
'Module
coalib
version
least
spaces
inline
comment'
*
PycodestyleBear
E261
severity
NORMAL
section
autopep8
None
same
default
values
Fixed
header
B
P
PipRequirement
vice
imo
Header
A
Header
B
Text
text
next
section
+1
rename
ng_words
better
no_good_words
\+
Rephrase
Set
NG
No
Good
words
https
//github.com/coala/coala-bears/issues/1576
issuecomment-305091004
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/bears/general/TextLintBear.py
+++
b/bears/general/TextLintBear.py
@
@
-69,94
+69,94
@
@
check_invalid_link
bool=True
textlint_config
str=
param
keyword_todo
rule
[
TODO
text
param
no_start_duplicated_conjunction
rule
sentence
conjunction
param
no_empty_section
rule
empty
section
example
empty
section
Header
B
Header
A
+
+
param
keyword_todo
+
rule
[
TODO
text
+
param
no_start_duplicated_conjunction
+
rule
sentence
duplicated
+
conjunction
+
param
no_empty_section
+
rule
empty
section
+
example
empty
section
Header
B
+
Header
A
text
+
text
Header
B
param
check_date_weekday_mismatch
rule
mismatch
date
corresponding
weekday
param
ginger
rule
English
grammar
Ginger
Proofreading
param
max_lines_per_file
Number
lines
file
param
max_comma_per_sentence
Number
commas
sentence
param
check_ng_words
rule
NG
No
Good
words
NG
words
param
period_in_list_item
rule
period
list
item
param
minimum_acronym_length
Minimum
length
unexpanded
acronym
param
maximum_acronym_length
Maximum
length
unexpanded
acronym
param
ignore_acronyms
list
acronyms
param
check_rousseau
rule
English
sentence
rousseau
param
check_alex
rule
gender
favouring
polarising
race
religion
inconsiderate
other
unequal
phrasing
param
check_common_misspellings
rule
common
misspellings
Wikipedia's
list
common
misspellings
param
write_good
rule
English
styles
https
//github.com/btford/write-good
param
check_invalid_link
rule
link
document
available
textlint_config
return
None
options
'no-todo
keyword_todo
'no-start-duplicated-conjunction
no_start_duplicated_conjunction
'no-empty-section
no_empty_section
'date-weekday-mismatch
check_date_weekday_mismatch
'ginger
ginger
'max-number-of-lines
'max
max_lines_per_file
'max-comma
'max
max_comma_per_sentence
'ng-word
'words
check_ng_words
'period-in-list-item
period_in_list_item
'unexpanded-acronym
minimum_acronym_length
maximum_acronym_length
'ignore_acronyms
'rousseau
check_rousseau
check_alex
'common-misspellings
check_common_misspellings
'write-good
write_good
'no-dead-link
+
Header
B
+
+
param
check_date_weekday_mismatch
+
rule
mismatch
date
corresponding
+
weekday
+
param
ginger
+
rule
English
grammar
Ginger
Proofreading
+
param
max_lines_per_file
+
Number
lines
file
+
param
max_comma_per_sentence
+
Number
commas
sentence
+
param
check_ng_words
+
rule
NG
No
Good
words
NG
words
+
+
param
period_in_list_item
+
rule
period
list
item
+
param
minimum_acronym_length
+
Minimum
length
unexpanded
acronym
+
param
maximum_acronym_length
+
Maximum
length
unexpanded
acronym
+
param
ignore_acronyms
list
acronyms
+
param
check_rousseau
+
rule
English
sentence
rousseau
+
param
check_alex
+
rule
gender
favouring
polarising
race
+
religion
inconsiderate
other
unequal
phrasing
+
param
check_common_misspellings
+
rule
common
misspellings
Wikipedia's
+
list
common
misspellings
+
param
write_good
+
rule
English
styles
+
https
//github.com/btford/write-good
+
param
check_invalid_link
+
rule
link
document
+
available
+
textlint_config
+
None
+
+
options
+
'no-todo
keyword_todo
+
'no-start-duplicated-conjunction
+
no_start_duplicated_conjunction
+
'no-empty-section
no_empty_section
+
'date-weekday-mismatch
check_date_weekday_mismatch
+
'ginger
ginger
+
'max-number-of-lines
max_lines_per_file
+
+
'max-comma
max_comma_per_sentence
+
+
'ng-word
'words
check_ng_words
+
'period-in-list-item
period_in_list_item
+
'unexpanded-acronym
minimum_acronym_length
+
'max_acronym_len
maximum_acronym_length
+
'ignore_acronyms
ignore_acronyms
+
+
check_rousseau
+
'alex
check_alex
+
'common-misspellings
check_common_misspellings
+
'write-good
write_good
+
'no-dead-link
check_invalid_link
+
default_config
=
'rules
options
'plugins
[
'rst
return
json.dumps
default_config
default_config
=
+
'rules
options
'plugins
[
'rst
]
+
+
return
json.dumps
default_config
staticmethod
def
create_arguments
filename
file
config_file
fine
default
behaviour
+1
rule
checks
occurrences
[
content
todos
RST
syntax
please
:3
Markdown
P
empty
section
Header
A
<
double
colons
Header
A
Header
B
Text
bad
same
documentation
[
]
https
//github.com/coala/coala-bears/blob/master/bears/natural_language/WriteGoodLintBear.py
L57-L58
*
*
*
*
date
bit
high
values
equivalent
feature
todo
example
line
Header
A
Header
B
Text
[
default
]
https
//github.com/azu/textlint-rule-max-comma
configure
[
default
]
https
//github.com/azu/textlint-rule-max-number-of-lines
configuration
E006
error
consistency
variable
E006_bad
comment
long
lines
such
comments
other
variables
meaning
error
codes
other
tests
blank
line
style
blank
line
consistent
other
examples
shouldnt
due
above
comment
pragma
cover
additional
tests
difficulty
chunks
code
test
|\
[
skip
appveyor\
]
whole
different
variable
brackets
E265
block
comment
*
Origin
PycodestyleBear
E265
Section
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpq7d1ckkd/bears/natural_language/LanguageToolBear.py
+++
b/tmp/tmpq7d1ckkd/bears/natural_language/LanguageToolBear.py
@
@
-63,7
+63,7
@
@
try
tool
=
LanguageTool
natural_language
motherTongue='en_US
ValueError
'en-US
language
'en-US
language
logging.warn
natural_language
'en-US
language_check
valid
language
Line
inconsistencies
Tabs
spaces
*
Origin
SpaceConsistencyBear
Section
python
issue
following
patch
diff
a/tmp/tmpq7d1ckkd/bears/natural_language/LanguageToolBear.py
+++
b/tmp/tmpq7d1ckkd/bears/natural_language/LanguageToolBear.py
@
@
-63,7
+63,7
@
@
try
tool
=
LanguageTool
natural_language
motherTongue='en_US
ValueError
'en-US
language
'en-US
language
logging.warn
natural_language
'en-US
language_check
valid
language
comment
-block
line
common
placement
test
pragma
cover
btw
specify
bears
analysis
slip
Line
inconsistencies
Trailing
whitespaces
*
Origin
SpaceConsistencyBear
Section
all.python
issue
following
patch
diff
a/tmp/tmpw92qch8j/bears/c_languages/GNUIndentBear.py
+++
b/tmp/tmpw92qch8j/bears/c_languages/GNUIndentBear.py
@
@
-160,7
+160,7
@
@
limit
number
max
C
max_line_length
max_line_length
=
+
indent_options
no-tabs
use_spaces
use-tabs
line-length
max_line_length
indent-level
indent_size
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpw92qch8j/bears/c_languages/GNUIndentBear.py
+++
b/tmp/tmpw92qch8j/bears/c_languages/GNUIndentBear.py
@
@
-160,7
+160,7
@
@
limit
number
max
C
max_line_length
max_line_length
=
+
indent_options
no-tabs
use_spaces
use-tabs
line-length
max_line_length
indent-level
indent_size
comment
large
more
correct
testing
lenth
'79
test
data
chars
trigger
range
algorithm
activates
right
number
characters
meaningful
name
tests
readable
nope
way
long
string
P
reason
do
else
part
code
something
like
tabs
default
indent_size
=
stripped_desc
=
line
'\t
*
+
line
line
stripped_desc
definition
docstring
use_spaces
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpi6wwtnit/bears/documentation/DocumentationStyleBear.py
+++
b/tmp/tmpi6wwtnit/bears/documentation/DocumentationStyleBear.py
@
@
-90,7
+90,6
@
@
stripped_desc
=
line
+
line
line
stripped_desc
new_desc
=
stripped_desc
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmp00z1dnqz/bears/documentation/DocumentationStyleBear.py
+++
b/tmp/tmp00z1dnqz/bears/documentation/DocumentationStyleBear.py
@
@
-90,7
+90,6
@
@
stripped_desc
=
line
+
line
line
stripped_desc
new_desc
=
stripped_desc
unexpected
indentation
comment
Origin
PycodestyleBear
E116
Section
*
Line
longer
Origin
LineLengthBear
Section
linelength
*
pragma
specific
previous
code
errors
stderr
self.warn
*
*
real
results
json
stdout
Result
objects
modified
approach
stderr
_or_
stdout
rename
unarchived_file
check_validity
move
next
line
pause
reading
comma
bear
link
https
//github.com/coala/coala-bears/issues/1726
redundancy
InvalidLinkBear
check_invalidity
check_validity
check_validity
E261
least
spaces
inline
comment'
*
PycodestyleBear
E261
severity
NORMAL
section
autopep8
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/bears/documentation/DocGrammarBear.py
+++
b/bears/documentation/DocGrammarBear.py
@
@
-33,7
+33,7
@
@
LanguageTool
correct
return
True
ImportError
pragma
cover
ImportError
pragma
cover
language-check
pip
package
def
process_documentation
CONTROL_START_REGEX
nah
nah
string
E501
line
characters
Origin
PycodestyleBear
E501
Section
*
line
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/tests/shell/ShellCheckBearTest.py
+++
b/tests/shell/ShellCheckBearTest.py
@
@
-35,7
+35,8
@
@
Check
option
ShellCheckBear2Test
=
verify_local_bear
ShellCheckBear
valid_files=
+
valid_files=
+
valid_with_ignore_rules_file
settings=
'ignore_rules
SC2164
new
test
documentation
style
param
generate_config
config
generation
hamlling_config
return
None
code
performance
unnecessary
config
file
generations
user
custom
hammlint
config
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/tests/python/MypyBearTest.py
+++
b/tests/python/MypyBearTest.py
@
@
-23,7
+23,7
@
@
self.check_validity
self.uut
[
type
int
]
valid=True
self.check_invalidity
self.uut
[
=
'abc
type
int
]
[
=
'abc
type
int
]
def
test_call_sum
self.check_validity
self.uut
other
checks
=
super
base_check
True
'travis
super
base_check
internet
check
sorry
joy
rules
stuck_out_tongue
Oops
branch/tag
mistake
right
Same
outside
weird
first
variable
bock
javascript
Python
variable
function
javascript
var
call
context
manager
rest
outside
Same
level
context
manager
comment
PR
title
part
commit
message
number
i.e
call
GitHub
API
variable
something
new_entry
output
import
StringIO
Same
comment
naming
methods
obvious
booleans
Forgot
mention
last
review
Ca
https
//docs.python.org/3/library/io.html
io.StringIO
import
StringIO
main
entry
point
needs
import
statements
Travis
CI
check
order
key
value
suggestion
AF_INET
SOCK_STREAM
default
explicit
such
low-level
lib
closing
socket.socket
socket.AF_INET
socket.SOCK_STREAM
sock
Timeout
initial
sock
sock.settimeout
self.timeout
try
self.enable_ssl
sslsocket
closing
context.wrap_socket
sock
server_hostname=self.host
ssock
return
self._get_data
ssock
command
return
self._get_data
sock
command
socket.timeout
socket.error
raise
ZKConnectionFailure
raise
issue
several
entries
different
labels
prometheus
message
several
labels
same
metric
rate
metric
wrong
value
second
metrics
rate
metrics
explanation
comment
own
sanity
comment
Looks
whitespace
CI
comments
Nit
Suggestion
verbosity
parameters
.add
scalar=
next=
Python
kw-only
usage
readability
Adding
defaults
scalar=
[
]
tests
Sequence
List
allows
empty
tuples
defaults
None
scalar
[
]
possible
accepts
iterable
suggestion
def
add
type
Sequence
[
OID
]
Sequence
[
OID
]
Sequence
[
OID
]
>
None
self._scalar.extend
scalar
self._next.extend
next
self._bulk.extend
bulk
Nit
naming
verbosity
bit
suggestion
self._scalar
=
[
]
type
List
[
OID
]
self._next
=
[
]
type
List
[
OID
]
self._bulk
=
[
]
type
List
[
OID
]
valid
utf-8
input
weirder
string
comment
redundant
different
loop
self._last_event_guid
restart
duplicates
wip
Let
add
comment
payload
look
links
documentation
easy
access
buffer
condition
mid
pagination
get_events
Could
use
case
fields
value
name
default
Let
add
comments
comment
order
precedence
agent
config
<
init
config
<
instance
config
small
comment
sample
output
postqueue
Good
question
only
reason
prometheus
check
more
url
instance
let
suggestion
https
//www.aerospike.com/docs/reference/info/
dcs
suggestion
Agent
hypervisors
system.load.1/5/15
available
system
metric
check
inline
comment
Same
comments
nit
suggestion
changelog
disk
write
preferable
file
open
parsing
scope
try/except
python
try
open
file
blkid_cache_data
=
parsing
extraction
logic
try/except
suggestion
Reset
tagger
tags
link
permalink
pymqi
avaiblable
mac
https
//github.com/DataDog/integrations-core/blob/48cb9081d5b992076955afba2d13a5276c61ee63/ibm_mq/tests/README.md
list
iteritems
scraper_config
[
]
only
new
thing
base
class
check
useful
future
checks
feature
requests
.keys
point
_api
api
object
suggestion
'win32_event_log
[
ERR_UNEXPECTED_LOG_COLLECTION_CAT
]
win32_event_log
log
collection
logs
constants
suggestion
try
wildcard
change
behavior
people
wildcards
custom
checks
metrics
additional
custom
metrics
attention
comment
single
double
quotes
let
scope=
session
service
times
nit
helper
method
prefix
duplication
help
consistency
+
easier
Example
helper
method
echo_row_failure
=
text
echo_failure
current_check
actual_line
text
usage
echo_row_failure
wrong
amount
columns'.format
'metric_name
]
suggestion
spacing
constants
inconsistent
module
comment
header
group
big
TODO
hater
source
code
something
Let
contextlib
import
closing
top
closing
pika.BlockingConnection
pika.BlockingConnection
suggestion
NOTE
in-toto
first
characters
signing
keyID
latter
key
filename
helpful
comment
assignments
type
checking
methods
docstrings
comments
helpful
suggestion
type
str
*
str
>
None
Does
work
ServiceCheck
class
ServiceCheck
Enum
OK
WARNING
CRITICAL
UNKNOWN
class
AgentCheck
object
OK
=
ServiceCheck.OK
WARNING
=
ServiceCheck.WARNING
CRITICAL
=
ServiceCheck.CRITICAL
UNKNOWN
=
ServiceCheck.UNKNOWN
sure
constant
AgentCheck
kind
duplication
metrics
metrics.yaml
file
conf.yaml
load_jmx_config
metrics.yaml
account
account
Could
doc
ok
error
ck.KafkaError._PARTITION_EOF
confluent_kafka
doc
comment
mapr_host
topic_path
Does
metric
result
result
need
values
[
]
self.service_check
SERVICE_CHECK
AgentCheck.CRITICAL
+
[
self.topic_path
]
Example
python
try
conn
self.get_connection
Exception
self.service_check
SERVICE_CHECK
AgentCheck.CRITICAL
+
[
self.topic_path
]
raise
self.service_check
SERVICE_CHECK
AgentCheck.OK
+
[
self.topic_path
]
much
documentation
custom
library
raw
regex
string
compiled
pattern
wildcard
string
None
worked
Anyway
new
recommended
way
stream
consume
method
available
version
library
🤷‍♂
consumer
data
collection
see
https
//docs.confluent.io/current/installation/configuration/consumer-configs.html
comment
link
dd-trace-py
docs
first
comment
threads
option
futures
name
dd-trace-py
futures
extensions
deals
trace
info
threads
concurrent.futures
module
suggestion
See
http
//pypi.datadoghq.com/trace/docs/other_integrations.html
futures
requests=True
futures=True
configuration
reason
futures
default
details
comment
PR
breaking
things
helpful
permalink
original
code
comment
nice
unit
tests
function
Hmm
at_least=0
metric
count=1
smart
example
link
lines
code
readability
able
issues
something
changes
suggestion
agent
versions
ensure_aware_datetime
base
package
setup.py
suggestion
integration
compatible
test
assertion
suggestion
wmi_property
==
'name
normalized_wmi_property
tag_by.lower
suggestion
skip
wmi_property
foo
bar
separate
wmi_property
foo
bar
wmi_property
continue
wmi_property.lower
s
wmi_sampler.property_names
s.lower
wmi_property
foo
property_names
foo
bar
name
break
else
suggestion
t
tag_by.split
t
=
t.strip
logic
condition
True
suggestion
WaitFor
exceptions
comment
key
value
rid
compat
layer
Agent5
datadog_checks
suggestion
quantile
label
present
metric
%
r
Minor
nit
suggestion
TODO
Prometheus
'quantile
label
optional
clear
azure
nit
scheme
config
comment
scheme
deprecation
small
snippet
microsoft
tends
documentation
urls
obsolete
suggestion
instances
agent
signature
Lets
old
new
new
old
day
suggestion
instances
agent
signature
Suggestion
need
comment
suggestion
existing_root
=
get_root
existing_root
return
rate
documentation
Total
number
microseconds
*
*
pgbouncer
*
*
PostgreSQL
scope
PR
Windows
day
🙂
sure
accurate
mcache
tests
suggestion
cpuload1
OctetString
Counter32
suggestion
cpuload2
Opaque
Counter32
comments
imports
legacy
decision
rid
slightly_smiling_face
C
Datadog
Inc.
rights
3-clause
BSD
style
license
LICENSE
suggestion
.common
import
INSTANCE
back
slightly_smiling_face
suggestion
PATH
os.environ
previous
code
PATH
map
Please
integration
users
older
agent
versions
Nit
Match
order
variable
declaration
primary
variable
primary
suggestion
Find
nodes
current
node
primary
Nit
imperative
form
suggestion
Make
reasonable
hostname
replset
membership
event
mention
state
-1
correspond
unknown
Maybe
small
comment
dedicated
STATE_UNKNOWN
=
-1
constant
top
module
track
state
_given_
member
several
members
suggestion
Member
last
replica
state
second
loop
iterating
[
'tcp
]
loop
iterating
combinations
protocols/ip
versions
get_subprocess_output
loop
specific
code
header
line
output
command
Feel
free
signature
internal
behavior
_parse_linux_cx_state
sense
ss
netstat
calls
nit
comment
metric
helpful
sections
awkward
transformer
column_type
column_type
tags.append
transformer
value
None
submission_queue.append
transformer
value
column_data.append
column_name
transformer
reason
None
good
reference
class
check
instance
init
easier
logger
other
comments
need
actual
instance
config
additional
token
column
part
original
regex
optional
bit
+
duplication
rest
regex
identical
license
bit
weird
config
function
quick
comment
bit
yesterday
line
imports
comments
lines
jump
sure
cpu
sense
data
way
comment
label
mapping
specific
test
usable
free
available
alex
previous
comment
cov
Tests
errors
Same
other
cases
master
db
loop
btw
most
checks
performance
mechanism
drops
nice
errors
case
least
few
tests
mocks
simple
bugs
past
execution
errors
rows
elsewhere
https
//github.com/DataDog/integrations-core/blob/1aa0314e2135ba0fe2cc8d2fb92576e8cdf63292/postgres/datadog_checks/postgres/postgres.py
L944-L948
https
//github.com/DataDog/integrations-core/blob/1aa0314e2135ba0fe2cc8d2fb92576e8cdf63292/ibm_db2/datadog_checks/ibm_db2/ibm_db2.py
L413-L416
https
//github.com/DataDog/integrations-core/blob/1aa0314e2135ba0fe2cc8d2fb92576e8cdf63292/vertica/datadog_checks/vertica/vertica.py
L395-L398
bad
state
tests
great
way
suggestion
self.queue_regex
=
[
re.compile
regex
regex
instance.get
[
]
type
List
[
Pattern
]
config.tags
config.no_channel_tags
normal
properties
Example
python
class
IBMMQConfig
def
__init__
instance
self.tags_no_channel
queue_manager
.format
self.queue_manager_name
mq_host
.format
self.host
port
.format
self.port
]
+
self.custom_tags
=
self.tags_no_channel.copy
channel
.format
self.channel
Same
comment
tags
self.config.tags
Calculated
property
comment
suggestion
def
test_current_support
metrics
ignored_columns
metric_source_url
test_current_support
obvious
test
name
bit
explicit
test_latest_metrics_supported
docstring
import
weakref
import
TYPE_CHECKING
TYPE_CHECKING
.snmp
import
SnmpCheck
def
discover_instances
config
interval
check_ref
type
InstanceConfig
float
[
SnmpCheck
]
>
None
way
type
checking
check
object
function
nit
comment
irrelevant
custom
checks
change
comment
Agent
Can
Remove
code
Did
worth
property
@
property
def
_conn
type
>
vim.ServiceInstance
raise
RuntimeError
self.__conn
@
_conn.setter
def
_conn
conn
type
vim.ServiceInstance
>
None
existing_conn
=
getattr
None
existing_conn
None
connect.Disconnect
existing_conn
self.__conn
=
other
comment
https
//github.com/DataDog/integrations-core/pull/6036
discussion_r393661305
property/setter
much
type
checker
[
Python
cheatsheet
]
https
//mypy.readthedocs.io/en/stable/cheat_sheet.html
suggestion
type
Any
*
*
Any
>
None
suggestion
self._wmi_props
None
type
Optional
[
WMIProperties
]
suggestion
type
Iterable
[
str
]
List
[
Dict
[
str
WMIFilter
]
]
Any
>
WMISampler
default
mypy
implicit
optional
]
https
//mypy.readthedocs.io/en/stable/command_line.html
cmdoption-mypy-no-implicit-optional
i.e
argument
Optional
default
None
suggestion
type
int
int
int
int
int
int
int
int
>
str
suggestion
type
Iterable
[
str
]
>
WMISampler
logic
wrong
check
wrapper
bar.py
foo.py
boolean
Could
constant
entire
row
unique
sure
metric_name
unique
constant
variable
top
py2
py3
wih
values
same
type
Python2
behavior
None
lower
anything
suggestion
self.value
None
None
<
x
>
True
return
suggestion
other.value
None
x
<
None
>
False
return
False
space
🙂
Can
’
sets
dictionnary
only
value
True
element
existence
suggestion
config
[
'_ignored_metrics
]
config
[
'_ignored_patterns
]
=
Separate
metric
names
patterns
different
maps
faster
lookup
metric
config
[
'ignore_metrics
]
*
metric
config
[
'_ignored_patterns
]
.add
metric
config
'_ignored_metrics
]
.add
metric
+
'rate
comments
people
full
context
Same
regular
comments
nit
regular
comment
suggestion
determine
number
columns
complete
None
values
DictReader
columns
None
https
//docs.python.org/3.8/library/csv.html
csv.DictReader
noqa
suggestion
TODO
Agent
=
suggestion
datadog_checks_base
version
Minor
comments
suggestion
@
click.argument
'path
suggestion
@
click.argument
'profile_path
command
clear
profile
mean
ddev
meta
translate-profile
-h
Usage
ddev
meta
translate-profile
[
OPTIONS
]
PROFILE
Do
OID
translation
SNMP
profile
plain
replacement
comments
indent
most
work
pysnmp
pysnmp-mibs
Options
-h
message
exit
description
@
click.argument
helpful
suggestion
See
https
//github.com/DataDog/integrations-core/pull/1109
discussion_r167133580
conditional
skipif
need
anymore
single
instance
fixture
conftest.py
CONFIG
need
anymore
Let
positional
formatting
excessive
way
suggestion
teams
[
label.rpartition
'/
-1
]
label
pull_request.labels
label.startswith
'team
teams
pull_request.repo
==
'integrations-core
teams
[
'agent-integrations
]
side
effects
instance
object
agent5
place
contains
method
str
e
'Bad
configuration
AssertionError
s
case
ca_cert
init_config
https
//github.com/DataDog/integrations-core/blob/master/openldap/tests/conftest.py
L22
Actually
’
t
work
to_string
>
ensure_bytes
https
//github.com/DataDog/integrations-core/blob/28c6182e45d84b63253fd62a96b4f18cb88a896a/datadog_checks_base/datadog_checks/base/checks/openmetrics/mixins.py
L635
PR
same
strategy
https
//github.com/pypa/wheel/blob/master/wheel/util.py
case
ensure_bytes
everything
*
*
*
*
text_type
’
consistent
ensure_unicode
everything
bytes
suggestion
RATE
>
[
]
=
[
e
e
envs_selected
e
available
]
way
simpler
invalid
type-wise
suggestion
suggestion
profiles
self.init_config.get
'profiles
profiles
None
profiles
get_default_profiles
=
profiles
type
Dict
[
str
Dict
[
str
Any
]
]
Nit
logic
bit
complex
separate
helper
def
resolve_profile_definition_path
path
type
str
>
str
os.path.isabs
path
return
path
path_in_confd
=
os.path.join
_get_profiles_confd_root
path
os.path.isfile
path_in_confd
return
return
os.path.join
_get_profiles_site_root
path
def
_read_profile_definition
definition_file
path
resolve_profile_definition_path
definition_file
https
//github.com/DataDog/integrations-core/pull/7143/files/5c2052bfbf282a6bf6832fa57b8267d06f7fe0ae
diff-d7d892cb1272fd7a345ce7d837a460a7R124-R125
suggestion
TODO
cleanup
hosts
TODO
common
way
todos
major
IDEs
new
test
Could
deprecation
note
compatibility
input
https
//github.com/DataDog/integrations-core/blob/master/.azure-pipelines/changes.yml
L24
compatibility
input
https
//github.com/DataDog/integrations-core/blob/master/.azure-pipelines/changes.yml
L24
mountpoint
space
something
mountpoint
=
mountpoint.rsplit
]
typo
good
aggregator
deps
present
Do
condition
behaviour
comment
suggestion
3-clause
BSD
style
license
LICENSE
suggestion
3-clause
BSD
style
license
LICENSE
suggestion
3-clause
BSD
style
license
LICENSE
dev
reference
comment
top
expected
format
counter_data_types
nit-
block
comment
spaces
consistent
Let
explain
comments
logic
bloc
differences
comments
Let
comment
logic
block
Let
comment
caches
structure
look
comments
logic
block
suggestion
Does
windows
zookeeper
image
compatible
windows
architecture
suggestion
Does
windows
zookeeper
images
compatible
windows
architecture
need
long
comment
lines
overview
endpoint
json
rabbit
version
rabbitmq_version
field
Rabbit
versions
semantic
versioning
https
//www.rabbitmq.com/changelog.html
example
payload
test
fixture
comment
comments
wrapper
proper
options
config
file
nit
Might
helpful
comment
different
precision
py2
py3
.timestamp
Python
implementation
Python
platform
dependent
platforms
leap
seconds
something
unix
epoch
time
crazy
tests
better
arguments
datetime.now
UTC
argument
freezegun
practical
perspective
[
concerned
dependency
]
https
//github.com/dateutil/dateutil/issues/923
get_timestamp
get_current_datetime
same
time
better
assert
get_timestamp
get_timestamp
dt
get_timestamp
actual
value
mocked
datetime.now
assertion
reliable
assert
get_timestamp
dt
something
TODO
more
concrete
Datadog
Agent
version
%
%
Agent
version
release
date
Are
_filter_metric
side
effect
count
self.count
work
case
correct
IMHO
Example
def
_send_telemetry_counter
metric_name
val
scraper_config
super
KubernetesState
self
._send_telemetry_counter
metric_name
val
scraper_config
[
]
self.count
scraper_config
[
'namespace
]
+
.telemetry.collector.metrics.count
metric.samples
comments
tags
constant
CUSTOM_TAGS
=
[
tag1
]
CACTI_CONFIG
=
'nohost
'tags
list
CUSTOM_TAGS
assert_metrics
tags=CUSTOM_TAGS
suggestion
service
name
service
log
suggestion
Attach
tag
service
<
SERVICE
>
metric
event
service
check
integration
long
lines
setup.cfg
file
max-line-length
Same
comment
request
suggestion
tools
Python
suggestion
tools
Python
suggestion
resources
patterns
match_blacklist
s/
display
/
display_func
suggestion
Always
distutils
test
sub-commands
set_defaults
@
property
something
sure
section
try
docstring
sample
existing/valid
Participant
whitespace
docstring
refresh_timeout
timeout
long
asynchronous
refresh
job
[
]
http
//django-cacheback.readthedocs.io/en/latest/advanced.html
highlight=refresh_timeout
tags
seconds
tags
appropriate
cacheback
job
happy
backup
hacky
better
full
base64
encode
CDATA
section
XHTML
thing
Exception
code-smell
big
broad
Again
serious
code
scale
prototype
production
ready
*
exception
lines
code
Sentry
Prod
proper
unexpected
errors
anything
renderer
=
_get_renderer
renderer.stdin.write
json.dumps
data
reading
renderer
bla
bla
yada
yada
try
True
stdout
SomeSpecificSubprocessError
exception
return
client_side_data
data
exception=exception
rest
great
code
comment
partial
=
data.copy
line
something
HTML
document
data
React
state
client
side
HTML
necessary
biggest
parts
HTML
strings
data
data
shallow
clone
data
partial
=
data.copy
*
*
shallow
clone/copy
anything
.html
utility
function
such
5-line
comment
call
comment
=
unquote
href.decode
'ascii
earlier
version
code
davidflanagan
comment
logins/logouts
next
week
change
KS
timeout
Typo
>
Nit
download
first
better
Nit
comment
same
check
PyQuery
out-of-sync
final
fix
space
suggestion
app
focus
error
haha
classic
chicken-egg
advanced_menu
darker
toggle
purpose
other
things
menu
availble
Show
Console
suggestion
Register
side
pipe
current
app
proxy
comment
'pytest
unused
lambda
expression
def
lambda
expression
def
lambda
expression
def
undefined
name
'client_factory
lambda
expression
def
suggestion
solution
foreground
modification
example
déjà
vu
suggestion
beginning
line
code
bit
complicated
multiple
pipeline
configurations
pipeline
configurations
checkboxes
actions
way
Reload
Restart
menu
computer
[
screen
shot
2017-11-08
]
https
//user-images.githubusercontent.com/8126447/32550705-17077f58-c45c-11e7-9808-cffac533cabb.png
everything
separator
everything
method
something
specific
clear_engine_actions_from_project_menu
small
comment
loop
context
actions
separator
docstring
comment
incomplete
'.osutils
unused
'.osutils
unused
note
python
documentation
plan
printf-style
formatting
example
function
definition
big
fan
R
context
in-sample
mechanism
overfit
bigger
model
higher
Rsquared
Besides
distinction
effects
interests
conditions
effects
interest
drifts
motion
interpretation
comment
plot
effects
interest
F
test
sense
import
novel
users
ten
initial
lines
imports
comment
good
idea
fMRI
time
series
people
estimated
signal
percent
baseline
change
baseline
signal
Somebody
signal
reason
Extra
line
new
API~
\
>
old
API
comment
explanation
many
places
+1
nice
comment
Ahh
interesting
reasonable
argument
comment
others
uncaught
log
message
someone
code
service
logs
actionable
helpful
metrics
large
flush
amount
request
i
TODOs
original
inciting
case
issue
possible
ways
categorical.random
tests
original
example
passes
parameter
case
test
size
Categorica.random
nominal
use
library
guidance
thanks
ropes.
[
image
]
https
//user-images.githubusercontent.com/7213793/42424573-5388a828-82c3-11e8-8ef5-686857121012.png
comments
arviz.rcParams
matplotlib
issue
rcParam
ArviZ
care
from_pymc3
ti
sentence
suggestion
Compute
mode
test
suggestion
Second
mixture_axis
value
tensor
mixture
axis
correct
location
negative
number
index
way
situations
value
observed
value
batch
dimensions
ones
present
comp_dists
suggestion
samples
array
mixture_axis
suggestion
random
choices
weights
suggestion
able
choices
mixture_axis
comp_samples
dimensions
right
choices
sure
batch_shapes
comp_samples
choices
other
comment
link
numpy
issue
clearer
cast
problem
@
ColCarroll
comment
line
formatting
lot
nicer
same
formatting
comment
i
line
tests
comment
bit
logp
RV
model
dist
suggestion
tau_e
=
self.tau_e
innovation
precision
PR
general
comment
users
own
tuning
schedule
easy
place
adaptation
window
users
list
other
iterator
adaptation
window
lengths
line
code
next
one
subsequent
PR
suggestion
Reset
background
covariance
end
adaptation
window
docstring
right
self.shape
comment
..
suggestion
size
None
size
data
=
rv.rvs
size
.cumsum
axis=axis
data
=
data
data
[
]
TODO
draw
init
available
line-breaks
helpful
]
https
//github.com/pymc-devs/pymc3/pull/2027/files
diff-2d726b5e607ce8ff792046bcb7ff167aR375
pm.theanof.tt_rng
support
random
seed
necessary
bit
consistent
way
seed
situations
ability
seed
number
issue
specific
experiments
take
Such
option
exists
experiments
global
rng
possible
seed
whole
notebook.So
sugar
constant
sizes
https
//github.com/pymc-devs/pymc3/blob/master/pymc3/variational/opvi.py
L596
comments
https
//github.com/Lasagne/Lasagne/blob/master/lasagne/updates.py
grads
objective
wrt
params
list
params
fly
user
unnecessary
work
Update
method
helper
function
below
call
gradients
updates
Current
implementation
case
list
shared
variables
dict
format
return
value
same
comments
other
updates
BTW
signature
interface
changes
inherited
classes
same
OOP
style
current
solution
locals
self
circular
reference
@
twiecki
*
*
Lasagne
*
*
good
reliable
implementation
copy-paste
great
same
Lasagne
api
E261
least
spaces
inline
comment
test
functionality
create_config_map
file
open
contents
mock
=
flexmock
sys.modules
'__builtin__
]
mock.should_call
'open
fall-through
mock.should_receive
'open
flexmock
read=lambda
'file
contents
issue
warnings.warn
koji/builders
Could
particular
reason
diagnostics
noqa
F811
E265
block
comment
comment
top
block
and_raise
calls
Hey
self.os.logs
returns
None
code
exception
logs.decode
utf-8
comment
decode
logs
regular
expression
value
manipulation
functions
*
regular
expression
comment
intention
comment
nice
regs
parsing
func
E265
block
comment
E266
many
block
comment
F811
redefinition
unused
line
F811
redefinition
unused
line
E302
blank
lines
F401
'tests.fake_api.openshift
unused
F401
'tests.fake_api.osbs
unused
neat
F401
'flexmock.flexmock
unused
least
element
'bad
status
images
update
first
image
status
single
server
error
retry
image
=
content_json
[
'status
]
[
'images
]
]
E501
line
characters
way
regexes
easier
minor
improvement
closing
new
line
noqa
F811
diagnostic
osbs
way
other
diagnostics
other
methods
file
noqa
specific
diagnostic
scope
PR
F811
redefinition
unused
line
noqa
F811
lot
places
noqa
particular
diagnostic
behavior
configurable
https
//github.com/dask/dask-ml/issues/239
Remind
SHAs
fit
parallel
wrong
sequential
yield
anything
SHA.fit
concrete
SucessiveHalvingSearchCV
future
list
concrete
SucessiveHalvingSearchCV
objects
yield
model
ID
@
TomAugspurger
opinions
bracket
information
key
3-10
bracket=3-10
Style
nit
lambda
unnecessary
bracket=
.format
if-statement
comments
metadata
property
dissonance
method
property
value
'brackets
List
[
Dict
]
Dict
[
str
Dict
]
key
bracket-=
useful
list
TODO
style
_brackets_ids
=
list
SHAs
>
_fit
parallel
*
tornado
coroutine
ones
L345
See
able
Same
comments
_adapt
reason
local
variable
class
len
best
>
len
best
_pf_calls
>
_partial_fit_calls
pf_calls
Intentional
Add
test
sure
patience=True
same
more
decisions
patience=False
assertions
library='dask-ml
nice
assertions
underlying
estimators
outside
statement
things
Incremental
possible
parameter
Expand
transparent
columns
=
[
]
column
dtype
condition
columns
assert
columns.keys
alg.cv_results_.keys
search.estimator
SHA.estimator
check
sure
history_
same
order
same
params
final
score
ref
comment
test
able
IncrementalSearchCV
tests
Add
docstrings
tests
testing
gen_cluster
c
s
b
fixtures
utils_test
sync
API
@
mrocklin
curious
thoughts
unknown
chunks/divisions
stuff
._chunks
pretty
hacky
case
da.Array
unknown
chunks
>
dd.DataFrame
RangeIndex
length
chunk
divsions
dd.from_dask_array
optional
divisions
argument
chunks
cleanest
way
argument
unknown
divisions
incorrect
results
dask
array
unknown
chunks
page
//scikit-learn.org/stable/modules/computing.html
incremental-learning
attribute
attributes
dask_ml._utils.copy_learned_attributes
self._transformer
same
comment
preserve_dataframe
behavior
dask
dataframe
behavior
test
user
specifies
n_components
large
sure
PCA
array
*
*
size
user
fact
Dask-ML
user-input
test
assert
statements
comment
solver
randomized
condition
array
*
*
number
columns
user
n_components=3
n_components
larger
number
singular
values
algorithms
actual
ndarrays
Dask
arrays
methods
.reshape
present
ExtensionArray
strict
ExtensionArray
appropriate
one
update
returns
bool
int
many
times
partial_fit
model
speculative
call
meta
]
np.random.choice
X.blocks
data
access
models
time
updated
part
Dask
assignment
Ok
id
index
former
unique
identifier
event
order
single
increments
latter
order
events
file
single
increments
EventFileReader
docstring
people
data.meta
[
origin
]
example
[
input_path
]
more
clear
understanding
something
=
DataContainer
something
single
event
correct
single
event
many
events
total
max_revents
somebody
file
Again
code
values
telescope
common
r
focal
length
field
view
example
instrument
description
functions
taubin
chaudhuri
fit
simple
functions
class
inputs
functions
easier
single
components
enhances
readability
dictionary
to_value
u.m
pure
number
meter
astropy
quantity
necessary
iteration
print
statement
use
f
next
iterator
good
someone
reorders
reason
needed
path
comment
log
other
case
point
self.log.critical
input
files
provide
input-dir
input
files
positional
arguments
sys.exit
pathlib
os.path
much
cleaner
case
main
use
case
file
Massive
processing
many
files
grid
job
successfull
log
error
real
error
warning
better
allowlists
lists
setup
options
work
single
sets
check
file
data
half
tables
broken
file
paths
config
file
args.input_files
Same
error
default
python
boolean
mask
length
n_pixels
integer
array
indices
best
choice
Same
result
timing
corrections
useful
test
Question
mac
users
approproaiate
location
mac
THis
comment
above
sense
integration
window
central
peak
spaces
inline
comment
https
//www.python.org/dev/peps/pep-0008/
inline-comments
spaces
inline
comment
DL1a
deep
learning
people
output_path.exists
self.overwrite
check
config
option
body
loop
function
event
loop
least
spaces
inline
comment
line
characters
line
characters
Black
changes.
<
br
>
least
spaces
inline
comment
>
>
issubclass
np.str_
np.str
np.str
general
Ah
more
thing
radius
magic
numbers
good
choice
comment
radius
needs
individual
comment
discussion
PR
clearer
default
None
clear
stars
magic
value
docstring
Yale
catalog
stops
magnitude
catalog
docstring
citation
date
nice
example
accurate
time
comments
code
changes
comments
..
code
method
little
functions
functions
easier
unit
test
point
reason
r1
stuff
function
fill_R0_stuff
better
r1
stuff
comment
R0
stuff
mind
nit
sorry
unused
above
primary
key
unique=true
model
wrong
please
hound
unexpected
indentation
comment
local
variable
local
variable
whitespace
operator
whitespace
whitespace
Sorry
grimacing
sponsors
invalid
level
NULL
shubham-padia
old
data
complete
sense
URL
endpoint
event
particular
event_copyright
/event_copyright/
int
copyright_id
>
sense
sense
white_check_mark
okay
afaik
@
niranjan94
https
//github.com/fossasia/open-event-orga-server/pull/3718
discussion_r119982046
/event_copyright/int
copyright_id
sure
endpoint
event_copyright
relationship
event
>
/session_types
@
niranjan94
/session_types/
<
int
sessiontype_id
>
patch
delete
functional
link
/session_types/
<
int
sessiontype_id
>
@
comments
unused
suggestion
elem_id
coords
zip
frame.typeid
frame.cif_coordinates
okay
medical
constants
integers
Makes
sense
file
lot
reason
medical
constants
Hmmm
method
logic
bomb
@
tedsalmon
elegant
good
amount
elifs
original
code
amount
huge
margin
next
refactor
dict
map
image
key
dict
comment
categories
time
onchange
scalable
better
way
comment
reminder
structure
dict
ah
sense
question
generic
lambda
args
browse
method
lot
times
Lambda
superfluous
defaultdict
self.env
[
'product.template
]
.browse
need
model
tricky
output
type
get_raw
warning
SInce
module
level
logging
=
logging.getLogger
__name__
reason
__name__
kind
redundant
such
information
file
git
Done
PR
Thanks
comment
Thanks
todo
comment
confusing
D
typo
docstring
case
snapshot_value
False
👍
@
jenshnielsen
@
eendebakpt
'GNU
repository
instrument
drivers
qcodes
GPL
other
instrument
drivers
GPL
license
statement
source
code
qtlab
instrument
drivers
GPL
license
statement
source
code
original
authors
general
guideline
GPL
instrument
drivers
qcodes
framework
good
code
stay
@
jenshnielsen
option
driver
qcodes
explicit
mention
GPL
driver
directory
driver
GPL
possible
MIT
policy
particular
reason
None
mapping
strong
opinion
manual
Fair
confusion
names
difference
'none
proper
response
string
instrument
python
None
value
whereas
case
present
manual
fine
'off
'identity
jenshnielsen
sure
implementation
reason
warning
docs
build
/home/travis/build/QCoDeS/Qcodes/qcodes/instrument_drivers/oxford/kelvinox.py
docstring
qcodes.instrument_drivers.oxford.kelvinox.OxfordInstruments_Kelvinox_IGH.get_idn:1
WARNING
Inline
emphasis
start-string
end-string
better
IDN
module
Same
name
comment
⚡️
D
please
use
reason
alternative
arguments
decorator
users
reason
alternative
comment
driver
favor
QDac_channels.py
redundant
unlikely
users
comment
space
many
😺
Yikes
right
wheel
[
previous
comment
]
https
//github.com/joerick/cibuildwheel/pull/18
issuecomment-313952707
change
Exact
problem
python
installer
instances
same
python
version
pre-installed
program
own
instance
python
x64
strange
path
part
code
discovery
installation
[
https
//github.com/Czaki/cibuildwheel/commit/b0cefb63c75e17952a19dabe4ffe410b75af3254
diff-bf885b72fecfdf7485cab147f7957d5c
]
internet
pep
comment
code
Please
constant
const.py
sid
unique
id
config
entry
get_mac
mac
address
reliable
user
incorrect
key
connection
gateway
Please
guard
user
interface
host
address
gateway
See
additional
comment
cloud
entry
local
entry
context
correct
source
suggestion
async
def
async_step_user
user_input=None
Handle
flow
user
return
self.async_step_environment
def
async_step_environment
user_input=None
Decide
environment
cloud
local
user_input
None
return
self.async_show_form
step_id=
user
data_schema=vol.Schema
environment
default=ENV_CLOUD
vol.In
[
ENV_CLOUD
ENV_LOCAL
]
Environment
chosen
additional
host
information
LOCAL
OAuth2
flow
CLOUD
Ask
host
detail
user_input
environment
==
ENV_LOCAL
return
self.async_step_local
Use
configuration.yaml
CLOUD
setup
return
self.async_step_pick_implementation
def
async_step_local
user_input=None
Handle
local
flow
user_input
None
return
self.async_show_form
step_id=
user
data_schema=vol.Schema
CONF_HOST
str
LOCAL
setup
host
serial
number
ip_address
=
[
host
smappee_api
=
api.api.SmappeeLocalApi
ip=ip_address
logon
=
await
self.hass.async_add_executor_job
smappee_api.logon
logon
None
return
self.async_abort
reason=
connection_error
=
await
self.hass.async_add_executor_job
smappee_api.load_advanced_config
serial_number
=
None
config_item
advanced_config
config_item
key
]
mdnsHostName
=
config_item
value
Smappee1
Energy
Solar
models
legacy
return
self.async_abort
reason=
invalid_mdns
=
serial_number.replace
Smappee
Check
await
self.async_set_unique_id
f
Smappee
self.async_create_entry
title=f
Smappee
CONF_IP_ADDRESS
ip_address
CONF_SERIALNUMBER
serial_number
suggestion
async
def
async_step_zeroconf
discovery_info
Handle
zeroconf
discovery
[
CONF_HOSTNAME
]
.startswith
Smappee1
Energy
Solar
models
legacy
return
self.async_abort
reason=
invalid_mdns
=
discovery_info
[
CONF_HOSTNAME
]
.replace
.local
.replace
Smappee
Check
await
self.async_set_unique_id
f
Smappee
pylint
disable=no-member
https
//github.com/PyCQA/pylint/issues/3167
self.context.update
CONF_IP_ADDRESS
discovery_info
host
]
CONF_SERIALNUMBER
serial_number
await
self.async_step_zeroconf_confirm
def
async_step_zeroconf_confirm
user_input=None
Confirm
zeroconf
flow
errors
user_input
None
pylint
disable=no-member
https
//github.com/PyCQA/pylint/issues/3167
serialnumber
=
self.context.get
CONF_SERIALNUMBER
return
self.async_show_form
step_id=
zeroconf_confirm
errors=errors
pylint
disable=no-member
https
//github.com/PyCQA/pylint/issues/3167
ip_address
=
self.context.get
CONF_IP_ADDRESS
=
self.context.get
CONF_SERIALNUMBER
Attempt
connection
local
device
smappee_api
=
api.api.SmappeeLocalApi
ip=ip_address
logon
=
await
self.hass.async_add_executor_job
smappee_api.logon
logon
None
return
self.async_abort
reason=
connection_error
self.async_create_entry
title=f
Smappee
CONF_IP_ADDRESS
ip_address
CONF_SERIALNUMBER
serial_number
GUI
entity
state
state
machine
frontend
GUI
many
consumers
data
individual
value
None
values
None
trv
status
fails
values
None
reading
following
multiple
if-statements
suggestion
temp
targ
_
trv_output
=
self._lwlink.read_trv_status
self._serial
issues
race
condition
host
update
case
regular
expression
^
.+\s
[
\w\d-_
]
+
*
==.+
group
package
https
//regexr.com/5b1em
Let
integers
library
valid_values
min/max
value
enum
fields
swing_modes
comment
Just
case
helper/system_info.py
changes
way
order
keys
suggestion
info.pop
key
None
set_preset_mode
method
suggestion
CONF_PORT
discovery_info
CONF_PORT
]
suggestion
info
=
await
self._get_bsblan_info
host
discovery_info
[
CONF_PORT
]
do
CONF_DEVICE_IDENT
item
code
iteration
above
iteration
single
iteration
suggestion
sensor
syst_datas
[
sensors
]
self._temperature_sensors
sensor
[
id
]
=
sensor
[
value
suggestion
access
stored
temperature
connection
sensors
router
instance
suggestion
SLOW_ADD_MIN_TIMEOUT
suggestion
SLOW_ADD_ENTITY_MAX_WAIT
=
Per
entity
int
discovery
schema
future
case
exception
discovery
schema
colon
base
class
stick
suggestion
return
f
base_name
value_label
item
present
suggestion
item
[
NOTIFICATION_DEVICE_CLASS
]
check
coordinator.shark_vacs
dict
ourselves
check
white
space
pytest
fixture
name
parameter
name
fixtures
something
different
function
name
suggestion
integration
details
tests
details
future
use
case
for/against
case
Let
comment
errors
method
argument
updates
config
entry
data
beneficial
CONF_HOST
host
receiver
new
IP
address
recovers
Please
integration
details
assert
states
home
assistant
core
state
machine
entity
registry
device
registry
config
entry
better
call_later
time
event
test
helper
https
//github.com/home-assistant/core/blob/af5cb948a0396d2031851115dbc848029b2c57b1/tests/common.py
L288
interested
retry
correct
time
method
Zeroconf
suggestion
call
_get_instance_by_id
call
returns
None
Comments
sure
loop
common
way
data
available
coordinator.last_update_success
coordinator.async_refresh
coordinator.data
ConfigEntryNotReady
Commented
code
specific
exceptions
broad
catch
coordinator
list
https
//github.com/home-assistant/core/blob/8d687c951a32ff4da1cb06c534f24bf40709b33d/homeassistant/helpers/update_coordinator.py
L141-L175
Untested
suggestion
async
def
test_lights_all_dimmable
hass
hue_client
Test
CONF_LIGHTS_ALL_DIMMABLE
lamp
brightness
support
hass.states.async_set
light.no_brightness
setup.async_setup_component
hass
http.DOMAIN
http.DOMAIN
http.CONF_SERVER_PORT
HTTP_SERVER_PORT
hass.async_block_till_done
patch
homeassistant.components.emulated_hue.create_upnp_datagram_endpoint
await
setup.async_setup_component
hass
emulated_hue.DOMAIN
emulated_hue.CONF_LISTEN_PORT
BRIDGE_SERVER_PORT
emulated_hue.CONF_EXPOSE_BY_DEFAULT
True
emulated_hue.CONF_LIGHTS_ALL_DIMMABLE
True
hass.async_block_till_done
light_without_brightness_json
=
await
perform_get_light_state
hue_client
light.no_brightness
HTTP_OK
import
pprint
pprint.pprint
light_without_brightness_json
assert
light_without_brightness_json
state
]
[
HUE_API_STATE_ON
]
True
assert
light_without_brightness_json
type
]
On/Off
light
assert
light_without_brightness_json
[
state
]
[
HUE_API_STATE_BRI
]
==
HUE_API_STATE_BRI_MAX
suggestion
global
_event_threads
pylint
disable=invalid-name
@
bdraco
right
global
Git
history
need
code
new
logic
loop
suggestion
single_master_thermostat
=
api.single_master_thermostat
=
ALL_PLATFORMS
single_master_thermostat
None
platforms
SENSOR_PLATFORMS
component
ALL_PLATFORMS
warning
YAML
import
instance
Plum
short
line
credentials
user
UI
line
code
assumptions
cleanup
instance
use
Makes
sense
return
value
check
call
values
methods
async_
cleanup
functions
self.options
easier
deep
options
little
dirty
entity
removal
work
suggestion
await
hass.async_block_till_done
logic
SSDP
Zeroconf
config
flow
async_handle_discovery_without_unique_id
developers
discovery
types
discovery
use
case
internal
function
official
sensor
device
classes
device_class
sensor
entity
property
https
//developers.home-assistant.io/docs/core/entity/sensor
available-device-classes
suggestion
self._kind
self._air_data.indices
attrs
[
f
label
_awair_index
=
abs
self._air_data.indices
]
elif
self._kind
DUST_ALIASES
API_DUST
self._air_data.indices
attrs
[
f
label
_awair_index
=
abs
self._air_data.indices.dust
suggestion
label
=
slugify
SENSOR_TYPES
[
self._kind
]
[
ATTR_DEVICE_CLASS
]
suggestion
def
_air_data
>
Optional
[
AwairResult
]
Return
latest
data
device
None
result
Optional
[
AwairResult
]
=
self._coordinator.data.get
self._device.uuid
suggestion
self._kind
==
API_SCORE
state
=
elif
self._kind
DUST_ALIASES
API_DUST
self._air_data.sensors
state
=
self._air_data.sensors.dust
state
=
self._air_data.sensors
]
self._kind
==
API_VOC
==
API_SCORE
return
round
state
==
API_TEMP
suggestion
suggestion
self._coordinator.last_update_success
self._air_data
results
sensor
type
self._air_data.sensors
available
True
dust
alias
self._kind
DUST_ALIASES
API_DUST
self._air_data.sensors
return
True
API_SCORE
self._kind
==
API_SCORE
suggestion
return
SENSOR_TYPES
[
self._kind
]
[
ATTR_ICON
]
comment
part
HATCPSite
class
suggestion
self._hosturl
name
suggestion
host
=
[
]
return
str
URL.build
scheme=scheme
host=host
port=self._port
suggestion
suggestion
separators
comment
enough
await
self.async_update
self.async_write_ha_state
Is
state
self.async_write_ha_state
callback
suggestion
Event
messages
SIGNAL_NEST_UPDATE
intercepted
signals
_device
callback
entity
async_dispatcher_connect
self.hass
SIGNAL_NEST_UPDATE
self.async_write_ha_state
name
identifier
access
ID
serial
number
service_info
Stale
comment
unique
ID
config
entry
ID
same
blinkpy
auth
token
https
//github.com/fronzbot/blinkpy/blob/b5c9a51e9ceab0ba9512d3e69d9c025a474d5f4d/blinkpy/blinkpy.py
L170
Android
app
user
time
auth
token
config
entry
data
use
API
homeassistant.update_entity
service
suggestion
Options
options
flow
comment
media_type
==
CAST_DOMAIN
reminder
play_media
specifi
cast
media
controls
speaker
group
cleanup
last
config
service
unique
ID
able
<
https
//developers.home-assistant.io/docs/entity_registry_index/
unique-id-requirements
>
suggestion
A
stateless
switch
SERVICE_LABEL_INDEX
part
group
message
light
color
state
attributes
comment
block
setup
entity
entity
GPIO
setup
error
continue
entity
dispatch
helper
entity
update
callback
callback
function
setup_platform
py
NUMATO_SIGNAL
=
def
setup_platform
def
read_gpio
port
level
Send
signal
entity
update
state
dispatcher_send
hass
NUMATO_SIGNAL.format
device_id
port
level
=
hass.data
DOMAIN
]
[
DATA_API
]
try
api.setup_input
device_id
port
api.edge_detect
device_id
port
read_gpio
NumatoGpioError
err
NumatoGPIOBinarySensor
add_entities
binary_sensors
True
class
NumatoGPIOBinarySensor
BinarySensorDevice
def
async_added_to_hass
Connect
state
update
callback
self.async_on_remove
async_dispatcher_connect
self.hass
NUMATO_SIGNAL.format
self._device_id
self._port
callback
def
_async_update_state
level
Update
entity
state
self._state
=
level
self.async_write_ha_state
disabled
Please
rename
add_devices
add_entities
suggestion
specific
errors
Looks
good
pylint
comment
@
balloob
ok
constant
unique
id
entry
need
additional
decoupler
case
library
changes
decoupler
simple
dict
strings
pypi
library
returns
copies
strings.json
keys
ok
use
case
async_play_media
TTS
media
url
method
playback
playing
TTS
media
normal
playback
playing
Pass
construction
master
entity
eye
hard
track
BTW
everything
config
defaults
vol
schema
entries
optional
sets
lists
builtin
intersection
method
sets
new
entities
latest
outputs
state
output
old
entities
way
new
entities
old
entities
entities
updater
ready
asyncio.Event
updater
wait
signal
event
updater
separate
test
case
please
combination
entry
exit
config
flow
test
Patch
call
arguments
call
access
updater._update
method
method
updates
asyncio
methods
unpredictable
standard
library
core
home
assistant
sleep
code
test
sleep
tests
time
slept
sign
hass.async_block_till_done
updater
code
Please
comment
code
>
serial
number
device
IMEI
device
new
variable
name
different
type
bad
request
last
one
same
length
number
proxies
cases
X-Forwarded-For
header
peer
untrusted
dangerous
IP
proxy
check
beginning
function
middleware
more
explicit
single
protocol
many
protocols
IPs
check
something
index
forwarded_proto
proto_index
=
-1
proto_index
=
index
bit
weird
index
value
IP
new
variable
yea
spec
wrong
ReadDevice
same
message
heartbeat
case
API
Update
signal
strenght
gateway
sensor
suggestion
start_time
Optional
[
float
]
=
None
feels
step
backwards
context
store
self
i
async_turn_on
hass
library
expected
command
condition
library
changes
state
hass
comments
tests
clear
protected
access
suggestion
PointSession.return_value.user
=
AsyncMock
pylint
TODO
suggestion
minimum
Python
version
supports
native
type
declarations
suggestion
devices
Iterable
[
SharkIqVacuum
]
=
coordinator.shark_vacs.values
suggestion
self._min_vol
=
config
[
CONF_MIN_VOLUME
]
+
dB
vol
0-200
self._max_vol
=
config
[
CONF_MAX_VOLUME
]
+
dB
vol
boolean
async_unload_entry
same
race
condition
exists
code
similar
new
function
error
something
use
return
self.async_abort
async_step_import
errors
base
=
async_step_edit
lot
similar
code
schema
discovery_info/user_input
function
pieces
Example
https
//github.com/home-assistant/core/pull/36827/commits/fc352e93b020547a6afd8459ac65ff4fdd0bdaab
suggestion
await
self.async_set_unique_id
info
[
uuid
]
update
info
configuration.yaml
info
exception
own
behavior
job
utc_point_in_time
suggestion
available
clock
support
timer
hardware
OS
kernel
little
bit
utcnow
bad
callbacks
assumptions
current
time
timer
time
delta
=
point_in_time.timestamp
time.time
delta
_LOGGER.debug
%
f
seconds
delta
cancel_callback
=
hass.loop.call_later
delta
run_action
return
hass.async_run_hass_job
job
suggestion
STATE_OPENING
HK_DOOR_OPENING
STATE_CLOSING
HK_DOOR_CLOSING
better
check
suggestion
isinstance
module.CONFIG_SCHEMA
vol.Schema
method
async
context
async_dispatcher_send
async
case
suggestion
self._hass.bus.async_fire
NEST_EVENT
data
sync
dispatcher_send
resource_update_events
device_id
device
event
something
documentation
last
week
https
//developers.home-assistant.io/docs/integration_events
automations
nest_event
device_id
<
thermostat
ID
>
events
thermostat
compatibility
layer
version
OpenZWave
correct
logic
backwards
compatible
topic
instance
>
/status
OpenZWave_Version
OZWDaemon_Version
QTOpenZWave_Version
QT_Version
Status
TimeStamp
ManufacturerSpecificDBReady
true
homeID
getControllerNodeId
getSUCNodeId
isPrimaryController
false
isBridgeController
false
hasExtendedTXStatistics
false
getControllerLibraryVersion
Z-Wave
getControllerLibraryType
Static
Controller
getControllerPath
/dev/serial/by-id/usb-Silicon_Labs_HubZ_Smart_Home_Controller_C0F009CE-if00-port0
suggestion
ozw_version
<
major
minor
version
suggestion
assert
CONF_USERNAME
entry.data
entities
single
call
async_add_entities
sensor
battery
enrity
unit
measurement
percentage
Error
level
enough
suggestion
_LOGGER.error
advice
async_unload_entry
method
scaffolding
list
use
[
]
import
function
circular
reference
suggestion
Attempt
Powerview
bdraco
[
comment
]
https
//github.com/home-assistant/core/pull/33388
discussion_r399852059
<
device
state
_close_
one
HomeKit
different
precision
HomeKit
sync
suggestion
device
worse
precision
HomeKit
state
_close_
HK's
state
HomeKit
DEVICE_PRECISION_LEEWAY
abs
current_tilt
self._homekit_target_tilt
<
DEVICE_PRECISION_LEEWAY
self.char_target_tilt.set_value
current_tilt
=
None
test
unknown
exception
library
specific
exception
entity
entity
Just
dev_id
set
.keys
Dict
membership
test
keys
default
serial
number
https
//pypi.org/project/python-synology/
https
//developers.home-assistant.io/docs/entity_registry_index/
Please
line
s
self.queue.get
call
block
break
except
block
suggestion
return
bool
data.now.datetime
suggestion
pilight
brightness
dimlevel_min
minimum
dimlevel
argument
suggestion
Update
brightness
argument
switch
previous
brightness
level
dimlevel
None
ATTR_BRIGHTNESS
kwargs
self._brightness
=
[
ATTR_BRIGHTNESS
]
Calculate
pilight
brightness
range
percentage
percentage
=
self._brightness
dimmer
range
aka
amount
available
brightness
steps
dimrange
=
self._dimlevel_min
pilight
brightness
dimlevel_min
minimum
dimlevel
=
int
percentage
*
dimrange
+
self._dimlevel_min
suggestion
Set
brightness
switch
previous
brightness
level
suggestion
pilight
brightness
dimlevel_min
minimum
suggestion
Update
brightness
argument
switch
previous
brightness
level
connect
CannotConnect
suggestion
raise
CannotConnect
suggestion
user
input
errors
block
user_input
None
suggestion
Roomba
configuration
flow
suggestion
__init__.py
def
async_setup
hass
HomeAssistant
config
dict
Set
roomba
hass.data.setdefault
DOMAIN
True
lot
executor
jobs
job
amount
threads
whole
method
sync
bunch
sync
methods
last
line
request
own
copy
paste
library
code
application
ID
encryption
key
suggestion
_LOGGER.exception
unknown
error
%
s
err
suggestion
Stale
comment
user
things
store
things
context
accessible
frontend
title_placeholders
other
things
use
instance
variables
SUPPORT_TARGET_TEMPERATURE
single
set
point
set
points
SUPPORT_TARGET_TEMPERATURE_RANGE
suggestion
Test
service
entity
features
suggestion
Test
service
entity
features
suggestion
Test
service
entity
required
features
code
Thank
Please
code
comment
suggestion
integration
custom_component
integration
config
entry
suggestion
suggestion
Initialize
ZoneTimeout
handler
suggestion
tests
_LOGGER.debug
zone
%
s
timeout
_FreezeNull
tests
suggestion
return
if-check
others
different
nature
other
guard
checks
execution
function
check
else
check
state.state
=
STATE_ON
state
state
more
values
suggestion
cur_state
=
hass.states.get
state.entity_id
ATTR_MODE
state.attributes
check
error
true
check
good
user
service
incorrect
effects
comment
update
method
correct
fix
effect
service
call
data
turn_on
method
self._effects_list
https
//github.com/home-assistant/core/blob/de7bbd3e24bee53b98a5481ac6fecf9505ca0565/homeassistant/components/nanoleaf/light.py
L212
Log
error
return
error
suggestion
level=logging.WARNING
Capture
warning
breadcrumbs
integration
template
suggestion
.const
import
pylint
disable=unused-import
suggestion
generic
info
device
discovery
API
specific
info
integrations
default_name
self.name
less
broad
exception
less
broad
exception
broad
thin
adaptor
UDP
BROADCAST
send/recv
sequence
exception
anything
socket
OS
specific
impact
atypical
timeout
possible
other
errors
system
broadcast
ipv4
interface
attempt
packet
device
data
structure
async
version
code
ready
branch
next
PR
status
underlying
tasks
discard
errors
lower
level
check
rid
need
exception
handling
level
Debug
default
level
update
method
coordinator.async_request_refresh
users
manual
updates
common
entity
update
service
async
def
async_update
Request
update
await
self._coordinator.async_request_refresh
suggestion
device
Device
=
hass.data
[
DOMAIN
]
[
devices
[
udn
]
unique
IDs
udn
+
sensor
type
Please
side
effects
__init__
function
async_setup_entry
entity
entity
Just
track
mac
addresses
new
Log
error
False
entities
respective
platform
ok
platform
entity
dispatch
helper
suggestion
api
WiffiIntegrationApi
=
hass.data
[
DOMAIN
]
[
config_entry.entry_id
]
Nest
_create_entity
async_add_entities
function
suggestion
.const
import
DEFAULT_PORT
DOMAIN
pylint
disable=unused-import
suggestion
return
Send
messages
encoded_message
encoded
Prepare
message
data
gammu_message
=
Text
encoded_message
Text
]
first
SMSC
number
phone
SMSC
Location
Number
self.number
try
message
self.gateway.SendSMS
gammu_message
gammu.GSMError
exc
pylint
disable=no-member
_LOGGER.error
%
s
%
s
suggestion
legacy
/
compatible
reasons
Debug
log
suggestion
legacy
/
compatible
reasons
suggestion
legacy
/
compatible
reasons
ConfigEntryNotReady
ConfigEntryNotReady
Home
Assistant
api
suggestion
hass.data
[
DOMAIN
]
[
]
=
DATA_HUB
hub
Config
entries
multiple
instances
data
suggestion
Exception
pylint
disable=broad-except
line
bit
pattern
multiple
times
function
example
august/config_flow.py
pysmarthab.RequestFailedException
exception
block
broad
exception
async_step_import
schema
same
def
async_step_import
Handle
import
return
self.async_step_user
user_input
language
top
level
key
translation
cache
description
comment
suggestion
current_unique_ids
entry.unique_id
entry
self._async_current_entries
suggestion
self._data
=
matching_discoveries
]
await
self.async_set_unique_id
user_input
[
'unique_id
]
unnecessary
only
time
test
requests_mock
main
conftest.py
Makes
sense
context
source
logic
import
discovery
remove
code
Please
comments
code
scaffold
tool
remove
code
Let
parts
schema
Please
comment
logic
future
readers
suggestion
def
_get_color
file_handler
>
Optional
[
tuple
]
Second
parameter
recent
call
last
/home/tom/Git/home-assistant/homeassistant/config_entries.py
line
async_setup
result
=
await
component.async_setup_entry
type
ignore
TypeError
async_setup_entry
positional
argument
data
coordinator
entities
same
function
component
integration
specific
error
error
place
python
homeassistant.components
media_source
media_source.is_media_source_id
media_id
media_info
=
await
media_source.async_get_media_info
hass
media_id
url
media_id
f
hass_url
media_id
suggestion
hass.components.websocket_api.async_register_command
websocket_browse_media
Jc2k
unique_ids
domain
DOMAIN
hash
suggestion
Test
suggestion
Test
CONF_I2C_ADDRESS
please
use
[
CONF_I2C_ADDRESS
]
add_entities
try
Please
try
recoverable
change
helpers/entity_platform.py
Same
recoverable
change
helpers/entity_platform.py
Please
top
bc58649c2becda4dbc46095c912c57201719c1a5
Can
second
session
scope
Please
globals
Please
code
comment
possible
content
types
Commented
code
fix
issue
Z-Wave
devices
temperature
climate
devices
old
Z-Wave
component
suggestion
Thermostat
valve
support
mode
suggestion
case
data
different
way
broad
exception
trap
Please
side
effects
init
authenticate
suggestion
self.account
=
None
suggestion
.const
import
CONF_CONTROLLER_UNIQUE_ID
CONF_LIGHT_COLD_START_TRANSITION_TIME
CONF_LIGHT_TRANSITION_TIME
DEFAULT_LIGHT_COLD_START_TRANSITION_TIME
DEFAULT_LIGHT_TRANSITION_TIME
DEFAULT_SCAN_INTERVAL
MIN_SCAN_INTERVAL
.const
import
DOMAIN
pylint
disable=unused-import
Stale
comments
core
codebase
scope
valid
name
pylint
case
bug
end
OAuth
specification
<
https
//tools.ietf.org/html/rfc6749
appendix-A.14
>
Let
comment
code
clear
message
Quby
suggestion
Toon
API
expires
string
tenants
OAuth
specifications
resp_json
expires_in
]
float
resp_json
expires_in
]
None
unit
Please
comment
above
Please
use
None
unit
measurement
None
NoneType
string
Pleas
use
hass.config_entries.async_setup
entity
customizations
entries
Exception
RuntimeError
connection
device
entry
exception
unknown
outdent
below
suggestion
current
standard
config
entry
authentication
credentials
everything
options
ongoing
discussion
topic
//github.com/home-assistant/architecture/issues/377
hass
entity
home
assistant
Pass
hub
entities
list
single
call
async_add_entities
suggestion
conf
=
config
sensor
[
DOMAIN
]
TypeError
list
indices
integers
slices
str
conf
=
config
[
DOMAIN
]
returns
TypeError
list
indices
integers
slices
str
different
way
config
better
config
component
module
integration
future
proof
platforms
discovery.load_platform
data
coordinator
helper
data
single
api
call
https
//developers.home-assistant.io/docs/integration_fetching_data
coordinated-single-api-poll-for-data-for-all-entities
strong
case
adjustable
timeouts
developers
reasonable
number
option
user
things
decision
Optional
settings
part
main
flow
options
flow
options
PR
options
flow
Stale
comment
Please
exception
broad
exceptions
suggestion
Test
node
status
comment
suggestion
Test
network
status
comment
suggestion
Exclude
binary
switch
multi_level_switches
light
devices
Stale
comment
comment
standard
integrations
import
config
flow
Stale
comment
Please
code
Stale
comment
suggestion
async
def
async_step_user
user_input=None
step_user
above
https
//developers.home-assistant.io/docs/config_entries_config_flow_handler/
suggestion
return
await
self.async_step_link
used
Please
commented
code
good
use
case
DataUpdateCoordinator
https
//developers.home-assistant.io/docs/integration_fetching_data/
coordinated-single-api-poll-for-data-for-all-entities
helpers/entity.py
hood
much
below
def
async_remove
>
None
Remove
entity
Home
Assistant
assert
self.hass
None
await
self.async_internal_will_remove_from_hass
self.async_will_remove_from_hass
self._on_remove
None
self._on_remove
self._on_remove.pop
self.hass.states.async_remove
self.entity_id
context=self._context
entity
dispatch
helper
suggestion
code
_LOGGER.exception
stream
source
full
traceback
error
actionable
something
stream
source
transient
error
camera
compatible
HomeKit
bit
word
..
upstream
TODO
lot
duplicated
code
Port
username
password
instance
attributes
method
host
port
unique_id
suggestion
No
name
source
name
suggestion
self.async_write_ha_state
able
state
domains
account
stage
domains
configuration
dependencies
example
alexa
cloud
depends
suggestion
Resolve
dependencies
integrations
right
=
domains
|
STAGE_1_INTEGRATIONS
integrations_to_process
=
[
int_or_exc
int_or_exc
await
asyncio.gather
*
loader.async_get_integration
hass
domain
domain
all_domains
isinstance
int_or_exc
loader.Integration
suggestion
audio
streams
profile
throw
errors
array
attribute
equivalent
CONF_INPUTS
field
below
actual
example
switch
platform
modbus
coils
name
plc_01_door_manual
hub
plc_01
slave
coil
code
state
duplicate
suggestion
stale
suggestion
hass.data.setdefault
DOMAIN
True
Exception
hence
pylint
check
kind
comment
mhmmm…
loop
anything
request.user
partial
requests
forwards
request.user
_non_-partial
requests
admins
collections
arbitrary
users
account
user
account
owner
request.user
same
thing
partial
requests
i.e
updates
author
read-only
field
serializer
comment
method
ValueError
comment
code
same
blog_lang
code
perfect
follow-up
github
issue
Add
comment
assert_cache_requests
empty
dict
comment
sure
able
field
python
class
UnsignedAutoField
def
db_type
connection
return
UNSIGNED
AUTO_INCREMENT'
def
rel_db_type
connection
return
UNSIGNED'
untested…
something
temporary
better
way
time
permanent
case
comment
significance
time
stamp
nice
reference
Might
docstring
comment
docstring
disable
add-ons
sole
owner
user
entry.in_progress
work
test
case
model
call
property
readable
property
safer
exact
same
logger
local
dev
prod
Eh
part
closure
namespace
issues
closure
list
comprehension
code
easier
comment
past
Couple
prints
print
bunch
Collection
models
properties
same
time
comment
Form
head
first
Form
comment
clones
celery
issue
eager
mode
heart
attack
comments
file
above
test
threads
reindexation
place
real
celery
eager
mode
implications
trivial
change
add-ons
developers
access
check_addon_ownership
False
add-ons
reviewers
read-only
access
only
thing
view
same
check
thanks
test
fact
developers
access
comment
access
next
decorator
call
helpful
comment
minimal
True
months
code
Ah
others
prod
change
separate
cleanup
step
safe
extraction
whole
lot
more
addons
past
API
response
frontend
badge
necessary
@
property
properties
something
class
comments
recommended
worth
different
groups
test
ongoing
investigation
https
//github.com/mozilla/addons-server/issues/5712
part
worth
comment
sense
changes
Imho
Ham
L10n
comment
translators
ham
traditional
sence
obvious
sure
everyone
English
thing
imho
everyone
reference
food
Monty
Python
matter
ugettext_lazy
/
_
import
time
comment
future
code
archaeologists
magic
numbers
other
similar
methods
filter
addons
content_review
non-admin
reviewers
anything
review
page
iirc
access
review
page
unlisted-only
addons
different
permission
reviews
reviewers
anything
review
page
anything
suboptimal
Product
okay
sure
inaccessible
review
page
TODO
E
django.db.utils.DataError
Data
column
'name
row
exact
author
value
multiple
times
email
email
name
significance
comment
case
bit
more
explanation
imho
legacy
frontend
pages
codestyle
fail
dashboard
credentials
others
comment
valid
anything
JS_MINIFIER_BIN
qs
type
ids
other
non-constant
defined
Category
instances
databases
seconds
wait
sure
flake8
space
/
lib/git
:get_diff
sure
low-level
possible
Make
sure
changes
dictionary
patch
datastructure
error
case
edge-case
case
various
diffs
scenario
tbh
%
sure
edgecases
renames
copies
others
diffs
more
file
redundant
comments
lines
gunicorn
bytes
WSGI
ghost
andym
cry
comment
jvillalobos
issue
comments
harmless
version
rsvg-convert
Travis
old
right
fix
trivial
quick
comment
code
undocumented
classes
ManyToManyDescriptor
many
undocumented
internal
methods
lot
more
documentation
tests
Docstrings
classes
comments
overridden
methods
different
tests
rest
basic
behavior
django
nightmare
next
django
upgrade
similar
way
translations
suggestion
Check
grandparent
folders
https
//github.com/mozilla/addons-server/pull/5178
discussion_r112623186
able
it…
imho…
fine
REVENUE_STATS_VIEW
_EDIT
postfix
_VIEW
_READ
matter
pendent
correct
cc
@
diox
opinion
explicit
names
assumed
meaning
nitpick
people
aware
implicit
meanings
easier
code
reason
permissions
constants
less
words
possible
View
explicit
Everytime
database
dev/stage/prod
database
something
confusion
couple
checks
user
collection
couple
checks
user
collection
Added
checks
https
//github.com/mozilla/addons-server/pull/5358/commits/73d2ad7c2a35f2d07038fe7b2d6917af6c995b32
comment
least
need
force_text
urlsafe_base64_encode
string
Django
onwards
bytestring.
problem
copy
paste
see_no_evil
…
author
something
responsible
laughing
anything
crazy
junk
files
Nit
cool
function
collection.modified
equal
point
nit
mapping
guessed_mimetype
None
i.e
line
mimetype
=
MIMETYPE_COMPAT_MAPPING.get
guessed_mimetype
guessed_mimetype
queries
idea
viable
descriptions
database
suggestion
knowns
necessary
best
shot
loop
known/match_all/urls
loop
twice
AFAIK
Firefox
same
locales
idea
something
knowns
list
empty
nativeMessaging
permission
knowns
list
creation
descriptions
database
/
check
permission
webext_permissions_list
knowns
re-sort
present
E.g
knowns
=
list
WebextPermissionDescription.objects.filter
name__in=self.webext_permissions_list
.iterator
urls
=
[
]
match_url
=
None
name
self.webext_permissions_list
re.match
WebextPermissionDescription.MATCH_ALL_REGEX
name
match_url
WebextPermissionDescription.ALL_URLS_PERMISSION
elif
name
==
WebextPermission.NATIVE_MESSAGING_NAME
Move
nativeMessaging
list
present
index
perm
enumerate
knowns
perm.name
WebextPermission.NATIVE_MESSAGING_NAME
knowns.pop
index
knowns.insert
perm
break
elif
'//
name
Filter
match
urls
group
urls.append
name
Other
strings
unknown
permissions
match_url
code
possible
urls
need
more
star
<
all_urls
>
position
first
loop
permission
descriptions
database
second
loop
permissions
manifest
order
algorithm
less
loops
b
sorts
loops
x
list
lookups
expensive
early
return
way
readability
method
big
early
returns
harder
sure
import
complicated
query
first
query
second
DB
e.g
something
=
WebextPermissionDescription.objects.filter
name__in=self.webext_permissions_list
len
q
something
results
knowns
=
list
q.exclude
name=WebextPermission.NATIVE_MESSAGING_NAME
match_url
=
q.get
name=WebextPermission.NATIVE_MESSAGING_NAME
reason
import
time
wasteful
time
permission
okay
least
Firefox
https
//github.com/mozilla/addons-server/blob/master/locale/ar/LC_MESSAGES/django.po
L713
explicit
decision
permission
descriptions
Seems
unlikely
race
condition
specific
package
msg.set_if_matches
value=True
store
trick
Redis
GETSET
command
trick
was_locked
=
msg.getset
'true
==
lock.
value
lock
True
lock
good
least
comment
return
value
docstring
way
oh
man
concerns
null
means
languages
mapping
specific
fact
comment
imho
comment
nice
Extra
comment
include_
*
variables
new
filter
names
comment
docs
comment
//www.unicode.org/reports/tr44/tr44-6.html
Property_Values
categories
future
reference
GIT_FILE_STORAGE_PATH
different
setting
libgit
non-existing
files
remote
filesystem
hack
way
stuff
thanks
pythons
dynamic
nature
like
StaticCategory
immutable
avoid
__setattr__
directly.
correct
Typo
regualr
[
comment
]
https
//github.com/mozilla/addons-server/issues/11819
issuecomment-515924406
logic
Django-Debug-Toolbar
more
code
otherwise
name
middleware
other
words
flexibility
comment
.no_cache
bit
important
.no_cache
django-cache-machine
otherwise.
data
better
error
one
obvious
comment
documentation
addon_id
need
hack
nasty
feeling
scikit-learn
metrics
use
binary
classification
fpr
fnr
widget
outcomes
class
group
overall
real
documentation
f
different
name
Please
review
comments
previous
PR
bad
conflict
resolution
above
comments
nit
comment
line
expression
clause
pd.nan
values
y
=1
super
.load_data
X
y
event=pd.Series
y
.apply
lambda
y
_LABEL
=
+
str
*
*
kwargs
sensitive
feature
protected
attribute
nit
typo
opportunity
men/women
males/females
nit
optimization
subdirectory
_postprocessing
class
name
indifferent
logical
directory
name
docstrings
user
pos_label
TPR
definition
labels
positives
samples
y_true=1
more
labels
label
present
ambiguity
TPR
FPR
TNR
FNR
label
pos_label
numeric
>
>
skm.confusion_matrix
[
]
]
labels=
[
]
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
File
/mnt/c/Users/mdudik/projects/fairlearn/.venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py
line
confusion_matrix
raise
ValueError
least
label
y_true
ValueError
least
label
y_true
>
>
>
point
message
text
sure
error
condition
multiple
options
other
params
documentation
new
way
doc
param
interpolation_dict
…
type
interpolation_dict
dict
sure
same
file
entire
file
crowded
things
fit
file
search
class
name
noqa
[
renders
]
https
//1786-133444044-gh.circle-artifacts.com/0/docs/_build/html/master/api_reference/fairlearn.widget.html
rid
listing
types
Something
off-topic
AzureML-related
review
....
'demographic
parity
good
name
different
people
different
things
'demographic
same
way
'bias
writing
term
literature
something
neutral
term
'selection
rate
parity
ConditionalSelection
rate
class
docstrings
similar
project_lambda
ones
further
changes
sensitive
feature
other
people
least
comment
better
build-widget.ps1
same
code
languages
easier
script.template_py
search/replace
replaces
multiple
lines
way
invalid
combinations
skipped
tests
unfixed
bugs
test
fix
unimplemented
features
maximum
value
>
parameter
vague
idea
clear
line
relationship
complicated
linear
dependence
redundance
constraints
things
correct
efficient
additional
clarification
fewer
constraints
correctness
GridSearch
Constraints
final
group
redundant
basis
comment
closer
basis
right
line
description
matrices
pos_basis
neg_basis
lower-dimensional
description
constraints
redundant
constraints
specific
reason
Might
confuse
people
A
B
least
something
simpler
random
numbers
comment
group
math
<
math
>
math
<
insert
math
>
@
MiroDudik
question
code
entries
gamma
negative
certain
sensitive
feature
one-sided
constraint
satisfied
lambda
vector
Lagrangian
value
L
negative
values
sure
unintended
top
file
current
code
tests
internal
logic
lagrangian
points
*
correct
value
lagrangian
value
*
best
only
requirement
projected_lambda
improvement
unspecified
many
possible
improvements
okay
better
theta
signed_weights
dependence
lagrangian
only
oracle
call
consistent
lagrangian
logic
signed_weights
incorrect
better
approach
signed_weights
separate
copy
Constraints
default
objective
fields
Moment
check
other
checks
tests
routine
issue
link
comment
fan
code
error
please
TODO
mark
instance
changes
view_no
self.view_no
self._next_view_indications
misprint
checkpint
sorry
Ok
rename
service
status
runs
update
service
>
passing
doc
strings
arguments
actual
args
day
bc
confused
asserts
code
vs
exceptions
huge
deal
nit
rename
last
last
end
kinda
suggestion
continue
comments
unnecessary
purpose
docstring
good
moment
commented
code
[
eradicate
]
https
//github.com/myint/eradicate
library
>
modern
revision
control
available
reason
commented-out
code
repository
fact
things
variable
names
pep8
rules
other
things
comments
good
idea
course
git
history
suggestion
file
same
name
target
directory
Grammar
police
oncoming_police_car
Nitpick
line
79-char
limit
least
chars
IMHO
file
instance
line
DOWNLOADER_CLIENTCONTEXTFACTORY
=
'scrapy.core.downloader.contextfactory.ScrapyClientContextFactory
chars
Gallaecio
part
windows
platform
parse_version
error
tests
least
comment
memory
leak
Could
fix
type
check
documentation
string
only
value
comparison
case-insensitive
e.g
thing
test
comments
generate_raiden_clients
new
token
network
comment
help
better
thanks
comment
english
comments
better
solution
look
upper
case
sql
keywords
pylint
disable=no-self-use
able
necessary
_i
disable
Remove
files
checker
line
top
file
first
import
statements
disable
comments
class/function
definitions
files
global
disable
directive
Same
comment
above
order
underlying
query
.filter
results
Use
assertIn/assertNotIn
results
iterate
resulting
list
things
Lines
15-18
properties
sort
access
account
other
parts
application
explanatory
comments
descriptive
method
names
HTML
inside
Azure
Boards
comments
newlines
i
self.md_table
=
|Stx
|Desc
|\n|
-|\n|Head|Title|\n|Text|Text
|
setup
method
def
test_markdown2html_convert_tables
self.assertEqual
self.md_table
<
table
>
clearer
IMO
comment
bogus
object
idea
variable
comments
code
describe
WHY
way
stil
>
DetailView
Remove
unnecessary
comment
Comment
unnecessary
code
speaks
comment
better
readability
scenario
special
comments
view
present
Use
follow=True
.post
redirect
assertContains
response
response
HTML
*
bug
*
comment
TODO
disable
directive
line
class
name
disable
checker
current
line
end
file
IDs
independent
bug
records
file
open
right
end
block
Just
file
ids
json.dumps
comment
b/c
correct
rebase
_default_manager
>
objects
models
CONTENT_TYPES
dictionary
default
manager
hmmm
same
username
website
other
words
token
IMO
notes
doc-string
new
repository
issue
https
//bitbucket.org/kiwitcms/integration/issues/1/hello-world
internal
BitBucket
Issue
tracker
JIRA
integration
point
test
tier2
same
variable
f
current
WA
health
check
'rook-ceph-crashcollector
Lets
next
test
cases
pods
openshift-storage
project
status
test
'rook-ceph-crashcollector
stays
state
better
'rook-ceph-crashcollector
associated
deployment
pod
disappears
WIP
implement
exception
case
Could
pods
PVCs
teardown
part
test
case
Use
teardown_factory
pvc
teardown
part
test
case
usage
test_pvc_to_pvc_clone
interface_type
pod_factory
teardown_factory
<
rest
code
>
teardown_factory
cloned_pvc_obj
content
file
content
sure
exact
copy
data
pytest.raises
TimeoutExpiredError
block
https
//docs.pytest.org/en/latest/assert.html
assertions-about-expected-exceptions
Remove
imports
self.run_io
redundant
start_io
test
pep8
failure
flatten
line
suggestions
testcase
threads
future
objects
list
lists
lists
list
flatten
line
overall
question/feedback/comment
different
lists
PVC
different
access_modes
intefaces
same
pods
lists
separation
good
test
test
case
ID
suggestion
use
url
digest
suggestion
auths
image
md5sum
directory
files
lot
information
individual
comment
lines
function
information
docstring
additional
benefit
information
documentation
pls
cases
more
prometheus
pod
different
PR
fixtures
class
references
Please
https
//github.com/red-hat-storage/ocs-ci/blob/master/docs/fixture_usage.md
use
get
method
same
comment
other
PR
consider
name
monitoring
tests
test
i.e.
test
names
consistent
readable
lot
future
validation
new
metric
node
request.addfinalizer
teardown
Please
line
add
empty
lines
sections
python
function
..
Args
arg1
type
Returns
type
description
other
places
Todo
Replace
TimeoutSampler
Todo
exception
case
BS
import
config
use
config.RUN
[
'log_dir
]
How
IO
failures
IO
thread
break
check
more
max
number
resources
selector=constants.NOOBAA_ENDPOINT_POD_LABEL
max
number
max_eps
nb_obj.get
.get
]
.get
'spec
.get
'endpoints
.get
'maxCount
build
status
..
Please
comment
use
ocp.wait_for_delete
build
status
state
@
Avilir
@
prsurve
similar
functionality
https
//github.com/red-hat-storage/ocs-ci/pull/1345/files
diff-ffa18f30e526ae7b2498579992b406efR272
Let
implementation
docstring
arg
value
label_worker_node
helpers.py
move
Please
function
bool
pod_list
same
list
deletion
get_all_pods
fresh
list
other
pls
openshift_logging_namespace.get
assert
openshift_logging_namespace.delete
openshift_operators_redhat_namespace.get
assert
openshift_operators_redhat_namespace.delete
resource_name='openshift-operators-redhat
-P
option
reboot
container
host
boolean
command
official
docs
setsebool
-P
container_use_cephfs
suggestion
experience
pods
nodes
most
better
throughput
results
nodes
PVC
access
mode
VolumeMode
PVC
upstream
pvc
name
helpful
failures
minor
nit
i
*
please
node
list
helpers.remove_label_from_worker_node
function
call
list
names
non-ocs
nodes
good
check
setup
fixture
time
same
Let
try
avoid
absolute
number
Please
issue
implementation
issue
break
lines
Any
reason
exec_cmds
present
ocs-ci
comment
places
suggestion
podman
hence
'relabel=shared
private
repository
flexy
directory
something
podman
run
command
pointing
directory
private
repo
flexy
directory
command
error
fatal
destination
path
exists
empty
directory.
@
dahorak
possibility
info
config
URL
custom
branch
please
variable
branch
name
repository
file
local
source
Daniel
different
comment
way
variable
env
file
config
higher
priority
private
repository
OCS-CI
specific
file
better
multiple
env
files
different
approaches
PSI
/
Disconnected
AWS
change
specific
variables
env
file
dahorak
more
maybe
proper
place
drop
comment
Thanks
favour
self.flex_env_file
__init__
ack
Initial
idea
default
download
private-conf
changes
inside
container
behaviour
default
env
file
clone
necessary
instad
flexy
container
configuration
LAUNCHER_VARS
*
ocs-osp.env
*
precedence
onfiguration
config.ENV_DATA
other
words
own
dict
config.ENV_DATA
[
]
keys
LAUNCHER_VARS
variable
*
ocs-osp.env
*
file
above
statement
correct
better
vice
higher
priority
configuration
user
config.ENV_DATA
[
]
other
configuration
variables
underscores
dash
key
name
sure
better
[
]
sure
mandatory
above
self.flex_env_file
__init__
logic
comment
logic
case
possible
multiple
env
files
flexy
private
repository
different
env
file
name
cloning
private
repository
approach
*
self.flexy_env_file
[
]
default
constants.FLEXY_DEFAULT_ENV_FILE
self.flexy_env_file
exists
self.flexy_env_file
exists
part
private
flexy
repo
clone
*
more
check
self.flexy_env_file
exists
exception
better
new
section
configuration
FLEXY
parameters
flexy
env
file
other
variables
*
ENV_DATA
*
section
comment
reduction
enwik8+snappy
compression
comment
specific
AWS
comment
mentions
Polarion
tests
same
Polarion
ID
polarion_id
marker
test
level
Please
testcase
more
detail
fixtures
same
decorator
@
pytest.mark.usefixtures
test_fixture.__name__
create_ceph_block_pool.__name__
least
part
code
example
part
helpers.create_unique_resource_name
general
piece
code
python
self.sc_data
[
'metadata
]
[
]
=
helpers.create_unique_resource_name
'test
f'csi-
interface.lower
whole
elif
block
code
something
python
log.info
f
interface
Storage
Class
=
templating.load_yaml_to_dict
getattr
constants
f
CSI_
interface
_STORAGECLASS_YAML
self.sc_data
[
'metadata
]
[
]
=
helpers.create_unique_resource_name
'test
f'csi-
interface.lower
rebase
logic
function
get_osd_count
see
https
//github.com/red-hat-storage/ocs-ci/commit/4132546cd260a80aa85b335299ee8038d0dd228f
diff-40ca86338b56ecd56fb458ca2ea36c3b
please
make
sure
content
commit
thanks
runtime
seconds
age
PR
test
setup
test/setup
separation
logic
fixture
line
@
pytest.fixture
autouse=True
def
test_setup
interface
storageclass_factory
pvc_factory
pod_factory
Create
resources
test
self.sc_obj
=
storageclass_factory
interface=interface
self.pvc_obj
=
pvc_factory
interface=interface
storageclass=sc_obj
size=pvc_size
self.pod_obj
=
pod_factory
interface=interface
pvc=pvc_obj
test
function
signature
def
test_pvc_resize
test_setup
great
functionality
ocs_ci.ocs.resources.pvc.PVC
resize_pvc
seconds
needs
timeout
bellow
Good
PVC
capacity
pod
much
helpful
analysis
pls
consider
osd
up
actions
separate
function
separate
PR
*
Create
DC
pods
failure
node
IO
inducing
failure
*
Post
failure
DC
app
pods
other
nodes
able
IO
DC
app
pods
FYI
patch
review
https
//github.com/red-hat-storage/ocs-ci/pull/1591
plans
PR
functionality
multiple
tests
function
common
file
node
bit
confusing
volume
few
lines
ec2_volume
comments
lot
flow
same
comments
same
volume
function
easier
approach
workers
function
strange
X
workers
list
class
attribute
'workers
attribute
node
~5-10
minutes
visible
OCP
cluster
side
NotReady
nodes
impact
cluster
self.validate_cluster
warnings
correct
certificate
sure
dropping
warnings
SSL
customer
scenario
messages
issue
todo
comment
code
warning
log
message
SSL
warnings
first
line
fixture
@
reason
sure
order
finalizer
comment
storage
class
different
order
PVC
example
vimdiff
output
executions
left
side
defined
storage_class
factory
right
side
https
//paste.fedoraproject.org/paste/Gc8WLgbYBTZkkkcybZlK4Q
storage
class
test
sure
required
resource
right
order
order
SC
PVC
order
PVC
SC
example
complex
matrix
resources
sure
fixture
factories
able
order
setup
resources
right
way
create_pvcs
fixture
function
factory
fixture
nightmare
multiple
tests
output
class
scope
factory
fixture
wrapper
fixture
factory
shared
resources
list
way
tests
list
resources
wrapper
fixture
list
example
tests
three_pvcs
fixture
list
pvcs
pvc_factory
fixture
sure
question
issue
resources
tests
fixture
class
scope
test
cases
same
polarion
id
polarion
such
case
Akarsha-rai
changes
sanity_helpers
implementation
new
implementation
https
//github.com/red-hat-storage/ocs-ci/blob/bd691eab475fd5b69d6b31752f96d2adbefcb116/tests/sanity_helpers.py
L13
reference
usage
https
//github.com/red-hat-storage/ocs-ci/blob/bd691eab475fd5b69d6b31752f96d2adbefcb116/tests/manage/cluster/nodes/test_nodes_maintenance.py
L40
chance
OSD
pods
able
resource
right
timing
Which
command
output
line
https
//github.com/red-hat-storage/ocs-ci/blob/9e04a842930d30c313fd51f6f28e1764a9512cde/ocs_ci/utility/utils.py
L2284
%
please
rename
capacity_2_use
capacity_to_use
digit
bug
ON_QA
validation
https
//github.com/red-hat-storage/ocs-ci/issues/502
add
more
loggers
helpful
more
logs
please
comment
//github.com/red-hat-storage/ocs-ci/pull/2335
discussion_r453698400
Please
comment
code
half
disk
case
RWX
same
wait_for_delete
True/False
please
comment
line
same
please
code
useful
many
test
cases
Please
same
need
seld
variables
method
assert
same
comment
line54
assert
number
image
registry
pod
expected
count
wait_for_resouce
TimeoutExpiredError
TimeoutSampler
See
ocs_ci.utility.utils.TimeoutSampler
create_pvc
updated
pvc
data
OCS.create
reload
same
change
function
Please
function
common
place
confest.py
same
implementation
Please
numbers
change
newer
builds
get_typed_nodes
num
nodes
input
node
random
choice
Delete
app
pods
PVCs
project
please
helpers.create_project
line
intentional
pod
reach
Change
Wait
pgbench
pod
state
pgsql.wait_for_pgbench_status
status=constants.STATUS_COMPLETED
node
pod
state
Please
arg
pod_status
true
Do
node_network_failure
network
node
ready
state
Please
polarion
id
tests/manage/mcg/test_bucket_creation.py:20
consider
pod_factory
deploymentconfig
service
account
@
jilju
part
POD
deletion
good
respective
mount
points
hosting
nodes
enhancement
POD
teardown
suggest
mount
point
/dev/rbdxxx
/var/lib/www/html
easy
same
node
side
meaningful
name
Test
Class
[
]
yaml
spec
accessModes
ReadWriteOnce
comment
logic
imports
top
module
order
pep8
way
~13
hours
test
hrs
such
long
timeout
value
wait_for_pgbench_status
node
noobaa-db-0
rgw
pod
log
storage
pods
healthy
Please
OBC
creation/object
IOs
node
buckets
objects
s3_put_object
s3_get_object
functions
objects
buckets
Did
ful
comment
*
*
right
True
danger
loop
number
retries
timeout
True
infinite
time
unexpected
behavior
happens
Please
lines
assert
self.check_cluster_health
Cluster
healthy.
EC2
Instances
self.instances_in_az
blocked
f
Access
EC2
instances
self.instances_in_az
loop
pod
nodes
pods
same
node
labels
node
specific
node
please
check
//kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/
better
part
'pod.delete
way
code
deletion
scripts
part
upper
classes
implementation
suggestion
range
hard
example
values
ocs_basic_install.yml
worker/master
nodes
....
dc_pod_factory
service_account
comments
get_deployment
method
factory
specific
exception
DeploymentPlatformNotSupported
helper
function
pvc.py
function
async_delete_pvcs
pvc.py
helper
function
please
function
fixture
setup
sure
pods
amq
benchmark
pods
benchmark
case
logic
suggestion
timeout
=
ocs_version
>
use
helpers.create_pod
pr
run_io
pod
object
better
dd
wait
thanks
great
docstring
Please
use
helpers.create_pvc
alignment
value
exception
Line
bool
Same
=
f'cp
s3
//
bucket_name
/
original_dir
./
result_dir
/
awscli_pod.exec_cmd_on_pod
command=craft_s3_command
mcg_obj
copycommand
secrets=
[
mcg_obj.access_key_id
mcg_obj.access_key
mcg_obj.endpoint
]
=
f'cp
./
original_dir
s3
//
bucket_name
/
awscli_pod.exec_cmd_on_pod
command=craft_s3_command
mcg_obj
copycommand
secrets=
[
mcg_obj.access_key_id
mcg_obj.access_key
mcg_obj.endpoint
]
same
assertion
message
line
polarion
importer
polarion
OCS-XXXX
polarion
ids
https
//github.com/red-hat-storage/ocs-ci/issues/3121
issue
W/A
value
Ckeck
osd_dump_dict
suggestion
osd_dump_dict
[
same
bracket
convention
please
same
bracket
convention
previous
comment
brackets
f
bla
bla
python
downloaded_files
helpers.retrieve_test_objects_to_pod
awscli_pod
original_dir
function
run_bg
messages
upstream
strimzi-kafka-operator
yamls
ocs-workloads
repo
yamls
yamls
amq.py
file
function
function
Kind
'PersistentVolumeClaim
position
objects
list
differs
OCP
OCP
comment
reference
Same
image_pull
successful
Any
assert
statements
return
values
sure
other
usages
destroy_folder
sense
check
way
check
other
places
course
destroy_folder
folder
log
message
folder
deletion
due
reason
line
absolute
number
seconds
functionality
ocs_ci.utility.utils.TimeoutSampler
ocs_ci.utility.retry.retry
change
test
add
capacity
nodes
restart
middle
process
function
ocs_ci.utility.utils.TimeoutSampler
polling
logic
assertion
message
block
line
upgrade
Vijay
f'release-
get_ocp_version
branch
branch
higher
branch
WA
conversation
yesterday
regular
z
streams
previous
versions
n-2
n-1
good
content
specific
version
branch
versiom
specific
version
function
pod
Looks
strange
Please
description
config
arg
TODO
tracker
TODO
=
CEPHCLUSTER.get
.get
unit
test
suggestion
Remove
privacy
actions
available
community
little
more
context
means
notes
..
note
search
API
return
relative
results
in-doc
search
https
//docs.example.com/en/latest/foo.html
custom
domains
subpaths
fewer
queries
worth
logic
docstrings
domain
note
list
bc
result
highlight
comment
params.ranking
worth
bit
shape
]
+1
ransac
comment
suggestion
weight
=
rng.rand
y.shape
]
iter
tired
assertions
suggestion
check_unknown=False
_encode_check_unknown
elipsis
print
fine
Round
bit
weird
ELLIPSIS
precision
issues
platforms
docs
https
//docs.python.org/2/library/doctest.html
directives
And/or
git
grep
ELLIPSIS
Ellipsis
honest
something
print
regr.coef_
[
]
precision
problems
@
amueller
mind
round
elipsis
round
more
explicit
comment
deprecation
logic
trivial
instance
Attribute
classes_
DecisionTreeRegressor
class
BaseDecisionTree
isinstance
estimator
DecisionTreeRegressor
check
spurious
warning
TODO
isinstance
check
classes_
attribute
DecisionTreeRegressor
class
pattern
different
path
transform
weird
pattern
something
py
def
transform
X
return
self._transform
X
def
fit_transform
X
return
self.fit
X
._transform
None
def
_transform
X
n_samples_transform
self.n_samples_fit_
X
None
X.shape
[
]
return
code
paths
different
extract
functions
little
strange
def
extract
sample
same
number
provided
neighbors
row_nnz.max
row_nnz_min
return
a.reshape
n_samples
-1
[
n_neighbors
idx
=
np.tile
np.arange
n_neighbors
n_samples
=
idx.reshape
n_samples
n_neighbors
+=
graph.indptr
[
-1
np.newaxis
]
return
a.take
idx
mode='clip
.reshape
n_samples
n_neighbors
true
diagonal
explicit
explicit
vs
implicit
zeros
diagonal
easiest
way
def
_get_explicit_diagonals
X
Returns
indices
rows
diagonal
X
=
X.tocoo
return
X.row
[
X.row
==
X.col
]
include_self
logic
comment
n_quantiles
training
size
warning
suggestion
ref
User
Guide
<
suggestion
new
transformers
class
suggestion
class
~sklearn.neighbors.RadiusNeighborsTransformer
precomputation
Nit
suggestion
number
neighbors
graph
comment
clear
ode
Maybe
let
comment
public
API
comment
iloc
condition
Please
use
assert_warns
hasattr
behaviour
test
test
non-deprecated
behaviour
assertion
comment
opposite
deprecation
complete
comment
store_covariance
effect
solvers
suggestion
digits
use-digits-dataset
command
line
argument
suggestion
nans
np.nan
last
element
difference
succinct
suggestion
missing_values
value
value
items
is_missing
value
output
=
items
missing_values
Enforces
order
None
first
None
missing_values
missing_values
output_missing_values
[
None
]
output_missing_values
[
None
]
elif
missing_values
output_missing_values
[
np.nan
]
output_missing_values
[
]
suggestion
Extract
missing
items
typo
fittng
procesdure
fair
few
typos
tree
pruning
in-depth
review
Calcuate
smaller
trees
math
notation
comments
beginning
example
effect
cpp_alpha
trees
other
parameters
tree
different
way
example
Nah
example
cpp_apha
_
cpp_alpha
zero
decision
tree
overfits
other
parameters
defaults
dataset
part
bit
misleading
happy
comment
happier
effect
cpp_alpha
let
max_depth
parameter
example
np.linspace
comment
PYTHON_CROSSENV
osx
arm
test
program
Does
compile
test_program
Nitpick
comment
double
whitespace
instance
course
title
plot
Please
sure
final
plot
readable
chosen
figure
size
Please
line
plt.figure
figsize=
figure
size
sure
size
good
strong
opinion
intention
example
something
specific
ears
comment
sense
threshold
max_features
default
threshold
able
use
X.power
suites
stratification
se
class
samples
suggestion
method
calls
scorer
dict
scorer
=
_MultimetricScorer
*
*
scorer
suggestion
scalar
need
such
comments
multiple
lines
chars
limit
PEP8
small
private
function
data
def
_apply_func
func
X
result_full
=
func
X
=
X.shape
[
]
result_by_batch
=
[
func
batch.reshape
n_features
batch
X
]
func
output
e.g
score_samples
type
res_all
tuple
result_full
result_full
]
result_by_batch
=
list
lambda
x
x
]
result_by_batch
np.ravel
result_full
np.ravel
result_by_batch
def
check_methods_subset_invariance
name
estimator_orig
result_full
=
_apply_func
get_attr
estimator
method
results_full
results_by_batch
atol=1e-7
err_msg=msg
comment
something
mini
bathes
whole
set
something
first
plot
interpretable
way
IMHO
last
plot
different
observation
goal
std
dev
CC
@
glemaitre
@
GaelVaroquaux
suggestion
other
features
younger
person
higher
suggestion
AGE
WAGE
other
features
paragraph
first
plot
one
conclusion
last
plot
different
order
better
multiplication
std
dev
efforts
obscure
/
CC
@
GaelVaroquaux
@
cmarmo
comment
github
sure
picky
blue
much
aggresive
alpha
median
value
instance
let
axis=0
pandas
numpy
same
default
numpy
array
std
whole
array
rest
incorrect
sure
sign
same
coefficient
AGE
correlation
EXPERIENCE
test
set
train_test_split
such
analysis
suggestion
Soon
different
coefficients
suggestion
feature
AGE
lot
more
several
decades
title
plot
people
example
fast
instance
suggestion
plt.scatter
coefs
[
AGE
]
[
EXPERIENCE
]
plt.title
'Variations
coefficients
AGE
EXPERIENCE
folds
split
exploratory
analysis
model
decisions
e.g
log
test
data
Uhm
issue
initial
message
following
http
//gael-varoquaux.info/interpreting_ml_tuto/content/02_why/01_interpreting_linear_models.html
coefficients-of-a-linear-model
point
relationship
single
feature
target
marginal
link
type
analysis
such
plot
linear
model
features
compute
conditional
links
legend
plot
'Coefficients
*
std
dev
'Coefficients
sentence
multiplication
division
CC
@
GaelVaroquaux
constant
experience
other
features
constant
bit
point
variable
seem
*
linearly
*
Variability
My
previous
comment
plot
tells
increase
AGE
decrease
first
plot
std
dev
conclusion
suggestion
suggestion
variability
coefficients
ambiguous
predictors
models
estimators
suggestion
features
different
natural
scales
hence
value
feature
scaling
problem
original
feature
transformations
division
large
>
larger
sentence
correct
random
feature
high
variance
predictive
power
coeff
effect
coeff
output
negligible
devil
advocate
coeff
bad
model
way
cross-refs
sphinx
seaborn
functions
suggestion
regularization
parameter
space
1.e-10
regularization
controls
complexity
term
regularization
parameter
use
hence
suggestion
math
=
\sum
coef_i
X_i
=
suggestion
model
learnt
good
model
accurate
predictions
suggestion
features
first
place
suggestion
order
interpretation
features
suggestion
problem
correlated
variables
people
hints
home
messages
table
content
suggestion
estimation
EXPERIENCE
coefficient
stable
important
predictors
cross-validation
disappointed
comparison
Lasso
open
question
suggestion
instance
AGE
coefficient
years
Typo
suggestion
linear
model
*
*
conditional
link
*
*
suggestion
machine-learning
practice
Ridge
Regression
non-negligible
regularization
Above
regularization
little
amount
suggestion
\sum
std_i
\times
X_i
/
std_i
discussed
IRL
new
section
data
pipeline
effect
regularization
coefficients
different
results
interesting
thing
reason
data
analysis
decisions
knowledge
test
data
suggestion
AGE
EXPERIENCE
coefficients
unstable
comments
X.describe
meanwhile
discussion
type
variables
Better
following
plot
dot
sample
something
sentence
Please
version
current
comment
enough
side
typo
parametrize
line
Returns
arbitrary
callable
metric
suggestion
Row
index
receivers
potential
donors
suggestion
non_missing_fit_X_col
array-like
shape
=
n_train_samples
suggestion
imputed_values
array
shape=
n_receivers
lines
iloc
X_index
=
X.index.copy
n_round
range
n_repeats
random_state.shuffle
shuffling_idx
hasattr
iloc
col
=
X_permuted.iloc
[
shuffling_idx
col_idx
]
col.index
=
X_index
X_permuted.iloc
[
]
=
col
@
ogrisel
safest
path
.values
only
confusing
thing
reset_index
drop=True
Otherwise
iloc
pandas
index
permuted
column
intuitive
@
check
trivial
solutions
Check
problem
model
complex
trivial
constant
importances
imp_min
importance_sequential
[
'importances
]
.min
=
importance_sequential
[
'importances
]
.max
imp_max
imp_min
threshold
right
scale
r2
score
Small
nit
except
ValueError
e
values
str
e
pipeline
raise
ValueError
msg
raise
regular
estimator
input
Fortran
array
error
code
code
more
intended
justification
iteritools.product
somebody
double
loop
simpler
readable
run
time
long
~20min
useful
indication
progress
tqdm
dependency
manual
progress
indicator
print
..
use
product
idiomatic
deep
loops
way
Python
comment
tip
Thanks
declaration
top
points
non
ideal
benchmarks
time
current
document
dataset
representative
real
work
dataset
vocabulary
size
wise
etc
sure
size
computations
Besides
benchmark
std
~1
%
run
time
factor
optimization
gains
more
%
performance
idea
order
magnitude
standard
deviation
run
variations
negligible
better
median
range
sure
thing
benchmarks
multiple
configurations
tables
hard
e.g
example
]
https
//github.com/rth/notebooks/blob/master/benchmark/benchmark_count_vectorizer.md
range
readable
median
right
mean
consistent
regular
%
timeit
benchmarks
stable
run
review
comment
iteritools.product
right
strange
windows
script
wheel
wheel
wheel
README.rst
part
MANIFEST.in
sense
output
identical
input
high
precision
scaler
features
input
dtype
test
tests
numpy
boolean
arrays
list
_check_key_type
key
int
check
i.e
py
_check_key_type
[
True
False
]
int
True
comment
excessive
min_impurity_split
end
ignore_warnings
line
tests
outputs
>
>
>
imp_mean
=
SimpleImputer
missing_values=np.nan
strategy='mean
SimpleImputer
copy=True
fill_value=None
missing_values=nan
strategy='mean
verbose=0
logic
correct
check_input=False
fit
copy_X=False
init
code
copy
cases
argpartition
ValueError
k
bounds
array
case
samples
max_proba
something
=
np.argpartition
n_to_select
max_proba.shape
]
-1
[
n_to_select
readable
y.astype
str
=
-1
incorrect
API
-1
'-1
label
unlabeled
samples
y.astype
object
=
-1
Thanks
~haslabel
]
unnecessary
call
samples
point
ConvergenceWarning
blank
line
astype
object
necessary
comment
code
problem
string
dtype
error
legit
generic
test
estimators
additional
input
iteration
docstring
fact
iris
samples
iteration
SelfTrainingClassifier
same
base
classifier
test
good
docstring
test
name
explicit
assert
np.all
st.y_labeled_iter_
==
max_iter
comment
redundant
test
take
Zhou
al
please
comment
suggestion
case
p-value
low
classifiers
able
suggestion
features
labels
empirical
p-value
suggestion
random
feature
data
i.e
features
uncorrelated
class
plot.show
wrong
single
one
end
suggestion
data
p-value
low
suggestion
possible
reason
high
p-value
classifier
suggestion
iris
dataset
labels
suggestion
clf
X_rand
y
scoring=
accuracy
cv=cv
n_permutations=1000
suggestion
f
p-value
pvalue_iris
.3f
good
xlabel
figure
suggestion
ax.text
score_label
fontsize=12
ax.set_xlabel
Accuracy
score
ax.set_ylabel
Probability
count
ax.hist
suggestion
class
classifier
ref
model
round
suggestion
distribution
null
hypothesis
dependency
suggestion
f
p-value
pvalue_rand
.3f
suggestion
poor
results
large
p-value
suggestion
classifiers
high
p-value
structure
present
shuffle=True
random_state=0
cv
iris
default
example
proper
density
suggestion
ax.hist
perm_scores_iris
bins=20
density=True
Default
suggestion
clf
X
y
scoring=
accuracy
cv=cv
n_permutations=1000
suggestion
class
classifier
ref
space
mathematical
operator
comment
test
assert_raises
ValueError
clf.fit
X
y
check_input=False
X
bits
_preprocess_data
prevent
fit
ValueError
check_input=False
smoke
test
X
bits
test
ValueError
test
smoke
test
smoke
test
clf.fit
X
y
check_input=False
comment
check_input=False
exhaustive
check
y
dtype
y
_preprocess_data
dtype
X
passes
future
lines
astype
dtype
copy=False
important
test
Could
comment
bit
descriptive
check
pd
plot
different
target
class
comment
bit
descriptive
check
pd
plot
same
labels
groups
case
order
>
visualize
>
information
>
information
KFold
StratifiedKFold
plots
small
side
https
//29038-843222-gh.circle-artifacts.com/0/doc/auto_examples/model_selection/plot_cv_indices.html
splits
suggestion
No
error
added
columns
ordering
identical
point
line
previous
line
same
assert_warns
works
output
n_components
sure
same
..
m
ignore_warnings
Um
Actually
dependent
previous
one
other
potential
causes
LinAlgError
try
block
statements
right
values
useful
comment
Cosmit
kwargs
easy
sample
weights
suggestion
comment
wrong
[
]
same
x_score
Please
comment
safe
ignore_ties
Comment
bit
confusing
clear
X_sparse
X_sparse_mix
'X_sparse
key
lines
best
thing
X_sparse
CSC
Please
red
blue
colormap
matplotlib
such
white
sparsity
filters
uncomment
print
__doc__
import
print_outlier_ratio
description
top
file
suggestion
DeprecationWarning
ValueError
NEP
https
//numpy.org/neps/nep-0034-infer-dtype-is-object.html
suggestion
DeprecationWarning
ValueError
NEP
https
//numpy.org/neps/nep-0034-infer-dtype-is-object.html
full
name
RFECV
API
more
suggestion
min_features_to_select
Minimum
number
features
suggestion
scoring='accuracy
min_features_to_select
same
thing
best_score_idx
=
np.argmax
cv_results
[
]
=
cv_results
]
[
best_score_idx
]
cv_results
]
[
best_score_idx
]
candidate_idx
=
np.flatnonzero
cv_results
[
]
>
=
threshold
code
little
bit
comment
good
something
less
verbose
such
contiguous
matrix
sub_covariance
equal
[
indices
=
idx
]
.T
[
=
idx
]
column
line
idx
suggestion
samples
suggestion
corresponding
sample
np.reciprocal
np.square
possible
X
hmm
unstack
duplicated
indices
Which
code
comment
incorrect
grid
values
correspond
highest
iter
max
mean_test_score
iter
pandas
weak
tips
jnothman
sure
refactor
python
res
pd.pivot_table
pd.DataFrame
grid.cv_results_
index='param_alpha
kinda
same
thing
confusion
matrix
plot
@
thomasjpfan
grid-search
visualizer
nice
added
default
ones
cv=5
reason
ratio=2
ratio=3
common
choice
implementation
multimetric
Side
note
fit_params
sample-aligned
third-party
estimators
current
convention
next
line
code
order
candidate_params
deterministic
comfortable
randomised
procedure
determinism
top
wishlist
Python
>
dict
ordering
order
suggestion
dict
set
deterministic
iteration
order
candidate_params
tuple
None
d
candidate_params
justified
order
references
docstring
complications
UG
https
//github.com/scikit-learn/scikit-learn/pull/17159/files
r463969726
suggestion
n_possible_iterations
number
iterations
same
tests
param_grid
Aggressive
elimination
>
relevant
cases
enough
resources
candidates
most
ratio
last
iteration
number
candidates
useful
single
candidate
final
iteration
candidates
last
round
default
True
https
//github.com/scikit-learn/scikit-learn/pull/13900/files
issuecomment-533552358
best
comment
line
verbose=True
comment
black
instnace
suggestion
_uniques
details
X_csc
=
X_csr.tocsc
benchmark
comment
minute
suggestion
libraries
performances
care
suggestion
entry
file
need
multiple
imports
different
>
similar
end
X_full
=
X_full
[
:10
>
X_full
=
X_full
[
:10
array
dtype
object
arrays
explicit
docstring
enough
docstrings
comments
comments
test
suggestion
check
classification
metrics
message
occurrence
non-finite
values
target
vectors
use
plot
API
feature
matplotlib
figures
suggestion
data
training
predicting
post-fit
fit
necessary
trees
data
Use
comment
docstring
nose
hides
function
name
docstring
comment
suggestion
triple
cote
test
name
function
pytest
suggestion
check
precomputed
distances
NearestNeighbors.radius_neighbors
non-regression
test
https
//github.com/scikit-learn/scikit-learn/issues/16036
Thanks
accuracy
bit
misplaced
example
laptop
easier
Test
accuracy
=
x
title
line
break
matrices
gradient
unraveled
gradient
better
sure
for-loop
vectorized
computations
slow
total
nitpick
free
inlined
function
definition
same
comment
right
below
Yes
better
thanks
Same
comment
function-local
RNG
reproducibility
test
thanks
comments
bit
ESL
deviance
-loglike
=
factor
book
logaddexp
readability
use
pred
z
*
confused
expression
ESL
deviance
=
log
+
exp
-2
*
z
*
new
changes
*
log
+
exp
-z
*
alt_dev
stick
definition
book
note
minutes
head
minus
sign
facepalm
sphinx-gallery
separators
line
continuous
longer
chars
block
Sphinx-gallery
html
rendering
Jupyter
point
epsilon
values
e.g
python
mst.data
[
mst.data
==
]
=
concerns
epsilon
approach
overall
example
case
smallest
value
array
factor
smallest
representable
value
epsilon
value
smallest
representable
positive
value
=
np.nextafter
dtype='float64
certain
dtype
problematic
case
array
value
enough
case
interest
C
extensions
mypy
type
errors
module
Generally
decorators
properties
mypy
Errors
message
module
HistGradientBoostingRegressor
experimental
module
maintainer.rst
error
negative
suggestion
pcr
=
make_pipeline
StandardScaler
PCA
n_components=1
LinearRegression
https
//scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html
plots
conclusions
components
factitious
target
feature
info
features
coordinate
system
features
point
cloud
X
result
PCA
decomposition
component
component
way
mistake
supervised/unsupervised
behavior
explicit
Compare
cross
decomposition
methods
example
suggestion
second
component
i.e
direction
lowest
variance
suggestion
unsupervised
transformation
results
data
low
suggestion
target
cases
data
regressors
bit
redundant
introduction
dedicated
section
assert_less
permissive
case
warrants
comment
particular
random
seed
toy
data
number
decimals
impurity
greater
provided
value
more
explicit
X
=
scaler
=
MinMaxScaler
clip=True
default
params
feature_range=
=
scaler.fit
X
X_min
=
np.min
X
axis=0
=
np.max
X
axis=0
X_test
=
[
np.r_
[
X_min
[
:2
]
X_max
]
]
]
X_transformed
=
X_scaled.transform
X_test
assert_allclose
[
[
]
]
suggestion
test
behaviour
parameter
MinMaxScaler
suggestion
scaler
=
MinMaxScaler
feature_range=feature_range
clip=True
.fit
X
suggestion
test
parameter
'clip
MinMaxScaler
Please
assertion
assert_raises
KNN
regressor
e.g.
RidgeCV
KNN
bad
regressor
task
users
good
estimators
all_estimators
ambiguous
short
comment
clear
documentation
good
first
column
default
option
mlxtend
features
default
e.g.
OneHotEncoder
linear
models
first
column
useful
tree-based
models
first
columns
useful
equivalent
first
meth
None
lists
predict_method
estimators_
self.predict_method_
=
[
meth
est
zip
self.predict_method_
estimators_
est
None
'drop
behavior
sense
cv.random_state
=
None
case
separate
random_state
parameter
note
check_cv
int
KFold
instantiations
user
own
random_state
CV
instance
global
RandomState
>
Hmm
differs
ColumnTransformmer
list
fitted
transformers
'drop
estimator
mutable
mutable
default
parameter
docstring
more
explicit
None
LinearRegression
suggestion
Fit
estimators
redundant
line
support
None
suggestion
est
est
estimators_
suggestion
Stack
estimators
final
classifier
suggestion
parameters
stacking
estimator
other
comments
random_state
param
test
comment
FIXME
true
use
check_estimator
sklearn
need
predict_method
X
parametrization
same
regressor
test
please
test
empty
list
hand-calculated
comment
numbers
something
gbc
=
GradientBoostingClassifier
learning_rate=0.1
max_depth=3
random_state=42
gbr
=
assert
gbc.fit
X_train
y_train
assert
gbr.fit
X_train
y_train
est
tol
early_stop_n_estimators
[
gbc
1e-1
gbr
1e-1
]
est.set_params
tol=tol
n_iter_no_change=10
est.fit
X_train
y_train
comment
searchsorted
c_start
argmin
D
X
y
file
tests
global
X
y
Sure
pytest.raises
message
Use
match
suggestion
consistency
bounds
tree
grower
node
bounds
predictor
tree
consistency
checks
values
node
children
leaves
grower
tree
predictor
tree
checks
predictor
tree
latter
former
predictor
=
grower.make_predictor
assert_children_values_monotonic
predictor
monotonic_cst
grower
monotonic_cst
assert_leaves_values_monotonic
predictor
monotonic_cst
depth
first
order
important
helper
explicit
function
name
suggestion
def
recursively_check_children_node_values
node
node.is_leaf
return
node
grower.root
node
node.parent.left_child
sibling
=
right
middle
=
node.value
+
sibling.value
MonotonicConstraint.POS
assert
node.left_child.value
<
=
node.right_child.value
<
=
middle
assert
middle
<
=
<
=
sibling.right_child.value
NEG
assert
node.left_child.value
>
=
node.right_child.value
>
=
middle
assert
middle
>
=
>
=
sibling.right_child.value
recursively_check_children_node_values
node.left_child
recursively_check_children_node_values
node.right_child
recursively_check_children_node_values
grower.root
assert_children_values_bounded
checks
bounds
available
grower
tree
predictor
good
grower
consistency
grower
node
predictor
node
super
assert_children_values_monotonic
assert_leaves_values_monotonic
grower
tree
bit
overkill
unlikely
randomly
assertion
sure
constraint
NO_CST
test
property
Same
answer
Note
reviewers
start
Can
check
output
fit_transform
dtype=np.float32
dtype=np.float64
same
comment
TODO
check
redundant
common
checks
Thanks
suggestion
Edge
case
single
feature
initial
suggestion
imputing
strategy
data
present
https
//github.com/scikit-learn/scikit-learn/issues/14383
suggestion
impute
initial
strategy
assert_allclose
X_test_est
[
]
np.mean
X_train
[
]
Side
comment
worth
numpy_provides_div0_warning
module
sklearn.utils
re-used
case
Essentially
platform
compatibility
flag
line
other
fixes
sklearn/utils/fixes.py
Better
ideal
try-except
block
error
message
rule
suggestion
Next
dataset
%
training
rest
comment
much
value
global
warnings.filters
warnings.catch_warnings
context
manager
warwnings.resetwarnings
warning.simplefilter
warnings.filterwarnings
py
warnings.catch_warnings
warnings.simplefilter
filters_orig
=
warnings.filters
]
assert_equal
assert_warns
UserWarning
f
assert_equal
warnings.filters
filters_orig
something
warnings.filters
assert_warns
comment
REALLY
necessary
comment
class
please
warnings
module
deprecation
warning
module
spare
blank
lines
warning
..
import
test
function
Please
line
file
suggestion
imbalanced
version
breast
cancer
dataset
suggestion
make_column_selector
dtype_include=np.number
rating
suggestion
OneHotEncoder
make_column_selector
dtype_include=object
city
values
suggestion
>
>
>
y
=
[
]
suggestion
voting
regressor
percentile
needs
scalar
column
vector
input
responsibility
caller
percentile
kind
automatic
squeezing
other
aggregation
axis
Scientific
Python
_weighted_percentile
output
comment
bit
obscure
test
lines
test_weighted_percentile_2d
X
=
sw
=
value
_weighted_percentile
X
sw
assert
_weighted_percentile
X
[
]
sw
update
comment
_yield_all_checks
check_sample_weight
estimators
green
status
check
great
much
noise
-1/3
formula
monotone
transformation
move
comment
L439
limits
ties
comment
previous
line
+1
thought
test
case
Thx
Did
following
suggestion
example
CI
time
constraints
own
test
whole
test
skip
pandas
moment
different
values
C
Comment
value
variable
fit_transform_one_cached
commit
solution
warm_start
transformer
warm_start
attribute
equal
user
warm_start
discarded
cache
user
cache
transformer
Important
thing
*
*
transformer
warm_start
attribute
*
*
comment
@
lesteve
@
ogrisel
+1
comment
compat
Bonus
points
comment
Comment
rot
transf
means_
attribute
W
original
instances
constructor
general
behavior
scikit-learn
@
jnothman
comment
Comment
rot
@
jnothman
suggestion
backslash
backslash
backslash
redundant
brackets
multiclass
multiple
comment
reader
decision_function_shape='ovr
default
logic
current
isinstance
getattr
classifier
'ovr
'ovr
tests
good
idea
test
test_estimator_checks
different
cases
new
tests
i.e
sure
appropriate
messages
estimator
bad
library
code
coverage
good
cases
condition
assert
suggestion
>
>
>
disp1
=
plot_partial_dependence
est
X
doctest
+SKIP
scores
number
samples
plot
further
code
first
samples
plot
much
explicit
comment
clear
rename
n_1
train
n_2
\mathrm
test
suggestion
suggestion
example
difference
%
accuracy
suggestion
good
first
model
suggestion
class
~sklearn.model_selection.GridSearchCV
case
statistical
posterior
distribution
suggested
wording
mu
sure
addition
case
necessary
suggestion
%
%
Region
Practical
Equivalence
more
structure
help
reading
opinion
case
same
normal
distribution
equivalent
credible
interval
highest
posterior
density
interval
https
//easystats.github.io/bayestestR/articles/credible_interval.html
example
class
suggestion
paired
t-test
p-value
Diebold-Mariano
test
forecast
literature
Many
variants
t-test
discussion
https
//github.com/scikit-learn/scikit-learn/pull/17432
discussion_r479447919
suggestion
same
criteria
frequentist
approach
probability
suggestion
estimated
quantity
case
mean
difference
table
different
story
same
rounding
'which
black
style
spaces
closing
parenthesis
bracket
mean
s
differences
observed
mean
differences
bit
strange
multiple
mean
differences
multiple
multiple
differences
account
*
empirical
mean
difference
suggestion
Many
variants
such
t-test
suggestion
columns=
[
'interval
'lower
value
value
]
variance
differences
variance
observed
differences
sample
population
p-values
<
hmm
rbf-linear
p-value
table
nitpick
'Region
Practical
Equivalence
suggestion
Bonferroni
output
p-values
higher
p_val
p_val
p_val
problem
Just
wondering
random
variable
*
mean
*
i.e
expectation
differences
differences
description
rest
text
former
unrelated
mu
>
Bayesian
estimation
output
distribution
distribution
mean
math
differences
performance
models
average
diff
diff
mu
other
letter
suggestion
Several
methods
correlation
suggestion
models
such
]
_
link
paper
non-paywall
possible
great
e.g.
..
]
Dietterich
T.
G.
Approximate
statistical
tests
classification
algorithms
<
http
//citeseerx.ist.psu.edu/viewdoc/download
doi=10.1.1.37.3325
rep=rep1
type=pdf
>
Neural
computation
things
i.e
high
variability
folds
shared
variance
models
score
vectors
test-sets
suggestion
math
train
number
observations
training
understanding
topic
response
comment
@
glemaitre
Frequentist
Normal
derive
personal
nouns
case
suggestion
estimation
difference
credible
intervals
probability
range
values
estimated
quantity
case
mean
difference
performance
example
%
credible
interval
[
x
y
]
%
probability
true
mean
difference
performance
models
x
y
quintessence
sentence
boldface
nice
differences
significant
random
right-tailed
t-test
null
hypothesis
model
performs
least
good
model
correct
null
hypothesis
docstrings
response
@
glemaitre
comment
[
]
https
//github.com/scikit-learn/scikit-learn/pull/17432
discussion_r440721828
strong
preference
easier
strong
preference
happy
comma
unnecessary
case
empty
line
end
pep8
//www.flake8rules.com/rules/W391.html
strange
comment
Basically
point
casting
issue
A
small
comment
good
future
developers
suggestion
FIXME
Remove
'legacy
support
suggestion
>
>
>
avoids
test
train
transformation
features
left
plot
entire
dataset
right
....
Amazing
work
guys
@
glemaitre
@
raghavrv
@
tguillemot
@
ogrisel
few
comments
beautiful
comments
dist_class
better
output_distribution
explanatory
comment
comment
such
random
yield
unique
approximation
linspace
CDF
methodology
comment
code
self-explanatory
someone
test
year
time
confused
test
Please
comment
CamelCase
var
names
>
br
br_model
same
rrModel
coef_
yeo
dosctest
comments
code
self
explanatory
try
string
numerical
column
safe
side
test
>
fit
while
accept_sparse=True
comment
support
suggestion
check
sample_weight
invocations
fit
anything
fit
method
attribute
suggestion
def
_check_colorbar
disp
has_colorbar
has_colorbar
assert
disp.im_.colorbar
None
assert
disp.im_.colorbar.__class__.__name__
Colorbar
assert
disp.im_.colorbar
None
disp
=
plot_confusion_matrix
fitted_clf
X
y
colorbar=colorbar
_check_colorbar
disp
colorbar
plot
opposite
effect
colorbar
disp.plot
colorbar=not
colorbar
_check_colorbar
disp
colorbar
change
necessary
tests
belongs
SKLEARN_OPENMP_SUPPORTED
check_openmp.pyx
error
bit
comment
disable
openMP
tests
case
test_configure
test
addresses
specific
use-case
clear
explanation
while
something
free
attempt
>
test
setup.py
check_openmp_support
C
file
SKLEARN_NO_OPENMP
users
tests
build-support
openmp
particular
mac
users
env
variables
openmp
test
time
SKLEARN_NO_OPENMP
tests
Please
force_all_finite=True
pd.NA
test
variant
dtype=
[
np.float32
np.float64
]
==
np.float32
comment
relevant
warnings
comment
thanks
dense_ridge
suggestion
[
Non
Regression
Test
issue
]
value
test
set
error
test_iterative_imputation_missing_value_in_test_array
test_simple_imputation_missing_value_in_test_array
pytest
@
pytest.mark.parametrize
'Imputer
SimpleImputer
IterativeImputer
def
test_imputation_missing_value_in_test_array
Imputer
[
Non
Regression
Test
]
value
test
set
error
finite
dataset
train
=
[
]
]
]
test
=
[
]
[
]
]
imputer
=
Imputer
add_indicator=True
imputer.fit
train
.transform
test
suggestion
display
computed
values
metrics
visualizations
matplotlib
API
following
example
displays
other
row
suggestion
decision
function
roc
curve
suggestion
dataset
predictions
confusion
matrix
class
comment
remove_config_comments
comment
generated
example
suggestion
classification
problem
target
individual
blood
sure
suggestion
Create
class
suggestion
roc
curve
probabilities
non-thresholded
suggestion
type
np.float64
Comment
ConvergenceWarning
IterativeImputer
suggestion
def
test_heterogeneous_ensemble_support_missing_values
Ensemble
Estimator
X
y
Voting
Stacking
predictor
values
validation
underlying
estimator
suggestion
test
pipeline
MultioutputEstimators
validation
values
underlying
pipeline
regressor
classifier
suggestion
FIXME
test
estimator_checks
able
meta-estimator
instances
def
test_support_missing_values
MultiOutputEstimator
Estimator
sum
dists
unchanged
sure
user
input
small
comment
classes
outputs
particular
case
object
np.object
functions
comment
data
type
helpful
tuple
typical
use
case
array-like
data
type
hasattr
cleaner
self.n_features_in_
fitted_n_features_in
suggestion
n_features_in_
Skip
check
expected
number
input
features
fit
case
stateless
transformers
good
idea
good
learning
experience
code
pipeline
scaled_clf
=
make_pipeline
StandardScaler
PCA
n_components=2
GaussianNB
unscaled_clf
=
make_pipeline
PCA
n_components=2
GaussianNB
line
long
>
characters
comment
Use
random_state
anything
e.g
determinism
extreme
situation
common
situation
comment
edge
case
py
all_lists
v
rvs
v
space.values
space
self.param_distributions
comment
name
function
sure
comment
suggestion
use
values
present
comment
function
comparison
clearer
subplots
same
y-axis
py
fig
axes
plt.subplots
nrows=2
sharey=True
figsize=
plt.sca
axes
]
plt.sca
axes
]
favour
something
non-linear
failure
linear
model
e.g
=
np.sin
X
rnd.normal
X
[
figure_1
]
https
//user-images.githubusercontent.com/11065596/33174918-3467ee3e-d05a-11e7-8750-457b81ec2e2e.png
note
docstring
better
BaseLoss
places
comment
readability/maintenance
pval
means
test
hypothesis
sample
uniform
distribution
independent
tests
different
values
orig_range
use
pytest.mark.parametrize
suggestion
_MAX_INT
@
pytest.mark.parametrize
orig_range
[
_MAX_INT
]
def
test_bounded_rand_int
orig_range
n_pts
n_iter
ks_pvals
=
[
]
uniform_dist
=
stats.uniform
loc=0
scale=orig_range
avg
multiple
tests
chance
outlier
result
negligible
_
range
n_iter
Deterministic
random
sample
=
[
bounded_rand_int_wrap
orig_range
_
range
n_pts
res
stats.kstest
sample
uniform_dist.cdf
ks_pvals.append
res.pvalue
avg_pval
=
np.mean
ks_pvals
avg_pval
>
\
p-value
>
distribution
isn\'t
uniform'.format
avg_pval
suggestion
safety
belt
check
%
p-values
previous
comment
review
p-vals
uniformity
test
comment
suggestion
null
hypothesis
p-values
counter-intuitive
multiple
refs
checks
check
uniformity
p-values
uniform_p_vals_dist
=
stats.uniform
loc=0
scale=1
res_pvals
stats.kstest
ks_pvals
uniform_p_vals_dist.cdf
assert
res_pvals.pvalue
>
safety
belt
check
most
p-values
min_10pct_pval
=
np.percentile
ks_pvals
q=10
lower
quantile
pvalue
<
=
means
test
null
hypothesis
sample
uniform
distribution
assert
min_10pct_pval
>
\
quantile
p-value
>
distribution
isn\'t
uniform'\
.format
min_10pct_pval
suggestion
..
note
practice
column
data
type
suggestion
category
columns
data
fetch_openml
suggestion
columns
category
suggestion
numerical
categorical
feature
suggestion
cleaned
dataset
preprocessing
automatic
suggestion
First
only
select
subset
columns
error
message
assert_raise_message
outfile=
none
StringIO
suggestion
>
>
>
sub_pipeline
doctest
+ELLIPSIS
+NORMALIZE_WHITESPACE
suggestion
>
>
>
Indexing
sub-pipeline
suggestion
Pipeline
memory=None
steps=
[
'anova
]
comment
suggestion
A
check
comment
case
multiple
initial
rows
index
[
np.argmin
masked_indptr
]
other
way
X_mask
X.indptr
]
]
np.concatenate
[
X_mask
[
X.indptr
]
]
intuitive
latter
bit
efficient
comparison
DBSCAN
complexity
overall
Please
test
bug
fix
entry
whats_new.rst
Thanks
suggestion
form
data
perturbation
issue
question
other
recurrences
stability
words
coefficients
[
comment
]
https
//github.com/scikit-learn/scikit-learn/pull/15706
discussion_r353219620
truth
Thanks
suggestion
outcome
model
sure
better
suggestion
models
effects
teased
suggestion
chose
little
additional
addition
non-regression
test
inline
comment
link
upstream
issue
numpy
https
//github.com/numpy/numpy/issues/14685
need
line
small
comment
e.g
sure
quantiles
quick
comment
np.maximum.accumulate
self.quantiles_
issue
readable
np.minimum
satisfying
output
issue
first
time
own
data
more
investigation
consistent
np.maximum
way
better
choice
readability
reason
comment
suggestion
minimum
zero
newton
method
<
y_true
annotations
arrays
single
element
Newton
comment
enough
suggestion
Need
arrays
assert_allclose
dimensions
y_true.ravel
case
redundant
Could
small
positive
float
e.g
number
output
features
atol
cf
https
//github.com/scikit-learn/scikit-learn/pull/14178
issuecomment-505182824
https
//www.python.org/dev/peps/pep-0485/
absolute-tolerance-default
space
comma
informative
Thanks
rid
whole
test
sure
jnothman
thinks
@
jnothman
Sorry
delay
@
amueller
test
negation
negation
test
below
issue
places
other
error
options
change
PR
other
diff
respect
PR
diff
git
a/sklearn/tests/test_grid_search.py
b/sklearn/tests/test_grid_search.py
index
a/sklearn/tests/test_grid_search.py
+++
b/sklearn/tests/test_grid_search.py
@
@
-217,6
+217,20
@
@
def
test_grid_search_score_method
scoring='roc_auc
.fit
X
y
search_auc
=
GridSearchCV
clf
grid
scoring='roc_auc
.fit
X
y
Check
situation
+
estimator
score
method
parameter
+
=
assert_no_warnings
search_no_scoring.score
X
y
score_accuracy
=
assert_no_warnings
ChangedBehaviorWarning
+
search_accuracy.score
X
y
score_no_score_auc
=
assert_no_warnings
search_no_score_method_auc.score
+
X
y
score_auc
=
assert_no_warnings
ChangedBehaviorWarning
+
search_auc.score
X
y
+
test
sane
+
assert_true
score_auc
>
+
assert_true
score_accuracy
assert_not_equal
score_auc
score_accuracy
@
jnothman
code
good
@
Sentient07
comment
line
test
jnothman
test
part
error
comment
tests
Failure
message
======================================================================
FAIL
sklearn.tests.test_grid_search.test_grid_search_score_method
Traceback
recent
call
last
/Users/Ramana/projects/macvnev/lib/python2.7/site-packages/nose/case.py
line
runTest
self.test
*
self.arg
/Users/Ramana/projects/scikit-learn/sklearn/tests/test_grid_search.py
line
test_grid_search_score_method
search_accuracy.score
X
y
/Users/Ramana/projects/scikit-learn/sklearn/utils/testing.py
line
assert_warns
%
func.__name__
AssertionError
warning
score
tests
FAILED
failures=1
comments
instance
case
practise
error
message
pytest.raises
ValueError
match=
err_msg
partial
error
messgae
min_value
shape
more
test
self
explenatory
need
comment
regression
better
check
scalar
array-like
works
values
parameters
test
reason
comment
parameter
ids
different
try
easier
tests
@
pytest.mark.parametrize
min_value
max_value
correct_output
scalars
list
None-default
inf
]
inf
dtype
array
comparison
assert_array_equal
case
None
array
different
assert
statement
Could
inline
comment
line
SGDClassifier
uses
loss='hinge
default
probabilistic
loss
function
predict_proba
method.
comment
clearer
previous
statement
regr.set_params
check_inverse=False
isinstance
transformer
StandardScaler
>
Y
clf
please
comment
obvious
predictor
X
list
Thanks
same
hard
similar
different
tests
sure
random_state=i
replicable
nice
expected
performance
results
comment
suggestion
digit
image
title
plots
suggestion
n_samples
number
images
n_features
total
number
suggestion
Note
image
files
e.g.
files
suggestion
2-D
array
grayscale
values
shape
vector
shape
suggestion
training
data
train/val
split
defined
API
docstring
reference
issue
IMO
sure
whole
test
relevant
Python
Windows
bit
isinstance
x.shape
]
int
False
sparse
arrays
np.int
reason
>
>
>
isinstance
np.int
int
False
classification
tests
comment
def
true_results
list
array
copy
super
explicit
explicit
copy
y
true_results
comment
suggestion
Test
sum
y
=0
y_pred=0
nodes
dataset
comment
enforced
Nit
concise
self.encode
'ordinal
return
Xt
one-hot
encode
features
=
np.ones
X.shape
]
dtype=bool
self.ignored_features
None
mask
[
]
=
False
encode_sparse
=
self.encode
==
'onehot
return
OneHotEncoder
n_values=np.array
self.n_bins_
mask
]
categorical_features='all'
self.ignored_features
None
mask
sparse=encode_sparse
.fit_transform
Xt
Nit
convention
file
comments
Currently
comment
Better
test
overloaded
term
CS
ML
contexts
suggestion
%
%
entire
file
[
]
Use
Pipeline
clear
suggestion
https
//www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html
sure
suggestion
%
%
same
steps
paper
normalization
implies
min-max
scaling
]
normalization
sample
unit
length
f-string
+1
suggestion
]
Pham
Ninh
Rasmus
Pagh
Fast
scalable
polynomial
kernels
explicit
feature
maps
KDD
'13
https
//doi.org/10.1145/2487575.2487591
favor
visual
plot
example
accuracy
example
accuracy
versus
time
plot
dot
model
something
degree
example
degree
~
output
features
n_components
suggestion
performance
kernel
course
time
SVC
class
poor
scalability
example
minutes
rule
examples
scikit-learn
bottleneck
SVC
number
samples
number
samples
much
computational
time
example
meaningful
say
samples
C=500
default
LinearSVC
matplotlib
object
API
easier
individual
figures
//matplotlib.org/3.3.0/api/index.html
usage-patterns
parametrization
suggestion
fig
ax
plt.subplots
figsize=
ax.scatter
[
results
LSVM
]
time
]
]
[
results
LSVM
]
score
]
]
label=
Linear
SVM
c=
green
^
ax.scatter
[
results
LSVM
+
PS
[
time
]
]
[
results
LSVM
+
PS
[
score
]
]
label=
Linear
SVM
+
PolynomialSampler
c=
blue
n_components
[
]
define
N_COMPONENTS
ax.scatter
[
results
f
LSVM
+
PS
n_components
[
time
]
]
[
results
f
LSVM
+
PS
n_components
[
score
]
]
c=
blue
ax.annotate
f
n_components
results
f
LSVM
+
PS
n_components
[
time
]
results
f
LSVM
+
PS
n_components
[
score
]
xytext=
-30
textcoords=
offset
pixels
ax.scatter
[
results
KSVM
]
time
]
]
[
results
KSVM
]
score
]
]
label=
Kernel
SVM
c=
red
x
ax.set_xlabel
Training
time
ax.set_ylabel
Accurary
%
plt.show
[
]
Described
bit
reason
[
Y
==
]
results
original
Tensor
Sketch
paper
]
[
binary
version
Covertype
dataset
]
https
//www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html
standard
6-classes
version
paper
dataset
]
>
7-class
classification
problem
binary
classification
problem
goal
separate
class
other
classes
bit
paper
archeology
man_scientist
[
]
Pham
N.
Pagh
R.
August
Fast
scalable
polynomial
kernels
explicit
feature
maps
Proceedings
ACM
SIGKDD
international
conference
Knowledge
discovery
data
mining
pp
239-247
]
R.
Collobert
S.
Bengio
Y.
Bengio
A
parallel
mixture
SVMs
large
scale
problems
Neural
Computation
:1105-1114
New
block
separator
%
%
suggestion
%
%
first
unecessary
better
apologies
random_state
sure
best
person
refactoring
DBSCAN
tests
best
separate
issue
strong
test
p=2
default
minkowski
nearest
neighbors
implementation
p=1
demonstrative
random
state
labels
deterministic
only
difference
numerical
precision
errors
issue
complete
set
labels
identical
weak
assertion
odd
[
DBSCAN
implementation
]
http
//scikit-learn.org/stable/modules/clustering.html
dbscan
algorithm
non-deterministic
core
samples
same
clusters
labels
different
non-determinism
non-core
sample
belongs
non-core
sample
distance
lower
eps
core
samples
different
clusters
triangular
inequality
samples
distant
eps
other
same
cluster
non-core
sample
cluster
order
Other
ordering
dataset
algorithm
deterministic
results
stable
runs
same
data
algorithm
same
parameters
ways
cluster
run
non-core
samples
labels
dbscan
tests
DBSCAN
weak
least
test
core
samples
same
clusterings
cluster
labels
runs
Note
blurb
determinism
master
http
//scikit-learn.org/dev/modules/clustering.html
dbscan
sequence
conditions
initial
pattern
easier
solver
sag
sparse.issparse
X
has_sw
solver
cholesky
solver
sparse_cg
solvers
sample
weight
favor
has_sw
condition
comment
type
checking
_insert_error_scores
comment
paper
>
<
something
suggestion
X
=
self._check_non_neg_array
X
reset=first_time
reset_n_features
_check_non_neg_array
comment
>
theory
reset
equal
*
*
equal
comment
non_negative_factorization
call
_validate_data
performance
overhead
simplicity
sake
part
PR
kwarg
non_negative_factorization
input
validation
typo
backward
Please
code
necessary
issues
added
lines
code
reader
examples
Could
bit
SVD
approximation
X
X
@
V
same
U
@
Sigma
suggestion
pipeline
numerical
input
features
suggestion
test
partial
dependence
little
use
suggestion
default
hyperparameters
gradient
model
section
dividers
suggestion
%
%
suggestion
test
orthomax
anything
special
input
Please
comment
@
if_matplotlib
@
pytest.mark.parametrize
data
params
err_msg
[
multioutput_regression_data
[
]
target
None
[
]
target
multi-output
multioutput_regression_data
[
]
target
-1
[
]
\
[
]
multioutput_regression_data
[
]
target
'features
[
]
\
[
]
make_classification
random_state=0
'features
[
'foobar
]
None
feature_names
make_classification
random_state=0
'features
[
'foobar
]
[
]
feature_names
make_classification
random_state=0
'features
[
]
entry
features
int
make_classification
random_state=0
'features
[
]
entry
features
int
make_classification
random_state=0
'features
[
tuple
]
entry
features
int
make_classification
random_state=0
'features
[
]
[
]
'All
entries
features
less
make_classification
random_state=0
'features
[
]
[
b
]
'feature_names
duplicates
]
@
pytest.mark.filterwarnings
Default
solver
@
pytest.mark.filterwarnings
Default
multi_class
def
test_plot_partial_dependence_error
data
params
err_msg
X
y
=
data
estimator
=
LinearRegression
.fit
X
y
pytest.raises
ValueError
match=err_msg
plot_partial_dependence
estimator
X
*
*
params
close_fig
python
class
NoPredictProbaNoDecisionFunction
BaseEstimator
ClassifierMixin
def
fit
X
y
return
estimator
params
err_msg
[
KMeans
'features
[
]
'est
fitted
regressor
classifier
LinearRegression
'features
[
]
'predict_proba
response_method
parameter
regressors
GradientBoostingClassifier
random_state=0
'features
[
]
'predict_proba
'recursion
'recursion
method
response_method
'decision_function
GradientBoostingClassifier
random_state=0
'features
[
]
'predict_proba
'auto
'recursion
method
response_method
'decision_function
GradientBoostingClassifier
random_state=0
'features
[
]
'blahblah
'response_method
blahblah
invalid
response_method
NoPredictProbaNoDecisionFunction
'features
[
]
'auto
estimator
predict_proba
decision_function
method
NoPredictProbaNoDecisionFunction
'features
[
]
'predict_proba
estimator
predict_proba
method
NoPredictProbaNoDecisionFunction
'features
[
]
'decision_function
estimator
decision_function
method
LinearRegression
'features
[
]
'blahblah
invalid
method
names
brute
recursion
auto
LinearRegression
'features
[
]
'recursion
'est
instance
BaseGradientBoosting
recursion
]
def
test_partial_dependence_error
estimator
params
err_msg
X
y
=
make_classification
random_state=0
estimator.fit
X
y
pytest.raises
ValueError
match=err_msg
partial_dependence
estimator
X
*
*
params
@
pytest.mark.parametrize
'estimator
[
LinearRegression
GradientBoostingClassifier
random_state=0
]
@
pytest.mark.parametrize
'features
[
-1
]
def
test_partial_dependence_unknown_feature
estimator
features
X
y
=
make_classification
random_state=0
estimator.fit
X
y
err_msg
=
features
pytest.raises
ValueError
match=err_msg
partial_dependence
estimator
X
[
]
pytest.mark.parametrize
'estimator
[
LinearRegression
GradientBoostingClassifier
random_state=0
]
def
test_partial_dependence_unfitted_estimator
estimator
err_msg
=
parameter
fitted
estimator'
pytest.raises
ValueError
match=err_msg
partial_dependence
estimator
X
]
@
pytest.mark.parametrize
'estimator
[
LinearRegression
GradientBoostingClassifier
random_state=0
]
def
test_partial_dependence_X_list
estimator
array-like
objects
X
y
=
make_classification
random_state=0
estimator.fit
X
y
partial_dependence
estimator
list
X
]
more
context
e.g
meta-estimators
future
TODO
second
comment
function
is-
>
comment
yield
ambiguous
suggestion
>
>
>
transformer.transform
X
suggestion
FIXME
test
due
fact
GBRT
sample_weight
same
implementation
median
initialization
DummyRegressor
future
sure
implementations
same
PR
more
assert_allclose
pass
FIXME
issue
link
relevant
PR/issue
track
suggestion
FIXME
decimal=0
permissive
due
fact
GBRT
sample_weight
same
implementation
median
initialization
DummyRegressor
future
sure
implementations
same
Refer
//github.com/scikit-learn/scikit-learn/pull/17377
detailed
explanations
assert_array_almost_equal
decimal=0
comment
loop
helper
function
duplicated
code
test
same
case
plot
>
prepare
line
matplotlib
[
example
]
https
//113142-843222-gh.circle-artifacts.com/0/doc/auto_examples/model_selection/plot_det.html
sphx-glr-auto-examples-model-selection-plot-det-py
nice
warning
Thanks
comment
grown
tree
data
MSE
suggestion
current_count
+=
[
n_samples
suggestion
current_count
+=
leaf
suggestion
counts
samples
node
assert_raises_regexp
FWIW
rag
bag
error
messages
improvement
number
acceptable
ways
estimator
state
preferred
message
test
value
error
weird
example
sample
feature
test
behavior
fit_1d
checks
check_fit1d_1sample
check_fit1d_1feature
check_fit1d
ValueError
suggestion
First
dataset
samples
features
suggestion
deviation
equal
feature
standard
deviation
import
numpy
np
suggestion
Gaussian
outlier
samples
feature
standard
suggestion
deviation
equal
feature
standard
deviation
equal
Next
samples
suggestion
Below
MCD
MLE
covariance
estimators
data
print
suggestion
indices
memory
footprint
idx
=
shuffle
idx
random_state=self._random_state
suggestion
check
consistent
error
estimators
raw_predictions
comments
line
clear
random
state
score
attributes
descriptive
short
comment
sections
huge
if/else
easy
track
first
time
fit
warm
start
warm
start
first
time
fit
revert
comment
please
rid
small
helper
readability
k
v
k
init_params
k
part
*
*
return
True
suggestion
try
repr
nested
estimators
suggestion
Use
repr
last
resort
expensive
repr
v
=
repr
init_params
[
k
]
fit
pipeline
modification
style
need
y=
clf.fit
X
y
import
top
import
sklearn.utils
readonly
memory
buffer
style
X
enough
Please
exact
values
red
reduced
Xt
transformed
X
sort
thing
common
tests
red
reduced
Xt
transformed
X
Could
full
nested
lists
reshape
orientation
clearer
reader
pease
comment
bit
misleading
variable
metrics
additional
arguments
strange
metric
VALID_METRICS
[
]
May
column_or_1d
example
issues
DataConversionWarning
warning
users
situation
suggestion
Let
class
sklearn.ensemble.HistGradientBoostingRegressor
only
way
ipython
]
np.array
'abcdef
]
array
dtype=
<
U6
]
np.array
list
'abcdef
]
array
[
b
c
e
f
]
dtype=
<
U1
]
np.array
dtype=
<
U1
]
array
dtype=
<
U1
big
fan
numpy
TBH
nth
non-blank
character
string
start
end
pythonic
way
happy
alternative
solutions
number
lines
lots
lines
lots
non-blank
characters
number
non
blank
characters
number
lines
something
buggy
.join
repr_.split
N_CHAR_MAX
non-blank
chars
N_LINES
=
arbitrary
=
repr_.split
'\n
=
[
N_LINES
]
+
[
]
+
[
-N_LINES
]
repr_
=
'\n'.join
reasonable
hard
appropriate
value
N_LINES
number
non-blank
characters
equal
Nit
consistency
i.e
comments
suggestion
parameters
results
suggestion
loss
loss
function
least
squares
function
case
change
bp
code
suggestion
predictive
feature
bp
same
methods
strange
severity
data
readers
familiar
whole
dataset
original
paper
suggestion
Gradient
Boosting
possibility
trees
Poisson
lines
estimators
class
~sklearn.linear_model.Ridge
class
~sklearn.compose.TransformedTargetRegressor
suggestion
low
penalization
alpha
linear
model
under-fit
such
suggestion
integer
class
~sklearn.preprocessing.OrdinalEncoder
encoding
same
suggestion
simplistic
model
mean
accuracy
%
suggestion
samples
i.e
1e-12
order
Ridge
regressor
L2
penalty
term
suggestion
integer
class
preprocessing.OrdinalEncoder
encoding
trees
categorical
features
ordered
features
F401
noqa
suggestion
HistGradientBoostingRegressor
a-priori
sure
relevant
/
clear
previous
sentence
suggestion
random
variable
mode
histogram
left-most
value
normal
distribution
Ridge
suggestion
distribution
response
variable
Ridge
model
suggestion
calibration
discriminative
power
model
linear
squared
error
normal
distribution
assumption
variance
suggestion
func
~sklearn.preprocessing.PolynomialFeatures
suggestion
ideal
model
well-calibrated
discriminative
suggestion
Poisson
loss
log-link
problems
suggestion
assumption
ideal
relationship
value
suggestion
particular
risk
suggestion
dummy
regression
model
constant
frequency
model
nice
parametrized
test
suggestion
impurity-based
feature
importance
numerical
features
bit
display
sphinx-gallery
remove_config_comments
latest
release
needs
line
rendered
html
features
names
tick
labels
boxplot
following
rendered
png
file
https
//63335-843222-gh.circle-artifacts.com/0/doc/auto_examples/inspection/plot_permutation_importance.html
tree-s-feature-importance-from-mean-decrease-in-impurity-mdi
sure
matplotlib
good
layout
issue
suggestion
impurity-based
importances
training
statistics
suggestion
important
features
result
non-predictive
random_num
suggestion
tree
feature
importance
numerical
features
skip
line
list
suggestion
problem
limitations
impurity-based
feature
importances
suggestion
impurity-based
importances
towards
high
cardinality
features
openml
suggestion
Next
threshold
visual
inspection
dendrogram
group
features
clusters
>
none
features
important
contradiction
high
test
accuracy
feature
important
copy
df
Numpy
views
suggestion
hasattr
X
'iloc
pandas
last
column
suggestion
def
test_permutation_importance_correlated_feature_column_transformer
comment
closed
form
certain
last
one
correlated
feature
pandas
default
check_array
True
option
tests
usual
short
comment
test
future
suggestion
array.sparse
exists
sparsity
suggestion
dataframe
columns
sparse
sparse
array
part
message
class
instance
pytest.raises
TypeError
match=msg
@
NicolasHug
sufficient
check
value
try
return
int
float
qualities
'NumberOfInstances
]
KeyError
return
default_n_samples
raise
animal
column
one
size
indexing
test
good
first
comment
Regression
test
link
description
comment
RemoteFileMetadata
straightfoward
mapping
figshare
URLs
original
URLs
better
util
utils
comment
necessary
suggestion
adimensional
numbers
value
coefficients
able
lines
few
additional
comments
precision
float64
instance
@
GaelVaroquaux
@
ogrisel
suggestion
'n_classes
integer
greater
Got
.format
n_classes
comment
allow_unlabeled
classification
dataset
class
suggestion
n_classes
bad
practice
protected
method
_fit_and_score
required
warning
message
error_score
parameter
cross_val_score
cross_validate
public
functions
additional
parameter
great
parameter
trivial
purpose
TODO
marker
easier
suggestion
TODO
REMOVE
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
TODO
Revert
lines
v0.23
suggestion
non-normal
more
normal
performance
suggestion
imputer
=
KNNImputer
missing_values=np.nan
entries
suggestion
First
datasets
Diabetes
dataset
suggestion
imputer
=
SimpleImputer
missing_values=np.nan
strategy=
mean
suggestion
imputer
=
SimpleImputer
missing_values=np.nan
suggestion
fetch
first
entries
sake
suggestion
suggestion
def
get_impute_knn_score
suggestion
score
suggestion
round-robin
linear
regression
feature
values
function
other
features
turn
suggestion
suggestion
suggestion
paragraph
one
code
log
loss
values
header
suggestion
%
%
Data
forth
large
code
block
figure
paragraph
image
image
figure
suggestion
true
class
'green
point
green
vertex
results
fewer
over-confident
probabilities
same
suggestion
figure
vertex
simplex
improvement
sure
empty
string
right
actual
columns
worth
small
comment
top
explaining
alpha
models
is_classifier
model_normalize
classifier
elif
model_normalize._get_tags
.get
False
multitask
learner
same
comment
previous
test
Mark
TODO
PDP
support
SW
current
error
message
TypeError
max_error
unexpected
keyword
argument
'sample_weight
good
TODO
TODO
calls
suggestion
Check
radius_neighbors
_graph
]
output
sort_result
True
n_samples
suggestion
Ames
housing
dataset
scikit-learn
therefore
CI
https
//app.circleci.com/jobs/github/maikia/scikit-learn/43
end
paragraph
less
chars
function
def
_get_valid_samples_by_column
X
i
Get
samples
NaN
samples
column
i
return
[
i
]
[
~np.isnan
X_train
[
]
]
use
test_missing_value_handling_dense
function
comment
useful
line
surprising
array
statistics.fill
fill_value
statistics
unary
space
suggestion
coef
=
-1
*
idx
*
np.exp
-idx
/
comment
coef
lines
PR
coefs
alternated
signs
visualization
purpose
*
sample
weight
mysterious
deserves
comment
regression
test
comment
results
something
clear
work
rest
discussed
IRL
F1
ROC-AUC
point
point
parameters
refit='AUC
Score
estimator
whole
training
parameter
best
cross-validated
AUC
score
callable
sure
callable-like
built-in
scorer
plt.figure
figsize=
simpler
Wait
whole
dataset
plot
less
precision
recall
models
highest
precision
highest
recall
useful
Matthews
Correlation
Coefficient
metrics
different
curves
lines
plot
much
IMO
Rather
comment
sphinx-gallery
break
title
>
way
keys
same
scorer
names
better
Quirks
examples
poor
wording
choice
Score
bit
redundant
set
comment
Thx
Prefer
text
>
>
>
comment
Prefer
text
>
>
>
comment
combinations
@
pytest.mark.parametrize
ntype2
[
int32
]
def
test_check_pandas_sparse_invalid
ntype1
ntype2
pd
=
pytest.importskip
pandas
=
pd.DataFrame
pytest.raises
ValueError
check_array
df
pytest.mark.parametrize
ntype2
[
int
]
def
test_check_pandas_sparse_valid
ntype1
ntype2
sure
valid
combinations
expected
sparse
matrix
worth
check_X_y
suggestion
First
datasets
suggestion
performance
complexities
changes
estimator
suggestion
Note
newsgropus
dataset
sparse
matrix
X
suggestion
suggestion
estimator
round
estimator
new
value
suggestion
prediction
times
prediction
suggestion
Note
func
suggestion
complexity
complexity_computer
personal
preference
parameters
code
suggestion
newsgroups
dataset
ready-to-use
features
suggestion
Next
influence
parameters
suggestion
complexity_computer
suggestion
different
data
suggestion
changing_param
name
parameter
suggestion
Complexity
complexity_label
suggestion
parameters
estimators
suggestion
influence
parameters
suggestion
ready
functions
configurations
suggestion
influence
parameters
use
suggestion
Check
memory
layout
effect
result
dtype=np.float64
Could
docstring
_errors_and_values_
functions
such
consistent
nitpick
same
info
typo
column
*
*
*
*
ones
column
square
root
sample
weights
comments
self.fit_intercept
line
small
docstring
single
line
stating
case
n_samples
>
n_features
suggestion
decorator
deprecated
decorator
past
https
//github.com/scikit-learn/scikit-learn/pull/18114/files
diff-e907207584273858caf088b432e38d04L243-L247
>
support_multi_class
y_pred.shape
]
case
binary
y_pred
multi-class
case
ROC-AUC
backward
compatibility
sure
better
way
exact
encoding
case
suggestion
implicit
positive
class
binary
classifier
pos_label
predictions
suggestion
imbalanced
classification
task
unnecessary
comment
suggestion
msg
Attribute
n_classes_
suggestion
TODO
Remove
def
test_gbr_deprecated_attr
n_classes_
GradientBoostingRegressor
thing
term
monospace
terms
double
backticks
glossary
link
target
backticks
able
work
big
deal
code
controls
match
sure
doc
nice
suggestion
topics
X_test
Performance
metrics
pipeline
suggestion
'stats
text_stats_transformer
list
dicts
null
dataset
suggestion
rng
=
np.random.RandomState
X
=
rng.randn
suggestion
class
MyEstimator
DecisionTreeRegressor
estimator
indices
information
fit
comment
first
line
something
dataframe
normal
check_array
validation
X.shape
arrays
dataframes
attribute
comment
pandas
dataframe
validation
column
column
suggestion
pandas
dataframe
validation
column
column
order
dtype
information
encoders
suggestion
dataframe
normal
check_array
validation
comment
check
pandas
column
column
docstring
less
lines
sure
readability
X
'dtype
np.issubdtype
X_temp.dtype
\
@
jorisvandenbossche
thought
list
columns
cases
way
different
types
transform
variable
SelectPercentile
chi2
pipeline
comment
pipeline
suggestion
clf
=
Pipeline
[
'anova
transform
StandardScaler
SVC
gamma=
auto
]
data
feature
selection
better
IMO
plot
well.
[
figure_1
]
https
//user-images.githubusercontent.com/1663864/51790669-cc6dbc00-2198-11e9-97d3-54e743568e9b.png
Ah
sorry
regression
test
issue
*
correct
np.random.binomial
y
default
test
imbalanced
y
python
n_samples
rng
=
np.random.RandomState
X
=
rng.randn
n_samples
.reshape
y
=
rng.rand
n_samples
.astype
np.int32
test
other
classes
classifier
enough
others
nit
random
state
estimator
self.n_classes_
DecisionTreeClassifier
fit
short
possible
small
docstring
class
e.g
Toy
classifier
only
support
binary
classification
self.categories_
[
i
object
dtype
bit
system
numpy
dtypes
strings
object
array
sufficient
self.categories_
[
i
.dtype
suggestion
Check
RobustScaler
gauss_adjust=True
equivalent
StandardScaler
\
line
parentheses
x
=
y
line
data
dense
suggestion
regression
coefficients
OLS
NNLS
same
plot
suggestion
non-negative
constraint
shrinks
Non-Negative
Least
squares
sparse
results
train_test_split
good
practices
comment
suggestion
Test
differences
LinearRegression
Test
coeffs
different
regular
LR
positive=True
necessary
part
suggestion
predictors_of_ith_iteration
estimators
reason
comment
let
test
methods
e.g
py
sklearn.base
import
is_regressor
top
method_names
[
'predict
]
is_regressor
gb
[
'predict
'predict_proba
'decision_function
]
method
method
=
getattr
iter
staged_method
=
getatr
aux
'staged_
+
method_name
random_state
suggestion
test
staged
predictions
iteration
equal
corresponding
predictions
same
estimator
scratch
next
insteaad
fromiter
error
message
part
need
everything
suggestion
new_module_name
deprecated_path
correct_import_path
entire
file
Please
comment
underscored_filed
deprecated_path
correct_path
suggestion
_FILE_CONTENT_TEMPLATE
=
module
import
*
noqa
=
np.ones
X
same
easier
reference
original
issue
i.e
https
//github.com/scikit-learn/scikit-learn/issues/7501
Nitpick
backquotes
predict_proba
useful
suggestion
ensemble
able
name
p
mark
todo
parametrization
suggestion
pkg_resources
import
parse_version
type
ignore
suggestion
parse_version
=
LooseVersion
Looks
mypy
fact
parse_version
same
signature
cases
@
rth
mypy
googling
option
https
//dev.azure.com/scikit-learn/scikit-learn/_build/results
buildId=18541
view=logs
j=32e2e1bb-a28f-5b18-6cfc-3f01273f5609
t=8a54543f-0728-5134-6642-bedd98e03dd0
sklearn/utils/fixes.py:28
error
Incompatible
types
assignment
expression
Type
[
LooseVersion
]
variable
Callable
[
[
str
]
Tuple
[
str
crucial
ensure_2d=False
ensure_2d=True
reads
error
message
please
e.g
assert_raises_regex
binary
df
consists
predictions
clf_fitted.classes_
]
pos_class_indices
sure
clearer
Done
capitalization
other
comments
file
more
iterations
gain
first
more
iterations
gain
first
May
following
def
get_openmp_flag
compiler
'openmp
os.getenv
os.getenv
flags
user
environment
variable
particular
macOS
wheel
build
jobs
following
environment
variables
Apple
clang
brew
libomp
export
CC=
clang
-fopenmp
export
CFLAGS=
CFLAGS
-I/usr/local/opt/libomp/include
export
CXX=
clang++
-fopenmp
export
CXXFLAGS=
CXXFLAGS
-I/usr/local/opt/libomp/include
export
LDFLAGS=
LDFLAGS
-L/usr/local/opt/libomp/lib
-lomp
export
DYLD_LIBRARY_PATH=/usr/local/opt/libomp/lib
return
[
sys.platform
win32
'icc
compiler
'icl
compiler
return
]
sys.platform
==
win32
return
]
sys.platform
==
darwin
'icc
compiler
'icl
compiler
return
'-openmp
]
Default
flag
GCC
clang
return
'-fopenmp
]
non-regression
test
specific
bug
URL
issue
/
PR
Just
extra
explicit
suggestion
x
=
np.array
[
1e-16
1+1e-14
]
dtype=np.float64
test
unique
filtering
log
case
simple
expected
solution
>
>
>
sklearn.isotonic
import
IsotonicRegression
>
>
>
X
=
np.array
[
1+1e-16
]
dtype=np.float64
>
>
y
=
np.array
[
]
dtype=np.float64
>
>
ireg
=
IsotonicRegression
.fit
X
y
>
>
ireg.predict
[
]
array
[
]
second
third
samples
training
corresponding
y
values
>
>
>
ireg.X_thresholds_
array
[
]
>
>
ireg.y_thresholds_
array
[
]
docstring
description
possible
imputed_arr
[
]
[
missing_mask
]
=
comment
suggestion
=
X
[
feature_count
]
.copy
suggestion
n_features_original
=
X.shape
]
weird
ptr
pointers
col
column
need
comment
Iterate
X_1
X_4
loop
suggestion
@
pytest.mark.parametrize
missing_value
[
-1
]
suggestion
X_2_trans
imputer.transform
X_2
Note
fit
ComplementNB
norm=True
test
norm=False
way
kind
helper
maintenance
script
recent
feature
Python
such
pathlib
import
pathlib
tmpdir
=
pathlib.Path
tmpdir.name
setup_path
=
tmpdir
/
setup.py
sklearn_dir
=
pathlib.Path
sys.argv
]
=
sklearn_dir.glob
*
*
/
*
.pxd
print
Found
pxd
files
pxd_file
pxd_files
print
warnings
comment
deprecated
attributes
warning
assert
true
py
ignore_warnings
assert
hasattr
est
attr.name
assert_array_almost_equal
>
comment
comment
assert
statement
initial
choice
author
Mathieu
Blondel
Is
way
Basically
file
scratch
scaling
intuitive
previous
sklearn
versions
backwards
compatibility
reasons
IMO
harder
COULD
self.alphas_
=
self.alphas_
/
np.sqrt
self.lambdas_
fit
transform
older
versions
sklearn
logic
meaning
self.alphas_
sk-learn
versions
line
pretty
self
explanatory
comment
above
line
pretty
self
explanatory
comment
above
thank
helpful
test
comments
important
Nit
comments
docstrings
tests
suggestion
Make
sure
TSNE
different
square_distance
settings
part
comma
comment
threshold_
Small
comment
Make
sure
custom
mst_linkage_core
same
results
scipy
builtin
test
scikit-learn
users
PyPy
suggestion
OpenMP
scikit-learn
user
suggestion
build-time
variable
cythonize
call
comment
Will
CalledProcessError
return
code
non-zero
suggestion
test
environment
variable
whole
new
CI
job
lines
Kinda
sad
OK.
suggestion
Check
sklearn
OpenMP-based
parallelism
suggestion
specific
features
automatic
early-stopping
criterion
right
PoissonRegressor
section
easier
results
same
X
room
improvement
@
jnothman
@
adrinjalali
happy
suggestions
free
problem
slight
majority
zeros
generalized
linear
HGBRT
models
score
~0.3
seed
suggestion
positive
integer
target
X
[
]
many
zeros
y
=
rng.poisson
lam=np.exp
X
[
]
suggestion
compatible
sparse
matrices
estimator
OpenMP
few
many
nows
lorentzenchr
suggestions
compelling
example
minimal
same
poisson
loss
GBDTs
suggestion
pipelines
composite
estimators
Click
entries
transparency
monotonic
cst
example
own
Joel
suggestion
own
PRs
number
samples
large
plotted
samples
model
sufficient
individual
samples
plot
suggestion
n_samples
monotonic
constraints
separate
paragraph
sure
part
indicator
mask
missing_values
MissingIndicator
mask
parameter
MissingIndicator
.fit
X
missing_values
part
Sure
comment
location
X
Imputer
comment
better
above
docstring
function
Parameters
X
....
reconstruct_sparse
bool
default=False
Whether
sparse
matrix
True
....
assumptions
docstring
function
comment
easier
code
opposite
way
sparse.issparse
X
reconstruct_sparse
return
_fit_mask
X
value_to_mask
=
_fit_mask
X.data
value_to_mask
variable
name
great
Basically
Xt_sparse
presence
scalar
men
indexables
bit
surprising
suggestion
tolerance
scalar
values
fit_params
comment
state
abuse
scikit-learn
Estimator
API
parameters
data
dependent
sample_weights
case
abuse
common
popular
third
party
libraries
behavior
careful
support
proper
deprecation
cycle
nitpick/style
pythonic
duck
typing
free
original
version
reason
suggestion
elif
hasattr
MiniBatchKMeans
comment
e.g
warm
starting
same
seed
first
time
fit
e.g
train/val
split
>
svd_solver
variable
svd_solver
new
self._fit_method
serious
problem
comment
Handle
_fit_svd_solver
side
simple
array
fine
regression
test
bug
simpler
example
bug
import
np
sklearn.metrics.classification
import
matthews_corrcoef
n
=
int
arr
=
np.repeat
[
]
print
matthews_corrcoef
arr
multiclass
test
good
measure
=
np.repeat
[
]
print
matthews_corrcoef
arr
suggestion
Behavior
v0.21
function
v0.23
docstrings
checks
nose
@
pytest.mark.parametrize
[
np.float32
np.float64
]
def
test_mlp_param_dtypes
dtype
Checks
input
dtype
attributes
prediction
X
y
=
X_digits
[
:300
]
.astype
dtype
[
:300
]
mlp
=
MLPRegressor
alpha=1e-5
hidden_layer_sizes=
random_state=1
max_iter=50
mlp.fit
X
y
=
mlp_64.predict
X
pred.dtype
==
dtype
core_distance
<
=
max_eps
equivalent
np.inf
>
max_eps
self.core_distances_
[
]
<
=
self.max_eps
conditions
*
*
point
second
header
PR
<
img
width=
alt=
Screen
Shot
2020-05-26
PM
src=
https
//user-images.githubusercontent.com/5402633/82955319-9141ef80-9f7c-11ea-97dc-f79f6501d577.png
>
Master
<
img
width=
alt=
Screen
Shot
2020-05-26
PM
src=
https
//user-images.githubusercontent.com/5402633/82955345-a159cf00-9f7c-11ea-89b4-c859842b0fe7.png
>
Revert
header
header
original
correct
suggestion
shape
=
reason
scipy.sparse.rand
different
scipy
Well
large
test
solutions
vs
components
dense
vs
sparse
different
solvers
variance
correct
case
easy
parametrization
tests
suggestion
particular
class
model
OvO
OvR
support
expression
scores
ROC
AUC
scores
scores
sentence
output
clf.predict_proba
X
output
roc_auc_score
clf.predict_proba
X
multi_class='ovo
cases
multiclass
ROC
AUC
scores
probability
sample
belongs
particular
class
model.
comment
outlier
detection
interface
RandomSearchCV
suggestion
SearchCV
suggestion
non-regression
test
goals
assertions
assertions
understandable
new
coder
year
std
vector
tests
first
test
std
second
nonzero
small
comment
next
A
stronger
idea
first
assertion
value
first
component
needs
least
sure
top
head
Okay
comment
Should
NaNs
train
test
suggestion
group
samples
First
sample
Note
split
tests
splitting
conditions
suggestion
element
indicator
matrix
position
i
j
suggestion
arrays
children_left
[
i
id
left
child
node
i
leaf
node
children_right
[
i
id
right
child
node
i
leaf
node
feature
[
i
feature
node
i
threshold
[
i
threshold
value
node
i
n_node_samples
i
number
training
samples
node
i
impurity
[
i
impurity
node
i
kind
nit
[
]
node_id
current_depth
=
stack.pop
parent
depth
suggestion
sample
i
node
j
sample
i
suggestion
sample
i
node
j
sample
i
positions
suggestion
i-th
element
array
information
node
i
Node
suggestion
node
ids
position
array
suggestion
non
elements
row
i
indicator
matrix
ids
>
clear
*
thing
whole
test
place
comment
same
line
>
TODO
same
other
places
uncomment
@
agramfort
Thanks
perspective
test
necessary
original
definition
advise
plot_confusion_matrix
estimator
case
samples
test
comment
suggestion
check
FeatureHasher
error
random_state
integer
fit
comment
doc
import
PEP8
anything
actual
output
See
section
online
link
available
forward
other
docstrings
user
guide
Ideally
better
explanation
bit
cryptic
good
idea
scipy
PR
suggestion
func
~metrics.nan_euclidean_distances
nearest
suggestion
sample
values
mean
value
suggestion
default
euclidean
distance
metric
comment
line
single
line
standard
comment
let
comment
something
FIXME
check_array
return
check_array
X
y
dtype='int
force_all_finite=True
comment
testing
partial_fit
handling
unseen
categories
part
little
clearer
handling
unseen
categories
test
handle_unknown
works
error
warn
unseen
categories
probability
discussed
[
]
https
//github.com/scikit-learn/scikit-learn/pull/12569
issuecomment-446756130
reworked
partial_fit
tests
category
count
unseen
categories
something
rid
Current
example
strange
side
https
//27375-843222-gh.circle-artifacts.com/0/doc/modules/generated/sklearn.cluster.AgglomerativeClustering.html
try
doctest
+ELLIPSIS
possible
failures
other
platforms
careful
pep8
issues
print
please
use
doctest
+ELLIPSIS
floating
points
digits
level
precision
causes
headaches
platforms
i.e
>
bit
confused
sure
shape
X
affinity
==
thing
moment
error
message
X
square
comment
X
flat
comment
top
function
little
bit
details
Check
error
non
square
matrix
PR
suggestion
>
>
>
import
matplotlib.pyplot
plt
doctest
+SKIP
suggestion
>
>
>
plt.show
doctest
+SKIP
suggestion
>
>
>
plot_confusion_matrix
clf
X_test
y_test
doctest
+SKIP
use
set_params
outliers
test
iris.data
work
comment
branch
tol
>
comment
branch
tol
>
>
way
module
cache
warnings
next
time
answer
denial
phase
suggestion
TODO
noqas
examples
trouble
suggestion
>
>
>
clf.predict
[
[
]
]
odd
fail
example
fit
right
construction
class
clf
result
pprint
object
issue
something
_Dummy_
code
snippets
sensible
option
bad
idea
suggestion
partial
dependence
curves
single
feature
LSTAT
suggestion
curves
model
row
First
figure
axes
example
pretty
condensed
multiple
functionalities
hard
things
example
bit
first
grid
column
simple
plot
feature
curves
models
suggestion
curve
n_cols
suggestion
func
~sklearn.inspection.PartialDependenceDisplay.plot
function
list
suggestion
tree_disp.axes_
numpy
array
axes
suggestion
Next
partial
dependence
curves
features
LSTAT
RM
comment
example
natural
hgbr_disp
default
arguments
generated
axes
API
ravel
something
something
support
OrderedDict
suggestion
case
line_kw
nit
suggestion
leaf
nodes
accumulate_prediction
call
f
func
predict
strong
opinion
solution
isinstance
straight
aim
statement
solution
comment
statement
sake
clarity
clf.score
X
y
doctest
+ELLIPSIS
comment
code
please
line
suggestion
Test
small
eigenvalues
'mle
pathological
X
top
function
Comment
update
pyx
files
wrong
.pyx
files
time
suggest
pyx
files
wrong
super
nit
helper
pxd
files
possible
section
error
object
intent
test
least
comment
sections
test
need
apparent
comment
ovbious
comment
noqa
E501
service
environment
base
objects
TODO
mkurek
+1
good
docstring
TODO
mkurek
TODO
mkurek
better
*
fetch
not_patched_ids
filter
sec
scan
ids
ones
*
theoretically
transactions
more
db-friendly
less
queries
whats
important
less
modifications
updates
dir
built-in
function
move
samples_dir
method
case
sec
scan
vulnerabilities
one
deadline
today
deadline
today
is_patched
documentation
*
*
reverse_code
*
*
parameter
optional
entire
reverse_func
file
implementation
Done
ralph/admin/filters.py
comments
more
sense
variables
comments
variables
necessary
line
unreadable
undiffable
dict
constructor
keys
object
comparison
test_purchase_info_parse
function
part
rePi
values
handy
factory
functions
wink
redundant
comma
end
line
Impossible
period
Could
atomic
boolean
value
fist
glance
line
unreachable
line
dataclasses
compatibility
preference
dict
test
data
dict
constructor
same
data
declaration
syntax
little
syntactic
noise
code
end
test
bad
Default
values
test
code
strong
preference
case
free
use
append
long
list
Black
many
blank
lines
send
method
client
on_message
method
middle
send
waiter
queue
Same
comment
Same
question
assert
logic
https
//github.com/census-instrumentation/opencensus-python/blob/a6d6834974b4ebf273905e2d903f3f1c39cc8e4e/opencensus/common/utils/__init__.py
L29
Stackdriver
[
divmod
]
https
//docs.python.org/3/library/functions.html
divmod
lines
operation
successful
Azure
Monitor
span
runtime
exception
@
reyang
thoughts
order
TODO
suggestion
time
series
typo
memoru
>
memory
minor
comments
different
styles
good
consistent
style
lint
checks
maximum
characters
length
namespace
Azure
Monitor
certain
standard
metrics
StandardMetricsProducer
only
state
class
registry
registry
reason
class
class
def
get_available_memory
return
psutil.virtual_memory
.available
def
get_available_memory_metric
gauge
=
DerivedLongGauge
AVAILABLE_MEMORY
'Amount
available
memory
bytes
[
]
gauge.create_default_time_series
get_available_memory
class
AzureStandardMetricsProducer
MetricProducer
def
__init__
self.registry
Registry
self.registry.add_gauge
get_available_memory_metric
def
get_metrics
return
self.registry.get_metrics
producer
=
AzureStandardMetricsProducer
option
fine
separate
classes
metric
point
registry
metric
relation
mapping
top
file
DESCRIPTOR_VALUE
=
metric_descriptor.MetricDescriptorType.GAUGE_INT64
value.ValueLong
metric_descriptor.MetricDescriptorType.CUMULATIVE_INT64
value.ValueLong
check_type
=
DESCRIPTOR_VALUE.get
self.descriptor.type
check_type
None
raise
ValueError
Unknown
metric
descriptor
type
label_values
points
start_timestamp
exporter
ignorant
queue
sounds
right
solution
cleaner
emit
export
only
API
method
batch
size
configurable
option
exporter
package
attribute
exporter
class
@
c24t
@
songy23
thoughts
please
comment
inline
feedbacks
problem
multiple
exporters
multiple
workers
queue
item
same
time
others
queue
items
multiple
batch
sizes/export
intervals
value
constructor
course
sense
piece
comment
thanks
sure
good
idea
trace
execution_context
@
c24t
WDYT
Good
feedback
comments
purpose
chance
blob
lease
timeout
transmission
timeout
few
seconds
chance
blob
network
lease
blob
process
extra
cost
introduce
data
Nit
free
suggestion
@
mock.patch
'.AzureLogHandler.log_record_to_envelope
Same
thing
suggestion
mock.patch
'opencensus.ext.azure.log_exporter'
'.AzureLogHandler._transmit
transmit
exceptions
try
block
bugs
transactions
surprising
users
understanding
flask
test
async
transport
django
test
sync
transport
good
idea
comment
django
test
different
code
paths
‘
non-retryable
’
kwargs
look
whole
request
body
example
request
headers
data
ephemeral
and/or
passwords
future-proofing
'contextvars
form
monkey-patch
contextvars
gevent
endpoint
Do
canonicalization
logic
helpful
decision
flow
valid
connection
string
https
//github.com/microsoft/ApplicationInsights-dotnet/pull/1187/files
diff-7421a28dc03eceb294044ed77594ec83R12-R18
keys
case-insensitive
blocker
other
SDKs
confusing
errors
users
conn
strs
thinking
comment
django
case
Add
params
uses
constructor
*
ID_SIZE
padding
bytes
beginning
beginning
transmission
_transmit
list
envelopes
single
envelope
illegal
request
body
important
result
error
ingestion
service
single
data
point
request
todo
comment
name
something
namespace
E.g
https
//github.com/census-instrumentation/opencensus-specs/blob/master/stats/HTTP.md
measures
yes
name
namespace
actual
name
metrics
data
point
requests
Need
logic
flow
rename
loop
_public_
users
_
prefix
name
PRODUCER|CONSUMER
census
..
>
specific
Exception
type
worried
alias-style
init
modules
sync
tedious
change
code
code
e.g
old
backports.py
backports/__init__.py
lots
code
__init__.py
files
stutter
problem
code
sync
Please
todo
TODO
todo
TODO
TODO
docs
references
classes
return
type
TODO
API
docs
good
MB
.NET
Put
TODO
comments
places
construction
comment
BTW
project-id
location
part
K8S
resource
K8S
container
resource
k8s.io/cluster/name
k8s.io/namespace/name
k8s.io/pod/name
k8s.io/container/name
latest
Java
implementation
https
//github.com/census-instrumentation/opencensus-java/blob/master/contrib/resource_util/src/main/java/io/opencensus/contrib/resource/util/K8sContainerResource.java
specs
minute
TODO
comment
exporter
specific
context
e.g
exporter
blacklist
dedicated
context
flag
exporter
logic
integrations
requests
such
activities
cause
dead
loop
other
way
label
value
LongGauge
comment
Are
exception
None
str
exception
mechanism
more
generic
allow
httplib
list
paths
+
hosts
reasonable
request
lmolkova
@
SergeyKanzhelev
change
API
Hive
db_engine_spec
diverge
base
sync
Agreed
back
forth
logic
incomplete
utils.get_metric_name
other
hand
metric
types
legacy
ad-hoc
Nit
json_metadata
[
'filter_immune_slice_fields
]
=
filter_immune_slice_fields
Nit
json_metadata
[
'default_filters
]
=
json.dumps
filters
s/FAR_FUTURE/YEAR_IN_SEC
someone
correct
types
motto
laugh
typing
noqa
Nit
order
conditions
readable
security_manager
optional
pythonic
way
list
comprehension
something
charts
=
o
o
layout_dict.values
isinstance
component
dict
component
[
]
==
'DASHBOARD_CHART_TYPE
]
line
nit
JavaScript
sp
nit
small
comment
feature
flag
Nice
docstring
super
clear
possible
default
arg
str
=
f
window-size=
self._window
]
self._window
]
options.add_argument
arg
example
new
config
WEBDRIVER_PARAMETER_OPTIONS
specific
kind
fine
tunning
machine_auth_provider_factory.instance.authenticate_webdriver
driver
user
same
comment
df
[
filled_cols
.fillna
value=NULLSTRING
inplace=True
warning
>
SettingWithCopyWarning
value
copy
slice
DataFrame
>
See
caveats
documentation
http
//pandas.pydata.org/pandas-docs/stable/indexing.html
indexing-view-versus-copy
risk
DRYer
helpers
delete_query
query
SavedQuery
delete_queries
queries
Sequence
[
SavedQuery
]
new
default
behvaior
None
comment
field
specific
function
good
[
]
https
//github.com/apache/incubator-superset/blob/ef2ebbd570524ffede72011803a76eacf1203370/superset/views/dashboard/api.py
L46
extra
slice_ids
step
python
filters
[
slice
slice
dashboard.slices
slice.viz_type
==
filter_box
^^
comment
line
reads
entire
statement
like
similar
comment
line
regards
new
constraint
foreign
key
simple
observers
numbers
floats
comment
observer
value
todo
observations
sqlamodels
example
https
//github.com/apache/incubator-superset/blob/671461d0d03ccc7ac1d7bef9cf1a5d9c1f39fdeb/superset/utils/log.py
L32
todo
malformed
observations
useful
failed
bit
different
setup
NOTNULLCONFIG=
type
notnull
alert
=
create_alert
sql=
....
config=NOTNULLCONFIG
create
alert
alert
validator
sql
text
config
closer
test
code
readable
Would
comment
config
params
more
app
factory
style
bunch
filters
username
string
Could
token_next
reverse=True
skips
comments
whitespace
etc
robust
[
nit
comment
bit
out-of-date
POST
request
point
todo
/
git
issue
dev-box
use
production
data
dependencies
table
use
slice_id
foreign
key
nit
value
chart_position
position_value
more
clear
type
ignore
type
sure
comment
config
var
func
such
Nit
comment
DAO
stuff
little
more
generic
something
dataset_dao.find_by_tablename
dataset
command
result
dataset
DAO
bit
low-level
business
logic
Update
configuration
dictionary
bit
nit
Superset
support
python
regular
type
annotations
type
comments
i.e
python
SQLLAB_CTA_SCHEMA_NAME_FUNC
Optional
[
Callable
[
[
Database
models.User
str
str
]
str
]
]
=
None
JINJA_CONTEXT_ADDONS
exclusive
SAFE_JINJA_PROCESSING
Someone
safe
function
environment
legacy/more
risky
approach
easy
caveats.
security
implications
window
untrusted
code
user
sure
objects
objects
objets
%
harmless
simple/pure
functions
native
types.
useful
results
new
column
original
df
Users
columns
ability
API
operation
rolling
options
columns
abc
cde
]
day
average
output_columns
abc
MA7
cde
MA7
]
rolling_type
mean
win_type
None
window
min_periods
operation
rolling
options
columns
abc
cde
]
MoM
growth
MA
output_columns
abc
MoM
cde
MoM
]
rolling_type
mean
win_type
None
window
min_periods
df.diff
diff_periods
diff_periods
operation
rolling
options
columns
abc
cde
]
YoY
growth
percentages
output_columns
abc
YoY
%
cde
YoY
%
]
rolling_type
mean
win_type
None
window
min_periods
df.pct_change
pct_change_periods
diff_periods
pct_change_periods
additional
diff
pct_change
operators
output
columns
operation
diff
options
columns
abc
cde
]
output_columns
abc
MoM
cde
MoM
]
periods
]
decorator
def
validate_column_args
*
argnames
str
>
Callable
def
wrapper
fn
def
df
*
*
options
columns
=
name
argnames
dict
type
fine
keys
elem
columns
elem
options
]
raise
ChartDataValidationError
_
Referenced
columns
available
DataFrame.
Columns
DataFrame
%
df_cols
s.
Referenced
columns
%
columns
s
df_cols=list
df.columns
columns=list
columns
return
fn
df
*
*
options
wrapped
return
@
'index
'columns
'aggregates
def
pivot
df
DataFrame
index
List
[
str
]
columns
List
[
str
]
pass
s/you
Nit
comment
function
immunity
comments
variable
names
something
scoped_container_ids
immune_slice_ids
sync
list
client
side
comment
client
file
nit
Alembic
comments
seconds
separator
similar
logic
DATETIME
CAST
dttm.isoformat
AS
DATETIME
[
image
]
https
//user-images.githubusercontent.com/33317356/67800874-c04cbd00-fa90-11e9-8880-df61e9309ac1.png
Hive
supports
nanosecond
precision
https
//cwiki.apache.org/confluence/display/Hive/LanguageManual+Types
LanguageManualTypes-TimestampstimestampTimestamps
Can
import
start
function
edge
cases
comment
comment
space
front
EXPLAIN
SELECT
*
FROM
TABLE
line
python
statements_without_comments
[
statement.strip
statement
self.stripped
.upper
.splitlines
.startswith
sqlparse.format
strip_comments
option
care
/
*
/
right
logic
SQL
single
statement
statements
EXPLAIN
typical
nit
suggestion
match
=
re.match
\
\
\d
*
\
[
]
Deal
First
foreign
key
constraint
columns
Second
columns
non-nullable
foreign
key
constraint
comments
correct
lines
field
non-nullable
logical
progressions
similar
things
past
readability
standpoint
make
make
sense
lines
comment
way
clear
steps
additional
flag
test
run
flag
form
TODO
REDUCE_DASHBOARD_BOOTSTRAP_PAYLOAD
helper
function
dashboard_id_or_slug
wrapper
code
transparent
def
wrapper
*
args
dashboard_id_or_slug
str=None
*
*
kwargs
>
ETagResponseMixin
=
dashboard_id_or_slug
None
Better
dashboard
specific
logics
etag_cache
generic
skip=
parameter
feature
flag
check
@
etag_cache
skip=lambda
ENABLE_DASHBOARD_ETAG_HEADER
def
etag_cache
max_age
int
check_perms
Callable
[
]
skip
Optional
[
Callable
[
]
]
=
None
>
Callable
[
]
def
decorator
f
Callable
[
Any
]
>
Callable
[
]
def
wrapper
*
args
*
kwargs
>
ETagResponseMixin
check_perms
*
args
*
*
kwargs
POST
skip
skip
*
args
*
*
kwargs
return
f
*
args
*
*
kwargs
talk
absolute
vs
relative
imports
@
john-bodley
time
consensus
absolute
paths
possible
function
comments
large
function
good
place
divisions
form_data
keys
consts
metric_names
[
]
column_names
=
[
]
slc
slices
required
columns
form_data
param
value
slc.form_data.items
param
'adhoc_filters
filter_
value
clause
]
==
WHERE
subject
column_names.add
subject
param
METRICS_FORM_DATA_PARAMS
metric_names
map
utils.get_metric_name
value
extra
logic
adhoc
metrics
column
references
+=
[
metric
[
column
]
.get
column_name
metric
value
isinstance
metric
dict
isinstance
metric
[
column
]
elif
param
METRIC_FORM_DATA_PARAMS
metric_names.append
utils.get_metric_name
value
param
COLUMNS_FORM_DATA_PARAMS
column_names
value
elif
param
COLUMN_FORM_DATA_PARAMS
column_names.append
value
=
set
metric_names
column_names
column_names
consts
comment
nested
dicts
dicts
sure
UserDao
def
find_user_by_id
id
int
good
point
comments
issue
reference
SQLAlchemyError
ex
same
end_dttm
email
content_type
validator_config_json
==
EMAIL
test
tests/data/test-data.sql
briefly
new_ratings
old_ratings
ratings
new_ratings
i.e
new
left
old_
prefix
sure
-D
server.types
module
good
place
sure
comment
refers
startspot
==
army
lua
code
true
server
least
comment
nobody
anything
Type
annotations
kwargs
need
big
lines
code
inner
content
try
big
readable
i
lot
small
operations
function
final
logic
python3
self._logger.debug
ladder
game
%
s
game
await
host.lobby_connection.launch_game
game
is_host=True
use_map=mapname
try
=
await
raise
TimeoutError
Host
lobby
TimeoutError
msg
=
command
contextlib.suppress
DisconnectedError
asyncio.gather
host.send_message
msg
guest.send_message
msg
TODO
Uncomment
line
client
game_launch_cancelled
client
ladder
server
queue
return
self._logger.debug
Ladder
game
due
timeout
TODO
Graceful
handling
NoneType
errors
due
await
guest.lobby_connection.launch_game
game
use_map=mapname
prepare_game
connect_users
host
+
guest
\+
rid
inner
TimeoutError
little
bit
ridiculous
variable
useless
load
server
i
way
exception
whole
stack-trace
other
information
raise
mechanics
..
boolean
check
=
await
....
please
comment
reason
such
value
suggestion
test
way
much
output
suggestion
host
other
player
lobby
game
okay
database
handle
DB
many
places
game_id
game
identifier
Game
class
internal
pieces
code
KeyError
look
https
//github.com/FAForever/server/blob/6b9aec7f04698da4b0843c2a26a82705c5faf503/server/games/game.py
L515
https
//github.com/FAForever/server/blob/6b9aec7f04698da4b0843c2a26a82705c5faf503/server/games/game.py
L897
docstring
https
//github.com/FAForever/server/blob/6b9aec7f04698da4b0843c2a26a82705c5faf503/server/games/game.py
L841
tests
persist_results
-1
database
more
matter
fact
code
path
tests
https
//coveralls.io/builds/25850926/source
%
%
L449
function
first
place
Remove
comment
member
Remove
comment
readable
python
package_supported_versions
version
[
]
package_name
package_names
package_name
configs.PKG_PY_VERSION_NOT_SUPPORTED
[
version
]
package_supported_versions.discard
version
data_for_versions
result.python_major_version
result
results
data_for_versions
=
package_supported_versions
None
return
compatibility
packages=
package_names
package_supported_versions
data_for_versions
compatibility
example
https
//github.com/GoogleCloudPlatform/cloud-opensource-python/blob/master/compatibility_server/pip_checker.py
L494
comment
comment
applies
previous
line
etag
suggestion
database
Sorry
original
grammar
bad
container
Command
List
[
]
str
argument
documentation
type
documentation
approach
docker
container
clever
much
something
conceptual
def
run
self._container
=
self._docker_client.containers.run
container_name
exit
minutes
CPU
bitcoin
detach=True
More
stuff
def
_run_command
command
stdout_path
stderr_path
raise_on_failure=True
exit_code
_
=
self._container.exec_run
command
docstring
types
names
docker
python
sdk
api
function
call
tests
Are
apis
app
ready
little
bit
comment
test
case
great
addition
own
function
proper
way
part
additional
cases
future
easier
ticket
ticket
number
comment
Same
time.time
ttl
>
ttl
code
calculation
suggestion
Check
project
Small
nitpick
logic
method
project_cleanup_ttl_check
project
ttl=None
file
means
project
project_cleanup_lock_check
jobs
project
Check
project
means
project
bit
inconsistent
suggestion
Find
process
CommandLineTool
Workflow
suggestion
Regular
activity
multiple
CWL
TODO
mark
Cleanup
suggestion
Test
exception
raise
dirty
datasets
directory
suggestion
Copyright
Swiss
Data
Science
Center
SDSC
suggestion
Pull
data
LFS
name
more
Pythonic
description
comment
comment
math
Just
reference
future
suggestion
file
progress
tracking
suggestion
suggestion
click.secho
fg='green
👍
TODO
pretty
sure
Aaaaaaaaaah
style
messages
user
console
new
renku
error
e.g
TemplateError
better
cc
@
mohammad-sdsc
@
Panaetius
Handle
exception
renku
exception
case
failure
👍
client
part
RepositoryApiMixin
set
comprehension
faster
lookup
good
idea
main
Primer
preparer
long
way
stuff
device
lot
skill
service
other
place
DeviceStartup
comments
next
_last_stop_signal
statements
big
better
separate
function
date_found
statement
code
readable
comment
case
many
variables
nested
function
huge
deal
comments
strings
efficient
string
kinda
weird
lines
noqa
Readability
python
testExtract
invasion
evening
Thursday
2017-06-29
invasion
use
Exception
bare
KeyboardInterrupt
other
things.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
Attribute
'msg
__init__
]
https
//app.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=3186237
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
Attribute
'count
__init__
]
https
//app.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=3186237
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
Attribute
'emitter
__init__
]
https
//app.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=3186237
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
Attribute
'_device_identity
__init__
]
https
//www.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=1144717
Just
observation
alarm
morning
24-hour
time
system
cultural
training
comment
TODO
Look
altogether
Arduino
serial
messages
other
messagebus
subscribers
sure
comment
skill
tester
class
own
bus
load
method
class
comment
before
comment
useful
same
thing
IMHO
name
hosts
opposite
wink
filtered_hosts
blocked_hosts
sure
hosts
[
parts
]
]
hosts
=
parts
:1
]
works
hosts
parts
same
sure
tab
text
setTabText
whole
tab
bar
setTabToolTip
idx
fields
'title
]
hard
bad
idea
comment
constant
values
qt
documentation
objects
http
//doc.qt.io/qt-5/qt.html
AlignmentFlag-enum
Hmm
pragma
cover
nitpick
2015-2017
pygment
imports
file
comment
incorrect
copy
paste
i
docstring
e.g
magic
number
@
feliam
@
details
ManticoreEVM
state
available
introspection
API
TODO
comment
@
feliam
result
proper
cache
key
Current
pc
okay
hash
BitVecAdd
comments
stylistic
structural
code
Second
feels
function
regular
use
future
unneeded
conversions
lines
self.write_bytes
+
chr
cast
circumstances
assert
false
suggestion
ready
states
eth
issymbolic
Nit
comment
black
comments
line
column
length
comment
byte
symbolic
concrete
value
suggestion
byte
symbolic
concrete
write
concrete
val
suggestion
symbolic
byte
appropriate
symbolic
suggestion
Set
dst
byte
random
char
equal
comparisons
brief
comment
sentences
method
high
level
let
word
'seth
one
ManticoreError
behavior
only_from_main_script
comment
docstring
same
thing
assert
paths
suggestion
Save
concrete
function
above
comment
num_body_params
optional
immediate
argument
TODO
great
point
i
lot
mature
projects
i
kind
exceptions
module
purposes
lot
custom
exceptions
evm.py
single
file
kind
single
file
contain
error
classes
exceptions
classes
error
classes
prefix_args
self
comment
own
line
XXX/TODO
comment
thumb
comment
wrong
Py3
constant
proper
way
py3
>
>
>
io
import
IOBase
>
>
>
isinstance
open
w
IOBase
Py2
try
file_type
=
file
Python
NameError
file_type
=
IOBase
Python
isinstance
source_code
file_type
code
addresses
more
explicit
e.g
thumb
mode
instruction
size
bytes
code
asm
=
'\n'.join
tst
r0
r0
beq
label
bne
label
'label
nop
cast
glibc
function
type
exception
suggestion
cache
assembled
instructions
Manticore
tests
Keystone
dependency
additional
test
cases
new
instructions
cache
assembly_cache
=
suggestion
def
_ks_assemble
asm
str
mode=CS_MODE_ARM
>
bytes
string
Keystone
CPU
mode
late
importing
Keystone
installation
Keystone
tests
suggestion
def
_ks_assemble
asm
str
mode=CS_MODE_ARM
>
bytes
string
Keystone
CPU
mode
late
importing
Keystone
installation
Keystone
tests
suggestion
cache
assembled
instructions
Manticore
tests
Keystone
dependency
additional
test
cases
new
instructions
cache
assembly_cache
=
syscall
stuff
separate
function
i
svc
sync
more
clear
checks
svc
instruction
same
function
Sorry
comment
last
review
something
Ensure
right
operand
__rrshift__
better
single
test
method
tests
Use
empty
lines
comments
CuriousLearner
Correct
first
case
second
case
dummy
class
something
class
OverrideRRShift
def
__rrshift__
lhs
return
Force
result
independent
LHS
self.assertEqual
print
>
>
OverrideRRShift
special
casing
rshift
operation
sensible
answer
good
print
>
*
new
exception
message
case
RHS
implements
__rrshift__
returns
NotImplemented
something
more
unique
Comment
typo
thecase
>
case
suggested
test_stream_redirection_hint_for_py2_migration
name
broad
comment
case
particular
aspect
Sure
names
Linux
specific
other
OSes
other
values
Python
supports
Linux
older
suggestion
Test
REPL
error
commonly
occurs
bpo-37409
.done
Interruption
recv
fut.set_result
loop._loop_self_reading
next
loop
iteration
suggestion
slow
buildbot
worker
SHORT_TIMEOUT
LONG_TIMEOUT
suggestion
test
failure
account
client
suggestion
timeout
INTERNET_TIMEOUT
test
sure
tasks
end
test
bit
head
scratcher
comment
more
clear
pattern
subclass
clarity
comment
line
full
sentence
suggestion
replacement
defect
list
bothers
code
fragile
'pad_err
computation
try/except
value
defects
tuple
single
return
end
method
way
PaddingDefect
else
clause
try/except
defect
list
comment
start/end
block
new
method
test_strptime_single_digit
bpo-34903
Check
single
digit
dates
times
comment
least
bpo-31530
comment
reference
RFC
help
code
if/else
block
v
zlib.ZLIB_RUNTIME_VERSION
v
v
=
v.split
]
v
=
v
+
.0
comment
SyntaxWarning
warning
DeprecationgWarning
suggestion
warnings
most
Indent
continuation
lines
other
tests
Thanks
review
Patches
last
sentence
same
test
test
test
same
data
twice
different
test
test_get_extra_help_source_list
test_get_all_extrap_help_source_list
comment
test
Thanks
mistake
option
returned
list
'option
sort
compare
assertEqual
Nit
comment
name
setting
self-descriptive
something
environment
variable
value
enough
IMO
manpages_url
=
'https
//manpages.debian.org/
path
suggestion
backwards
compatibility
ourselves
TODO
attempt
pytest.mark.xfail
strict=True
@
vstinner
process
__init__
method
dct
attribute
Just
use
p.keywords
self.dct
separate
test
method
test
fragile
comment
p.keywords
]
value
MutatesYourDict
lib64
code
path
lib
Example
Fedora
>
>
get_python_lib
>
>
>
get_python_lib
standard_lib=1
/usr/lib/python3.7/site-packages
third
party
modules
example
pip
python3-pip
RPM
package
stdlib
/usr/lib64
python3
Python
default
Jan
[
GCC
Red
Hat
]
linux
Type
help
copyright
credits
license
more
information
>
>
>
import
os
>
>
>
module
'os
'/usr/lib64/python3.7/os.py
>
idea
able
co-install
Python
32-bit
64-bit
mode
Python
own
standard
library
directory
32-bit
64-bit
whereas
third
party
modules
better
timeout
delay
sleep
time
timeout
wait_for
>
sleep
sleep
sleep
sufficient
epsilon
code
tight
loop
count_lines_with_wrapping
computation
current
code
readable
user
experience
important
IMO
comment
longer
bit
Test_add_option
verifies
something
comment
load
suggestion
state
states
NB
states
suggestion
Find
transitions
current
state
other
reachable
states
suggestion
label
str
label
token
suggestion
label
DFA
state
suggestion
new
arc
connect
present
state
target
state
NFA
suggestion
DFA
equivalent
DFA
fewer
states
suggestion
label
set
states
suggestion
mapping
label
possible
*
*
p.__exit__
chance
wait
something
same
comment
suggestion
https
//bugs.python.org/issue39682
previous
versions
pathlib
method
path
subsequent
attempts
I/O
IOError
functionality
effect
Path
objects
mutable
contrary
Python
attribute
method
no-op
method
__enter__
/__exit__
future
suggestion
path
context
manager
no-op
following
operations
context
manage
line
tricky
python
try
support.throw_unraisable_exceptions
Exception
e
exception
eg
@
contextlib.contextmanager
def
throw_unraisable_exceptions
unraisable
=
None
old_hook
=
sys.unraisablehook
def
hook
exc
nonlocal
unraisable
unraisable
=
exc
sys.unraisablehook
=
hook
try
yield
unraisable
None
raise
unraisable
unraisable
=
None
consistent
options
suitable
python2
python3
documentation
b
stderr
DEVNULL
Again
recommendation
someone
documentation
Popen
....
p
p.returncode
non-zero
return
value
None
ok
[
drop
_a_
]
i.e.
variables
Indentation
mentor
uncertainity
information
programs
scan
blocks
prefix
functions
slow
time
get_ld_headers
possible
module
scope
same
thing
example
michael
@
x071
[
/data/prj/python/git/python-3.7.0.1
]
find
-name
\
*
.py
|
xargs
grep
sys.platform
./Lib/_bootlocale.py
sys.platform.startswith
./Lib/_bootlocale.py
result
sys.platform
==
'darwin
./Lib/_osx_support.py
sys.platform
==
'win32
ext
=
'.exe
./Lib/_pyio.py
sys.platform
'cygwin
./Lib/asyncio/__init__.py
sys.platform
./Lib/asyncio/__init__.py
sys.platform
pragma
cover
./Lib/asyncio/base_events.py
reuse_address
=
os.name
==
'posix
sys.platform
=
./Lib/asyncio/base_events.py
reuse_address
=
os.name
==
'posix
sys.platform
=
./Lib/asyncio/test_utils.py
sys.platform
pragma
cover
./Lib/asyncio/unix_events.py
sys.platform
pragma
cover
./Lib/asyncio/unix_events.py
is_socket
is_fifo
./Lib/asyncio/windows_utils.py
sys.platform
=
pragma
cover
./Lib/code.py
sys.version
sys.platform
cprt
./Lib/ctypes/__init__.py
_os.name
==
posix
==
darwin
./Lib/ctypes/__init__.py
_sys.platform.startswith
./Lib/ctypes/__init__.py
elif
_sys.platform
==
cygwin
./Lib/ctypes/util.py
os.name
==
posix
==
darwin
./Lib/ctypes/util.py
sys.platform.startswith
./Lib/ctypes/util.py
sys.platform
sunos5
./Lib/ctypes/util.py
sys.platform.startswith
freebsd
openbsd
dragonfly
./Lib/ctypes/util.py
elif
sys.platform
==
sunos5
./Lib/ctypes/util.py
sys.platform
darwin
./Lib/ctypes/util.py
elif
sys.platform.startswith
sys.platform
frequent
michael
@
x071
[
/data/prj/python/git/python-3.7.0.1
]
find
-name
\
*
.py
|
xargs
grep
sys.platform
So
please
question
'sys
understood
way
My
original
implementation
enhancement
useful
ripples
change
blocker
parameter
preferred
priority
keyword-only
Rather
single
preferred
browser
sense
_preferred_browsers
ripple
effect
other
updates
good
signature
impossible
high
priority
browser
xdg-settings
update_tryorder
param
preferred
approach
boolean
arguments
Python
code
ambiguous
point
True
conveys
info
reader
signature
preferred=True
lot
descriptive
things
firefox
firefox.desktop
explanatory
comment
code
fine
idea
set
opportunity
improvement
tri-state
definition
old
parameter
bit
clumsy
unnecessary
documentation
change
appropriate
other
comment
subtests
other
comment
list
tuples
dictionary
dictionary
fine
least
Python
comment
commit
message
test
return
value
_i_
stricter
assert
_i_
=
_bytes_to_copy_
test
_i_
[
in_skip
+
i
]
_
strict
option
_i_
<
_bytes_to_copy_
tests
man
page
isn
’
t
clear
short
special
cases
interrupt
limit
EOF
disk
space
tests
negative
numbers
test
zero
default
value
ways
default
explicit
zero
test
main
process
SIGINT
manager
self.assertRaises
KeyboardInterrupt
os.kill
os.getpid
signal.SIGINT
>
Timeout
compile
special
function
note
suggestion
Note
compile
argument
handling
actual
compilation
compile
pass
exec
x
*
*
x.kwargs
explanation
tracker
issue
link
fresh
comment
PyUnicode_AsUTF8AndSize
eryksun
test
test_pathext
https
//github.com/python/cpython/blob/master/Lib/test/test_shutil.py
L1835
sense
second
assert
edge
case
single
test
_AssertionError
ConnectionError
sure
patch
sendfile
offset
high
different
other
platforms
nothing
issue
entire
message
close_after
asyncio
internals
guess
regression
idea
case
exit
code
short
comment
Exit
code
Py_FinalizeEx
stdout
stderr
>
comment
Windows
Windows
error
invalid
operation
Done
comment
Windows
Windows
error
invalid
operation
least
error
experience
invalid
operation
operation
closed
socket
urllib2.urlopen
comment
test
function
easier
suggestion
selector
=
getattr
select
method
None
selector
None
select
module
method
return
False
check
OS
Kernel
method
Call
OSError
[
Errno
]
Function
try
selector_obj
=
selector
==
poll
selector_obj.poll
epoll
kqueue
devpoll
fd
selector_obj.close
True
OSError
return
False
first
read
purpose
pass
comment
comment
end
-D
comment
bottom
test
crash
non-zero
exit
code
Python
exceptions
exit
code
success
test
nitpick
=
comment
dash
suggestion
def
recv
*
_delay=10
/
milliseconds
better
private
sentinel
None
users
None
default
_NOT_SET
needs
module-level
due
weird
scoping
rules
class
bodies
suggestion
def
recv_nowait
default=_NOT_SET
recv
default
waiting.
default
_NOT_SET
return
_interpreters.channel_recv
self._id
return
_interpreters.channel_recv
self._id
default
_NOT_SET
=
object
f-strings
Shame
scheme
value
default
scheme
urlsplit
urlparse.
comment
applies
lists
uses_relative
uses_netloc
uses_params
empty
string
supported
scheme
default
urlsplit
url
scheme=
allow_fragments=True
def
urlparse
url
scheme=
allow_fragments=True
current
comment
classification
schemes
apply
default
comment
change
bit
clear
comment
discussion
Ah
comment
functions
lists
something
empty
string
classifies
relative
URLs
scheme
default
“
urlsplit
”
“
urlparse
”
Can
method
tests
code
+
meth
[
cm.__aenter__
cm.__aexit__
]
+
awaitable
=
meth
self.assertTrue
inspect.isawaitable
awaitable
awaitable
exception
type
unchanged
exception
message
assert
new
exception
message
Style
nit
cm
name
unittest
context
managers
Style
nit
better
store
exception
message
msg
message
variable
assertRaisesRegex
case
minor
nit
assumed
default
use
F_GETPIPE_SZ
default
value
half
double
something
process
need
a-zA-Z
a-z
suggestion
removal
previous
comment
file
new
comment
coroutine
cpython
dependent
precisely
reference
counting
garbage
collection
future
versions
other
implementations
OK
behavior
test
Let
comments
Create
async
generator
garbage
async
generator
finalization
tests
implementation
details
garbage
collector
Changes
gc
function
suggestion
Linux
abstract
socket
namespaces
unlinked
Uncomment
correspond
module
return
>
module
return
Lexical
order
comment
necessary
StopIteration
ISTM
other
cases
newline
end
unified
point
things
simple
IMO
unnecessary
briefly
*
*
last_line
best
understanding
last
line
newline
check
loop
line
last
loop
iteration
non-collection
iterable
e.g
iter
[
'module
]
sure
least
test
zero-length
parser_list
other
tests
parser_list
more
item
Might
make_parser
[
'module
]
Next
>
'next
command
<
explicit
Move
comment
block
Please
comment
next
bpo-32962
Python
-mcet
-fcf-protection
arguments
unusable
first
instruction
function
entry
point
Ditto
please
comment
file
source
tree
folder
Could
suggestion
Honor
directory
components
RFC1952
pickle
test
zip
iterator
Python
string
same
zip
iterator
same
string
latter
test
sufficient
points
pickle
protocols
Minor
clarification/nit
suggestion
wakeup
fd
file
descriptor
main
thread
typo
accessible
comment
bpo-35794
PermissionError
Sorry
linux
darwin
lists
shorter
Please
comment
code
change
necessary
set
getters
delicate
matter
nice
source
code
comments
checkers
others
elements
order
same
_NODE_GETTERS_UNIX
strong
reason
suggestion
bpo-39453
list.__contains__
strong
references
SyntaxError
big
deal
__main__
SystemExit
cases
case
suggestion
run_module
SystemExit
success
suggestion
run_module
alters
sys.modules
sys.argv
exit
effect
alter_sys=True
comment
sys
unmodified
run_module
exit
suggestion
run_module
alters
sys.modules
sys.argv
exit
runpy.run_module
pip
run_name=
__main__
alter_sys=True
reference
bpo
comment
short
description
purpose
complex
test
reason
comparison
Does
matter
nitpick
Python
error
messages
dot
Same
comment
error
messages
FWIW
Windows
invalid
address
OSError
illegal
IP
address
comment
similar
lines
note
docs
suggestion
_urandom
n
ValueError
n
block
test
specific
Linux
version
size
fields
test
suggestion
plistlib.dumps
huge_uid
fmt=plistlib.FMT_BINARY
suggestion
huge_uid.data
*
*
size
check
constructor
docs
>
data
range
<
=
data
<
*
\
*
plistlib
expert
*
valid
value
docs
separate
issue
sure
question
assertion
issue
patch
quopri.incrementalencoder
assertion
issue
patch
sure
effects
Python
issue
patch
Python
assertion
failure
quopri.incrementalencoder
other
way
way
nice
trio
[
MultiError
]
https
//trio.readthedocs.io/en/latest/reference-core.html
trio.MultiError
stdlib
unfortunate
other
exceptions
E.g
IIUC
instance
cleanups
exceptions
self.errors
such
place
modules
code
yuck
other
alternative
something
simple
MultiError
exceptions
MultiError
len
exceptions
lot
extra
complication
um
exceptional
case
punt
IOW
cool
same
invalid_utf8
meaning
value
clear
hex
hex
constant
i.e
something
pending_size_nine
avoid
backticks
comment
pretty
clean
tests
Avoid
backticks
Please
comment
new
flags
old
flags
idea
-i
python3
-W
default
python3
-iW
default
shebang
single
option
argument
-option
default
ignore
-W
default
-W
ignore
Please
typo
suggestion
dump_traceback_later
comment
something
bpo-35017
shutdown
different
thread
select
request
exit
comment
suggestion
unraisable.object
object
Unit
tests
side
effect
old
verbose
value
Example
self.addCleanup
setattr
tabnanny
Sub
tests
great
IMHO
docstring
useless
Again
sure
long
comment
simple
unit
test
assert_python_ok
returncode==0
chain
methods
assert_python_ok
>
_assert_python
>
universal_newlines
argument
Reference
https
//github.com/python/cpython/blob/master/Lib/test/support/script_helper.py
L94
Are
script_helper.assert_python_ok
subprocess.Popen
better
readability
textwrap.dedent
multiline
string
test_faulthandler
examples
need
method
private
_
prefix
Use
universal_newlines=True
newlines
text
bytes
stdout/stderr
method
way
docstring
proc
=
script_helper.spawn_python
'-m
'tabnanny
*
args
text=True
err
=
proc.communicate
self.assertEqual
stdout
self.assertEqual
err
stderr
self.assertEqual
proc.returncode
text=True
normalizes
newlines
Unix
EOL
real
filesystem
troubles
intsead
return
date
date
year
Typo
stirng
hour
line
something
ord
=123
Make
sure
right
unicode
character
local
variable
test
isinstance
None
int|None
back
debug
mode
2-3
lines
traceback
variables
Minor
nitpick
typo
comment
>
propagated
length
line
character
limit
[
PEP
]
https
//www.python.org/dev/peps/pep-0008/
maximum-line-length
strings
contain
spaces
hard
following
cases
junk
junk
repr
commented
test
UnicodeEncodeError
CPython
implementation
specific
test
worth
error
message
+
first
read
error
non-ASCII
digits
error
invalid
character
suggestion
def
test_length_zero_header
bpo-39017
CVE-2019-20907
zero-length
header
exception
self.assertRaisesRegex
tarfile.ReadError
file
enum
end
function
comments
current
style
process
exit
code
non-zero
better
separation
concerns
IMO
function
line
'\n
beginning
suggestion
width
>
=
len
tag
blank
line
consistent
module
style
path
return
None
shutil.which
right
branch
console
git
rev-parse
HEAD
touch
chmod
+x
PATH=
./python
-c
'import
distutils.spawn
print
distutils.spawn.find_executable
oops
oops
PATH=
./python
-c
'import
shutil
print
shutil.which
oops
None
order
test
comment
cwd
inside
tmp_dir
test
error
good
idea
tests
sys.__stderr__.fileno
comment
Replace
line
try
stderr_fd
=
sys.__stderr__.fileno
ValueError
stderr_fd
=
None
IDLE
command
line
python
import
idlelib.idle
backup
call
>
>
sys.__stderr__
<
_io.TextIOWrapper
name=
<
stderr
>
mode=
w
encoding='utf-8
>
>
>
>
sys.__stderr__.fileno
wekref
potential
garbage
cycles
tasks
bulk
cancelled
errors
case
GC
asap
Rather
date
conditional
logic
comment
something
generic
most
*
nix
platforms
ASCII
C
locale
different
encoding
files
TESTFN
TESTFN2
comment
*
os.getcwd
different
function
test
skip_no_disk_space
function
test_it
skip_no_disk_space
TESTFN
size
*
TESTFN
relative
sure
skip_no_disk_space
absolute
os.path.abspath
Remove
obsolete
comment
Update
comment
other
fields
\r
empty
line
group
stuff
asyncgens
suggestion
bpo-36366
start
None
suggestion
bpo-36366
patch
None
comment
IIUC
small
integers
frame
comment
interact
next
line
safe
unnecessary
Line
idle
thread
None
queue
siblings
threads
work
executor
work
item
shutdown
race
Could
comment
approach
sure
guarantee
tests
wide
machine
example
32-thread
CPU
and/or
thread
scheduling
details
cancel
number
workers
small
value
executor_type
constructor
call
test
reliability
magic
attributes
possible
Please
reference
bpo-30775
comment
preference
deletion
%
real
problem
practice
case
uid_t
different
definition
platforms
=
Linux
certain
architectures
sense
bigger
value
<
https
//github.com/python/cpython/blob/a24107b04c1277e3c1105f98aff5bfa3a98b33a0/Modules/posixmodule.c
L621
typo
git_t
>
gid_t
comment
_POLL_TIMEOUT
queue_management_thread
thread
results
workers
jobs
May
following
comment
_ThreadWakeup
communication
channel
wait
main
loop
queue_manager_thread
thread
e.g
executor.submit
executor.shutdown
_result_queue
wakeup
signal
queue_manager_thread
deadlock
worker
process
_result_queue
write
lock
captured_stderr
warning
log
message
root.tk.call
script
TclError
side
effect
comment
test
after_cancel
TclError
root.tk.call
'after
'info
'spam
TclError
command
after_cancel
implementation
detail
_tclCommands
implementation
detail
better
tests
implementation
past
tests
side
effect
script
root.tk.call
script
suggestion
filename
=
os.path.join
directory
'script.py
type
uppercase
suggestion
bpo-38347
Test
filename
lowercase
uppercase
hash
'nofar
true
hash
randomization
_study1
continuation
type
mismatch
example
likely
wild
likely
issues
someone
editor
non-matching
bracket
example
IDLE
editor
[
indents
space
Enter
linter
syntax
error
users
next
line
dictionary
Uncomment
harumph
tzinfo
object
tests
comment
order
subclasses
C
implementation
able
__init__
raise
NotImplementedError
case
comment
bpo-37915
good
idea
true
years
comment
commit
message
more
sense
justification
change
worth
new
frame
single
bytes/string
object
size
file
number
file
operations
opcode
+
size
+
payload
comment
concatenation
line
https
//github.com/python/cpython/pull/22405/files
suggestion
PR
part
same
effect
equivalent
easier
suggestion
conv
=
float_round
get_tk_patchlevel
<
noconv
self.checkFloatParam
widget
conv=conv
suggestion
conv
=
float_round
get_tk_patchlevel
<
noconv
self.checkFloatParam
widget
conv=conv
python
Skip
event
loop
cycle
private
helper
'asyncio.sleep
'delay
bare
expression
Task._step
Future
object.
nitpick
comment
future
readers
more
test
git
blame
other
-X
options
such
-Xfaulthandler
lower
limited
read
n
limited
unlimited
blank
line
typo
chagelist
>
changelist
Good
catch
@
lulouie
Define
empty
function
Windows
comment
__del__
zombie
process
process
exit
__del__
comment
_active
None
confused
zombies
visible
zombie
task
list
Unix
process
kernel
alive
handle
pointer
reference
kernel
Process
object
information
such
exit
status
reader
Popen
instance
nothing
_cleanup
Windows
Please
code
_active
support.reap_children
Windows
useful
tests
expectations
comments
things
way
perfect
world
Nitpick
CET
Control-flow
enforcement
technology
CF
Control-flow
enforcement
technology
CET_CF_PROTECTION
Control-flow
enforcement
technology
control-flow
protection
Pick
IIRC
base_executable
applies
macOS
PypeBros
trailing
space
suggestion
auth-int
response
response
c
locals
certain
more
appropriate
RuntimeError
ValueError
first
ValueError
due
reuse_address=True
error
related
invalid
value
ValueError
operation
function
argument
right
type
inappropriate
value
situation
precise
exception
such
IndexError
specific
exception
class
suitable
situation
result
appropriate
choice
RuntimeError
RuntimeError
error
doesn
’
t
fall
other
categories
associated
value
wrong
open
suggestions
though
other
exception
classes
suggestion
usage
Good
catch
test_fromkeys_operator_modifying_dict_operand
test_fromkeys_operator_modifying_dict_operand
same
dicts
new
key
test
other
tests
Use
try
Please
explaining
comment
possible
time.perf_counter
function
way
example
test
space
test
spaces
test
second
test
like
slower
general
tests
time
likely
slowest
buildbot
hardcoded
timing
timings
function
calls
buildbot
threshold
large
slower
more
cc
@
pablogsal
time
something
python
http2time
Feb
GMT
*
*
*
http2time
Feb
GMT
*
*
*
iso2time
python
iso2time
'1994-02-03
-0100
*
*
*
iso2time
'1994-02-03
-0100
*
*
*
second
line
comment
>
above
comment
unneeded
@
vstinner
thoughts
question
@
vstinner
please
review
sure
comment
code
minor
typo
suggestion
Subclasses
int/float
__repr__
way
autospecced
object
helper
function
sensible
name
wherever
pattern
sure
comment
text
tweaking
comment
Please
function
Python
startup
sysconfig
import
site
module
reference
bpo
change
env_base
return
env_base
top
Please
sysconfig._getuserbase
sysconfig
sys._framework
get_config_var
PYTHONFRAMEWORK
tuples
str
following
TypeError
in-sync
implementation
value
type
str
int
None
kind
comment
docstring
usefull
comment
suggestion
bpo-41919
method
StatefulIncrementalDecoder
resource
leak
codecs
cleanup
functions
constants
CO_FUTURE_
comment
reference
issue
test
suggestion
bpo-39562
test
future
flags
compiler
flags
future
flags
CO_
*
*
*
__future__
module
dictionary
mapping
constant
names
values
self.assertCountEqual
flags.values
flags.values
__future__.all_feature_names
name
f
CO_FUTURE_
Maybe
overkill
comment
-D
suggestion
exported
compiler
flags
PyCF_
*
*
*
ast
module
suggestion
__dataclass_fields__
=
[
]
asyncio
reuse_addr
parameter
None
default
*
disable
*
reuse
addr
feature
logic
useful
cases
implicit
error
suppressing
useful
Please
comment
IPPROTO_IPV6
IPV6_V6ONLY
available
NameError
first
read
]
acceptable
argument
type
check
runtime
None
Rather
whole
condition
comment
several
times
simple
@
skip_if_buggy_ucrt
decorator
decorator
bugs
UCRT
bug
present
skips
spawnv
arguments
command
line
lpCommandLine
parameter
shell
Python
subprocess.list2cmdline
CRT
spawn
family
command
line
[
MSVC
rules
]
https
//docs.microsoft.com/en-us/cpp/c-language/parsing-c-command-line-arguments
view=vs-2019
spaces
caller
argument
rules
target
application
need
quotes
argument
single
quotes
special
meaning
MSVC
example
=
[
'python
'-c
code
]
code
double
quote
characters
need
args
[
]
fully-qualified
path
spawnv
[
]
=
sys.executable
wrong
test
build
path
spaces
path
spaces
C
[
]
first
space
path
rest
argv
[
]
full
path
example
sys.executable
C
\\Program
Files\\Python38\\python.exe
>
>
>
os.spawnv
sys.executable
[
f
sys.executable
'-V
]
example
>
>
>
os.spawnv
sys.executable
[
sys.executable
'-V
]
C
\Program
[
Errno
]
No
such
file
directory
unqualified
python
>
>
>
os.spawnv
sys.executable
[
'python
'-V
]
comment
time
function
function
def
test_get_objects_arg
allow
duplicate
comment
dict
merge
duplicates
self.keywords
keyword
same
keys
KeyError
assignments
None
checks
suggestion
Multi-part
glob-style
pattern
suggestion
See
bpo-40862
Invalid
word
format
defect
other
type
parsers
value
TODO
new
bpo
only
kind
whitespace
tag
string
blank
simpler
eyes
clearer
clause
tag_c
c.isspace
need
nested
function
expense
many
times
body
_keep_original_ws
statement
Replace
blanks
tag_s
corresponding
whitespace
characters
s
aim
visual
output
contains
tabs
.join
tag_c
c.isspace
tag_c
c
tag_c
zip
s
good
private
function
level
old
_count_leading
expense
new
function
time
worth
loop
Just
regression
test
enough
buildbots
race
conditions
*
test
bpo-30594
Please
new
syntax
bpo-6986
Issue
confusion
bugs.python.org
bug
tracker
GitHub
bug
tracker
invalid
argument
stream
create_server
function
strong
reference
reader
connection
reader
garbage
connection
StreamWriter.close
protocol
method
issue
>
bpo-34900
Might
worth
brief
comment
purpose
recursive
reprs
futures
something
lines
name
clear
context
internal
set
reprlib.recursive_repr
result=
same
most
cases
local
testing
PR
branch
issues
regards
ellipses
parts
repr
>
>
>
asyncio.gather
func
timeout=10
asyncio.wait_for
func
<
Task
coro=
<
wait_for
/home/aeros/repos/cpython/Lib/asyncio/tasks.py:419
>
result=
<
Task
finishe
>
result=
>
<
Task
finishe
res.py:391
]
>
>
<
Task
finishe
res.py:391
]
>
>
<
Task
tures.py:391
]
>
<
Task
finishe
result=
>
>
>
<
Task
name='Task-21
coro=
<
func
<
console
>
:1
>
result=
<
Task
finishe
res.py:391
]
>
>
<
Task
finishe
esult=
>
>
>
<
Task
finishe
>
result=
>
<
Task
tures.py:391
]
>
>
<
Task
name='Task-19
coro=
<
wait_for
/home/aeros/repos/cpython/Lib/asyncio/tasks.py:419
>
result=
<
Task
finishe
>
result=
>
<
Task
finishe
esult=
>
>
>
<
Task
finishe
res.py:391
]
>
>
<
Task
tures.py:391
]
>
>
<
Task
name='Task-17
coro=
<
<
module
>
<
console
>
:1
>
cb=
[
_chain_future.
<
locals
._call_set_state
/home/aeros/repos/cpython/Lib/asyncio/futures.py:391
]
>
<
Task
name='Task-20
coro=
<
func
<
console
>
:1
>
result=
<
Task
finishe
result=
>
>
<
Task
finishe
res.py:391
]
>
>
<
Task
finishe
res.py:391
]
>
>
<
Task
tures.py:391
]
>
<
Task
finishe
>
result=
>
>
<
Task
name='Task-19
coro=
<
wait_for
/home/aeros/repos/cpython/Lib/asyncio/tasks.py:419
>
result=
<
Task
finishe
>
result=
>
<
Task
finishe
esult=
>
>
>
<
Task
finishe
res.py:391
]
>
>
<
Task
tures.py:391
]
>
>
<
Task
coro=
<
wait_for
/home/aeros/repos/cpython/Lib/asyncio/tasks.py:419
>
result=
<
Task
finishe
>
result=
>
<
Task
finishe
res.py:391
]
>
>
<
Task
finishe
res.py:391
]
>
>
<
Task
tures.py:391
]
>
<
Task
finishe
result=
>
>
>
<
Task
name='Task-21
coro=
<
func
<
console
>
:1
>
result=
<
Task
finishe
res.py:391
]
>
>
<
Task
finishe
esult=
>
>
>
<
Task
finishe
>
result=
>
<
Task
tures.py:391
]
>
>
<
Task
name='Task-17
coro=
<
<
module
>
<
console
>
:1
>
cb=
[
_chain_future.
<
locals
._call_set_state
/home/aeros/repos/cpython/Lib/asyncio/futures.py:391
]
>
]
hard
problematic
line
<
Task
name='Task-21
coro=
<
func
<
console
>
:1
>
result=
<
Task
finishe
res.py:391
]
>
>
<
Task
finishe
esult=
issue
reprs
though
sure
fix
comment
accurate
check
__aexit__
synchronous
asynchronous
context
managers
dubious
good
idea
recipe
confusion
reading
code
cached
value
test
least
None
test
E.g
self.addCleanup
global
test
Minor
style
nit
please
complete
sentences
e.g
period
Okay
assertion
true
reason
random
UUID
generator
getters
latter
valid
value
comment
line
explaining
bit
head
scratcher
someone
test
*
bit
head
scratcher
comment
mention
64-bit
hardware
address
node
bits
easy
logic
bits
First
failure
bug
second
minor
cognitive
hiccup
IOW
off-by-one
possibility
minor
think
next
person
code
variable
too_large_getter
such
Please
new
bpo-xxx
format
little
bit
characters
control
characters
space
control
character
suggestion
characters
HTTP
URL
paths
comment
filesystem
uw
skip
test
Note
[
patch
]
https
//sourceware.org/git/
p=glibc.git
a=commit
h=ccfb2964726512f6669fea99a43afa714e2e6a80
pipe
POSIX
implementation
unconditional
use
fork
main
motivation
posix_spawn
performance
benefits
vfork
glibc
POSIX
implementation
branch
LGTM
clause
while
comments
specific
statements
main
reason
referenced
code
time
comments
likely
stale
See
bpo-41654
more
information
nitpick
bpo-41654
*
*
comment
comment
complex
code
complex
unique
name
suggestion
self.codec_name
=
Interesting
new
created
objects
new_callable
different
mock
type
TODO
last
thing
short
comment
branch
First
argument
wrapped
callable
*
args
partialmethod
lambda
*
args
sig
sense
spaces
please
PEP8
clearer
use
local
function
lambda
other
tests
partialmethod
nice
tests
more
common
partialmethod
work
keyword-only
parameters
*
args
work
partialmethod
classmethod
NOQA
def
*
NOQA
pass
style
other
tests
expected
result
next
line
serhiy-storchaka
@
Codecov
complains
unit
test
codes
functions
test
unit
tests
test
code
reasonable
Thank
tip
comment
following
line
AsyncMock
asyncio
loop/policy
state
return
something
descriptive
way
clear
time_supports_trailing_percent
=
True
try
_time.strftime
%
ValueError
time_supports_trailing_percent
=
False
Good
catch
time
module
date
object
wrapper
method
comments
line
function
body
assertRaises
possible
loops
combinations
combinations
test
reference
count
crash
empty_dict
please
comment
Please
constants
wantobjects
function
problem
comment
original
pull
request
solution
simple
..
components
relative
symlinks
e.g
bar\\
..
\\spam
kernel
absolute
directory
symbolic
links
junction
mount
point
target
..
component
relative
link
example
bar
>
M
\\eggs\\foo
bar\\
..
\\spam
M
\\eggs\\spam
old_path
contains
directory
symlinks
kernel
relative
symlink
Unix
..
components
place
Windows
internal
CreateFileW
call
nt.readlink
implements
same
naive
behavior
..
components
native
NT
path
NT
..
components
file-system
paths
I/O
manager
internal
handling
IO_REPARSE_TAG_SYMLINK
reparse
points
kernel
sure
complete
redesign
POSIX
realpath
added
complexity
complications
Windows
paths
copy
call
suggestion
self.assertEqual
period
comment
important
cache
curous
tuple
range
range
comment
bit
test
faster
https
//bugs.python.org/issue41531
msg375255
Nice
hack
docstring
jumping
forbidden
curious
output.append
Edit
oh
jump
ValueError
block
comment
issue
>
race
condition
signal
delivery
>
Technically
process
signal
waits
signal
process
something
obvious
reasoning
Sorry
comment
helpful
way
dummy
test
beginning
comment
function
upper
case
letters
case
letters
purpose
test
explicit
Hum
comment
bpo-38243
Ensure
server
title
documentation
HTML
comment
start
function
comment
mentioning
PermissionError
part
ignored
errnos
Sorry
GIVEN/WHEN/THEN
A
pair
descriptors
timeout_ms
value
test
sure
function
expensive
detrimental
dynamic
code
base
class
update_abstractmethods
subclasses
check
documentation
Typo
subclassing
function
ABC
cls.__abstractmethods__
works
>
>
>
class
FooABC
pass
>
>
>
FooABC.__abstractmethods__
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
AttributeError
__abstractmethods__
test
function
non-ABC
nitpicking
other
comments
file
start
capital
letter
end
period
utils
>
format_helpers
suggestion
Subtract
listdir
file
suggestion
nonexistent
module
need
comment
nitpick
self.skipTest
test
assertion
test_userbase
Clarification
values
handler
attributes
tests
default
values
future
handler.wsgi_version
https
//github.com/python/cpython/blob/c6a2320e876354ee62cf8149b849bcff9492d38a/Lib/wsgiref/handlers.py
L160
setup_environ
change
below
assertion
checks
loops
values
handler.get_stdin
'wsgi.errors
handler.get_stderr
'wsgi.version
handler.wsgi_version
'wsgi.run_once
handler.wsgi_run_once
handler.get_scheme
handler.wsgi_multithread
handler.wsgi_multiprocess
util.FileWrapper
policy.linesep
None
…
[
-len
policy.linesep
\n
policy.linesep
…
[
-len
policy.linesep
hasattr
policy
linesep
\n
combination
’
t
code
sure
scenario
Please
comment
C
module
frames
recent
oldest
reverse
order
Python
API
good
comment
new
call
bpo-36520
refer
GitHub
issues
bpo-36520
Similar
comment
backslashes
helpful
tests
line
comment
name
test
numbers
Test
header
maxlen
middle
encoded
word
relationship
b
__iter__
nonobvious
able
crash
something
call
__iter__
item
p
pass
comment
case
b
__iter__
similar
comment
is_type_predicate
previous
paragraph
comments
great
good
future
reference
examples
other
comment
text
comment
obsolete
arg
name
annotation
worth
test
non-reiterable
value
e.g
iter
[
]
test
false
non-iterable
value
defaults=False
test
empty
*
defaults
Same
question
previous
call
flashing
call
safety
original
self.remove_calltip_window
call
beginning
function
PR
type
code
such
defensive
coding
good
reasons
difficult
possible
flow
edge-case
possible
future
coupling
other
code
Calltip
class
way
internal
invariants
such
outside
parenthesis
open
calltip
remove_calltip_window
no-op
self.active_calltip
self.active_calltip.hidetip
call
below
necessary
separate
comment
fix
fetch_tip
OpencalltipTest
methods
code
mock
editwin
hyperparser
mock
fetch_tip
appropriate
_calltip_window
showtip
added
comments
tests
higher
priority
Typing
only
case
branch
various
other
cases
force_open_calltip_event
elem.text
elem.tail
elem.clear
FWIW
len
path
[
:261
]
>
MAX_PATH
beginning
_check_dirW
equal
MAX_PATH
_dirnameW
first
shorter
surprised
ZIpFile-specific
code
whole
module
abstraction
various
concrete
loaders
wrong
later
comment
mentions
version
code
stdlib
version
comparison
PyPI
backport
compatible
pragma
Pragma
Ditto
check
non-obvious
more
verbose
explicit
impossible
Please
comment
bpo
identifier
bpo-30584
Use
security
identifier
*
S-1-5-32-545
Users
locale
SID
localized
names
correct
Thanks
issue
numbers
comments
lot
explanation
issue
comment
suggestion
Strip
whitespace
suggestion
node_or_string
=
parse
node_or_string.lstrip
\t
mode='eval
possible
line
comment
line
tests
Suggestion
Remove
test
loop
argument
Python
Thanks
tests
smile
regular
comment
docstring
suggestion
issue
test
_randbelow
returns
zero
few
formats
loop
result
format
i
self.assertEqual
PyBuffer_SizeFromFormat
format.encode
format
Unicode
format
UTF-8
byte
string
char
*
test
able
ctypes
Could
function
Modules/_testcapimodule.c
Dt
]
attribute
tm_mon
comment
hour
self._member_names
sufficient
*
truthy
*
Looks
change
test
line
new
auto_called
flag
False
changes
auto
first
time
test
comment
backslash
control
character
'\r
'\n
DeprecationWarning
case
'\\\n
'\\\r\n
length
value
informative
error
message
eval
unexpected
result
Okay
'\\\r
zero
length
versions
docstrings
comments
whole
file
fixes
check
redundant
len_str
pos
check
*
test_pathfix_without_keeping_flags
code
test_pathfix
move
test_pathfix_keeping_flags
test_pathfix
test
test_pathfix_keeping_flags
use
-k
shebang
flag
bug
Please
comment
IMHO
helpful
end
default
value
text=True
Unicode
suggestion
lslpp_output
=
subprocess.check_output
[
/usr/bin/lslpp
-Lqc
bos.mp64
]
text=True
lslpp_output
verbose
result
variable
f-strings
readability
suggestion
assert
lpp
bos.mp64
f
lpp
=
bos.mp64
sure
assert
s
optimized
mode
runtime
module
level
other
similar
vars
readable
line
return
Side
note
modules
sense
DRY
future
patch
pass
Nothing
test_cancelled_putters_not_being_held_in_self_putters
fine
print
raise
block
test
fix
Please
sure
test
code
b
clear
comment
code
line
longer
characters
Please
PEP8
code
other
reason
particular
other
PyCharm
static
self
rid
static
declaration
Sure
delegation
assert
test
Sure
chars
Hi
@
serhiy-storchaka
1st
PR
comment
opportunity
review
same
exception
original
code
resolve_dotted_attribute
returns
None
Fixed
OSError
comfortable
wide
range
exceptions
*
*
better
power
*
comment
GiB
limit
size
64-bit
system
Please
comment
instruction
limits
purpose
line
more
explicit
Lilke
=
count
count
bpo-38319
truncate
GiB
OverflowError
=
min
*
*
py
filename
=
getattr
module
None
suggestion
__file__
None
empty
packages
sure
functional
test
following
attributes
>
>
sys.stdout.write_through
sys.stdout.write_through
False
False
pitrou
worry
functional
tests
likely
more
CI
nitpick
comment
function
test
crashes
unpatched
code
dummy
member
necessary
short
comment
comment
explicit
addAsyncCleanup
Please
comment
logic
reprlib
logic
reprlib
docstring
function
internal
module
comment
module
comments
same
line
code
spaces
comment
git
blame
line
sense
much
loadfile
same
edit
second
time
eol_convention
EOL
convention
file
part
fine
comment
correct
__builltin_available
checks
libffi
functionality
libffi
one
OS
Can
bpo-34155
domains
@
@
malicious.org
@
important.com
bpo-
issues
code
bugs.python.org
suggestion
case
double
trailing
comma
end
line
source
bpo-41044
suggestion
Note
comma
call
comma
end
example
rules
repeat0
optional
markers
e.g
[
rule
*
]
Hummmm
find
generated
code
reason
grammar
structure
other
places
difficult
reason
case
fine
good
attribute
line
comment
branch
comment
thread
sys.modules
import
lock
fix
open_local_file
_open_local_file
Python
risk
method
party
code
reason
bpo-35907
disallow
typo
Please
fix
need
_urlopener
Just
block
access
schema
special
cases
subclasses
special
instances
Please
reference
bpo-42264
suggestion
bpo-42264
OptimizedUnicode
Python
removal
comment
file
size
database
compression
unlikely
filename
docstring
False
suggestion
sys.path
site.addpackage
test
least
reference
issue
comment
regression
test
document
URL
clear-text
HTTP
redirection
HTTPS
example
http
//www.python.org/
direction
HTTPS
comment
person
code
restored
flag
Test
İ
İ'.lower
i
older
Python
versions
[
a-z
]
ı
İ
sense
something
addresses
UUID1
objects
unique
change
doc
https
//docs.python.org/dev/library/uuid.html
uuid.getnode
Add
..
versionchanged
Python
suggestion
import
chance
plenty
links
source
years
time
different
tracker
obvious
last
parameter
line
text
argument
position
argument
keyword
argument
comment
arguments
result
arguments
correct
order
example
return
f'm=
message
c=
category
f=
filename
l=
lineno
t=
text
new
test
new
method
def
test_formatwarning_override
new
test
nitpick
different
function
name
confusion
ex
def
myformatwarning
*
days
runpy
__package__
[
contextlib.suppress
]
[
suppress
]
context
managers
suppress
]
https
//docs.python.org/3/library/contextlib.html
contextlib.suppress
order
patch
clearer
add
comments
items
E.g
python
Python
protocol
b'\x80\x02cuuid\nUUID\n
\x81
U\x03int\x8a\x11\xa5z\xecz\nI\xdf
\xde'
b'\xa0Bf\xcey
%
\xd8\x00sb
Python
protocol
Thanks
comment
FWIW
following
more
clear
SimpleNamespace
repr
namespace
class
name
same
class
name
check
sake
explicit
suggestion
type
object
_types.SimpleNamespace
more
space
comment
self
>
self._numerator
>
ValueError
_PyHASH_MODULUS
divides
self._denominator
case
second
pow
line
dinv
comment
effect
modular
inverse
branch
suggestion
'annotations
future
default
way
'key
pointless
confusing
something
'key
below
Same
other
comment
Please
use
bpo-38588
istead
issue
confusion
issue
tracker
change
i-th
argument
compiler_cxx
[
i
]
string
change
whole
compiler_cxx
*
list
*
linker
list
Sorry
https
current
command
line
command
line
change
short
example
command
line
case
doubt
current
code
non-AIX
platforms
linker
[
i
.endswith
'ld_so_aix
Linker
ld_so_aix
compiler
next
arg
i
linker
=
linker
[
i
+
self.compiler_cxx
+
linker
[
i+1
]
linker
[
i
=
self.compiler_cxx
[
i
socket.SOCK_STREAM
bit
value
socket.SOCK_NONBLOCK
bit
weird
Values
socket
creation
flags
mixed
example
check
sock_type
==
socket.SOCK_SEQPACKET
>
>
>
socket.SOCK_SEQPACKET
socket.SOCK_STREAM
socket.SOCK_STREAM
True
possible
values
Linux
>
>
>
list
socket.SocketKind
<
SocketKind.SOCK_STREAM
>
<
SocketKind.SOCK_DGRAM
>
<
SocketKind.SOCK_RAW
>
<
SocketKind.SOCK_RDM
>
<
SocketKind.SOCK_SEQPACKET
>
<
SocketKind.SOCK_NONBLOCK
>
<
SocketKind.SOCK_CLOEXEC
>
]
short
comment
first
parameter
send
bytes
BlockingIOError
bytes
write.send
b
x
Please
comment
signal
handler
signals
socket
comments
explanations
_queue_management_worker
docstring
Minor
grammar
fix
suggestion
Terminate
executor
broken
state
cause
Minor
typo
suggestion
resources
Minor
grammar
fix
suggestion
executor
Hmm
huge
fan
name
shutdown_executor_when_no_pending_tasks
bit
method
name
shutdown_executor
fine
docstring
resources
tasks
comment
references
most
IDLE
classes
more
pep8
start
comments
capital
letter
end
period
suggestion
script
capture
absolute
path
output
file
startup
suggestion
script
capture
absolute
path
output
file
startup
comment
purpose
self._paused
future
hard
time
code
complex
crystal
clear
Please
comment
await
@
dutradda
Sure
everything
looks
good
sure
different
path
run_until_complete
self.new_task
loop
foo
enough
patch
bit
getpathp.c
whole
time
specific
information
RFC
desirable
RFC
Section
multipart
boundary
delimiters
header
fields
US-ASCII
suggestion
self.assertFalse
has_cycle
try
..
sure
loop
failed
tests
Small
easy
point
passing
source=coro
user
tracemalloc
origin
traceback
warning
Kinda
neat
*
set_coroutine_origin_tracking_depth
tracemalloc
at-least-partially-redundant
tracebacks
same
warning
FYI
point
None
test
comment
logic
_AIX
example
behaviour
qualifier
comment
Close
parenthesis
modname.split
]
=
tzdata
sentences
full
stop
valid
result
]
nice
tests
cases
*
__subclasses__
callable
wrong
signature
*
__subclasses__
exception
*
__subclasses__
returns
list
*
__subclasses__
returns
list
type
docstring
_ourJobObjectList
list
objects
objects
docstring
non-integer
things
return
value
exit
code
Kubernetes
batch
system
-1
cases
exit
code
something
descriptive
https
//github.com/DataBiosphere/toil/blob/8e1d8c0f45f6210bbd0900380b62c5a1c1a6cdc7/src/toil/leader.py
L498
EXIT_STATUS
something
reason
getUpdatedBatchJob
docs
early
exit
return
None
-999
issue
toil
]
https
//github.com/DataBiosphere/toil/pull/2959
issuecomment-584207037
branch
comment
bottom
None
None
jobs
responds
scontrol
scontrol
show
job
slurm_load_jobs
error
Invalid
job
id
Cromwell
behavior
same
Cromwell
case
sort
duck
floats/ints
reasonable
workflows
error
Cromwell
Toil
comment
comment
spec
TODO
concerned
stdout
str
bytes
generated
code
right
comment
difficult
newbies
people
code
long
time
translate
Use
frm.dashboard
progress
dialog
progress
ignore
permission
flag
bucket
name
bucket
lines
code
suggestion
conn.create_bucket
Bucket=bucket_lower
CreateBucketConfiguration=
'LocationConstraint
self.region
need
ClientError
frappe.throw
_
Unable
bucket
unique
name
.format
bucket_lower
head_bucket
access
bucket
exception
pretty
redundant
suggestion
frappe.throw
_
Forbidden
Do
permission
access
bucket
.format
bucket_lower
flag
suggestion
comments
suggestion
exception
error
code
equal
much
whitespace
left
use
frappe.db.exists
above
possible
code
work
E303
many
blank
lines
comments
clear
correct
appropriate
answer
i.e
point
comment
clear
simultaneous
statistics
derived
stats
points
bounds
properties
DimCoords
useable
docstring
*
setter
*
xxx
=
property
Coord._xxx_getter
_xxx_setter
experiment
same
help
print
coord.xxx.__doc__
Results
>
>
print
iris.coords.Coord.points.__doc__
coordinate
points
values
NumPy
array
>
>
print
iris.coords.Coord.bounds.__doc__
coordinate
values
NumPy
array
None
bound
values
..
note
shape
bound
array
points.shape
+
n_bounds
>
>
print
iris.coords.DimCoord.points.__doc__
coordinate
points
values
NumPy
array
>
>
>
>
>
iris.coords.DimCoord.bounds.__doc__
iris.coords.Coord.bounds.__doc__
True
>
>
>
iris.coords.DimCoord.points.__doc__
iris.coords.Coord.points.__doc__
True
>
>
>
Results
new
>
>
print
iris.coords.Coord.points.__doc__
coordinate
points
values
NumPy
array
>
>
print
iris.coords.Coord.bounds.__doc__
coordinate
values
NumPy
array
None
bound
values
..
note
shape
bound
array
points.shape
+
n_bounds
>
>
print
iris.coords.DimCoord.points.__doc__
None
>
>
>
print
iris.coords.DimCoord.bounds.__doc__
None
>
>
>
wrap
right
change
behaviour
comment
appropriate
PR
New
simple
context
FuncFormatter
input
function
Oops
Could
'chunks
section
docstring
Biggus
magic
number
different
sets
conventions
'chunks
value
returns
*
None
*
wrong
'chunks
keyword
*
None
'contiguous
comments
E501
line
characters
E501
line
characters
suggestion
testcase
empty
slices
documentation
age
necessary
attributes
Sorry
original
data
fill-value
*
ignored
*
worth
implementation
iteration
explicit
indication
division
ints
code
clarity
code
tidier
clear
old-fashioned
approach
'np.float
explicit
statement
summation
multiple
dimensions
axes
E.G
alternatives
>
=
np.ones
>
array
[
[
[
]
]
]
]
[
[
]
]
]
]
>
>
np.sum
axis=1
array
[
[
]
]
>
>
np.sum
axis=-1
array
[
[
]
]
>
>
np.sum
>
>
>
np.sum
axis=
array
[
]
>
better
way
okay
+
least
'axis
parameter
prescribed
numpy
manner
point_counts
np.prod
array.shape
/
np.prod
dask_result.shape
lbdreyer
Minor
end
comment
extra
comment
something
arrays
masked
points
points
bounds
lazy
real
good
test
data
points
same
Better
np.arange
.reshape
😉
HPC
comment
bit
specific
Met
Office
Could
general
platform
internet
access
something
timeout
call
platform
internet
access
above
comment
MaskedConstants
lack
distinction
NumPy
scalar
values
e.g
scalar
arrays
e.g
np.array
dtype=np.float64
asanyarray
line
Nice
test
comments
test
pp-mo
Minor
point
Just
terminology
previous
[
comment
]
https
//github.com/SciTools/iris/pull/3255/files
diff-066f828420b27bfd2a03868477b98415R1608
Land-masked
compressed
fields
pp-mo
format
strings
runtime
arguments
in-scope
runtime
problem
line
coordinates
*
*
version
[
]
https
//github.com/SciTools/iris/pull/3127/files
r207562522
minimal
changes
main
branch
tests
need
list
Can
line
Did
comment
simplest
way
clearer
explicit
copy
i.e
old_unit
=
self.units.copy
Remember
original
unit
work
pelson
comment
test
beside
work
diff
diff
git
a/py3status/modules/volume_status.py
b/py3status/modules/volume_status.py
index
..
a/py3status/modules/volume_status.py
+++
b/py3status/modules/volume_status.py
@
@
-251,6
+251,7
@
@
class
PactlBackend
AudioBackend
output
=
[
pactl
list
]
.strip
try
state
perc
self.re_volume.search
output
.groups
=
==
yes
AttributeError
state
perc
=
None
False
device
unset
@
@
-259,12
+260,6
@
@
class
PactlBackend
AudioBackend
self.device
=
self.get_default_device
self.update_device
[
]
==
=
False
return
perc
def
volume_up
delta
part
Examples
docstrings
other
modules
examples
ha
comments
much
better
self.gaps_module_options
name
self.i3_gaps_module_options
comment
definition
everything
code
things
super
clear
aside
background
fine
classic
i3-bar
time
border
issues
practical
_get_color
border
fix
alpha
channel
uncommented
Github
spaces
comments
Many
other
websites
Internet
legacy
practice
shortcomings
typewriters
fonts
Anyhow
changes
Ready
current
approach
cases
TODO
module
TODO
Could
example
examples
discriptions
able
paste
examples
config
api_keys
docstring
good
short
line
other
places
SAMPLE
DATA
ERROR
title
second
screenshot
Tip
Never
full_text
=
None
composite
empty
velib
dict
data
full_text
=
None
format
=
station
|No
Velib
Velib
thresholds
times
datetime.fromtimestamp
Chance
users
efficient
placeholders
first
variables
station
....
unrelated
variables
station
self.placeholders
index
code
index
thing
velib_data
index
self.station_index
Opinion
stations
More
clean
special
stations
manipulate
number
stations
Sorry
Internet
Comment
small
file
self._parseModels
anything
None
real
need
value
suggestion
stack.getTop
stack.getTop
Comparison
none
empty
list
pre-training
phase
pre-training
phase
pre-training
phase
pre-training
phase
pre-training
phase
pre-training
phase
pre-training
phase
Good
catch
minor
detail
sure
importance
possible
comments
length
limit
methods
generator
files
such
random_tree_generator.py
tuple
current_sample_x
current_sample_y
inconsistency
API
elements
same
semantic
extra
method
*
*
temporal
data
stream
*
*
tuple
list
same
data_stream
classes
variations
docstring
more
information
@
garawalid
same
case
data
cases
docstring
data
None
jacobmontiel
code
data_stream
temporal_data_stream
@
same
happen
data_stream.py
streams
idea
@
jacobmontiel
Pass
parameters
parent
class
available
Nit
Todo
note
commented
code
correct
behaviour
has_event_handler
filtered
events
Same
code
teston
correct
behaviour
filtered
events
nit
code
possible
context
manager
behaviour
context
manager
decorator
[
contextlib
]
https
//docs.python.org/3/library/contextlib.html
following
python
context
lib
import
contextmanager
@
contextmanager
def
attach
engine
model
optimizer
output_transform=lambda
output
output
num_iter=None
end_lr=10
step_mode=
exp
smooth_f=0.05
diverge_th=5
DO
ALL
THE
ATTACHING
STUFF
yield
self
self.detach
self._engine
suggestion
lr_finder
Anyway
user
lr_finder
multiple
times
different
arguments
__init__
parameters
line
support
suggestion
lr_finder.attach
trainer
model
optimizer
trainer_with_lr_finder
nit
part
way
epoch
same
precision
L180-L181
python
self._true_positives
torch.cat
[
cast
torch.Tensor
self._true_positives
]
dim=0
=
torch.cat
[
cast
torch.Tensor
self._positives
]
dim=0
comment
tomorrow
comment
detach
output
other
classes
output
output
]
.detach
output
]
.detach
gards
nit
calls
false
nit
>
TIME_ITERATION_COMPLETED
^
score_function
y
indices
good
point
thank
check
initial
feeling
coordinate
refers
single
entry
vector
coordinates
multiple
entries
whole
vector
wrong
native
speaker
tomorrow
same
reasoning
dimension
recursive
iteration
higher
dimensional
space
algorithm
check
suggestion
def
to_hiplot_experiment
max_list_elements
int
>
tp.Any
typing
Hiplot
hard
requirement
name
commented
code
specific
test
cases
name
quite
confident
experience
....
D
most
people
dummy
time
name
optional
parameter
suggestion
def
__init__
model
pyomo.Model
name
tp.Optional
[
str
]
=
None
>
None
name
available
string
case
second
argument
first
important
aspect
model
description
experiment
way
users
anything
benchmarks
list
comments
meaning
functions
definitions
Chain
classes
function
weird
bugs
s
getattr
obj
__name__
Dict
*
real
*
dict
whereas
UserDict
dict
data
attribute
same
methods
one
MRO
second
one
UserDict
effect
UserDict
first
MutableMapping
Bare
😨
purpose
first
item
numpy
arrays
comment
k
v
x
y
p
few
details
documentation
able
parameters
suggestion
isotropic
bool
isotropic
version
EMNA
True
i.e
identity
matrix
Gaussian
separable
version
diagonal
matrix
Gaussian
anisotropic
naive
bool
set
False
noisy
problem
best
points
average
final
population
notice
sense
way
naive
default
True
thee
whole
docstring
first
line
lines
initial
Classifier
init
line
line
equivalent
second
shorter
easier
pure
array
self.random_state.normal
size=1
enough
isnt
lot
optimizer
groups
suggestion
init
=
np.random.RandomState
seed=next
seedg
.uniform
arity
-0.5
size=nv
instrum
=
ng.p.Array
init=init
arity
-0.5
type
ignore
half
mutation
nothing
Prefer
Path
os.path
python
pathlib
import
Path
path
=
Path
__file__
.with_name
headrgb_olivier.png
DOC_BASE_4
line
comment
wrong
R2xR
shape
policy_dim
policy_dim
array
shape
way
unnecessary
reshape
structure
problem
classes
similar
base
class
base
class
code
additional
class
env_name
possible
policy_dim
possible
class
variable
classes
attributes
state_std
policy_dim
need
__init__
more
explicit
discretization
clear
@
thought
TODO
following
good
>
+inf
point
lower
better
name
non_measurable
term
more
precise
scrambled
len
price
-1
end
indices
list
list
loop
indices
len
price
ones
range
line
Kind
detail
math.cos
np.cos
scalars
interested
code
code
loop
numpy
arrays
readable
opinion
comment
energy
usage
thermal
power
plants
cost
factor
Constant
Move
__init__
top
method
class
parameters
infra.py
sure
same
most
parameters
init
function
hardcoded
constants
horizon
number
plants
suggestion
front
=
front
key=lambda
x
x.loss
type
ignore
comments
call
comment
intuitive
Dont
uid
mutate
Nit
easier
Parameter
class
Parameter.from
x
deterministic
continuous
property
class
nit
hardcoded
strings
constants
same
self._parameters
sigma
]
experimenting
nit
sure
relevant
assert
isinstance
sigma
float
type
ignore
silent
error
fail
description
examples
actual
functions
readd
name
wouldnt
something
np.max
np.maximum
np.array
losses
self._upper_bounds
i.e
maximum
part
bounds
positive
Shoulnt
return
value
smaller
last
comment
report_diagnostic_event
PR
😃
addition
comment
suggestion
try-except
block
explicit
telemetry
try
events.ReportEventStack
name=
obtain-dhcp-lease
dhcp
lease
primary
NIC
PPS
VM
workflow
parent=azure_ds_reporter
Exception
e
report_diagnostic_event
dhcp
lease
'determine
primary
NIC
PPS
VM
restore
due
%
s
%
e
LOG.error
code
comments
code
horizontal
space
available
last
comment
diagnostics
telemetry
delays
nic
suggestion
events.ReportEventStack
name=
wait-for-nic-attach
description=
wait
nic
attach
%
d
nics
%
len
nics_found
parent=azure_ds_reporter
ifname
=
netlink.wait_for_nic_attach_event
nl_sock
nics_found
discussed
offline
ready
happens
platform
nic
VM
nic
netlink
socket
cloud-init
nic
detach
event
netlink
socket
ready
nic
detach
event
netlink
socket
ready
netlink
messages
nic
detach
event
message
cloud-init
scenarios
netlink
socket
creation
ready
comment
information
future
devs
@
aswinrajamannar
Can
comment
VM
primary
NIC
IMDS
WireServer
DHCP
NIC
mechanism
NIC
primary
secondary
case
desired
behavior
VM
DHCP
failure
primary
NIC
comment
https
//github.com/canonical/cloud-init/pull/613/files
r527343165
early
return
logic
future
maintainability
changes
parentheses
long
lines
suggestion
'/dev/disk/by-path/pci-0000:00:00.0'
/dev/disk/by-path/virtio-pci-0000:00:00.0
easier
tuple
.join
udevadm_output
body
test
suggestion
'/dev/disk/by-path/pci-0000:00:00.0
'/dev/disk/by-path/virtio-pci-0000:00:00.0
good
test
thank
use
Mock
s
function
call
suggestion
log
=
mock.Mock
spec=Logger
handle
mock.Mock
passes
parameters
parameters
something
implementation
little
confusing
_isn't_
metadata
logic
dict
couple
parses
statically-defined
dict
indication
first-class
control
flow
case
dict
same
code
twice
different
parameters
function-based
approach
rough
sketch
sort
thing
def
_get_secondary_addresses
cidr_key
str
ips
List
[
str
]
prefix
str
>
List
[
]
cidr
=
nic_metadata.get
cidr_key
cidr.split
'/
LOG.warning
prefix
=
cidr.split
'/
]
ips
metadata
IP
type
return
[
ip
/
prefix
ip=ip
prefix=prefix
ip
ips
]
]
=
[
]
bool
isinstance
ipv4s
list
ipv4s
addresses.extend
_get_secondary_addresses
ipv4s
'24
bool
isinstance
ipv6s
list
ipv6s
addresses.extend
_get_secondary_addresses
ipv6s
'128
return
addresses
type
annotations
additional
clarity
suggestion
Parse
interface-specific
nic
metadata
secondary
IPs
comment
IPv4
secondary
IP
secondary
v4
secondary
v6s
TBH
comment
duplicate
comment
second
occurrence
code
liberal
documentation
error
messages
good
lot
duplicate
code
def
convert_delay
delay
fmt=None
scale=None
fmt
%
s
scale
scale
=
try
delay
fmt
%
int
int
delay
int
scale
ValueError
pass
delay
r
0-9
]
delay
raise
TypeError
[
delay
]
minutes
%
s
%
delay
return
delay
distro_name
==
Convert
integer
seconds
Alpine's
halt/poweroff/reboot
commands
seconds
param
+
delay
==
delay
delay
=
convert_delay
delay
%
s
scale=60
=
[
mode
-d
]
delay
=
convert_delay
delay
fmt=
%
s
scale=1
=
shutdown
mode
]
docstring
variable
kind
granularity
HACKING.rst
[
image
]
https
//user-images.githubusercontent.com/153674/83090476-79db3300-a05e-11ea-889b-ce70b1978db0.png
little
internally-cached
feature_overrides
module
present
cloudinit.features
updated
feature_overrides
suggestion
sys.modules.pop
'cloudinit.feature_overrides
None
reload
cloudinit.features
same
cloudinit.features
problems
other
tests
wow
thanks
importlib
Great
contextual
comments
line
]
https
//github.com/candlerb/cloud-init/blob/bridge-parameters/cloudinit/net/network_state.py
L738
item_params.get
'parameters
params
confusion
documentation
value
good
possible
stacktrace
python-traceback
Traceback
recent
call
last
/usr/local/lib/python3.6/site-packages/cloudinit/cmd/main.py
line
status_wrapper
ret
=
functor
name
args
/usr/local/lib/python3.6/site-packages/cloudinit/cmd/main.py
line
main_init
init.apply_network_config
bring_up=bool
mode
=
sources.DSMODE_LOCAL
/usr/local/lib/python3.6/site-packages/cloudinit/stages.py
line
apply_network_config
return
self.distro.apply_network_config
netcfg
bring_up=bring_up
/usr/local/lib/python3.6/site-packages/cloudinit/distros/__init__.py
line
apply_network_config
dev_names
self._write_network_config
netconfig
/usr/local/lib/python3.6/site-packages/cloudinit/distros/freebsd.py
line
_write_network_config
return
self._supported_write_network_config
netconfig
/usr/local/lib/python3.6/site-packages/cloudinit/distros/__init__.py
line
_supported_write_network_config
renderer.render_network_config
network_config
/usr/local/lib/python3.6/site-packages/cloudinit/net/renderer.py
line
render_network_config
templates=templates
target=target
/usr/local/lib/python3.6/site-packages/cloudinit/net/freebsd.py
line
render_network_state
self._write_network
network_state
target=target
/usr/local/lib/python3.6/site-packages/cloudinit/net/freebsd.py
line
_write_network
self._write_ifconfig_entries
settings
target=target
/usr/local/lib/python3.6/site-packages/cloudinit/net/freebsd.py
line
_write_ifconfig_entries
'netmask
TypeError
NoneType
good
something
something
users
call
caller
target
value
Please
message
case
users
cloud-init
logs
renderer
route
headers
change
curious
cp
better
reason
temporary
file
needs
perms
'owner
arguments
*
permissions
arbitrary
permissions
ownership
user
push_file
temp
file
other
side
'pull_file
pycloudlib
temp
file
race
condition
failure
path
_get_tmp_path
files
extra
process
extra
process
'rm
useful
if/else
clauses
Meeeeeh
half
dozen
other
instance
checking
OO
code
easier
simple
check
one-off
attributes
matter
single
type
terminate
line
image
creation
fixture
wink
reasonable
point
image
snapshot
fixture/IntegrationClient
code
further
reflection
IMAGE_SOURCE
right
name
CLOUD_INIT_SOURCE
good
idea
sure
problem
image
id
text
image
id
image
'tests
platform
exception
idea
future-proofing
sense
other
IMAGE_SOURCE
types
text
obvious
way
image
id
something
prefix
source
type
sense
>
ImportError
>
Could
problems
open
file
least
flush
Hmm
great
point
case
py
contextlib.ExitStack
stack
stack.callback
tmp_file.name
self.push_file
trick
delete=False
context
manager
anything
tmp_file
=
NamedTemporaryFile
w
clearer
built-in
cleanup
>
implementation
little
lazy
concerned
file
/tmp/
case
push
failure
case
concerned
Jenkins
slave
failures
hours
days
awful
lot
files
/tmp
cloud-init
debs
~0.5MB
huge
deal
johnsonshi
Thank
update
today
blacklist_driver
update
tip
master
due
SRU
verification
comment
instance
type
mlx5_core
driver
verification
next
SRU
v3
type
networking
sure
suggestion
Was
change
unrelated
docstring
comment
master
>
>
cloudinit.sources
import
DataSourceHetzner
>
>
>
print
DataSourceHetzner.__doc__
Hetzner
Cloud
API
Documentation
https
//docs.hetzner.cloud/
branch
>
>
cloudinit.sources
import
DataSourceHetzner
>
>
>
print
DataSourceHetzner.__doc__
None
loop
additional
IP
addresses
v4
v6
default
mode
=
true
dhcp6
=
False
dhcp6
=
true
first
ip
addr
list
values
DHCP
ipaddr
inft
[
'ipv4
]
[
:1
]
+
intf
[
'v6
]
]
addresses.append
ip/prefix
[
'addresses
]
=
route
subnet
prefix
Right
addresses
netmask
cidr
value
Let
comment
first
IP
DHCP
additional
IPs
static
addresses
Good
comment
RMC
A
log
message
good
LOG.debug
Editing
interface
file
%
s
iface
%
s
interface_file
interface
list
info.keys
many
times
result
info_keys
=
list
info.keys
loop
bunch
python
iface
data
info.items
iface
lo
i
continue
ipv4
[
]
interface
addrs
continue
disable_NM_ipv6
iface
easier
unit
tests
method
python
ability
easier
anything
comfortable
SED
pretty
easy
file
contents
lines
python
unit
tests
different
contents
expected
results
python
try
contents
util.load_file
interface_file
IOError
e
ENOENT
free
fatal
application
LOG.debug
file
%
s
interface_file
e
'IPV6ADDR
contents
fatal
LOG.debug
file
%
s
IPV6ADDR
interface_file
return
LOG.debug
file
%
s\n
interface_file
commands
single
subp
subp.subp
SED
'-i
subp.subp
[
'systemctl
'restart
]
open
interface_file
f
content
=
f.
debug
message
little
more
verbose
interface
line
i
tox
good
comments
relevance
code
block
eg
whole
intent
module
IPV6
interface
active
reason
communication
PowerVM
hyp
RMC
communication
interface
good
comments
communication
eg.
communication
reason
RHEL
Network
Manager
interface
RMC
state
VM
management
plane
perspective
inactive
RMC
state
VM
inactive
lot
operations
VM
migration
host
Hypervisor
odd
executables
paths
cloud-init
path
executable
system
configuration
PATH
such
cloud-init
'recfgct
log
LOG
little
bit
palatable
code
perspective
PATH
paths
tools
PATHs
'util.subp
paths
apologies
flake8
pylint
PIDOF
=
RMCCTRL
=
RECFGCT
=
SRCMSTR
=
programs
paths
unlikely
system
PATH
RSCT_PATHS
=
[
'/usr/sbin/rsct/bin
'/usr/sbin/rsct/install/bin
'/opt/rsct/bin
'/opt/rsct/install/bin
'/sbin
]
NODE_ID_FILE
=
SRCMSTR_TIMEOUT_SECONDS
def
handle
name
_cfg
_cloud
log
_args
open
'/run/cloud-init/instance-data.json
data_file
ds
=
json.load
data_file
ds_value
=
ds
[
'v1
]
.get
'platform
node
id
first
boot
ds_value
==
log.debug
creation
new
ct_node_id
node
ppaths
=
[
p
p
RSCT_PATHS
p
=
[
t
t
[
RMCCTRL
RECFGCT
SRCMSTR
]
subp.which
t
search=ppaths
log.debug
Missing
required
tools
%
s
orig_path
=
os.environ.get
'PATH
try
suff
orig_path
orig_path
os.environ
'PATH
]
.join
ppaths
suff
refresh_imc
orig_path
None
del
os.environ
[
'PATH
]
os.environ
]
=
orig_path
def
refresh_imc
pretty
sure
global
isnt
necessary
Aman306
changes
LOG
@
smoser
recommendations
log
variable
variable
reference
log
LOG
@
Aman306
new
path
/opt/rsct/bin
/usr/sbin/rsct/bin/
old
path
symbolic
link
previous
comment
/opt/rsct/bin
PATH
variable
fine
comment
full
path
/opt/rsct/bin
user
PATH
variable
rmcctrl
full
path
https
//www.ibm.com/support/knowledgecenter/SGVKBA_3.2/admin/admin_pdf.pdf
_The
rmcctrl
command
/opt/rsct/bin
directory
PATH
full
path
command
line_
@
smoser
@
otubo
FYI
Internally
subp.subp
subp.ProcessExecutionError
Ensure
clear
system
admin
user
action
cloud-init
RMCCTRL
RECFGCT
system
PATH
/opt/rsct/bin
/opt/rsct/install/bin
suggestion
Verify
Azure
DS
blacklist
drivers
distro
networking
object
suggestion
params
parameter
expected
line
header
expected_extra_line
something
useful
=
True
test
parameterisation
msdosfs
codepath
below
test
more
details
Did
https
//github.com/canonical/cloud-init/blob/66b4be8b6da188a0667bd8c86a25155b6f4f3f6c/tests/integration_tests/bugs/test_lp1900837.py
L25
[
]
https
//github.com/canonical/pycloudlib/blob/master/pycloudlib/lxd/instance.py
L215
default
def
restart
wait=True
*
*
kwargs
test
container
AFAIK
issue
VMs
fact
s
wait
cloud-init
failure
general
issue
write_file
target
write_files
lines
sphinx
hyphen
'-
readthedocs
bullet
items
list
See
https
//cloudinit.readthedocs.io/en/latest/topics/modules.html
apt-configure
disable
apt
sources
local
docs
docs
differences
tox
-e
doc
browser
choice
URL
file
///home/
<
your-user
>
/src/cloud-init/doc/rtd_html/topics/modules.html
apt-configure
Additionally
something
schema
rendering
multi-line
white
space
markdown
=
>
RELEASE-updates
text
single
wrapped
line
separate
bullet
points
@
lucasmoura
Monday
post
standup
simple
thing
more
complex
thing
Monday
item
<
distro
>
-mirror
following
bulleted
list
hyphens
order
render
sphinx
documentation
readthedocs
readthedocs
content
generation
tox
-e
doc
browser
something
file
///home/
<
YOUR_USER
>
/src/cloud-init/doc/rtd_html/topics/modules.html
apt-configure
Compare
https
//cloudinit.readthedocs.io/en/latest/topics/modules.html
apt-configure
significant
unexpected
discrepancies
whitespace
damage
docs
CLI
python3
-m
devel
schema
-d
cc_apt_configure
due
//github.com/canonical/cloud-init/blob/master/cloudinit/config/schema.py
L321
Originally
schema
coverage
simple
expectation
property
descriptions
simple
concise
line
detail
single
line
case
need
pre-formatted
content
whitespace
damage
whitespace
smarter
https
//github.com/canonical/cloud-init/blob/master/cloudinit/config/schema.py
L321
]
use
<
pre
>
format
tag
something
places
Let
wrap
bool
exception
callback
True
False
docstring
please
exc_cb
behavior
confuses
something
Callback
retries
SKIP_USERDATA_CODES
token
available
comments
extra
explanation
code
good
something
tuple
copy/paste
keys
DMIDECODE_TO_KENV_MAPPING
DMIDECODE_TO_DMI_SYS_MAPPING
things
easier
obvious
someone
key
dmidecode
idea
python
collections
namedtuple
kdmi=
namedtuple
[
'linux
]
kdmi.__new__.defaults__
=
None
None
DMIDECODE_TO_KERNEL
=
'baseboard-asset-tag
kdmi
'smbios.planar.tag
'baseboard-manufacturer
kdmi
'smbios.planar.maker
'baseboard-product-name
kdmi
'smbios.planar.product
'baseboard-serial-number
kdmi
'board_serial
'smbios.planar.serial
DMI_SYS_PATH
=
/sys/class/dmi/id
def
_read_dmi_syspath
key
kmap
=
DMIDECODE_TO_KERNEL.get
key
None
return
None
dmi_key_path
=
/
.format
DMI_SYS_PATH
kmap.linux
print
i
%
s
%
dmi_key_path
def
_read_kenv
key
kmap
=
DMIDECODE_TO_KERNEL.get
key
None
return
None
print
i
%
s
%
kmap.freebsd
_read_dmi_syspath
baseboard-manufacturer
baseboard-manufacturer
i
/sys/class/dmi/id/board_vendor
i
kenv
-q
smbios.planar.maker
sentence
cursor
index
service
directions
exception
last
comment
version
code
code
docker
logic
existence
*
.crt
files
Client
service
container
Dockerfile
host
filesystem
right
minimal
change
_container
line
sure
git-lfs
base
old
bases
entrypoint
issues
someone
client
update
base
update
discrepancy
Python
git
wrapper
hard
someone
error
message
problem
initializing
dataset
user-facing
vocabulary
Could
git
submodule
necessary
submodule
standard
Gigantum
suggestion
Remove
creds
comment
delay
future
delay
seconds
context
problem
complete
comment
Idle
status.text
Jupyter
Kernel
running
comment
comment
line
fine
default
'vault
lot
complexity
reason
way
ignore
message
details
XXX
test
new
version
easier
reason
versions
recent
least
recent
gtmunit2
visible
UI
gtmunit3
method
same
functionality
verify_package_version
test_add_package.py
call
__verify_package_version
gtmunit
packages
teardown
fixture
test
error
test
assert
False
middle
test
project
creation
project
resources
run
ticket
todo
TODO
PR
comment
commented
code
ticket
%
TODOs
current
task
reminder
something
PR
additional
comment
_why_
corner
case
logic
means
only
time
branch
name
FETCH_HEAD
single
branch
clone
comment
string
literal
comment
intentional
Might
worth
TODO
anything
branches
Branch
Manager
comment
valid
ticket
comment
valid
ticket
TODOs
PR
comment
commentary
subprocess
call
windows
rmtree
otherwise
typo
convention
space
comment
character
sure
chars
line
PEP8
Nit
comments
period
Similar
comment
GoogleAdsClient
top
file
google.ads.google_ads.errors
GoogleAdsException
line
except
GoogleAdsException
ex
Nit
multiple
managers
last
behavior
_create_ad_text_asset
more
param
text
asset
readability
closer
line
line
variable
function
Comments
periods
Same
below
Nit
comments
similar
above
request
server
responsive
search
ad
though
general
simplistic
comments
retrieval
function
Could
https
//github.com/googleads/googleads-dotnet-lib/blob/master/examples/AdWords/CSharp/v201809/AdvancedOperations/AddDynamicPageFeed.cs
more
comments
example
clearer
reader
link
reference
Kind
weird
actual
existing
app
endorsement
something
generic
API
input
sentence
Other
settings
per-ad
basis
context
different
more
explicit
other
settings
single
quotes
double
quotes
campaign_experiment.resource_name
%
s
nitpicky
pydocs
simple
methods
examples
purpose
apparent
Most
existing
examples
push
previous
comment
\
continuation
service
path
resource
name
place
case
formats
future
example
https
//github.com/googleads/google-ads-python/blob/2e11de5f0edbb561b6c186aeef95a5605336723a/examples/basic_operations/add_responsive_search_ad.py
L38
nit
build
construct
set
prev
comment
ditto
currency
comment
please
links
documentation
page
literals
*
nitpick
*
Generally
good
conditionals
possible
keywords
page_url
Nitpick
*
conditionals
parenthesis
Applies
comment
link
line
relevant
Is
hypothetical
world
elif
extra
set
parens
ambiguity
ie
keywords
page_url
consistent
delimited
quotes
status
result
values
useful
complex
async
interface
sync
main
benefit
MutateJobService
likely
reader
sync
call
comment
line
required=True
default=
[
]
many
comments
more
rows
information
media
file
Add
spaces
parameters
letter
variable
names
code
easier
category
c
spaces
parameters
rest
function
declarations
space
indentation
space
indentation
comment
lines
.feed_item_path
full
resource
name
whereas
feed_id
~
feed_item_id
nit
s/constructs/Constructs
example
AttributeError
'GRPCIterator
object
attribute
line
comments
state
obvious
next
comment
preferable
trivial
comment
line
consistency
*
nit
*
actual
utility
samples
examples
directory
something
recognizable
standard
library
uuid
easier
user
field
part
printResults
method
https
//github.com/googleads/google-ads-php/blob/master/examples/ErrorHandling/HandlePartialFailure.php
L201
resource
names
Golden
optional
parameters
marketing_image_asset
square_marketing_image_asset
https
//github.com/googleads/google-ads-php/blob/3dc0d995dd292a3cb77671917da6528011f7a3d2/examples/AdvancedOperations/AddSmartDisplayAd.php
L89
nit
combine
start
/
end
date
comments
golden
ad_group.status
PAUSED
General
comment
temporary
variables
hierarchy
message
YMMV
fine
ways
samples
style
preference
class_def_src
stringified
definition
enum
example
[
]
https
//github.com/googleads/google-ads-python/blob/2e11de5f0edbb561b6c186aeef95a5605336723a/google/ads/google_ads/v3/services/enums.py
L163
assertion
string
'class
AccessRole
enum
example
outer
class
name
AccessRoleEnum
pattern
majority
API
enums
]
https
//github.com/googleapis/googleapis/blob/master/google/ads/googleads/v3/enums/access_role.proto
L31
outer
message
FooBarEnum
inner
enum
FooBar
few
cases
enums
Operations
example
[
FeedAttributeOperation
]
https
//github.com/googleapis/googleapis/blob/bf839ae632e0f263a729569e44be4b38b1c85f9c/google/ads/googleads/v1/resources/feed.proto
L175
inner
enum
Operator
assertion
patter
'class
Operator
enum
assertion
operator
cases
Nice
test
verify=False
works
Please
import
golem_messages_.constants
+1
SLEEP_TIME_AFTER_SPAWNING_OR_KILLING_PROCESS
test
least
seconds
possible
validation
isinstance
golem_message
message.CannotComputeTask
validate_id_value
golem_message.task_to_compute.compute_task_def
[
'task_id
]
'task_id
redundant
check
latter
isinstance
golem_message
message.TaskToCompute
message.TaskFailure
golem_message.compute_task_def
]
raise
Http400
task_id
blank
TaskFailure
compute_task_def
TaskFailure
msg
AttributeError
golem_message.compute_task_def
[
'deadline
]
=
validate_int_value
golem_message.compute_task_def
[
'deadline
]
redundant
sure
weather
TaskFailure
present
int
https
//github.com/golemfactory/concent/issues/286
issuecomment-382278207
comment
something
line
Otherwise
clear
computed_task_def
whole
need
individual
fields
whole
TaskToCompute
message
inside
unchanged
same
signature
subtask_id
message
queue
timestamp
ack
message
allowed
range
example
past
client
able
use
assertIsNone
readable
Do
queue
field
PendingResponse.Queue
enum
difference
yes
problems
mypy
ignore
Plase
Exception
other
way
pylint
exception
test
fail
fine
test
failure
error
specific
exception
types
Stuff
SyntaxError
TypeError
top-level
catch-all
handler
comprehensive
different
kinds
errors
empty
line
down
L242
false
kinds
kind
attributes
template_entities
L249
Just
case
order
log
consistent
formatting
keys
readable
pid
process
ID
proj
below
descriptive
consider
somewhere
comparison/reuse
static
old_scc.users
None
got_users
old_scc.users
]
chunk
own
method
thoughts
*
*
REQUIRED
*
*
*
REQUIRED
*
*
more
info
logging
entries
project
name
template
name
case
logs
greppable
*
*
REQUIRED/QUESTION
*
*
kind
exception
least
Sprout
exceptions
failure
*
*
REQUIRED
*
*
Same
Shriver
REMOVE
ME
environment
TODO
FIXME
temporary/workaround/etc
link
paper
https
//ieeexplore.ieee.org/document/7424299/
accuracies
>
learn
weights
nit
lower
case
log
reg
comment
case
..
sentence
period
sentence
portion
nit
Crowdsourcing
common
technique
mess
comment
comment
indices
verb
tokens
sentence
comment
more
comments
e.g
valid
noun
synonym
None
let
separate
set
LFs
sentence
snorkel.classification.task
import
ce_loss
softmax
important
f1_micro
one
haha
suggestion
environment
variable
TRAVIS
]
utils.py
import
TRAIN_DIR
nit
sure
state-of-the-art
ResNet
anymore
tricky
image
download
woes—but
cool
few
examples
nit
extra
comma
>
imbalance
classes
_Due
class
imbalance
chosen
relationships_
comment
operation
prediction
features
comment
operation
image
features
word
embeddings
comment
operation
word
embeddings
subject
object
categories
comment
define
feature
extractors
union
subject
object
image
crops
Qi
comment
command
form
e.g.
verify-next-image
>
Unable
cause
previous
reboot
[
]
length
=
Unexpected
reboot
sample
PR
comment
Suggest
Click
entrypoint
command
name
def
ssdutil
need
flag
optional
parameter
line
other
SONiC
commands
optional
parameter
present
e.g.
show
container
feature
autorestart
swss
output
container
present
e.g.
show
container
feature
status
containers
look
file
many
examples
style
help
statement
command
Please
brief
explanation
command
need
group
definition
@
cli.group
name='container
multiple
container
features
autorestart
command
group
couple
groups
show
container
feature
autorestart
way
other
things
container
feature
groups
future
Provide
example
E.g.
group
show
container
reader
nesting
need
group
definition
@
container.group
name='feature
comments
python
doc
necessary
necessary
Typo
teh
global
variable
local
comment
necessary
[
]
length
=
extra
blank
>
tempDict
[
]
length
=
better
name
Please
space
=
colons
tempDict
[
neighbor_dict
[
port
]
[
]
]
=
'localPort
port
neighbor_dict
[
port
]
[
'port
]
comment
expected
command
function
'neighbor
subcommand
show
>
p2
[
]
length
=
same
>
show
[
]
length
=
Suggest
command
line
show
future
other
subcommand
reality
show
arp
show
interfaces
lldp
Add
spaces
==
Add
space
=
docstring
Click
library
help
message
command
descriptive
better
description
migrate
data
entries
interface
table
use
comments
regex
simple
state
machine
menuentry
comment
menuentry
image
grub.cfg
s/has//
use
case
change
issuer
long
run
Could
part
code
changes
comments
changes
comments
daemon_base.py
class
sonic-utilities
part
HOST
similar
class
line
unnecessary
bgp
cli
group
decorator
line
unnecessary
bgp
cli
group
decorator
line
line
unnecessary
bgp
cli
group
decorator
line
Suggest
change
comment
Ensure
interfaces
'alias
key
PORT
dict
comment
helper
function
connecToLine
similar
long
function
easier
command
THis
>
lowercase
h
enable
route
cache
quagga
show
bgp
ipv4
neighbor
Same
comment
>
[
]
length
=
Add
blank
char
code
script
[
]
length
=
Add
blank
char
@
renukamanavalan
delConfigToLoad
DB
results
crash
orchgent
syncd
system
inconsistent
state
db
correct
crash
risk
today
wrong
config
DB
crash
rollback
config
push
DB
warm-reboot
SWSS
syncd
part
effort
Main
Function
PR
@
renukamanavalan
comment
place
code
main
function
purpose
file
bit
confusing
standalone
executable
script
classes
other
scripts
sense
code
non-executable
library
file
executable
script
directory
scripts/
directory
directory
files
subcommands
config
command
Suggest
imports
ordering
issues
import
re
import
syslog
imp
import
load_source
json
import
load
os
import
system
time
import
sleep
tsleep
import
sonic_yang
swsssdk
import
ConfigDBConnector
SonicV2Connector
<
Add
clear
comment
>
load_source
'/usr/local/bin/sonic-cfggen
sonic_cfggen
import
deep_update
FormatConverter
s/print/syslog
only
place
i/p
arg
ports
loadDefConfig
False
arg
help
Sure
prints
interactive
mode
python-click
interactive
more
Syslogs
less
MSGs
appear
screen
parameter
sum
decimal
numbers
binary
digits
Parameters
int
decimal
integer
b
int
decimal
integer
Returns
binary_sum
str
Binary
string
sum
b
word
suggest
tablesWithoutYang
word
suggest
allowTablesWithoutYang
lowercase
o
case
occurrences
file
entire
code
way
Exceptions
code
last
outer-most
function
meaningful
message
internal
exception
Python
doc
stream
comments
syslog
Notice
msg
library
read\writes
config
DB
functions
sonic-cfggen
ConfigDBConnector
sonic-cfggen
load_source
only
way
.py
extension
better
way
exists
Thx
python-click
config
command
new
process
process
new
class
instance
breakOutPort
case
today
good
Example
generate_args
'2x50G
output
'Ethernet8
'Ethernet9
'Ethernet10
]
[
'Ethernet8
]
'lanes
'73,74
'lanes
'75,76
generate_args
output
'Ethernet8
]
[
'Ethernet8
'Ethernet9
'Ethernet10
]
'lanes
'73
'lanes
'74
'lanes
'75
'lanes
'76
Write
Json
iconfig
dconfig
function
update
configDB
Assume
conf
current
config
ConfigDB
ConfigDB
[
format
mod_config
]
configDB
conf
dict
end
function
i.e
conf
dict
conf+uconf
delConfig
addConfig
Add
TODO
function
sonic-py-common
Remove
space
'errors
subcommand
show
counters
errors
Change
'state
subcommand
'config
feature
state
acl
other
show
commands
acl
table
show
acl
rule
show
runningconfiguration
acl
consistency
unused
code
line
breakup
table
header
data
below
table
please
description
command
parameters
output
big
picture
tool
sort
table
rule
name
sure
current
behavior
expected
one
mirroring
data
i
case
table
additional
configuration
info
change
comment
IP
address
comment
such
TODO
Stub
place
body
Click
underscores
hyphens
subcommand
is-armed
change
comment
backward-compatibility
older
versions
Click
name
name
parameter
I.e.
'is-armed
subcommand
@
'is-armed
same
applies
get_remaining_time
subcommand
'is-armed
'get-remaining-time
commands
'status
command
armed
status
time
watchdog
line
main.py
LGTM
alert
function
something
def
get_client
project_id=None
client
project.
project_id
return
bigquery.Client
project=project_id
raise
RuntimeError
project
client
rows
PID
question
file
need
drug
class
table
staticmethod
required_lab_test.py
only
new
comment
docstrings
single
line
summary
statement
blank
line
more
descriptions
parameter
definitions
Just
separate
sections
blank
lines
[
pep-257
]
https
//www.python.org/dev/peps/pep-0257/
[
Pep-8
docstrings
documentation
]
https
//www.python.org/dev/peps/pep-0008/
documentation-strings
pep-257
counter
following
i
table
enumerate
FITBIT_DATE_TABLES
.....
self.get_sandbox_tablenames
i
out
environment
utils.bq.py
lines
25-35
utils.bq
import
JINJA_ENV
lines
pandas
pandas
helper
function
column
custom
functions
[
post
]
https
//stackoverflow.com/questions/50947447/convert-values-of-a-column-in-pandas
interpreter
pandas
pd
dataframe
df
=
pd.DataFrame
[
[
'P111
]
[
'P222
]
[
'P333
]
]
columns=
[
'pid
]
view
dataframe
df
view
dataframe
info
df.info
verbose=True
define
custom
function
def
participant_id_to_int
pid
return
int
pid
]
custom
function
df
[
'pid
]
=
df
[
'pid
]
.apply
participant_id_to_int
view
dataframe
df
view
dataframe
info
df.info
verbose=True
transformation
dataframe
column
index
participant_id
test
get_deactivated_participants
store_participant_data
functions
part
integration
test
tested
code
table
BigQuery
sure
test
code
functions
only
part
test
response
RDR
API
@
mock.patch
'utils.participant_summary_requests.requests.get
partial
patch
file
call
assumption
more
documentation
convention
few
higher
level
comments
important
purposes
integration
test
behavior
table
subset
suffice
tables
feels
bit
change
detector
test
e.g
transform
particular
table
likely
test
test
breaks
likely
set
tables
transform
association
data
test
more
individual
test
cases
specific
scenarios
difficult
expectations
original
data
understand
intent
assertion
way
test
more
table_infos
initial_values
inline
base
test
query
problems
cross-references
model
mark-velez
Actually
comment
Stream
Handler
matter
Stream
handlers
fine
/
great
/
user
code
command
line
script
cron
job
other
automated
action
stream
handler
command
line
flag
command
line
setup
clean
cdr
engine
module
logging
setup
difficult
log
line
lines
console
looks
log
messages
log
files
hard
test
file
import
import
tools.exclude_site_submission
ess
utils
import
pipeline
setup
yours
fake
module
logger
=
pipeline_logging.get_logger
__name__
logger.info
Random
logging
message
==
logger.info
STARTINGGGGGGGGG
code
module
ess.main
'/Users/lbiggers/.keys/aou-res-curation-test-me.json
'aou-res-curation-test
'lrwb_aou_ehr_ops_test
[
'ca
]
logger.info
DONEEEEEE
code
separate
log
files
logs/__main__.py
logs/tools.exclude_site_submission.log
files
lines
logs/__main__.py
other
module
module
other
file
console
stream
conciousness
type
logging
log
files
single
log
file
interwoven
log
statements
restriction
lines
logger.addHandler
.addHandler
Similar
portion
[
cookbook
]
https
//docs.python.org/3/howto/logging-cookbook.html
logging-to-multiple-destinations
issues
setup
next
test
part
[
standard
context
manager
]
https
//docs.python.org/3.7/library/unittest.html
unittest.TestCase.assertLogs
RDR
project
project
names
public
result
error
property
result
errors
[
LoadJob
]
https
//googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.LoadJob.html
documentation
[
stack
answer
]
https
//stackoverflow.com/questions/57039771/how-to-get-detailed-big-query-error-by-using-python
utility
methods
unit_normalization
instance
result
case
method
return
value
variable
result
=
unit_normalization.setup_rule
client
query_list
=
unit_normalization.get_query_specs
Code
duplication
unit
test
Sorry
sure
idea
run_setup
client
above-
suggestion
suggestion
self.assertRaises
RuntimeError
c
self.query_class.setup_rule
None
self.assertEqual
str
c.exception
BigQuery
client
object
unable
comment
due
rebases
>
calbach
days
Member
feels
single
test
case
test
class
restrictive
whole
thing
helper
method
name
subclass
test
e.g
expectations
test
output
expectations
parameter
base
class
definition
>
@
lrwb-aou
lrwb-aou
hours
•
Author
Member
No
OOP
perspective
method
test
default
method
Meaning
tests
class
method
method
class
new
definition
pass
body
point
class
method
additional
tests
additional
tests
class
reasonable
grasp
OOP
comment
experience
test
cases
base
classes
initial
impression
comprehensive
test
more
scenario
Test
naming
tracing
model
extra
tests
subclass
awkward
above
test
setup
whole
unit
test
single
test
case
ideal
end
state
large
number
child
test
cases
default
behavior
pattern
reasonable
boilerplate
skeptical
sufficient
happy
wrong
Please
consideration
fine
as-is
nit
sense
documentation
exhaustive
such
sampling
valid
keys
instance
logic
constants
e.g
[
first
constant
file
]
https
//github.com/all-of-us/curation/blob/develop/data_steward/common.py
L4
mistakes
several
dogmatic
arguments
e.g
hardest
logic
constants
way
code
constants
man_facepalming
constants
more
substitutes
literal
values
good
idea
group
constants
person-to-observation
step
dict
pto_concept_id
extra
care
keys
dict
literals
[
]
future
reusability
example
concept
id
gender
easy
way
constant
variables
e.g
GENDER_CONCEPT_ID=4135376
enumeration
[
smells
]
https
//martinfowler.com/bliki/CodeSmell.html
little
facepalm
moment-
difficulty
[
client
code
ehr_union_test
]
https
//github.com/all-of-us/curation/pull/136/files
diff-5e001260be368659bdb3a2b698df77d0R296
multiple
assignments
something
here-
please
further
person
new
bq
module
old
bq_utils
new
bq
module
helper
function
re.match
DEID_REGEX
date_row.dataset_id
match
True
match
false
design
rationale
Are
somewhere
line
Nishanth
get_sandbox_dataset
function
sandbox
dataset
function
reason
issues
function
bug
20-24
create_sandbox_dataset
project_id
dataset_id
raise_error=True
try
create_dataset
project_id=project_id
dataset_id=sandbox_dataset_id
friendly_name=friendly_name
description=description
HttpError
err
err.code
=
raise
raise_error
return
sandbox_dataset_id
dataset
dataset
error
default
error
dataset
change
lines
271-279
create_sandbox_dataset
date_row.project_id
date_row.dataset_id
safe
module
unsure
python
dictionary
key
query_dict.get
'key
<
default_value
>
key
dictionary
default
value
None
default
value
KeyError
>
>
d
=
>
>
>
=
d.get
>
>
print
]
module
lot
queries
retraction
queries
create_queries
pass
client
create_queries
function
other
client
creation
method
different
comment
first
module
dataflow
[
job_config
]
https
//googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.client.Client.html
google.cloud.bigquery.client.Client.query
query
table
[
job_config
api
documentation
]
https
//googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.QueryJobConfig.html
google.cloud.bigquery.job.QueryJobConfig
line
depends
table
suggestion
additional
refactoring
function
arguments
parsed
arguments
parse_args
raw_args=None
parser
definition
code
parser.parse_args
raw_args
def
main
args=None
args
=
parse_arguments
args
query_list
=
create_queries
args.project_id
args.ticket_number
args.pids_project_id
args.pids_dataset_id
args.pids_table
run_queries
query_list
logging.info
'Retraction
complete
==
main
approach
module
same
command
line
python
module
research_id_df.empty
logging.info
f'no
research_id
person_id
pid
return
else
statement
unnecessary
return
empty
string
same
None
conditional
statements
get_pids_datasets_and_tables
uses
query
SELECT
table_name
FROM
project
dataset
.INFORMATION_SCHEMA.COLUMNS
COLUMN_NAME
=
query
SELECT
table_name
FROM
project
dataset
.INFORMATION_SCHEMA.COLUMNS
identical
BigQuery
results
second
query
lists
pids_tables
list
useless
list
tables
person_id
tables
'DATE
field
test
project
results
bigquery
calls
get_pids_datasets_and_tables
bigquery
calls
get_table_info_for_dataset
minutes
something
as
clean
possible
few
calls
possible
time
account
actual
retraction
queries
time
queries
functions
test
project
nit
statement
Dataframe
creation
complete
rest
incomplete
thought
responses
loop
outside
list
variable
list
response
objects
list
response
objects
sure
exceptions
response_list
list
response
objects
resp
response_list
resp.result
resp.exception
statements
exception
aggregation
desired
custom
code
job
errors
job
nit
grammar
nit
spelling
teh
comment
log
statement
same
comment
necessary
nit
something
comment
thought
process
possible
conditional
logic
statements
easy
pd.isnull
date_row.date_column
queries
end_date/start_date
statement
date
field
query
generation
statement
isnull
False
pid
pid
None
empty
string
string
python
BigQuery
failure
reason
get_research_id
returned
None
empty
string
queries
function
False
BigQuery
BigQuery
exception
catch
return
value
SELECT
COUNT
*
count
FROM
aou-res-curation-test.lrwb_deid_test_input_20190910.observation
person_id
BigQuery
error
response
google.api_core.exceptions.BadRequest
name
None
]
SELECT
COUNT
*
count
FROM
aou-res-curation-test.lrwb_deid_test_input_20190910.observation
person_id
BigQuery
error
response
google.api_core.exceptions.BadRequest
Syntax
error
Unexpected
end
script
]
good
question-
person
table
person
records
deactivation
date
turn
person
table
death
table
wrong
Caroline
nit
Finish
parameter
return
info
docstring
pandas
method
good
Always
simpler
ways
logging
logging
module
logging
module
setup
project
log
file
location
s
date
formatting
message
formatting
handlers
lines
query_list
=
create_queries
args.project_id
args.pids_project_id
args.pids_table
run_queries
query_list
logging.info
'Retraction
complete
Retraction
complete
console
nothing
deid
runner
logging
location
console
logger
function
https
//github.com/all-of-us/curation/blob/develop/data_steward/tools/run_deid.py
L40
module
logger
line
=
logging.getLogger
__name__
LOGGER.info
logging
instance
module
new
work
bigquery
client
library
bq_utils
unit
test
worthwhile
information
blank
lists
unit
test
mocked
object
mocked
object
loop
line
none
test
patch
unit
test
return
value
client.query
.to_dataframe
call
rest
function
expected
return
value
parameters
comparison
internals
function
expected
result
test
pattern
same
result
places
result
code
correct
provided
test
error
line
retract_deactivated_pids.py
patch.txt
]
https
//github.com/all-of-us/curation/files/4738011/patch.txt
ChaoPang
help
set
tables
better
name
specific
person_id_validator
tool
context
goal
list
tables
person
ID
rows
provenance
EHR
RDR
@
mark-velez
Do
way
concept/concept_ancestor
tables
environment
better
way
test
data
forced
nullable
approach
test
data
insertion
easier
good
idea
pid_list
=
bq.query
function
better
separation
function
units
easier
purpose
function
records
list
person_ids
current
implementation
things
person_ids
sandbox
records
separate
basic
function
units
easier
writing
tests
instance
integration
test
get_sandbox_queries
correctness
pids_query
list
person_ids
Other
functions
responsible
pids_query
pid_list
=
bq.query
own
cleaning
rule
reason
pids_query
same
way
project_id
dataset_id
pids_query.format
project=project_id
dataset=dataset_id
case
e.g
cleaning
rule
way
pids_query
function
pids_query
jinja_env
utils.bq
comment
easy
copies
sync
interesting
next
difference
iterator
value
list
comment
clearer
new
developers
nit
better
code
function
queries
following
error
recent
call
last
File
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
<
module
>
main
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
main
globals
debugger.run
setup
[
'file
]
None
None
is_module
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
run
return
self._exec
is_module
entry_point_fn
module_name
file
globals
locals
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
_exec
pydev_imports.execfile
file
globals
locals
script
File
/Applications/PyCharm
CE.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py
line
execfile
exec
compile
contents+
\n
file
'exec
glob
loc
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
<
module
>
main
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
main
write_csv_report
args.output_filepath
args.data_stage
args.fields
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
write_csv_report
required_fields_dict
=
format_values
required_fields_dict
fields_list
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
format_values
rules_values
separate_sql_statements
rules_values
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
separate_sql_statements
query_dict.get
AttributeError
'str
object
attribute
same
lines
variables
self.project_id
etc
setUp
delete
tables
tearDown
comments
get_retraction_dataset_ids
get_retraction_submission_folder
Pep
doc
format
line
summary
blank
line
descriptive
summary
paragraph
blank
line
parameter
definitions
expected
return
nit
comment
line
removed
count
nit
dataset_ids
dataset_ids
dataset_ids.split
same
logic
function
test
possible
errors
function
agreement
combined
datasets
function
possible
concept_id
s
non-trivial
first
glance
e.g
multiple
concepts
concept_code
LIKE
%
clear
TODO
relevant
vocabulary
team
REDCap
preferable
CSV
files
Thanks
notebook
lot
checks
define_dataset
function
better
function
consistent
reuse
code
None
bq_utils.create_dataset
None
description
param
overwrite_existing
determine
defaults
want
place
comment
check
suggestion
infinite
loop
_is_raised_from_itself
record
Done
sandbox_queries_list.extend
drop_queries_list
assert
statements
unit
test
comment
param
vs
overwrite_ok
exceptional
cases
standard
cases
fine
separate
test
test
body
tests
simple
xfails
bugs
exceptions
pytest.raises
AttributeError
Bonus
points
match
keyword
arg
words
data
input
loose
text
strict
sure
clear
parameterize
tests
values
different
cross-verify
values
FULL_TXN_DICT
=
'0x1
'0x2
'nonce
pytest.mark.parametrize
transaction_params
FULL_TXN_DICT
FULL_TXN_DICT
'data
'0x0
'0x0
'0x0
'0x0
'0x0
def
test_extract_valid_transaction_params
transaction_params
valid_transaction_params
extract_valid_transaction_params
transaction_params
valid_transaction_params
==
functionality
side-by-side
IMO
coroutines
websockets
different
thread
event
loop
least
https
//docs.python.org/3/library/asyncio-dev.html
concurrency-and-multithreading
states
life
cycle
thread
provider
such
instance
provider
thread
*
thread
*
*
*
loop
function
nitpick
*
single
letter
variables
something
thread
loop_thread
IPCProvider
[
PersistantSocket
]
https
//github.com/voith/web3.py/blob/0970ee3ee5fe1e1fb4fc75ab3521c3c0febefdd8/web3/providers/ipc.py
L33
docs
parity
+
geth
private
net
sparse
part
documentation
+
part
todo
list
change
anything
issue
biggie
way
same
way
note
least
comment
parse_pos
function
least
similar
comment
file
comment
fast
magic
array
assignment
conversion
problem
code
docs
above
example
translate
workflow
usage
function
Changes
timestep
AtomGroup
ts
comment
valid
more
additional
thought
RDKIT
charge
units
anything
specific
docs
users
types
charges
available
Gasteiger
user-read
ones
checks
correct
count
different
order
bonds
order
different
bonds
'trajectory
comment
fresh
AUTHORS
..
/package
AUTHORS
e.g.
sdist
tar
ball
way
unpacked
tar
ball
–
AUTHORS
something
python
try
AtomGroup/Universe
tri_dims
obj.universe.coord.triclinic_dimensions
AttributeError
Timestep
tri_dims
obj.triclinic_dimensions
following
code
windows
python
different
results
pos
=
f.tell
f.seek
f.seek
pos
print
f.tell
TODO
comments
residues
>
residue
default
values
various
parameters
docstring
crucial
extraneous
spaces
Elements
comments
suggestion
self._bat
=
[
]
description
bat
data
structure
actual
attribute
docs
separate
subsection
module
docs
attribute
documentation
comment
_Document
attributes
data_
bat
user
subsection
module
docs
sub
header
..
_bat-datastructure-description
BAT
data
structure
description
attr
BAT.bat
attribute
bond-angle-torsion
coordinates
frames
trajectory
structures
NumPy
class
numpy.ndarray
shape
attribute
text
ref
link
section
attribute
docs
reST
..
autoclass
BAT
members
inherited-members
..
attribute
bat
Bond-angle-torsions
internal
coordinates
trajectory
frames
numpy
array
shape
*
N
N
atoms
class
ag
ref
bat-datastructure-description
details
data
structure
numpy
array
*
list
arrays
lot
easier
more
comments
_conclude
load
/
duecredit
citations
/
load
input
generator
little
efficient
ie
a1.bonded_atoms
....
AtomGroup.indices
numpy
array
little
unwise
list
sake
.index
copy
indices
bare
exceptions
good
idea
function
known
type
error
ValueError
way
numpy
list
comprehension
Things
slow
big
systems
setters/getters
properties
ag
read-only
attribute
suggestion
@
property
def
atoms
atomgroup
BAT
read-only
property
return
section
data
structures
part
class
user
R.bat
first
element
R.bat
[
]
XYZ
full
array
shape
N
case
clear
data
structures
entries
data
structures
_mean_
means
appropriate
equations
references
papers
great
sure
people
papers
p0
p1
p2
same
periodic
image
p1-p2
bond
box
boundary
Rewrite
R.bat
array
comment
pylint
comment
format
known_pos
class
method
Add
comment
DNS
CNAME
etc
previous
https
//www.mdanalysis.org/mdanalysis/
standard
GitHub
setup
gh-pages
repo
top
level
new
correct
DNS
update
comment
Use
–
writer
xtc
fake
trajectory
session-level
fixture
stream
line
@
pytest.fixture
scope=
session
def
membrane_xtc
tmpdir_factory
u
=
MDAnalysis.Universe
Martini_membrane_gro
x_delta
y_delta
=
tmp_xtc
=
tmpdir_factory.mktemp
'streamlines
'dummy.xtc
XTCWriter
tmp_xtc
xtc_writer
i
range
u.atoms.translate
[
x_delta
y_delta
]
xtc_writer.write
u.atoms
y_delta
return
tmp_xtc
def
test_streamplot_2D
membrane_xtc
tmpdir
def
test_streamplot_3D
membrane_xtc
tmpdir
session-level
fixture
separate
file
import
easier
tests
single
test_streamlines.py
class
self
other
fixture
values
dmap
fixture
Please
fixture
Requires
comment
documentation
docs
talk
units
name
observables
h5md
files
observable
lambda
able
_any_
observable
data
h5md
init
data_keywords
“
data.keys
”
copy
step
position
work
float32
array
None
values
right
None
dimensions
method
H5MD
case
self._unitcell
None
assert
sure
_before_
assertion
true
assert
input
checking
message
users
assert
choices
assert
explicit
test
__init__
comm
assert
exception
assert
exeption
clear
error
message
i.e.
preference
–
code
units
units
class
variable
H5MDReader
second
one
units
first
second
units
first
one
lead
difficult
errors
comment
units
instance-level
variable
set
H5MD
file
__init__
self.units
_translate_h5md_units
true
Eg
default
something
sensible
comm
moment
comment
assigns
None
ts.velocities
velocities
ts.velocities
process
’
t
Timestep
velocities
none
self._has
“
velocities
]
setattr
ts
“
velocities
value
method
true
“
”
method
units
frame
__init__
top
documentaton
https
//www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
lot
repetitive
code
small
method
class
level
_data_keywords
=
'time
'lambda
'dt
particle_group
data
=
[
'data
]
name
self._data_keywords
self._copy_data
name
data
ts
more
extensible
kwargs
reader
such
comm=MPI.COMM_WORLD
driver=
mpio
http
//docs.h5py.org/en/stable/mpi.html
trajectory
comment
code
[
H5MD
]
https
//nongnu.org/h5md/h5md.html
simulation-box
specification
simulation
box
group
box
subgroups
particles
group
group
particles
box
error
box
line
function
same
way
script
developer
pyh5md
need
comment
suggestion
test
trajectory
pyh5md
https
//github.com/pdebuyl/pyh5md
'pip
install
pyh5md'
import
pyh5md
ok
ImportError
superfluous
comment
fixme
lipid_head_string
variable
fixture
last
frame
fixture
comment
element
different
things
such
pair
atoms
case
hydrogen
bond
lifetime
atom
ID
water
survival
probability
name
applicable
state
event
survival
probability
Please
preference
Thanks
memory
pytest
approx
grief
past
try
np
testing
equivalent
Good
point
thanks
loop
frames
comment
trajectory
length
comment
test
trajectory
length
increase
Try
split
tests
test
thing
ts
independent
previous
fine
_reader
dt
readers
dt
pickling
def
dt
time
difference
ps
timesteps
Note
defaults
ps
absence
time
data
..
try
return
self.data
KeyError
pass
try
dt
=
self.data
[
'dt
]
=
self._reader
._get_dt
return
dt
AttributeError
pass
warnings.warn
Reader
dt
information
ps
return
motivation
Mention
FileIOPicklable
BufferIOPicklabe
TextIOPicklabe
context
manager
func
open
Btw
function
context
manager
neat
–
anyopen
rid
[
openany
]
https
//www.mdanalysis.org/docs/documentation_pages/lib/util.html
highlight=openany
MDAnalysis.lib.util.openany
_Raises_
_Returns_
[
NumPy
standard
]
https
//numpydoc.readthedocs.io/en/latest/format.html
docstring-standard
[
User
Guide
docs
]
https
//www.mdanalysis.org/UserGuide/contributing_code.html
working-with-the-code-documentation
coords
arrays
non
C
contiguous
Split
tests
See
richardjgowers
comment
multiple
asserts
test
function
harder
Eg
xyz.flat
box
problem
test
breakdown
fan
classes
python
class
TestXTC
object
@
staticmethod
@
pytest.fixture
def
XTC
XTCFile
XTC_single_frame
f
yield
f
def
test_n_atoms
XTC
assert
XTC.n_atoms
def
test_xyc
XTC
lot
imo
XTC
fixture
good
future-proofing
u
keyword
AtomGroup
Universe
achievable
u.universe
AtomGroup.universe
interchangeable
AtomGroup.atoms
Universe.atoms
@
RMeli
couple
PR
selection
other
keywords
standard
AnalysisBase
select
argument
select
strings
effect
actual
attempt
AtomGroup
s
interchangeable
selection
strings
[
prudent
postponement
]
https
//github.com/MDAnalysis/mdanalysis/pull/2375
issuecomment-547187106
due
complexities
UpdatingAtomGroup
suggestion
plot
MSD
respect
lag-time
math
plot
suggestion
segment
MSD
self-diffusivity
second
dtype
same
dtype
line
lag
range
correct
run
step=10
frames
way
information
[
check_slice_indices
]
https
//www.mdanalysis.org/mdanalysis/documentation_pages/coordinates/base.html
MDAnalysis.coordinates.base.ReaderBase.check_slice_indices
@
lilyminium
suggestions
attribute
suggestion
self.n_particles
self._atoms
interest
user
many
particles
calculation
code
symmetrical
relation
self.n_frames
other
suggestion
docs
n_particles
example
image
[
doc/sphinx/source/images
]
https
//github.com/MDAnalysis/mdanalysis/tree/develop/package/doc/sphinx/source/images
https
//github.com/MDAnalysis/mdanalysis/blob/39b6385b358a7b38d52693b2345620292a2b4297/package/MDAnalysis/analysis/dihedrals.py
L90-L100
example
suggestion
dim_fac
_dim
etc
__init__
placeholder
values
transfer_to_memory
viable
many
trajectories
default
approach
unwise
Parameters
__init__
docstring
Attribute
class
docstring
Same
question
re
dtype
next
line
_prepare
AnalysisBase
discussion
iterating
frames
_single_frame
self.n_frames
–
rid
superfluous
variable/two
lines
code
naieve
inline
comment
same
thing
docstring
Ill
test_msd.py
author
info
comments
fixture
names
@
pdebuyl
test
inaccuracies
high
sample
sizes
constant
velocity
trajectory
MSD
y=3x
*
test
architecture
yours
NSTEP
top
file
number
frames
toy
trajectory
decimal=4
error
tolerance
higher
sample
sizes
FFT
MSD
tests
standard
naive
ones
super
super
grateful
bottom
something
simple
tidier
function
See
@
lilyminium
comment
list
same
question
[
0-9
]
characters
Third
test
test
function
test
ans
center
second
test
comment
test
jbarnoud
LinearDensity
parameter
universe
parameters
proper
docstring
comments
data
line
comment
test
branch
pull
request
IOError
Traceback
recent
call
last
ipython-input-10-07ae04b43a93
>
<
module
>
>
u
=
mda.Universe
'permission.denied.xyz
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/core/universe.pyc
__init__
args
*
*
kwargs
err.errno
None
[
]
[
'ENOENT
'EACCES
]
Runs
error
parser
permission/
file
six.reraise
*
sys.exc_info
else
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/core/universe.pyc
__init__
args
*
*
kwargs
try
parser
self.filename
p
self._topology
=
p.parse
IOError
OSError
err
err.errno
None
[
]
[
'ENOENT
'EACCES
]
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/topology/XYZParser.pyc
parse
MDAnalysis
Topology
>
openany
self.filename
r
inf
natoms
=
int
inf.readline
.strip
inf.readline
/usr/lib/python2.7/contextlib.pyc
__enter__
def
__enter__
try
>
return
self.gen.next
StopIteration
raise
RuntimeError
generator
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/lib/util.pyc
openany
datasource
mode
reset
..
SeeAlso
func
stream
=
anyopen
datasource
mode=mode
reset=reset
try
yield
stream
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/lib/util.pyc
anyopen
datasource
mode
reset
ext
'gz
file
last
openfunc
=
handlers
ext
]
stream
=
_get_stream
datasource
openfunc
mode=mode
stream
None
break
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/lib/util.pyc
_get_stream
filename
openfunction
mode
IOError
OSError
err
errno.errorcode
[
err.errno
]
[
'ENOENT
'EACCES
]
six.reraise
*
sys.exc_info
return
None
mode.startswith
r
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/lib/util.pyc
_get_stream
filename
openfunction
mode
Return
open
stream
*
filename
*
*
openfunction
*
else
None
try
stream
=
openfunction
filename
mode=mode
IOError
OSError
err
errno.errorcode
[
err.errno
]
[
'ENOENT
'EACCES
]
/home/jon/Envs/oldnp/local/lib/python2.7/site-packages/MDAnalysis/lib/util.pyc
bz2_open
filename
mode
Open
BZ2
file
mode
=
mode.replace
.replace
b
return
bz2.BZ2File
filename
mode
python
bz2.open
IOError
[
Errno
]
Permission
silly
question
anticipated
size
positions
angles
'Tilts
copy
[
]
input
positions
bit
nit-picky
way
'biscectors
true
biscectors
CA_i
>
CA_i+1
etc
vectors
same
length
plane
bad
assumption
radius
calculation
assumes
better
name
worth
notebook
biscectors
geometry
right
course
wrong
[
]
coordinates
]
D'oh
right
Related
thought
reason
direction
helix
vector
towards
residue
references
least
sense
helix
axis
last
residue
same
direction
local
helix
axes
origin
point
own
local
helix
axis
matters
intuition
upside-down
global
tilt
[
guys
https
//github.com/davecao/biHelix/blob/00f6e3905b0171e604be2edc4c7a61096893b3ea/src/helanal.f90
L367-L374
first
local
origin
point
comment
inaccurate
case
tests
easy
test
comment
*
code
comment
better
code
something
lines
>
PBC
box
information
tinker
files
beginning
frame
box
z
alpha
beta
gamma
box
information
second
value
space
atom
name
box
second
value
pure
numerical
atom
names
understandable
maintainer
ARC_PDB
comment
Are
ts.positions
positions
array
array
integer
latter
former
little
different
Lily
tests
correct
answer
atoms
Around
selection
thing
around-ing
https
//www.mdanalysis.org/docs/documentation_pages/selections.html
geometric
small
box
infinite
loop
[
]
https
//github.com/MDAnalysis/mdanalysis/blob/develop/package/MDAnalysis/lib/nsgrid.pyx
L587
....
commas
Generally
PEP8
same
issue
most
valid
elements
problem
elements
guess_types
MDA
guess
form
case
FF
atom
names
Rather
guess_types
behaviour
use
case
impact
user
code
downstream
Z2SYMB
periodic_table
=
SYMB2Z
list
=
[
elem.capitalize
elem
element
]
elem
periodic_table
elem
elements
attrs.append
Elements
elements
warnings.warn
warning
message
@
lilyminium
comment
elements
attribute
u.atoms
above
comment
indentation
docstring
example
https
//github.com/MDAnalysis/mdanalysis/blob/5f513831301492ffcf054c7b57ee6092bf153c41/package/MDAnalysis/topology/TOPParser.py
L316-L323
Rather
comment
REMARK
section
PDB
PDB_hex
commented
line
Just
sure
atom.segid
integer
*
*
bug
MDAnalysis
exact
issue
appropriate
exception
extension
test
exception
corpus
dir
empty
Please
comment
modules
branch
comment
potential
FIXME
function
bit
more
fine
exception
fix
function
bit
confusing
emulator
predictable
serial
https
//developer.android.com/studio/run/emulator-commandline
ro.serialno=123456
comment
emulator
case
nit
comment
argument
sense
Could
comment
temperature
Fix
comment
method
GET
POST
code
new
circular
import
issue
nice
many
functions
comment
applicable
comment
something
lines
values
existing_fuzzers
comment
condition
GROUP_BY_JOB
code
self.ctx.fuzzer
default
implementation
simple
real
benefit
nothing
vs
showing
first
page
case
Dont
understand
engine_impl
branch
dead
FIXME
TODO
strategy
selection
blackbox
fuzzers
strategy
selection
work
LF
LF
function
case
comments
clearer
unit
testing
best
way
understanding
slow
full
minimization
HTML
Minimizer
job
data
series
sub-minimizers
test
sure
results
right
way
JS
Minimizer
own
unit
tests
tests
Chunk
Delta
minimizers
Nit
comment
formatting
Please
much
possible
line
break
something
bazel
device.start_qemu
method
things
reason
callers
methods
single
one
comment
SupressOutput
feels
hacky
stdout
TODO
something
data_handler
several
_URL
globals
uses
+1
backwards
compatible
possible
places
free
helper
utils.py
src/python/bot/startup/heartbeat.py
sys.exc_clear
src/python/bot/startup/run_bot.py
sys.exc_clear
src/python/bot/tasks/commands.py
sys.exc_clear
need
comment
pretty
self
evident
Let
group
lines
vertical
whitespace
Return
jobs
name
query
=
datastore_query.Query
data_types.Job
query.order
filters.add
query
params
FILTERS
page
=
helpers.cast
this.request.get
'page
int
'page
int
items
total_pages
total_items
=
query.fetch_page
page=page
page_size=PAGE_SIZE
projection=None
more_limit=MORE_LIMIT
second
part
comment
vars
BOT_TMPDIR
INPUT_DIR
CF
func
environment.set_bot_environment
environment.set_default_vars
[
set_bot_environment
]
enough
resources
mkdtemp
logic
gitignore
dirs
conflict
tool
dir
line
line
helper
loop
commands.update_environment_for_job
Assume
kernel
crashes
security
bugs
crash_type.startswith
'Kernel
failure
return
logic
bit
difficult
code
ideal
crash_type
other
testcase
information
crash
type
bugs
'Kernel
failure
crash_type
check
True
comment
bit
confusing
anything
'ASSERT
comment
more
general
lines
Go
Python
Kernel
crash
sanitizer
signal
handler
failures
comment
hard
TODO
comment
AFAICT
complete
CSP
bypass
anyone
code
Nit
>
probability/probabilities
file
Nit
bit
offline
fewer
abbreviations
variable
names
easier
first
glance
comment
necessary
previous
comment
end
line
comment
TODO
shell.get_directory_file_count
fine
temporary
solution
weird
long
term
necessary
other
update_state
function
file
todo
Nit
Could
detailed
comment
context
odd
test
worth
necessary
untrusted
runner
separate
process
nit
correct
spelling
separator
Add
comment
errors
much
word
panic
False
positives
nit
sense
comment
strategy_pool
timeout
LibFuzzerCommon.minimize_crash
example
arguments
TODO
return_code
one
test
smaller
file
nit
comment
little
outdated
AFL
TODO
comment
code
everything
%
TESTCASE
%
new
engine
impl
hacky
remove_directory
plugin
everytime
launcher
instance
sure
unpacked
cases
good
idea
subprocess
loads
unexpected
issues
track
log_error
bool
result
https
//docs.python.org/3/using/windows.html
removing-the-max-path-limitation
TODO
correct
results
lot
cases
datastore
read
reading
=
ndb.Key
data_types.FuzzTarget
testcase.overriden_fuzzer_name
.get
target.binary_name
need
else
branch
result
=
result.replace
%
FUZZ_TARGET
%
target_name
Nit
reference
token_combiner
[
data
]
comments
note
token
combiner
second
sentence
something
cases
combiner
data
way
such
data
Nit
return
testcase.get_current_testcase_data
==
data
ones
unused
constant
exit
codes
nit
convert
TODO
sense
context
syzkaller
comment
comment
TODO
back
temperature
use
case
nit
line
line
comment
one
part
query
cleanest
way
'STRATEGY_SELECTION_DISTRIBUTION
variable
different
experimental
cases
Nit
typo
Just
following
block
code
needs
mock
tests
please
current
version
reupload
build
[
'stable
]
build_revision_mappings
revisions.get_build_to_revision_mappings
platform
build_revision_mappings
return
Impacts
mapping
=
build_revision_mappings.get
return
Impacts
chromium_revision
[
'revision
]
component_revisions
revisions.get_component_revisions_dict
chromium_revision
'default
component_revisions
return
Impacts
result
=
False
import
key
value
six.iteritems
component_revisions
value
'name
value
value
[
'name
]
.lower
==
component_name
branched_from
=
revisions.revision_to_branched_from
value
[
'url
]
value
[
'rev
]
return
Impacts
impact
=
get_impact
'revision
branched_from
'version
mapping
[
'version
]
start_revision
end_revision
[
build
]
=
impact
result
=True
break
result
return
Impacts
need
str
host
var
int
int
int
need
comment
code
obvious
comment
bit
something
default
issue
metadata
preference
specified
issue
metadata
nit
short
comment
free
port
ADDITIONAL_
*
rid
TODO
matches
style
like
ADDITIONAL_ASAN_OPTIONS
Nit
example
similar
comments
clearer
reader
necessary
Nit
end
comments
punctuation
pattern
few
times
condition
worth
kind
helper
comment
return
value
get_path
validation
mapping
overkill
path
function
.xml
argument
returns
None
file
Callers
error
things
nit
inverse
early
exit
indentation
lines
44-47.
nit
better
line
break
return
constants.LKL_REPO_KERNEL_PREFIX
line.split
]
.strip
u\
call
environment.get_value
environment.get_value
'FUCHSIA_RESOURCES_PATH
environ
btw
=
environment.get_value
'FUCHSIA_RESOURCES_URL
fuchsia_resources_url
None
logs.log_error
path
remote
Fuchsia
resources
bucket'
FUCHSIA_RESOURCES_URL
Bail
gsutil_command_arguments
[
'cp
'-r
gcs_resources_url
resources_path
]
url
descriptive
path
comment
L342
nit
TODO
flowerhack
blank
space
beginning
end
docstring
rid
Could
TODO
nit
please
ssh
functionality
private
method
retrying
logic
easier
comment
e.g
@
retry.wrap
def
_test_qemu_ssh
def
fuzz
self.test_qemu_ssh
LibFuzzerCommon.fuzz
Similar
comment
command
IMO
more
straightforward
current
version
nit
fuchsia_resources_url
TODO
cleanup
logic
new
process
run
todo
i
mutations
radamsa
etc
fuzz
method
runner
TODO
nit
move
check
comment
use_mutator_plugin
comment
comment
FYI
right
memory_tool
=
anyway
strategy
object
name
probability
key
attributes
different
constants
.name
little
clunky
entire
strategy
key
dict
booleans
best
fit
set
better
way
something
python
class
StrategyPool
object
def
__init__
self.strategy_names
def
strategy
return
strategy.name
self.strategy_names
mbarbella-chromium
Do
comments
worth
useful
cases
more
clear
line
first
comment
implementation
good
ml
rnn
False
radamsa
case
someone
code
order
something
test
TODO
root
cause
nit
line
comment
line
line
higher
Add
FIXME
Add
support
new_comment
notify
arguments
stop
linting
directory
init
file
comment
lint.py:177
linting
yaml
file
invalid
comment
lint.py:177
linting
file
bad
import
order
comment
lint.py:177
dictionary
dictionary
manager
comment
period
symbol
archive
filename
different
function
target
build_id
get_kernel_info
settings.py
New
line
line
End
comment
period
dot
staticmethod
https
//google.github.io/styleguide/pyguide.html
217-function-and-method-decorators
empty
line
merge_control_file
arg
libfuzzer
specific
code
interface
argument
easier
subclasses
different
path
i.e
def
merge
merge_control_file=None
merge_control_file
subclasses
path
necessary
additional_arguments.append
constants.MERGE_CONTROL_FILE_ARGUMENT
+
merge_control_file
nit
tmp
needed
libfuzzer.py
interface
Please
use
single
quotes
strings
docstrings
line
others
able
labels
=
list
issue.labels
components
Nit
please
end
comments
punctuation
other
parts
file/files
nit
*
//
nit
bit
nicer
python
self.is_json
'application/json
request.headers.get
single
quote
strings
comment
Nit
add
docstrings
handlers
TODO
module
imports
top
stats
afl.stats.StatsGetter.set_strategy_stats
variables
self.generator_strategy
=
None
signify
comment
BOT_ROOT
value
[
'BOT_ROOT
]
warning
message
emitted
BOT_ROOT
COBOT_ROOT
'BOT_ROOT
os.environ
os.environ
COBOT_ROOT
environment
places
Add
support
COBOT_ROOT
Environment
variable
deprecated
Deprecation
*
*
word
warning
same
log
entry
Please
real
words
variable
names
'snake
case
PEP
standard
Wrong
space
uncaptured
group
error
command
code
space
optional
review
Tests
spaces
good
captured
groups
uncaptured
groups
comment
Ugly
indentation
new
task
names
b
way
skip
decorator
Great
catch
test
case
current
behavior
update
PR
comment
docstring
emphasis
redshift
comment
https
//docs.python.org/3/library/multiprocessing.html
sharing-state-between-processes
Same
concern
see
comment
direct
dropbox
method
download_as_byte
method
OK
lists
space
job_id
context
log
record
i.e
following
lsf
args
space
var
space
string
pyc
intention
.pyc
c
something
errors
errors
None
concatenation
output
space
output
var
General
critique
concatenation
%
interpolation
Pick
%
.format
partial
stick
dill
function
head
node
LSF
cluster
identical
nodes
cluster
issues
pickling/unpickling
objects
Dill
robust
scenario
comment
code
sorry
nit-picky
param
docstring
descriptions
docstring
new
get_as_string
inherit
object
dlstadther
tests
master
branch
tests
issue
closer
look
PR
complexity
please
use
OSError
Python3
comment
helpful
error
Thanks
comments
necessary
standard
way
python
attributes
product.product
]
._get_default_category_id
Thanks
flake8
additional
fix
utility
products
other
cases
'company_id
False
multicompany
contexts
website_id
default
self.env
[
'website
]
.search
[
]
limit=1
required
field
empty
proposal
_default_website
original
db
website
ID
null
table
other
modules
old
website.pricelist
model
migration
new
short
headers
copyright
exists
part
whole
table
AFAIK
wrong
several
ways
company
aware
product
account
ORM
product
*
force_company
*
=company.id
context
correct
account
expenses
expenses
product
company
big
sweep
many
lookups
write
operations
function
account
product
product
addon
ir_property
table
much
cleaner
specifics
comment
sure
account
company
many
accounts
company
account
product
template
therefore
view
comment
clear
code
Same
comment
something
obvious
code
comment
substra
library
InvalidRequest
sufficient
create
suggestion
Ensure
order
dataset
keys
correct
levels
returned
traintuple
train
method
algo
order
incorrect
.future
.wait
assert
traintuple.dataset.keys
data_sample_keys
single
test
traintuple
sufficient
same
behaviour
tuples
minor
suggestion
Ensure
order
dataset
keys
correct
levels
returned
traintuple
train
method
algo
order
incorrect
.future
.wait
assert
composite_traintuple.dataset.keys
data_sample_keys
comments
other
statement
one
previous
comment
directory
pathlib.Path
issue
quickstart
similar
default
parameter
home
~
pathlib
type
string
statement
directory
property
statements
local
variable
self.config
directory
None
next
loop
comment
consistency
suggestion
records
source
async
record
load
source
topic
sure
https
//github.com/intel/dffml/issues/339
dffml
Let
imports
end
imports
standard
library
packages
note
https
//github.com/intel/dffml/issues/339
block
delete
possible
Let
sure
comments
capitalized
word
suggestion
first
occurrence
predict
data
=
text
+
f
message
+
suggestion
future
call
python
async
self.octx.parent
self.config.dataflow
octx
Register
subflow
parent
parent
flow
inputs
specifed
defintions
DataFlow.forward
self.octx.register_subflow
self.parent.op.instance_name
octx
python
async
self.subflow
self.config.dataflow
octx
subflow
method
OperationImplementationContext
PIL
Image.new
feature
data
record
suggestion
section_data
=
record.features
line
suggestion
.keys
section
headers
aka
record.key
.items
record
suggestion
section
record
self.mem.items
suggestion
necessary
suggestion
operation
dffml/operation/preprocess.py
literal_eval
operation
flow
connect
modelprediction.features
Connect
dffml.mapping.create
value
Add
Input
origin=
seed.feature
create_feature_map
InputFlow
key
seed.feature
]
literal_eval
connection
value
Change
demo
slr
model
dffml/model/slr.py
way
piece
input
feature
data
suggestion
pass
program
util
function
util
function
utils
function
Please
separate
actor
facts
collection
phase
whatever'.split
double
import
pylint
right
case
import
Discovered
NFS
share
idea
TODO
directory
subpackage
library_path
directory
package
tests
'subpackage/tests
certain
tests
mocked
file
directory
test
dummy
file
possible
'full
path
dummy
file
'relative
path
open
context
manager
good
reason
linter
checks
disable=line-too-long
code
refactor
Please
context
manager
open
exception
handling
place
data
way
Traceback
framework
sexy
Please
comment
suggestion
code
library
reuse
tests
suggestion
case
cautious
other
suggestion
msg
careful
solution
similar
thing
please
document
attributes
reason
os.path.isabs
https
//docs.python.org/3/library/os.path.html
sure
has_package
right
choice
installed_packages
package
cycle
lookup
package
presence
cycle
leapp.libraries.common.rpms
import
create_lookup
def
process
=
create_lookup
InstalledRedHatSignedRPM
key='name
package
keywords
DAEMONS
package
installed_packages
issue
macros
RHEL
system
better
such
case
Value
list
diff
NEW_MACROS
=
[
RemoteName
'CreateIPPPrinterQueues
All'
+
NEW_MACROS
=
[
+
'LocalQueueNamingRemoteCUPS
'RemoteName
+
'CreateIPPPrinterQueues
'All
@
zdohnal
Let
sync
monday
suggestion
'https
//access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/upgrading_to_rhel_8/troubleshooting_upgrading-to-rhel-8
known-issues-upgrading-to-rhel-8
noqa
E501
pylint
disable=line-too-long
suggestion
events
=
get_events
pes_json_filepath
filtered_events
=
filter_events_by_releases
events
filtered_releases
=
get_releases
events
releases
data
ofc
target
=
version._version_to_tuple
api.current_actor
.configuration.version.target
=
filter_releases_by_target
releases
target
=
filter_events_by_architecture
filtered_events
arch
add_output_pkgs_to_transaction_conf
transaction_configuration
arch_events
suggestion
from_repo_cdn
=
fields.String
RHEL
repoid
present
Red
Hat
CDN
bocekm
Michal
logic
separate
function
POV
readable
black
plugin
reason
line
suggestion
used_target_repos
=
next
self.consume
UsedTargetRepositories
type
List
[
UsedTargetRepository
]
line
below
same
suggestion
local
repository
http
details
wide
exception
suggestion
rhsm
container
mode
mounting.NspawnActions
constants.TARGET_USERSPACE
target_context
rhsm.set_container_mode
target_context
exception
loop
case
mount
points
mount
point
python
mount_points_maps
=
'/boot
/installroot/boot
'/boot/efi
/installroot/boot/efi'
suggestion
'rhel8-appstream
'rhel-8-for-x86_64-AppStream-htb-rpms
suggestion
'rhel8-BaseOS
'rhel-8-for-x86_64-baseos-htb-rpms
good
description
suitable
description
comment
@
zdohnal
docstring
list
fom
CANON_DR
such
case
docstring
lists
little
related
list
comment
Use
CenterCrop
memory
order
CI
Need
line
class_idx
gts
parse_directory
necessary
frame
annotation
file
frame
number
logger.info
..
code-block
f-string
Use
comments
codes
docstring
returned
vars
]
https
//github.com/open-mmlab/mmaction2/blob/master/mmaction/models/recognizers/base.py
L101-L104
ious
=
[
temporal_iou
self.start_frame
self.end_frame
gt.start_frame
gt.end_frame
gt
gt_list
]
Regression
Stats
>
Regression
Normalization
Constant
one-liner
function
aug_start
=
self.aug_segments
self.logger
member
variables
get_root_logger
many
times
comment
elements
proposal_infos
gts
=
[
]
x
proposal_info
]
int
x
]
int
x
]
ssn_instance
=
SSNInstance
int
x
]
int
x
]
label=int
x
]
gts.append
ssn_instance
same
following
proposals
var
btw
int
evitable
proposal_infos
brackets
\
comment
positive_props
member
proposal_ranges
=
np.array
[
real_relative_starting
*
relative_proposal
]
proposal_tick_list
=
proposal_ranges
*
.astype
np.int
process_localize_proposal_list
repo
localization/proposal_utils.py
comment
gt_list
member
w
h
=
[
int
d
d
result.readline
.rstrip
.split
-vsync
vfr
good
hardcoded
value
delta
keyword
argument
function
def
_calculate_localization_map
inputs
use_labels
delta=1e-20
docstring
thx
use
full
abbreviate
var
name
type
returns
list
=
torch.rand
print
]
False
shape
huge
unittest
CI
dtype=
use
safe
case
someone
name
video
-rf
~
joking
input
video
video_annos
function
staticmethod
isort
skip
redundant
base_channels
X3D
model
equals
*
self.gamma_w
isort
comments
redundant
checkpoint
url
ckpt
HOME/.cache/torch/checkpoints
new
fromfile
load_from
corresponding
url
load_from
corresponding
url
outer
brackets
redundant
MMAction2
comment
future
hackers
copy
Mypy
list
Union
types
List
Union
Types
sense
type
check
Exceptions
special
file
problems
feature
oriented
file
structure
method
public
implementation
define_int
family
great
chance
as-as
get_spec
returns
internal
implementation
details
likely
documentation
returned
value
end-user
user
need
method
timeout
safe
event
UNIX
tuple
[
None
]
None
large
problem
many
thousands
columns
loop
quadratic
complexity
loop
linear
complexity
sum_width
i
width
enumerate
calc_widths
sum_width
+=
width
sum_width
max_width
max_empty_columns
=
i
un
espace
avant
et
après
+
dans
o.type+
o.url
je
ne
trouve
pas
l'assertion
très
lisible
il
faudrait
peut-être
extraire
o.type+
dans
une
fonction
du
type
get_offer_complete_type
set
[
o.type+
o
offers
:4
]
]
dans
unique_complete_types_of_first_four_offers
ça
correspond
à
quoi
excinfo
Il
rest
un
et
un
auxquels
une
majuscule
sur
la
première
lettre
😉
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
E303
many
blank
lines
E303
many
blank
lines
E501
line
characters
punchlist
item
issue
tracker
Postgres
compressed
files
future
records
databases
way
dataframe
only
piece
E501
line
characters
E501
line
characters
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
F841
local
variable
'directory_urls
F841
local
variable
'service
F841
local
variable
'file_urls
Uncompleted
punchlist
item
issue
tracker
E501
line
characters
punchlist
item
issue
tracker
E402
module
level
import
top
file
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
E303
many
blank
lines
E303
many
blank
lines
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
E302
blank
lines
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
E501
line
characters
punchlist
item
issue
tracker
E501
line
characters
E116
unexpected
indentation
comment
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
E261
least
spaces
inline
comment
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Hmmm
feels
lot
information
code
comment
sure
better
place
overall
discussion
project
structure
BQ
time
logging
hours
punchlist
item
issue
tracker
Uncompleted
punchlist
item
issue
tracker
Should
comment
function
argument
default
function
pygments
options
necessary
ipython
]
import
pygments
[
]
pygments.lexers
TextLexer
[
]
pygments.formatters
HtmlFormatter
[
]
formatter
HtmlFormatter
]
pygments.highlight
<
script
>
alert
>
TextLexer
]
u
<
div
class=
highlight
<
>
<
>
<
/span
>
lt
script
gt
alert
lt
/script
gt
/pre
>
<
/div
>
\n'
logic
get_payload
integrations
Might
cleanup
other
calls
file
list
enough
better
way
proper
repo
id
gitlab
Github
TODO
comment
line
https
//github.com/rtfd/readthedocs.org/pull/3520/files/7f6c098983acb4bb3afc90e5c780af7dae9ec9d8
r163242699
return
states
last
rest
comment
little
build_env
self
overriden
method
class
method
little
elaborated
thoughts
success_message
failure_message
copy
bit
*
activate
webhook
webhook
webhook
*
link
user
problem
persistent
messages
example
python
success_message
=
_
failure_message
=
NO_CONNECTED_SERVICES
_
webhook
project.name
Please
href=
url
>
provider
account
<
/a
>
NO_PERMISSIONS
_
webhook
project.name
Make
sure
href=
url
>
correct
provider.name
permissions
/a
>
NO_ACCOUNTS
_
webhook
project.name
Please
href=
url
>
provider.name
account
<
/a
>
NO_CONNECTED_SERVICES
NO_ACCOUNTS
same
thing
user
perspective
certain
subject
email
Double
check
purposes
good
UX
copy
email
subject
webhook
success
>
webhook
>
Webhook
clearer
user
core
developer
language
receiver
signal
django-async-messages
L75
separate
line
args
comment
Yeah
last
PR
way
Pretty
sure
patch
json
call
non-JSON
data
non-JSON
return
data
Just
point
python3
function
call
tests
something
update
anything
creation
something
redis
entry
pep8
check
space
operator
=
better
method
views
MirrorErrorListResource
comment
huali027
thanks
changes
parser
use
Scannable
good
call
example
little
misleading
someone
parser
way
context_wrap
function
lines
24-27
doc
test
rhsmd
object
lines
reference
Scannable
class
extensive
documentation
examples
Same
comment
dict
subsystems
logic
KeyError
exception
appropriate
method
rules
ParseException
meaningful
simplify
way
self.data.extend
[
str
i
i
range
int
start
int
end
+1
]
@
wushiqinlou
reference
]
https
//docs.openshift.com/container-platform/3.5/install_config/install/advanced_install.html
applicable
file
parser
multiple
example
multiple
key/value
pairs
settings
lines
IRC
INSPEC
card
Spec
Change
first
FYI
please
use
first_of
RHEL
[
root
@
liuxc-rhel6-sat6
~
]
uname
-r
2.6.32-754.9.1.el6.x86_64
[
root
@
liuxc-rhel6-sat6
~
]
/sbin/grubby
[
root
@
liuxc-rhel7-sat6
~
]
uname
-r
3.10.0-957.12.1.el7.x86_64
[
root
@
liuxc-rhel7-sat6
~
]
/usr/sbin/grubby
[
root
@
team-jupyter-server
~
]
uname
-r
4.18.0-147.5.1.el8_1.x86_64
[
root
@
team-jupyter-server
~
]
Better
SkipException
empty
Same
comment
dict
normal
method
https
//github.com/RedHatInsights/insights-core/issues/2798
Please
document
vm_name
class
attribute
/var/lib
cut-and-paste
error
example
input
data
needs
[
documentation
guidelines
]
https
//insights-core.readthedocs.io/en/latest/docs_guidelines.html
testing-your-docstring
documentation
output
errors
chenlizhong
please
docstrings
module
class
documentation
reference
module
docs/api_index.rst
docstring
datasource
datasource
loop
s
logic
above
comment
loop
unnecessary
col_index
first
line
course
good
correct
col_index
line
len
col_split
LEN
@
xiangce
exception
True
code
tuple
matysek
filter
rule
parser
filter
[
section
lines
phh
>
php
@
rasrivas-redhat
value
present
data
good
negative
test
main
]
plugins
present
intentional
modification
key
explicit
explanation
docstring
def
str2datetime
timestamp
code
tz
time_f
%
%
b
%
d
%
H
%
M
%
S
%
Y
time_s
=
timestamp
time_f
%
%
b
%
d
%
H
%
M
%
S
time_s
=
timestamp.rsplit
None
]
try
time
=
datetime.strptime
time_s
time_f
ValueError
pass
str2datetime
str
True
utc_time
=
line.strip
'/etc/localtime
.split
=
local_time
=
[
i.strip
i
remains.split
isdst
]
isdst
=
[
i.strip
'=
i
remains.split
None
gmtoff
=
remains.split
'=
]
code
namedtuple
def
str2datetime
timestamp
str2datetime
str
True
utc_time
error
TypeError
non-iterable
NoneType
object
@
xiangce
method
default
incorrect
method
implementation
Same
comment
above
test
data
ODBCIni
Driver
SERVER
NO_SSPS
filter
lowercase
excepted
lines
absent
archive
Please
double
confirm
NFSExportsD
optional
nfsexportsd
None
better
sure
None
operations
helpful
data
attribute
docstring
developers
parser
Examples
better
uncomment
line
nomenclature
place
care
pre-release
feature
scope
d
_Mock_
%
necessary
tests
present
PR
s
changes
tests
’
t
necessary
merge
conflicts
https
//github.com/Glutexo/insights-core/commit/f10ffed5b4e399dc22e99d0e95f0f3adcae015a7
files
lines
regex
recommended
way
simple
content
other
simple
methods
split
re-implement
logic
startswith
split
everything
line
parser
dict
self.data
contents
dict
something
assert
sctp_obj
None
nothing
__init__
method
case
None
problem
vishwanathjadhav
assert
assert
line
object
SCTPEps
None
assert
bit
right
thing
sctp_obj.sctp_eps_ips
empty
empty
dict
None
better
test
assert
sctp_obj
expected
condition
parser
Same
above
comment
OK
content
empty
following
for-loop
caller
return
value
parse_content
something
case
Committing
code
pointless
commit
changes
code
revert
partial
revert
code
verify_ssl
false
old
bitbucket
client
methods
auth
method
unnecessary
comment
worth
overcautious
FileBlob.DoesNotExist
way
failure
rest
deletions
unsure
likely
different
tasks
same
blobs
same
time
conflict
suggestion
ServiceHookProject
records
descriptive
exists
variable
something
python
project_specific
=
ServiceHookProject.objects.filter
service_hook_id=sevicehook.id
.exists
project_specific
intent
clear
code
Comments
help
last
resort
intent
logic
imo
comment
necessary
@
wonder
Note
users
value
days
infinity
@
BYK
opinion
days
max
thoughts
comment
something
option
values
obvious
wrong
schema
safer
logic
other
sequence
types
tuple
lists
edge
case
single
string
sequence
type
Good
docstring
interactive
shell
display
>
>
>
>
>
Please
query
slower
Use
query
filter
fact
index
AuditLogEntry
pretty
large
rows
event
indexed
Iterate
SentryApp
rows
creator_user__isnull=True
date_deleted__isnull=True
search
related
AuditLogEntry
rows
related
org
quicker
AuditLogEntry
rows
org
event
[
NODE_OPTIONS
]
=
env.get
NODE_OPTIONS
max-old-space-size=4096
TODO
relevant
significance
magic
number
least
self.raise_error
e
comment
docstrings
new
methods
easier
Feel
great
docstrings
IssueTrackingPlugin2
methods
]
https
//github.com/getsentry/sentry/blob/master/src/sentry/tsdb/base.py
good
example
good
docstrings
suggestion
card
cards
commented-out
code
reason
line
comment
prefix
first
chars
token
suggestion
re.search
r
\w+/https
//trello\.com/
issue
example
label
regex
great
comments
comment
FK
@
MeredithAnya
How
other
parts
PR
migration
WHITELIST_PK
Probably
sense
lazy
query
time
redis
keys
concern
separate
other
logic
permissions
Someone
endpoint
app
integration
nitpick
parenthesis
😛
Typo
publish
integration
app
<
rows
table
safe
part
deploys
suggestion
function
users
PD
incomplete
suggestion
Potential
problems
My
guess
org
sure
integration
integration
valid
ID
mgaeta
owners
default
least
owner
org
@
mgaeta
confused
d
integration_id1
field
model
OrganizationIntegration
specific
integration
mgaeta
case
call
fine
owners
owner
UI
Shall
TODO
comments
move
commits
list
get_commits
better
part
larger
queryset
possible_file_change_matches
CommitFileChange.objects.filter
commit__in=commits
Commit.objects.filter
releasecommit=ReleaseCommit.objects.filter
release=Release.objects.get
projects=project_id
version=version
filename__endswith=frame
[
]
todo
maxbittker
last
same
way
score_path_match
comment
_get_commits
QuerySet
changing
behavior
point
code
commits
unevaluated
QuerySet
database
database
commits
query
expensive
operation
commits
_match_commits_frame
discussed
back
True
SQL
hand
sure
quicker
issue
something
something
access
gitlab
instance
james
base
url
something
important
due
unique
constraint
reason
multiple
chunks
request
request
able
more
throughput
parallelization
Anything
chunksPerRequest
reason
value
first
place
value
endpoint
able
information
server
support
theory
points
exact
same
endpoint
GET
situation
different
nit
False
constant
comments
XXX
slohmes
easy
thing
[
XXX
]
https
%
%
Tags
nice
way
important
NOTE
better
secrets
access
tokens
private
keys
jira-server
Might
best
STATUS_MAP
new_status
=
SentryAppInstallationStatus.INSTALLED
raise
ValidationError
u
Invalid
value
status
.format
new_status
way
check
anyone
installation
status
Ah
crap
API
Forgot
environment
objects
methods
least
knowledge
parameters
applicable
things
progress
async
delete
assumption
wrong
callers
code
single
project/group
many
TagKeys
true
user
tag
names
unique
much
error
GroupTagKeyNotFound
TagKeyNotFound
Same
other
method
re-uses
comment
difficult
pretty
familiar
implementations
clearer
@
markstory
Dataset.Discover
argument
resolve_condition
typo
nit
translated_columns
=
resolved_discover_aliases
snuba_args
bit
weird
translated
columns
snuba_args
dict
arg
Snuba
option
default
True
time
MeredithAnya
fields
optional
sense
[
None
comment
top
file
targets
target
'non-empty-string
=
step
anchor
target
anchor
step
anchor
exists
type
invisible
anchor
target
None
=
step
particular
element
guide
confusing
pass
things
possible
block
kind
utility
function
EventManager
Basically
something
line
comment
https
//github.com/getsentry/sentry/blob/master/src/sentry/db/models/manager.py
L355-L356
Basically
sure
code
event_id
id
times
field
discover1
queries
events
group_id
>
identity
Banner
style
comments
application
simpler
comment
/
comments
better
dictionary
comprehension
suggestion
sampling
rate
load
control
constant
rate
cached
value
cache
sampled
value
Otherwise
spiky
load
%
errors
project
webhook
seconds
periods
cache
True
matter
rate
organization
case
feature
sampling
check
good
call
i
able
events
stream
/
discover
runnign
i
requirement
Does
need
full
URL
URI
portion
query
project
primary
key
events
event_id
unique
*
*
project
unique
chance
update
wrong
thing
comment
true
POST
requests
anything
DELETE
comment
limit
code
transaction.atomic
block
real
need
permalink
master
ref
Nit
property
queue
task
race-like
conditions
comment
jira
update
scenario
error
should_comment_sync
function
tuple
condition
return
Might
TODO
mobile/native
comment
general
principle
predicate
call
suggestion
gmail
domain
users
gmail
Done
organization-saved-search
class
name
@
wedamija
events
expensive
test
functionality
projects
lower
page
limit
per_page
2-3
owners
message
ordered_owners
=
serialized_owners
len
serialized_owners
=
len
ordered_owners
@
mgaeta
EventAction
class
actual
class
yea
other
database
tests
sure
reasonable
number
context
manager
python
self.mobile_viewport
Organization
OrganizationEndpoint
organization
parameter
leeandher
transaction.atomic
DB
operation
leeandher
confused
IntegrityError
DB
constraints
model
stray
comment
suggestion
next
incoming
crash
report
%
sure
unique
event
ids
chars
risk
collisions
low
from_event_id
multiple
projects
multiple
groups
error
random
group
log
stats
something
environment
filter
ticket
comment
function
projects
Should
tests
organization/project
permissions
tbh
comment
same
string
additional
value
thing
suggestion
Try
reasonable
time
frame
stats
stats
day
earliest
last
least
days
more
days
Fallback
days
able
value
wait
production
/integrations/
*
static
marketing
pages
endpoint
app
wrong
enough
smile
line
personal
favorite
Was
status
column
best-effort
exclusive
access
much
many
other
ways
case
sure
implications
data
>
events
operation
events
guarantee
Nothing
possible
least
note
possible
short
aside
opinion
good
idea
anything
reliable
piece
technology
enforces
constraint
much
referential
integrity
things
foreign
key
constraints
aware
shared
opinion
team
only
ways
note
list
exhaustive
off
top
head
events
specific
hash
cleanup
other
means
sure
API
endpoint
top
head
secondary
fingerprint
group
multiple
hashes
https
//github.com/getsentry/sentry/blob/fe03d388e52fe7c73330857c59b0f4f3fd6104ac/src/sentry/event_manager.py
L836-L849
application
hash
system
hash
task
first
primary
hash
event
L136
file
secondary
hash
nothing
likely
second
case
other
GroupHash
record
UX
future
good
ideas
top
head
comments
sure
error.handled:1
route
bit
specific
e.g
access
check
is_internal
check
someone
someone
app
internal
additional
SQL
queries
token
sentry_app
eager
application
relations
high
throughput
endpoint
column
values
relations
queries
error
message
sentry
app
organization
ok
information
potential
attacker
sentry_app
SentryAppBaseEndpoint
nitpick
i
comment
api_token
=
Creator.run
..
informative
logic
mediator
mediator
endpoint
restriction
case
data
api_token
=
Creator.run
request=request
sentry_app_installation=sentry_app_installation
RedisCluster
mean
comment
class
StrictRedisCluster
something
sure
single
Redis
server
default
is_redis_cluster
defaults
False
Redis
Cluster
size
is_redis_cluster
configuration
key
example
structure
easier
right
plugin_slug
project_id
True
configure
False
little
clearer
wordy
i
ProjectOption
keys
plugin
e.g
plugin
enabled
configured
information
plugin.required_field
plugin
e.g.
plugin
auth_key
@
MeredithAnya
Thanks
Appreciate
doc
comment
small
typo
connfiguration
>
configuration
Thanks
change
much
cleaner
commented
code
lol
comment
endoint
comment
descriptive
https
//github.com/getsentry/sentry/pull/10265/files
utf8=
%
E2
%
%
diff=split
diff-7be9ee4c221344b6b849dc9a27929075R48
suggestion
chance
correct
result
wrong
test
comment
sense
latin-1
subset
utf-8
encoding
first
characters
unicode
codepoints
same
problem
https
//github.com/getsentry/sentry/pull/14249
DEFAULT_START
DEFAULT_END
application
start
hard
Basically
legacy
options
producers
legacy
options
consumers
bootstrap.servers
legacy
options
Rename
with_legacy
only_bootstrap
invert
legacy_options
only_bootstrap
assert
bootstrap.servers
legacy_options
options
bootstrap.servers
=
legacy_options
bootstrap.servers
]
options.update
legacy_options
same
clear
bootstrap
legacy
option
way
other
options
legacy
options
everything
legacy
Thanks
right
fix
bootstrap_server
parameter
custom
fields
branch
consumer
producer
configuration
producers
mere
presence
legacy
fields
new
fields
consumers
new
field
specific
legacy
config
same
bootstrap.servers
field
new
fields
consumer
bit
race
condition
ta
update
comment
suggestion
file_details
u
.format
payload
project_slug
]
key
data
best
way
'Export
CSV
task
use
case
different
logic
payloads
same
convert_to_csv
function
function
leeandher
endless
loop
unnecessary
local
testing
TODO
lol
comment
Should
trailing
Similar
comment
L55
pipeline
parameter
helper
method
buffer
sentry_app
expiry
keys
anything
set
buffers
new
lists
EXPIRE
https
//redis.io/commands/expire
way
data
explicit
deletion
keys
SentryApp
status
code
redis-cluster
sure
key
names
sentry_app_id
https
//redis.io/topics/cluster-spec
keys-hash-tags
sure
better
documentation
easy
wrong
redis
data
single
sentry_app_id
same
Redis
shard
assumption
information
informed
decision
belong
integrations.jira.utils
special
way
percent
@
pierredup
BitBucket
Cloud
check
start_sha
None
Wh
check
@
pierredup
Could
something
*
bit
cleaner
s
valid
methods
class
type
hints
api
implementation
comment
method
method
parameters
docstring
bad
😬
Maybe
specific
>
bucket
membership
feature|strategy|value
per-bucket
membership
count
feature|strategy|value
group
Clean
last
night
review
Might
worth
comment
django
INSERT
suggestion
devserver
configured
port
backend
port+1
nolachen
Just
wondering
reason
check
app
has_object_permission
method
permissions
issue
check
backend
frontend
button
dashboard
unpublished
app
bad
user
experience
check
backend
Same
request_body
max
size
models.TextField
size
something
reasonable
someone
huge
response
sure
possible
Sentry
error
field
unclear
sure
json.dumps
request.body
field
plain
string
response
HTML
top
module
with_relative_paths
Commit
paths
..
stacktraces
theory
access
rest
file
path
dots
best
same
obj.datetime
field
line
reason
new
Projects
large
table
offline
set
is_dangerous=True
giant
transaction
index
platform
case
rows
iterate
+1
Nice
comment
behavior
serializer
fine
logic
user.get_orgs
.filter
id=obj.organization_id
.exists
change
pretty
subtle
decent
performance
improvement
User.get_orgs
returns
lazy
Django
QuerySet
query
ability
query
trip
database
rows
able
database
row
boolean
True/False
row
row
disqus
docstring
remnants
second
thought
'sso-saml2
comment
valid
Naming
reason_details
Yeah
same
concern
translations
mocks
strings
events
hour
worth
frontend
best
way
PD
docs
>
API
request
POST
JSON
object
data=json.dumps
payload
sure
json=True
MeredithAnya
Is
timeout=5
timeout
value
good
place
tags
project
slack
integration
fallback/summary
TODO
slack.v2.signing-secret
AuthProviderSerializer
access
obj.organization
value
object
auth_provider._organization_cache
=
organization
query
something
sure
suggestion
arguments
dict
MultipleObjectsReturned
exception
problem
Django
rows
database
case
much
pattern
case
more
=
Repository.objects.filter
]
repos
none
repos
else
more
minor
lighter
database
Postgres
sure
everything
i
HerokuReleaseHook
easiest
thing
do
set_refs
method
release
hook
HerokuReleaseHook
ReleaseHook
class
def
set_refs
self
release
*
*
values
pass
something
def
set_refs
self
release
*
*
values
user
exists
refs
version
values.get
'owner
None
try
repository
=
Repository.objects.get
name=ProjectOption.objects.get_value
project=self.project
key='heroku
repository'
Repository.DoesNotExist
pass
release.set_refs
refs=
[
release.version
repository.name
]
[
'owner
]
fetch=True
self.set_refs
release
*
*
values
good
freight
plugin
able
sentry-plugins
@
pytest.mark.xfail
reason=
breaks
level
repositories
nit
FIELD_ALIASES
[
'user
]
[
'fields
]
changes
case
comment
out-of-date
OMG
separate
file
snapshot
good
point
i
stuff
old
plugins
handle
errors
i
external
issue
task
best
way
sure
comments
request
errors
literal
none
type
comment
confusing
bit
clearer
above
comment
comment
clap
duplicate
code
stuff
mean
superusers
activeorg
member
org
Please
docstring
responsibility
class
IMO
sense
hmm
true
e.g
provider
identity
provider
new-account
flow
different
key
redis
key
db
'github
markstory
tests
release
release_1
outline
example
comment
@
markstory
tests
release
release_2
outline
example
comment
assertions
state
comment
queries
results
correct
various
intermediary
states
valuable
many
more
state
Same
general
set
comments
other
groups
check
mypy
valid
type
comments
[
PEP
]
https
//www.python.org/dev/peps/pep-0484/
Regardless
check
repository
useful
documentation
Hmm
warning
other
options
Buhhh
crap
@
alex-hofsteede
comment
https
//github.com/getsentry/sentry/pull/7925
pullrequestreview-111822758
tag
exist
function
returns
possible
Comment
cleanup
items
digest
unclosed
more
timeline
more
clear
way
Love
yapf
lines
long
=
'record
i
i
xrange
assert
record.key
record
records
mnoble
right
able
prod
issue.I
today
suggestion
to_json
custom
logic
empty
keys
return
cls.to_python
data
.to_json
data
None
untitaker
Option
previous
comment
redundant
pass
python
to_json
way
to_json
extra
comment
yeah
sense
environment
environments
assumption
other
place
events
events
deploy
..
@
dcramer
and/or
@
mattrobenolt
thoughts
environment
unique
org
unique
projects
weird
issues
environment
endpoint
comment
whole
lot
Hm
None
comment
lines
setup
pipeline
things
Seems
Might
worth
previous
test
duplication
code
False
comment
data
http
interface
*
multiple
times
data
store
endpoint
http
interface
Later
data
*
event
details
comment
line
valid
leeandher
Might
worth
error
error
Sentry
None
responses
network
response
bike
house
Style
comments
config
serializer
provider
thought
GH
lets
None
@
MeredithAnya
Are
important
comment
clear
intention
evaluation
order
MeredithAnya
error
browser
ApiError
other
expected
ones
file
error
move
IMO
MeredithAnya
logic
input
path
stack_root
RepositoryProjectPathConfig
request
confused
result
array
results
result
unsymbolicated
frames
symbolication
successful
FWIW
unlikely
impossible
case
symbolicator
inline
functions
unable
result
least
native
plugin
process_frame
afterwards
TODO
comment
symbolserver_match
path
theoretical
None
case
value
option
projects
kafka-ingest-pipeline
suggestion
DRF
configured
wait
time
different
number
@
markstory
test
TODO
Ah
thank
reasonable
time
o
happen
more
tests
comments
thing
user
part
organization
sure
appropriate
validation
error
certain
somewhere
function
org
request
....
anyone
operator
duplicate
code
import
operator
thresholdType
alert_op
=
operator.lt
operator.gt
alert_op
=
operator.gt
alert_op
triggers
]
[
alertThreshold
]
triggers
]
[
alertThreshold
]
way
error
message
generic
ops
<
>
function
example
comments
useful
integration
id
documentation
link
/for/flask
>
python-flask
>
https
//docs.sentry.io/clients/python/integrations/flask/
only
time
countdown=None
task
queue
immediate
processing
overhead
different
groups
delete_groups
new
task
task-hopping
batch
much
main
thing
ASAP
only
path
other
PRs
data
CH
compounding
problem…
[
line
]
https
//github.com/getsentry/sentry/blob/148a0c22f5f6fbea50f660cab78f93ebcec215a9/src/sentry/event_manager.py
L506-L507
@
person
componentId
meaningful
value
users
component
type
more
sense
comment
na
change
channels
not_found
surface
email
post_migration.py
something
i
dk
widgets
order
widget
save
risk
overflow
while
code
comment
incomplete
suggestion
Any
known
third
party
package
optional
test
nit
Move
comment
function
line
_nit
_
data.get
'foo
None
second
parameter
limits
issues
large
customer
Curious
full
hour
window
something
minute
second
more
abuse
ve
comment
accurate
longer
intersection
union
largest
possible
selection
project_id
s
user
pass
project_id
s
sure
top
level
param
project_ids
nit
python
try
install
=
SentryAppInstallation.objects.get
sentry_app__slug=slug
organization=organization
SentryAppInstallation.DoesNotExist
install
=
Creator.run
organization=organization
slug=slug
user=request.user
request=request
intentional
obvious
specific
value
umm
i
OrganizationFeature
Just
@
wedamija
review
rows
RangeQuerySet
rows
individual
updates
atomic
=
False
id
slug
project
slug
id
UI
project.slug
projectId
i
kind
payload
endpoint
project
org
id
keys
value
i
helpful
payload
type
id
i
type
notification
nit
i
efficient
UserOption.objects.filter
*
*
filter_args
.delete
i
above
queries
row
results
single
delete
query
DoesNotExist
error
nit
parens
alex
free
name
todo
suggestion
attrs
lifetime
]
.update
stats
None
current
implementation
serialized
response
different
interface_id
interface.is_enrolled
logic
model
serializers
endpoints
odd
API
behaves
request
params
reasonable
Bad
Request
errors
context
case
sense
malformed
HTTP
request
bad
user
input
errors
idea
plain
body
lots
cases
challenge
response
None
leeandher
get_or_create
https
//docs.djangoproject.com/en/3.0/ref/models/querysets/
get-or-create
manager.get_by_slug
portion
other
suggestions
refactor
manager
pattern
manager
bit
assertion
sure
dumb
data
good
project
@
denamwangi
next
week
KeyError
much
Just
paranoid
consequences
high
exception
typo
entire
processing
pipeline
silly
redundant
error
prone
.get
key
None
key
None.split
event.data
try
framework
=
event.data
[
'sdk
]
[
]
.split
]
KeyError
IndexError
pass
level
frozenset
constant
on-boarding
purposes
actual
user
id
Thoughts
sentry_organizationonboardingtask
User
Context
tasks
Just
conversation
@
dcramer
@
bretthoerner
framework
separate
attribute
colon
syntax
comments
magic
CI
var
i
couple
https
//github.com/getsentry/sentry/pull/10503
column
i
snuba
Let
dict
copy
touchy
configuration
change
😅
sure
events
topic
messages
transition
lower
higher
partition
count
committed
offsets
default
initial
offset
low
watermark
spot
integration
test
nit
wil
callback
formatting
garbage
autoformatter
😩
ok
debugging
outbox
empty
email
sending
async
something
python
self.settings
SENTRY_PROJECT=0
self.tasks
rest
able
rid
email
backend
settings
@
MeredithAnya
constants
MEMBER_PREFIX
+
CHANNEL_PREFIX
sense
method
prefix
class
scope
@
MeredithAnya
much
work
normal
HTTP
client
http.build_session
API
call
util
method
places
@
MeredithAnya
Awesome
changes
D
comment
value
*
explanation
MeredithAnya
Nit
comment
seconds
caller
function
get_channel_id_with_timeout
suggestion
params=dict
payload
cursor=cursor
limit=1000
MeredithAnya
limit
thousands
API
limit
suggestion
user
request
same
payload
organization
worth
comment
json=False
sure
foreign
keys
user/team
future
options
much
wider
issue
Same
comment
KafkaEventStream
SnubaProtocolEventStream
abstraction
admonition
actual
protocol
definition
…
wrong
style
nit
guard
statements
None
render_to_response
better
screen
spaces
nit
dataset
aggregate
groupby
conditions
part
snuba
query
dataset
separate
concept
part
URL
comment
clear
implementation
_columns
representative
suffix
point
SnubaModelSettings
contains
more
column
references
dataset
conditions
comment
sense
new
implementation
sure
such
good
idea
requests
GitHub
Enterprise
GitLab
On-premise
etc
Sentry
On-Premise
installs
integrations
applies
part
Will
Snuba/system
safe_urlopen
calls
tho
follow
SENTRY_DISALLOWED_IPS
comment
point
line
py3
comment
ensure_unicode_for_csv
sentry
idea
getsentry
ideal
fix
allowed_paths
Django
setting
getsentry
comment
wrong
suggestion
range
[
-9
-4
]
buckets
width
suggestion
range
[
]
buckets
width
suggestion
range
[
]
buckets
width
suggestion
TODO
TSDB
Errant
code
inefficient
many
suggestion
crash
directory
Python
package
Good
find
actual
explanation
empty
directory
esmvaltool
current
working
directory
Python
modules
[
namespace
package
]
https
//packaging.python.org/guides/packaging-namespace-packages/
native-namespace-packages
tool
aggregator
result
sure
_
valid
character
short_name
filenames
_
facets
DRS
suggestion
Dataset
nc_path
mode=
w
dataset
dataset.createDimension
size=1
dataset.createDimension
'lat
size=1
dataset.createDimension
'lon
size=1
Dimensional
variables
dataset.createVariable
dimensions=
dataset.createVariable
'lat
dimensions=
'lat
dataset.createVariable
dimensions=
'lon
[
'time
]
[
]
=
]
dataset.variables
]
.standard_name
=
dataset.variables
]
.units
'days
6543-2-1'
dataset.variables
'lat
]
[
]
=
[
-30.0
]
[
'lat
]
.standard_name
=
dataset.variables
'lat
]
.units
dataset.variables
'lon
]
[
]
=
]
dataset.variables
'lon
]
.standard_name
=
dataset.variables
'lon
]
.units
dataset.createVariable
dimensions=
'lat
'lon
[
'siconc
]
[
]
dataset.variables
'siconc
]
.standard_name
=
dataset.variables
]
.units
%
context
manager
exception
statement
suggestion
suggestion
Run
phasar
IDELinearConstantAnalysis
analysis
@
pdschubert
Could
short
description
suggestion
TODO
se-passau/VaRA
suggestion
TODO
se-passau/VaRA
glibc
suggestion
TODO
se-passau/VaRA
glibc
suggestion
configurations
merge
reminder
future
suggestion
Skip
hashes
uncommitted
files
Idea
lazy
init
plot
cmap
special
requirements
suggestion
TODO
se-passau/VaRA
refactor
dpi
plot_config
tensorflow
package
constraint
commented
lines
same
template
HOC_LIBRARY_PATH
obvious/redundant
variant
name
comments
accurate
suggestion
MPI
flags
same
run
environment
i.e
wrappers
TODO
check
OpenMPI
recipe
explicit
call
>
Isn
’
time
prelude
same
syntool
static
library
contains
dependencies
curious
means
better
empty
space
mechlib.ld_flags
self._get_lib_flags
nice
point
env
var
BglibPy
need
code
comment
nice
comment
comment
TODO
bzip2
ssanderson
person
chat
correct
change
conversation
cost_basis
value
price
position
current
implementation
correct
basis
cost
basis
tax
reporting
purposes
change
correct
short
sale
stocks
briefly
current
market
price
wrong
case
tax
reasons
cost
basis
sale
shares
Position.update
cost_basis
second
definition
short
cost_basis
initial
short
sale
short
clarification
blocks
commit
units
comment
@
field
way
thoughts
@
llllllllll
easy
way
RegistrationManager
instances
anything
due
fact
user
options
zipline
Good
point
nesting
body
checks
same
conditionals
something
is_valid
=
column
=
result
result
is_valid
return
result
Better
ffill
non-price
fields
python
assert
column
==
'price
result
return
result
blank
lines
comment
most
linters
unused
variable
whitespace
Black
changes.
<
br
>
whitespace
better
case
other
compute
environments
aws
room
error
test
deployment
SM
gpu-worker-manager
loop
progress
bundles
plausible
scenario
Worker
manager
staged
bundles
worker
jobs
Worker
manager
worker
job
min_workers
wait_for_progress
new
worker
run
bundle
worker
Worker
manager
new
iteration
aware
worker
bundle
bundle
staged_uuids
list
run
bundle
Codalab
staged
state
worker
manager
worker
job
bundle
progress
first
worker
second
run
bundle
first
run
bundle
problem
bundle
new
worker
worker-manager
staged
bundle
ie
worker
manager
perspective
latest
worker
nothing
staged
bundles
mysterious
reason
head
degenerate
state
other
way
way
current
system
style
comment
heartbeat
something
accessors
write
self._args.bypass_cleanup
amount
boilerplate
See
comment
'/
part
bit
strange
offset
bytes
comment
logic
parallel_run_quota
new
term
job
suggestion
AWS
worker
manager
versus
Fail
unresponsive
bundles
many
days
comment
last
updated
time
simplicity
space
logical
comment
block
related
test
command
root
user
non-root
user
restricted
fields
feature
different
formats
root
non-root
users
CLI
command
documentation
mean
comment
reason
target_info
None
request
bundle
contents
metadata
.keys
weird
comment
whole
block
get_n_host_worksheet_uuids
function
better
block
logic
first
get
most
host
worksheet
filter
permission
ok
worksheet
none
qualifies
necessary
Want
'argument
context
something
comments
bundle
commands
rid
vi
specific
first
comment
commands
only
thing
slurm_work_dir
slurm
batch
config
case
unnecessary
extra
folder
worker_id
slurm_work_dir
i
things
directory
get
possible
sort
message
worker
password-file
CODALAB_USERNAME
CODALAB_PASSWORD
configurable
somehow—if
as-is
Stanford
NLP
cluster
NFS
worker
local
disk
slow
other
users
mind
fixed
path
hostname/scr1
default
nlp-cl-worker
script
possible
folder
full
bunch
jobs
Personally
script
get-scr-with-most-space
hostname/scr
*
space
work-dir
get-scr-with-most-space
USER-cl-worker
sure
nice
usage
/usr/bin/env
bash
shebang
omitted—the
worker
directory
host
slurm
worker
things
squeue
-u
name
prefix
load_worker_jobs
s/SBATCH_COMMAND_RETRUN_REGEX/SBATCH_COMMAND_RETURN_REGEX/
s/Not/Do
codalab
workeer
batch
job
CodaLab
Slurm
worker
batch
job
Hm
unique
directory
workers
same
host
share
directory
self.cpus
codalab-worker-scratch
worker_id
+
worker_id
easier
ones
particular
user
docker
rest
api
documentation
docker
image
image
id
local
file
system
PR
comment
change
comment
states
_load_state
comment
clearer
Remove
invalid
paths
Just
comment
block
Replace
state
'dependency
state
comment
command
column
empty
nit
consistency
end
period
same
username
cl-worker
launched
uses
clearer
larger
higher
priority
specific
worker
higher
priority
bit
weird
request_queue
default
username
password
file
consistent
comments
Deduct
DISK_QUOTA_SLACK_BYTES
Let
slack
offset
more
meaning
comment
better
default
disk
request
disk
quota
slack
Comment
action
user
Could
comment
future
s/Optinal/Optional/
space
Optional
line
comment
Otherwise
run
quota
following
Say
parallel
run
quota
running
bundle
dummy
private
worker
ram
job
ram
check
nonempty
list
private
workers
private
worker
run
public
workers
many
runs
comment
list
FINAL_STATES
killed
list
final
states
weird
expected_state
more
explicit
something
use_sentry
initialize_sentry
use_sentry
something
sentry_util.py
simple
check
Same
load_sentry_data
way
detailed
comment
nit
capitalize
comments
Sorry
point
None
placeholder
comment
clear
future
readers
code
suggestion
Add
empty
item
placeholder
other
directives
substantial
items
many
more
DB
calls
ideal
GitHub
Docs
https
//docs.readthedocs.io/en/rel/theme.html
implementation
something
path2.startswith
path1
+
'/
Return
path1
ancestor
path2
flake8
errors
line
JsonApiClient
comments
one
error
code
comment
rule
comment
gpus
number
free
GPUs
general
trivial
English
migration
=
>
migration
easier
SQLite
database
file
flask_migrate.upgrade
run
flask_migrate.upgrade
install
immediate
directories
tarball
alphabetical
order
package.json
separate
function
previous
comment
comment
ssh_url
anyways
setup_method
setup_method
@
mprahl
necessary
parts
queries
comments
Could
query
parameter
OpenAPI
document
cachito/web/static/api_v1.yaml
API
documentation
https
//release-engineering.github.io/cachito
documentation
https
//swagger.io/docs/specification/describing-parameters/
query-parameters
entries
necessary
filtering
entry
different
state
test
little
faster
amount
disk
IO
necessary
tasks
while
more
worker
queue
cause
resent
worker_concurrency
more
worker
pod
situation
self._path.name
much
upside
somehow
filename
log
messages
much
experience
advanced
Python
logging
something
python
self.log.debug
Found
something
%
filename
s
%
s
some_value
filename
ideas
Worst
case
scenario
self._path.name
desirable
neat
repetition
pure
list
comprehension
approach
python
p.strip
p
package_items
p.strip
enumerate
suggestion
directory
tree
noqa
comments
types
comments
flake8-docstrings
tox
easier
contributors
suggestion
directory
tree
request
documentation
parameter
date
Could
comment
PosixPath
Linux
WindowsPath
Windows
base
class
someone
strange
comment
cachito/paths.py
Good
catch
Optional
nice
descriptive
variable
names
Optional
nice
comments
properties
Could
unnecessary
comment
keys
suggestion
v
self._gomod_data.values
version
case
actual
package
module
comment
code
descriptive
request
requests
Could
submitted
requests
items
code
more
page
requests
stale
only
single
page
Python
loop
way
code
url
=
config.cachito_api_url
+
True
json_response
=
get_completed_requests
url
identify_and_mark_stale_requests
json_response
]
json_response
]
[
'next
]
url
=
json_response
[
'meta
]
[
'next
]
big
deal
weird
chunk
integer
bytes
work
suggestion
loop
end
file
bytes
time
chunk
=
file.read
chunk
h.update
chunk
chunk
=
file.read
new
shiny
python3.8
cry
python
chunk
=
file.read
h.update
chunk
single
item
packages
comment
seconds
[
dircmp
documentation
]
https
//docs.python.org/3/library/filecmp.html
the-dircmp-class
check
enough
Files
subdirectories
a.
right_only
Files
subdirectories
b.
diff_files
Files
b
contents
class
’
s
file
comparison
operator
least
above
subdirs
variable
name
expected_project_root_dir
comment
root
directory
original
package
dependency
cachito
source
logic
len
mod_name
previous_length
submodules/nested
modules
comment
loop/if
statement
suggestion
e.g
'angular-animations-8.2.0.tgz
@
angular/animations
suggestion
Create
target
directory
dependency
suggestion
Move
dependency
target
directory
function
.zip
.tar.gz
archives
binary
content
i.e
response.content
response.text
rb
mode
open
context
manager
open
f
function
URLs
files
context
manager
comparison
file
file
files
memory
union
dependencies
package
correct
dependencies
i.e
following
response
packages
name
package-a
dependencies
A
B
]
name
package-b
dependencies
[
B
C
]
]
better
package-a
A
B
package-b
B
C
path.relpath
absolute_file_path
start=source_path
Drop
copyright
__init__
files
copyright
something
Just
....
qweb
widgets
values
human
readable
mode
formatted
value
char
qweb
rendering
date
datetime
monetary
type
values
different
fields
value
correct
field
need
particular
rendering
more
simahawk
ah
sense
date
datetime
monetary
future
improvement
@
pedrobaeza
suggestion
%
s
<
/a
>
%
partner.email
reason
event.id
suggestion
event.id
_
suggestion
href=
data-oe-model=
mail.tracking.event
data-oe-id=
%
d
>
format
https
//github.com/OCA/social/pull/211/files
diff-1394f09592f46f5e2304b9fe7b4c71baR2
course_info
empty
list
lines
fine
expected
result
list
objects
column
>
value
…
column
>
value
]
empty
list
Yep
@
pushyamig
error
data
model
course_id
Resource
course_id
things
line
comment
artifact
previous
iteration
updating
test
course
suggestion
Drop
columns
resource_type
name
resource_access
resource_access_df
=
resource_access_df.drop
[
resource_type
name
]
axis=1
suggestion
Drop
columns
user_id
course_id
access
time
resource
data
frame
first
lines
code
block
login
repeated
code
code
block
new
function
[
dummy_cache
launch_data_storage
cache_lifetime
]
login
launch
new
function
returned
values
place
launch_data_storage
launch
cache_lifetime
dummy_cache
more
like
*
*
verify_course_ids
comment
sense
re-assigning
something
ENABLE_BACKEND_LOGIN
=
True
STUDENT_DASHBOARD_SAML
variable
STUDENT_DASHBOARD_SAML
STUDENT_DASHBOARD_LTI
ENABLE_BACKEND_LOGIN
=
False
Allow
ENABLE_BACKEND_LOGIN
ENABLE_BACKEND_LOGIN
=
ENV.get
ENABLE_BACKEND_LOGIN
ENABLE_BACKEND_LOGIN
fine
better
line
df3
=
df.loc
[
df
[
]
]
.copy
Sam
wordier
something
df_positive_grades
something
better
name
df3
df2
looks
df_greater_that_percent_selection
comment
time
limit
something
wrong
query
single
course
data
cron
process
fine
multiple
courses
error
sqlalchemy.exc.IntegrityError
_mysql_exceptions.IntegrityError
Duplicate
entry
'17700000000123456-17700000000098765
key
'PRIMARY
Background
error
http
//sqlalche.me/e/gkpj
least
1e-5
optimum
harder
optimum
higher
precision
practice
BORF
experiments
regret
1e-6
course
arbitrary
number
end
1e-5
reasonable
gap
type
cls
least
great
docstring
link
multiprocessing
pickable
function
use
__main__
Details
https
//docs.python.org/3.2/library/multiprocessing.html
multiprocessing-programming
function
below
rosenbrock
function
minimization
example
compliant
API
function
own
file
Dask
particular
check
sure
rosenbrock_2d
same
workers
case
function
fmin
example
main
different
rosenbrock_2d
Below
WA
function
rosenbrock_2d
something
curr_challengers
afterwards
yes
comment
message
point
new
instance
idle
workers
instances
wait
wait
search
occurences
SH
hyperband
code
add
docstrings
methods
comment
entire
line
Done
Target
Algorithm
+
signature
function
arguments
+
i.e.
budget
target
algorithm
present
signature
same
Fixed
fmix
rosenbrock
new
code
Below
WA
function
rosenbrock_2d
+
Below
work
function
mlp_from_cfg_func
same
new
strategy
more_advanced_iteration
advanced
runs
multiple
strategies
reason
'more_advanced_iteration
reset
Could
comment
configs
ValueError
something
illegal
value
appropriate
exception
loops
self.rh
rh
define
stage
variables
init
IMO
status
single
request
device
bug
deviceauth
hmm
wrong
ID
device_id
adm_id
@
kjaskiewiczz
results
..
>
TODO
change
need
python
dict
service
name
>
ports
grab
lines
split
service
name
split
_
middle
element
]
d
=
srv
]
.split
_
]
srv
]
srv
[
l.split
l
subprocess.check_output
ps
.Names
.Ports
shell=True
.decode
.splitlines
]
]
d
]
'mender-api-gateway
0.0.0.0:443-
>
'mender-conductor
'8080/tcp
'mender-deployments
'8080/tcp
'mender-device-adm
'8080/tcp
'mender-device-auth
'8080/tcp
'mender-dynomite
'mender-elasticsearch
'9200/tcp
'mender-gui
'80/tcp
'mender-inventory
'8080/tcp
'mender-useradm
'8080/tcp
'9000/tcp
'mongo-common
'27017/tcp
'storage-proxy
0.0.0.0:9000-
>
grab
public
ports
[
]
re.findall
r
[
0-9
]
*
d.values
]
[
]
docker
print
public
ports
Read
factoryboy
documentation
line
block
comment
least
spaces
inline
comment
entire
directory
file
@
uds5501
loop
other
cases
operation
local
variable
@
bhaveshAn
microlocation
Please
migrations
@
bhaveshAn
microlocation
least
spaces
inline
comment
least
spaces
inline
comment
Black
changes
least
spaces
inline
comment
<
br
>
line
characters
least
spaces
inline
comment
<
br
>
line
characters
line
characters
least
spaces
inline
comment
<
br
>
line
characters
Remove
lines
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
whitespace
]
https
//app.codacy.com/app/fossasia/open-event-orga-server/pullRequest
prid=3636466
whitespace
least
spaces
inline
comment
<
br
>
line
characters
comment
whole
block
'app.factories.ticket.TicketFactory
unused
'unittest.TestCase
unused
'datetime.timezone
unused
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
'unittest.TestCase
unused
]
https
//app.codacy.com/manual/fossasia/open-event-orga-server/pullRequest
prid=4778007
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
datetime
]
https
//app.codacy.com/manual/fossasia/open-event-orga-server/pullRequest
prid=4778007
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
unused
]
https
//app.codacy.com/manual/fossasia/open-event-orga-server/pullRequest
prid=4778007
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
TestCase
unittest
]
https
//app.codacy.com/manual/fossasia/open-event-orga-server/pullRequest
prid=4778007
line
characters
least
spaces
inline
comment
indentation
multiple
comment
indentation
multiple
comment
boolean
field
google_captcha_enabled
whitespace
operator
block
comment
Write
minutes
front
least
spaces
inline
comment
use
comment
paypal_mode
=
settings.get
'paypal_mode
settings
'app_environment
]
==
Environment.PRODUCTION
'sandbox
statement
semicolon
indented
block
comment
name
'view_kwargs
Delete
code
git
project
college
project
pen
drives
much
nesting
early
return
data.get
elemen
=
order.get
element
suggestion
pytype
enable=attribute-error
suggestion
pytype
enable=attribute-error
good
pointer
migration
files
line
auto
Alembic
please
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
whitespace
]
https
//app.codacy.com/app/niranjan94/open-event-orga-server/pullRequest
prid=1736942
去掉注释
typo
pleae
fer
tensor，在动态图里面lod信息被丢失了。
如果batchsize
>
lace
>
place
Done
Thanks
yapf
disable
>
yapf
code
tensorpack
frame
issue
comment
https
//github.com/zenghsh3/models/blob/3bf1d4b2b48e4239f4b420c8f3592d7d47e1bb33/fluid/DeepQNetwork/atari.py
L19
useless
code
memory_optimize
several
methods
https
//www.paddlepaddle.org.cn/documentation/docs/zh/1.5/advanced_usage/best_practice/memory_optimize.html
Done
这些注释删掉
comment
code
comments
code
Done
unused
code
comments
arguments
BN_MOMENTUM
arguments
line
un-used
code
other
files
若干debug的注释掉的code可以留着，大多没用的code请去掉吧。
same
other
framework
reference
line
Need
TODO
many
config
little
confused
commented
code
able
ludwig.datasets
import
mnist
load
split
MNIST
dataset
dataset_df
=
mnist.load
training_set
=
dataset_df
[
dataset_df
[
SPLIT
]
==
]
=
dataset_df
[
dataset_df
[
SPLIT
]
==
]
initiate
model
training
train_stats
statistics
_
output_directory
location
results
model.train
training_set=training_set
test_set=test_set
experiment_name='simple_image_experiment
model_name='single_model
skip_save_processed_input=True
same
advanced_model_training.py
good
files
open
/predict
sure
right
serve.py:74
init
tf2
dropout
layer
https
//www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout
dropout
singe
number
rate
boolean
now.
example
/predict
first
row
df
one
/batch_predict
single
predict
main
people
way
example
use
cases
todo
sure
ARN
secret
[
]
import
boto3
]
s
boto3.client
secretsmanager
SecretId=
dcp/dss/dev/es_source_ip
boto3
documentation
>
Amazon
Resource
Name
ARN
friendly
name
secret
paranoid
encrypted
secret
operation
tasks
operation
local
machines
most
able
key
rare
AWS
console
=
False
dry_run
=
True
=
sys.exit
RuntimeError
Unable
secret
secret
name
secret-name
flag
https
//github.com/HumanCellAtlas/data-store/pull/2331
Consider
indent=4
secret_val
dictionary
string
something
try
secret_val
=
json.loads
secret_val
pass
print
json.dumps
secret_name
secret_val
reference
output
command
scripts/dss-ops.py
secrets
secret-name
dcp/dss/dev/admin_user_emails
dcp/dss/dev/application_secrets.json
json
Same
several
other
comments
tests
related
comments
uuid4
job_id
other
PR
same
API
https
//developer.github.com/v3/guides/traversing-with-pagination/
header
Link
RFC5988
format
Dict
key
strings
single
quotes
convention
secrets.py
Is
something
idempotent
@
ttung
comments
Swagger
def
DSSException
raise
except
Exception
ex
raise
DSSException
comment
number
indexes
total
indexes
alias
people
queries
type
value
queries
docblock
index
subscriptions
name
subscriptions
queries
constant
name
value
TODO
python
chunk
resp_obj.iter_content
chunk_size=None
max_size
content
large
chunks
content
+
chunk
self.max_size
raise
SizeLimitError
url
Contents
Bytes
chunk
exceeded
bytes
class
SizeLimitException
Exception
def
__init__
url
limit
>
None
super
.__init__
f
url
Contents
limit
SizeLimitException
url
protected
method
name
wrong
file
handle
proof
URL
bit
weak
stronger
proof
evict
idempotence
row
log
messages
log
message
action
IOW
test
present
evict
evict
asserts
S3UrlCache.contains
url
method
cheap
HEAD
request
key
method
handy
tests
access
exceptions
boto3.client
logs
.exceptions.ResourceAlreadyExistsException
botocore.errorfactory.InvalidSequenceTokenException
identities
same
multiple
client
instances
services
EC2
exceptions
AWS
API
service
model
//github.com/boto/botocore/pull/1005
ditto
Done
update_from_dict
/
self-contained
Elasticsearch
query
case
.query
match
*
*
query
portion
query
match
…
Does
indent=4
Python
print
JSON
readable
format
JSON
invalid
comment
]
https
//github.com/HumanCellAtlas/data-store/pull/2264
issuecomment-519290408
Brian
Did
_fqid
'fqid
Unable
manifest
bundle
unable
manifest
fqid
duration
comment
seconds
sleep
duration
seconds
Nit
verbose
try
BlobNotFoundError
verify_delete
handler
bucket
key
function
sure
test
response
code
rid
type
ignore
DSS_XRAY_TRACE
consistent
naming
convention
Please
edit
infra/build_deploy_config.py
references
HCA
wrap
doc
triple
quotes
NL
Test
possible
context
test
requests.codes.conflict
Has
Please
mypy
behavior
new
test
subtest
self.subtest
mixed/inconsistent
metadata
schema
release
versions
same
bundle
new
test
subtest
self.subtest
version
file
unversioned
file
new
test
subtest
self.subtest
consistent
versions
different
version
value
new
test
subtest
self.subtest
versioned
file
pattern
storage
identifiers
case
ticket
effort
helpful
comment
intent
English
sense
exception
thrown
subscription
logical
created
field
percolate
query
problem
subscription
useful
construct
careful
error
checking
worth
@
mikebaumann
assumption
exception
document
example
Elasticsearch
documentation
https
//www.elastic.co/guide/en/elasticsearch/guide/master/create-doc.html
document
responds
top-level
objects
error
status
Status
Elasticsearch
Python
Bindings
https
//elasticsearch-py.readthedocs.io/en/master/exceptions.html
ConflictError
reasonable
Elasticsearch
situation
exception
other
reason
doc
ElasticsearchException
comment
Short
explanation
Elasticsearch
inputs
strings
punctuation
john
@
example.com
people
email
address
jill
example.com
john
@
example.com
elasticsearch
example
w/
example
index
Elasticsearch
owner
necessary
email
config
test
stage
test
stage
tests
negative
code
paths
owner
unnecessary
negative
code
path
tho
batch_size
changes
error
Might
comment
values
lambda
console
lambda
triggers
Log
important
user
fact
return
code
bad
comment
relevant
PR
docstrings
SSM
store
Print
variables
SSM
DSS_DEPLOYMENT_STAGE/environment
FIXME
secretsmanager
Can
comment
None
disabled
same
point
lease
empty
dictionaries
utils
collections
subscriptions
iterate
demos
add
subscription
endpoints
life
function
weird
name
listen_scmb
app.py
loggging.exception
more
user
subscribing
callback
URL
json
schema
mandatory
fields
subscriptions
requiredOnCreate
[
Destination
EventTypes
Protocol
]
weird
other
way
round
efficient
prettier
py
branches
np.array
[
adata.obs
[
'branch_wishbone
]
.values
trajectory.index
[
trajectory
>
trajectory
<
b
]
]
b
pairwise
bins
axis=0
’
correct
branch_counts
=
np.array
[
branches
i
.sum
axis=1
i
[
]
]
pythonic
py
try
importlib.metadata
import
version
ImportError
<
Python
importlib_metadata
import
version
sense
parameters
select
nID
query
param
functionality
TODO
Participant
ditto
checks
role
above
check
easier
constraint
role
config
sensible
explicit
checks
grades
right
node
*
*
*
*
entry
anything
https
//github.com/eJourn-al/eJournal/blob/e3bbe76a3577c1e7bfcd327dd6a90e9298081623/src/django/test/test_teacher_entry.py
L102
title
title
Moved
publish_grades
*
different
API
inherent
entry
grade
Make
issue
todo
issue
ditto
entries
superusers
journals
comments
RT
temp
files
cleanup
task
Attached
files
cleanup
call
clear
benefit
direct
DB
layer
relationship
ID
text
similar
comment.files.exclude
pk__in=files
.delete
laos
Great
node_id
deletion
entry
node
Furthermore
line
Notify
teacher
new
entry
node.journal.sourcedid
node.entry.vle_coupling
==
Entry.NEED_SUBMISSION
lti_tasks.needs_grading.delay
node.pk
verification
logic
final
return
helpful
elections
more
current
total
validator
power
invalid
particular
reason
constructor
able
particular
election
validator
set
only
persist
conclude
more
Elections
validator
set
Bad
copypaste
empty
__init__
chance
such
mistake
docstring
comment
BadRequest
sentence
first
tokens
bdb.transactions.prepare
correspondence
CREATE
transaction
issues
tokens
Bob
Alice
token
hour
bike
_base_database_localmongodb.keys
check
error
todo
assert
error
/
error
message
use
output
id
cid
//github.com/bigchaindb/bigchaindb/issues/1465
someone
comment
description
original
issue
Nice
narrative
small
typo
suggests
..
trip
database
line
comments
Rodolphe
clear
reader
trip
necessary
spelling
configuration
comment
remove
log
un-comment
space
python
print
Copy
.aztk/secrets.yaml
file\n
.format
secrets
parts
while
service
principal
print
statements
piece
code
progress
nothing
user
sure
error
Remove
uncomment
code
TODO
spark
job
node
driver
app
i.e
task
Hrm
scope
cause
issues
example
everything
cluster
create
w/
PoolAdmin
permissions
file
TaskAdmin
access
comment
jars
Please
fix
indent
Use
convention
Arguments
start
applies
new
docstrings
TF-specific
Please
print
statement
Fix
indent
4-space
indent
Comment
NotImplementedError
more
appropriate
logic
implement
simpler/clearer
way
comment
Please
docstrings
same
other
docstrings
codebase
Please
code
codebase
comment
line
minimum
input
size
Nit
use
code
keywords
comments
Nit
use
code
keywords
comments
dimensions
mask_t.ndim
<
x_t.ndim
-1
+1
reader
more
explicit
result
case
mask_t.ndim
equal
possible
loop
apply_mask
function
shapes
advance
super
big
fan
multi-lines
lists
comprehension
purpose
list
comprehension
comment
personal
thing
Please
new
line
Instantiates
good
idea
loss
compile
code
readable
Please
comment
top
file
description
example
Typo
perfermace
>
performance
Are
comments
Format
docstrings
other
docstrings
codebase
Please
documentation
docstring
Keras
documentation
style
style
docstring
layer
Everything
ImageDataGenerator
%
sure
inline
comments
comment
top
operation
please
Please
standard
formatting
docstrings
e.g
Arguments
Keras
functions
anything
Returns
docstring
Please
__init__
docstrings
arguments
sections
class-level
docstring
applicable
line
initial
weight
values
models
difference
model
Keras
optimizers
consistent
TF
optimizers
tf.init_ops
line
nice
multiple
outputs
out1
=
tensors
]
*
tensors
]
out2
=
K.mean
tensors
]
axis=-1
return
[
out1
]
same
way
code
suggestion
Please
appropriate
image
file
INPUT_IMG_FILE
dog.jpg
following
parameters
other
models
use
global
average
pooling
e.g
InceptionResnetV2
/
NASNetLarge
NETWORK_INPUT_SIZE
=
MODEL_CLASS
=
resnet.ResNet50
PREPROCESS_FN
=
LAST_CONV_LAYER
=
activation_49
PRED_LAYER
=
fc1000
number
imagenet
classes
N_CLASSES
mention
vs.
image
file
format
true
reason
Implementation-level
comments
code
comments
user-facing
docs
K.is_keras_tensor
Please
same
formatting
e.g
Conv2D
docstring
typo
specific
error
AttributeError
Please
docstring
other
docstrings
codebase
previous
References
Please
docstrings
CL
other
docstrings
codebase
python
One-line
summary
period
Arguments
argument_1
Description
type
relevant
argument_2
Description
Returns
Description
output.
standard
format
use
Keras
repo
sequence
pool
beginning
epoch
sure
correct
indexes
case
Sequence
length
filters
filters
python
layer_filters
[
]
filters
layer_filters
filters
layer_filters
[
:-1
]
decoder
arbitrary
layer
size
arbitrary
number
layers
Better
activation
activation
keyword
layer
BN
such
shallow
network
MaxPooling2D
filters
*
BN
such
shallow
network
relu
activation
strides
TensorFlow
specific
K.int_shape
x
strides
Please
line
length
python
isinstance
min_value
int
float
isinstance
max_value
int
float
same
theano
cntk
backend
functions
docstrings
tensorflow
backend
docstrings
documentation
Same
我改改
满足小屏用户
timeout=self.time_left
'range
[
e
]
'levels
[
[
[
b
bid1
]
[
c
z
bid2
]
]
]
[
bid1
]
为啥要把virtual
和swap
加起来
..
这里的lvs
全称是啥？
是要获取所有挂载点吗
suggestion
class
SemanticVersion
str
A
custom
type
semantic
version
semver
regexp
https
//semver.org/
is-there-a-suggested-regular-expression-regex-to-check-a-semver-string.
regex
=
re.compile
r
^
1-9
]
\d
*
\.
1-9
]
\d
*
\.
1-9
]
\d
*
[
1-9
]
\d
*
|\d
*
[
a-zA-Z-
]
[
0-9a-zA-Z-
]
*
\.
[
1-9
]
\d
*
|\d
*
[
a-zA-Z-
]
[
0-9a-zA-Z-
]
*
*
\+
[
0-9a-zA-Z-
]
+
\
[
0-9a-zA-Z-
]
+
*
classmethod
def
__get_validators__
cls
yield
cls.validate
@
classmethod
def
__modify_schema__
cls
field_schema
field_schema.update
examples=
1.0.0-rc.2
1.2.3-rc.5+develop
]
classmethod
def
validate
cls
v
str
v
raise
ValueError
f
Unable
version
v
semver
SemanticVersion
v
@
property
def
_match
regex
match
return
self.regex.match
property
def
major
>
int
major
version
number
incompatible
changes
return
int
self._match.group
property
def
minor
>
int
minor
version
number
Changes
backwards
compatible
functionality
return
int
self._match.group
property
def
patch
>
int
patch
version
number
Changes
backwards
compatible
bugfixes
return
int
self._match.group
property
def
prerelease
>
str
pre-release
tag
return
self._match.group
property
def
build_metadata
>
str
build
metadata
return
self._match.group
property
def
base_version
>
str
base
version
patch
metadata
info
return
f
self.major
self.minor
self.patch
suggestion
case
Client
SystemExit
KeyboardInterrupt
server
suggestion
isinstance
result
SystemExit
KeyboardInterrupt
suggestion
SystemExit
user
suggestion
Catch
SystemExit
KeyboardInterrupt
block
comment
main.py
proper
exception
optimade.server.exceptions
detail
afterwards
Remember
docstring
suggestion
least
valid
field
TODO
Please
follow
PEP8
*
*
space
os_name
dep_data.keys
os
key
variable
commented
line
section
titles
space
space
Lines
general
limit
line
length
something
reasonable
e.g
characters
Use
Exception
subclasses
e.g
ValueError
assert
test
argument
presence
section
presence
e.g
Returns
IFF
function
returns
something
Raises
IFF
exceptions
Arguments
IFF
arguments
argument
order
presence
one-line
description
same
line
docstring
marker
dot
mean
Please
more
info
possible
comment
more
context
Same
more
info
concrete
example
imports
top
file
activation
return_sequences
default
values
Example
scripts
comment
valid
multiprocessing
branch
_train
arrays
please
block
test
time
comment
Better
inputs
targets
iterator.get_next
mnist
test
data
loading/preprocessing
Returns
section
change
separate
parameter
datadir
useful
comment
Example
meaning
comment
clear
>
keras.layers.merge
import
Add
docs/examples
public
API
layers
need
line
Yeah
..
current
easier
Well
similar
full
line
bit
easier
beginners
equivalent
keras.layers.add
keras
import
layers
Dense
necessary
clear
import
keras.layers.Add
keras.layers.merge
import
Add
keras.layers
Add
Hm
..
okay
anyplace
stuff
opinion
purpose
examples
better
import
lines
pretty
sure
people
layers
different
ways
undersired
ways
import
example
e.g
keras.layers.Dense
equivalent
>
Arguments
section
*
args
line
function
names
Add
line
break
Explain
most
people
familiar
width
multiplier
name
alpha
rows
need
layer
Initial
Please
docstring
different
example
CSV
file
lambda
Good
point
options
points
graph
time
@
fix
plot
epoch
suboptimal
better
shortest
code
snippet
interactive
matplotlib
backend
new
data
import
np
import
matplotlib
mpl
Use
interactive
backend
continous
updates
matplotlib.use
'TkAgg
import
matplotlib.pyplot
plt
plt.ion
fig
ax
plt.subplots
ax.set_xlim
ax.set_ylim
loss_line
=
ax.plot
[
]
[
]
def
plot_loss
epoch
logs
loss_line.set_xdata
np.append
loss_line.set_ydata
np.append
logs
[
'loss
]
fig.canvas.draw_idle
fig.canvas.flush_events
plot_loss_callback
=
LambdaCallback
on_epoch_end=plot_loss
little
much
code
lambda
Line
comment
Add
comment
block
necessary
sure
block
comment
..
clear
Add
comment
shape
inference
code
TF
case
find
replacement
way
thoughts
@
ozabluda
early
comment
>
global
constant
type
np.float64
K.floatx
changes
thread-safety
issue
float32
constant
wrong
float64
x
floatx
x
way
x
-=
np.float64
right-hand-side
PR
BTW
ILSVRC
nothing
Imagenet
enough
pixels
mean
accuracy
insufficient
@
ahundt
last
comment
items
>
fit_generator
batches
fit_generator
batches
generator
one
responsability
Dataset
Dataset
IMO
Dataset
batching
multi-input
multi-output
bunch
Enqueuer
something
def
create_batch
batch_info
batch
list
data
Arguments
batch_info
list
items
Dataset
Returns
A
batch
x
x
y
list
multi-input/multi-output
docstring
description
first
line
fine
comment
Thanks
p
p
need
+
end
space
isinstance
tf.Tensor
raise
ValueError
MESSAGE
hasattr
'_keras_history
only
thing
inputs
assert_input_compatibility
side
effect
error
i.e
x
inputs
K.is_keras_tensor
x
Copy/paste
error
variable
keras
Tensor.
correct
behavior
Keras
tensor
tensor
_keras_shape
_keras_history
attributes
set
preferable
_keras_history
_keras_shape
ValueError
isinstance
tf.Tensor
correct
Same
comments
Put
docstring
comment
Fix
comment
Comment
incorrect
target
data
input
data
target
future
Please
fix
file
'with
statement
case
weights
path
file
other
applications
comment
Same
comment
needs
Same
comments
file
Please
comment
Please
comment
purpose
_permute_required
obvious
name
Such
methods
docstring
use
consistency
rest
file
comments
useful
line
line
variable
names
Dref360
suggestions
explanation
first
pass
create
external
loss
function
useful
loss
functions
Keras
API
such
TensorFlow
TimZaman
PR
new
batch
size
assumptions
knowledge
such
assumptions
internals
input
user
Peharps
something
scope
PR
special
advanced
documentation
section
blog
post
stackoverflow
question
Set
default
None
fit
incorrect
implementation
original
paper
b
=
q
+
\alpha
q
q
-1/2
b
q
\alpha
keep
probability
drop
probability
rate
Please
comment
line
shorter
function
in-lining
code
code
optimizers
tensorflow
condition
K.backend
condition
easier
track
parts
code
backend-specific
wow
case
let
exception
comment
Exception
exception
message
safer
Exception
comment
specific
Exception
class
situation
pydot
generic
Exception
[
source
]
https
//github.com/erocarrera/pydot/blob/master/pydot.py
L1881
Again
specific
Exception
class
check
default
Arnold
case
https
termination
nginx
NIT
Better
variable
name
csv_with_empty
code
expected_enrolls_by_course_key
dict
comment
student_keys
way
bug
previous
logic
comment
assumption
curricula
multiple
programs
nothing
self.permission_filter
None
user_has_perm
query
param
user.has_perm
None
False
global
permissions
own
branch
self.permission_filter
user.has_perm
self.permission_filter
test
function
condition
s/Djang/Django
task
able
course_key
multiple
course
course
enrollment
CSV
grouping
example
ORGANIZATION_APP_PREFIX_PERM
commented-out
code
sure
JWT_ISSUERS
docstring
comment
interesting
override
comment
redundant
PyCharm
anyways
descriptive
LBC
default
account
specific
account
comment
reflect_uploads
re-reflect
anymore
Let
test
_a
a_
Correct
complex
case
wemake_python_styleguide.compat.nodes.NamedExpr
case
extra
sys.version_info
>
function
line
TODO
please
Correct
link
original
issue
cover
bad
sign
'unreadable
class
sorry
violation
number
Sorry
I001
idea
new
rule
Thank
https
//github.com/wemake-services/wemake-python-styleguide/issues/1248
same
I001
same
I001
assignment
MeaninglessExpressionViolation
case
examples
exe001_neg_shouldnt_be_executable
=
__name__
==
print
executable
variables
number
shorter
same
effect
line
https
//github.com/wemake-services/wemake-python-styleguide/blob/master/wemake_python_styleguide/logic/naming/name_nodes.py
L87
functions
comments
has_same_kwarg
Single
line
comments
uppercase
letters
rule
🤔
Please
x
correct
check
while
testing
strategy
solution
different
cases
types
template
different
cases
module
level
https
//github.com/wemake-services/wemake-python-styleguide/blob/master/tests/test_visitors/test_ast/test_general/test_magic_numbers.py
L13
templates
different
values
test
==
=
>
<
<
=
>
=
ternary
=
>
ternary
operators
>
Values
variables
integers
floats
booleans
right
side
strings
right
side
tuples
lists
dicts
sets
special
cases
>
<
errors
<
<
different
cases
comparison
x
x
y
x
correct
base_methods_order.get
first
constant
number
readability
Can
function
https
//github.com/wemake-services/wemake-python-styleguide/blob/master/wemake_python_styleguide/logic/tree/functions.py
L13
nit
materialize
cache
abi
option
necessary
comment
issue
symbols
bell
python3
python3
type
annotation
whoops
@
jekbradbury
comment
PR
+1
something
refs_len
iteration
end
refs_len
last
candidate
refs
pair
option
unicode
csv
iterator
comment
..
inactivate-upon-rerun
logic
fails
active
cases
inactive
comments
old
case
silent
minor
update
mode
update
function
case
status
modification
date
report
..
auth
endpoints
Flask-Login
server
app
before_request
decorator
Please
counterexample
something
little
worried
constructs
later
confusion
auth
old
functionality
nice
attention
current
user
access
unreasonable
own
patient
data
variant
interest
actual
user
institute
available
store.user
something
Sure
👍
Yes
fixture
😄
Fixture
special
Simply
filter
only
reason
POST
nowadays
double
negative
code
looks
good
Right
Hm
comment
code
case-specific
default
panels
suggestion
gene
panels
case-specific
default
gene
panels
Good
idea
update_status
[
open
]
open
submission
store.update_clinvar_submission_status
institute_id
submission_id
update_status
comment
nice
doc-string
small
function
constant
top
fixtures
something
other
test
file
Eh
semantics
mean
autosome
N
coverage
😊
sure
comment
human
readable
descriptions
computed
coverage
stats
MT
reports
populated
gene
database
top
function
new
case
wrapping
weird
comment
previous
code
points
cbook.delete_masked_points
comment
above
available
suggestion
..
_Tk
https
//www.tcl.tk/
..
_Qt4
https
//doc.qt.io/archives/qt-4.8/index.html
..
_wxWidgets
https
//www.wxwidgets.org/
Picky
good
Thanks
turn
parents
list
w/
plt.subplots
ndarray
natural
pass
parents
=
np.atleast_1d
parents
Picky
thing
comment
right
fig
ax_arr
plt.subplots
squeeze=False
something
plt.subplots
ndarray
tolist
flat
array
fine
reference
suggestion
suggestion
Axes
artist
layout
calculation
suggestion
b
intersect
angle
phi
comment
first
line
function
part
example
circumference
divider
plot
calculate
period
sentence
bullet
list
extra
backtick
provide
sentence
particular
parts
Figure
comments
demo
most
things
text
lines
benefits
vector
graphics
artists
images
mesh
SVG
results
huge
file
long
time
save
load
suggestion
d
=
np.arange
.reshape
values
color-mapped
concise
possible
comments
suggestion
xx
=
x
*
theta
y
*
np.sin
theta
rotate
x
-theta
yy
=
x
*
np.sin
theta
y
*
np.cos
theta
rotate
y
-theta
suggestion
focus
example
np.meshgrid
link
rendered
html
docs
people
comments
triple-quote
block
Individual
artists
vector
backend
such
PDF
SVG
PS
embedded
images
useful
file
size
large
artists
advantages
vector
graphics
other
artists
such
axes
annotations
instance
complicated
~.Axes.pcolormesh
~.Axes.contourf
Note
size
resolution
rasterized
artist
physical
size
value
dpi
kwarg
examples
interval_contains
*
locators
charge
sure
interval
interval
classic
mode
idea
1e-10
tolerance
something
return
None
Otherwise
loct
None
check
principle
artist
axes
coordinates
axes
similar
problems
annotations
annotation
boxes
axes
coordinates
h
v
lines
axes
boundary
legends
someplace
tutorial
way
connection
patch
example
prop_cycle
axes
actual
python
objects
line
error
documentation
[
]
*
prop_cycle
*
property
*
axes
loop
versus
times
API
design
call
bubble_plot.collapse
n_iterations=50
nicer
iterative
process
process
self
worth
example
logic
N
interactions
_much_
collapse
method
user
side
suggestion
new
bubble
collides
other
bubbles
suggestion
bubble_chart
=
BubbleChart
area=browser_market_share
[
'market_share
]
descriptive
parameter
name
comment
Needs
class
initalizer
first
thing
/
np.pi
list
suggestion
calculate
orthogonal
vector
suggestion
try
center
mass
note
source
randomness
kiwisolver
deterministic
parentheses
second
element
nothing
necessary
something
part
PR
code
OO
format
python
fig
ax
plt.subplots
homogeneous
list
tuples
same
dtype=
int
bool
int
Could
comment
line
expressions
behavior
comment
special
characters
newline
bit
strange
x
way
smaller
x
result
modulo
operation
obvious
way
random
number
same
comment
comment
brain
hard
time
line
sweat_smile
comment
line
parentheses
understandable
=
x
x
complex
TODO
valid
errors
pyccel
folder
pyccel.errors.messages
*
several
files
long
term
aim
syntax
errors
syntax
other
imports
pytest
error
line
whole
file
comment
end
line
case
few
enough
messages
syntax
only
object
errors.messages
PYCCEL_RESTRICTION_TODO
argument
segmentation
fault
Should
function
obsolete
folder
other
functions
useful
useful
most
cases
max
value
cases
max
float
Can
comment
mac
necessary
line
toto
pylint
disable=undefined-variable
undefined-variable
line
undefined-decorator
pylint
flag
disable
whole
file
case
line
please
rid
unnecessarily
concept
least
classmethod
someone
bin
part
feels
odd
..
reason
empty
class
class
UnsetBool
object
docstring
proper
docstring
API
public
more
sense
default
UnsetBool
suggestion
constructor
class
UnsetBool
object
def
__init__
raise
NotImplementedError
'nope
Eh
docstrings
new
wart
UnsetBool
ToolPrep.tool_instance_cls
path
pex
helper
function
glob
way
much
task
internals
fragile
test_tool_execution
un-equal
paths
lines
distinct
cases
whitespace
cases
first
comment
Check
valid
empty
__init__.py
comment
second
Check
valid
__init__.py
pkg_resources
setup
input
rename
input
added_files
clear
domain-level
function
defaults
Add
mode
suggestion
safe_file_dump
init_py_path
mode=
w
test_added_files_correctly_detected
quicker
intent
hm
URL
BinaryUtil.Factory
fine
version
URL
users
tools
proxies
space
padding
set
generator
fc
....
dependencies
>
fc
dependencies
goal
line
mixin
things
output
cloc
separator
character
LineOriented
methods
Console
comment
hack
hack
pexes
PATH
form
PythonSetup
interpreter-search-paths
option
https
//github.com/pantsbuild/pants/blob/455190b28609e33acc1d340dbf6733e7b980294a/pants.remote.ini
L30-L40
Consider
issue
bootstrap
implicit
binary
requirements
BinaryUtil
more
deep
bootstrapping
c
compiler
toolchain
way
building
perl
rules
way
/
requirements
users
better
/
error
message
environment
EPR
required
binary
suggestion
isinstance
checks
expensive
abstract
base
classes
such
Mapping
better
Type
vs
object
verbose
form
Get
[
ProductType
]
SubjectType
subject
subject
form
Get
[
ProductType
]
SubjectType
<
constructor
args
subject
>
docstring/comment
good
Done
TODO
type
info
nit
s/inputted/input
Neat
Consider
validation
failing
Malformed
string
Please
./pants
help-advanced
options-scope
documentation
known-versions
options
scope
_
code
purposeful
indenting
sense
white
space
log
purposeful
case
Skip
message
couple
lines
catch_warnings
threadsafe
https
//docs.python.org/3/library/warnings.html
warnings.catch_warnings
specific
ignores
error
code
ignore
MyPy
look
error
code
return-value
type
ignore
[
return-value
]
example
Disagree
official
type
stubs
lot
attention
Python
intentional
resources
NB
typical
leading
space
style
Consider
@
classproperty
s/comment/docstring/
snake_case
lower
overridable
overridable
bit
magical
magic
kind
like
cases
list
useful
cases
folks
useful
notice
more
letter
deprecation
law
situation
facility
list
unlikely
only
case
goal
porting
bunch
cases
people
likely
mistake
Thoughts
alternative
name
path
binary-search-path
pex
binary
important
thing
true
influence
interpreter
code
rest
docstrings
WARN
lookup
separate
Process
specific
subsystem
direction
ie
PATH
something
possible
deprecation
blocker
clear
env
intrinsic
rest
binary_search_path
option
PATH
global
option
overridden
Process
TODO
//github.com/pantsbuild/pants/issues/10507
parameteration
more
benefits
costs
cost
little
difficult
magic
numbers
need
comments
information
code
def
test_timeout_greater_than_maximum
>
None
assert
get_timeout_seconds_for_target
test_target_timeout=10
default_timeout=1
timeout_maximum=2
def
test_timeout_valid_target_timeout
>
None
assert
get_timeout_seconds_for_target
test_target_timeout=2
default_timeout=1
timeout_maximum=3
implicit
understanding
sure
comment
necessary
specific
issues
TODO
possible
parameterized
type
file
possible
descriptive
name
possible
docstring
TypeVar
workunit
error
case
cache
task
cache
cache
users
settings
changes
fine
comment
whitespace
work
dependency
graphs
cross
classifiers
https
//github.com/coursier/coursier/issues/717
method
doc
argument
result
Nit
convention
codebase
comments
complete
sentences
https
//www.pantsbuild.org/styleguide.html
TODO
^^
example
case
directory
trie
all_paths
such
case
extra
match
*
*
/src/
*
/
source
root
foo
concern
subdir
former
better
something
globs
subdirs
source
roots
e.g.
src/py/foo/src/bar
find_by_path
candidate
source
root
important
failure
mode
s/SourceRoot's/SourceRoots
i.e.
apostrophe
sentence
period
Prefix
NB
comment
necessary
code
/
official
help
message
describe
couple
places
select
timeout
readable
something
common
behaviour
PY3
checks
something
def
check_readable
file_descriptor
int
timeout
int
py3_selector=DefaultSelector
PY3
Use
py3_selector
use
select.select
worth
directory
s/interprter/interpreter/
Coursier
json
output
forced
classifiers
invasive
change
issue
Coursier
bare
TODO
comment
//github.com/pantsbuild/pants/issues/5440
small
nit
lot
people
listening
point
digest
init
file
InjectedInitDigest
name
Feel
free
comment
top
nice
suggestion
digest
init
file
module
class
InitInjectedDigest
datatype
[
'directory_digest
Digest
]
pass
near
term
plan
fine
case
Please
fill
issue
link
unfinished
thought
todo
half-done
state
much
fine
things
review
effort
though
one
untrue
novelty
test
AbstractClass
convenient
way
support
@
abstractproperty
only
way
many
places
codebase
revelation
novel
comment
more
tests
check
parts
error
comments
fields
assertion
information
pattern
helpful
context
manager
assertRaises
example
python
self.assertRaises
MyError
cm
call
self.assertIn
'my
error
best
error
cm.exception
above
try
assert
python
self.assertRaises
TypedDatatypeInstanceConstructionError
cm
SomeTypedDatatype
self.assertIn
'my_val
cm.exception
self.assertIn
field
cm.exception
something
goal
pex
normal
pex
comment
syntax
same
thing
function
different
output
types
Union
something
comment
NB
comment
useful
TODO
stale
rust
good
comment
behavior
non-intuitive
particular
owners
source
file
way
least
let
comment
Document
keys
values
dict
https
//stackoverflow.com/questions/42268401/how-can-i-get-pytest-to-ignore-test-classes-that-dont-subclass-unittest
message
reason
one
traces
such
exception
message
front
center
change
good
stopgap
good
comment
special
casing
traces
clearer
post
comment
necessary
comment
less
information
fact
chroot
sufficient
fact
PEX_PATH
pex
code
location
suggestion
Add
.with_binaries
entry
points
CoercingEncoder
right
thing
map
fact
next
line
note
TODO
funny
funny
possible
parameter
constructor
necessary
zipkin_attrs
workunit
advantage
constructor
None
error
cases
suggestion
start_workunit
new
thread
local_tracer
empty
suggestion
start_workunit
new
thread
local_tracer
empty
span
storage
stack
suggestion
start_workunit
root
thread
local_tracer
same
self.tracer
possible
excessive
flakiness
good
ie
test
sleep
seconds
fewer
Nit
s/ran
by/
Can
use
deprecated_conditional
https
//github.com/pantsbuild/pants/blob/2e65f46e044ed6c9fce07a240615e7a96d8b7c27/src/python/pants/build_graph/build_file_aliases.py
L44-L50
nothing
node-specific
class
useful
TODO
pants.util.
comment
Lead
suggestion
CSV
summary
interpreter
constraints
whole
repository
summary
contains
information
target
headers
Target
Constraints
Transitive
Constraints
Dependencies
Dependees
.\n\nThis
information
useful
Python
migration
version
Use
Dependencies
Dependees
help
targets
easiest
low
dependencies
highest
impact
high
dependees
favorite
CSV
processing
tool
filter
e.g
pandas
spreadsheet
comments
longer
applies
part
block
comment
pattern
spec_roots
changed_options
blank
line
Hm
review
todo
result
class
sense
check
associated
place
rsc_outline_
thingies
*
rsc_outline_cc
*
rsc_outline_classpath
*
*
rsc_outline
*
rsc_outline_jobs
convention
zinc_compile_cc
rsc_compile_classpath
x
y
message
time
error
way
internal
testing
targets
jce.jar
optional
sense
<
optional
>
true
<
/optional
>
corresponding
POM
file
example
https
//oss.sonatype.org/content/repositories/releases/org/scalatest/scalatest_2.11/3.0.0/scalatest_2.11-3.0.0.pom
line
typo
Done
fair
verbose
Metacp
invocations
Metai
invocations
deliberate
Hm
jvm_compile
JvmPlatform.global_instance
.get_options
.compiler
abstract
property
current
tasks
compiler
jvm
compile
results
rsc
module
broken
method
longer
exists
nothing
code
references
codebase
tests
//
TODO
tho
sign
middleman
comment
RE
SetupPyNativeTools
rule
Python
conventions
snake_case
function
names
hundreds
call
purity
class
__call__
@
semantics
comment
sources
Pex
V1
comment
obvious
FieldSetsWithSources
needs
LintRequest
different
shape
earlier
obvious
FieldSetsWithSources
same
shape
IsortFieldSets
>
point
multiple
owners
Ditto
part
reason
lack
support
typed
collections
comparison
digests
appropriate
TODO
add
type
checks
file
sure
legal
glob
*
/
*
*
/
*
test
case
case
IIRC
injected
__init__.py
files
output
true
TODO
extend
InitInjectedSnapshot
field
added_files
init
files
final
report
benefits
dataclass
cons
particular
case
bit
manual
type
gotcha
nit
comments
class
members
arguments
constructor
Thanks
previous_signal_handler
None
block
no-ops
such
same
previous_signal_handler
=
cls.reset_signal_handler
new_signal_handler
try
yield
cls.reset_signal_handler
previous_signal_handler
comment
sort
point
code
normal
pattern
further
explanation
crazy
patterns
complete
versions
compiler
flexible
config
pants
list
option
users
configuration
module-level
constants
regexes
pants
startup
option
members
class
case
things
native
deps
current
platform
targets
ok
trade-off
such
time
per-root
resolves
way
other
suggestion
is_inner_run
=
self._env.get
'PANTS_INNER_RUN
reading
option
specific
parent
pantsd
pants
non-pantsd
runs
LocalPantsRunner
pantsd
variable
name
suggestion
help='The
build
ID
other
pants
suggestion
pants
command
inner
run
other
pants
command
unusual
behaviour
most
users
flag
pants
inner
run
behaviour
Rather
flag
_is_
suggestion
register
parent-build-id
default=None
suggestion
Currently
pants
option
pantsd
effect
people
flag
order
pantsd
side
effect
effect
clear
future
suggestion
option
parent
pants
inner
runs
informational
puposes
https
//github.com/pantsbuild/pants/issues/6071
TODO
deprecation
cycle
deprecation
removal
TODO
BuildInvalidator
removal
confident
correctness
script
point
i.e
is_py3_file
end-to-end
validation
Py3
end-to-end
validation
py23
worry
header
such
valid
py2
py3
passes
.join
first_lines
EXPECTED_HEADER_PY2
EXPECTED_HEADER_PY3
impossible
code
change
concern
code
try
code
branch
suggestion
Python
relevant
line
right
couple
issues
PythonSetup
SelectInterpreter
subsystem_dependencies
logic
PythonInterpreterCache
property
_python_setup
following
diff
diff
diff
git
a/src/python/pants/backend/python/tasks/select_interpreter.py
b/src/python/pants/backend/python/tasks/select_interpreter.py
index
..
a/src/python/pants/backend/python/tasks/select_interpreter.py
+++
b/src/python/pants/backend/python/tasks/select_interpreter.py
@
@
-13,7
+13,6
@
@
pex.executor
import
Executor
pex.interpreter
import
PythonInterpreter
pants.backend.python.interpreter_cache
import
PythonInterpreterCache
-from
pants.backend.python.subsystems.python_setup
import
PythonSetup
pants.backend.python.targets.python_requirement_library
import
PythonRequirementLibrary
pants.backend.python.targets.python_target
import
PythonTarget
pants.base.fingerprint_strategy
import
DefaultFingerprintHashingMixin
FingerprintStrategy
@
@
-24,10
+23,13
@
@
pants.util.dirutil
import
safe_mkdir_for
class
PythonInterpreterFingerprintStrategy
DefaultFingerprintHashingMixin
FingerprintStrategy
+
def
__init__
interpreter_cache
+
self.interpreter_cache
=
interpreter_cache
+
def
compute_fingerprint
python_target
compatibility
requirements
targets
global
constraints
interpreter
interpreter_constraints
=
PythonSetup.global_instance
+
interpreter_constraints
=
self.interpreter_cache._python_setup.interpreter_constraints
=
[
]
python_target.compatibility
hash_elements_for_target.extend
python_target.compatibility
@
-69,7
+71,7
@
@
class
SelectInterpreter
Task
python_tgts_and_reqs
return
python_tgts
=
[
tgt
tgt
python_tgts_and_reqs
isinstance
tgt
PythonTarget
fs
=
PythonInterpreterFingerprintStrategy
fs
=
PythonInterpreterFingerprintStrategy
interpreter_cache=PythonInterpreterCache.global_instance
python_tgts
fingerprint_strategy=fs
invalidation_check
relevant
targets
motions
interpreter
downstream
tasks
special
case
wrong
global_instance
bit
confused
comment
little
tricky
same
thing
batching
files
different
subdirs
files
like-names
last
file
like-name
one
loss
information
ignored
files
OK
loss
information
b
same
behavior
batching
docs
black
sure
single
argument
many
things
listed
directories
list
files
single
argument
set
list
multiple
files
same
dir
tuple
dirs
Please
TODO
definitions
ticket
unions
TODO
//github.com/pantsbuild/pants/issues/8351
TODO
//github.com/pantsbuild/pants/issues/4535
something
@
union
assumes
targets
union
targets
something
configurable
non-matching
targets
newlines
stdout/stderr
let
result.std
*
check
console.write_std
extra
newlines
pass
end=
TODO
//github.com/pantsbuild/pants/issues/4535
hasattr
check
TODO
https
//github.com/pantsbuild/pants/pull/8329
reason
ok
horribly
inefficient
implementation
D
stale
class
worth
static/class
methods
add
docstrings
good
useful
deprecation
matter
many
times
grammar
girls
'run
vs
/
JVM
case
Task
level
options
targets
build
reproducible
ie
someone
certain
command
line
flags
target
case
node_bundle
dependencies=
[
x
y
]
archive='tar
target
something
good
idea
node_bundle
goal
bundle
goal
symlink
realpath
thoughts
additional
target
node_bundle
much
sense
suggested
node_bundle
dependency
node_module
archive
node
modules
directories
valid/common
scenario
archive
options
node_module
target
Suggestions
welcome
unlikely
node_module
node_bundle
target
sure
high
overhead
practice
Does
differentiate
binary
library
package.json
node_bundle
target
sense
target
build
graph
root
uncertainty
target
argument
indentation
early
return
return
generator
coroutine
StopIteration
empty
iterator
=
self._lib.Broke
=
c.to_value
e.value
Hopefully
tomorrow
Close
..
last
parts
V1
BuildFileAddress
comment
local
zipkin
Add
comment
start
times
Fixed
sure
classpath
nit
classes_output_dur
doe
thing
plugins
scalac_plugin_search_classpath
only
thing
suggestion
MyResult.success
same
MyResult
'success
line
Hm
good
method
easier
comment
method
aware
only
reason
Exiter
file
KeyboardInterrupt
e
messaging
behavior
Exiter
import
time
bottom
exception_sink.py
active
able
exiter
reason
sure
specific
reason
exiter
pants_exe.py
first
place
particular
change
exiter
hygiene
Exiter
file
change
exception
string
same
tests
pass
error
comment
sorting
necessary
contributors
codebase
familiar
python
idiosyncracies
general
Py2
.items
new
list
Py2
whereas
Py3
lazy
dict
items
view
rule
future
simple—easier
wrapper
request
type
deprecation
PR
How
default
likely
current
test
fine
unlikely
more
time
improvement
TODO
commit
message
mentions
Caches
stdlib
context.log
latter
references
runtracker
impossible
Interesting
old
new
task
line
logging
tests
handlers
logger
test
something
ticket
tests
subprocess
tests
idea
cargo-culted
original
pytest_run
author
comment
meant
git
archeology
reveals
author
@
dt
edcd459b9cf96c3e5ffc8d6965df5f2e731b3b84
https
//github.com/pantsbuild/pants/issues/4296
comment
good
NoopExiter
many
things
post
merge
good
bit
context
case
while
Exiter
API
DaemonExiter
exiter
code
standalone
class
inherit
name
something
other
*
Exiter
classes
issue
PR
solution
PR
TODO
linking
name
PythonBinary
target
type
PythonBinary
point
python_binary
sole
thing
target
fields
PythonBinarySources
EntryPoint
next
PR
await
Get
[
Target
]
Address
python_binary_adaptor.address
username
TODOs
worth
github
numbers
little
odd
list
loop
good
idea
dependencies
protobuf
yea
part
clean-all
comment
code
code
file
%
time
people
own
trace
IDs
flag
actionable
TODO
fix
use
'current
hacky
glad
comment
behavior
os.path.join
specific
reason
quick
comment
way
sad
comment
file
couple
comments
way
character
limit
changes
Same
json_dir
thing
report
report
path
Nit
Period
matters
tiny
bit
sentences
thoughts
readers
Files
plural
file
run
class
universe
dirname
json_dir
comment
os.path.dirname
self.report_path
field
concepts
json_dir
report_file
report_path
report_path
_stack_per_workunit_root
accurate
name
Workunits
parents
different
thread
Tiny
nit
End
sentences
periods
sense
@
property
self._output_files
unused
Results
state
clunky
phrasing
much
information
name
field
build
state
dict
good
bit
brittle
over-elaborate
FakeWorkUnit
instances
sync
struct
test
simpler
comprehensive
workunit
struct
dicts
FakeWorkUnits
callbacks
fly
*
same
*
struct
several
different
structs
input
output
sync
make_fake_workunit
wu_dict
parent_wu
return
FakeWorkUnit
Set
wu_dict
parent_wu
def
generate_callbacks
wu_dict
parent_wu=None
wu
=
make_fake_workunit
wu_dict
parent_wu
reporter.start_workunit
fake_wu
child_dict
wu_dict.children
generate_callbacks
child_dict
wu_dict
reporter.end_workunit
fake_wu
def
check_callbacks
root_wu_dict
generated_wu_dict
=
generate_callbacks
root_wu_dict
self.assertDictEqual
root_wu_dict
generated_wu_dict
sure
couple
details
wrong
sense
general
easy
check_callbacks
variety
different
structs
various
edge
cases
intentional
Py3
Py2
reasoning
vast
majority
user
code
Py3
unnecessary
work
Py3
Py3
experience
Py2
experience
comment
order
brief
comment
Good
comment
Thanks
Done
big
leak
hermeticity
able
working
current
interpreter
PATH
https
//github.com/pantsbuild/pants/blob/4de08d613d9e70a53951b3ca2869835af6fd7b32/src/python/pants/backend/python/rules/python_test_runner.py
L68
preferable
Ditto
s/
/g
next
lines
line
Ah
other
problem
general
check
present
CI
passes
dead
code
Will
landing
./pants
setup-py
run=
bdist_wheel
examples/src/thrift/org/pantsbuild/example/distance
distance-python
results
whl
dist/pantsbuild.pants.distance-thrift-python-0.0.1/dist/pantsbuild.pants.distance_thrift_python-0.0.1-py2-none-any.whl
context
test
command
same
stdout
whl
field
_exit_with_failure
comment
accurate
_log_unhandled_exception_and_exit
Exiter
stream
failure
user
ExceptionSink
exception
logs
use
case
RemotePantsRunner
bit
exception
possible
log
files
thinking
situation
unhandled
something
ExceptionSink.set_destination
RemotePantsRunner
logs
thin
client
error
message
_all_destinations
bit
way
commented-out
incomplete
method
body
logs
useful
same/opposite
reason
situation
something
special-case
>
field
defaults
comment
accurate
signal-handler
output
exception
log
exception/signal
log
order
faulthandler
exception
log
signal/exception
handler
validity
exception
log
other
methods
docstring
handling
great
ensure_bytes
Eric
comment
register
choices
kwarg
register
execution-strategy
[
'nailgun
]
validation
only
guards
pexrc
PEX_PYTHON_PATH
againts
pexrc
PEX_PYTHON
appropriate
exact
single
interpreter
correct
answer
pex_builder.add_interpreter_constraint
str
interpreter.identity.requirement
env
interpreter.binary
'True
comment
safe
operation
dead
code
rsc
parallelism
zinc-only
scala
targets
vast
majority
targets
enum
-java
-scala
versions
good
idea
targets
rsc
compiles
dependencies
targets
java
sources
javac
rsc
output
https
//github.com/pantsbuild/pants/pull/7227/files
diff-074dd871ff62c835ab90d4a0a1264a63R314
https
//github.com/pantsbuild/pants/pull/7227/files
diff-074dd871ff62c835ab90d4a0a1264a63R549
coarser
strategy
intermediate
zinc_scala_classpath_from_rsc
product
diff
clear
TODO
describing
parallelism
non-rsc
targets
zinc
compiles
dependencies
dependency
graph
followups
end
result
mixed
compile
changes
terms
execution
graph
intermediate
products
several
comments
concerned
parallelism
performance
implications
dependency
graph
zinc
jobs
course
complex
part
whole
thing
lot
imho
maintainable
small
amount
time
rules
v2
engine
construct
graph
comment
sync
other
location
explanation
location
consumers
easier
multiple
lockfiles
options
default
lockfile
default
lockfile
repository
targets
default
advantage
individual
targets
lockfile
separate
resolve
part
reason
lockfile
docs
entire
function
make_hydrated_target
similar
inlined
implementation
different
test
files
util
function
early
API
example
apparent
EagerFileSet
TargetAdaptor
PR
TODO
Ah
good
catch
comment
higher-level
test
scope
creep
py37
case
comment
deleted
repo_dir
interpreter
version
comment
value
non-obvious
comment
impact
list
empty
suggestion
N.B
callable
protocol
Callable
lines
pathlib.Path
Path
get_buildroot
/
file
.read_text
.splitlines
]
Consider
something
test_includes_direct_dependencies
comment
direct
dependencies
transitive
Other
reviewers
known
TODO
integration
tests
Iirc
issue
parser.py
files
actual
build
root
cwd
file
parser.py
thinks
Bad
copy
pasta
python_test_runner_integration_test.py
python_tests
target
Python
target
able
create_python_library
method
above
comment
possible
scope
task
fine
followup
file
IO
method
call
pass
result
field
OptionsParseRequest
IO
rule
options
changes
suggestion
element
List
[
ParsedConstraint
]
ANDed
help
message
anything
user
strict
deps
full
explanation
help
message
None
placeholder
inflexibility
prospect
classproperty
indecision
style
files
pr
something
self-review
better
PythonTests
platforms
has_to_run_under_default_platform
target
PythonTests
case
platform
python_setup.platforms
something
may_add_python_platform_to_resolve
target
something
comment
docstring
has_to_run_under_default_platform
stale
code
bike-sheddy
PythonDistribution
same
effect
suggestion
source
root
drastic
bump
increase
reference
TODO
_fetch_pkg
comment
mine
TODO
import_root_map
Added
comments
weird
normal
definitions
==
address
=
address
worth
comment
correct
issue
project
IIRC
/
Note
behavior
https
//docs.python.org/3/reference/datamodel.html
object.__hash__
good
comment
link
mixin
declaration
order
latter
get_targets
method
effect
Use
SENTINEL
suffix
error
messages
example
hydrated_target.address.spec_path
old
code
snippet
comment
full
content
string
file
empty
present
else
displayed
helpfullness
pants.util.meta.classproperty
allows
docstring
kinds
properties
suggestion
good
brief
comment
jvm_target_with_sources
transitive
dep
strict_deps_enabled
strict_deps_disabled
assertions
obvious
dependency_library_entry
dependency_library_entry
TODO
update
suggestion
entries
dependencies
TODO
more
focused
cute
Hello
nice
re-started
failing
shards
failures
general
issue
Stu
email
timeouts
flaky
one
lots
PRs
only
failures
timeouts
Comment
relevant
statement
Hm
sure
COMPILE
DEFAULT
ie
==
COMPILE
|
RUNTIME
filter
effect
suggestion
_get_target_from_test
comments
priority
code
subject
comment
line
yield
able
feeds
MergedDirectories-
>
Digest
Snapshot
rule
Digest
path
stats
available
good
use
time
API
easier
Digest-
>
Snapshot
digests
easier
reason
TODO
Snapshot
MergedDirectories
possible
likely
Rust
changes
Digest-
>
Snapshot
TODOs
issue
links
everyone
reason
idea
TODO
specific
region
code
>
hard-code
argv
/usr/bin/touch
TODO
nice
abstraction
snapshots
file
contents
Done
https
//github.com/pantsbuild/pants/issues/7718
Thanks
explanation
PATH
same
file
sentence
comment
help
description
rules/core/fmt.py
comment
classpath
superset
'export_dep_as_jar_classpath
safe
'runtime_classpath
'export_dep_as_jar_classpath'
please
Thanks
test
set
warnings
issue
possible
test
separate
issue
warnings
issue
ticket
normalization
//github.com/pantsbuild/pants/blob/master/src/python/pants/source/wrapped_globs.py
L299
rust
necessary
important
lucid
comment
standard
travis
addons
thing
suggestion
instance
self.ExecutionStrategy
type
argument
docstring
smile
io.BytesIO
io.RawIOBase
io.BufferedIOBase
https
//docs.python.org/3/library/io.html
class-hierarchy
type
hint
e.g
form
docstring
inline
type
hints
helpful
module
FYI
Py3
sys.stderr
type
io._TextIOWrapper
sys.stderr.buffer
io.BufferedWriter
Python
open
file
follow-up
explanation
https
//github.com/pantsbuild/pants/issues/6632
issuecomment-430593574
TODO
comment
downstream
interpreter
consumers
interpreter
sort
importable
python
target
PythonRequirementLibrary
targets
such
targets
interpreters
IE
importable
targets
compatibility
constraints
Java
tools
jar
Could
comment
Java
Java
JDK
layout
http
//openjdk.java.net/jeps/220
details
way
types
classpath
Java
-addmods
option
Java9
July
comment
helpful
someone
Java
Good
point
comment
single
comment
accurate
previous
failed
run
comment
vs
static
class
.PluginField
union
Target
subtype
need
@
final
@
memoized_classproperty
def
_plugin_field_union
cls
>
Type
N.B
Target
subtype
own
union
plugin
fields
plugin
fields
target
types
return
union
type
f
cls.__name__
PluginField
suggestion
await
statement
assignment
end
suggestion
await
rule
point
sure
useful
datatype
example
stdout
stderr
irrelevant
ExecuteProcessRequest
fails
user
repetitive
requirements
ResolveRequirementsRequest
entry_point
interpreter_constraints
@
illicitonion
rule
order
@
rule
memoization
unfortunate
thing
API
perspective
sorted
constraint
datatype
fields
reasonable
datatype
wrapper
python
requirements
List
[
str
]
output_filename
str
entry_point
Optional
[
str
]
interpreter_constraints
List
[
comment
clear
cases
codegen
targets
synthetic
derivative
*
non-codegen
targets
codegen
targets
synthetic
derivative
first
cases
target
last
target
synthetic
derivative
wrong
Hm
order
codegen
task
synthetic
targets
issue
other
codegen
tasks
targets
order
synthetic
target
detection
Target.exports
able
exports
fact
targets
😞
change
extra
exports
original
exports
special
handling
synthetic
targets
changes
things
change
synthetic
targets
codegen
targets
exports
codegen
Doing
right
tricky
properly
modifications
change
tries
weird
edgecases
codegen
targets
different
tasks
interact
target-types
work
PEP
valid
Python
3-only
codebase
implicit
namespace
packages
e.g
Pants
repo
way
okay
functionality
functionality
error
message
target.adaptor.sources.snapshot
Snapshot
Hm
strict
deps
requirement
Pants
python
codebases
change
behaviour
v1
case
>
reason
short
cli
flag
names
reason
old
values
ci.sh
/
ci.py
script
/
alias
/
habit
audience
ci
scripts
small
safe
readability
diff
suggestion
TODO
normal
logging
output
order
native-image
zinc
issue
link
TODO
sure
code
reason
Larger
docstrings
other
pydocs
name
awesome
abc
_lock
guards
X
Y
Z
etc
suggestion
Directory
encoded
spans
nit
bit
blank
section
May
comment
suggestion
section
options
option
blank_section
=
len
section_values.values
change
sure
different
Different
mypy
pex
mypy
pex
user
code
different
value
python-version
conditional
little
confusing
comment
result
little
easier
transitive
dep
something
specific
comment
fine
practice
comment
/
TODO
=2.7
*
valid
specifier
anyone
worried
suggestion
FileContent
fp
b
Pants
package
importable
semantics
kind
field
value
non-optional
value
optional
None
Ughhhh
different
aliases
jvm
options
case
target
source
buildroot
clear
possible
restrictions
symlinks
engine
good
why/if
copy
zinc_args
product
compilation
similar
runtime_classpath
product
options.semantic
check
CI
failure
certain
weight
MyPy
code
lines
comments
Fine
IMO
pants_python_version
sufficient
global
options
recursive
other
subsystem
namespaces
more
comment
help
option
ambitious
same
help
expansion
pants-version
TODO
URL
See
explanation
vs
daemon=True
relevant
afaict
exceptions
scheduler
full
stacktrace
necessary
pantsd
ie
option
other
hand
marked
fingerprint=False
means
Scheduler
value
_that_
bug
Scheduler
option
fingerprint=True
loop
engine
MultiGet
processes
parallel
high
level
something
processes
=
pex.create_process
HTML
pex.create_process
XML
results
=
MultiGet
processes
result
results
result
below
[
Mypy
docs
]
https
//mypy.readthedocs.io/en/stable/generics.html
PEP-484
]
https
//www.python.org/dev/peps/pep-0484/
mention
HKTs
something
GOTCHA
_TAbstractOrderedSet
[
S
]
+
T
subclass
S
+
S
subclass
T
Freudian
slip
please
scala-isms
comments
<
means
nothing
average
target
audience
extern_val_to_str
definition
global
constraints
test
use
empty
snapshot
TODO
digests
TODO
old
test
comment
approach
obvious
documentation
RootRule
grasp
documentation
file
e.g
-e
cat
options
option
file
something
general
TODO
assert
s
Python
version
strange
behavior
pytest
consistent
testing
worth
longest
prefix
match
amongst
multiple
Hm
composibility
rules
rule
pytest
purpose
other
test
goal
possible
options
wrong
place
workaround
fact
https
//github.com/pantsbuild/pants/pull/8910
discussion_r363480513
ie
equivalent
[
TestResult
]
Params
Target
CoverageConfiguration
something
case
comment
TODO
TestOptions
subsystem
TestRunner
coverage
configuration
suggestion
field_constructor
=
[
alias
field_type
construct_field
need
separate
Field
subclass
Field
suggestion
aliases_to_field_constructors
field.alias
field
field
self.field_types
field_types
something
bit
confused
meta
concrete
reading
💯
Thank
much
easier
Likely
Address
property
Target
Address
followup
PR
core
abstractions
user-facing
error-wise
lot
guiding
something
java_library
target
target
some/BUILD:15
invalid
sources
argument
list
elements
type
string
number
element
Fine
as-is
today
sure
path
something
PrepCommand
v2
part
semantic
tasks
obvious
source
files
remote
source
perfect
sense
v2
world
V1-only
verbage
Good
point
couple
remnants
comments
Python
codebase
..
new
suggestions
grain
salt
sense
HydratedTarget
wrapper
HydratedTarget
build
graph
dependency
relations
addition
TargetAdaptor
Target
part
HydratedTarget
key
clue
higher
precedence
people
configuration
multiple
files
path
too.pytest.ini
explicit
extra
indication
part
name
comment
marks
warnings.py
suggestion
Filters
precedence
mark
cmdline
options
config
suggestion
point
'test_something.txt
'custom.txt
exist
test
directory
suggestion
point
'test_something.py
'custom.py
exist
test
directory
suggestion
r
Shortcut
.makefile
.txt
extension
Thinking
fixture
tests
non-repr
path
suggestion
return
File
%
s
%
d
%
s\n
%
s\n
%
os.getcwd
pathlib
case
next
comment
fact
useful
suggestion
faulthandler
test
Note
pytest-xdist
regard
Anyway
scope
PR
suggestion
users
option
suggestion
pytest-xdist
monkeypatches
sys.stderr
object
actual
file
suggestion
Do
faulthandler
warn
comment
way
s
’
t
assert
function
assert
function
suggestion
Strip
unreliable
ResourceWarnings
no-output
assertions
stderr
comment
clear
comment
A
quick
look
new
method
connected_workers
original
connected_workers
connected_managers
method
_hold_block
connected_workers
context
connected
managers
other
places
same
context
weird
comment
log
failure
docstring
default
low
real
use
large
systems
default
pbspro
torque
parameter
SSHChannel
set
>
self.ssh_client.set_missing_host_key_policy
paramiko.AutoAddPolicy
host
keys
Does
something
break
use
PIPE
end
blocks
pipe
writes
problem
parsl
https
//github.com/Parsl/parsl/issues/1628
unsure
sshd
hang
Better
pods
deployment
docstrings
parameter
high
throughput
executor
script
process_worker_pool.py
script
current
PATH
explicit
path
example
users
virtualenv/conda
environment
job
submission
install
process
script
available
current
path
script
block
setup.py
worker
environment
same
assumption
way
rid
path
mean
task
parsl
level
current
implementation
script
bin
parsl
runner
other
side
dependency
lines
code
file
package
file
worker
dead
code
self.max_idletime
config.max_idletime
docstring
diff
simple
strategy
strategy
comment
mean
use
logging
wait
tcp
connection
traffic
common
firewall
configuration
internet
a-while
i
>
exception
clause
trigger
*
function
config
run
rename
vs
del
different
behaviour
units
style
units
main
azure
AWS
providers
latest
release
version
parsl
template.py
consistency
version
github
master
version
type
annotation
syntax
python
>
=3.6
Use
something
type
Dict
[
object
JobStatus
]
end
line
resource_monitoring_interval
float
docstrings
wrong
PR
informative
description
scheduler_options
example
string
SBATCH
blocks
submit
script
scheduler
array
object
things
arrayOf
shape
foo
shape
bar
bool
example
options
something
[
image
]
https
//user-images.githubusercontent.com/1280389/29590901-34c4cf16-876a-11e7-96e0-073ecf1d474c.png
readable
list
dict
dict
following
keys
'label
'value
'label
visible
label
dropdown
'value
hidden
value
dropdown
value
dash
callbacks
boolean
optional
True
option
type
recursive
document
generation
component
docstrings
help
dcc.Graph
Keyword
arguments
id
clickData
dict
optional
Data
latest
click
event
hoverData
dict
optional
Data
latest
hover
event
|
clear_on_unhover
boolean
optional
True
clear_on_unhover
hoverData
property
|
user
unhovers
point
False
hoverData
property
equal
|
data
last
point
selectedData
dict
optional
Data
latest
select
event
relayoutData
dict
optional
Data
latest
relayout
event
|
user
zooms
pans
plot
figure
dict
optional
figure
object
schema
|
https
//plot.ly/javascript/reference
style
dict
optional
Generic
style
overrides
plot
div
|
animate
boolean
optional
Beta
true
animate
updates
|
plotly.js
animate
function
animation_options
dict
optional
Beta
Object
animation
settings
applies
animate
true
config
optional
Plotly.js
config
options
See
https
//plot.ly/javascript/configuration-options/
|
more
info
..
config
following
type
dict
keys
'staticPlot
'editable
'edits
'autosizable
'queueLength
'frameMargins
'scrollZoom
'doubleClick
'showTips
'showAxisDragHandles
'showAxisRangeEntryBoxes
'sendData
'modeBarButtonsToRemove
'modeBarButtonsToAdd
'modeBarButtons
'displaylogo
'plotGlPixelRatio
'topojsonURL
keys
following
types
staticPlot
boolean
optional
interactivity
export
image
generation
|
editable
boolean
optional
titles
move
annotations
sets
pieces
edits
separate
edits
config
item
overrides
individual
parts
edits
optional
set
editable
properties
edits
following
type
dict
keys
'annotationPosition
'annotationTail
'colorbarPosition
'legendPosition
'shapePosition
keys
following
types
annotationPosition
boolean
optional
annotationPosition
main
anchor
annotation
|
text
arrow
arrow
whole
thing
arrow
length
direction
unchanged
annotationTail
boolean
optional
annotations
arrows
length
direction
arrow
annotationText
boolean
optional
axisTitleText
boolean
optional
colorbarPosition
boolean
optional
colorbarTitleText
boolean
optional
legendPosition
boolean
optional
legendText
boolean
optional
edit
trace
name
fields
legend
shapePosition
boolean
optional
titleText
boolean
optional
global
layout.title
autosizable
boolean
optional
DO
layout.autosize
|
use
default
width
height
values
queueLength
number
optional
length
undo/redo
queue
|
fillFrame
boolean
optional
container
screen
frameMargins
number
optional
frame
margins
percents
plot
size
|
scrollZoom
boolean
optional
mousewheel
two-finger
scroll
plot
doubleClick
value
equal
false
'reset
'reset+autosize
optional
double
click
interaction
false
'reset
showTips
boolean
optional
new
users
hints
interactivity
|
showAxisDragHandles
boolean
optional
enable
axis
pan/zoom
drag
showAxisRangeEntryBoxes
boolean
optional
enable
direct
range
entry
pan/zoom
drag
points
drag
handles
showLink
boolean
optional
link
plot
|
sendData
boolean
optional
link
data
file
linkText
optional
text
sendData
link
|
displayModeBar
value
equal
true
false
'hover
optional
mode
bar
true
false
modeBarButtonsToRemove
list
optional
mode
button
name
modebar
button
names
https
//github.com/plotly/plotly.js/blob/master/src/components/modebar/buttons.js
|
Common
names
|
sendDataToCloud
zoom2d
pan2d
select2d
lasso2d
zoomIn2d
zoomOut2d
autoScale2d
resetScale2d
Cartesian
hoverClosestCartesian
hoverCompareCartesian
zoom3d
pan3d
orbitRotation
tableRotation
handleDrag3d
resetCameraDefault3d
resetCameraLastSave3d
hoverClosest3d
Geo
zoomInGeo
zoomOutGeo
resetGeo
hoverClosestGeo
hoverClosestGl2d
hoverClosestPie
toggleHover
modeBarButtonsToAdd
list
optional
mode
bar
button
config
objects
modeBarButtons
boolean
|
number
|
|
dict
|
list
optional
mode
bar
buttons
nested
array
|
outer
button
groups
inner
arrays
buttons
objects
names
default
buttons
displaylogo
boolean
optional
end
mode
bar
|
plotGlPixelRatio
number
optional
pixel
ratio
Gl
plot
images
topojsonURL
optional
URL
files
geo
charts
mapboxAccessToken
boolean
|
number
|
|
dict
|
list
optional
Mapbox
access
token
mapbox
trace
types
Mapbox
Atlas
server
option
|
plotly.js
public
Mapbox
server
code
code
recursive
code
https
//github.com/plotly/dash/blob/master/dash/development/base_component.py
L287-L419
comments
Slider
moment
dash.no_update
errors
section
part
update
New
v0.38
comment
note
legacy
users
bottom
section
Similar
//github.com/plotly/dash-docs/pull/813/files
diff-52557333f7abf15f2706b6aac3a80652R91
suggestion
Input
dash.callback_context
title
section
component
part
layout
dcc.Tabs
props
updated
section
above
misleading
information
Side
note
least
non-determined
behavior
DataTable
derived_
*
props
table
least
part
https
//github.com/plotly/dash/pull/1103
recommendations
>
filesystem
following
recommendations
data
own
app-specific
folder
>
entire
filesystem
[
Filesystem
Hierarchy
Standard
FHS
]
https
//en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard
folders
/srv
folder
good
conventional
place
app
level
data
fence
section
section
sort
Deploy
Dash
Apps
Plotly
Enterprise
section
Configuration
>
Project
Files
>
More
application
Dash
Deployment
Server-ready
different
types
files
Dash
Deployment
Server
section
sections
Required
Files
Optional
Files
Optional
Files
extra
features
apt-packages
file
app.json
file
pull
requests
examples
https
//github.com/plotly/dash-on-premise-sample-app/pull/3
https
//github.com/plotly/dash-on-premise-sample-app/pull/2
admins
able
something
>
Redis
feature
Plotly
Enterprise
administrator
[
other
dcc.SyntaxHighlighter
sections
section
Referencing
Environment
Variables
Code
Running
Locally
*
*
*
Environment
Variables
Code
variables
os.environ
module
database_password
=
os.environ
[
'DATABASE_PASSWORD
]
variable
environment
other
value
use
database_password
=
os.environ.get
'my-default-database-password
Environment
Variables
Your
Local
Environment
environment
variables
code
variables
local
environment
easy
way
variables
app.py
python
app.py
DATABASE_USER=chris
DATABASE_PASSWORD=my-password
python
app.py
session
export
DATABASE_USER=chris
export
DATABASE_USER=chris
python
Do
consistent
Maybe
Deploy
Requirements
Application
Structure
Application
Requirements
Deploy
Requirements
operational
comfortable
git
actual
code
american
english
british
english
Whilst
comma
Similar
environment
variables
section
section
Directory
Mapping
>
File
System
Code
>
directory
/srv
/srv/app-data
files
folder
following
code
import
os
file_pathname
=
os.path.join
'data
'some-file.csv
>
cases
filesystems
deployed
application
different
application
code
environment
following
code
os.environ
deployed
app
filepath
=
os.path.join
'data
'my-dataset.csv
local
file
path
filepath
=
os.path.join
'Users
'data
'my-dataset.csv
example
contents
python-2.7.13
python-3.6.6
case
dopsa
https
//github.com/plotly/dash/pull/322
documentation
screenshot
little
bit
confusing
PASSWORD
DATABASE_USER
PASSWORD
name
environment
variable
similar
right
hand
side
form
left
Let
sure
real
world
example
Maybe
let
descriptions
files
i.e
ones
https
//github.com/plotly/dash-docs/pull/136/files
diff-29b3786f65c5f0e2a90c92fa20aa8785R374
Let
note
linking
works
>
redis
instance
multiple
apps
unique
Redis
Database
individual
app
unique
Redis
Database
Dash
app
easier
application
data
separate
application
line
break
[
image
]
https
//user-images.githubusercontent.com/1280389/44159365-25331780-a085-11e8-9c44-971ed9813b50.png
@
T4rk1n
work
windows
your-dash-app-name-stage
>
Plotly
Enterprise
secrets
environment
variables
application
good
practice
application
secrets
database
passwords
code
>
secrets
code
environment
variables
Dash
application
code
update
little
context
Redis
something
>
Redis
powerful
memory
database
many
Dash
applications
>
particular
Redis
Enable
processes
Celery
Redis
Celery
Demo
App
]
https
//github.com/plotly/dash-redis-demo
Save
application
data
>
Cache
data
callbacks
processes
[
Dash
Redis
]
https
//dash.plot.ly/performance
>
Redis
_in
memory_
database
data
server
safe
production
usage
Dash
Deployment
Server
secure
instances
Redis
application
consistent
looks
indendation
s
everything
left
gutter
[
image
]
https
//user-images.githubusercontent.com/1280389/44241209-6f54ef80-a190-11e8-9219-b7bb9dd17cc3.png
helpful
inline
example
manual
configuration
comments
readers
focused
code
text
explanation
same
indentation
problems
snapshot
https
//percy.io/plotly/dash-docs/builds/3858298/view/230583995/1280
mode=diff
browser=firefox
snapshot=230583995
Written
Folder
Reference
Header
search_params
login
Ill
previous
comment
urljoin
need
string
https
//github.com/pymedusa/Medusa/blob/master/medusa/providers/torrent/html/alpharatio.py
L166-L168
title
download_url
https
//github.com/pymedusa/Medusa/blob/master/medusa/providers/torrent/html/alpharatio.py
L135-L139
TODO
TODO
lol
little
comment
nice
Same
strip
'-
little
hacky
alternatives
imports
app
classes
properties
module
Whe
getters/setters
episode
status
file
status
SNATCHED|DOWNLOADED|ARCHVED
Operations
single
resource
resource
list
resource
list
Can
comment
pylint
disable=unused-import
p23
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Parameters
overridden
'search
method
]
https
//www.codacy.com/app/pymedusa/Medusa/pullRequest
prid=648782
newest_version
current_version
anything
class
cleanest
UpdateManager
methods
exception
def
newest_version
NotImplmentedError
def
current_version
NotImplmentedError
@
p0psicles
new
setting
PROPER_SEARCH_DAYS
search
setting
already_processed
propers
configurable
days
@
i
doubt
days
PROPER_SEARCH_DAYS
OK
change
proper
duration
proper
imo
sense
Please
class_=
syntax
Daily
search
results
self.calc_seeds
results
Manual
search
results
Same
docstring
type
item
better
example
Cache
search
result
necessary
Please
check
below
shows
imdb
entry
exception
changes
container
new
image
old
hash/branch
TODO
PR
body
Stop
max
proper
tags
tag
result.proper_tags
[
:3
]
score
+=
percentage
score
old
NumDict
way
comments
old
misleading
StatusStrings
code
api
v2
index
fine
guessit
GuessIt
type
movie
min_time=1
class_=
lot
double
quotes
thing
animes
absulute
numbering
show
Medusa
inclined
latter
'Remux
'BR-Rip
incorrect
Full
HD
HD
intact
name
parser
_guesses_
fine
OrderedDict
dict
Remove
hash
pubdate
Okay
@
p0psicles
checks
show_obj.scene
=
scene
user
change
vars
i
tje
flag
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Use
insecure
function
consider
safer
ast.literal_eval
]
https
//www.codacy.com/app/pymedusa/Medusa/pullRequest
prid=587257
ast.parse
cache
@
ratoaq2
@
p0psicles
ValueError
clear
status.name
logger
message
code
better
TODO
hardcoded
language
handle
subtitles.py
fact
support
software
Kodi
Plex
problems
pt-br
pr-BR
case
sensitive
app.TV_DOWNLOAD_DIR
sense
root
_UNPACK
app.TV_DOWNLOAD_DIR
Ca
better
python
root
_
os.walk
app.TV_DOWNLOAD_DIR
topdown=False
Must
files
NZB
client
logger.info
root
root
root=root
u'_UNPACK
root.upper
2017-05-06
INFO
FINDSUBTITLES
[
ce27a23
]
Checking
root
/media/SAMSUNG/media/downloaded/series/Bull.S01E20.Make.Me.1080p.AMZN.WEBRip.DD.5.1.x264-RTN-Scrambled/_UNPACK
2017-05-06
INFO
FINDSUBTITLES
[
ce27a23
]
Checking
root
/media/SAMSUNG/media/downloaded/series/Bull.S01E20.Make.Me.1080p.AMZN.WEBRip.DD.5.1.x264-RTN-Scrambled
Did
issue
doubt
root
Check
line
code
same
different
info
Most
providers
pubdate
comment
consistent
way
HorribleSubs
publication
date
comment
True.
case
more
explicit
way
things
easy
record
codes
end
favour
comment
type
assertQuerysetEqual
preferred
python
parent
=
GoodsNomenclatureIndent.objects.filter
indented_goods_nomenclature__item_id__lte=item_id
indented_goods_nomenclature__valid_between__contains=
new_row.start_date
new_row.start_date
new_row.start_date
new_row.start_date
depth=parent_indent
'indented_goods_nomenclature__item_id
]
correct
job
end-dating
described
other
comment
parents
children
combination
unit
qualifier
measurements
table
order
number
definition
–
issue
reason
model
footnote
association
model
historical
data
regex
validators
validators.py
easier
sharing
serializers
other
comments
import_indents.py
helpful
–
goods
E.g
|
Commodity
code
|
Suffix
|
Indent
|
Real
Depth
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
codes
chapter
headers
Nothing
wrong
code
comment
suggestion
_
digital_ocean_module
https
//docs.ansible.com/ansible/latest/modules/digital_ocean_module.html
digital-ocean-module
suggestion
instance_name
=
_config
[
]
]
[
]
_config
[
]
+=
[
instance_name
]
duplicate
platform
name
lines
Please
specific
warning
everything
wholesale
comments
comments
code
changes
comment
test
code
simple
require
such
comments
Just
thought
religious
comment
style
promise
comment
tox.ini
comment
code
few
lines
comment
next
looks
unorthodox
next
one
suggestion
log
=
logger.get_logger
__name__
line
mobile_tag
latest
Let
part
docstring
🆗
six.moves.configparser
same
bit
https
//github.com/tox-dev/tox/issues/1172
issuecomment-471071464
unkillable
^C
reproduction
non-parallel
mode
sure
code
comments
seconds
ms
file
structure
declaration
simple
dictionary
textrap
+
write_text
more
idiomatic
Python
way
plain
example
py
key
value
out.items
isinstance
value
bytes
[
key
]
=
.decode
'utf-8
binary
data
object
UTF-8-encoded
string
case
acoustid
fingerprint
example
raw
binary
blob
representation
text
[
standard
library
function
]
https
//docs.python.org/2/library/base64.html
base64.b64encode
bytes
ASCII-safe
bytes
.decode
'ascii
text
string
JSON
encoder
line
line
length
limit
characters
]
https
//travis-ci.org/beetbox/beets/jobs/460820041
L1086
comment
preceding
line
suggestion
Drop
path
user
multiple
times
=
[
k
k
included_keys
k
=
'path
]
[
spaces
inline
comment
]
https
//travis-ci.org/beetbox/beets/jobs/460820041
L1087
suggestion
val.pop
None
path
item
present
__xonsh_env__
-xSSE2
-axAVX
-axCORE-AVX2
-ipo
case
target
machine
old
AVX
host-specific
optimization
flags
Spack
way
host
cross-compiling
users
host-specific
flags
compilers.yaml
P.S
one
package
line
compiler
flags
line
entire
if-statement
spec
with-openmp-flag=
self.compiler.openmp_flag
users
other
compilers
+openmp
non-Apple
clang
users
Apple
clang
users
need
own
checks
Thanks
suggestion
comment
link
Arch
linux
patch
Spack
Homebrew
https
//github.com/Homebrew/homebrew-core/blob/master/Formula/lua.rb
bottom
better
version
Spack
versions
numeric
versions
non-numeric
versions
exception
greater
anything
else
correct
default
version
greatest
_numeric_
version
Thanks
info
special
treatment
minds
great
newest
sure
wisest
normal
cluster
ie
stable
develop
default
version
eg
spack
spec
-I
openfoam-com
newest
numeric
Can
behaviour
motivation
revision
next
package
spec
update
LIBXSMM
development
many
releases
stable
revision
Major.Minor.Update
series
i.e.
latest
Update
Minor
revision
leaner
specification
dead/commented
attempt
shared
library
item
mind
stable/tested
package
specification
worth
variant
right
case
package
blas
Users
BLAS
implementation
command
line
spack
install
^intel-mkl
trouble
ATLAS
ATLAS
developers
look
package
generic
compiler
BLAS
library
QBox
atlas
BLAS
spack
ATLAS
icc
pgi
clang
available
system
dependency
atlas
openblas
necessary
stuff
GCC
template
everything
copyright
mirror
URL
good
suggestion
better
way
tradition
Spack
mirror
http
//spack.readthedocs.io/en/latest/mirrors.html
modifications
package
comment
package
more
other
CMakePackages
Spack
stuff
belongs
documentation
right
section
docs
edit
clear
Does
MPICC
result
Could
explanation
comment
Sorry
obvious
examples
other
spack
packages
Type
'build
dozen
dependencies
setup.py
look
install_requires
setup_requires
setuptools
line
package
gmp
mpir
Crypto.PublicKey._fastmath
latter
gmp
fine
package
pkg_resources
versions
Python
python
depends_on
type=
'run
Use
https
//pypi.io/packages/source/c/cutadapt/cutadapt-1.13.tar.gz
line
hopes
headaches
Intel
components
32-bit
libraries
libc
libstdc++
mkl_link_tool
-h
mkl_link_tool
error
shared
libraries
libstdc++.so.6
wrong
ELF
class
ELFCLASS64
fix
list
COMPONENTS
x86
things
anyone
32-bit
support
code
bug
side
other
variables
loop
sense
comment
mpicc
friends
intel
typo
adoptation
>
adaptation
%
clang
way
rid
template
problem
gcc-7
DEBUG
OPT
PIC
variants
please
lib
names
other
package
blas/lapack
lapack_blas
[
'lapack
]
.libs
+
[
'blas
]
.libs
lapack_blas.ld_flags
http
//spack.readthedocs.io/en/latest/llnl.util.html
module-llnl.util.filesystem
quiet
https
//github.com/LLNL/spack/blob/develop/lib/spack/llnl/util/filesystem.py
L744
doc
page
reason
http
//spack.readthedocs.io/en/latest/llnl.util.rst.html
highlight=librarylist
llnl.util.filesystem.LibraryList
good
comment
problems
branch
future
reference
separate
branch
changes
better
way
Which
Fortran+C
compiler
combos
work
name
detection
CMake
Autotools
whole
build
CMake
name
mangling
Hmm
Just
mvapich2
ch3_rank_bits
values
nothing
documents
acceptable
values
My
practice
package
pattern
PR
reflection
things
question
PR
minute
details
precedent
set
packages
style
time
effort
re-code
packages
new
style/policies
use
Spack
Just
curious
BLAS
LAPACK
same
package
case
BLAS
LAPACK
dependency
good
sheesh
i
Just
try
Ok
git
pull
upstream
OSX
LLNL
system
fortran
name
So
better
worse
thinks
superlu-dist
example
obvious
package.py
file
spack
variables
objects
lapack_blas
[
'lapack
]
.libs
+
[
'blas
]
.libs
=
-DUSE_VENDOR_BLAS
%
%
lapack_blas.ld_flags
BLASLIB
-L/some/blas/path
-llapack
-lblas
lower-case
l
options
LDFLAGS
_only_
uppercase
-L
options
LDLIBS
lower
case
multi-value
variants
values=
reason
multi-valued
variant
support
better
worse
values
things
crash
@
alalazo
mvapich2
latest
develop
branch
values
CXX=
%
s
%
spack_cxx
please
assert
beginning
w.r.t
allowed
values
dims
@
adamjstewart
instance/example
'values=
statement
packages
/Users/miller86/spack/spack/var/spack/repos/builtin/packages
scratlantis
repos/builtin/packages
%
grep
*
/
*
.py
[
scratlantis
repos/builtin/packages
%
Hmm
Well
@
davydden
depends_on
telephone
call
Brain
Van
Straalen
Chomb
Spack
github
path
same
github
download
save
unchecksumed
svn
download
Satisfactory
Ok
version
checksummable
work
default
Spack
version
%
s
%
spack_fc
>
My
question
PR
PR
hours
old
review
kinds
changes
typical
most
PRs
new
packages
strange/complex
builds
PRs
many
months
minute
details
precedent
set
packages
nobody
previous
precedent
Which
good
idea
more
stuff
>
style
time
fear
detailed
average
first-committer
humans
issues
>
effort
re-code
packages
new
style/policies
use
Spack
@
davydden
sorry
inquiry
need
install
method
MakefilePackage
*
*
*
*
install
method
MakefilePackage
default
install
method
results
'make
install
dummy
fastmath.tar.gz
file
wrong
install
README
file
fastmath
package
install
point
packages
pgi
url
url_for_version
correct
way
comment
join_path
==
os.path.join
convention
previous
conventions
meaningless
meantime
@
BarrySmith
convention
additional
files
Makefiles
p.s
binary
file
i
surprised
things
Well
different
route
BarrySmith
xsdk
_install_
_supposed_
adopted
convention
something
part
Spack
package
writers
join_path
code
url_for_version
simpler
simple
i
convention
i
*
*
*
install
bundled
package
@
alalzo
right
syntax
multi-valued
variants
install
meta-package
i.e
install
spec
prefix
Prevent
error
message
==
>
Error
Install
<
package
>
Nothing
==
>
Error
Installation
process
nonzero
exit
code
open
spec.prefix
'bundle-package.txt
w
out.write
bundle\n
dummy
fastmath.tar.gz
file
i
i
binary
file
Git
VCS
sake
dummy
installation
fact
week
least
>
little
Fix
incoming
comment
i.e
problems
scenarious
work
other
cases
spack
load
/Users/davydden/spack/opt/spack/darwin-sierra-x86_64/clang-8.0.0-apple/python-2.7.13-hcpozzgaht7gddrvyrn2fprcm5tmqqii/bin/python
python
Python
default
Mar
[
GCC
Compatible
Apple
LLVM
clang-800.0.42.1
]
darwin
Type
help
copyright
credits
license
more
information
>
>
>
import
io
>
>
>
RPATH
support
earlier
test-case
def
test_satisfies_matching_variant
check_satisfies
'mpich+foo
check_satisfies
'mpich~foo
check_satisfies
'mpich
foo=1
synonymous
syntax
check_satisfies
check_satisfies
'mpich
foo=true
'mpich+foo
check_satisfies
check_satisfies
'mpich
foo=False
'mpich~foo
BoolValuedVariant
s
case-insensitive
true
false
So
foo=TrUe
same
+foo
input
size
elements
self.value
famous
last
words
sure
precedent
variants
omp
mpi+omp
>
@
tgamblin
minor
philosophical
comments
w.r.t
much
defaults
package
build
system
unaware
precedent
Spack
Spack
*
package
best
set
defaults
package
Spack
build
variables
non-default
behaviors
bad
strategy
Spack
packaging
code
dependent
defaults
package
time
correct
approach
answer
defaults
fine
*
variant
*
default
same
thing
build
system
boolean
variant
defaults
lie
Additional
comment
same
sort
approach
+debug
+particles
i.e
arguments
values
build
defaults
rid
message
most
packages
Spack
sure
As
PR
longer
work
people
https
//groups.google.com/forum/
topic/spack/afI3-EbiglM
force_autoreconf
=
True
rid
dependencies
configure
script
url
line
URL
patches
developers
many
things
possible
build
time
+shared~fpic
depends_on
'yaml-cpp
http
//spack.readthedocs.io/en/latest/build_settings.html
more
information
packages.yaml
explicit
Nalu
moment
libraries
yaml
Nalu
future
moment
fpic
statement
conflicts
@
adamjstewart
comments
variant
necessary
earlier
please
drop
~variant
+epetra
i
guess
solvers
Ah
sense
custom
packages.yaml
machines
preferred
variants
Back
building
Trilinos
🙁
Again
Trilinos
package
file
exact
set
variants
packages
Nalu
compile
time
Trilinos
reason
own
Trilinos
build
Nalu
package
file
preferred
set
variants
command
line
install
time
reluctant
Understandable
🙂
trouble
double
negative
packages.yaml
own
local
settings
care
concretisation
line
Are
only
possible
trilinos
installation
specific
jrood-nrel
please
packages.yaml
such
things
command
line
packages
nalu
variants
~metis
only
thing
~shared
Nalu
moment
comment
obvious
>
Again
i
@
nalu
package
fine
trilinos+metis
metis
installation
trilinos
enabled
metis
same
other
things
@
jrood-nrel
Whenever
something
_others_
someone
nalu
^trilinos+metis
package
possible
nalu
builds
trilinos+metis
trilinos~metis
reason
people
general
specific
variants
specific
variants
*
*
*
*
package
case
yaml-cpp+fpic~shared
package
yaml-cpp~fpic+shared
explicit
good
one
merge
conflict
line
Create
list
pairs
pair
configuration
option
option
option
value
variant
uses
word
value
configure
options
able
@
platform=darwin
wrong
=
spec
[
'lapack
]
.libs
+
[
'blas
]
.libs
math_libs.ld_flags
put
intsead
-lopenblas
[
BLAS_ROOT
]
https
//github.com/ECP-copa/ExaSP2/blob/master/src/Makefile.vanilla
L132-L135
list
libraries
spack
lib64
i686
-DCMAKE_INSTALL_LIB=prefix.lib
bml
spackage
comment
OPENBLAS
generic
blas
buildsystem
Nice
hack
work
MPI
wiki
https
//github.com/ornladios/ADIOS2/wiki/Building-on-HPC-Systems
sure
good
thing
able
versions
right
line
stand-alone
thing
development
adios
none
note
spack
syntax
bit
non-pythonic
upper
bound
@
adamjstewart
extends
'python
only
thing
aware
DataMan
dlopen
things
static
environments
Cray
compiler
wrappers
static
mode
Other
additional
issues
@
chuckatkins
ADIOS2
transport
engines
MPI
nice
way
ADIOS
python
p
[
'+dataman
'+zeromq
'+hdf5
]
conflicts
p
@
adamjstewart
proper
way
package
python
package
ON
default
needs
default
AUTO
external
libs
further
dependencies
ZeroMQ
question
line
case
multiple
packages
same
library
example
MPI
BLAS/LAPACK
someone
dependency
adios2py
Python
bindings
adios2
confusion
@
chuckatkins
dataman
project
anyone
homepage
embedded
private
dependencies
built-in
external
versions
future
important
spack
integration
naming
convention
python
packages
spack
module
py-adios2
Interesting
DataMan
static
libs
conflicts
Hard
full
safety
DataMan
dlopen
conflicts
'+dataman
bad
Intel
fine
fantastic
Intel
fine
good
Good
question
@
JasonRuonanWang
wrappers
sure
pybind11
dependencies
matrix
operations
@
@
chuckatkins
DataMan
useful
*
*
ZeroMQ
DataMan
WAN
transport
@
chuckatkins
hard
time
dependencies
[
gRPC
]
https
//github.com/grpc/grpc
wish
yes
please
ax3l
DataMan
current
master
branch
ZeroMQ
WAN
transports
dependency
near
future
ZeroMQ
optional
library
ZeroMQ
transport
other
WAN
thank
patch
'ibm-ppc64le.patch
when=
@
:2.11.1
Temporary
patch
old
versions
'when
@
:2.11.1
Phew
closing
dicts
tuple
list
tuples
staticmethod
def
list_resources
url
md5
dicts
p
=
urlparse
url
.path.split
'/
name
=
p
]
package
=
re.sub
p
]
yield
url
md5
p
]
p
]
url
md5
name
package
list_resources
variant
name
description=package
resource
name=name
url=url
md5=md5
placement=package
name
work
lack
understanding
python
behavior
few
bits
re.sub
yield
name
package
p
]
p
]
dicts=
definition
def
_list_resources
visible
loop
def
list_resources
additional
dictionaries
ftp
//ftp.gnu.org/gnu/aspell/dict/0index.html
dicts
[
'ftp
//ftp.gnu.org/gnu/aspell/dict/en/aspell6-en-2017.01.22-0.tar.bz2
a6e002076574de9dc4915967032a1dab
'ftp
//ftp.gnu.org/gnu/aspell/dict/es/aspell6-es-1.11-2.tar.bz2
'8406336a89c64e47e96f4153d0af70c4
'ftp
//ftp.gnu.org/gnu/aspell/dict/de/aspell6-de-20030222-1.tar.bz2
'5950c5c8a36fc93d4d7616591bace6a6
]
d
dicts
p
=
urlparse
d
[
'url
]
.path.split
'/
name
=
p
]
package
=
re.sub
]
yield
d
[
'url
]
d
[
'md5
]
name
package
name
url
loop
variants
resources
url
definition
line
@
staticmethod
decorator
call
dict_url
loop
[
/home/hartzelg/tmp/spack-aspell/var/spack/repos/builtin/packages/aspell/package.py
line
<
module
>
class
Aspell
AutotoolsPackage
/home/hartzelg/tmp/spack-aspell/var/spack/repos/builtin/packages/aspell/package.py
line
Aspell
dict_url
md5
name
package
list_resources
TypeError
'staticmethod
object
callable
decorator
bit
works
analogous
bit
dictionary
fails
[
]
==
>
Executing
phase
==
>
Error
NameError
global
name
'list_resources
/home/hartzelg/tmp/spack-aspell/var/spack/repos/builtin/packages/aspell/package.py:98
install_dictionaries
@
run_after
'install
def
install_dictionaries
prefix
=
self.prefix
>
dict_url
md5
name
package
list_resources
name
self.spec
working_dir
package
[
method
>
phase
==
>
Executing
phase
==
>
Error
TypeError
list_resources
arguments
/home/hartzelg/tmp/spack-aspell/var/spack/repos/builtin/packages/aspell/package.py:98
install_dictionaries
@
run_after
'install
def
install_dictionaries
prefix
=
self.prefix
>
dict_url
md5
name
package
self.list_resources
name
self.spec
comment
AspellDictPackage
patch
[
[
least
release
https
//github.com/google/protobuf/pull/3406
comments
means
comments
commit
list
strings
big
string
equivalent
quotes
arguments
command
line
single
string
parallelism
Spack
able
need
output
build
Spack
spack-build.out
Basically
useful
rest
:4.6
std=c++11
flake8
test
failing
var/spack/repos/builtin/packages/protobuf/package.py:44
[
E261
]
least
spaces
inline
comment
support
C++11
https
//gcc.gnu.org/projects/cxx-status.html
able
comments
package
depends_on
package
Correct
build
error
-j
t
Ca
Test/Builder.pm
@
INC
@
INC
/usr/local/lib64/perl5
/usr/local/share/perl5
/usr/lib64/perl5/vendor_perl
/usr/share/perl5/vendor_perl
/usr/lib64/perl5
/usr/share/perl5
t/join.t
line
BEGIN
compilation
t/join.t
line
t/join.t
Dubious
test
wstat
subtests
Ca
Test/Builder.pm
@
INC
@
INC
/usr/local/lib64/perl5
/usr/local/share/perl5
/usr/lib64/perl5/vendor_perl
/usr/share/perl5/vendor_perl
/usr/lib64/perl5
/usr/share/perl5
t/mcf.t
line
BEGIN
compilation
t/mcf.t
line
t/mcf.t
....
Dubious
test
wstat
subtests
Ca
Test/Builder.pm
@
INC
@
INC
/usr/local/lib64/perl5
/usr/local/share/perl5
/usr/lib64/perl5/vendor_perl
/usr/share/perl5/vendor_perl
/usr/lib64/perl5
/usr/share/perl5
t/multx.t
line
BEGIN
compilation
t/multx.t
line
t/multx.t
..
Dubious
test
wstat
subtests
Test
Summary
Report
t/join.t
Wstat
Tests
exit
status
Parse
errors
plan
TAP
output
t/mcf.t
Wstat
Tests
exit
status
Parse
errors
plan
TAP
output
t/multx.t
Wstat
Tests
exit
status
Parse
errors
plan
TAP
output
Files=3
Tests=0
wallclock
secs
+
sys
CPU
Result
FAIL
make
*
*
*
[
]
Error
Makefile
BIN
check
beginning
file
check
BIN
t
perl
dependencies
TODO
'test
deptype
https
//github.com/LLNL/spack/issues/1279
depends_on
type='test
kinds
packages
Makefile
able
steps
separate
comment
perl
module
make
check
default
target
non-intuitive
logic
developer
side
Please
short
comment
line
something
>
CUDA=no
NOT
cuda
internal
search
CUDA_PATH
>
addition
latter
empty
CUDA
disabled
%
%
spec
[
'cuda
]
.prefix
'+cuda
spec
sure
CUDA_PATH
user
environment
i
python
code
clear
condition
below
whole
comment
scope
session
module
class
function
parser
tests
naming
convention
funcargs
pytest
context
def
test_foo
parser
parser
object
parser
=
parser
....
[
]
http
//pytest.org/dev/fixture.html
complete
documentation
fixtures
Ah
module.py
test
spack
module
scope
module
name
command
pytest
please
pointers
able
working
basic
tests
url
list
spack
url
test
url_for_version
url
file
//
/chlorop-1.1.Linux.tar.gz
.format
consistency
time
http
>
https
back
http
spack
versions
spack
checksum
longer
work
reason
change
change
PR
forth
versions
http
type=
'run
line
[
PerlPackage
]
https
//github.com/LLNL/spack/blob/develop/lib/spack/spack/build_systems/perl.py
L67
perl-extutils-makemaker
perl
modules
runtime
build-section
github
pkg-config
bash-completion
typo
>
weird
@
gmatteo
patch
necessary
abipy
repo
https
//github.com/gmatteo/abipy/pull/118
better
workaround
prefix.lib
package
case
dynamic
stick
fact
qtgraph
package
variable
homepage
comment
git
repo
available
comment
ha
ok
D
Comments
space
flake8
virtual
provider
sure
mkl
different
interface
part
proper
interface
'fftw
package
fftw
comment
package
blas
/
lapack
specific
BLAS
library
packages.yaml
CLI
involved
parmetis
brief
in-code
comment
ot
RPATHs
Out
curiosity
patches
cursory
look
website
typo
version
constraint
more
space
comment
flake8
happy
someone
emacs
comment
line
Flake8
compatible
....
same
thing
Logical
right
answer
Makefile
install
step
DESTDIR
PREFIX
places
DESTDIR
others
bug
Makefile
upstream
upstream
active
DESTDIR
build_targets
new
inc
flake8
tests
Comments
space
test
dependency
mock
complete
Windows
dependency
http
//www-03.ibm.com/systems/spectrum-computing/products/mpi/
homepage
URL
fake
user
package
error
current
mpi
packages
e.g
openmpi
self.spec.mpicc
=
join_path
self.prefix.bin
'mpicc
self.spec.mpicxx
=
join_path
self.prefix.bin
'mpic++
self.spec.mpifc
=
join_path
self.prefix.bin
'mpif90
self.spec.mpif77
=
join_path
self.prefix.bin
'mpif77
self.spec.mpicxx_shared_libs
=
[
join_path
self.prefix.lib
dso_suffix
join_path
self.prefix.lib
dso_suffix
anything
discrepancies
different
MPIs
spack
flake8
complains
git
add
reference
actual
content
file
Will
rid
versions
@
junghans
commit
master
branch
cmake2
version
most
other
packages
code
first
variants
depends_on
use
conditional
mpi
variant
return
args
loop
lammps
package
example
>
spack
spack
Could
comment
packages
advantage
other
file
exists
use
need
user
lot
perl
packages
difficult
sure
general
auto-detection
extra
overrides
relative
prefix
result
Ah
true
legacy
first
attempt
Thanks
need
prefix
relative
dir
u
%
s
full
string
Even
cleaner
self.prefix.lib
comment
brief
magical
operation
Extensions
private
tree
INSTALL_BASE
install_base
]
results
predictable
installation
tree
Perl
core
@
INC
structure
activation
extension
extendee
]
directory
tree
extensions
@
INC
extensions
bit
@
INC
directory
activate
extensions
]
]
https
//metacpan.org/pod/ExtUtils
:MakeMaker
INSTALL_BASE
]
activate
method
PackageBase
class
]
https
//metacpan.org/pod/distribution/perl/INSTALL
APPLLIB_EXP
objection
things
cleaner
search
path
/lib/perl5
sure
self.prefix.lib
/lib
something
/lib64
cleaner
spec.prefix
lib
remve
filter_file
edit
following
error
>
Error
TypeError
edit
argument
/lustre/home/acct-hpc/hpc-jianwen/spack/lib/spack/spack/package.py:1350
build_process
def
build_process
input_stream
build
own
process
python
module
space
build_environment.fork
Run
post
install
build
stage
>
spack.hooks.post_install
self.spec
Stop
timer
Code
mxnet/package.py
edit
filter_file
CC
=
gcc
string=True
filter_file
CXX
=
g++
string=True
@
serbanmaerean
necessary
Just
URL
Spack
URL
other
versions
most
default
CMake
flags
dependency
missing
sys.platform
==
install_requires.extend
[
'appnope
]
Spack-language
import
sys
depends_on
'py-appnope
type=
'run
when=sys.platform
==
'darwin
package
function
>
env
Nope
Spack
things
LD_LIBRARY_PATH
CPATH
anything
ESMF_
section
code
]
https
//github.com/LLNL/spack/blob/develop/lib/spack/spack/build_environment.py
L288
build.env
installation
environment
variables
Spack
most
Spack
work
current
directory
setup_environment
different
install
real
reason
method
setup_environment
lot
users
things
module
file
other
choice
environment
variables
install
Currently
things
issues
case
entire
environment
blacklisting
Cray
something
aggressive
package
testing
curiosity
when/why
intel-mkl
access
/opt
@
lee218llnl
anything
Intel
packages
openblas
depends_on
'blas
depends_on
'lapack
users
Blas/Lapack
declared
conflicts
atlas
compilers
dependencies
Spack
line
easy
way
make
variables
VAR=value
build-targets
CC
coevp
spackage
Same
favor
general
Blas/lapack
inverse
requirement
conflict
U
don
’
t
need
lower
Spack
intel-mkl
Spack
prefix
problem
comment
blas/lapack
filenames
Guide
case
conflicts
%
gcc
@
CC=env
[
CC
]
Use
self.compiler.cc
openblas
able
spec
[
]
u
‘
^intel-mkl
’
speck
act
gcc-6.1
gcc-6.4
broken
conflicts
@
:6.9999
LAPACKE
interface
conflicts
+1
date
idea
last
time
update
2015-02-11
version
number
different
route
something
mind
template
copyright
use
spack.directives.reserved_names
hard-coded
special
case
comment
comment
description
Does
Python
libraries
extends
MakefilePackage
description
blank
lines
flake8
compliant
spec
[
'hdf5
]
.prefix.include
spec
[
'hdf5
]
.prefix.lib
copy_tree
default
obvious
people
default
default
patches
huge
build
time
nauty
example
when=
someone
new
version
something
code
Sure
functionality
tests
'difficult
part
dependency
types
something
bar
=
Spec
'bar
bar
link
None
setdefault
recursive
Spec
constructor
expensive
setdefault
lambda
something
default
part
possible
normal
denormalized
specs
prior
version
Spec
DAG
copy
isinstance
spec_like
Spec
Spec
objects
literals
Ok
great
Sorry
documentation
changes
line
<
guide
http
//spack.readthedocs.io/en/latest/packaging_guide.html
version-comparison
newest
openfoam
version
conflict
somehow
i.e
when=
@
x.y.z
function
regular
directive
version
variant
patch
promised
build
error
parallel
more
sense
var/spack/repos/builtin/packages/man-db/package.py:46
[
E265
]
comment
var/spack/repos/builtin/packages/man-db/package.py:52
[
F841
]
local
variable
line
//
flake8
line
length
checks
URL
line
@
adamjstewart
need
help
flake8
little
worried
stuff
dependency
build
workaround
least
cleanup
code
intervening
error
move-back
clause
*
something
conditional
below
context
manager
python
contextlib
import
contextmanager
@
contextmanager
def
hide_files
*
file_list
baks
[
%
s.bak
%
f
f
file_list
]
f
bak
zip
baks
file_list
shutil.move
f
bak
yield
f
bak
zip
baks
file_list
shutil.move
bak
f
error
handling
cleanup
code
matter
code
conditionals
context
manager
python
hide_files
join_path
spec
[
]
.prefix.include
'dwarf.h
stuff
conditionals
Thoughts
package
AutotoolsPackage
things
Basically
install
method
def
configure_args
Disable
OpenCL
hwloc
OpenCL
library
build
time
run
time
[
disable-opencl
]
people
llvm
macOS
OpenMP
fine
better
check
qt
uses
python
str
self.spec.compiler.version
.endswith
'-apple
comment
fair
patch
ancient
versions
Perl
most
people
recent
version
Perl
Waffling
%
hand
changes
other
hand
research
*
change
pretty
sure
patched
form
safe
way
something
Internet
problems
Phew
patch
mozjs
independent
perl
version
happy
versions
sense
warning
message
different
other
Intel
packages
Quick
way
Spack
bison
Same
run+build
Default
link
[
documentation
]
http
//spack.readthedocs.io/en/latest/packaging_guide.html
dependency-specs
docs
cell
default
Add
more
space
comment
symbol
flake8
happy
args.append
%
%
spec
variant
Same
u
spec
compiler
if-else
other
words
explanation
conflicts
Spack
specific
version
install
llvm-openmp-ompt
@
towards_tr4
variant
version
incompatible
Can
comment
motivation
conflicts
next
person
package
instance
openmpi
specific
conflict
gcc
FIXME
template
stuff
license
import
line
Flake8
unhappy
😱
course
flake8
unhappy
class
CMakePackage
issue
way
@
citibeth
global
variants
automatic
propagation
variants
concretizer
near
future
Just
virtual
dependency
http
//spack.readthedocs.io/en/latest/packaging_guide.html
virtual-dependencies
Just
clear
Python
Perl
R
%
chance
build/run
dependency
http
//spack.readthedocs.io/en/latest/packaging_guide.html
dependency-types
other
MPI
library
conditional
dependency
meme+mpi
meme~mpi
same
thing
same
thing
examples
meme-mpi
package
meme-mpi
meme
-mpi
package
meme
mpi
support
meme~mpi
package
meme
mpi
support
meme
~mpi
same
meme
/home/mpi
tgamblin
spack
install
meme
-mpi
>
exact
command
Something
mpi
support
depends_on
when='+mpi
type=
'link
depends_on
when='+mpich
type=
'link
Input
spec
meme+mpich
Normalized
meme+mpich
^libgcrypt
^libgpg-error
^libxml2
^pkg-config
@
^xz
^zlib
^libxslt
^mpi
^perl
^gdbm
^readline
^python
@
^bzip2
^openssl
^sqlite
Concretized
meme
@
%
gcc
4.4.6~mpi+mpich~serial
arch=linux-rhel6-x86_64
^libgcrypt
%
gcc
arch=linux-rhel6-x86_64
^libgpg-error
@
%
gcc
arch=linux-rhel6-x86_64
^libxml2
@
%
gcc
arch=linux-rhel6-x86_64
^pkg-config
@
%
gcc
arch=linux-rhel6-x86_64
^xz
@
%
gcc
arch=linux-rhel6-x86_64
^zlib
@
%
gcc
arch=linux-rhel6-x86_64
^libxslt
@
%
gcc
arch=linux-rhel6-x86_64
^openmpi
@
%
gcc
fabrics=verbs
~java
schedulers=
~sqlite3~thread_multiple+vt
arch=linux-rhel6-x86_64
^hwloc
@
%
gcc
arch=linux-rhel6-x86_64
^libpciaccess
%
gcc
arch=linux-rhel6-x86_64
^libtool
%
gcc
arch=linux-rhel6-x86_64
^m4
@
%
gcc
arch=linux-rhel6-x86_64
^libsigsegv
@
%
gcc
arch=linux-rhel6-x86_64
^util-macros
@
%
gcc
arch=linux-rhel6-x86_64
^perl
@
%
gcc
arch=linux-rhel6-x86_64
^gdbm
@
%
gcc
arch=linux-rhel6-x86_64
^readline
%
gcc
arch=linux-rhel6-x86_64
^ncurses
%
gcc
arch=linux-rhel6-x86_64
^python
@
%
gcc
arch=linux-rhel6-x86_64
^bzip2
@
%
gcc
arch=linux-rhel6-x86_64
^openssl
@
%
gcc
arch=linux-rhel6-x86_64
^sqlite
%
gcc
arch=linux-rhel6-x86_64
mpi
@
MPICH
^openmpi
%
gcc
fabrics=verbs
~java
schedulers=
better
variant
+serial
~mpi
Bad
die
hard
recompile
readelf
-d
package
|
grep
R
*
PATH
shows
correct
possible
disable
MPI
enable-serial
option
yeah
install
-mpi
install
meme
~mpi
depends_on
when='+mpi
type=
'link
mpi
def
configure_args
spec
=
self.spec
args
=
[
]
'-mpi
spec
args
+=
[
enable-serial
]
spec
args
+=
[
enable-serial
]
return
install
meme
-mpi
usage
spack
[
-h
]
[
-d
]
[
-D
]
[
-k
]
[
-m
]
[
-p
]
[
-P
STAT
]
[
lines
LINES
]
[
-v
]
[
-s
]
[
-V
]
[
COMMAND
]
spack
error
argument
-p/
profile
explicit
argument
i'
>
~
MPI
variant
default
MPI
+serial
-mpi
~mpi
reason
latest
commit
appropriate
serial
valid
option
users
workloads
fat
nodes
default
dependency
type
most
packages
MPI
MPICH
Yeah
py-flake8
/
py-pyflakes
friends
strict
dependency
versions
dependencies
Spack
See
EasyBuild
framework
test
suite
installation
*
runtime
dependency
python
-O
-m
test.framework.suite
vsc-install
available
test
line
partial
hit
yellow
more
information
go
provider
versions
bug
able
@
tgamblin
possible
line
abundance
caution
sure
issue
PRs
Got
Thanks
@
filter_file
'/usr/local/qwt-
VERSION
prefix
'qwtconfig.pri
way
full
travis
test
suite
line
problem
statement
python
depends_on
depends_on
extra
comments
Python
Python
bindings
enough
package
MPI
support
HDF5
support
HDF5_IS_PARALLEL
+hdf5~mpi
~hdf5+mpi
hdf5
other
hdf5~mpi
+mpi
defaults
Personally
default
user
best
possible
version
reason
e.g
cuda
bindings
way
default
+mpi
+hdf5
hdf5+mpi
flann
defaults
hdf5
defaults
course
users
defaults
packages.yaml
hard
requirement
flexible
possible
understanding
[
section
]
https
//github.com/mariusmuja/flann/blob/master/CMakeLists.txt
L108-L112
only
place
boost
build_type
different
flags
cmake
line
definition
cmake_args
def
build_type
return
flags
CMakePackage
edit
-b
cmake
details
record
things
TODO
'test
deptype
depends_on
type='test
depends_on
'gtest
type='test
test
dependency
lines
+hdf5
spec
hdf5
+hdf5
+mpi
spec
hdf5+mpi
constraints
problem
multiple
depends_on
statements
same
package
specific
string
formatting
site_packages_dir
string
hard
requirement
restrictive
boost
thing
below
restrictive
restrictive
flann+hdf5+mpi
^hdf5~mpi
restrictive
flann+hdf5+mpi
hdf5+mpi
Please
comment
line
brief
explanation
links
//github.com/LLNL/spack/issues/3813
Same
comment
py-basemap
py-pbr
versions
Python
least
py-enum34
certain
older
Python
versions
Please
indicate
package
versions
Python
Python2-only
depends_on
Otherwise
comment
Python2
Python3
comment
helpful
>
Please
advise
guarding
clause
python
depends_on
@
:3.4.2
Concretization
broken
exact
syntax
woes
past
py-flake8
dependencies
least
python
necessary
necessary
u
comment
Personally
latest
version
package
single
build
system
package
everyone
life
interesting
technical
problem
@
alalazo
many
other
open
issues
old
versions
CMake
releases
someone
old
releases
worth
old
versions
i.e
codes
useful
dyninst
example
package
build
systems
disadvantage
many
nice
phases
CMakePackage
provideI
anyone
multiple
inheritance
@
alalazo
[
]
https
//github.com/LLNL/spack/issues/3642
issuecomment-290725251
tgamblin
How
frequent
cases
package
build
system
multiple
inheritance
box
build
system
class
variant
design
pattern
sense
later
stage
instantiation
actual
type
example
shell
build
system
instruct
AutotoolsPackage
CMakePackage
inspection
version
concrete
spec
CMake
run
dependency
mariadb
worth
vdep
future
mysql
providers
build/link
dependency
suspicious
run
dependency
codes
dependent
older
versions
SCR
team
versions
version
Delete
line
Hmm
@
comment
Wait
libx11
+X
sense
weird
X
deps
enable-headless
frustrating
Well
glad
dependencies
case
internal
blas
variants
sundials
part
bigger
DAG
i.e
dealii
petsc
trilinos
mumps
everyone
use
same
Blas/Lapack
different
Blas/Lapack
sundials
dynamic
linking
troubles
control
blas/lapack
sundials
/
openmp
consistent
other
packages
i.e
least
petsc
mump
superlu-dist
hypre
single
bool
variant
]
True
False
Compile
indices
openmp
pthread
exclusive
i.e
True
same
time
single
variant
variant
default='none
support
'pthreads
'openmp
blas/lapac
i.e
openblas
FYI
discussion
Spack
static/shared
https
//github.com/LLNL/spack/issues/5269
preferences
free
discussion
same
single
something
Sundials
regardless
superlu_mt
build
option
macOS
default
=
platfom
=
darwin
thanks
right
documentation
only
ones
necessary
new
spack
rid
dependencies
python
import
ipdb
.....
Huh
developers
lazy
dependencies
dependencies
py-ipython
dependencies
setuptools
ipython
nothing
sure
other
dependencies
necessary
specific
version
ipython
python
depends_on
'py-ipython
@
type=
'link
old
line
docs
py-biopython
apologies
python
module
setup
thinking
py-biopython
own
dependency
python
spec
only
time
hybpiper
used
python
building
docs
Typo
dependencies
dependency
scalapack
most
likely
depends_on
depends_on
'lapack
reason
~int64_blas
little
explanatory
text
logic
comments
helpful
depends_on
'blas
likely
build
other
blas
https
//github.com/LLNL/spack/issues/1712
variants
virtual
dependencies
@
adamjstewart
part
CMakePackage
Has
CMake-standard
build_type
stuff
CMakePackage
package.py
method
Again
potential
problem
Different
BLAS
implemenations
different
names
blas
libraries
package
BLAS
cost
http
//spack.readthedocs.io/en/latest/spack.build_systems.html
spack.build_systems.cmake.CMakePackage.build_type
lists
class
level
spec
language
bindings
tested_bindings
=
'+java
'+perl
language
bindings
additional
dependencies
untested_bindings
=
'+sharp
'+go
'+io
'+lua
'+ocaml
'+php
'+python
'+r
'+ruby
'+tcl
b
tested_bindings
+
untested_bindings
b
spec
depends_on
'swig
FIXME
template
stuff
license
template
everything
copyright
line
package
comment
discussion
other
PR
default
type
link
comment
comment
wrong
dependency
type
wrong
backends
exclusive
+mariadb
backend
[
database
object
DBO
creation
]
https
//github.com/emweb/wt/blob/3.3.7/CMakeLists.txt
L103-L105
exclusive
test
PR
description
section
something
similar
Okay
more
sense
code
account
use
spack.Spec
correct
install
prefix.bin
Thanks
[
'lapack
]
.lapack_libs+spec
[
'blas
]
.blas_libs
ld_flags
duplicates
install_tree
story
commented-out
resources
PLC
dataset
several
tarballs
ones
ones
likely
most
people
variants
tarballs
hugs
LLVM
similar
approach
inspiration
only
work
GCC
install
Makefile
GCC
Intel
tempted
Makefile
sources
files
CMakeLists.txt
only
GCC
Intel
compiler
explicit
library
specifications
fact
gfortran
specifications
necessary
comma-separated
list
strings
API
docs
@
mentions
file
user
point
variable
first
line
elpa
PR
uncomment
conflicts
fine
i
guess
oneliner
clause
flake8
tests
mixed
tabs
spaces
Please
use
spaces
line
URL
something
generic
https
//pypi.io/packages/source/c/cdat-lite/cdat-lite-6.0.1.tar.gz
optional
features
idea
values
boolean
variant
Hmm
more
natural
separate
variants
mind
multi-valued
variants
useful
things
exclusive
multiple
values
Boolean
variants
need
conflicts
way
Ok
kind
adamjstewart
one
other
features
exclusive
boolean
variants
own
useful
description
run
type
dependency
same
line
variant
noqa
end
flake8
skips
breaks
Ubuntu16.04
libpthread
others
locations
recursive
fix
i
issue
with-blas-libs=pthread
m
dl
with-blas-lib-dirs=/usr/lib/x86_64-linux-gnu'
actual
blas
libs
MKL
rid
template
everything
copyright
self.ctest
runs
ctest
command
line
different
test
same
spirit
builtin
function/method
Spack
CMake
Python
module
robust
ctest
able
command
line
arguments
Python
module
large
patch
file
QE
Did
big
patch
file
part
QMCPACK
distribution
patch
Spack
Spack
patch
QE
patch
file
downloaded
QMCPACK
distribution
William
convention
other
Spack
packages
Relative
paths
fine
prefix
arbitrary
sub-directories
prefix
python
def
install
spec
prefix
install_tree
'manual
prefix.manual
install_tree
'nexus
prefix.nexus
working_dir
self.build_directory
install_tree
'bin
prefix.bin
ctest
able
command
line
arguments
Python
module
command-line
arguments
self
ctest
'VERBOSE=ON
need
pass
ctest
self.ctest
@
naromero77
details
Blas/Lapack
part
self.compiler.cc
actual
compiler
Spack
compiler
wrappers
clause
ok
typo
th
ctest
'-L
'unit
ctest
'-R
'short
same
running
ctest
-L
unit
command
line
problems
single
string
options
intel-mkl
]
True
False
bit
integers
[
none
]
openmp
none
Multithreading
support
packages
libs
interface
Good
catch
text
Let
install
@
[
build_environment.py
]
https
//github.com/LLNL/spack/blob/36496b91740b2af0099dce6066722f763b38341f/lib/spack/spack/build_environment.py
L345
Will
text
qmcpack
end
libraries
lack
headers
include
directory
header
fftw
package
self.ctest
default
Spack
test
different
package
flags
CFLAGS
CXXFLAGS
environment
variables
compiler
wrapper
default_flag_handler
method
specific
cflags_handler
method
equivalent
flag
documentation
flag
handlers
idiom
compiler
default_flag_handler
flag_val
return
flag_val
]
different
environment
variable
cmake
different
variables
flag
handlers
adamjstewart
@
naromero77
questions
Same
depends_on
'fftw
technical
difficulties
Just
curious
builtin
function/method
Spack
CMake
Python
module
CMakePackage
thanks
kind
test
script
https
//pypi.io/packages/source/Q/QtAwesome/QtAwesome-0.4.4.tar.gz
format
https
//pypi.io/packages/source/
first-letter-of-name
/
name
/
name
version
.zip
capitalization/whether
py
pypi
name
comment
openmpi
general
mpi
python
args.append
without-metis
url_for_version
package
def
url_for_version
version
url
https
//gigenet.dl.sourceforge.net/project/netgen-mesher/netgen-mesher/
/netgen-
.tar.gz
return
url.format
version.up_to
version
someone
version
Spack
wrong
location
rid
line
homepage
@
mathstuf
+
necessary
Python
literal
strings
source
code
bug
mathstuf
Do
Pgp
interface
signing
comment
formatting
hard
line
pattern
example
paths
flake
better
way
disappears
produced
doc
cleaner
way
truncated
example
latest
commit
Sorry
approach
system
other
suggestion
reason
warnings
My
main
point
case
write
permissions
print
warnings
present
Spack
permissions
exceptions
Could
comments
parameter
names
example
Change
RPATHs
file
path_name
old_dir
new_dir
case
line
Extra
functionality
https
//github.com/LLNL/spack/pull/4868
output
function
example
verify
build
cache
specs
comment
https
//github.com/LLNL/spack/pull/4854/files
r131737394
external.key
creation
new
signing
key
external.key
useful
files
private
key
external.key
needs
tests
sure
gpg
old
changes
test
conftest.py
defaults
Sorry
key
signing
package
coverage
enough
%
IMO
donttrustthis.key
fair
test
binary
caching
anyhow
long
time
more
demand
much
time
Are
options
weaker
keys
GPG
tests
private
key
things
signatures
public
key
sure
use
binary
corresponding
private
key
test
private
key
while
private
key
IMO
binary
caching
easy
public
key
fixture
private
key
multiple
tests
public
key
Code
coverage
test
key
mirror
gpg_mock/external.key
gpg
tests
@
mathstuf
example
verification
case
Spack
package
external.key
OK
sense
private
key
gpg
tests
public
key
useful
new
tests
binary
caching
comment
obvious
first
glance
helper-method
get_one_box
way
key
frames
option
comment
good
addition
operation
Please
comment
section
method
call
other
methods
docstrings
things
suggestion
mouseovers
other
events
animation
lag
suggestion
axis
point
nice
comment
bit
*
usage
*
terms
window
unclear
b
logic
code
passing
function
double
negative
raise
window
Jupyter
app_name
=
self._qt_window.raise_
macOS
self._qt_window.activateWindow
Windows
comments
modifier
thereof
added
comments
Viewer
keybindings
ViewerModel
ones
functional
same
good
catch
comment
little
outdated
dtype
@
property
surface
layer
comment
width
calculation
bit
arcane
Could
comment
giant
block
text
hard
sections
nicer
tests
separate
test
functions
comments
docstrings
fixture
repeated
condition
suggestion
validate
[
]
ValueError
Nope
PEP257
compliant
joy
Suggestion
Ensure
current
dimension
order
dims
Parameters
less
crazy
comments
insert
syntax
vs
interval
explanation
[
docstring
NestableEventedList
]
https
//github.com/napari/napari/pull/1444/files
diff-e68dd71c52551aecc697df17b73e30cfR87-R95
note
inline
comments
test
point
object
SupportsEvents
Protocol
i.e
attribute
events
EmitterGroup
parent
container
events
root
container
index/indices
child
ren
event
event
super-important
events
future
LayerTree
list
model
stuff
test
event
emission
Mock
see
//github.com/sofroniewn/napari/blob/87910700153881903401c4f1d3f58285c94a674b/napari/utils/list/_tests/test_list_model.py
different
approach
fine
same
stuff/
approach
mock
good
way
event
emission
etc
repo
comment
code
API
mean
[
int
]
regular
[
tuple
[
int
]
]
a.index
int
custom
lookup
int/tuple
[
parametrized
fixture
]
https
//docs.pytest.org/en/stable/fixture.html
parametrizing-fixtures
super
useful
multi-parameter
test
matrices
Will
comment
links
suggestion
WAIT
module
reimplement
methods
suggestion
comment
issue
int
return
*
_T
NestableEventedList
[
_T
]
super
cool
btw
—
overload
IRL
implementation
unchanged
input
types
output
types
worth
comment
implementation
default
line
details
implementation
something
thread
i.e
comment
Talley
[
comment
]
https
//github.com/napari/napari/pull/1391
issuecomment-653939143
future
generations
and/or
—
comment
readers
self.components
contains
Talley
terrible
shift
point
point
Keynote
least
base
layer
//github.com/napari/napari/blob/51cedac63cb166c2851f10a28a86461aca43f635/napari/layers/base/base.py
L619
base
generic
name
image
_value
property
pixel
value
things
status
bar
future
PR
noqa
@
tlambert03
Can
noqa
python
pytest.raises
Runtime
error
Viewer
@
sofroniewn
little
allergic
noqa
way
flake8ignore
somesuch
better
implicit
inclined
heh
better
explicit
function
definition
comment
convert
NumPy
axis
VisPy
axis
Same
classes
docstring
=
pwinston
comment
line
meat
real_func
easier
function
work
new
viewer
layer
*
*
*
*
original
view_
method
combo_sig
[
inspect.Signature
]
https
//docs.python.org/3/library/inspect.html
inspect.Signature
object
representation
original
function
inner
real_func
part
body
view_
*
functions
e.g
data=data
name=name
scale=scale
view_func_code
compiled
code
safe
empty
namespace
locals
dict
python
function
name
real_func
fakefunc
real_func
line
Note
evaluation
step
python
def
view_
*
declaration
function
empty
namespace
documentation
Can
separate
function
_combine_docstrings
example
suggestion
def
layer_update
update_interval
num_updates
GC
function
reference
counter
debugger
suggestion
more
present
special
case
/
statement
python
assert
np.sum
view.dims._displayed_sliders
ndim
ndisplay
ndisplay
variable
test
default
value
comment
docstring
__init__
class
docstring
parameters
section
doctest-compatible
syntax
examples
]
https
//numpy.org/doc/stable/docs/howto_document.html
search
Examples
python
built-in
slice
object
Same
use
doctest
format
https
//numpy.org/doc/stable/docs/howto_document.html
section
name
Examples
trick
worth
[
QComboBox.addItem
method
]
https
//doc.qt.io/qt-5/qcombobox.html
addItem
optional
_UserData_
value
arbitrary
data
item
[
currentData
]
https
//doc.qt.io/qt-5/qcombobox.html
currentData-prop
let
boilerplate
forth
strings
floats
note
conversations
moment
better
worse
[
numpy
convention
]
https
//numpydoc.readthedocs.io/en/latest/format.html
class-docstring
napari
codebase
full
docstring
init
method
Parameters
section
class
docstring
way
selectable
text
qlabels
i.e
open
able
text
i
github
issue
screenshot
suggestion
exception
handler
f-strings
strings
logging
module
%
time
log-level
such
logging
formatting
effort
logging
module
older
style
Pylint
wil
flag
error
warning
only
reason
guideline
projects
past
pylint
performance
logging
important
common
case
See
https
//blog.pilosus.org/posts/2020/01/24/python-f-strings-in-logging/
way
Use
alternative
formatting
styles
section
logging
cookbook
new
custom
class
log
message
https
//docs.python.org/3/howto/logging-cookbook.html
async
JSON
format
issue
other
performance
issues
while
good
time
things
log
things
Same
comment
performance
comments
self.range
offset
+1
lines
someone
more
axis
labels
sure
suggestion
dims
world
coordinates
data
coordinates
comment
worth
super
first
line
setter
setter
side
effects
bad
smell
noses
bit
—
comment
line
suggestion
self._image_view.shape
]
image
RGBA
suggestion
register
napari
types
magicgui
LayerData
tuple
comment
b
return
type
base
layer
layers.Layer
NOT
subclass
subclasses
confused
=
Aha
tests
useful
pytest.raises
agree
xfail
interesting
something
mind
ID
approach
i.e
properties
track_id
present
data
Z
Y
X
data
ID
T
Z
Y
Z
nice
way
best
worlds
API
complex
other
hand
more
clever
more
difficulties
other
users/
tools
data
dict
cumbersome
best
approach
lines
stick
ID
yes
afaik
suggestion
suggestion
max
number
tracks
thumbnail
more
tracks
present
suuuuper
function
Could
docstring
numpy
coordinates
padding
data
flat
necessary
@
sofroniewn
merges
rid
suggestion
canvas
new
data
canvas
camera
automagic
thing
VisPy
worth
place
code
worth
i
comment
pyramids
suggestion
recalculation
corner_pixels
new
example
comments
refresh
methods
Fixed
Yes
comment
Ah
sorry
number
number
categories
factor
number
points
array
number
points
suggestion
QtViewer
model
necessary
None
none
related
code
anyways
Are
directory
watcher
[
watchdog
]
https
//github.com/gorakhargosh/watchdog
dependency
example
most
people
handy
final
file
eg
typical
data
instruments
lab
directory
watcher
napari
sure
user
Ctrl+C
terminal
nice
thing
example
key
assumption
files
filenames
assumption
fine
clear
docstring
comments
backwards
suggestion
*
*
*
viewer.layers
layers
—
grab
layers
]
😂
Can
comment
for/else
clunky
point
worker
Final
change
request
let
attribute
semi-private
=
people
viewer.
TAB
>
comment
attribute
set
napari.Viewer._napari_app_id
None
dock
icon
Windows
fact
None
empty
string
right
way
purpose
correct
future
proofing
statement
python
Set
camera
....
elif
Set
camera
....
error
ndims
datasets
last
volume
able
self.indices
dims.set_display
comment
original
code
comment
statement
whole
block
clear
different
current
approach
actual
function
signature
terms
names
things
comment
ones
special
treatment
iterable
lot
nicety
csv.reader
full
file
headers
function
alternative
def
iter_csv
filename
str
open
filename
newline=
csvfile
reader
=
csv.reader
csvfile
delimiter=
yield
reader
full
file
column
names
=
iter_csv
'file.csv
header
=
next
gen
i_dont_like_the
header
return
data
=
np.array
list
gen
note
output
current
read_csv
function
def
read_csv
filename
column_names
*
=
iter_csv
filename
return
np.array
data
csv_to_layer_data
def
csv_to_layer_data
filename
str
>
List
[
FullLayerData
]
gen
=
iter_csv
'file.csv
header
=
next
gen
layer_type
=
guess_layer_type_from_header
header
layer_type
return
[
reader_functions
layer_type
]
'file.csv
suggestion
Decompose
linear
matrix
sorry
earlier
f
file
built-in
name
Probably
comment
__main__.py
input
type
Iterable
iterator
object
array
value
iterator
upcoming
versions
NumPy
error
things
something
_string_to_rgba
color
alpha=1.0
PEP257
Return
hex
RGB
names
parsable
format
easier
Parameters
description
docstring
length
two_color
lists
identical
bugs
first
two_color
list
lines
second
list
comment
_start_thread=True
idea
user
worker
objects
constructor
easier
time
i
worker
=
Worker
myfunc
*
args
worker.start
i
decorator
myfunc
myfunc
separate
thread
suggestion
Request
worker
playing
simpler
convenience
decorators
other
words
more
flexibility
example
comment
something
decorators
Set
setup
main
thread
yield
function
different
threads
confusing
transition
first
yield
magic
unconventional
fact
pattern
weird
line
function
different
thread
something
function
generator
sense
kind
hidden
way
hidden
function
user
giant
comment
part
main
thread
worker
thread
need
comments
illustration
things
kind
hidden
compact
clever
clever
way
lot
functionality
implicit
built-in
stuff
anything
explicit
drawback
proud
simple
function
fact
simple
better
way
hand
My
guess
rid
idea
user
function
base
class
people
clear
method
runs
thread
everything
way
explicit
less
compact/clever
model
standard
way
learnable
people
documentation
bit
magic/custom
comments
suggestion
Request
worker
level
detail
documentation
thank
blush
suggestion
comment
code
more
comments
adj
averaging
[
]
—
logic
crazy
comments
=
suggestion
size
=
np.log2
np.max
comment
future
search
bar
top
Does
Qt
search
functionality
priority
curious
i
free
comment
free
yikes
bug
select_all
viewer
sure
comment
something
merge
hah
good
point
[
copying
]
https
//pluggy.readthedocs.io/en/latest/
the-host
kind
favour
default
users
easy
way
environment
variable
least
comprehensive
model
stability
security
plugins
logs
default
handler
default
level
basicConfig
order
logs
following
code
manager
plugin
import
logging.basicConfig
level=logging.INFO
bit
tricky
moment
imports
library
__main__
hard
loglevel
flag
CLI
same
reason
hard
info
flag
]
https
//github.com/napari/napari/pull/814
issuecomment-567628580
import
sort
separate
issue
logging
point
order
people
stuff
something
loguru
stdlib
easier
hotspots
something
lol
action
item
general
comment
suckiness
regex
thanks
while
issue
pyproject.toml
most
packages
source
pip
installed
package
[
poetry
plugins
]
https
//python-poetry.org/docs/pyproject/
plugins
example
plugin
discovery
mechanism
poetry
current
directory
path
/
pyproject.toml
poetry_file
=
locate
cwd
local_config
=
TomlFile
=
local_config.get
plugins
_developer_
poetry
build
system
pyproject.toml
file
root
i
examples
pyproject.toml
i.e
people
setup.py
manifest
pip-installed
packages
little
better
pyproject.toml
distributions
pip-installable
package
example
unique
explanation
below
sufficient
suggestion
Discover
convention
entry
points
terminology
little
confusing
distribution
installed
package
dist-info
package
term
distribution
consistent
others
more
metadata
setup.py
example
package
module
environment
_not_
dist-info
folder
entry_points.txt
file
generator
comment
effect
added
comment
easy
availability
try/catch
statements
pluggy
e.g
plugin_manager.PluginValidationError
plugins
pm._name2plugin
autodiscovery
happen
file
purpose
big
fan
emit_
names
i.e
length
average
present
please
explain
comment
array
connector
segments
comment
i
same
applies
Whoa
np.delete
Nice
use
else
clause
rare
cases
axis
singleton
suggestion
colormap
None
n_channels
colormap
=
iter
colormaps.MAGENTA_GREEN
elif
n_channels
colormap
=
itertools.cycle
colormaps.CYMRGB
colormap
cwood1967
desire
channel
information
front
convention
usability
fix
layer
names
opinion
image
number
end
suggestion
layer_name
=
f
name
layer
i
python
layer_name
=
f
name
ch
i
example
comment
expression
bit
comment
comment
monkeypatch
fixture
pytest
suggestion
image
pixels
tile
coordinate
space
full
resolution
data
suggestion
pixel
image
data
coordinates
suggestion
Note
top
location
top
left
canvas
thanks
[
mypy
example
]
https
//mypy.readthedocs.io/en/stable/common_issues.html
no-errors-reported-for-obviously-wrong-code
Must
return
type
type-check
arguments
type
hints
pluggy
]
https
//github.com/pytest-dev/pluggy/blob/6e8b6d4e8e0519e50af05b4e4b90b18b924bcbcc/src/pluggy/manager.py
L75
alias
own
plugin
manager
subclass
part
API
seperate
napari
pluggy
API
anyone
experience
pluggy
sure
setattr
brain
fart
state
needs
checkbox.stateChanged
signal
int
type
signature
suggestion
relationship
lists
bad
typo
suggestion
list
paths
list
layer
data
relationship
lists
iterate
first
name
while
i
comment
clear
i
odd
case
suggestion
data
face
color
effect
code
main
thread
bit
Aaaand
comment
mine
😂
BUT
thing
linked
comment
>
sure
consequences
people
black
text
additive
blending
worst
worlds
private
variables
layer
local
function
obj.copy
method
copy.copy
most
situations
something
original
branch
bugs
code
exact
equivalent
guess
code
release
section
specific
move
section
suggestion
brush
size
sofroniewn
np.unique
layer.data
[
:5
:5
]
paint
callback
]
https
//github.com/napari/napari/blob/6313ffc2dcc2408fb56eb5b132399af34c126708/napari/layers/labels/_labels_mouse_bindings.py
L21
line
first
click
label
layer.coordinates
brush
size
layer._last_cursor_coord
layer.coordinates
line
event
starts
layer.coordinates
new
additional
pixels
line
dragging
ends
correct
np.unique
layer.data
[
-5
]
true
pixels
[
:5
:5
]
os.path.dirname
self.selectedFiles
]
successful
None
return
=
result
suggestion
git
commit
history
use
namedtuple
post
//tobeva.com/articles/brain-compatible-code/
np.random.seed
call
function
example
fine
ziyangczi
comment
case
day
someone
same
thing
versions
Darwin
fullscreen
bug
deep
NSWindow
fullscreen
test
draw
cycle
fullscreen
explicit
tests
tlambert03
Interesting
sense
fix
pyramid
stuff
more
detail
described
[
]
https
//napari.org/docs/developers/CONTRIBUTING.html
writing-tests
problematic
widget
qtbot
own
cleanup
end
test
possible
viewer_factory
own
Viewer
@
different
tests
ie
comment
>
new
function
name
cool
docstring
GitHub
issue
uncommented
comment
check
amount
active
keybindings
constant
appropriate
.keys
part
implicit
dict
prior
Python
dictionaries
default
implementation
detail
please
OrderedDict
comment
ordinary
dict
minimum
Python
version
reason
suggestion
self
C
function
body
empty
Plugin1
sort
stuff
events
model
files
keyword
NOTE
andrey.lykhoman
more
space
indent
relational
comment
strings
better
highlighting
IDE
Added
comment
Please
comments
following
parameters
TODO
part
requirements
PR
@
RuslanSkiraRaccoongang
TODO
user
session
current
viewing
user
username
user
view
Please
describe
comment
Do
operation
honor_code
honor_code
Strange
comment
exception
logs
s/enrol/enroll/
module
plugin
course_date_offsets
[
gitlab
repository
]
https
//gitlab.raccoongang.com/hippoteam/edx/course_date_offsets
change
transformer
functionality
rg_odoo_api
plugin
division
responsibility
add
test
code
suggestion
stored
stats
correct
Same
comment
make_api_request
seperate
json
file
tests
dict
code
easier
way
path
helpful
listens
last
days
mapped_listens_df
mapped_listens_subset_df
function
documentation
steps
simple
english
comment
confusing
UUIDs
time_range
range
time_range
range
predefined
function
python
stdlib
docs
field
activity
ambiguous
specific
ok
function
names
docstrings
more
detail
Same
comment
better
helpful
try-except
entry
]
readable
random
detailed
comment
docstring
mention
ViewSubElement
class
api.py
downstream
projects
warning
Please
class
docstring
documentation
class
namespace
code
test
something
self.assertWarns
class
UserDefinedClass
HasTraits
trait
some_value
Oops
index
negative
index
+
length
negative
larger
equal
Ah
code
evolution
start
=
step
guard
Will
issue
rid
XXX
comment
Nit
situations
depends_on='child.name
example
<
entry
space
characters
'10
better
relative
number
absolute
time
one
comment
link
related
issue
illegal
right
test
__dict__
implementation
detail
metadata
retrieval
example
following
traits
same
metadata
filtering
>
>
tr1
=
Float
edible=None
.as_ctrait
>
>
tr2
=
Float
.as_ctrait
>
>
tr2.edible
==
tr1.edible
True
getattr
trait
metadata_name
filter
result
clear
None
bool
usual
on_trait_change
expression
reason
assertSetEqual
assertEqual
[
documentation
]
https
//docs.python.org/3/library/unittest.html
unittest.TestCase.addTypeEqualityFunc
necessary
methods
comment
check
necessary
assertEqual
calls
consistent
most
rest
codebase
majority
other
Python
projects
actual
actual
level
reader
mixture
circumstances
necessary
exception
Exception
broad
risks
errors
something
targeted
comment
necessity
reminder
Somehow
GitHub
comment
such
diff
comment
comment
list
added
value
[
value
]
index
integer
case
value
iterable
list
validate
other
methods
__delitem__
comment
previous
GitHub
list
added
*
*
please
*
*
impossible
list
list
list
EEP
removed
added
item
many
items
listener
context
change
invoked
append
extend
content
list
problem
__init__
time
code
bit
hacky
wrong
place
comment
confusing
clear
code
reader
pickle
relevant
explanation
bit
notification
docstrings
comment
base
class
sort
method
discussion
https
//github.com/enthought/traits/pull/912
issuecomment-599570303
membership
changes
validation
other
notifications
notion
element
ordering
odd
relevant
sort
confusion
keys
method
names
Property
support
other
branches
name
class
dict
name
trait
property
property
half
comment
branch
comment
special-casing
str
bytes
bytearray
Same
question
notifiers
different
dispatch
on_trait_change
opportunity
possibility
spurious
equality
case
everything
same
_except_
handler
different
method
handlers
garbage
case
None
equal
course
situation
None
_same_
handler
gc
something
handler
returns
None
something
OK
as-is
nice
protocol
standard
API
best
need
top
module
Do
sys.modules
test
complete
sys.modules
test
setup
teardown
Flake8
input
stdin
e.g
flake8
<
myfile.py
IDEs
use
flake8
possible
case
E.g
python
flake8
import
utils
def
copyright_header
filename
filename
stdin
Flake8
input
stdin
e.g
flake8
<
my_file.py
output
command
case
filename
input
stdin
Many
editors
input
stdin
Note
user
different
name
stdin
stdin-display-name
option
flake8
file_contents
=
utils.stdin_get_value
enthought/LICENSE.txt
LICENSE.txt
most
files
separate
PR
favor
🇺🇸
Can
check
spans
other
sentences
configurable
many
iterator
batch
large
significant
buffer
iterator
instances
large
significant
memory
comment
input
size
batch_size
times
larger
output
size
partial
TODO
mattg
need
tiling.
[
comment
]
https
//github.com/allenai/allennlp/pull/1235
issuecomment-391540133
@
matt-gardner
tests
correct
implementations
attention
modules
cosine
similarity
last
dimension
matrix_1
cosine
similarity
last
dimension
matrix_2
entries
F.cosine_similarity
matrix_1
matrix_2
dim=-1
only
cosine
similarity
entry
matrix_1
corresponding
entry
matrix_2
permutations
expand
way
expand
ticket
worth
comment
bit
IIUC
meaning
next
statement
_max_span_width
operates
word
pieces
words
enumerate_spans
word-level
width
limit
word
pieces
phrasing
stricter
todo
comment
aside
same
_max_span_width
experiments
label
distribution
logic
perf
check
fairer
comparison
much
domain
knowledge
w.r.t
coref
please
bad/irrelevant
idea
reason
docstring
complicated
like
AllennlpLazyDataset
DatasetReader
lazy=True
.read
clear
simpler
clarity
real
world
scenario
example
sequences
same
length
little
weird
space
WHNP
WHNP
pylint
statement
super
class
pylint
statements
span
-.-
optional
thanks
Sequence
Set
list
places
change
IMO
little
readable
loop
skip_indexing
isinstance
label
int
label
labels
raise
largest_label_id
=
max
labels
MultiLabelField._vocab_size
[
..
]
=
max
largest_label_id
+
model
archive
Other
docstring
temporary
fix
better
solution
https
//github.com/allenai/allennlp/issues/244
nice
brief
comment
various
granularities
logic
conversion
logic
residual
skip
connection
disable
anymore
Better
consistent
rest
code
new_id_of_flipped_token
=
first_order_taylor
grad
origin
==
.__eq__
below
squeezes
second
line
different
Wait
return
value
way
implementations
_none_
magnitude
better
mag
norm
point
short
argmax
square
root
unnecessary
comment
tokens
good
much
cleaner
functionality
stuff
periods
end
sentence
tokens
ok
unfortunate
outputs
outputs
demo
answer
demo
task
new
label
same
line
use
python
normal
line
continuation
syntax
\
inside
parens
brackets
sanitize
final
final_tokens
original
mypy
similar
things
bunch
other
places
field
TextField
error
type
ignore
something
isinstance
new_instance
[
name_of_input_field_to_attack
]
TextField
raise
ValueError
input
field
name
TextField
field_to_attack
TextField
=
new_instance
[
type
ignore
variables
field_to_attack
type-safe
way
code
access
field
name
method
argument
input_field_name
grad_name
bunch
similar
comments
hotflip
way
share
code
ill
variable
pylint
Same
comment
default
value
None
getattr
mypy
warning
type
object
awful
TextField
tag_field
SequenceLabelField
=
current_instance
[
tags
]
type
ignore
predictor
right
type
comment
loop
becomes
label
tag_field
label.label
use
label
top
file
class
docstring
plenty
cases
special
NER
presence
field
tags
check
brittle
users
aware
Same
comment
list
nice
same
name
places
instance
original_instances
previous
instance
variable
Extra
space
unfortunate
special
case
NER
sure
way
other
predictions_to_labeled_instances
complex
return
type
tokens
comment
name
method
new
information
unnecessary
Format
embeddings_list
List
numpy.ndarray
]
=
[
]
Better
scale
=
output.detach.max
output.detach.min
noise
=
torch.randn
output.shape
.to
output.device
stdev
*
scale
backslash
continuation
better
way
code
same
number
lines
readable
magic
numbers
magic
numbers
middle
implementation
code
good
practice
something
self._stdev
self._num_samples
constructor
easier
change
configure
implementation
user
information
method
comment
docstring
NAQANet
lot
readable
lines
python
offsets
instance
[
'metadata
]
.metadata
[
'passage_token_offsets
]
type
ignore
index
enumerate
offsets
formatting
nicer
obvious
type
issue
passage_field
SequenceField
=
new_instance
[
'passage
]
type
ignore
line
[
'passage
]
passage_field
type
ignore
calls
line
pylint
warning
Just
__init__
brief
comment
interpreter
pass
extracted
grads
list
list
hooks
cleaner
something
register_embedding_gradient_hooks
descriptive
general
Predictor
class
obvious
kind
hook
method
backslash
pylint
command
method
body
docstring
wsp
tests
striding
case
masks
random
tensors
particular
tests
metric
_batched_
tensors
good
loops
comment
redundant
couple
ones
Preference
shape
computation
line
-1
obvious
likely
bugs
comment
-1
shape
output_dim
output_dim
need
comment
crash
somehow
error
while
right
computation
-1
hard
reason
things
train_save_and_load
test
fine
separate
test
flag
index
logic
nested
annotations
comment
Though
name
cached_path
obvious
sure
comment
necessary
cached_path
function
call
sentence
open
cached_path
file_path
r
logic
coreference
clusters
input
nice
thing
docstring
file
format
binary
mask
more
detail
obvious
computation
method
docstring
initial
sentence
beginning
docstring
something
Computes
element-wise
dropout
mask
element
tensor
shape
shape
probability
dropout_probability
Duh
man_facepalming
mask
Seems
simpler
next
other
parameters
space
http
//legacy.python.org/dev/peps/pep-0008/
whitespace-in-expressions-and-statements
comment
earlier
similar
comment
self
*
_linearity
constructor
numbers
different
highway
case
way
lot
sense
easiest-to-read
LSTM
code
easier
few
more
explanatory
comments
good
comment
token.tag_
spacy
fine-grained
part
speech
token.pos_
coarse
part
speech
spacy
coarse
part
speech
same
universal
dependencies
pos
tag
scheme
comment
comment
output
TextField.as_array
TokenEmbedder
something
similar
minus
good
comment
nice
reference
magic
numbers
third
index
comment
line
something
robust
future
changes
something
python
i
tag_index
enumerate
gold_indices
prediction_tensor
i
tag_index
]
Fewer
lines
code
=
[
]
TODO
out
timing
sort
tricky
train_model
comment
output
line
=
'tokens
text_field_embedder.type
=
basic
text_field_embedder.tokens
text_field_embedder.tokens.type
=
embedding
param
stuff
output
command-line
tool
model
bulk
output
flask
inplace
argument
activation
max
sure
readable
unmatched
parentheses
max
tokens
result
activation
function
meantime
readable
activation
convolution_layer
tokens.max
dim=2
]
.squeeze
dim=2
wrapping
weird
versions
http
//pytorch.org/docs/master/torch.html
torch.max
able
max
inplace
TODO
Ca
intentional
other
one
easier
shape
line
list
activation
functions
obvious
type
pytorch
activations
Inconsistent
line
suggestion
super
.__init__
beta
average
labels
=
threshold
reason
multiplication
Bilinear
higher-order
tensors
tests
properly
somehow
issue
way
pytorch
preferable
API
wrapper
nn.Sequential
stuff
last
week
able
allennlp
model
module
outputs
TODO
input
dictionary
dictionary
forward
call
labels
optional
None
default
arguments
contradictory
other
comments
inputs
model
user
types
hints
ambivalent
reason
Type
surprised
lowercase
type
Type
type
ignore
other
places
listed
return
type
method
reason
type
failure
right
from_params
pattern
code
TODO
from_params
Thanks
sense
comment
script
run_with_beaker.py
line
unnecessary
comment
Stuff
wrong
tree
thing
input
mask
kind
API
shape
annotations
https
//pytorch.org/docs/stable/nn.html
torch.nn.Transformer.forward
dimensions
input
different
dimensions
mask
PyTorch
people
idiots
wrong
IMO
regular/positional/type
layers
transformer
architecture
transformer
models
explicit
first_step
bit
confused
event2mind
model
Could
Sorry
something
obvious
logic
test
test
helpers
dead
simple
surprises
readability
Type
hints
arguments
add_function
rows
mode
sense
mode
distribution
one
function
argmax
particular
mapping
cells
cell
parts
strings
SEMPRE
sure
Chen
pass
nesting
next
try
control
Nit
trainer.optimizer
config
nice
discoverable
somehow
general
problem
sure
suggestion
dataclass
default
values
class
level
somehow
pylint
ok
something
shape
comment
unsqueeze
sentinels
out-of-bounds
span
index
point
weird
behavior
weird
line
semantics
variables
backward_combination
backwards
start_embeddings
end_embeddings
end_embeddings
start_embeddings
backward_start_embeddings
refers
start
backwards
direction_
combination
same
directions
mask
span
span
ends
groups
logic
much
part
code
tests
crash
-1
exclusive_span_starts
instances
point
-1
valid
entry
index_select
dim=-1
-1
Might
nice
reader
keyword
argument
time
torch.split
sequence_tensor
mask
float
long
index_select
float
masking
span
recast
masking
confusing
backward_end_embeddings
consistency
real
worry
tiny
bit
simpler
something
loss_count
=
total_loss
loss
=
model
*
*
batch
.get
loss
loss
None
metrics
loss
=
loss.item
total_loss
+=
loss.item
loss_count
loss_count
final_metrics
loss
=
/
loss_count
cleaner
maps
name
task
imports
try
block
code
comment
batch
index
number
steps
hard
reason
size
dictionary
batch
index
list
Monstrous
type
least
computation
major
caveat
use
batch
size
docstring
keep_beam_details
parameter
initial_sequence
need
class
docstring
terminology
right
snapshots
beam
timestep
something
beams
funny
sounding
beam_snapshots
something
similar
obvious
nested
logic
hard
reason
seq_length
=
instance.fields
[
'source
]
.sequence_length
self._max_sequence_length
<
=
self._max_sequence_length
yield
instance
clearer
yield
statements
different
places
tokenization
expensive
something
line
file
tokens
line
self._max_sequence_length
tokens
self._max_sequence_length
+
yield
Instance
fields=
logic
inside
text_to_instance
ok
alternative
line
f
instance
=
self.text_to_instance
line
instance.fields
source
]
.tokens
=
yield
instance
better
subtle
point
metric
many
classes
data
way
tensor
appropriate
shape
i.e
None
tensor
shape
num_classes
FbetaMeasure
average=None
exception
better
idea
metric
F1Measure
due
compatibility
sense
python
j
action_action
enumerate
best_action_sequences
i
]
j
block
top
action
sequence
block
time
got_top_action_sequence
flag
minute
]
]
]
comment
order
>
instances
index
order
test
data
vocab
size
something
larger
comment
lines
i
means
201st
instance
many
test
customary
dropout
sure
important
https
//github.com/huggingface/pytorch-pretrained-BERT/blob/3ae8c8be1e3fc770968cd3fdb3b643e0b166e540/pytorch_pretrained_bert/modeling.py
L1058
approach
spacy
models
static
dictionary
loaded
models
little
hairy
fine
tuning
lots
potential
crazy
bugs
wrong
private
only
use
token
embedder
pooler
ok
right
thing
word
splitter
[
CLS
]
tokenization
-1
s
wrong
Hmm
appropriate
rows
predictions
targets
batch
sure
anything
loss
computation
training
lengths
logits
relevant
targets
different
way
embeddings
share
weights
default
choice
separate
fine
many
cases
summarization
toy
example
low
NLL
decoded
sequences
most
copy
task
mapping
symbols
source
side
*
different
*
set
symbols
target
side
sure
embeddings
easier
comment
docstring
separate
method
duplication
docstring
comment
num_decoding_steps
num_classes
-1
come
l2
l3
l4
l5
l6
l7
Right
unsqueeze
top
head
wrong
fix
second
dimension
lengths
mask
name
method
decoder
EncoderDecoder
reader
method
name
helpful
comment
docstring
something
Model.decode
inference
predictions
call
Model.forward
separate
notion
model
decoder
decode
method
output
strings
_predict_step
softmax
probabilities
max
predictions
method
call
complex
dictionary
long
docstring
lines
extensibility
decoding
method
lines
_predict_step
function
sure
dictionary
return
type
anything
simple
tuple
Good
point
mask.size
mask
None
block
arg_tags
None
check
scorer
parameters
gradients
comment
Module
certain
worth
effort
type
annotation
people
modules
problem
LanguageModelTokenEmbedder
line
good
example
tests
prudent
able
minimal
duplication
https
//github.com/allenai/allennlp/blob/511c846c9c779fdac0066dbae6765c1619037098/allennlp/tests/fixtures/bidirectional_lm/experiment.jsonnet
share
config
jsonnet
files
familiar
more
documentation
yeah
....
comment
previous
PR
torch.bmm
tensors
dimensions
long
comment
easier
sure
original
comment
tensor.dim
pytorch
wrong
expand_as
embedding
shape
num_tokens
embedding_dim
mask
num_tokens
last
dimension
fine
BiDAF
tensor
shape
passage_length
question_length
mask
shape
question_length
last
dimension
wrong
odd
unpredictable
behavior
passage_length
mask
wrong
dimension
caller
mask
same
dimension
tensor
function
little
concerned
BiDAF
test
sure
line
type
ignore
conversation
type
signature
method
called
class
ignore
haha
cheeky
simple_tagger.py
=
one
]
https
//google.github.io/styleguide/pyguide.html
showone=TODO_Comments
TODO_Comments
name
Idea
functionality
assert_batch_dimension
flag
arrays_as_variables
something
TODO
Add
span_start_probs
docstring
paragraph
multiple
instances
question
comment
more
clear
need
comment
definition
flaky
sure
change
test
flaky
ones
suggestion
Sampler
Gumbel-Top-K
trick
replacement
[
*
Stochastic
Beams
Where
Them
Gumbel-Top-k
Trick
Sequences
Replacement
*
W
Kool
H
Van
Hoof
M
Welling
]
https
//arxiv.org/abs/1903.06059
Parameters
temperature
float
optional
default
=
temperature
sharper
probability
distribution
temperature
flatter
probability
distribution
suggestion
Create
mask
probabilities
top
p
shape
num_classes
>
self.p
Make
sure
least
options
[
]
=
False
suggestion
Sampler
probability
mass
function
nodes
top
choices
cumulative
probability
least
p
subset
probabilities
Beams
default
deterministic
way
Parameters
p
float
optional
default
=
cumulative
probability
cutoff
threshold
higher
value
p
possible
examples
temperature
float
optional
default
=
temperature
sharper
probability
distribution
temperature
flatter
probability
distribution
need
softmax
exp
suggestion
shape
num_classes
=
log_probs_descending.exp
suggestion
Sort
probabilities
highest-first
cumulative
sum
shape
num_classes
suggestion
Sampler
nodes
multinomial
distribution
Beams
default
non-deterministic
way
Parameters
temperature
float
optional
default
=
temperature
sharper
probability
distribution
temperature
flatter
probability
distribution
with_replacement
bool
optional
default
=
False
Whether
replacement
extra
call
something
suggestion
shape
k
top_k_log_probs
top_k_indices
log_probs.topk
self.k
dim=-1
Apply
temperature
necessary
shape
k
self.temperature
=
top_k_log_probs
=
top_k_log_probs
/
self.temperature
Re-normalize
subset
shape
k
torch.nn.functional.softmax
top_k_log_probs
dim=-1
Sample
re-normalized
subset
NOTE
indices
indices
log_probs
indices
top_k_log_probs
shape
sampled_indices
torch.multinomial
normalized_top_k_probs
replacement=self.replacement
Convert
sampled_indices
indices
original
log_probs
tensor
shape
indices
sampled_indices
log_probs.gather
indices
indices
state
loop
something
_log_probs
place
temperature
suggestion
Create
mask
probabilities
top
p
shape
num_classes
>
self.p
included
log
probs
shape
num_classes
[
exclusion_mask
]
=
min_value_of_dtype
log_probs.dtype
shape
num_classes
filtered_probabilities
torch.nn.functional.softmax
dim=-1
Sample
re-normalized
subset
NOTE
indices
indices
log_probs
indices
shape
sampled_indices
torch.multinomial
filtered_probabilities
per_node_beam_size
Convert
sampled_indices
indices
original
log_probs
tensor
shape
selected_indices
sorting_indices.gather
sampled_indices
NLL
criterion
Losses
criterions
torch
NLL
=
Negative
log
likelihood
i
bunch
argmax
easy
way
computed
loss
typo
s/sicne/since/
TODO
separate
file
Could
docstring
class
Remove
print
statement
way
module
scope
app
import
pretty
sure
logging
hacks
line
sanic
version
service
top
directory
level
cli
commands
+1
easier
functions
something
def
order_func
key
Makes
tuple
tuple
index
preference_orders
key
key
preference_orders
alphabetical
order_tuple
=
[
order.index
key
order
order
order
preference_orders
return
order_tuple
+
[
key
]
same
logic
easier
reader
single
function
good
comment
need
initial
states
standard
practice
ELMo
LSTM
different
memory
state
sizes
expensive
comments
end
possible
handling
num_valid
stuff
masked
values
tensor
mask
suggestion
pool_length
=
tokens.shape
]
convolution_layer.kernel_size
]
Forward
pass
convolutions
shape
num_filters
pool_length
activations
self._activation
convolution_layer
tokens
Create
activation
mask
shape
pool_length
=
torch.arange
tokens.shape
[
]
+
.unsqueeze
.expand
pool_length
shape
pool_length
activations_mask
=
indices.ge
pool_length
shape
num_filters
pool_length
activations_mask
=
activations_mask.unsqueeze
.expand_as
activations
Replace
values
smallest
possible
value
dtype
max
pooling
activations
shape
pool_length
activations
activations
+
activations_mask
*
min_value_of_dtype
activations.dtype
suggestion
cnn_encoder
large
negative
value
suggestion
filter_outputs
[
]
batch_size
=
tokens.shape
]
shape
=
mask.sum
dim=1
.unsqueeze
dim=-1
way
operation
inputs
=
add_positional_features
clause
cached_input
inputs
self._input_dim
=
hidden_dim
check
big
note
docstring
things
highway
layer
input
only
place
positional
encoding
important
feedforward_output
consistent
naming
spacing
comment
Are
similarity
projection
dimension
head
*
notation
little
confusing
split
=
projected_tensor_x.size
[
-1
]
projected_tensor_x.resize
*
all_but_final_dim
self._num_heads
-1
simpler
need
_remove_batch_dim
def
__call__
instances
shuffle
epoch
num_epochs
num_epochs
==
None
instance
instances
yield
instance.as_tensor_dict
means
epoch
tracking
lot
other
things
sure
way
something
base
class
down
base
class
docstring
need
function
check_dimensions_match
ConfigurationError
helpful
message
e.g.
flag
sure
people
type
ids
extra
space
instance
comment
line
diff
torch
tensor
np.ndarrays
cases
x.cpu
.tolist
torch
tensor
Otherwise
x.tolist
GPU
function
typedef
common/utils.py
similar
bad
id
ELMoCharacterMapper
account
first
place
Simple
Tagger
model
test
comment
unwrap_variables
function
comment
ideal
limitation
comment
tied_source_embedder_key
block
level
comment
block
own
test
case
blocks
much
state
Vocabulary.from_params
access
namespace_token_counts
true
sure
comment
bunch
duplicated
code
more
tokens
comment
code
shuffle
block
NOTE
shuffle
false
data
different
order
bucket
commented-out
code
obvious
code
@
matt-gardner
Python
strings
🙄
around
pre-processing
reference
anywhere
code
info
class
docstring
assumptions
directory
little
....
separate
IndicatorField
functionality
verb_indicator
key
IndexField
None
value
route
lot
code
instance
processing
pipeline
different
keys
verb_indicator
None
dictionary
special
casing
parts
instance
pipeline
simpler
sure
same
comment
Add
type
hints
comment
<
characters
pylint
torch.LongTensor
Same
thing
torch.LongTensor
pylint
consistent
other
places
similar
code
same
variable
names
Makes
easier
things
sync
useful
remove_beginning_and_end_tokens
flag
default
false
people
CNN
only
part
elmo
embeddings
case
Seq2VecEncoder
docstring
arguments
types
ok
.T
easy
lowercase
full
name
variables
great
>
weight_transform
readability
harder
same
_load_weights
function
other
ELMo
components
same
options/weights
hook
weights
something
easy
bad-continuation
pylint
self._char_embedding_weights
=
torch.nn.Parameter
torch.FloatTensor
weights
good
catch
thanks
sources
flag
similar
beaker
sure
best
way
fine
subsequent
PR
notebook
tests
empty
bit
args.k
elif
args.run_all
pytest_k
=
[
]
pytest_m
=
[
]
pytest_k
[
'-k
sniff_test
]
true
predict
predictor
option
need
predictor
overrides
rid
May
docstring
short
description
parameters
Particularly
numbers_in_passage
mask
second
return
argument
add_sentence_boundary_token_ids
whole
section
Vocabulary.get_token_index
bos
eos
tokens
token
indexer
ConfigurationError
name
character
embeddings
uncontextual_token_embeddings
sketchy
None
private
attribute
class
public
method
something
delete_softmax
language
model
low
level
details
code
scalar
mix
logic
beginning/end
sentence
markers
gain
other
functionality
custom
module
Elmo
class
https
//github.com/allenai/allennlp/blob/master/allennlp/modules/elmo.py
L76
surprised
case
self._bos_indices
None
mask
input
<
S
>
<
/S
>
mask
changes
updated
mask
comment
custom
module
logic
module
type
annotation
necessary
unfortunate
better
way
API
environment
variables
beaker
colon
better
comments
periods
bidirectional
shape
comment
lot
way
Registry
allennlp.experiments
various
components
models
data
things
pretty
separate
sense
other
hand
Registry
Collection
same
goal
unified
way
sense
Registry
way
third-party
users
things
experiment
framework
problem
service
argument
way
hmm
sense
Registry
direction
AugmentedLstm
num_directions
belongs
class
least
nice
comment
decision
Agreed
wrong
shape
output
reshape
reshaping
something
batch
hidden_size
batch
output_dim
comment
class
forward
backward
states
reminder
/
explanatory
comment
little
bit
comment
blocks
transformers
comment
odd
spaces
end
line
indices
tags
tags
self.start_tag_index
denominator
Seems
definition
slices
manipulation
model
fit
viterbi_decode
.view
little
confusing
.unsqueezes
little
annoying
nice
least
.view
reader
-1
prev_tag
next_tag
tag
current_tag
Hmm
value
parameter
trainable
model
tags
bit
unstable
large
values
potentials
better
parameter
constant
value
space
operators
comment
mask
[
]
inputs
logits
other
method
ByteTensors
torch.ones
]
.sum
Variable
torch.ones
]
reference
Hmm
entire
sentence
string
key
fine
docstring
clearer
first
token
unique
identifier
first
token
sentence
first_token_key
something
convention
class
file
Sphinx
docstrings
class
Parameters
name
type
description
Returns
kind
loop
file
new
vocab
entries
much
simpler
logic
computation
complex
logic
negligible
least
comment
easiest
embeddings
entire
vocab
ones
embeddings
original
vocab
training
additional
sanity
check
extend_vocab
pre-trained
file
max
lengths
tensor
+SMALL
feels
clunky
tests
line
line
mask
typo
input
shape
[
ellipsis
]
https
//en.wikipedia.org/wiki/Ellipsis_
linguistics
bit
implicit
word
references
stab
comment
more
intuitive
CoNLLU
annotations
words
original
sentence
dependencies
original
sentence
obvious
[
id
]
None
maps
words
ellipsis
annotation
guidelines
http
//universaldependencies.org/u/overview/specific-syntax.html
ellipsis
head
comment
BERT
Albert
comment
Mypy
dictionaries
different
types
least
offensive
way
No
need
tests
comments
code
justification
safe
important
notion
epoch
batch
size
independent
measure
much
data
epoch
attribute
little
scary
something
__call__
client
last
time
iterator
value
attribute
properties
Dataset
iterator
sense
__iter__
API
constructor
instance
BucketIterator
Dataset
attributes
dataset
iterator
number
batches
unfortunate
affect
previous
API
things
API
fact
scary
state
better
way
redesign
problem
return
value
as_training_data
many
batches
dataset
epoch
fit_generator
Keras
able
issue
overhead
negligible
relative
time
idea
epoch
terms
number
gradient
updates
specific
Predictor
types
better
code
completion
predict
methods
guess
major
speedup
default_value
ok
*
nervous
default
value
list
cases
*
same
list
*
lots
times
value
lists
fine
least
comment
dangerous
uses
suggestion
default
value
list
subtle
bugs
risk
low
much
=
[
default_value
*
pad_length
typo
next
PR
coverage
computation
block
different
classes
lines
TODO
Nothing
unused
argument
logic
cases
member
None
cleaner
file
decision
logic
method
something
def
open_uri
file_path
file_name
member
=
parse_file_uri
file_path
file_path
=
cached_path
file_path
member
None
return
open
file_path
r
logic
_read
file_path
open_uri
file_path
data_file
tsvin
=
joelgrus
more
stuff
case
pre-tokenized
important
point
thanks
class
docstring
text
reason
demo
tokenization
someone
text
demo
if/when
demo
Predictor
tokenizer
pass
pre-tokenized
text
premise
List
[
str
]
hypothesis
List
[
str
]
tokenizer
]
.split
]
.split
sense
torch.rand
great
way
parameters
something
reasonable
default
list
parameters
hard
parameter
values
tensorboard
debugging
similar
better
parameters
full_match_weights
None
rid
mv_idx
mv_idx_increment
little
confusing
[
Google
definition
camel
case
]
https
//github.com/allenai/allennlp/blob/master/STYLE.md
BiMpm
BiMPM
Good
catch
type
annotation
Optional
[
Instance
]
little
bit
simpler
first
sentinel
end
iteration
loop
python
start
=
None
child
tree
start
None
start
last_appended_span
]
end
=
last_appended_span
]
typed_spans
start
end
=
tree.label
comment
last
appended
span
relies
fact
span
subtree
end
method
variable
return
value
new
variable
error-prone
other
hand
behavior
way
recursive
function
result
return
value
something
python
child
tree
return
value
call
self._get_gold_spans
child
index
typed_spans
spacy
tokens
nice
comment
complex
logic
description
data
available
=
token
current_tokenized_utterance
]
other
comments
loop
Makes
logic
method
sure
treatment
string_linking_dict
loop
_last_
utterance
utterances
intentional
sure
comment
test
linking
scores
values
values
comments
line
entity
]
https
//github.com/allenai/allennlp/blob/4fa4dc23ccc5a0f5332d73e8da7688d343296f82/allennlp/tests/data/fields/knowledge_graph_field_test.py
L120-L123
alignment
correct
particular
arbitrary
ordering
linking
right
sense
comment
Care
typo
Most
comments
single
line
function
descriptive
name
comments
strong
preference
something
semantic
content
timesteps
timesteps
vacuous
term
num_tokens
part
sure
docstring
noqa
statements
note
word
good
first
conll_components
[
-1
]
_process_span_annotations
first
word
empty
Remove
blank
line
contains
reason
confusion
finger
_why_
fine
ok
reason
default
others
much
input
much
same
embedding
text
input
times
parameter
most
time
nlp_api.embed_text_field
inputs
get_token_embedder
function
Module
Module
pytorch
same
Layer
keras
i.e.
object
tensors
input
returns
tensors
output
verbatim
example
class
docstring
valid
head
fluent
Scala
API
Scala
A.
question_embedder
=
nlp_api.get_token_embedder
question
new
default
embedded_question
question_embedder
question
passage_embedder
=
nlp_api.get_token_embedder
passage
fallback_behavior=
use
question
embedded_passage
=
passage_embedder
passage
JSON
config
following
none
question
passage
params
hand
params
dict
B.
question_embedder
=
nlp_api.get_token_embedder
params.get
question
embedded_question
question_embedder
question
passage_embedder
=
nlp_api.get_token_embedder
params.get
passage
question
embedded_passage
=
passage_embedder
passage
B
equivalent
difference
Cool
example
code
equivalent
intent
=
nlp_api.get_token_embedder
question
embedded_question
question_embedder
question
passage_embedder
=
nlp_api.get_token_embedder
passage
question_embedder
embedded_passage
=
passage_embedder
passage
fallback
behavior
stern
exception
Fail
fast
more
detail
quick
scan
general
recurrent
architectures
CNNs
networks
future
way
current
API
TextFields
same
way
model
embedder
default
key
constructor
clear
better
documentation
method
class
docstring
]
https
//github.com/allenai/allennlp/pull/8/files
diff-0940390725a7dbf30fe6786557b2b060R55
good
enough
reason
layers
harder
concrete
object
function
specific
layer
other
words
valid
=
nlp_api.get_token_embedder
params.get
question
embedded_question
embedder
question
embedded_passage
=
embedder
passage
documentation
docstring
syntax-highlighted
python
use
question
behavior
new
default
behavior
something
question_embedder
=
nlp_api.get_token_embedder
question
Params
here_
JSON
config
NlpApi
object
nlp_api.get_token_embedder
params.get
question
sense
name
name
text
field
name
Clearly
bad
today
nit
+1
Consider
examples
separate
files
easier
syntax
python
plain
docstrings
name
default
suggestion
part
standard
language
idioms
own
less
library
user
easier
casual
users
val
foo_layer
=
nlp.foo_layer
params.getOrElse
default
params
>
question
convention
way
params
factory
methods
=
suggestion
pretty
reasonable
=
way
case
Params
object
way
reason
way
simpler
suggestion
simple
redirection
good
point
thinking
encoders
seq2seq_encoders
pytorch
distinction
CNNs
TreeLSTMs
such
encoders
seq2seq_encoders
thin
wrappers
pytorch
RNNs
get_seq2seq_encoder
get_recurrent_layer
identical
behavior
simple
example
flexible
afterwards
tag
name
predictions
little
confused
bit
readable
sequence_logits
number
logit
values
less
room
garden
path
readings
comment
numpy.array
function
numpy.ndarray
data
type
place
DeepQA
Useful
documentation
readability
issue
shuffling
easy
disable
checks
comment
double
ticks
code
docstring
single
tick
italics
easier
code
attention
torch.eye
GPU
implementation
mask
passage_self_mask
=
torch.eye
passage_length
device=self_attention_matrix.device
.unsqueeze
.unsqueeze
self_attention_mask
=
passage_self_mask
*
passage_mask.unsqueeze
-1
*
passage_mask.unsqueeze
-2
lines
_should_
work
current
lines
shape
mangling
num_questions
shapes
confusing
column_types
self.column_types
different
information
better
documentation
parameters
class
different
names
things
better
comment
pylint
complaints
line
reasonable
pylint
disable=protected-access
simplifiable-if-statement
scope
function
TODO
Type
wrong
token
mypy
overridden
methods
correct
instantiation
type
variable
Type
annotation
get_padding_token
logic
reference
self.get_padding_token
sequence_length=2
sequence_length
sequence_tensor
=
torch.LongTensor
[
[
]
]
IIUC
type
ignore
statement
lambda
functions
mypy
check
Nit
START
END
places
code
BIOUL
constraints
coherent
from_tag
START
inside
constraint_type
==
block
below
nice
comment
expected
result
tar
component
elmo_embeddings.txt.gz
special
tokens
<
S
>
<
/S
>
file
Are
other
special
tokens
necessary
usable
allennlp
Vocabulary
file
format
allennlp
Vocabulary
exception
tokens
]
=
@
@
UNKNOWN
@
@
Debug
statement
cleaner
DummyModel
inputs
DummyIterator
outputs
i.e
class
DummyIterator
DataIterator
def
__init__
tensor_dicts
List
[
TensorDict
]
>
None
super
.__init__
=
tensor_dicts
__call__
args
*
*
kwargs
>
Iterator
[
TensorDict
]
yield
self._tensor_dicts
class
DummyModel
Model
def
__init__
super
.__init__
tensor_dict
TensorDict
>
Dict
[
str
torch.Tensor
]
pylint
disable=arguments-differ
return
tensor_dict
instances_per_epoch
optional
same
order
time
function
docstring
Ah
good
point
set
point
tests
string
easier
users
context
Okay
couple
points
*
comment
email
user
zulip
mail
id
Move
function
get_user_name
main
webhook
function
*
variable
names
descriptive
p
n
code
readable
Okay
Python2
style
mypy
annotation
Python3
syntax
example
]
https
//github.com/zulip/zulip/blob/master/zerver/webhooks/dropbox/view.py
L10
further
guidance
earlier
comment
master_id_record
Sorry
blank
line
line
newlines
tests
prettier
multiline
strings
brackets
slashes
\
quotes
other
types
events
fixture
ticket_state_changed
event
need
fact
exception
function
bad
idea
exceptions
handle_input
need
brackets
return
original_content.startswith
@
yoda
file
Better
open
resources
comment
dependency
Btw
specific
reason
requests
trailing
newlines
tests
message
mistake
other
bots
next
line
code
error
somebody
thesaurus
stream
comment
guest
users
priority
most
users
comment
bit
detail
special
test
adjacent
ones
use
Envelope-To
bit
context
clear
few
times
explanation
_get_response
middleware_mixin__call___hack
code
Django
get_response
comment
paragraph
mentions
get_response
_get_response
thing
few
more
lines
pseudocode
akin
line
line
helpful
main
event
key
second
argument
event
ADD
ADD
event
repo
something
UnexpectedWebhookEventType
BitBucket3
.format
payload
[
'eventKey
]
event_type
simpler
way
something
=
'repo
comment
function
EVENT_HANDLER_MAP.get
eventKey
nested
dictionary
unnecessary
point
simpler
approach
event
names
functions
advantage
catalog
supported
events
UI
future
change
comments
DATABASE_PATH
point
Could
blank
lines
imports
constants
definitions
create_chat_bot
line
orginal_content
=
message
[
'content
]
.lower
line
literal
\n
HTML
<
div
class='codeblock
>
print
'\n
/div
>
problem
i
guess
file
'\\n\
bad
info
[
'offset
]
[
]
fill_edit_history_entries
same
result
maintainable
row
col
blank_locations
Same
pattern
need
comment
win
condition
x_locations
readable
function
own
necessary
nice
modularization
logic
Okay
block
TODO
behind
way
big
deal
Super
nit
comment
unnecessary
superusers
comment
typo
TODO
anything
info
message
line
other
credentials
sense
reply
Nit
duplication
top
top
=
custom_completion_email_settings.get
str
program_uuid
custom_completion_email_settings.get
program.type_slug
user_context
custom_template_thing.get
html
textwrap.dedent
custom_template_thing.get
plaintext
attempt
dict
other
URL
Security+
Discount
code
various
emails
URL
send_program_certificate_created_message
utility
method
links
easy-ish
filepath
extension
default
[
:2
]
case
default
language
default
language
nit
static
real
harm
way
Command.log_action
note
test
flaky
Should
request.user.username
==
warning
simpler
trouble
thinking
case
behavior
setting
base
settings
module
setattr
usage
second
warning
direct
attribute
assignment
view.throttle_scope
=
'staff_override
qs
contains
objects
empty
queryset
bare
good
python
exception
invalid
UUID
Add
new
line
nit
redundant
Same
above
exception
better
actual
exception
generic
Exception
case
pyspark
<
falls
clause
Could
more
tests
index
pd.MultiIndex.from_tuples
[
x
x
b
y
]
pd.MultiIndex.from_tuples
[
x
x
None
y
]
pd.MultiIndex.from_tuples
[
x
None
y
]
case
kser.index.value_counts
self.to_frame
.to_spark
test
-kser
.argmax
spaces
inlined
comment
pep8
ditto
forgot
comment
test
itholic
explanation
Let
merge
first
reason
multilevel
index
following
verify_integrity
output
set
conditions
output
condition
right
usage
__new__
instance
initialization
__init__
How
name
names
exception
end
file
kdf
kdf
copy
paste
error
course
compare
kdf
pdf
TODO
keep=
parameter
>
TODO
add
parameter
@
unittest.skipIf
Hmm
way
custom
confusion
bit
good
current
approach
tomorrow
Shall
TODO
comment
precision
scale
somehow
Shall
elif
tpe
decimal.Decimal
block
Let
default
index
type
sequence
distributed-sequence
documentation
page
index
type
anther
PR
get_dtype_counts
pandas
=1.0.0
DataFrame.info
itholic
get_dtype_counts
>
_get_dtype_counts
case
pandas
okay
i
follow-ups
thins
PR
Thanks
comment
nit
doctest
+NORMALIZE_WHITESPACE
DataFrame
same
output
comments
separate
PR
many
Spark
jobs
Could
more
tests
tupled
names
ks.Index
[
]
x
.to_series
ks.Index
[
]
.to_series
x
valid
pandas
anchor
different
position
label
label
Might
best
comments
@
ueshin
comments
bit
difficult
..
_apply_series_op
good
idea
diff
@
@
-689,15
+689,9
@
@
class
GroupBy
object
metaclass=ABCMeta
Name
dtype
int64
=
self._apply_series_op
lambda
sg
sg._kser._cum
F.count
True
part_cols=sg._groupkeys_scols
should_resolve=True
ret
Cast
columns
int64
pandas.core.groupby.GroupBy.cumcount
return
ret.max
axis=1
.astype
'int64
+
ret
=
self._groupkeys
]
._cum
F.count
True
+
internal
=
ret._internal.resolved_copy
+
return
first_series
DataFrame
internal
def
cummax
behavior
self._groupkeys
]
contains
null
values
Could
expected
result
test
doc
anchor
DataFrame
proper
_InternalFrame
tests
pandas
expected
result
diff
diff
git
a/databricks/koalas/utils.py
b/databricks/koalas/utils.py
index
..
a/databricks/koalas/utils.py
+++
b/databricks/koalas/utils.py
@
@
-72,21
+72,23
@
@
def
combine_frames
args
how=
full
join_scols
[
]
merged_index_scols
=
[
]
+
Note
order
element
index_map
index
+
level
+
this_and_that_index_map
=
zip
this_index_map
that_index_map
same
index
this_column
this_name
this_index_map
that_col
that_name
that_index_map
this_column
==
that_col
this_name
==
that_name
Spark
columns
pandas
behavior
this_scol
=
this._internal.scol_for
this_column
that_scol
=
that._internal.scol_for
that_col
join_scol
=
this_scol
==
join_scols.append
join_scol
merged_index_scols.append
F.when
this_scol.isNotNull
.otherwise
that_scol
this_column
break
+
this_column
this_name
that_column
that_name
this_and_that_index_map
+
this_name
==
that_name
+
Spark
columns
+
pandas
behavior
this_scol
=
this._internal.scol_for
this_column
that_scol
=
that._internal.scol_for
that_column
join_scol
=
this_scol
==
that_scol
+
join_scols.append
join_scol
merged_index_scols.append
+
F.when
+
this_scol.isNotNull
this_scol
+
.otherwise
that_scol
this_column
ValueError
Index
names
Spark
column
name
different
e.g.
set_index
to_koalas
index_col=
[
]
@
yuwillrun
https
//github.com/databricks/koalas/pull/481/files
r296667059
comment
update_sdf.filter
old_col.isNull
new_col.isNull
dataframe
exception
tricky
errors
PR
later
result
=
spark_frame.head
result
return
elif
comment
Could
parentheses
range
conditions
fine
implementation
time
exotic
case
mixed
types
warning
doc
dictionary
small
dict
zip
range
range
limit
time
suggestion
dictionary
mapping
yesterday
big
ask
@
anabranch
hack
Pandas
behaviour
defaultdict
behaviours
input
dictionary
_2.12
Spark
Spark
Scala
default
Set
None
dataframe
length
larger
limit
Koalas
users
PySpark
'compute.shortcut_limit
limit
shortcut
specified
number
rows
schema
test
tests
test_filter
Data
big
schema
inference
pdf
=
pd.DataFrame
[
]
*
b
[
]
*
c
[
]
*
columns=
[
b
c
]
kdf
=
koalas.DataFrame
pdf
self.assert_eq
b
.filter
lambda
x
x.b.mean
.sort_index
b
.filter
lambda
x
x.b.mean
.sort_index
self.assert_eq
[
b
]
.filter
lambda
x
x.a
==
.sort_index
[
b
]
.filter
lambda
x
x.a
==
.sort_index
self.assertRaisesRegex
TypeError
<
class
'int
>
object
callable
kdf.groupby
b
.filter
groupby.filter
schema
test
better
comment
configuration
limit
current
DataFrame
Set
None
input
length
limit
shortcut
data
driver
side
pandas
API
limit
unset
operation
PySpark
Default
Modified
return
statement
type
ignore
commented
tests
comment
variable
names
comment
above
import
pkg_resources
consistency
other
comments
special
reason
=
mlflow.set_experiment
my_experiment
output
i
docs
convention
data
type
default/optional
value
first
line
actual
explanation
parameter
line
issue
function
column
dataframe
obvious
@
thunterdb
big
deal
doctest
+SKIP
>
>
>
Will
message
dataframes
>
>
>
df
y
=
doctest
+SKIP
self._internal.sdf
sdf
=
self._internal.sdf
'__natural_order__
sdf.columns
sdf
=
sdf.withColumn
F.monotonically_increasing_id
sorry
please
fix
ks.Multi
😄
nit
need
spaces
ditto
class
Permission
name='goods_type
Rather
comment
id
afterwards
eg
name
INPUT_NAME_ID
Could
object
type
selector
last
eg
LINK_FILTER_ID
comments
comments
internal
https
//github.com/uktrade/lite-internal-frontend/pull/362
discussion_r379521191
example
/raise_hmrc_query/
newline
unnecessary
comment
Get
rid
comment
endpoint
advisory
data
sections
sections
task
list
_ID
comment
Add
ex
code
intention
different
variable
styles
lot
reason
element
ID
least
buttons
suggestion
Same
docstrings
empty
@
return
suggestion
configured
page
limit
max_val
=
conf.getint
api
maximum_page_limit
PAGE_LIMIT_DEFAULT
Minor
typo
anything
airflow.models.serialized_dag
store_serialized_dag=False
tests
comment
Roger
Removed
dont
need
list
[
]
list
line
same
code
together
suggestion
schema_update_options
None
schema_update_options
[
]
compatibility
schema_update_options
list
schema_update_options
comment
function
def
check_value
action
value
cmd_map
=
worker
celery
worker
old
new
try
msg
command
use
airflow
.format
value
[
value
]
raise
ArgumentError
action
msg
KeyError
raise
ArgumentError
action
Command
.format
value
map
global
constant
useful
future
WDYT
suggestion
*
*
argument
everything
suggestion
Check
part
context
suggestion
Warn
py2
support
likely
NIT
Retstart
>
restart
So
Pipe
Stats
results
Nice
[
black
]
https
//github.com/psf/black
s
consistent
docstrings
👍
unused-argument
comments
exception
boto3
protocol
other
extra
maintenance
everything
kind
auto-doc
duplication
typing
params
suggestion
Wait
batch
job
no-go
Please
use
mock
tests
environment
variables
unittest.mock.patch.dict
'os.environ
AIRFLOW__CORE__DEFAULT_IMPERSONATION=TEST_USER
tests
due
side
effects
failed
tests
AWS
most
failures
_______________
TestS3Hook.test_create_bucket_us_standard_region
_______________
=
<
tests.hooks.test_s3_hook.TestS3Hook
testMethod=test_create_bucket_us_standard_region
@
mock_s3
def
test_create_bucket_us_standard_region
hook
=
S3Hook
aws_conn_id=None
hook.create_bucket
bucket_name='new_bucket
region_name='us-east-1
bucket
=
hook.get_bucket
'new_bucket
self.assertIsNotNone
bucket
region
=
bucket.meta.client.get_bucket_location
Bucket=bucket.name
.get
'LocationConstraint
None
>
self.assertEqual
region
'us-east-1
AssertionError
'eu-west-1
=
'us-east-1'
eu-west-1
generic
approach
raised
exception
[
assertRaises
]
https
//docs.python.org/3/library/unittest.html
unittest.TestCase.assertRaises
Unnecessary
comments
line
L81
mapping
ERROR
DEBUG
CRITICAL
ERROR
color
clarity
sake
logic
hidden
if-else
conditions
dict
log
levels
colors
e.g
=
ERROR
RED
DEBUG
RED
comment
doc
string
base
one
self.getsection
section
suggestion
See
https
//docs.aws.amazon.com/AmazonECS/latest/developerguide/stopped-task-errors.html
noqa
E501
pylint
disable=line-too-long
airflow.helpers.chunks
comment
order_columns
specific
meaning/purpose
Flask
AppBuilder
good
separate
function
Same
suggestion
race
condition
subprocesses
Table
suggestion
connexion
need
import
top
whole
celery
Should
short
note
odd
-we
next
step
suggestion
calculate
metrics
suggestion
self.assertEqual
pool.occupied_slots
pylint
disable=no-value-for-parameter
self.assertEqual
comment
_right_
logging.shutdown
celery
worker
process
multiple
times
next
task
wrong
place
best
place
StandardTaskRUnner._start_by_fork
little
odd
place
least
loads
explanatory
comments
change
someone
airflow
task
run
suggestion
Ignore
comments
JSON
schema
validation
[
image
]
https
//user-images.githubusercontent.com/12058428/99383072-ab2a1280-28cd-11eb-8d37-708358c87f7c.png
multiple
webserver
worker
refresh
state
new
list
old
way
way
_all_
workers
https
//docs.python.org/2/library/itertools.html
itertools.product
product
'xy
>
Ax
Ay
Bx
Cx
Cy
Dx
Dy
suggestion
=
dr
]
.state
dr
None
methods
docstrings
return
suggestion
return
list
iterators
values
environment
variables
values
=
os.environ.get
FB_TABLE_NAME
airflow_test_datatable
FACEBOOK_ADS_CONN_ID
fallback
connection
behavior
DAG
execution
date
default
reattach
job
behavior
job
configurable
suggestion
job_id
f
job_id
_
int
time
Google
client
loop
job
unused
argument
suggestion
dag
past
owner
config
next
change
Please
mock
mock_hook.check_for_bucket.assert_called_once_with
S3CreateBucketOperator.execute
Same
other
tests
Same
please
Same
access
boto3
same
suggestion
env_var_secret_path
=
+
env_var_secret_path
os.environ
valid
secret
key
section
key
self.sensitive_config_values
return
os.environ
[
env_var_secret_path
]
suggestion
non-None
non-default
owner
f
Current
value
task.owner
Fix
License
headers
suggestion
filter_tis
=
[
not_
TI.filter_for_tis
tis_to_keep
change
filter_for_tis
method
something
code
@
staticmethod
def
filter_for_tis
tis
Iterable
[
Union
[
TaskInstance
TaskInstanceKeyType
]
]
>
Optional
[
BooleanClauseList
]
Returns
SQLAlchemy
filter
task
instances
TI
=
TaskInstance
tis
return
None
isinstance
t
tuple
t
tis
t
t
tis
filter_for_tis
=
[
and_
TI.dag_id
==
dag_id
TI.task_id
==
task_id
TI.execution_date
==
execution_date
dag_id
task_id
execution_date
_
tis
]
return
or_
*
filter_for_tis
t
t
tis
filter_for_tis
=
[
and_
TI.dag_id
==
dag_id
TI.task_id
==
task_id
TI.execution_date
==
execution_date
dag_id
task_id
execution_date
tis
]
return
or_
*
filter_for_tis
raise
TypeError
elements
same
type
TaskInstance
tuple
[
dag_id
task_id
execution_date
]
isinstance
t
TaskInstance
t
tis
filter_for_tis
=
[
and_
TI.dag_id
==
ti.dag_id
type
ignore
TI.task_id
==
ti.task_id
type
ignore
TI.execution_date
==
ti.execution_date
type
ignore
ti
tis
]
return
or_
*
filter_for_tis
raise
TypeError
elements
same
type
TaskInstance
tuple
[
dag_id
task_id
execution_date
]
NamedTuple
helper
methods
def
_make_single_record
config_option
return
f
config_option.key
=
config_option.value
source
config_option.source
\n'
def
_make_single_section
config_section
return
f
[
config_section.name
]
\n
_make_single_record
o
o
config_section.options
def
_config_to_plain_text
config
return
_make_single_section
s
s
config.sections
Thanks
pickle
_processor_factory
@
staticmethod
suggestion
type
._processor_factory
suggestion
def
send_email
pylint
disable=too-many-arguments
way
scope
function
suggestion
specific
..
suggestion
timezone
start_date
suggestion
airflow.api_connexion.exceptions
NotFound
wrong
order
First
iam_role_name
s3_bucket
order
__init__
Please
consistent
documentation
functions/methods
magic
values
JOB_POLL_INTERVAL
=
comment
documentation
suggestion
return
id
current
glue
job.
glue_job
AwsGlueJobHook
job_name=self.job_name
desc=self.job_desc
concurrent_run_limit=self.concurrent_run_limit
script_location=self.script_location
conns=self.connections
retry_limit=self.retry_limit
num_of_dpus=self.num_of_dpus
aws_conn_id=self.aws_conn_id
region_name=self.region_name
s3_bucket=self.s3_bucket
iam_role_name=self.iam_role_name
self.log.info
Initializing
AWS
Glue
Job
%
s
self.job_name
glue_job_run
=
glue_job.initialize_job
self.script_args
self.log.info
AWS
Glue
Job
%
s
status
%
s
Run
Id
%
s
]
self.job_name
[
'JobRunState
]
return
[
'JobRunId
]
return
execute
value
key
return_value
correct
syntax
documentation
class
constructor
same
time
option
options
process
building
documentation
pylint
comment
next
line
GCP
cloud
provider
Airflow
operators
Google
service
]
https
//airflow.readthedocs.io/en/latest/operators-and-hooks-ref.html
id13
code
similar
following
self.auth_type
==
gcp
credentials
self.get_gcp_credentialss
self._client.auth.gcp.configure
credentials=credentials
mount_point=self.mount_point
def
get_gcp_credentialss
self.gcp_key_path
credentials
JSON
file
key_path.endswith
'.json
self.log.debug
connection
JSON
key
file
%
s
key_path
credentials
google.oauth2.service_account.Credentials.from_service_account_file
key_path
scopes=self.scopes
elif
key_path.endswith
'.p12
raise
AirflowException
P12
key
file
JSON
key
file
AirflowException
extension
key
file
self.log.debug
connection
google.auth.default
key
file
credentials
_
=
google.auth.default
scopes=self.scopes
credentials
test
re
base
interface
more
blank
space
operator
few
methods
ideal
world
operators
get_conn
method
suggestion
def
construct_pod
pylint
disable=too-many-arguments
correct
suggestion
schema
[
'properties
]
[
Encoding.TYPE.value
]
=
type_enum
section
_very_
least
code
comment
special
case
type
column
uniqueness
constraints
table
suggestion
Should
ignore
HTTP_X_FORWARDED_PROTO
HTTP_X_FORWARDED_HOST
HTTP_X_FORWARDED_PORT
suggestion
Should
HTTP_X_FORWARDED_FOR
comment
valid
sure
suggestion
elif
isinstance
value
bool
value
suggestion
logic
method
compatible
Apache
Beam
suggestion
command.append
f
attr
=
value
suggestion
command.extend
[
f
attr
=
v
v
value
]
suggestion
command.append
f
attr
suggestion
context
TaskGroup
task_id
Note
pylint
rule
everything
context
rest
code
init
function
SlackHook
fine
WebClient
external
service
WebClient.call
class
name
deprecation
message
init
Example
https
//github.com/apache/airflow/pull/6771/files
suggestion
operators
[
]
type
List
[
Type
[
BaseOperator
]
]
list
classes
list
objects
code
bit
cleaner
suggestion
operators
[
]
type
List
[
BaseOperator
]
suggestion
operator_extra_links
[
]
type
List
[
BaseOperatorLink
]
n+1
problem
advanced
features
SQLAlchemy
https
//docs.sqlalchemy.org/en/13/orm/loading_relationships.html
suggestion
sources
importable
airflow
sources
PYTHONPATH
comment
such
order
day
someone
meta_class
backward
compatibility
problems
users
metaclass
operator
BaseOperatorMeta
user
creates
operator
DAG
set_upstream
Operator
implementation
metaclass
metaclass
__init__
method
operator
matter
someone
super
.__init__
*
args
*
*
kwargs
other
words
resolve
initialization
operator
resolve
__init__
works
custom
operator
python
class
CustomOp
BaseOperator
template_fields
custom_field
def
__init__
custom_field
*
args
*
*
kwargs
=
custom_field
super
.__init__
*
args
*
*
kwargs
resvole
case
more
popular
python
class
CustomOp
BaseOperator
template_fields
custom_field
def
__init__
custom_field
*
args
*
*
kwargs
super
.__init__
*
args
*
*
kwargs
resvole
happens
=
custom_field
tests
suggestion
other._lock_for_execution
=
True
pylint
disable=protected-access
more
suggestion
@
pytest.fixture
scope=
class
def
test_dag_bag
return
DagBag
dag_folder=TEST_DAGS_FOLDER
class
def
test_upstream_is_set_when_template_field_is_xcomarg
pylint
disable=redefined-outer-name
need
yield
provide_
Pytest
docs
https
//docs.pytest.org/en/latest/fixture.html
fixtures-as-function-arguments
case
value
test_dag_bag
example
comment
suggestion
mock_client
mock
correct
args
current
task
ID
messages
context
task
suggestion
reason=
parent
task
task
constants
SkipMixin
module
please
gcp
other
cloud
providers
similar
services
future
suggestion
[
START
]
session
least
quick
suggestion
create_session
session
self.assertEqual
session.query
TaskInstance
.filter
TaskInstance.dag_id
==
dag_id
.count
suggestion
invalid
chars
short
hash
python
suggestion
full_content
request.headers.get
'Content-Type
None
==
full
journal
text
format
easy
way
token
suggestion
full_content
content_type
logs
metadata
task_log_reader.read_log_chunks
ti
task_try_number
metadata
=
logs
]
task_try_number
None
return
logs_schema.dump
dict
continuation_token=str
metadata
content=logs
=
task_log_reader.read_log_stream
ti
task_try_number
metadata
mik-laj
comment
accurate
suggestion
necessary
example
https
//airflow.readthedocs.io/en/latest/howto/operator/gcp/cloud_build.html
@
mik-laj
field
uri
human
readable
documentation
airflow
nit
IMO
context
link
CDAP
bug
https
//issues.cask.co/browse/CDAP-7641
way
suggestion
start
call
CDAP
run_id
state
https
//issues.cask.co/browse/CDAP-7641
things
−-non-interactive
command
line
password
user
os.system
string
subprocess
array
https
//docs.python.org/2/library/subprocess.html
replacing-bin-sh-shell-backquote
Done
Check
apache
spark
documentation
example
suggestion
=
self.req.copy
Through-out
please
comment
previous
TIMESTAMP
nullable
obvious
Always
TIMESTAMP
nullable
MySQLdb
None
types
fields
MySQL
timestamps
Python
datetime
e.g
0000-00-00
correct
name
dummy
class
warning
name
change
message
module
new
class
name
other
modules
please
whole
table
column
type
code
difference
DATETIME2
sa.TIMESTAMP
good
practice
task
variable
task_id
sync
suggestion
suggestion
destination
Google
Cloud
Storage
path
slash
/
empty
content
memory
temporary
file
suggestion
object
prefix
empty
directory
dest_gcs_object_prefix
existing_files_prefixed
existing_files_prefixed.remove
dest_gcs_object_prefix
object
prefix
object
string
paths
file
existing_files_prefixed
file.startswith
dest_gcs_object_prefix
existing_files.append
file
[
len
dest_gcs_object_prefix
]
existing_files.append
file
everything
same
way
number
blosks
ok
pylint
Any
reason
list
suggestion
file
existing_files_prefixed
file
contain
form
airflow.models
DAG
airflow
safe
mode
Exception
dag
possible
code
point
view
something
python
MacBook-Pro-van-Fokko
home-analytics
fokkodriesprong
python2
Python
default
Dec
[
GCC
Compatible
Apple
LLVM
clang-1100.0.33.16
]
darwin
Type
help
copyright
credits
license
more
information
>
>
>
invalid_args
=
'dag
'task
>
>
>
'bar'
>
>
>
>
>
>
def
serialize
item
try
return
serializer.loads
serializer.dumps
value
except
Exception
e
msg
Exception
%
s
argument
object
%
s
op_kwargs
key
%
s
skipping
%
e
value
key
self.log.debug
msg
>
>
Replace
something
simple
sake
>
>
def
serialize
item
return
item
>
>
>
=
key
serialize
item
key
item
op_kwargs.items
key
invalid_args
>
>
>
>
>
>
'bar
serialize
function
below
code
'airflow
Loggers
manager
=
logging.root.manager
=
logging.NOTSET
airflow_loggers
[
logger
logger_name
logger
manager.loggerDict.items
logger_name.startswith
]
logger
airflow_loggers
pylint
disable=too-many-nested-blocks
isinstance
logger
logging.Logger
logger.setLevel
logging.NOTSET
logger.propagate
=
True
=
False
logger.filters.clear
handlers
logger.handlers.copy
handler
handlers
Copied
logging.shutdown
try
handler.acquire
handler.flush
handler.close
OSError
ValueError
pass
handler.release
logger.removeHandler
handler
suggestion
suggestion
post_op
=
SimpleHttpOperator
task_id='post_op
task
instance
task_id
functional
approach
full
swing
airflow.operators.python
import
get_current_context
def
extract
ctx
=
get_current_context
ti
=
ctx
[
'ti
]
whole
example
docs
ok
👌
invocation
favor
None
schedule
most
examples
example
scheduler
multiple
runs
suggestion
@
task
def
extract
*
*
kwargs
able
@
task
doc_md=
docs
extract
*
*
kwargs
suggestion
@
task
def
transform
*
*
kwargs
@
task
decorator
PythonOperator
main
point
functional
DAGs
Format
how/why
doc
comment
anything
function
name
python
class
ConfiguredSentry
DummySentry
Sentry
=
DummySentry
type
DummySentry
suggestion
elif
unfinished_tasks
leaf_ti.state
State.SUCCESS
State.SKIPPED
leaf_ti
leaf_tis
suggestion
Ensure
string
Large
offset
numbers
suggestion
suggestion
logic
None
higher
priority
=
token
AirflowException
token
valid
api
pagerduty_conn_id
previous
suggestion
block
suggestion
mod_attr_value
m
m
mod.__dict__.values
is_valid_plugin
m
plugin_instance
=
mod_attr_value
plugins.append
plugin_instance
strong
opinion
way
able
pylint
disable=too-many-nested-blocks
suggestion
Dependencies
instance
re-queued
pylint
comment
suggestion
accounts
=
conn.management
.accounts
pylint
disable=no-member
L72
suggestion
response
totalResults
==
len
result
loop
results
suggestion
Use
parameter
pagination
mechanism
max-results
parameter
suggestion
def
list_accounts
max_results
int
start_index
int
>
List
[
Dict
[
str
Any
]
]
generic
types
block
comment
update
interval
bit
time
previous
statements
Same
example
curious
variable
value
future
code
migration
natIP
empty
access
configuration
comment
def
generate_key_string
pkey
paramiko.PKey
key_fh
=
StringIO
pkey.write_private_key
key_fh
key_fh.seek
key_str
=
key_fh.read
code
SSH
key
Had
wrong
%
]
[
2020-06-19
]
validation.py:230
ERROR
http
//localhost/api/v1/dags/test_dag/details
validation
error
'TimeDelta
'days
'seconds
valid
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
/components/schemas/ScheduleInterval
]
'object
[
]
'properties
'years
'integer
'months
'integer
'days
'integer
'leapdays
'integer
'integer
'integer
'integer
'integer
'year
'integer
'month
'integer
'day
'integer
'integer
'integer
'integer
'integer
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
/components/schemas/ScheduleInterval
]
'object
[
]
'properties
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
/components/schemas/ScheduleInterval
]
'object
[
]
'properties
'days
'integer
'integer
'integer
'oneOf
schema
[
'allOf
]
]
[
'properties
]
[
'schedule_interval
]
'discriminator
'__type
[
'properties
'days
'integer
'integer
'integer
[
]
'object
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
/components/schemas/ScheduleInterval
]
'properties
'day
'integer
'days
'integer
'integer
'integer
'leapdays
'integer
'integer
'integer
'integer
'integer
'month
'integer
'months
'integer
'integer
'integer
'year
'integer
'years
'integer
[
]
'object
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
/components/schemas/ScheduleInterval
]
'properties
[
]
'object
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
/components/schemas/ScheduleInterval
]
]
True
x-scope
[
/components/schemas/DAGCollection
/components/schemas/DAG
]
instance
[
'schedule_interval
]
'TimeDelta
'days
'seconds
sure
right
way
nothing
mind
clients
single
DAG
dagbag
second
one
empty
serialization
@
houqp
more
suggestion
DAG
dag_id='simple_dag
start_date=datetime
tzinfo=timezone.utc
dag
BaseOperator
task_id='simple_task
RuntimeError
dictionary
size
iteration
SerializedDAG.to_dict
dag
ashb
assertWarns
>
assertRegex
number
queries
falsifies
results
optimizations
DagFileProcessor
queries
number
Dags
file
option
number
queries
time
big
impact
performance
Curious
functions
bit
users
e.g
task_ids
something
TODO
worth
comment
feels
bit
hacky
kind
couples
task
execution
global
state
use
kwargs
relate
deprecation
Airflow
e.g
BaseOperator
code
args
kwargs
TODO
*
args
*
*
kwargs
Airflow
warnings.warn
'Invalid
arguments
task_id
'Support
such
arguments
'Airflow
Invalid
arguments
*
args
\n
*
*
kwargs
'.format
c=self.__class__.__name__
a=args
k=kwargs
t=task_id
stacklevel=3
deprecation
kwargs/args
first
place
backwards
compatibility
comment
auto
id
looks
easier
suggestion
Validate
callable
operator
suggestion
Python
wrapper
PythonFunctionalOperator
simple
python
functions
suggestion
dag2
clarification
comments
tests
able
access
job
task_instace.xcom_pull
create_glacier_job
job_id
something
suggestion
need
type
suggestion
GoogleSystemTest.delete_gcs_bucket
BUCKET
suggestion
def
suggestion
def
test_poke_fail
suggestion
def
test_poke_in_progress
pylint
rc
Argument
names
expression
Default
ignored-argument-names=_
|^ignored_|^unused_|^kwargs|^args|^mock_.+
suggestion
TODO
Re-enable
python-requests.org
example
block=True
default
means
extract
second
task
block=False
suggestion
comment
condition
union
intersection
stuff
rid
line-too-long
possible
noise
code
atleast
Github
diff
D
IMHO
link
documentation
necessary
schedule_interval
DAG
class
same
feng-tao
question
noqa
W605
test
original
code
issue
code
similar
self._get_job_id_from_name
def
_get_job_id_from_name
Helper
method
list
jobs
start
job
name
return
list
jobs
id's
rtype
list
jobs
self._dataflow.projects
.locations
.jobs
.list
location=self._job_location
.execute
num_retries=self._num_retries
=
[
]
jobs
job
jobs
[
'jobs
]
job
]
.startswith
self._job_name.lower
dataflow_jobs.append
job
dataflow_jobs
self._job_id
=
]
[
'id
]
return
Same
key
string
constructor
bit
unclear
xcomarg
PythonFunctionlOperator
operator
XComArg
case
actual
code
clear
check
Let
actual
string
value
More
explicit
suggestion
assert
actual
==
XComArg
python_op
test_key
one-liner
pylint
disable=too-many-arguments
too-many-locals
My
time
execute
get_connection
api_key
api_key
object
level
hook
further
calls
key
get_connection
call
hook
concern
problem
suggestion
HttpHook
nice
constant
test
old
behaviour
i.e
dupe
same
test
tests/providers/cncf/kubernetes/operators/test_kubernetes_pod.py
such
tests
old
behaviour
import
top
level
looks
more
test
Minor
point
Bowler
constants
comment
types
Looks
nice
readable
👌
suggestion
airflow.gcp.hooks.speech_to_text
import
CloudSpeechToTextHook
change
change
behavior
suggestion
authentication
code
reuse
Hook
Secret
class
rendered
docs
suggestion
HashiCorp
HVAC
documentation
suggestion
HashiCorp
hvac
documentation
suggestion
def
get_current_task_group
cls
dag
Optional
[
DAG
]
>
Optional
[
TaskGroup
current
TaskGroup.
airflow.models.dag
import
DagContext
cls._context_managed_task_group
dag
dag
DagContext.get_current_dag
DAG
optional
due
logic
L387
comment
docstring
nothing
false
row
suggestion
_DEFAULT_SCOPES
type
Sequence
[
str
]
=
//www.googleapis.com/auth/cloud-platform
work
py2
py3
comment
char
set
valid
char
noqa
log_id
internal
key
memory
log
handler
smart
sensor
service
output
path
configure
set_context
function
consistent
other
tasks
Misplaced
comment
L207
suggestion
mock_client.assert_called_once_with
credentials
CREDENTIALS
marker
suggestion
def
convert_value
cls
value
Optional
[
Any
]
>
Optional
[
Any
]
pylint
disable=too-many-return-statements
other
handles
pages
user
pagination
WDYT
suggestion
@
GoogleBaseHook.fallback_to_default_project_id
def
list_deployments
project_id
str
deployment_filter
Optional
[
str
]
=None
max_results
Optional
[
int
]
=None
order_by
Optional
[
str
]
=None
suggestion
type
page_token
str
suggestion
page_token
Optional
[
str
]
=None
>
List
[
Dict
[
str
Any
]
]
pylint
disable=too-many-arguments
suggestion
request
=
client.deployments
.list
project=project_id
pylint
disable=no-member
suggestion
request
=
client.deployments
.delete
project=project_id
pylint
disable=no-member
Optional
type
comments
tools
CI
suggestion
import
Optional
suggestion
original_account
=
None
type
Optional
[
str
line
information
available
Web
UI
global
variable
assertion
redundant
range_
default
value
py
=
L126
self._wait_for_completion
state
None
True
dag_run.refresh_from_db
state
=
dag_run.state
state
self.failed_states
AirflowException
state
self.allowed_states
self.log.info
sleep
block
else
condition
right
comment
suggestion
non
jenkins
api
point
function
Ca
function
operator
write_object_to_file
duplicate
isinstance
content
tuple
check
clarity
list
tuple
check
elif
isinstance
content
list
result
=
[
rt
attr
e
context
e
content
]
elif
isinstance
content
tuple
type
content
tuple
Namedtuple
result
=
content.__class__
*
rt
attr
e
context
e
content
result
=
[
rt
attr
e
context
e
content
]
behaviour
difference
usages
fields
optional
exclusive
testing
bit
API
key
fed-observer
instance
^^typo
Please
complete
description
function
example
test
https
//github.com/metabrainz/picard/blob/master/test/test_script.py
datetime.now
.astimezone
.strftime
format
>
>
>
datetime.now
.astimezone
.strftime
%
z
>
>
>
datetime.now
.strftime
%
z
sure
Python3.5
@
phw
country
attribute
MB
response
area
attribute
something
area
iso-3166-1-codes
DE
]
id
85752fda-13c4-31a3-bee5-0e5cb1f51dad
sort-name
Germany
disambiguation
name
Germany
Overall
much
value
attribute
order
something
List
pictures
previous
loop
insert
index
value
order
>
>
>
l
=
[
b
c
]
>
>
>
l
[
b
c
]
>
>
>
p
[
'pic1
'pic2
]
l.insert
p
>
>
l
[
'pic3
'pic2
'pic1
b
c
]
AttributeError
good
idea
least
protect
specific
attribute
access
case
peer.head_info
attribute
error
others
sure
ditto
ideal
inclined
simpler
i.e.
two-level
acceptable
minor
comment/formatting
https
//github.com/ethereum/trinity/pull/478/commits/b8a0843e9c046c455ffcf59916f89fed132d1f51
small
comment
number
nodes
important
someone
number
created
nodes
flaky
Makes
sense
Any
suggestions
content/place
such
comment
Nit
comment
await
event_bus.wait_until_any
line
more
sense
line
suggestion
Sort
order
exit
epoch
validators
exit
same
epoch
exit
Nitpick
*
styleguide
first
doc
line
same
line
opening
triple
quotes
https
//github.com/ethereum/snake-charmers-tactical-manual/blob/master/style-guide.md
exceptions-to-docstring-style-peps
Does
line
work
errors
CI
linter
line
bug
rationale
something
method
mocked
method
sure
exceptions
result
start_peer
comment
suggestion
False
tests
connection
successful
https
//github.com/ethereum/trinity/issues/1767
issuecomment-654004827
lines
card
much
identical
python
async
background_trio_service
discovery
manager
reason
manual
manager
instantiation
server
others
Question
possible
=
self.chain.get_state_machine
state.slot
.state_class
type
ignore
comment
python3.8
python3.7
only
way
happy
warn_unused_ignores
=
False
mypy.ini
Maybe
assign
DEFAULT_BACKEND
DEFAULT_BACKEND
=
PyECCBackend
type
Type
[
BaseBLSBackend
python
try
.milagro
import
MilagroBackend
DEFAULT_BACKEND
=
MilagroBackend
default
MilagroBackend
AVAILABLE_BACKENDS
+=
MilagroBackend
ImportError
pass
try
.chia
import
ChiaBackend
AVAILABLE_BACKENDS
+=
ChiaBackend
ImportError
pass
fixture
multiple
test
files
little
uncomfortable
implicit
validation
mechanisms
functionality
part
eth-keys
API
more
side
effect
tests
code
path
tests
clear
implicit
reliance
internal
validation
mechanisms
eth-keys
need
noqa
anything
tomorrow
>
comment
exceptions
comment
nit
suggestion
EMPTY_SIGNATURE
invalid
@
NIC619
@
pipermerriam
case
other
words
specific
module
lower
level
stderr
file
stderr
logs
file
log
trinity
-l
ERROR
-l
p2p.discovery=DEBUG2
discovery
logs
stdout
file
log
reason
current
approach
dedicated
handler
p2p.discovery
logger
time
file
something
nobody
solution
preferred
way
commented
test
case
issue
PR
net
positive
able
trinity
-l
ERROR
-l
%
comment
timeout
exceptions
information
separate
mapping
Exception
>
timeout
different
approach
spec
validations
....
e.g
ValidationError
https
main
advantage
i
able
wrong
AssertionErrror
something
follow-up
PR
issue
redefinition
config
Wrong
comment
code
block
multiplexer.raise_if_streaming_error
handshake_err
code
equivalent
current
if/else
construct
new
block
witness
local
tip
block
number
+1
block
importer
hashes
urgent
new
block
earlier
comment
ok_hand
logic
hairy
reminder
futur
modifications
explanatory
comment
No
end
point
more
sense
duration
minutes
ie
multiple
times
minutes
realistic
suggestion
Remove
reuse
logo
sizes
comment
natural
code
use
invalid
axis
ValueError
_translated_key
line
corresponding
case
duplicate
axes
weird
wrong
Oops
commented
code
link
relevant
fear
slow
large
sheets
test
ok
Otherwise
something
code
untested
much
faster
last_cell
=
None
row
=
used.Row
+
used.Rows.Count
used.Column
sheet
row/columns
data
col_count
=
used.Columns.Count
last_cell
None
max_row_cell
=
used.Cells
row
col_count
+
.End
xldir.xlToLeft
max_row_col
=
max_row_cell.Column
first
column
max_col
max_row_cell.Value
=
last_cell
=
row
max_col
row
data
blank
column/row
sheet
usedRange
equivalent
Ctrl-End
Excel
bad2
sheet
new
file
issue
BTW
bad2
xlrd
engine
other
hand
behavior
option
nice
everything
blanks
default
intuitive
subset
much
data
rename
same
changelog
example
array
axis
docstring
space
same
thing
array
array
fine
key
different
case
tuple
scalar
unit
test
*
*
*
arr_2D.sort_values
axis=
b
comment
block
code
need
comment
something
integer
fill_value
error
comment
list
TypeOfAny
case
deeply
kind
corresponds
case
false
info
comment
enums
thing
TODO
comment
conditions
side
explicit
better
implicit
sure
comment
places
future
change
doesnt
dangling
comment
reference
Add
wrong
TODO
item
better
overload
type
semantic
analyzer
need
anything
TODO
comment
dummy
comment
variable-length
tuple
*
args
assumptions
comment
issue
str
somes
types
internal
state
equality
visible
string
representation
better
approach
bullet
use
quadratic
pairwise
is_same_type
comparisons
items
right
type
item
left
union
Union
[
int
str
]
same
Union
[
int
str
]
other
way
test
case
Wow
dumb
Anyway
readability/performance
hack
something
workaround
correct
solution
Did
isinstance
get_proper_type
arg.variable.type
AnyType
Added
TODO
comment
problem
minor
worth
issue
explanation
clear
function
top-level
functions
second
phase
analysis
processing
functions
reasonable
shorter
one-line
help
text
longer
explanation
docs
comment
quick
comment
mypyc
motivation
Add
comment
complete
implementations
operands
long
integer
Add
current
date
comment
somebody
comment
year
flag
other
mypy
tests
flags
better
consistent
comments
Mypy
able
int
sure
comment
example
check_op_local
code
TODO
comments
duplication
non-
Instance
types
name
Could
TODO
item
mypy
modules
client
quicker
case
server
stats
code
methods
logic
method
less
cluttered
TBH
sure
return
context
cases
T
<
int
T
<
Iterable
[
int
]
only
way
T
<
List
int
]
better
invariant
containers
less
subtypes
original
problem
def
f
x
List
[
T
]
>
T
y
object
=
f
[
]
Incompatible
argument
type
List
[
int
]
List
[
]
other
words
problem
return
type
variable
invariant
context
argument
types
invariant
ones
correct
return
type
Any
uninhabited
type
None
sure
infer_type_arguments
behaves
no-strict-optional
vs
strict-optional
mode
subtle
difference
behavior
None
inhabits
type
former
mode
latter
ret_type
something
same
way
modes
sure
edge
cases
E.g
pair
def
__get__
typ
>
float
return
self._val
def
__set__
value
>
None
self._val
=
float
value
usage
isinstance
a.foo
int
a.foo
=
int
a.foo
blah
[
]
Suppose
blah
List
index
int
less
real
unions
subtypes
most
cases
subtypes
float/int
int
changes
representation
set
items.keys
part
TypedDict
required_keys
subset
items
comment
Hm
something
least
directions
hard
things
straight
notes
tests
comment
specific
argument
key
compatible
non-required
key
=
TypedDict
A
x
int
B
=
TypedDict
B
x
int
def
f
b
B
>
None
del
b
[
x
]
=
x
f
Error
next
line
[
x
]
KeyError
item
attribute
__delitem__
e.g
=
TypedDict
A
x
int
y
=
x
y
[
x
]
unclear
Please
comment
Add
comment
references
semantic
analysis
sure
TODO
comment
worth
Values
Items
sure
comment
nothing
comment
clear
something
class
subtype
relationship
classes
incompatible
overrides
'__init__'/'__new__
general
little
unsafety
common
pain
point
Please
more
detailed
comment
motivation/trade-offs
points
mention
*
unsafe
due
possible
errors
members
nested
classes
*
many
false
positives
Django
*
single
inheritance
potential
solution
least
structural
compatibility
nominal
impractical
rename
subtype_caches
proper_subtype_caches
above
comment
moot
_
prefix
methods
rename
clear
clear_caches
mention
proper
subtype
checks
caches
normal
subtype
checks
unnecessary
public
API
caches
demand
comment
helpful
code
_motivation_
from_type_type
flag
error
collection
concrete
class
objects
common
abstract
superclass
same
applies
please
start
comments
uppercase
letter
Add
comment
clear
erase_typevars
refers
explicit
such
erase_typevars
type
variable
above
comment
particular
use
int64_t
type
Hm
tricky
problem
top
level
TypeInfo
state
semantic
analysis
class
named
tuple
update
sure
TBH
old
aststrip
wrong
decorators
part
module
top-level
test
test
Maybe
mention
docstring
additions
tables
method
new
ones
course
least
extent
constant
top
file
bit
info
Aha
comment
incremental
step
number
regexp
cmd2
cmd3
function
incremental
step
name
m2
kind
code
bit
clearer
cmdlol
able
cmd
cmd2
cmd3
others
cmd
other
second
cmds
cmdlol
sure
worth
much
deliberation
outN
staleN
etc.
type
annotations
unnecessary
straightforward
attribute
hooks
type
_autoconvertible_to_cdata
return
type
argument
type
example
Array.__setitem__
rules
union
types
complicated
example
arr
type
Array
[
Union
[
c_int
c_uint
]
]
arr
[
i
=
x
valid
x
c_int
*
*
c_uint
i.
type
x
intersection
_autoconvertible_to_cdata
c_int
_autoconvertible_to_cdata
c_uint
mypy
intersection
types
easy
intersection
calculation
sets
Type
objects
hashable
manual
intersection
algorithm
is_subtype
Fixed
union
Union
[
c_char
Any
]
useful
Every
c_char
Any
union
get
point
make_simplified_union
points
s
unions
unclear
contexts
Add
comment
Add
comment
special
case
visitor
single-use
mention
docstring
Add
comment
clear
short
comment
attention
typo
Add
comment
add_trigger=True
Again
current_full_target
comment
type
aliases
special
necessary
useful
precise
root
cause
mention
TODO
comment
os.makedirs
parent
exist_ok=True
https
//docs.python.org/3/library/os.html
os.makedirs
search
__getattribute__
object.__getattribute__
typeshed
Any
mypy
attribute
fix
object.__getattribute__
NoReturn
AttributeError
comment
second
half
test
guard
comment
Add
comment
mention
non-
None
cached
value
mention
TypeAliasType
reader
much
comment
value
optimization
same
TODO
line
modules
set
modified
files
class
other
namespace
get_prefix
component
end
utility
name
prefix
prefix
+
'.
TODO
suggestion
attribute
hook
extra
spaces
comment
name
descriptive
docstring
few
things
*
Load
fine-grained
deps
cache
*
Calculate
fine-grained
dependencies
files
build
incremental
build
subset
modules
dependencies
file
function
something
generate_deps_for_cache
mention
above
things
docstring
true
worth
coarse-grained
incremental
mode
elif
OverloadedFuncDef
TODO
Inexperience
mypy
codebase
existence
self.type
thanks
update
complex
code
tasks
self.type
addresses
other
task
base.node
fact
reference
class
instance
added
test
variable
class
reference
https
//gist.github.com/carljm/174bff5aeb78d9a3b04ed11a536cfb9f
suggestion
better
way
verification
happy
course
possible
variable
name
cls
self
correct
such
naming
requirement
language
nested-class
cases
people
e.g
self_
complex
code
access
current
active
class
self.type
attributes
TBH
bunch
s
hard
sense
refactor
explanatory
comments
fail
AssertionError
additional
final
pass
Just
infinite
loops
other
cases
check
everything
sendall
sockets
empty
string
end
buffer
dmypy_util
comment
Could
test
errors
longer
read
size
PIPE_ACCEPT_REMOTE_CLIENTS
flag
third
arg
last
one
*
remote
clients
last
arg
lpSecurityAttributes
trouble
default
NULL
ACLs
default
security
descriptor
pipe
grant
full
control
LocalSystem
account
administrators
creator
owner
read
access
members
Everyone
group
anonymous
account
https
//docs.microsoft.com/en-us/windows/desktop/ipc/named-pipe-security-and-access-rights
clear
implications
read
access
everyone
typechecking
connection
server
Solve
concurrency
problems
thing
Event
server
ready
opposite
implicit
specifics
clear
comment
Added
comment
implicit
more
clear
explicit
opposite
implicit
implicit
refers
situations
variable
parameter
explicit
refers
situations
explicit
annotation
instance
unimported
type
explicit
implicit
False
implicit
wrong
name
disallow-untyped-defs
parameter
variable
explicit
type
annotation
comments
implicit
worth
comment
need
PlaceholderNode
something
unexpected
weird
things
generated
C
source
subset
other
source
clearer
distinction
source
source
source
explicit
few
more
sentences
typing.List
builtins.list
comment
fault
nested
function
method
Style
nit
self
body
module-level
function
name
_
prefix
module
level
Suggestion
type_info_from_type
short
comment
Add
short
comment
Add
comment
something
incomplete
type
ignore
mypyc
strange
ways
mention
difference
exception
historical
reasons
PEP
way
instance
variable
default
value
x
int
strict-optional
same
code
module
function
scopes
PR
@
ilevkivskyi
violation
strict
optional
value
declaration
Optional
[
Key
]
build
PR
new
literal_hash
returns
None
match
client
code
declaration
Optional
[
Key
]
>
error
type_object_type
other
types
least
cases
error
comment
Could
comment
fields
typical
usage
TODO
inference
deferred
nodes
pretty
pointless
suggestion
Fine-grained
mode
non-blocking
parse
errors
suggestion
Fine-grained
mode
non-blocking
parse
errors
https
//github.com/python/typeshed/pull/2683
os.stat_result
general
type
ignore
greppable
way
run
warn-unused-ignores
hack
small
typo
checkmember.py
meme-ber
Thank
erased
instance
TODO
checker.py
Try/except
special
handling
type
checker
added
comment
statements
TODO
precise
mypy
issue
https
//github.com/python/mypy/issues/1533
Any
position
content
comment
method
check
clear
None
i.e
something
None
None
isinstance
existing.node
Var
Style
nit
parens
precedence
explicit
/
single
expression
Thanks
big
comment
confusion
possible
line
second
step
dependencies
function
returns
data_mtime
nice
comment
list
star
args
empty
comment
likely
daemon
Same
blank
line
reason
worth
TODO
comment
issue
Add
comment
self.obj
pytest
magic
many
readers
likely
familiar
more
context
test
code
path
code
__future__
import
print_function
def
main
distutils.sysconfig
import
get_python_lib
import
site
hasattr
site
'getusersitepackages
hasattr
site
'getsitepackages
user_dir
=
site.getusersitepackages
return
site.getsitepackages
[
user_dir
]
return
get_python_lib
__name__
==
print
repr
main
active_python
exec_globals
exec
code
exec_globals
=
exec_globals
]
res
ast.literal_eval
call
[
'python
'-c
]
typeshed
stubs
typed_ast
update
test
idea
fill_typevars
python
class
C
Generic
[
T
]
x
T
def
meth
self.x
error
check-untyped-defs
TODO
question
mark
statement
=
unioned_errors.is_errors
comment
Record
comment
something
simple
Step
branch
much
union
math
fails
bit
TODO
something
easy
perf
Could
test
change
name
cleaner
filed_args.get
'init
comment/coercion
unnecessary
comment
more
details
Please
above
comment
attr.is_in_init
important
dangerous
same
type
cmp_other_type
different
methods
attrs
plugin
many
things
block
Move
unnecessary
code
field_args
Please
space
comma
need
comment
source
bug
people
information
git
blame
Add
comment
Discuss
comment
bit
unclear
use
expression/runtime
context
mypy
suggestion
method
minor
nested
function
Type
[
C
]
checks
logic
left
right
cases
plural
next
error
most
implementation
plurals
sentence
singulars
time
t
name
more
sense
defn.items
separate
case
Add
comment
pretty
key
Optional
Currently
None
initialization
function
id_mapper
None
Add
short
docstring
need
arguments
detail
comment
comment
bit
unclear
Which
comment
refer
kinds
clear
type-checked
TypeInfos
new
dependencies
dependencies
global
property
program
Please
bit
type-checked
example
ClsName
<
ClsName
>
file
class
target
class
definition
none
nits
few
TypeInfos
few
TypeInfos
only
only
ones
comment
hint
deps.json
files
fine-grained
deps
c_function_call
suffix
verbose
results
ambiguity
f/when
new
class
different
names
name
current
implementation
new
name
C
function
comment
date
C
functions
ERR_MAGIC
things
error
example
targeted
dependencies
base
abstract
attrs
class
abstract
abstract
changes
whole
class
dependency
base
abstract
attrs
base
abstract
TODO
Maybe
types
suggestion
precise
types
comment
lines
comment
new
Var
time
same
module
logic
same
docstring
create_getattr_var
rename
something
logical-deps
semantic-deps
imply
cache-fine-grained
motivation
dependencies
independent
details
fine-grained
incremental
checking
works
Mention
experimental
undocumented
feature
time
Add
comment
Could
attribute
x.y
Typo
TOOD
>
TODO
__iter__
depend
__getitem__
audit
TODOs
asserts
docstring
rename
get_type_triggers
TODO
Use
more
places
get_type_dependencies
+
add_dependency
comment
RuntimeError
visit_partial_type
type
type
inference
type
List
[
str
]
comment
bit
unclear
afterwards
something
options
kind
least
mention
docstring
hack
unrelated
definitions
function
definition
overload
items
latter
.items
.impl
separate
helper
method
comment
corner
case
mypy
runtime
name
resolution
fine
overloaded
function
single
unit
__init__
object
many
tests
info.names
condition
true
above
elif
block
suggestion
s
Any
case
missing_import
Any
bit
ad
hoc
TBH
better
proposal
Could
comment
False
particular
case
result
suggestion
mode
pass
anymore
comment
Add
comment
Add
short
comment
example
something
Type
assignment
union
item
inferred
lvalue
types
union
item.
Again
comment
purpose
look
sentence
more
comment
loop
Add
comment
suggestion
typeshed
more
implementation
detail
Enums
blank
line
last
commit
better
sys.exit
calls
print
bit
bit
odd
Update
comment
TypeVarExpr
part
particular
test
case
only
cause
deferral
possible
caller
None
return
case
above
None
returns
above
checks
fails
e.g.
covariant
invalid
value
Somehow
global
effect
fact
base
check
base.isidentifier
throwaway
variable
stuff
other
comment
suggestion
Ensure
base
valid
python
module
name
base.endswith
'-stubs
base
=
base
[
-6
]
PEP-561
stub-only
directory
extra
negation
isinstance
typ
AnyType
is_explicit_any
typ
clearer
able
unicode
str
literals
Python
example
open
mode
argument
unicode
literal
__future__
import
unicode_literals
name
LiteralValue
bit
descriptive
current
name
implies
Expression
object
case
comment
useful
thanks
debugging
script
Please
comment
FileNotFoundError
original
cache
startswith
behavior
docstring
necessary
issue
number
rest
comment
useful
spaces
suggestion
if_map
=
type
TypeMap
subtle
order
dependency
comment
debug
print
error
test
temp
dir
condition
hard
comment
high
level
concrete
examples
worth
nested
boolean
expression
Ideas
*
top-level
expression
form
e1
e1
e2
first
operator
bit
harder
*
Use
temp
variable
result
self.type
self.is_func_scope
meaningful
name
bit
subtle
comment
original
full
name
multiple
imports
same
original
definition
qualified
names
test
comment
error
internal
Dropbox
codebase
py
import
Union
class
A
B
=
Union
[
int
str
]
def
f
>
B
PR
invalid
type
pass
type
aliases
class
body
anything
rvalue
valid
type
IndexExpr
type
alias
i.e
restrict
simple
cases
X
=
Y
pyversion
]
+
range
pyversion
]
+
class
docstring
simple
example
situation
def
foo
x
int
>
None
def
bar
x
str
>
None
test
y
foo
x
bar
y
[
[
int
]
[
]
]
Trivial
>
Nitpick
comment
preceding
line
consistency
next
member
variable
initalization
Ew
way
logic
change
particular
Add
TODO
item
items
list
Similar
term
'pass
more_passes
variable
Github
comment
above
simplifications
rid
next
statement
hard
new
error
messages
changed
tests
longer
case
redundant
way
minor
nit
cleaner
sub_result
nested
loop
single
one
comment
something
Step
splitting
duplicate
items
short
comment
track
is_function
understanding
fine-grained
targets
top
level
functions
NAME
=
NamedTuple
'NAME
same
l.h.s
sure
variant
TypeOfAny
guidance
comment
equality
types
wrong
thing
Might
more
sense
much
extended
comment
new
field
instances
expensive
necessary
Short
motivation
PR
Large
scale
design
i.e
checker
expression
visitor
type
*
example
None
noqas
issue
generate_c_for_modules
things
loops
declarations
Similar
comment
previous
one
mean
version
check
true
versions
earlier
version_info
extra
components
first
Please
comment
<
condition
implementation
hexadecimal
escape
sequences
octal
diff
diff
git
i/mypyc/cstring.py
w/mypyc/cstring.py
index
..
i/mypyc/cstring.py
+++
w/mypyc/cstring.py
@
@
-19,9
+19,11
@
@
octal
digits.
import
+import
itertools
import
Tuple
-CHAR_MAP
=
[
:03o
i
i
range
]
+HEX_DIGITS
=
frozenset
string.hexdigits
=
safe
string.printable
C
locale
c
string.printable
@
@
-49,5
+51,13
@
@
def
s
str
>
Tuple
[
str
int
]
def
encode_bytes_as_c_string
b
bytes
>
Tuple
[
str
int
]
quoted
C
literal
size
byte
string
.join
[
CHAR_MAP
[
i
i
b
]
+
=
+
printable
group
itertools.groupby
b
key=CHAR_MAP.__contains__
+
printable
+
s
.join
[
CHAR_MAP
[
i
i
group
]
s
[
]
HEX_DIGITS
+
+=
+
+=
s
+
+
+=
.join
[
'\\x
:02X
i
i
group
]
return
b
msullivan
simplest
method
able
escape
sequences
python
x
'\\
b
f
'n
r
't
v
x
value
=
escaped.encode
'ascii
.decode
'unicode_escape
C_CHAR_MAP
[
ord
value
=
huge
fan
escape
sequence
method
something
various
auto-generated
s
methods/variables
syntactic
nodes
namespace
bunch
crashes
logic
TBH
only
changes
first
pass
everything
level
strict-optional
statement
error
message
second
pass
able
test
case
error
message
test
case
ill-defined
anyways
f
x
>
T
case
gitter
Same
sort
thing
comment
conditions
old
logic
sig1
None
condition
false
generics
generics
is_callable_compatible
something
poor
job
complicated
cases
use
+
NoReturn
type
guards
idea
comments
new
implementation
sure
new
approach
correct
wrong
wrong
overload
signature
int
>
int
List
[
int
]
>
str
user
argument
type
List
[
str
]
something
guess
user
second
option
error
message
compatibility
lot
error
messages
comment
comment
Sorry
look
evening
Any
annotation
type
ignore
important
aspect
explicit
type
annotation
module
assignment
module
alias
normal
variable
type
consistent
type
aliases
great
behaviour
PR
import
m
import
types
class
A
class
B
A
Alias
A
type
alias
Var
Type
]
=
A
normal
variable
mod
=
m
module
mod.a
OK
mod_var
types.ModuleType
=
m
normal
variable
mod_var.a
Fails
ModuleType
attribute
test
module
assignment
explicit
type
types.ModuleType
Any
Hmm
further
point
type
alias
var
type
Type
type
types.ModuleType
sure
intuitive
useful
behavior
type
aliases
module
references
different
ways
real
module
reference
function
parameter
types.ModuleType
anything
real
module
reference
ordinary
variable
types.ModuleType
preferred
behavior
real-world
use
case
variable
types.ModuleType
mind
changes
reasoning
several
things
better
annotation
module
type
ignore
specific
location
mypy
latter
better
test
case
mypy
other
attribute
accesses
module
own
code
base
type
ignore
special-case
line
annotation
variable
explicit
annotation
type
module-ref
propagation
bug
PR
good
catch
fix
test
explicit
annotation
types.ModuleType
propagation
module-reference
information
consistent
class
work
above
example
import
Type
class
A
foo
=
var
Type
]
=
A
reveal_type
var.foo
code
type-checks
fine
type
builtins.str
parallel
import
m
import
types
mod
types.ModuleType
=
m
reveal_type
m.a
latter
code
type
builtins.str
Module
attribute
explicit
type
types.ModuleType
imply
mypy
dumb
module
behavior
sense
happy
comment
docstring
Ditto
Docstrings
users
function
comments
readers
function
body
spaces
=
special
case
PEP
comment
kind
hack
look
other
comment
code
helper
method
callee
type
method
name
name
Sorry
issue
comment
PR
more
Again
short
motivational
comment
helpful
future
reader
function
something
look
error
least
positional
argument
several
lines
Python
arguments
logic
bit
wrong
bit
inconsistent
first
argument
logic
simple
error
message
question
consistency
case
error
message
sense
constant
comment
whatever
kind
explains
code
abstract
purpose
way
good
methods
__init__
nit
less
indentation
order
conditional
checks
avoid
backslashes
conditional_type_map
current_type
return
isinstance
current_type
CallableType
return
None
isinstance
current_type
UnionType
callables
[
item
item
current_type.items
isinstance
item
CallableType
type
List
[
Type
]
=
[
item
item
current_type.items
isinstance
item
CallableType
type
List
[
Type
]
return
expr
UnionType.make_union
callables
expr
UnionType.make_union
non_callables
None
list
comprehensions
bit
wasteful
fine
unions
docstring
clear
C
[
int
]
type
reference
good
explicit
worth
type
alias
context
important
error
messages
sense
type
alias
downside
nested
functions
annotation
function
several
times
last
week
sure
simple
way
nested
functions
sense
issue
TODO
Nit
document
contains
module
search
directories
id
top-level
package
name
Add
Add
comment
assert_true
redundant
assert
statement
consistency
other
ops
single-line
comment
e.g
Create
empty
dictionary
old
op
something
single-line
comment
documents
arguments
special_sig
=
None
type
Optional
[
str
]
<
blah
>
special_sig
rest
comment
pretty
redundant
casts
scary
complexity
Suggestion
item_list
=
[
item_name
s_item_type
s_item_type
None
t_item_type
item_name
s_item_type
t_item_type
self.s.zipall
t
]
type
List
[
str
Optional
[
Type
]
]
Actually
none
items
least
s_item_type
t_item_type
None
items
=
OrderedDict
cast
List
[
str
Type
]
items_list
cast
comprehension
type-checked
alternative
item_list
good
old-fashioned
for-loop
declared
type
List
[
str
Type
]
assert
loop
body
item
None
kind
arbitrary
items
multiple
*
args
rvalues
values
specific
way
*
item
types
iterable
*
args
rvalues
same
next
other
single
iterable
item
next
other
generate
error
fall
conservative
approximation
such
types
current
behavior
unsafe
=
[
]
b
=
[
x
y
z
]
x1
x2
x3
x4
=
*
b
x2
+
Runtime
error
Update
comment
comma
colon
semicolon
mind
part
bit
confusing
callee
type
callee
type
optimization
update
docstring
clear
callee
type
correct
commented-out
code
same
pattern
redundancy
idea
list/set
full
names
typing.Callable
other
information
lower
case
version
import
Foo
part
check
final
iteration
suspicious
bit
comment
kind
situation
error
invalid
type
assignment
TODO
type
typing.Counter
[
str
]
item
type
comment
independently
assignments
abstract
property
little
magical
comment
base
classes
different
manner
other
expressions
exprtotype.py
AST
nodes
names
Maybe
TODO
item
low
priority
major
minor
benefits
add
comment
Add
comment
error
condition
such
code-generated
methods
vi_boolean
Might
same
avoid
noqa
TODO
default
parameter
TODO
Error
descriptions
whole
thing
sort
headers
comment
Equivalent
attribute
available
comment
code
readable
own
different
PR
comment
weird
parameter_list
list
earlier
implies
order
assumption
is_repeated_capability
=
False
more
correct
channels
list
strings
is_repeated_capability
=
True
potatoes
Product
NI-SCOPE
fault
consistency
spelling
names
drivers
ta
fact
class
nidmm.NIDMMWarning
forth
step
class
bunch
complexity
own
warning
classes
things
clients
advantage
client
per-driver
Warning
classes
reword
comment
clarity
simplicity
ViChar
[
]
ViString
ViConstString
ViRsrc
same
ViChar
True
FWIW
more
pythonic
'size
parameter
'mechanism
course
way
comment
accurate
Converters
ctype
object
surprised
encoding
parameter
unused
linter
machine
flake8
run-test
commands
]
|
flake8
config=./tox.ini
generated/
generated/nidigital/nidigital/unit_tests/test_nidigital.py:65:75
E261
least
spaces
inline
comment
self.side_effects_helper
[
'GetAttributeViBoolean
]
'value
]
=
False
history_ram_number_of_samples_is_finite
^
generated/nidigital/nidigital/unit_tests/test_nidigital.py:81:74
E261
least
spaces
inline
comment
self.side_effects_helper
[
'GetAttributeViBoolean
]
'value
]
=
True
history_ram_number_of_samples_is_finite
^
generated/nidigital/nidigital/unit_tests/test_nidigital.py:103:48
W292
newline
end
file
assert
len
history_ram_cycle_info
^
linter
anything
Issue
Added
tests
Override
C
names
valid
Python
names
mean
comment
noqa
F401
TODO
same
line
whine
nifgen
review
more
historical
snippet
source
control
odd
variable
name
Sure
_today_
obsolete
attributes
tomorrow
is_obsolete
True
flag
things
Python
API
firs
ship
attributes
obsolete
_first_
release
Python
API
name
configuration_converted
configuration
configuration_converted
configuration_ctype
NI-FGEN
multiple
write
waveform
create
waveform
methods
double
comment
comment
same
wording
NI-DCPower
addon.py
inaccurate
comment
Same
comment
support
function
simulation
mode
other
devices
DCPower
function
atomic
driver
function
Same
comment
above
session
parameter
old
version
file
least
comment
metadata
able
necessary
NI-SCOPE
modifies
renames
stops
example
comment
wrong
ok
most
comments
Several
several
code
C
example
way
*
array.array
numpy
Explain
optimization
fetch_into
buffers
reallocation
function
call
user
pass
channels
empty
string
user
pass
channels
ranges
such
0-4
user
channels
whitespace
such
ass
Seems
fail
unexpected
ways
channels
channels
session
Use
single
line
comments
need
nifgen
review
commit
messages
Git
comment
unecessary
comment
other
discarded
implementation
>
Python
print
comment
necessary
>
GitHub
>
URL
Fancy
Measure
waveform
data
device
onboard
memory
unused
string
Consider
temporary
variables
data
functions
parameter
list
parameter
Step
num
parameters
sort
copy/paste
error
need
comment
user
example
Arbitrary
Waveform
Mode
something
strengths
Script
Mode
single
script
mix
waveforms
different
number
times
arbitrary
waveform
generator
world
functions
something
device
signal
case
calculate
term
default
resource
something
PXI1Slot2
other
examples
code
underscores
applies
Comment
inaccurate
something
NI-FGEN
ViInt64
Please
formatting
way
following
*
convention
type
TODO
lnjaleea
string
*
issue
note
case
GitHub
issue
Read
>
safe
TODO
generator
waveforms
test
coverage
original
metadata
hack
separate
PR
Added
TODO
marcoskirsch
metadata
new
key
comment
line
Same
comment
array_size
]
Can
comment
session
False
test
exception
right
try
block
exception
test
try
block
useful
No
need
array_size
parameter
Same
comment
above
measurements
Checks
equality
point
numbers
brittle
[
StackOverflow
]
https
//stackoverflow.com/questions/5595425/what-is-the-best-way-to-compare-floats-for-almost-equality-in-python
link
possible
solution
typo
returns
F401
|
module
unused
tests
unfortunate
much
example
interesting
aspect
session.get_self_cal_last_date_and_time
several
values
great
suggestion
definite
hole
coverage
timeout
conversion
codegen
possible
issue
generator
limitation
reference
least
opportunity
reasoning
clear
actual_num_waveforms_ctype.value
*
actual_samples_per_waveform_ctype.value
get_site_results_site_numbers
method
enum
param
necessary
benefit
something
flake8
happy
TODO
test
TODO
optional
IMO
NISE
specific
IVI
context
bit
outdated
Suggestion
>
specific
session
APIs
'close
function
metadata
code-generated
private
method
Session
public
wrapper
documentation
public
wrapper
build
documentation
close
initiate
case
nice
nidigital
documentation
reason
documentation
add-on
functions
IVI
>
IVI
state
model
drivers
nimi-python
follow
important
aggregator
aggregation
data
aggregations
configurable
views
configurable
Nit
python
updated_labels
=
lk
lv
lk
lv
labels
set
view.label_keys
@
cnnradams
please
wrap
comments
chars
great
black
alas
good
configuration
variable
reference
argv
function
celery
instrumentation
package
much
benefit
special
case
real
life
fact
entire
tracing
pipeline
packages
sure
celery
instrumentation
right
choice
orthogonal
instrumentation
Users
celery
instrumentation
celery
process
other
instrumentation
packages
batch
span
exporter
celery
workers
Exception
suggestion
cases
FlaskInstrumentor.instrument_app
app
super
.tearDown
comment
valid
value
case
outside
parent
span
tests
span
functionality
suggestion
self.assertIs
spans
]
.parent
[
]
.get_context
self.assertIs
spans
]
.parent
[
]
.get_context
self.assertIs
spans
]
.parent
[
]
.get_context
self.assertIs
spans
]
.parent
[
]
.get_context
self.assertIs
spans
]
.parent
[
]
.get_context
nitpick
nice
rest
asserts
particular
span
e.g
spans
]
spans
]
few
lines
suggestion
self.assertIs
spans
]
.parent
[
]
.get_context
self.assertIs
spans
]
.parent
[
]
.get_context
good
time
message
cal
occurs
span
suggestion
checkpoint
update
suggestion
type
reason
type
alias
nit
carrier
key
argument
names
doc
string
asgi
scope
header
name
carrier
subclass
carrier
key
first
place
case
something
getter
arguments
logging
module
such
messages
OpenCensus
case
least
root
logger
dedicated
logger
module
link
@
reyang
https
//docs.python.org/3/howto/logging.html
logging-advanced-tutorial
=
logging.getLogger
__name__
comment
__init__
parameter
destination
keyword
argument
next
statement
docstring
accurate
DD
b3
specification
trace/span
id
auto-instrumentation
suggestion
Span
comment
span
multiple
codes
docs
attribute
docstrings
change
PR
branch
https
//github.com/hectorhdzg/opentelemetry-python/pull/1
comment
_func_path
code
_func_name
test
checking
warning
suggestion
self.assertIs
status.canonical_code
StatusCanonicalCode.OK
suggestion
self.assertIs
status.canonical_code
StatusCanonicalCode.OK
element
unique
PYTHONPATH
following
same
result
=
environ.get
PYTHONPATH
[
PYTHONPATH
]
=
filedir_path
+
pathsep.join
+
curios
case
test
comment
FastAPI
app
suggestion
Callback
fastapi
route
good
exception
uninstall
description
module
README
users
module-level
constants
otel
folks
blocking
operation
second
Might
worth
comment
state
traces
shutdown
🙂
async
case
parent
spans
child
spans
name
code
closer
usage
code
project_id
application
default
credentials
argument
suggestion
export
exact
same
labels
Fussy
comment
alert
Wikipedia
f
https
//en.wikipedia.org/wiki/Fibonacci_number
https
//github.com/open-telemetry/opentelemetry-python/pull/280
attempts
test
execution
test
cases
obvious
errors
self._cursor
course
convenient
hard
situation
separation
test
case
setup
test
case
execution
former
operations
test
case
latter
execution
test
case
latter
one
actual
test
result
part
testing
setup
execution
sense
test
case
setup
ready
Pyhton
unittest
package
example
python
unittest
import
TestCase
class
TestCase
TestCase
def
setUp
def
test_0
assert
True
test
session
==============================
platform
linux
Python
pytest-5.4.1
py-1.8.1
pluggy-0.13.1
rootdir
/home/ocelotl/sandbox/tast
item
test_unittest.py
F
[
%
]
===================================
FAILURES
===================================
_______________________________
TestCase.test_0
________________________________
=
<
test_unittest.TestCase
testMethod=test_0
>
def
setUp
E
ZeroDivisionError
division
zero
test_unittest.py:7
ZeroDivisionError
===========================
short
test
summary
info
============================
FAILED
test_unittest.py
:TestCase
:test_0
ZeroDivisionError
division
zero
===============================
*
failure
*
right
failure
something
wrong
code
test
code
test
case
Pytest
concept
*
error
*
results
example
python
pytest
import
fixture
@
fixture
def
the_fixture
def
test_0
the_fixture
assert
True
test
session
==============================
platform
linux
Python
pytest-5.4.1
py-1.8.1
pluggy-0.13.1
rootdir
/home/ocelotl/sandbox/tast
item
test_pytest.py
E
[
%
]
====================================
ERRORS
====================================
___________________________
ERROR
setup
test_0
___________________________
@
fixture
def
the_fixture
E
ZeroDivisionError
division
zero
test_pytest.py:6
ZeroDivisionError
===========================
short
test
summary
info
============================
ERROR
test_pytest.py
:test_0
ZeroDivisionError
division
zero
===============================
error
===============================
accurate
failure
error
something
wrong
test
concept
error
useful
teardown
test
cases
python
pytest
import
fixture
@
fixture
def
the_fixture
pytest
fixture
yield
setup
teardown
pass
setup
yield
teardown
def
test_0
the_fixture
assert
True
test
session
==============================
platform
linux
Python
pytest-5.4.1
py-1.8.1
pluggy-0.13.1
rootdir
/home/ocelotl/sandbox/tast
item
test_pytest.py
.E
[
%
]
====================================
ERRORS
====================================
_________________________
ERROR
teardown
test_0
__________________________
@
fixture
def
the_fixture
pytest
fixture
yield
setup
teardown
pass
setup
yield
/
teardown
E
ZeroDivisionError
division
zero
test_pytest.py:9
ZeroDivisionError
===========================
short
test
summary
info
============================
ERROR
test_pytest.py
:test_0
ZeroDivisionError
division
zero
==========================
error
==========================
accurate
test
reporting
test
case
code
test
Nevertheless
something
wrong
test
teardown
error
unittest.TestCase
style
test
case
limitation
style
test
case
kind
setup
external
component
rest
useless
ideal
course
able
fixtures
current
unittest.TestCase
test
cases
order
consistency
rest
test
cases
[
possible
]
https
//docs.pytest.org/en/latest/unittest.html
pytest-features-in-unittest-testcase-subclasses
following
pytest
features
different
design
philosophies
>
Fixtures
autouse
fixtures
autouse
fixtures
fixtures
complete
set
test
cases
solution
specific
situation
test
cases
set
rest
team
unsure
suggestions
Pytest
fixtures
non
unittest.TestCase
test
cases
bit
controversial
Thanks
sorry
long
post
comment
span
active
span
active
aside
use_span
afterwards
zeros
effect
int
conversions
no-ops
wrong
base=16
argument
specific
comments
versions
ages
MIDDLEWARE
separate
variable
same
more
cases
span
attributes
name
old
docstring
attrs
copy-pasted
details
GCP
detector
later
PR
mind
GCE
Metadata
Server
available
GCP
compute
services
GCE
service
different
data
structure
services
information
environment
variables
job
GCP
spec
Ah
use
case
different
=
True
try
case
GCP
instance
detector
above
except
failure
Resource
detection
case
GCP
instance
nothing
params
query
SQL
invalid
exception
bare
expectation
people
DatabaseApiTracer
connect
look
mysql
connector
integration
code
logic
people
worth
types
requirement
supports
python3.4+
problem
Are
fields
right
values
process_start
Curious
double
quote
single
quote
literal
strings
exception
Span.SetStatus
anything
event
exception
user
user
exception
higher
level
event
TODO
good
separate
PR
suggestion
combine
resource
labels
span
attributes
span
particular
reason
issue
Nit
suggestion
read
response
reason
library
version
Please
comment
https
//github.com/open-telemetry/opentelemetry-python/pull/95/files
diff-27dca41b0ed750373d4340152e76a2d2R84
line
loader.py
name
Nit
comment
tracer_provider
call
set_tracer_provider
https
//docs.python.org/3/library/runpy.html
execl
nice
Windows
Note
PYTHONPATH
setup
interpreter
instance
logging.disable
calls
unnecessary
logging
python
import
disable
WARNING
NOTSET
tearDown
disable
WARNING
PymysqlInstrumentor
.uninstrument
disable
NOTSET
suggestion
test
pass
list
processors
constructor
kind
tests
suggestion
Returns
token
detach
context.
suceeded
failed
exception
other
way
span
ed
list
index
Please
new
key
bounded
dict
old
elements
new
ones
Same
BoundedList
assertion
base
BoundedList
vice
suggestion
item
TestBoundedList.base
keys
iterator
len
tuple
bdict
bdict
Same
BoundedList
enumerate
suggestion
Do
url
suggestion
url
suggestion
def
disable_tracing_url
url
excluded_paths
Disable
excluded
paths
url
path
excluded
path
return
True
type
excluded_paths
list
param
excluded_paths
Paths
rtype
bool
returns
False
suggestion
def
disable_tracing_hostname
url
excluded_hostnames
Disable
excluded
URLs
type
excluded_hostnames
list
param
excluded_hostnames
hostnames
rtype
bool
returns
False
return
url
excluded_hostnames
nice
function
list
dict
key-value
peers
correlation
context
many
temporal
contexts
next
iteration
loop
Same
test
relying
original_tracer_provider
span
clear
test
AttributeError
autospec=True
pylint
disable
place
check
next
lines
docs
http
//pylint.pycqa.org/en/latest/user_guide/message-control.html
kwargs
reasonable
args
WDYT
Argument
names
expression
Default
ignored-argument-names=_
|^ignored_|^unused_|^kwargs|^args|^mock_.+
elif
s
rest
suggestion
headers
None
Plan
Will
suggestion
instrumentor
elasticsearch
TODO
PR
example
SDK
initialization/setup
experience
Ideally
http_requests
extension
single
line
setup
function
similar
fashion
//docs.python.org/3/library/logging.html
logging.basicConfig
nit
suggestion
try
result
=
await
*
args
*
*
kwargs
Exception
exc
pylint
disable=W0703
exception
=
exc
raise
exception
None
span.set_status
Status
_exception_to_canonical_code
exception
span.set_status
Status
StatusCanonicalCode.OK
something
different
approach
Implicit
python
tracer.span
name
do_work
Explicit
span
=
tracer.span
name
span.begin
do_work
span
class
__enter__
__exit__
__aenter__
__aexit__
conversations
Tracestate
time
won
https
//github.com/census-instrumentation/opencensus-java/pull/1300
time
people
times
typo
wrong
choice
team
great
counter-intuitive
active
span
presence
parent
root
span
parent
libraries
application
explicit
propagation
library
implicit
context
propagation
suggestion
context
manager
span
creation
stateful
example
different
non-stateful
ways
other
state
goal
stateful
non-stateful
batchers
examples
earlier
worth
lock-free
algorithm
checkpoint
lock-free
algorithms
easy
wrong
worse
performance
suggestion
checkpoints
updates
single
collection
period
comment
merge
design
concern
batcher
methods
things
checkpoints
collection
general
meter
collect
operations
general
meter
top
batcher
ABC
interfaces
few
advantages
unimplemented
APIs
startup
unit
tests
live
application
tries
function
first
time
suggestion
Test
instrument
suggestion
Test
uninstrument
bad
@
ocelotl
OTEP
https
//github.com/open-telemetry/opentelemetry-specification/issues/819
[
metrics
API
]
https
//github.com/open-telemetry/opentelemetry-specification/blob/master/specification/metrics/api.md
valueobserver
similarity/confusion
UpDownSumObserver
example
queue
size
>
Therefore
choice
ValueObserver
UpDownSumObserver
recommendation
instrument
more-appropriate
default
aggregation
queue
size
group
machines
only
thing
aggregate
queue
size
use
SumObserver
sum
distribution
queue
size
group
machines
interested
distribution
queue
sizes
machines
use
ValueObserver
tracking/discussion
spec
issue
https
//github.com/open-telemetry/opentelemetry-specification/issues/818
issuecomment-681149833
Unless
wrong
self.active_span
explicit
parent
check
correct
i.e
python
tracer.start_active_span
span
block
*
OTel
Span
related
SpanWrapper
able
pieces
way
note
good
idea
users
span_cm.__exit__
earlier
comment
review
active
else
self._span
case
property
[
no-ops
TestCase
]
https
//github.com/python/cpython/blob/fd628cf5adaeee73eab579393cdff71c8f70cdf2/Lib/unittest/case.py
L488-L494
import
retry
logic
retries
lot
times
name
iter_entry_points
https
//setuptools.readthedocs.io/en/latest/pkg_resources.html
convenience-api
_CONTEXT
=
iter_entry_points
opentelemetry_context
OPENTELEMETRY_CONTEXT
default_context
map
qualifies
error
exception
current
context
global
variable
context-local
variable
least
thread
local
variable
context
inside
current
Context
context
manager
Nit
wrap
docstrings
Just
bit
context
word
sooo
stuck_out_tongue
current
Context
implementation
immutable
sense
new
current
item
new
value
square
bracket
operator
[
]
future
order
PR
immutable
update
methods
such
curiosity
enough
context
methods
form
context
context
=
get_current
return
some_action
context
some_action
context
get_current
other
implementation
RuntimeContext
return
None
only
place
different
context
module
set_current
Context
sense
logic
handle
single
place
private
API
suggestion
label
observer
self._system_memory_labels
=
*
*
self._labels
self._system_cpu_labels
*
*
self._labels
self._network_bytes_labels
*
*
self._labels
self._runtime_memory_labels
*
*
self._labels
self._runtime_gc_labels
*
*
self._labels
Nit
blank
line
Args
documentation
updated
set_preferred_meter_implementation
meter_factory
actual
meter
https
//github.com/open-telemetry/opentelemetry-python/blob/master/examples/metrics/record.py
L27
correct
unit
requests
comment
]
https
//github.com/open-telemetry/opentelemetry-python/pull/341
discussion_r376758482
warning
case
warning
unsupported
metrics
type
pass
len
labels
Nit
evident
code
comment
helpful
placeholder
default
Tracer.CURRENT_SPAN
suggestion
Labels
key-values
specific
suggestion
metrics
batch
labels
sequence
suggestion
labels
conditional
self.status
OK
default
None
possible
status
user
case
auto-update-status
mechanism
]
https
//github.com/open-telemetry/opentelemetry-python/issues/292
issuecomment-554484563
specific
request
status
status
OK
user
status
case
OK
status
user
best
understanding
status
[
response
code
]
https
//developers.google.com/maps-booking/reference/grpc-api/status_codes
opinion
response
beginning
span
life
Please
share
opinions
particular
approach
self.status
=
None
default
mypy
error
lines
error
Property
trace_state
SpanContext
read-only
https
//github.com/open-telemetry/opentelemetry-python/runs/1130417833
check_suite_focus=true
tests
useful
attribute
SpanContext
immutable
way
restrictions
test
file
tests
unnecessary
Thank
many
levels
nesting/indentation
use
case
contextlib.ExitStack
ctx
managers
new
run
application
step
new
submission
original
run
<
img
width=
alt=
Screen
Shot
2020-11-16
PM
src=
https
//user-images.githubusercontent.com/187676/99297688-963e7800-2816-11eb-8dba-849c151a9364.png
>
application
status
'AWAITING_PAYMENT
UI
new
Video
interview
<
img
width=
alt=
Screen
Shot
2020-11-16
PM
src=
https
//user-images.githubusercontent.com/187676/99297785-b8d09100-2816-11eb-8fef-824238c04b6a.png
>
reason
twice
configuration
Sentry
docs
reason
places
docs
https
way
Sentry
client
Celery
app
other
way
much
clearer
pylint
error
[
pylint
]
bootcamp/celery.py
____________________________________________________________________________________________
E
attribute
celery.app.base
line
hides
method
method-hidden
same
skip
step
Could
pytestmark
=
pytest.mark.django_db
tests
parameter
test
way
context
variable
serializer
application
body
method
conditional
value
context
variable
true
bool
statement
false
actual
query
filter
FULFILLED
useful
comment
comments
timeout
=
timestr_to_secs
timeout
timeout
reflection
little
prototyping
fine
python
javax.tools
import
DocumentationTool
ToolProvider
file_manager
=
DocumentationTool.getStandardFileManager
ToolProvider.getSystemDocumentationTool
None
Locale.US
StandardCharsets.UTF_8
comment
least
verbose
interested
platform.java_ver
value
docs
Checking
name
contain
default
value
loop
default
value
loop
getters
value
Use
name
[
-1
]
%
.strip
latter
strips
%
characters
ends
is_set
something
similar
good
idea
dataset
different
platforms
32-bit
vs
64-bit
intention
integer
platform
agnostic
manner
following
suggestion
model_data
var
]
.dtype.kind
i
numpy.dtype
docs
]
https
//numpy.org/doc/1.18/reference/generated/numpy.dtype.kind.html
numpy.dtype.kind
astype
float
larger
context
second
comment
po
unused
'calliope.core.attrdict.AttrDict
unused
'xarray
xr
unused
'xarray
xr
unused
is_valid
check
line
clear
separation
valid
invalid
easier
reason
separate
-clause
validity
check
is_valid
..
invalid
..
cost_con
loc_tech_is_in
..
loc_tech_is_in
..
comment
right
rest
loop
rest
loop
cost
class
mutable
data
structures
argument
defaults
function
definition
time
function
reuse
instance
data
structure
changes
many
blank
lines
lambda
expression
def
@
FLomb
attention
continuation
line
over-indented
indent
run
due
MIPGap
condition
returns
feasible
optimal
above
comment
attrs
model
_model_run
worth
C0301
line-too-long
]
Line
please
debug
comments
commented
line
something
wrong
prediction
CharacterRecognitionPrediction
class
object
d
variable
assignment
ignore
pylint
positive
suggestion
pspec
=
np.absolute
np.fft.rfft
frames
self.fftbase
pylint
disable=W9904
comment
bit
answers
old
family
tree
afterwards
new
separate
_info
module
inspect-only
option
part
state-changing
module
/
action
plugin
Examples
new
modules
FQCNs
Fully
Qualified
Collection
Names
suggestion
community.general.iptables_state
useful
plugin
transform
situation
transform
FQCNs
examples
suggestion
secret
lookup
suggestion
U
https
//updates.thycotic.net/secretserver/restapiguide/TokenAuth/
operation
secrets
id
>
suggestion
False
suggestion
Copyright
Andrew
Klaus
<
@
gmail.com
>
loop
Ansible
care
environment
variables
documentation
get_option
etcd
lookup
suggestion
etcd3
connection
parameters
class
password
log
suggestion
suggestion
endpoints
fact
default
Ansible
playbook/play_context.py
become_exe
become
method
name
*
option
defaults
See
ansible/ansible
suggestion
Output
color
on_any_msg
Template
L
valid
color
value
notes
same
other
descriptions
short
GPL
header
i.e
https
//github.com/ansible-collections/community.general/blob/main/plugins/filter/time.py
L3
short
one
new
stuff
headers
time
short
one
new
filter
suggestion
required_if
care
module
state=present
user
member
group
better
general
Please
group_exists
True
sense
non-existing
users
state=absent
suggestion
state
'absent
module.exit_json
changed=False
result=
user
%
s
part
group
%
gitlab_user
module.fail_json
msg=
user
%
s
%
gitlab_user
user
name
group
name
Same
next
ones
suggestion
RETURN
=
r
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
return-block
Same
Looks
good
lines
check
required_if
suggestion
EXAMPLES
=
r
specific
JWT
implementation
GCP
JWT
Ansible
plugin
GCP
such
documentation
JWT
auth
clear
GCP
auth
method
continued
compatibility
other
JWT
applications
HVAC
generic
JWT/OIDC
paths
error
HVAC
version
other
auth
methods
comment
https
//github.com/ansible-collections/community.general/pull/154
issuecomment-719729868
suggestion
Copyright
c
Pavlo
Bashynskyi
@
levonet
@
mail.com
>
day
ansible
stuff
huge
number
users
necessary
suggestion
i
felixfontein
questions/suggestions
above
i
docs
available
upgrade
reset
world
dependencies
change
logic
replacing
downgrading
packages
package
available
repository.
part
important
value
self.delay
delay_sec
self.delay
second
time
function
everything
self._play_context.check_mode
True
shutdown_result
=
self._low_level_execute_command
shutdown_command_exec
sudoable=self.DEFAULT_SUDOABLE
previous
function
way
mode
realistic
suggestion
Copyright
c
Ansible
Project
action
module
*
*
*
module
action
plugin
symlink
plugins/action/
file
module
file
plugins/modules/system/
documentation
suggestion
Example
credentials
workload
instances
stack
suggestion
plugin
community.general.stackpath_compute
suggestion
name
Return
entries
'groups
organizational
unit
community.general.ldap_search
suggestion
name
Return
GIDs
groups
option
good
idea
Next
line
documentation
force
entry
description
[
'Not
module.
]
option
description
suggestion
module.params
]
iscoroutinefunction
iscoroutine
checks
object
coroutine
object
suggestion
topic
=
_
Re
ticket
guild.name
side
side
other
instance
other
form
legible
suggestion
member_snowflakes
ctx.author._roles
DEP-WARN
Same
comment
get_locale
method
more
thought
logical
resolution
order
guild
regional
format
use
guild
regional
format
None
use
guild
locale
None
use
global
regional
format
None
use
global
locale
sense
sure
worse
current
resolution
order
use
guild
regional
format
None
use
global
regional
format
None
use
guild
locale
None
use
global
locale
//
Edit
Hmm
more
rewriting
sure
worth
outdated
comment
walk_commands
aliases
exists
other
purposes
cogs
bot
method
discord.py
suggestion
command
cog.__cog_commands__
pass_context=True
necessary
no_pm=True
@
new
line
Sorry
@
everyone
role
line
results
incorrect
results
suggestion
name=_
Roles
roles
_
Role
suggestion
later
date
things
extra
formatter
small
typo
comment
link
return
False
suggestion
day
more
data
Same
above
declaration
clause
Please
comment
workaround
Maybe
comment
method
name
code
better
one
method
object
import.json.mapping
suggestion
useless
long
suggestion
partner.contact_type
==
partner.active
NOTE
_render_
*
functions
None
line
filters
out.
case
actual
mapping
json
schema
types
types
supported
backends
way
BasicDatasetProfilerBase
contains
sets
type
names
best
bet
example
type_
==
'integer
type_expectation
BasicDatasetProfilerBase.INT_TYPE_NAMES
Ditto
above
suggestion
validator
=
jsonschema.validators.validator_for
schema
validator.check_schema
schema
TODO
validate_schema
available
json_schema
dependency
core
GE
TODO
>
NOTE
Add
test
site
Add
link
feature
description
features/data_documentation.html
confusion
part
Both
TODOs
separate
real
send_usage_message
calls
careful
events
comment
roundabout
way
known
subclass
implementations
out
chance
good
compare-and-contrast
*
https
//github.com/EarnestResearch/great_expectations/pull/114
*
https
//github.com/EarnestResearch/great_expectations/pull/9
@
spbail
suggestions
note
please
Better
docs
feature
bump
👍
previous
Credit
Transfer
blockchain_status=UNSTARTED
transfer_status=REJECTED
only
first
range
problematic
multiple
blocks
initial
PENDING
status
concurrency
filters
block
ranges
calls
possible
multiple
identical
blocks
local
config
something
dev
nah
purpose
i
sure
i
delete
i
clean
thoughts
g.active_organisation.id
big
deal
results
cleaner
key
Please
TODO
http
errors
comment
next
line
commit
tmpfile
alternative
separate
interpreter
one-line
Pylint
warning
reason
think
text
Please
block
check
lines
logs
logs
opinion
readable
assert
line
log
assert
line
log
line
log
console_out_log
config
Old
artifact
string
project
check
able
test
code
POSIX
locale
en_US
counterintuitive
test
correct
provide
explanations
source
code
comments
Submitter
lines
explanation
Please
comment
order
assert
comment
unsuccessful
execution
important
part
*
*
*
operations
fact
mention
operations
first
comment
execution
important
link
launcher-output
ok
docstrings
way
generated
documentation
path
user-defined
variables
description
documentation
nice
little
understandable
thing
spaces
_arguments_
same
changes
actual
documentation
paragraph
description
same
PR
users
class
documentation
approach
configs
users
class
change
changes
better
dictionary
option
Variations
dictionary
class
variants
fields
way
Union
[
str
List
[
]
]
command
attribute
ProjectConfiguration
value
sure
anything
details
madrid_air_quality.py
script
pretty
evident
urllib2.
imports
removal
lines
lines
import
contextlib
move
top
file
try
contextlib.closing
urllib.urlopen
f
return
f.read
json
data
e
print
%
s
%
s
%
source
e
None
Done
pylint
disable
other
methods
Inside
access
policies
sub
resources
e.g
service_perimeter
access_level
access_policies
sure
Example
access
policy
dump
file
name
//cloudresourcemanager.googleapis.com/organizations/660570133860
asset_type
cloudresourcemanager.googleapis.com/Organization
access_policy
name
accessPolicies/1008882730433
parent
organizations/660570133860
title
default
policy
ancestors
organizations/660570133860
]
name
//cloudresourcemanager.googleapis.com/organizations/660570133860
asset_type
cloudresourcemanager.googleapis.com/Organization
service_perimeter
name
accessPolicies/1008882730433/servicePerimeters/Test_Service_Parameter
title
Test
Service
Parameter
status
resources
projects/179891054368
]
access_levels
accessPolicies/1008882730433/accessLevels/abcb
]
restricted_services
container.googleapis.com
]
ancestors
organizations/660570133860
]
name
//cloudresourcemanager.googleapis.com/organizations/660570133860
asset_type
cloudresourcemanager.googleapis.com/Organization
access_level
name
accessPolicies/1008882730433/accessLevels/abcb
title
abcb
basic
conditions
ip_subnetworks
]
regions
US
]
]
ancestors
organizations/660570133860
]
name
//cloudresourcemanager.googleapis.com/organizations/660570133860
asset_type
cloudresourcemanager.googleapis.com/Organization
access_level
name
accessPolicies/1008882730433/accessLevels/Ebil
title
Ebil
basic
conditions
device_policy
require_screenlock
true
]
]
ancestors
organizations/660570133860
]
comment
changes
please
comment
[
]
same
other
methods
//forsetisecurity.org/docs/latest/setup/install.html
Great
comment
worth
todo
other
comment
CAI
resource
ancestory
/
full
name
metadata
function
excluded
resources
CAI
exclusions
API
call
exclusions
right
way
status
code
access
status
e.resp.status
==
test
case
let
comment
docstring
function
None
Thanks
special
check
CommandError
case
same
ProtocolUtil
ExtHandler
thread
internal
call
issues
same
object
better
direction
towards
extra
ProtocolUtil
objects
different
places
protocol
main
loop
Same
comment
add_event
Thanks
comments
clarity
redundant
mock
worried
scope
mock
other
code
branches
os.path.exists
unrelated
file
patch
cause
issues
inner
function
special
cases
exact
file
rest
original
function
Unnecessary
return
Groups
code
Delete
code
Same
comment
logger
checking
correct
error
messages
log
Same
comment
architected
interface
correct
behavior
zip
next
run
let
name
IID
manifest
other
commands
IID
log
collection
commands
useful
purposes
comment
code
AGENT_LOG
module
agent
logger
waagent.log
standalone
module
results
file
zip
case
unsuccessful
log
collection
value
archive
i
sure
anything
little
overhead
extra
code
archive
entire
archive
single
collection
call
many
same
files
files
disk
last
collection
call
new
files
update
files
TODO
need
.zip
files
history
folder
zip
files
conversion
other
comment
hard-coded
v1
support
next
iteration
comments
file
name
archive
name
i
obvious
code
Updating
easier
copy-paste
command
line
function
i
'.xz
careful
dependencies
other
modules
agent
agent
several
globals
example
point
dependency
function
logger
output
agent
log
Telemetry
global
current
dependencies
safe
rid
dependency
fileutil
functions
much
note
comment
people
code
undesired
dependencies
anything
ll
copy
command
smile
+1
Removing
archive
internal
implementation
detail
test
terms
zip
let
comment
different
direct_funcs
report
failure
None
False
resourcegone/invalidcontainer
NIT
pylint
error
explicit
VALID_EXTENSION_STATUS
*
explicit
private
wont
block
None
Popen.returncode
child
return
code
poll
communicate
None
value
process
hasn
’
t
first_proc.returncode
command
first
doesnt
right
comments
test
case
e.g
first
result
new
test
settings
case
extension
status
file
let
comment
test
better
descriptive
test
name
test_wait_for_handler_successful_completion_returns_false_when_there_is_no_status_file
Same
comment
right
dependency
much
everything
breaks
more
context
reply
follow
previous
comment
worth
status
successful
many
times
second_ext.status_blobs
ExtensionEmulator
class
self.actions
dict
actions
Actions
class
functions
old
objects
Mocks
python
self.actions
ExtensionCommandNames.INSTALL
install_action
ExtensionCommandNames.UNINSTALL
uninstall_action
ExtensionCommandNames.UPDATE
update_action
ExtensionCommandNames.ENABLE
enable_action
ExtensionCommandNames.DISABLE
disable_action
class
Actions
object
collection
static
methods
basic
functionality
ExtensionEmulator
class
actions.
@
def
succeed_action
*
args
*
*
kwargs
A
nop
action
correct
function
signature
ExtensionEmulator
patched_popen
Action
emulator
arguments
next
emulator.actions
ExtensionCommandNames
command_name
]
emulator
emulators
emulator.matches
ext_name
ext_version
cmd
*
args
*
*
kwargs
main
question
line
mock
something
python
_
=
second_ext.actions
ExtensionCommandNames.UPDATE
]
.call_args
NUMBER_OF_DOWNLOAD_RETRIES
arbitrary
number
comment
WireClient
goal
state
XML
files
disk
mock
test
data
XML
files
irrelevant
something
Basic
test
get_ext_conf
verifies
correct
data
data
test
data
mock_wire_protocol
similar
try
host
=
self.get_host_plugin
host.put_vm_status
self.status_blob
ext_conf.status_upload_blob
ext_conf.status_upload_blob_type
return
except
ResourceGoneError
e
direct
force
goal
state
update
wait
self.update_goal_state
forced=True
Exception
e
other
errors
pass
getprocstat
thanks
systemd
fallback
code
something
matter
systemd
timeout
systemd
execution
failure
exit
non-0
exception
same
way
case
particular
reason
tests
method
get_file
comment
code
read_file
get_file_contents
better
method
get_parameter
comments
Seems
useful
own
future
PR
comments
example
comment
text
cpu
cpuacct
/user.slice
example
Please
parsing
object
code
easier
future
PR
comment
infinite
recursion
RuntimeError
asserts
little
comment
code
comment
sample
output
netstat
-rn
easier
reader
parsing
logic
common
schemas
tables
Kusto
GAExtensionEvents
GAGenericLogs
GAPerfMetrics
comment
tables
sure
tables
comment
offline
minor
comment
event_id
=
id
minor
suggestion
sys.executable
function
Python
mocks
reason
reason
Python
sure
Python
call_args
args
mock_report_event.call_args_list
]
assert
comment
NIT
missed
linter
comment
Please
comment
agent
support
EOL
STDOUT/STDERR
.communicate
more
time
e.strerror
others
ESRCH
Fixed
second
space
comment
@
narrieta
giant
PR
little
_adding_
Similar
comment
Correct
wrong
function
False
right
understanding
correct
docstring
specific
>
Possible
return
values
manifest
artifacts
*
*
True
*
*
None
reason
new
pylint
supressions
comment
caller
nit
match
indentation
code
limiters
Agent
events
more
relaxed
extensions
pipeline
limiters
agent
events
leftover
comment
line
comment
definitions
errno.EPIPE
extension
time
file
error
suggestion
TODO
turn
False
feedstock_ctx.attrs.get
'conda-forge.yml
.get
'bot
.get
False
correct
'feedstock
feedstock_name
everything
name
nervous
extra
quotes
string
double
quotes
jinja2
quotes
logic
ros2/ci
imo
logic
complex
like
self.documentation_type
DOC_TYPE_MAKE
DOC_TYPE_EXTERNAL
assert
worth
TODO
logic
space
level
Packages
Dashing
result
several
stanzas
Packages
buildfile
default
Packages
Packages
buildfile
ubv8
rendered
markdown
plaintext
harder
Please
use
single
quote
possible
message
trailing
space
Same
Nitpick
code
new
module
yes
year
package.xml
data
stage
package
issue
url
precise
PR
concerned
client-certificate-data
wrong
certificate
certificate
new
same
private
key
something
private_key
generate_one
private
key
certificate
Verify
certs
field
CN
Verify
certs
CA
public
key
x509.verify_signature
Verify
certs
x509.will_expire
Verifiy
private
key
certs
certificate
x509.verify_private_key
certs
public
key
something
wrong
certificate
None
salt
command
x509.get_signing_policy
CA
certificate
better
Wait
*
*
taints
node
shows
more
startup
states
IIUC
jobs
minion
module
executions
states
bunch
fun
state.sls
jid
pid
tgt
comments
log
messages
jobs
startup
state
sense
info
running
jobs
python
log.debug
Attempt
%
d/
%
d
]
Waiting
jobs
%
s
attempts
retry
'.join
minion
minion
jobs
minion=minion
jobs=
job
[
fun
]
job
[
pid
]
job=job
job
minion_jobs
minion
minion_jobs
running_jobs
log.debug
sure
kind
log
warrants
default
debt
issue
TODO
TODO
common
steps
conftest.py
first
place
whole
href
test
sense
full
config
*
*
Regex
reqpath
=
re.search
r'href=
[
\
]
P
<
reqpath
>
/oidc/\S+
]
auth_request
.group
'reqpath
warning
class
correct
syntax
class
DockerTag
pylint
disable=too-few-public-methods
A
class
docker
tag
command
API
client
wrong
Jordi
PR
Ditto
something
def
list_volumes
api_client
node_name
customObjectApi
=
kubernetes.client.CustomObjectsApi
api_client=api_client
NOTE
wary
API
errors
storage
classes
=
list_storage_classes
api_client
try
volume_list
=
customObjectApi.list_cluster_custom_object
group=
storage.metalk8s.scality.com
v1alpha1
volumes
ApiException
exc
return
[
'pillar_utils.errors_to_dict
]
dict
volume.metadata.name
volume
storage_classes
volume
volume_list
volume_info
helper
dict
Volume
object
dict
StorageClass
cache
performance
problem
someday
entity
move
project
parent
project
cache
big
concern
performance
issue
moment
safer
cache
comment
future
mention
dangers
tk-core
run_test.py
unit
test
tests/python
submodule
[
comment
]
https
//github.com/shotgunsoftware/tk-core/pull/469
pullrequestreview-42064764
correct
line
valid
other
places
get_path
self
script
arg_data
[
sys_path
]
comments
great
i
useful
concrete
example
[
sys_path
]
process
sys.path
see
comments
other
script
comment
code
maintainers
note
engine
older
core
etc
same
comment
markdown
helpful
i
comments
first
log_info
call
functions
use
markdown
suggestion
sys.path
sgtk
line
needs
self._index
=
idx
terms
naming
favor
'last
'index
Question
units
units
sequence
i.e
unit.000003
unit.000002
condition
idx
==
+
yep
lets
real
ret
=
Continuous.try_allocatio
cu
new
index
=
idx
return
ret
attempt
self._log.debug
unit
%
s
%
s
]
uid
self._last
return
False
question/suggestion
ease
understanding
code
assumption
sequence
uids
correct
interesting
spaces
above
=
config
[
resource
]
.get
'schema
'ssh
resource
configs
available
session
test
RP
changes
/
method
Windows
Same
comment
configs
suggestion
Shall
<
usalt
root
directory
>
/
<
case-id
>
/fastq/
suggestion
return
f
sample
_
flowcell
_L
lane
_
.fastq.gz
protected
members
utility
class
suggestion
same
Remove
comments
suggestion
correct
bit
vague
intention
THEN
clause
information
system
test
uncertain
correct
correct
test
implementation
business
rule
suggestion
GIVEN
database
female
sample
suggestion
THEN
application
date
comment
test
GIVEN
WHEN
THEN
descriptions
test
case
same
test
case
weird
code
work
move
fictures
fan
linter
arguments
e.g
del
kwargs
true
subprocess.run
stderr
process
suggestion
i
_
enumerate
process.stderr_lines
something
magic
number
name
variable
something
descriptive
pass
suggest
magic
number
suggest
checking
..
test
pass
setup-method
pip
install
..
suggestion
THEN
assert
MIP
analysis
uploaded
suggestion
store
MIP
analysis
suggestion
WHEN
analysis
pipeline
MIP
suggestion
WHEN
analyses
MIP
suggestion
WHEN
pipelines
MIP
suggestion
store
analysis
MIP
suggestion
THEN
analysis
object
completed_at
entry
suggestion
WHEN
analyses
ready
upload
MIP
suggestion
THEN
analysis
object
suggestion
GIVEN
case
analysis
helpers.add_analysis
store=sample_store
pipeline=
MIP
completed_at=None
suggestion
store
analysis
suggestion
store
analysis
missing_pipeline
suggestion
store
analysis
MIP
completed_at
entry
suggestion
WHEN
analyses
ready
upload
suggestion
WHEN
analysis
ready
upload
pipeline
suggestion
store
analysis
completed_at
date
suggestion
store
analysis
MIP
suggestion
THEN
analysis
object
MIP
suggestion
WHEN
analyses
ready
upload
analysed
MIP
THEN
statements
asserts
hard
test
explanation
branch
code
branch
merge
cleaner
fixtures
tests/apps/crunchy/conftest.py
suggest
word
correct
expected
stuff
fixtures
fixtures
@
pytest.fixture
def
bam_path
crunchy_test_dir
PATH
non
file
return
@
pytest.fixture
def
bam_file
bam_path
PATH
EXISTING
file
Create
file
path
return
fixtures
arguments
bam_dict
actual
fixture
suggestion
THEN
dry-print
NOT
bed_key
exception
None
something
log
output
fixture
suggestion
WHEN
case
variants
good
thing
stuff
bit
confused
point
type
hard
coded
values
conftest
relevant
purpose
function
test
dates
suggestion
THEN
object
suggestion
WHEN
error
case
adapter
tests
suggestion
Mock
success
returncode
success
failure
condition
way
comment
unnecessary
comment
helpful
error
No
need
superfluous
comment
obvious
suggestion
more
explicit
condition
suggestion
process.poll
suggestion
Test
command
sample
commented
code
suggestion
THEN
housekeeper
files
tags
version
suggestion
tilt
horizontal
PV
lingo
from_tmy
method
https
//pvlib-python.readthedocs.io/en/stable/generated/pvlib.location.Location.from_tmy.html
highlight=from_tmy
hourly
intervals
time
difference
time
step
sync
rainfall
rainfall
accumulation
time
interval
[
]
amount
first
timestamp
interval
length
t
rainfail.index
last
time
difference
value
[
i
equal
constant
*
t_i+1
t_i
equal
*
t_i
t_i-1
=
np.array
rainfall.index.values
/
datetimes
seconds
dt_sec
=
dt.diff
first
value
dt_sec
]
=
dt_sec
]
reasonable
assumption
interval
prior
first
value
equal
length
first
interval
inline
comment
default
value
]
Sect
suggestion
trig_term_gnd
=
sin_beta
+
sin_beta
/
cos
beta
noqa
E222
same
comment
re
ghi
line
W291
whitespace
suggestion
NOTE
requests.get
url
params=args
least
spaces
inline
comment
variable
names
confusing
desired
result
times
hours
HH99
e.g
2400-
>
exceptions
datetime
day
hour
leap
year
rationale
ok
better
top
module
easier
people
interested
descriptive
value
duplicates
series
[
]
dict
something
'ghi_0_flag
'temp_air_0_flag
-99.9
fill
values
non-existant
data
flag
values
regardless
data
value
data
values
NaN
DatetimeIndex
E226
whitespace
arithmetic
operator
E126
continuation
line
over-indented
indent
units
V
thermal
voltage
consistent
bypass
diode
v
v.clip
-bypass_voltage
[
Cliff
]
r427429840
*
*
negative
*
*
sign_
bypass_voltage
argument
combine_series
bypass_voltage=0.5
[
V
]
typical
diode
trigger
voltage
_aka_
[
forward
voltage
drop
_threshold_
voltage
]
https
//en.wikipedia.org/wiki/Diode
Forward_bias
clearer
substring/submodule
level
reverse
bias
important
substring
bypassed
entire
substring
near
Vmp
shaded
cell
substring
reverse
bias
part
cell
useful
shifts
shaded
cell
rest
substring
bump/jump
current
inflection
discontinuity
shaded
cells
drop
reverse
bias
current
_ie_
first
knee
IV
curve
usu
Vmp
voltage
shaded
cells
positive
negative
break
voltage
second
knee
starts
total
breakdown
voltage
shaded
cells
forward
bias
cells
less
negative
bypass
diode
trigger
voltage
-Vbypass
substring
voltage
lower
-Vbypass
code
little
long
verbose
int
sections
text
reader
tutorial
better
>
parallel
most
mono/poly-silicon
modules
substrings
series
substring
parallel
bypass
diode
lot
whitespace
plot
x
y
limits
space
python
axes
]
.set_ylim
[
]
Imax
A
]
enough
axes
]
.set_ylim
[
]
point
]
.set_xlim
[
]
Vmax
[
V
]
enough
cell_parameters
module
parameters
plot
bypass
diode
substring_voltage
=
np.clip
lower=bypass_diode_voltage
typical
value
module
bypass
diodes
unusual
module-level
IV
curve
correct
bypass
diodes
Cool
example
[
]
https
//numpy.org/doc/stable/reference/generated/numpy.divmod.html
floor-like
quotient
remainder
nrow_full_shade
partial_shade_fraction
=
np.divmod
shaded_fraction
partial_shade_fraction
nrow
*
partial_shade_fraction
fraction
transmitted
light
light
incident
angle
modifier
IAM
Marion
true
normal
incidence
%
internal
reflection
light
%
[
Fresnel
equation
normal
incidence
]
https
//en.wikipedia.org/wiki/Fresnel_equations
Normal_incidence
=
n2
/
n1
+
n2
[
Sandia
Array
Performance
model
]
https
//prod-ng.sandia.gov/techlib-noauth/access-control.cgi/2004/043535.pdf
IAM
f2
ratio
=
Isc
aoi=aoi
/
Isc
aoi=0
suggestion
Marion
diffuse
irradiance
modifiers
cases
standard
'sky
region
region
posterity
comment
trapezoid
rule
use
Riemann
sum
trapezoid
rule
faithful
Marion
paper
number
intervals
large
errors
1e-4
1e-5
honesty
call
reason
Bill
Reimann
trapezoid
access
MATLAB
R
less
intervals
speed
nanoseconds
painted
white
wink
😛
term1
+
term2
back-calculated
line
_EG_
cosaoi
=
term1
+
term2
aoi
=
arcos
cosaoi
L720
cosaoi_dAs
=
cosaoi
*
Bill
paper
gamma
term
azimuth
panels
cosaoi
=
term1
+
gamma_pvmodule_azimuth
sorry
previous
comments
forgive
redundant
@
adriesse
suggestion
args=
specs
preference
i_sc
v_oc
i_mp
v_mp
beta_voc
alpha_sc
pv_fct
arguments
params
i_sc
v_oc
i_mp
v_mp
beta_voc
alpha_sc
nested
tuple
tuple/array
function
function
fit_sdm_desoto
own
private
function
module
level
=
eV
units
eV
lines
comments
few
comments
example
great
Thanks
minor
suggestion
plots
share
x-axis
]
https
//matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html
python
fig
ax
plt.subplots
sharex=True
stack
plots
share
x
axis
ax1
ax2
=
ax
ax
[
]
ax1
[
]
ax2
minor
preference
hard
time
dates
x-axis
bit
crowded
vertical
nicer
call
blocker
fine
THANKS
y-label
graphs
little
smushed
readthedocs
same
ylabel
cases
suggestion
Generate
clearsky
data
Ineichen
model
default
suggestion
GHI
winter
POA
irradiance
higher
nice
example
novices
function
avoid
copy/paste
small
tiny
nit
tz
caps
TZ
=
times
pd.date_range
date
freq='10min
*
tz=TZ
reasoning
least
tz
kinda
same
scope
function
module
caps
better
option
pass
function
argument
possible
tz
arg
site_location
Thanks
Different
suggestion
GHI
data
py
meth
pvlib.irradiance.get_total_irradiance
function
suggestion
example
py
meth
pvlib.location.Location.get_clearsky
method
clearsky
suggestion
solar_zenith=solar_position
[
'apparent_zenith
]
FYI
someone
apparent
solar
position
appropriate
change
get_clearsky
returns
dataframe
values
GHI
DNI
DHI
IMO
clearsky
clearsky_irrad
clearsky
=
site_location.get_clearsky
times
dni
=
clearsky
[
'dni
]
ghi
=
clearsky
[
'ghi
]
dhi
=
clearsky
[
'dhi
]
comment
work
correct
English
>
Zenith
angle
nonzero
DNI
values
NaN
doc
string
comparison
greater
greater
equal
same
calculation
readable
max_dni
=
clearsky_dni
*
clearsky_tolerance
same
comparison
type
function
need
reference
able
hack
len
freq
hack
to_offset
example
python
pandas.tseries.frequencies
index
=
pd.date_range
start=
2019-1-1
2019-1-1
=
to_offset
pd.infer_freq
index
hr_norm
=
/
pd.Timedelta
'1h
pandas
versions
voltage
division
zero
power
night
time
value
errors
suggestion
https
//github.com/pvlib/pvlib-python/issues/837
suppress_warnings
'ref.footnote
]
case
external
functions
%
timeit
datetime.datetime
huge
deal
case
more
principle
line
pvlib.solarposition.calc_time
previous
good
practice
minimum
amount
code
block
pandas
dt
lookup
block
python
try
pandas
type
vals
clearsky_index.values.flatten
AttributeError
numpy
type
vals
clearsky_index.flatten
dt
None
raise
ValueError
numpy
type
inputs
pandas
type
dt
try
time
series
type
index
dt
=
clearsky_index.index
clearsky_index.index
]
except
AttributeError
numeric
index
dt
=
clearsky_index.index
clearsky_index.index
]
min_tmscale
mindt
minimum
time
time
step
Similar
preference
max_tmscale
maxdt
def
test_latlon_to_xy_single
coordinates
expect_xpos
expect_ypos
Must
test
central
value
latlon_to_dist
mean
coord
=
]
sure
indexing
.T
]
pos
=
scaling.latlon_to_xy
coord
assert_almost_equal
pos
expect_xpos
]
[
]
decimal=1
def
test_latlon_to_xy_list
coordinates
positions
pos
=
scaling.latlon_to_xy
coordinates.tolist
assert_almost_equal
pos
positions
decimal=1
@
pytest.fixture
def
positions
return
np.array
[
pt
pt
zip
expect_xpos
expect_ypos
]
section
fixture
future
PR
@
pytest.fixture
def
coordinates
lat
=
np.array
lon
=
np.array
=
np.array
[
lati
loni
lati
loni
zip
lat
lon
]
return
positions
fixture
below
use
indexing
single
coordinate
function
comment
github
issue
loop
guaranteed
clear
line
Redundant
len
v
loop
define
numpoints
v
line
loop
better
use
try
IndexError
best
python
try
coef
=
np.polyfit
v
[
idx
]
i
[
idx
]
deg=1
]
intercept
term
beta0
=
coef
]
.item
sign
change
slope
positive
parameter
value
beta1
=
-coef
]
.item
break
else
idx
except
IndexError
e
raise
RuntimeError
fit
try
Exception
e
e
blocks
purpose
Briefly
acceptable
elements
task
hand
greek
pattern
beta_voc
I0_vmp
I0_voc
while
blocks
private
function
readability
Calculate
indices
>
ilim
*
i_sc
eg
i_nonlin
=
y
>
ilim
*
i_sc
use
x
[
i_nonlin
]
case
other
parameters
states
NaN
parameter
fitting
successful
line
%
/degC
behavior
python
]
times
pd.DatetimeIndex
start='20180101
end='20190101
freq='1s
]
timezone
=
times.tz.utcoffset
times
.total_seconds
/
[
]
timezone
Out
[
]
-7.466666666666667
surprised
-7
times
vector
result
time
DST
preferable
python
]
np.array
None
.astype
int
times.astype
int
/
]
array
[
-7.
-7.
-7.
-7.
-7
]
np.array
wrapper
known
type
version-dependent
Index/array
type
E126
continuation
line
over-indented
indent
E265
block
comment
s
asserts
context
blocks
@
adriesse
ADR
inverter
model
definition
parameter
Vdcmax
definition
function
docstring
trouble
Vdcmax
Vmax
maximum
DC
input
voltage
Vdcmax
alternate
upper
bound
DC
voltage
Same
'pvwatts
Indent
TODO
comments
fine
docstrings
old
comment
add
reference
comment
such
GH
issue
future
code
readers
more
context
long
line
python
HEADERS
=
UTC_DATE
UTC_TIME
LST_DATE
LST_TIME
CRX_VN
LONGITUDE
LATITUDE
AIR_TEMPERATURE
PRECIPITATION
SOLAR_RADIATION
SR_FLAG
SURFACE_TEMPERATURE
ST_TYPE
ST_FLAG
RELATIVE_HUMIDITY
RH_FLAG
SOIL_MOISTURE_5
SOIL_TEMPERATURE_5
WETNESS
WET_FLAG
WIND_1_5
WIND_FLAG
noqa
E501
nit
comprehension
DTYPES
=
[
np.dtype
t
t
necessary
addition
multiplication
readability
[
'int64
]
+
[
'float64
]
+
[
'int64
'float64
O
'int64
'float64
'int64
'float64
'float64
'int64
'int64
'float64
]
white_check_mark
suggestion
De
Soto
model
[
DeSoto
]
_
electrical
parameters
IV
curve
certain
irradiance
suggestion
References
..
]
W.
De
Soto
al.
Improvement
validation
model
photovoltaic
array
performance
Solar
Energy
vol
pp
numpy
warnings
function
np.errstate
masks
proponent
np.errstate
more
places
library
particular
reason
*
args
*
*
kwargs
associated
comment
*
*
kwargs
minor
nit
comment
arguments
test
decorator
comment
necessary
typo
right
self.name
contains
self.value
worth
docstring
entries
typo
asame
same
handy
examples
fields
processing
unit
tests
bootstrap
code
focus
navigator
objects
ancestors
certain
point
comment
clarification
roles
parent
ancestors
super
helpful
comment
roles
dialog
list
list
item
braille
desktop
object
last
point
confused
much
trouble
regions
positions
braille
return
namedtuple
tests
readable
e.g
self.regionsWithPositions
]
.end
little
name
LwrWord
Lines
words
Result
Word
nice
caller
direction
resize
offsets
resultCoordConverter
comment
ms
useEvents_maxTimeoutMs
comment
exe
files
Many
lines
end
copy
paste
mistake
URL
translator
comment
strings
nice
URL
>
RuntimeError
other
comment
bit
weird
NVDA
restart
multiple
times
something
NVDA
add-ons
enabled
/
state
add-ons
Changes
effect
NVDA
clarity
comments
suggestion
elif
addon.isPendingEnable
install
addon.isPendingInstall
addons
restart
globalVars.appArgs.disableAddons
checkable
list
keyboard
list
example
good
easier
new
line
utterances
clear
suggestion
\n
.join
[
list
item
b
]
following
lines
output
Copy
d
\Development\NVDA\source
repo\include\py2exe\win32wnet.pyd
D
\Development\NVDA\source
repo\dist\win32wnet.pyd
Copy
d
\Development\NVDA\source
repo\include\py2exe\_winxptheme.pyd
D
\Development\NVDA\source
repo\dist\_winxptheme.pyd
Copy
ExtensionDLL
d
\Development\NVDA\source
repo\include\py2exe\pywintypes37.dll
D
\Development\NVDA\source
repo\dist\
files
pywin32
following
files
library.zip
*
win32wnet.pyc
*
winxptheme.pyc
*
_winxptheme.pyc
typo
tetermines
suggestion
length
characters
text
window
something
explanation
right
value
numChars
half
number
bytes
wide
character
string
impossible
null
character
null
bytes
mid-point
wide
character
string
ANSI
string
MUST
least
null
character
numChars+1
end
string
odd
number
chars
wide
character
strings
byte
character
byte
next
worth
point
relies
memory
VirtualAllocEx
function
numChars
copy
logical
hi
buffer
string
buffer
garbage
string
hi
wide
memory
garbage
bW
=
bW
numChars
==
bW
[
numChars+1
]
==
i
unicode
ANSI
memory
hi
garbage
bA
hi0garbage
ok
bW
numChars
==
bW
[
numChars+1
]
==
g
unicode
broader
issue
odd
numbers
characters
wide
string
numChars
buf
=
b
\x00\x04\x41\x00\x00\x01\x00\x00
ЀAĀ
null
chars
buf
[
numChars
False
buf
[
numChars+1
False
buf
ANSI
something
window
unicode
text
range
multi
byte
characters
self.obj.isWindowUnicode
VirtualAllocEx
memory
ANSI
string
null
bytes
first
numchars
wide
character
strings
number
bytes
number
characters
numchars
points
mid-string
non-zero
bytes
c
buf
numChars
bufLen
]
text=ctypes.cast
buf
ctypes.c_wchar_p
.value
encoding=locale.getlocale
]
worth
single
char
buf
=
b
\x41\x00\x00\x00
=
A
null
chars
valid
wide
string
ANSI
=
b
\x00\x45\x00\x00
enough
cases
worth
unit
test
perf
considerations
byte
alignment
bytes
wCharAlignedIndex
=
numChars+
numChars
%
buf
[
wCharAlignedIndex
]
[
wCharAlignedIndex
]
==
several
characters
different
ways
clearer
constants
various
combinations
test
facePalm
=
u
\U0001f926
🤦
smile
=
u
U0001f60a
😊
thumbsUp
=
u
\U0001f44d
👍
converter
WideStringOffsetConverter
text=u
.join
[
smile
]
syntax
error
https
speech
selection
message
current
comment
PR
behaviour
behaviour
illuminating
good
someone
code
whole
investigation
top
issue
windows
error
best
guess
system
file
different
disk
drive
clear
situation
stack
trace
issue
error
exception
paths
directories
relative
path
link
python
bug
comment
Leonard
PR
comment
Python
os.renames
function
copies
disk
drives
OSError
ERROR_NOT_SAME_DEVICE
extended
description
error
system
file
different
disk
drive
error
portable
copy
NVDA
See
https
//bugs.python.org/issue28356
information
change
/
length
comments
more
80-100
characters
Long
lines
hard
sighted
developers
Could
comments
obvious
indexed
-3
long
time
index
key
last
byte
string
packet
list
comment
Packet
end
*
string
single
element
elements
packetB
bytearray
byte
index
way
difference
>
>
b
=
list
[
b
b
b
z
*
]
>
>
b
[
b
b
b'zz
]
>
>
>
b
[
-2
]
=
b
>
>
>
b
[
b
b
b'zz
]
>
>
>
ba
=
bytearray
b
.join
b
>
>
ba
bytearray
>
>
ba
[
-2
]
=
ord
c
>
>
ba
bytearray
suggestion
checksum
3rd
index
end
'packet
end
bytes
'packetB
bytearray
checksumIndexInPacketB
int
helpful
examples
kind
values
set
examples
AfxFrameOrView80u
AfxFrameOrView90u
AfxFrameOrView100u
>
comment
concrete
doubts
cases
comment
effect
comment
WeakSet
sets
hashable
types
set
something
suggestion
_pendingEventCountsByObjId=
Same
question
braille
module
ti
end
range
endOffset
end
current
range
earlier
ti
call
_findNextContent
textInfo
object
text
current
range
comment
remarks
section
[
]
https
//docs.microsoft.com/en-us/windows/desktop/controls/em-posfromchar
check
<
<
Thanks
old
configurations
user
comment
nice
error
good
comment
focus
practical
terms
e.g
focus
list
useful
quick
navigation
navigation
efficient
translator
comment
line
feeling
checkpot
parenthesis
same
line
string
word
bothers
everyone
necessary
sign
screen
everyone
suggestion
label=_
Use
NVDA
Windows
sign-in
administrator
privileges
administrator
privileges
part
better
user
guide
translator
comment
needs
checkPot
test
suggestion
point
method
text
range
end
endpoint
collapsed
textrange
fine
comment
relevant
case
auto-property
form
def
suggestion
case
need
logic
good
reason
negative
names
positive
form
hasText
_isCollapsed
nit
comment
more
cache
code
code
end
file
code
root
Win8
metro
app
ROLE_APPLICATION
ROLE_DOCUMENT
automatic
browse
mode
apps
browse
mode
wwahost
apps
code
redundant
something
Typo
suggestion
DownArrow
list
twice
extra
com
range
new
ends
anything
i.e
caret
first
collapse
line
collapse
self._rangeObj.end
collapse
anything
end
True
newEndOffset
=
self._rangeObj.end
new
endOffset
smaller
old
endOffset
infinite
loop
case
end
collapse
size
range
example
see
sayAll
readTextHelper_generator
sayAllHandler.py
end
newEndOffset
<
oldEndOffset
+
end
<
oldEndOffset
suggestion
.eclipse
import
*
noqa
F401
F403
sure
performance
decrease
lot
log
calls
Liblouis
level
debug
many
switches
c
Python
log
callback
Python
function
returns
error
UnidentifiedEdit
NVDAObjects.window.edit
clsList
Make
sure
try/except
statement
putty
module
example
colon
issue
number
such
comments
suggestion
Edit
fields
Excel
displayModel
helpful
problem
Win
2006-2020
automated
testing
copyright
headers
point
line
ran
same
thread
function
_btComs
middle
drivers
suggestion
langs
[
loc
f
name
loc
name
loc
loc
name
langs
L
language
suggestion
panel
language
list
desc
lc
most
languages
full
language
mean
context
Were
stand
Could
constants
Note
constants
regex
bit
broken
RE_ARIA_CURRENT_PROP_VALUE.match
current=true
dummy=test
RE_ARIA_CURRENT_PROP_VALUE.match
var=val
current=true
dummy=test
May
unit
test
cc
@
feerrenrut
errenrut
latter
false
Could
comment
false
valid
value
comment
center
Did
bug
Firefox
IMO
implementation
bug
centre
character
part
character
safe
characters
nasty
objects
due
borders
etc.
centre
worth
comment
bug
occur
Firefox
bug
manifest
user
perspective
right
character
reports
wrong
clear
centre
diff
centre
point
bounding
rectangle
fan
above
classmethod
helper
function
former
able
classmethod
TextInfo
whole
NVDA
documentation
open
Python3
False
Windows
least
machine
locale.getpreferredencoding
False
cp1252
Latin
alphabet
encoding='utf-8
call
.encode
'utf-8
string
_display
causes
circular
reference
__del__
classes
garbage
collector
able
safer
weakreference
model
instances
lifetime
display
function
suggestion
_
suggestion
Maintain
backwards
compatibility
F403
unable
undefined
names
good
comment
example
content
conditions
>
example
Mute
toggle
button
way
_getLabelForProperties
lazy
fetcher
control
field
overkill
something
def
propertyGetter
prop
Lazily
attributes
first
time
attrs.update
self.textInfo._getControlFieldAttribs
self.vbufFieldIdentifier
]
self.vbufFieldIdentifier
]
return
attrs.get
prop
Good
point
comment
something
*
Do
states
Sure
box
like
Elements
List
user
list
specific
control
overview
form
values
quick
navigation
reason
other
screen
readers
elements
lists
SuperNova
JAWS
element
states
elements
list
particular
element
overview
elements
review
input
form
quick
navigation
most
cases
case
form
full
check
boxes
i
elements
list
states
user
particular
control
first
letter
navigation
current
state
•
bit
REASON_ELEMENTSLIST
states
calculation
collapsed
state
collapsed
state
specific
states
explicit
more
more
exceptions
controlTypes
collapsed
state
sense
elements
list
collapsible
item
combo
box
elements
list
states
stuff
bit
arbitrary
moment
states
Sure
box
like
Elements
List
user
list
specific
control
overview
form
values
quick
navigation
*
bit
REASON_ELEMENTSLIST
states
calculation
collapsed
state
collapsed
state
specific
states
explicit
more
more
exceptions
controlTypes
*
questions
specific
use
cases
mind
*
least
comments
choices
interfaces
good
thing
something
mro
interface
interfaces
QueryInterface
pass
identical
result
IUIAVersion
=
interface.__name__
comment
please
typo
offselts
>
%
sure
exceptions
space
newline
blank
field
only
thing
space
new
line
field
new
line
space
Chrome
Firefox
browse
mode
Suggest
use
term
content
value
placeholder
worried
difference
None
empty
string
placeholder
None
comment
prefix
l1
l2
documentation
variable
epydoc
code
doc
tool
private
appModule
method
internal
function
typo
Please
rename
comment
correct
tuple
safearray
variants
safearray
ints
Python
int
array
files
case
-4
value
name
something
numberOfCharsInExtension
next
list
files
comment
files
same
number
characters
extension
comment
short
.pdb
extension
.sym
output
file
name
filename
extension
extension
more
characters
file
names
.dll
part
....
Split
suggestion
in-process
legacy
console
window
console
windows
own
specific
character
support
thing
code
invalid
pairs
non-surrogate
exceptions
most
implementations
individual
characters
case
example
U+d800
U+d800
��
separate
characters
Notepad
Firefox
offsets
before
current
one
cleverness
tedious
>
chars
self._getTextRange
+
need
length
invalid
empty
string
prevChar
=
chars
]
curChar
=
]
nextchar
=
chars
]
chars
self._getTextRange
+
prevChar
u
Slicing
need
length
invalid
empty
string
curchar
=
chars
]
nextChar
=
chars
]
HIGH_SURROGATE_FIRST
<
=
curChar
<
=
HIGH_SURROGATE_LAST
LOW_SURROGATE_FIRST
<
=
=
LOW_SURROGATE_LAST
idea
Note
prevChar
empty
checks
prevChar
False
concerned
Range
comment
misleading
collapsed
range
point
comment
Range
similar
Ditto
other
Range
comments
helpful
reader
alternatives
suggestion
accPropServices
needs
control
pythons
__del__
method
wx
framework
Destroy
child
controls
window
destroy
event
control
necessary
cleanup
wxWidgets/Phoenix/
cleanup
results
reference
parent
window
freeze
exit
NVDA
suggestion
UIA
bug
Windows
versions
suggestion
Windows
versions
UIA
word
comment
word
check
name
function
reluctant
fact
check
method
driverHandler.Driver
other
words
check
way
BrailleDisplayDrivers
SynthDrivers
consistency
clarity
Could
wx.CallAfter
short-circuiting
logic
wx.CallAfter
self.postGuiInit
def
postGuiInit
self.handleConfigProfileSwitch
config.post_configProfileSwitch.register
self.handleConfigProfileSwitch
return
mean
unsuccessful
termination
mean
Beware
providers
list
providerInstance
returns
other
return
False
same
issue
intentional
case
comment
handy
trick
fine
case
comment
hint
lint
error
much
fun
future
developer
manditory
>
mandatory
native
English
speaker
pretty
sure
whos
Add
Bill
Dengler
list
timing
events
design
events
contextManager
active
NVDA
specific
state
winUser
winUser
module
win32
APIs
Rather
wrapper
function
mouseHandler
new
mouseUtils
module
something
modal
dialog
option
runScriptModalDialog
source/gui/__init__
See
https
//github.com/nvaccess/nvda/pull/6355
discussion_r167452784
button
last
place
cancel
Eg
Yes
No
Cancel
No
Remind
fine
focus
last
last
call
suggestion
winEventCallback
event
ConsoleWindowClass
windows
lines
except
Having
only
exception
Windows
Error
order
reverse
terminate
__init_-
terminate
engine
ShowSystemCursor
IOI
latter
MagUNitialize
MagShowSYstemCursor
something
def
terminate
try
super
.terminate
Feel
free
new
style
super
call
Magnification.MagShowSystemCursor
True
Magnification.MagUninitialize
clarity
contents
next
line
suggestion
pr
next
line
C
D
identifiers
normalizedIdentifiers
line
reason
string
KeyboardInputGesture.fromName
fromName
identifier
main
key
modifiers
example
NvDA+f
identifiers
kb
nvda+f
normalizedIdentifiers
kb
f+nvda
determinate
way
internal
matching
f+nvda
KeyboardInputGesture.fromName
broken
gesture
normalizedIdentifier
kb
+nvda
bug
KeyboardInputGesture.fromName
sure
fromName
user-acceptable
representation
kind
internal
representation
normalizedIdentifiers
identifiers
line
kb
nvda+f
script
OS
Note
shift+downArrow
deed
anything
normalizedIdentifiers
line
long
suggestion
Modern
IME
candidate
list
windows
menu
events
conjunction
input
composition
support
comment
parent
Please
suggestion
Candidate
list
Microsoft
Quick
IAccessible
_get_parent
Use
_get_parent
NVDAObject.window
Mmm
_get_parent
Window
super
same
Window
sure
ambiguous
Note
import
suggestion
parent=NVDAObjects.window.Window._get_parent
current
code
case
first
time
suggestion
UIA
events
candidate
window
MSAA
events
rename
comment
necessary
comment
values
GUI
intent
log
value
fixed
set
values
GUI
better
suggestion
level
log.DEBUG
log.IO
log.DEBUGWARNING
log.INFO
log.OFF
comments
error
Please
lines
Please
change
comment
more
generic
I.e
specific
Python
version
someone
comment
variables
base
method
i.e
LiveText
speaks
line
filtering
LiveText
comment
wrong
suggestion
Perform
character
filtering
class
characters
events
Hmm
github
code
safe
assumption
code
github
someone
comments
comment
user
_-gestures
dictionary
case
most
objects
default
check
hasattr
efficient
exception
handler
pot
file
header
metadata
pot
file
EG
msgid
msgstr
Project-Id-Version
NVDA
branch-1d146f6\n
Report-Msgid-Bugs-To
\n
POT-Creation-Date
2020-04-28
PO-Revision-Date
YEAR-MO-DA
HO
MI+ZONE\n
Last-Translator
FULL
NAME
<
EMAIL
@
ADDRESS
>
\n
Language-Team
LANGUAGE
<
LL
@
Language
\n
MIME-Version
Content-Type
text/plain
charset=UTF-8\n
Content-Transfer-Encoding
header
file
passedHeader
metadata
checkPot
comment
instance
single
empty
msgid
pot
file
metadata
header
msgstr
portion
start
file
subsequent
entries
comment
Freeze
NVDA
Google
Chrome
python
e.g
=
git
merge-base
baseBranchPlaceholder
target
branch
PR
HEAD
format
_mergeBaseCommand
actual
branch
list
Honestly
bit
uncomfortable
placeHolderIndex
Space
=
Can
better
lines
LOWORD
variable
name
clear
comments
information
doc
string
shouldUseUIAConsole
auto
default
Please
list
Rather
dict
[
key
]
list.index
key
checkbox
former
combo
box
See
example
open
scratchpad
dir
button
checkbox
Typo
windoes
code
appmodule
appModule.isBadUIAWindow
note
earlier
lines
appModule
None
Please
comment
things
problems
problems
issue
number
depth
discussion
Above
class
ambiguous
window
class
Start
lines
'fixes
issue
'NetUIHWND
controls
MS
office
IAccessible
place
UIA
NetUIHWND
classes
office
versions
Fixes
focus
reporting
Fixes
reporting
context
menu
items
Fixes
able
ribbon
sections
edit
field
issue
XYZ
office
similar
ribbon
sections
start
edit
fields
IAccessible
collapsed
ribbons
focus
changes
focus
events
comments
styles
Typo
suggestion
Initialization
response
id
suggestion
self._serial.write
b
reset
new
driver
suggestion
Copyright
C
NV
Access
Limited
full
name
>
m
sorry
<
result
suggestion
Copyright
C
NV
Access
Limited
Mohammed
Noman
suggestion
Translators
prompt
confirmation
gestures
Input
Gestures
dialog
suggestion
_
sure
gestures
factory
defaults
nice
comment
description
layout
args
packet
type
code
easier
easier
bugs
arithmetic
FS_PKT_WHEEL
bits
bbbaaa
bits
count
count
b
bits
wheel
number
course
different
explanations
other
packet
types
argument
block
many
wheels
values
wheelNumber
first
values
isRight
False
isDown
False
isRight
False
isDown
True
isRight
True
isDown
True
isRight
True
isDown
False
rest
following
pattern
isRight
True
isDown
True
isRight
True
isDown
False
correct
values
wheel
id
table
prefereable
isRight
=
[
False
False
True
False
True
True
False
True
[
wheelID
]
raised
indexError
unicode
strings
bytes
suggestion
tempRange
end
range
way
strings
Translators
Character
replacement
Review
current
Symbol
command
Example
Character
Replacement
question
message=_
Character
\nReplacement
text
expandedSymbol
languageDescription
=
languageHandler.getLanguageDescription
curLanguage
Translators
title
expanded
symbol
dialog
Example
symbol
English
title=_
symbol
languageDescription
ui.browseableMessage
message
title
symbol
replacement
symbol
ambiguous
case
cursor
symbol
symbol
replacement
other
comments
Microsoft
Office
Microsoft
Excel
different
helpId
abstract
property
panel
mixin
add-ons
context
help
case
something
help
mixin
Ah
file
temp
directory
end
comment
suggestion
strings
formatted
stack
end
\n
join
separator
necessary
=
.join
traceback.format_stack
frame
correct
Firefox
setFocus
physical
focus
subsequent
call
physical
focus
Same
result
code
change
worth
comment
suggestion
knowledge
msgctxt
msgid
msgstr
concepts
other
library
module
brief
explanation
pointer
handy
someone
background
knowledge
line
endpoint
end
line
Typo
suggestion
visible
range
small
comment
statement
tries
hard
first
glance
bit
windows
ieproxy.dll
program
files/internet
explorer/
program
files
x86
/internet
explorer
implies
oleacc.dll
result
way
technical
line
real
problem
worth
mindful
solution
more
damage
good
other
situations
error
multiple
directives
principle
following
error
Animal
name
name
alias
@
output
out_name
alias
above
error
message
response
unnecessarily
strict
editors
below
option
e.g
default
Flask-JSONRPC
frontend
adjacent
advice
property
fields
misleading
duplicate
vertex
fields
one
first
nit
least
output
vertex
nit
>
Yikes
constants
Mind
constant
separator
character
equality
column
theirs
columns
same
NotImplementedError
least
Postgres
list-typed
columns
future
union
types
tables
mention
objects
interfaces
JunctionJoinDescriptor
DirectJoinDescriptor
Postgres
sqlalchemy.ARRAY
SQL
flavor
SQLAlchemySchemInfo
comment
]
okay
node.arguments
bad
idea
function
arguments
copy
set
arguments
fine
free
option
alternative
approach
current
casts
need
comment
crux
problem
static
analysis
powerful
right_is_binary_composition
==
True
iff
isinstance
expression.right
BinaryComposition
true
right_is_binary_composition
precise
statement
line
new
numbering
right_is_binary_composition
point
point
easiest
way
limitation
mypy
left_binary_expression
Optional
[
BinaryComposition
]
right_binary_expression
Optional
[
BinaryComposition
]
variables
side
BinaryComposition
None
type
coercion
operation
many
languages
operation
operator
left_binary_expression
=
BinaryComposition
pseudo-Python
way
assignments
lines
cast
expression_to_rewrite
=
left_binary_expression
valid
matter
types
variables
same
Feel
free
best
judgment
alternative
readable
current
version
assumption
good
way
convention
ok
Assumption
current
location
child
locations
folds
mark
location
way
clerer
something
assumptions
short
names
better
way
future
Steps
unfold
comment
update
additional
step
fold
subquery
main
selectable
Bojan
authors.md
file
html
file
2019-Present
Kensho
Technologies
LLC
dot
end
dot
LLC
2019-Present
Kensho
Technologies
LLC
..
function
independent
value
boundary
pages
function
param_name
caller
responsible
value
flexibility
cost
caller
value
filter
stronger
filters
place
example
x
>
val
val
filter
parameterizer
place
x
>
__paged_param_0
caller
value
greater
__paged_param_0
parameter
spec
parameter
generator
nice
filters
stronger
filters
way
desired
parameter
value
function
cross-dependency
parameter
generation
dependency
easy
tests
modules
@
obi1kenobi
thoughts
error
Use
parens
backticks
PR
exception
Lets
raise
values
part
quantile
comment
sense
quantile
precise
value
collection
values
technicality
important
precise
possible
comment
multiple
times
code
base
feel
free
places
moment
comment
other
places
code
sense
comment
comment
pages
[
]
quantiles
[
[
-inf
inf
]
]
filter
distinct
result
estimate
infinity
pagination
capacity
suggestion
first
quantile
values
greater
known
maximum
part
last
quantile
minimum
TODO
clear
sure
Thanks
import
NamedTuple
nice
type
annotations
namedtuple
feasible
information
parameter
metadata
metadata
canonical
place
info
support
new
collection
type
e.g
parameter
input
wrong
bindparam
painful
bug
nit
shorter
clause
sake
readability
copy-paste
Notice
explicit
super
method
postgres
pattern
BINDPARAM_
key
comment
Are
error
somebody
date
datetime
parameter
much
documentation
datetime
parameters
neo4j
library
idea
parameters
correct
python
type
link
https
//neo4j.com/docs/api/python-driver/
documentation
right
place
good
Just
nit
date
objects
datetime
objects
dates
datetimes
types
python
clear
possible
actual
python
types
[
]
https
//github.com/kensho-technologies/graphql-compiler/pull/369/files
r304532811
PR
>
share
error
pylint
comment
pylint
handling
decorators
possible
bears
error
error
pylint
E
value
argument
'call
function
call
no-value-for-parameter
>
tries
positional
argument
kwarg
Good
call
suggestion
pagination
capacity
None
quantiles
property
capacity
None
comment
suggestion
comment
order
operations
matters
implementation
regression
bugs
other
people
mess
code
float
nit
sentence
hard
something
edge_counts
aggressive
[
edge
]
statistics
same
time.
Similar
issue
at_eligible_location
eligible
preferred
locations
where_block
None
logic
helper
function
something
_contains_local_filter
loop
good
catch
multi-line
disjunction
multi-line
bit
friendly
class
bit
confusing
differences
Py2
Py3
classes
support
Py2
point
nonlocal
other
type
Field
objects
other
root
fields
validation
functions
docstring
exceptions
query
validity
graphql_compiler/exceptions
QueryStructureError
order
exceptions
same
kind
place
class
non-trivial
way
new-style
NamedTuple
proper
fields
documentation
comment
addition
new
functionality
Thoughts
docs
inline
right
next
field
definition
way
type
docstring
type
hint
e.g
boolean
proximity
field
https
//mypy.readthedocs.io/en/stable/common_issues.html
spurious-errors-and-locally-silencing-the-checker
more
type
ignore
[
no-redef
]
something
particular
type
mypy
check
component
strings
comment
comment
code
clarity
maintainability
clarity
line
Cypher
Nice
writeup
docstrings
one-line
headline
blank
line
other
text
wrong
true
name
variable
value
variable
relevant
value
error
type
type
NotImplementedError
parens
error
message
same
thing
docstring
someone
error
code
good
documentation
update
line
specific
imports
Literal
TypedDict
code
function
error
message
repetition
much
function
private
one-liner
suggestion
Mapping
field_name
>
field_value
observed_count
field
names
number
samples
counts
value_counts.values
lot
pleasant
API
ready
union
types
subclass
data
Subclass
union
bit
awkward
concept
problematic
unions
type
equivalence
hint
union
nit
good
idea
Optional
something
nit
over-indented
black
Optional
lack
Option
[
]
type
intended
use
value
truly
optional
auto-generated
__init__
method
positional
argument
field
features
approach
different
dialect
example
inheritance
list
values
useful
separate
ones
long
run
clear
design
features
least
difference
compilation
same
emit
function
different
lowering
passes
early
redesign
version
dialect
part
type
Dialect
Option
[
Dialect
]
huge
fan
layout
fields
case
SQL
case
non-SQL
worried
additional
complexity
bugs
example
fields
backend
SchemaInfo
instance
instance
valid
usable
SchemaInfo
[
BackendSpecificDataT
]
generic
dataclass
BackendSpecificDataT
different
things
different
backends
able
NewType
[
]
https
//docs.python.org/3/library/typing.html
newtype
new
types
few
combinations
SchemaInfo
backend-specific
data
sure
solution
ideal
something
better
fewer
risks
option
backend-specific
fields
part
respective
backend
nit
backend
MATCH
Gremlin
good
idea
import
graphql_compiler.orientdb
vendor
easier
same
place
Raises
section
end
rest
project
convention
Args
Returns
suggestion
fewer
ideal
number
quantiles
more
suggestion
values
quantiles
N
domain
N
chunks
%
%
quantiles
min
max
values
domain
N
distribution
Nit
values
immutable
variables
new
values
suggestion
variables
code
vertex
ideal
way
VertexPartitionPlan
clear
actual
partition
comments
if/elif/else
branches
nice
last
minutes
general
approach
fresh
mind
months
able
more
one-liner
Args/Returns
sections
suggestion
Args
schema_info
query
planning
information
quantile
statistics
pagination
query_ast
GraphQL
AST
node
query
number_of_pages
number
pages
query
Returns
tuple
best-effort
pagination
plan
tuple
advisories
ways
pagination
plan
less
ideal
note
type
hints
constant
suggestion
quantiles
uniform
bit
more
detail
%
sure
intent
problem
way
angle-brackets
<
QUANTILE_REQUIREMENT_FACTOR
>
readability
reason
namedtuples
dataclasses
@
obi1kenobi
suggested
docstring
motivation
next
version
pagination
planner
considers
vertices
other
root
query
planner
pagination
capacity
vertex
combine
multiple
vertex
partition
plans
desired
number
pages
scenario
leap
perfect
vertex
partition
plan
action
statistics
total
pagination
capacity
partition
insufficient
action
statistics
Thank
good
catch
bit
vague
docstring
same
word
hard
function
better
same
notation
line
number
AB
edges
AB
edges
use
precise
language
symbols
symbol
docstring
Replace
number
Please
arguments
type
hints
documentation
Avoid
functions
blank
lines
docstring
suggestion
function
part
user-facing
public
API
module
such
bit
more
detail
docstring
—
user
problem
appropriate
functionality
users
features
need
important
thing
user
_their_
introspection
query
same
one
module
user
in-process
graphql-core
same
version
compiler
fine
—
users
user
GraphiQL
introspection
query
server
code
server
code
introspection
current
API
problem
users
likely
end-to-end
user
experience
usage
code
more
detail
convention
best
function
multi-line
docstring
explicit
Args
Returns
sections
example
https
//github.com/kensho-technologies/graphql-compiler/blob/main/graphql_compiler/compiler/compiler_frontend.py
L739
new_name_string
self.custom_scalar_types
part
statement
block
awkward
variable
name
comment
nit
i
*
numbers
*
kind
odd
giant
comment
super
helpful
code
Thanks
😄
nit
comment
bit
mean
reader
code
colocated
means
part
same
vertex
field
i.e
directive_location.at_vertex
same
property
field
i.e
directive_location
==
location
suggestion
generator
mutable
data
type
Iterable
[
DataToken
]
part
careful
Make
sure
state
upon
bug
hard
admonition
important
short
sweet
additional
points
closures
functions
more
short
code
examples
prose
Thanks
bad
comments
out/in
same
source/sink
local/remote
clear
source/sink
opinions
worth
terminology
nit
full
docstring
Args
Returns
sections
general
rule
thumb
description
line
sections
much
documentation
function
easier
code
documentation
documentation
section
headline
argument
name
>
want
argument
name
query
path
other
custom
scalars
addition
sure
Date
particular
special-cased
good
comment
formatting
suggestion
names
e.g
String
exception
Date
built-in
scalar
types
scalars
key
code
explanation
pylint
suppression
comment
description
Note
black
auto-formatted
comment
imports
relevant
import
[
]
https
//github.com/kensho-technologies/graphql-compiler/pull/369
discussion_r303974011
PR
>
hesitant
definitions
arguments
bad
design
backends
definition
all_backends
exclude
args
obvious
thing
kwarg
e.g
obvious
thing
good
all_backends
>
use_all_backends
decorator
@
use_all_backends
except_backends
[
test_backend.REDISGRAPH
]
natural
language
except_backends
except_for_backends
case
joins
>
junctions
junction
tables
confusion
nit
GraphQLObjectType
from_table
from_table
python
variable
Same
to_table
fields
vertex
fields
README.md
let
follow
suit
intuitive
next
first
next
relates
python
generator
vocabulary
context
continuation
clearer
partition
results
next
continuation
user
module
clear
split_into_next_page_query_and_continuation_query
paginate_query
public
methods
__init__.py
module
documentations
similar
difference
last
parameter
same
thing
next
page
query
outside
scope
type
context
overall
documentation
namedtuple
document
please
way
parameterized
vertex_class
vertex_field
different
things
name
vertex_field
name
edge
class
sure
others
assertion
errors
much
sense
assertion
error
preconditions
undefined
behavior
Nobody
documentation
Nobody
assertion
errors
assertion
error
assertions
Python
code
fewer
assertions
better
own
example
own
schema
concept
reader
article
website
/
get
/
schema
code
scalable
type
output
optional
QueryMetadataTable
object
superset
other
metadata
principle
line
file
info
context
[
'outputs
]
[
output_name
]
OutputInfo
object
QueryMetadataTable
fixture
master
merge
child
parent
query
Bonus
points
convenient
efficient
way
parent
child
child
TODO
need
lot
detail
link
similar
algorithm
sufficient
constant
link
way
comment
multiple
places
bucket
quantile
change
comments
least
>
=
tests
much
effort
docstrings
module
ones
prior
PRs
descriptive
helpful
unknowledgeable
reader
many
e.g
def
do_thing
thing
docstring
additional
useful
information
function
name
function
problem
Please
avoid
docstrings
better
docstrings
unhelpful
ones
suggestion
backends
such
MSSQL
most
fold
functionality
de-indent
sure
auto-generated
schema
hand-written
equivalent
Update
comment
new
P-2
description
module
suggestion
continue
inside
folds
suggestion
continue
inside
folds
much
work
composite
multi-column
primary
keys
day
Dict
[
str
Collection
[
]
]
type
suggestion
base
cte
primary
key
suggestion
times
more
common
queries
suggestion
recursion
performance
factor
filter
selectivity
Selectivity
fraction
improvement
speedup
multiple
inverse
selectivity
suggestion
optimization
necessary
queries
selective
filters
re-wrapping
lines
chars
sorry
better
own
test
suite
test
query
separate
test
function
last
xfail
test
correct
input
Postgres
CTE
setup
SQL
implementations
N=2
lot
confident
statement
N=1
😄
suggestion
file
Returns
section
worth
ID
types
int
string
GraphQL
spec
particular
UUID-like
common
error
good
possible
sufficient
Per
line
arrow
error
subclass
ValueError
code
lot
repetition
functions
function
refactor
rid
repetitions
left-addition
%
right-addition
%
LIKE
clause
times
time
lengthy
comment
transformation
able
helper
functions
complexity
repetitiveness
code
detailed
comments
example
detailed
slight
differences
lowering
starts_with
ends_with
unnecessary
loss
documentation
nit
try_get_pagination_plan
docstring
reason
flake8
arguments
underdocumented
getter
docstrings
account
join_info
Comment
group
nit
comment
imperative
nit
comment
imperative
i
comment
bit
fold
scope
location
query_path
some_location
base_location
open
fold
scope
location
comment
key
comment
key
self._aliases
fold
subquery
alias
error
something
schemas
X
appropriate
values
X
docstring
lint
more
generality
https
//github.com/kensho-technologies/graphql-compiler/blob/c54e165b32e461c3c6947a9e5390c1697c4f73e1/graphql_compiler/cost_estimation/filter_set.py
constructor
invalid
stacks
ImutableStack
None
stronger
pre-requirement
character
uuid
GraphQLID
uuid
field
test
SchemaGraph
GraphQLID
class_to_field_type_overrides
wording
different
equivalent
option
call
subexpression
block.predicate.left
block.predicate.right
isinstance
subexpression
FoldedContextField
subexpression.fold_scope_location.field
==
'_x_count
_x_count_filters.append
subexpression
time
Dun
dun
dun
..
Interesting
—
OrderedDict
generic
default
Might
good
short
comment
reader
code
time
able
clear
definitive
answer
docs
comments
clear
Basically
_x_count
filters
clause
whole
query
folded
subquery
comment
_join_to_parent_location
function
@
bojanserafimov
wrong
query
decorator
bit
dict
Types.String
Types.String
lower-case
please
random
port
unused
random
googling
before
https
//unix.stackexchange.com/questions/55913/whats-the-easiest-way-to-find-an-unused-local-port
course
sure
https
//support.okta.com/help/s/question/0D50Z00008G7VBgSAN/openid-connect-redirect-uri
i
NamedTuples
Proto
Structs
future
PR
comment
presto
necessary
lower
possible
Flyteadmin
need
example
format
@
EngHabu
blank
space
Please
look
commit
bnsblue
docstring
file
file_path
show
remote
path
remote_path
local_path
naked
object
other
one
i
overhead
standard
Love
i
dont
implications
Right
thanks
like
new
FileFormat
type
limit
hyphen
underwcore
comment
suppose
case
Please
comment
url
docs
//www.oauth.com/oauth2-servers/signing-in-with-google/verifying-the-user-info/
docstring
comment
mean
field
suggestion
print
Warning
GOOGLE_OIDC_USER_WHITELIST
Please
update
timesketch.conf
suggestion
TODO
months
following
check
compatibility
config
file
suggestion
Check
user
suggestion
TODO
Investigate
.keyword
fields
Sigma
+is
-generic
+default
Renove
function
2038-01-01
Y2K38
bug
Add
TODO
Place
comment
Did
minimal
list
return_fields
dicts
event_seq
OK
future
PR
case
TODO
comment
Same
docstring
brief
one-line
description
insert
details
paragraph
underneath
function
other
classes
docstring
condition
error
message
enough
return_fields
suggestion
Test
multiple
sessions
Quick
note
string
previous
comments
string
suggestion
number
s
sessions
configurable
user
input
analyzers
ready
TODO
changes
function
realistic-looking
set
events
quantity
events
time_diffs
batches
other
number
events
time_diffs
timestamp
first
element
time_diff
event3,4000000
second
element
time_diff
event2,1
event3,2
first
element
time_diff
event102,3000002
second
element
time_diff
event201,4000001
much
tweaking
dataset
look
realistic
other
corner-cases
least
comment
docstring
User
logoff
typo
statement
line
other
piece
code
Can
TODO
underlying
issue
rid
sleep
ready
Just
curious
limit
_create_mock_event
arguments
same
def
_create_mock_event
datastore
event_id
quantity
time_diffs=None
source_attrs=None
Loads
datastore
mock
events
arguments
Args
datastore
instance
MockDataStore
event_id
Desired
ID
Event
quantity
number
Events
time_diffs
list
time
differences
generated
Events
source_attrs
Dictionary
attributes
source
generated
events.
functions
_
private
Please
name
function
share
same
states
several
objects
best
strategy
inheritance
same
states
places
Better
technique
https
//github.com/OCA/sale-workflow/blob/eb94d71ba9f75a0f84c9435b6dac10c010a35aa7/sale_order_type/models/sale_order_type.py
L20
translations
first
kronecker
product
function
TensorFlow
backup
expanded
equation
better
way
version
slightly_smiling_face
reason
calls
operations
related
tape
tf
delete
comments
useful
particular
mention
test
default.qubit
Worth
previous
loop
efficiency
worth
NumPy
loops
added
overhead
numpy
array
suggestion
Loop
object
symbol
table
thinking
numpy
function
scalar
float
value
output
differentiable
come
[
i.requires_grad
i
tensor_args
]
previous
comment
wrong
string
better
specific
elif
check
finite
differences
else
part
output
error
message
diff_method==
bset
JacobianQNode
DeviceJacobianQNode
case
diff_method==
best
comment
wire
checks
care
new
wire
management
strategy
too-few-public-methods
disable
necessary
nice
short
sentence
explainer
sentences
following
new
paragraph
short
sentence
summary
box
bit
less
busy
[
image
]
https
//user-images.githubusercontent.com/49409390/82906403-2fa96300-9f33-11ea-8227-f408e98064f0.png
better
measure='expval
default
way
users
measure
type
keyword
argument
MSECost
pytest.approx
Ville
signature
😆
tests
QubitQNode.best_method
method
QubitQNode
tests
Better
tests
test_qnodes_qubit
way
changes
QubitQNode
logic
require
updating
corresponding
QubitQNode
unit
tests
Looks
good
good
solution
operation
issue
Update
fitting
number
samples
operation
comment
better
suggestion
state
case
comment
useful
self.circuit.operations
first
argument
docstrings
same
Minor
suggestion
comment
helpful
suggestion
Indices
mat
new
indices
state
contraction
new_indices
ABC
[
self.num_wires
wires
change
NumPy
scalars
gate
arguments
e.g
>
>
=
np.array
>
>
>
circuit
PennyLane
core
fine
NumPy
scalars
matter
input
validation
change
user
scalars
non-differentiable
Autograd
>
>
=
np.array
circuit
PyTorch
TF
work
e.g.
tf.Variable
self.type
=
are_cvs
josh146
TODO
note
self.device.capabilities
empty
dictionary
tests
comments
sense
read
order
+1
Might
worth
comment
suggestion
successor
gate
non-Gaussian
analytic
differentiation
mode
observable
sense
default
JacobianQNode
model
capabilities
QubitQNode
unknown
circuits
Yep
functional
external
ML
library
qnode.jacobian
qnode
+
classical
processing
good
code
base
class
goal
check
same
thinking
whole
interface
output
conversion
logic
coherent
long
time
whole
logic
interfaces
conversion
inputs
outputs
sensible
possible
domain
check
parameters
foreign
i.e
float
ndarray
docstring
temporary
WIP
implementation
decisions
Agree
TODO
kind
contract
device
pennylane
qnode
order
more
use-cases
contract
minimal
pennylane
core
minimal
assumptions
things
data
type
sure
elegant
way
things
thinking
problematic
code
operation.Operator
smart/flexible
hand-coding
special
case
workaround
few
non-straightforward
things
tf.UnconnectedGradients.ZERO
etc.
simpler
unit
test
case
Again
expression
hand
expression
previous
test
See
expval
As
inconsistent
behaviour
way
following
point
*
*
*
*
sample
'sample
observable
queue
boolean
flag
result
flag
computational
basis
samples
python
e
self.obs_queue
hasattr
e
return_type
e.return_type
==
Sample
self._memory
=
True
sure
samples
computational
basis
samples
self._memory
sample
computational
basis
states
state
probability
=
np.arange
*
*
self.num_wires
samples
=
np.random.choice
basis_states
self.shots
p=self.rotated_probability
basis
states
base
binary
representation
self._samples
samples
,None
]
<
<
np.arange
*
*
self.num_wires
.astype
int
sample
method
resulting
computational
basis
states
correlation
information
def
sample
observable
observable.name
PauliX
PauliY
PauliZ
Hadamard
eigenvalues
-1
post-processing
step
return
*
self._samples
[
[
]
]
Need
samples
observables
Extract
columns
basis
samples
wires
wires
wires
samples
self._samples
[
np.array
wires
basis
state
computational
basis
correct
eigenvalue
indices
np.ravel_multi_index
samples.T
]
*
len
wires
converted_measurements
=
observable.eigvals
indices
return
converted_measurements
import
abc
std
lib
import
analytic
mode
samples
circuit
reason
Note
self._sample
attribute
previous
comment
devices
hardware
number
occurrences
self._sample
self.shots
self._hardware
flag
hardware
devices
logic
worth
Device.sample
explicit
easy
PR
easy
plugin
side
slightly_smiling_face
suggestion
return
type
variance
code
comment
suggestion
return
type
sample
clarifying
operation
contexts
context
list
suggestion
behaves
list.remove
ValueError
operator
suggestion
S2
[
w
+
N
.reshape
w
+
N
.reshape
-1
=
S
[
M
M
]
.copy
PP
suggestion
S2
[
w.reshape
w.reshape
-1
=
S
[
M
M
]
.copy
same
comment
suggestion
multivariate_func
nested
lists
parameters
suggestion
Check
gradient
suggestion
flattenened
list
[
data1
data2
weights
suggestion
Check
gradient
suggestion
Check
gradient
docstring
thinking
Ah
apply
contract
state
single
node
technical
reason
non-trivial
Might
explicit
copy
list
comprehension
self._free_edges
self._state.edges
]
nice
line
comments
while
print
statements
check
low
sgntr
high
s
Need
name
qubit
test_cv_template_followed_by_operation
test
docstring
suggestion
skip
test
template
operations
template.__name__
NO_OP_BEFORE
op_before_template
pytest.skip
Template
operations
skipping
test
Change
type
differentiable
arguments
qubit
case
CV
templates
NO_OP_BEFORE
future
suggestion
random
variational
quantum
circuit
terms
structural
flow
barren
plateau
problem
PennyLane
same
level
Create
randomized
variational
circuit
import
statements
clearer
worth
short
ReST
comment
PennyLane
NumPy
Matplotlib
headings
subheadings
suggestion
barren
plateau
problem
PennyLane
suggestion
systems
suggestion
small
number
samples
code
reasonable
amount
time
suggestion
print
Variance
gradient
samples
.format
num_samples
grad_vals
suggestion
check
number
wires
corresponds
number
best
comment
docstring
😆
impossible
pytest
case
useful
Plan
B
pattern
Nathan
earlier
fixture
Qiskit
plugin
idea
GitHub
comment
original
comment
something
lines
exact
tests
sampled
tests
different
tolerances
sampled
tests
way
stochasticity
integration
tests
ability
stochasticity
bit
loss
Minor
suggestion
pytest
allows
fixture
injection
instance
following
@
pytest.fixture
scope=
function
def
tol
analytic
analytic
return
atol
float
TOL
TOL
rtol
atol
TOL_STOCHASTIC
rtol
analytic
fixture
_not
defined_
test
value
analytic
fixture
pytest.mark.parametrize
@
pytest.mark.parametrize
analytic
[
True
]
def
test_something
tol
np.allclose
result
*
tol
test
anlaytic
signature
dependent
fixtures
case
test
multiple
values
usual
@
pytest.mark.parametrize
analytic
[
True
]
def
test_something
analytic
tol
dev
=
qml.device
dsfasd
analytic=analytic
np.allclose
result
*
tol
way
opt.device
list
devices
Small
skip_if
conditions
lot
mark
decorators
SF
@
pytest.mark.backends
gaussian
fock
class
TestSomething
nice
thing
marks
classes
test
entire
file
mark
=
pytest.mark.backends
SF
pytest_runtest_setup
function
test
def
pytest_runtest_setup
item
Automatically
tests
certain
backends
tf_available
allowed_backends
gaussian
tf
fock
allowed_backends
gaussian
fock
marker
backend
marks
mark.name
mark
item.iter_markers
mark.name
allowed_backends
marker
test
certain
backends
=
[
mark.args
mark
item.iter_markers
name=
backends
test
particular
backends
backends
=
allowed_backends
set
backend
strings
test
test_backends
=
test_backends
]
b
marks
b
test_backends
pytest.skip
\nTest
backend
s
backend
.format
item.nodeid
test_backends
b
skip
broken
tests
mark
item.iter_markers
name=
mark.args
pytest.skip
Broken
test
.format
*
mark.args
pytest.skip
Test
corresponding
code
base
ours
sure
elegant
way
type=bool
third
option
None
flag
unused
default
value
Minor
suggestion
e.g
Rot
suggestion
list
single-qubit
gates
single
parameter
suggestion
Test
inverse
single
qubit
gate
application
later
suggestion
import
math
import
cmath
import
numpy
np
suggestion
Test
single
qubit
gates
single
scalar
argument
suggestion
two_qubit_param
=
[
qml.CRX
crx
cry
crz
suggestion
Test
qubit
gates
single
argument
suggestion
Test
inverse
single
qubit
scalar
parameter
suggestion
Test
inverse
qubit
gates
parameter
suggestion
Test
device
nice
more
attribute
docstrings
wrong
test
asserts
separate
tests
test
data
pytest
decorators
Nice
approach
entry
points
able
cli
binary
executable
pl-benchmark
example
revisions
Parser
way
PennyLane
pl-benchmark
revisions
command
available
terminal
example
Strawberry
Fields
*
https
//github.com/XanaduAI/strawberryfields/blob/a144b4c38034a94853441818d8072a9a9cf41d06/setup.py
L50
*
https
//github.com/XanaduAI/strawberryfields/blob/master/strawberryfields/cli/__init__.py
version
revisions
entire
benchmark
module
Overall
version
_version.py
file
benchmark
directory
PennyLane
core
suggestion
Parse
arguments
specific
revisions
args
unknown_args
=
parser.parse_known_args
reason
lint
comment
odd
Just
comment
template
e.g
wires
[
]
features
wire_pair
]
]
features
wire_pair
]
]
wrong
places
features
Ah
good
point
future
compatibility
suggestion
503-528
suggestion
]
Liu
Dong
C.
Nocedal
J
limited
memory
BFGS
suggestion
]
Kingma
Diederik
P.
Ba
J
Adam
method
stochastic
Good
idea
Hmm
suggestions
branch
okay
laughing
general
SciPy
versions
more
use
LAPACK/BLAS
libraries
Ah
SF
implementation
laughing
comments
method
GradientDescentOptimizer
test
file
optimizer
Weird
something
tol
fixture
suggestion
First
layer
non_parametrized_layer
suggestion
Test
metric
tensor
comment
case
wires
active_wires
suggestion
Redefine
property
number
wires
_matrix
Nitpick
method
use
line
comments
logical
flow
Might
comment
answer
Nathan
question
future
devs
suggestion
TensorFlow
'mock
Layer
class
KerasLayer
error
initialization
KerasLayer
CORRECT_TF_VERSION=False
Layer
=
ABC
CORRECT_TF_VERSION
=
False
parametrization
comment
first
statement
clearer
line
self.non_identity_obs
identity
observables
identity
=
qml.Identity
suggestion
qnode_interface
tf
==
qnode._dtype
return
qnode
elif
qnode_interface
None
qnode
=
qnode._qnode
pylint
disable=protected-access
work
QubitQNode
CVQNode
split
code
new
D
method
docstring
D
error
message
contradictory
Nice
fix
jacobian
user
autodiff
systems
B
method
needs
Let
self.type
previous
PR
different
attribute
+1
interface=
numpy
correct
docs
decorator
new
VQE
module
suggestion
qubit
operations
other
ops
choice
methods
reason
separate
CVQNode
ans
circuitgraph
_op_descendents
Analytic
method
method
change
strings
reason
other
methods
analytic
gradients
e.g.
https
//arxiv.org/abs/1905.13311
flexible
docstring
clear
parameter
shift
analytic
str
property
__repr__
docstring
same
function
None
functions
such
[
]
https
//pennylane.readthedocs.io/en/stable/introduction/interfaces/tf.html
[
tf.convert_to_tensor
]
https
//www.tensorflow.org/api_docs/python/tf/convert_to_tensor
shape
argument
reshaping
better
separate
call
Nitpick
suggestion
code
readability
free
suggestion
jacobian
=
tf.constant
jacobian
dtype=dtype
Reshape
gradient
output
array
row-vector
=
tf.transpose
tf.reshape
grad_output
[
-1
]
Calculate
vector-Jacobian
matrix
product
output
=
tf.matmul
grad_output_row
jacobian
grad_input
=
tf.reshape
grad_input
[
-1
]
use
torch_support
tf_support
fixtures
curious
underscore
end
preferred
variable
name
python
word
input
input_
inp
tests
thinking
suggestion
Checks
parameter
initialization
compatible
qubit
templates
good
idea
try
/
block
way
self._check_circuit
errors
user
exception
class
attribute
pennylane.operation.Operator.do_check_domain
properly
reset
python
try
pennylane.operation.Operator.do_check_domain
=
False
self._check_circuit
res
pennylane.operation.Operator.do_check_domain
True
line
different
case
flag
function
angle
computation
Might
worth
docstring
function
hard
😆
Would
good
comments
process
WIP
🙂
WIP
label
difficult
due
indentation
top
file
TEST_STATE_DATA
variable
test
readable
@
pytest.mark.parametrize
state_vector
wires
target_state
TEST_STATE_DATA
def
test_state_preparation
tol
qubit_device_3_wires
state_vector
wires
target_state
black
formatting
issues
come
test
due
note
tests
unittest
fixture
single
class
tests
lets
method
class
python
class
TestQNodeOperationQueue
QNode
operation
queue
@
pytest.fixture
scope=
function
def
opqueue_test_node
mock_device
circuit
subsequent
tests
operation
queue
def
circuit
x
qml.RX
wires=
]
qml.CNOT
wires=
[
]
qml.RY
[
]
qml.RZ
wires=
]
return
qml.expval
qml.PauliX
qml.expval
qml.PauliZ
=
qml.QNode
circuit
mock_device
node.construct
[
]
return
More
stylistic
functional
change
advantage
Python
indentation
group
test
functions
exception
class
great
easier
suggestion
Test
QNode
arrays
input
arguments
Autograd
suggestion
EMBED_PARAMS
suggestion
amp_embed_and_strong_ent_layer
EMBED_PARAMS
LAYER_PARAMS
suggestion
part
next
step
JacobianQNode
good
reason
invisible
ops
circuit
tests
much
work
vis_check
property
observable
queue
obs_queue
Are
args
tutorials/tests
predicate
more
places
file
=
mean
context
POSITIONAL_OR_KEYWORD
IntEnum
suggestion
Validate
quantum
function
arguments
apply
defaults
new
QNode
old
QNode
parallel
_current_context
old
QNode
suggestion
Sort
quantum
function
arguments
positional
keyword-only
question
brackets
JacobianQNode
intention
user
variables
context
bit
overkill
_set_variables
Device.execute
feels
scratch
Python
function
argument
behaviour/validation
test_measure
suggestion
Further
gates
form
suggestion
suggestion
quantum
natural
gradient
descent
arguments
params
function
suggestion
math
parameters
math
\
\dots
\theta^
Looks
wrong
Suggestion
vertical
theta_0
theta_1
labels
left-side
matrix
brain
own
internal
convention
laughing
small
section
new
method
advanced
usage
tutorial
\ell
V
W
repetition
U
layer
application
X
A
bit
ambiguous
quantum
node
variational
circuit
unitary
state
prep
measurement
setting
unitary
suggestion
*
math
layers
non-parametrized
quantum
gates
suggestion
QNG
Optimizer
class
~.GradientDescentOptimizer
simple
variational
back-to-back
comments
bit
confusing
typo
something
suggestion
math
parameters
math
\
\dots
\theta^
suggestion
variational
quantum
circuit
quantum
hardware
suggestion
first
block-diagonal
math
g^
subcircuits
suggestion
math
math
circuit
single
gate
math
X
operator
math
*
generator
*
parametrized
operation
math
X
\theta_i
suggestion
PennyLane
built-in
method
Fubini-Study
metric
optimization
convergence
QNG
Optimizer
class
~.GradientDescentOptimizer
simple
variational
circuit
suggestion
block-diagonal
approximation
Fubini-Study
metric
tensor
word
calculated
PR
image
suggestion
gates
form
math
X
\theta_
e^
i\theta_i
K_i
superscript
K_i
suggestion
math
X
\theta^
e^
i\theta^
i
K^
suggestion
vanilla
gradient
descent
suggestion
Therefore
quantum
natural
gradient
optimizer
analytic
suggestion
*
math
V_\ell
\theta_\ell
layers
parametrized
quantum
deep
able
😆
same
comment
same
comment
😆
pennylane.utils
explicit
validation
general-purpose
unflatten
function
def
unflatten
flat
model
res
tail
=
_unflatten
np.asarray
flat
model
tail
raise
ValueError
iterable
more
elements
model
return
slight
usage
subtlety
unflatten_torch
Torch
interface
backpropagation
result
*
Torch
backpropagation
combination
inputs
len
flat
emblematic
bug
PyTorch
impossible
Further
input
validation
more
'should
assertion
assertion
TorchQNode.backward
e.g.
assert
len
flat
wrong
issues
PyTorch
functional
interface
difficult
backward
call
'invisible
pytest-cov
@
trbromley
chat
validation/assertion
suggestion
check
gradient
computed
first
parameter
circuit1
suggestion
Check
gradient
parameters
circuit2
wrt=None
spy.call_args_list
]
]
[
wrt
]
==
None
suggestion
measured
pd
correct
locations
good
change
such
pylint
example
suggestion
TODO
try-except
statement
suggestion
Return
estimated
probability
computational
basis
state
generated
samples
suggestion
TODO
test
analytic_probability
method
analytic
devices
condition
wires
self
None
return
False
suggestion
return
wire
self.wire_tuple
wire
item.wire_tuple
True
condition
False
suggestion
return
item
self.wire_tuple
suggestion
input
Wires
object
wire
tuple
Minor
nitpick
above
statement
E.g.
elif
isinstance
wires
Iterable
isinstance
w
str
isinstance
w
Number
w
wires
elements
strings
numbers
iterable
tuple
return
tuple
wires
isinstance
w
Wires
w
wires
wires
[
w
wires_
wires
w
wires_.tolist
return
tuple
wires
awesome
Ok
suggestion
Determine
input
tensors
backpropagation
function
should_record_backprop
https
//github.com/tensorflow/tensorflow/tree/master/tensorflow/python/eager/tape.py
L163
accepts
lists
*
tensors
Variables
True
more
gradient
tape
False
suggestion
check
gradient
differentiable
elements
weights
data
input
suggestion
Check
gradient
parameters
circuit2
wrt=None
suggestion
check
gradient
differentiable
elements
weights
data
input
suggestion
check
gradient
varphi
suggestion
check
gradient
computed
first
parameter
circuit1
Small
thing
crucial
worth
one-dimensional
ndarray
start
docstring
x
list
conversion
something
Small
suggestion
crucial
x
array
[
float
]
conversion
happening
example
list
logic
check
lines
sure
array
correct
shape
one-dimensional
conversion
array
place
docstring
other
accepted
types
Union
[
array
[
float
]
list
]
similar
suggestion
>
>
>
dev
=
qml.device
default.qubit
wires=2
>
>
@
qml.qnode
dev
def
circuit
params
generators=None
generators
keyword
arg
generators
]
params
]
wires=0
generators
]
params
]
wires=1
qml.CNOT
wires=
[
]
return
qml.expval
qml.PauliX
qml.expval
qml.PauliY
case
rotoselect
optimizer
objective
function
user
signature
cost
generators
case
something
docstring
step
example
class
rest
example
nice
clear
init
method
comment
other
optimizer
tests
i.e
result
actual
optimizer
routine
test
recipe
optimization
meantime
tests
cases
actual
numbers
compare
numbers
targets
bit
work
long
run
optimizer
tests
way
suggestion
Test
values
squeezed
state
first
second
moments
copy-pasted
docstrings
comment
more
clear
suggestion
Let
functions
math
[
s_1
s_2
s_3
]
=
[
-1
-1
]
spin
bit
image
TensorFlow
optimization
numpy/autograd
optimization
code/context
tutorial
above
worth
plot
above
pytorch
cost
step
suggestion
clarity
angles
numpy
suggestion
ok
Same
specific
exception
comments
things
other
comments
@
vkedia
@
tseaver
GIL
part
gcloud
workload
right
graceful
quit
>
quit_
note
*
*
*
*
self._thread
None
i.e
return
self.is_alive
*
*
*
same
block
helper
read-a-billy
catch-all
batch.commit
close
script
docstrings
Ditto
please
class
docstring
Provide
constant
value
problematic
side
effect
multiple
calls
labels
right
thing
bucket.labels
bucket.labels
'bar
bucket._label_removals
bucket.labels
bucket._label_removals
'bar
'foo
ISTM
_get_error_count
query
consistent
fine
right
concern
case
test
flaky
error
reporting
system
bit
quicker
sleep
problem
retry
helpers
reasonable
condition
initial
count
-1
sleep
please
retry
helpers
system
tests
sleep
recipe
flaky
system
test
Empty
line
fun
Client
function
Please
commented-out
code
corresponding
enable
invalid-name
much
COVER
copy-pasta
unit
tests
value
tests
benefit
maintainers
future
trivial
tests
abstractness
class
dismissive
good
argument
this-
anything
likely
block-level
fn
add_done_callback
disable
specific
Good
plan
@
dhermes
[
skip
lines
NotImplementedError
]
https
//github.com/zopefoundation/zope.interface/blob/master/.coveragerc
L10
Please
'labels=
LABELS
i.e
present
Python
earlier
please
__all__
statement
https
//docs.python.org/3/tutorial/modules.html
importing-from-a-package
comment
text
type
Python
default
syntax
yields
bytes
strict
separation
*
unicode
*
six.text_type
STRING
six.binary_type
BYTES
Order
important
Worth
mentioning
docstring
comment
Per
PEP
attribute
case
.execute
*
cursor
rowcount
last
operation
interface
>
exc
Docstring/comment
constant
purpose
argument
helpers
@
staticmethod
comment
copy-pasta
/
job
rest
PR
free
Google-style
docstrings
traditional
Sphinx-style
project
years
old
*
*
*
Google-style
docstrings
year
general
PRs
Googlers
Google-style
docstrings
new
methods/functions/classes
use
single
quotes
i.e
row
Please
empty
line
docstring
class
members
constants
point
property
self._rows
mutable
i.e
atrribute
_rows
Please
use
other
Python
fallbacks
Please
return
See
Entity.__eq__
datastore
[
]
https
//github.com/GoogleCloudPlatform/google-cloud-python/blob/0b6df3d8ba76a9ed917ff94357a7fa7eb16a7582/datastore/google/cloud/datastore/entity.py
L154-L155
Please
rename
self._generator
racy
case
comment
user
state
Did
comfortable
flag
something
identity
check
paranoid
Trivial
question
irrelevant
review
trailing
underscore
retry_
sense
unit
interface
necessary
doc
comment
constructor
helpful
reason
seconds
pretty
infrequent
frequent
comment
comment
%
clear
least
stage
X_ratio_max
PEP257
line
end
-1
comment
source
git
blame
accomplishes
similar
things
Gotcha
comment
clearer
comment
set
instance
set
reload
empty
instance
documented
back-end
limit
SWAG
name
clearer
TableMismatchError
back-end
limit
https
//cloud.google.com/bigtable/docs/reference/data/rpc/google.bigtable.v2
mutaterowsrequest
comment
URL
e.g.
verification
back-end
limit
future
note
state=None
correct
NOTE
_check_row_type
row
DirectRow
mutations
state
comment
other
exceptions
user
document
grpc/gax
exceptions
https
comment
branch
self.media_link
None
copy-pasta
tasks
v2beta2_library
v3
comment
try
StopIteration
Variations
table
setup
present
samples
core
snippet
comment
setup
table
instantiation
snippet
range
example
more
schema
adaptation
possibility
old/new
schema
many
fields
many
new
fields
print
statements
asserts
comment
clearer
column
relaxation
Split
part
separate
testcase
method
table.created
converts
creationTime
property
datetime.datetime
UTC
whole
comment
part
TODO
newline
separation
comment
TODO
clear
different
section
test
sure
request
proto
stub
tests
duplicates
tests
lines
[
502-504
]
https
//github.com/GoogleCloudPlatform/google-cloud-python/pull/5790/files
diff-d495c61ac7ca28885a9cb09130c527c1R502
better
separate
tests
__eq__
__ne__
class
_ClusterState
similar
same
tests
Table
class
[
]
https
//github.com/GoogleCloudPlatform/google-cloud-python/blob/master/bigtable/tests/unit/test_table.py
L225-L241
]
https
//github.com/GoogleCloudPlatform/google-cloud-python/blob/master/bigtable/tests/unit/test_table.py
L243-L256
class
_Other
end
file
python
class
_Other
object
def
__init__
replication_state
self.replication_state
=
replication_state
tests
asserts
lines
501-504
def
test___eq___ClusterState
google.cloud.bigtable.table
import
_ClusterState
google.cloud.bigtable.enums
import
Table
ready
=
Table.ReplicationState.READY
cluster_state1
=
_ClusterState
ready
cluster_state2
=
_ClusterState
ready
self.assertTrue
cluster_state1
==
cluster_state2
def
test___eq___ClusterState_type_differ
google.cloud.bigtable.table
import
_ClusterState
google.cloud.bigtable.enums
import
Table
ready
=
Table.ReplicationState.READY
cluster_state1
=
_ClusterState
ready
other
=
_Other
ready
cluster_state1
==
other
def
test___ne___ClusterState_same_value
google.cloud.bigtable.table
import
_ClusterState
google.cloud.bigtable.enums
import
Table
ready
=
Table.ReplicationState.READY
cluster_state1
=
_ClusterState
ready
cluster_state2
=
_ClusterState
ready
cluster_state1
=
cluster_state2
def
test___ne___ClusterState
google.cloud.bigtable.table
import
_ClusterState
google.cloud.bigtable.enums
import
Table
ready
=
Table.ReplicationState.READY
=
Table.ReplicationState.INITIALIZING
cluster_state1
=
_ClusterState
ready
cluster_state2
=
_ClusterState
self.assertTrue
cluster_state1
=
cluster_state2
code
coverage
happy
per
comment
lines
clause
point
results
@
daspecster
Please
comment
constructor
+=
row.get_mutations_size
method
flush
comment
something
MutationsBatcher
batch
cases
number
mutations
large
unknown
DirectRow
s
memory
size
limits
explicit
call
flush
event
DirectRow
s
memory
Cloud
Bigtable
Batching
mutations
efficient
individual
req
class
usage
systems
mutation
mutate
in-memory
change
case
system
crash
DirectRow
memory
service
completion
mutate
method
TODO
Performance
class
capability
asynchronous
parallel
RPCs.
@
sduskis
Please
MAX_MUTATIONS
check
options
care
right
field
binary
value
unicode
value
Ditto
type_
Does
conversion
base-64
binary
base-64
[
type
Python
built-in
]
https
//docs.python.org/2/library/functions.html
type
convention
type_
unique
comment
necessary
comment
create_dataset
line
[
google.api_core.exceptions.AlreadyExists
https
//googlecloudplatform.github.io/google-cloud-python/latest/core/exceptions.html
google.api_core.exceptions.AlreadyExists
comment
dataset_ref
line
START
line
DATASET_ID
=
Nit
single-quotes
strings
Pyarrow
thead_name_prefix
future
source
mock
server
raw
binary
bit
opaque
someone
server
Python
part
code
base
feature
[
Bigtable
emulator
Go
]
https
//github.com/GoogleCloudPlatform/google-cloud-go/blob/master/bigtable/bttest/inmem.go
comment
superfluous
same
function
name
more
information
Extract
archive
change
rebase
mine
module
google.cloud.logging.handlers.handlers
EXCLUDED_LOGGER_DEFAULTS
jonparrott
PR
right
suggestion
header
=
config
[
setup_commands
]
.split
\n
]
line
test
data
able
single
concat
loop
python
append_vals
pandas.DataFrame
columns=result.columns
index=range
result
df
pandas.concat
[
result
append_vals
loop
inefficient
try
python
append_vals
pandas.DataFrame
columns=range
result.columns
df
index=result.index
pandas.concat
[
result
append_vals
review
comments
code
rule
thumb
things
abstract
class
modin.pandas.DataFrame
Anything
underscore
implementation
detail
abstract
class
Comment
@
dchigarev
please
short
explanation
way
pandas.Series
[
]
dtype=self.dtype
Series
require
data
work
data
numeric
error
data
values
apply_func
assumes
strings
integer
brief
comment
behavior
helpful
suggestion
names
list
smaller
number
columns
file
first
columns
hierarchical
index
=
pandas.read_csv
filepath_or_buffer
nrows=0
suggestion
query_compiler
import
remote
PandasQueryCompiler
local
counterpart
module
fix
specific
class
type
suggestion
such
rpyc
bogus
class
type
TypeError
suggestion
class
WrappedIO
please
suggestion
object.__getattribute__
potential
class-level
__getattr__
useful
comment
last
column
original
columns
comments
Nevermind
updated
devin-petersohn
code
return
statement
brief
comment
==
things
integers
.equals
code
ray_df_equals_pandas_df
rest
callable
convenient
readability
place
comments
cases
exception
others
great
comment
line
indexing
correct
case
self.data.to_pandas
call
MultiIndex
case
case
iloc
loc
axis
issue
name
Series
needs
correct
index
_CAUGHT_NUMPY
__init__
comment
explanation
Please
methods
obvious
__setattr__
super
__getattr__
__getattr__
let
logic
self._get_modin_version
user
user
please
class-level
axis==1
necessary
separate
tasks
suggestion
operation
different
number
columns
bit
inline
comments
extra
check
suggestion
same
length
self.columns
correct
index
suggestion
derived
columns
self.compute_index
convention
suggestion
pandas_df
=
pandas.DataFrame
frame_data
phrase
unclear
partition
blocks
whole
new
comments
descriptive
comments
comment
loop
isinstance
local_obj
netref.BaseNetref
please
update
comment
sense
operation
something
wait-for-transform-completion
Rally
stop-transform
while
..
clear
documentation
|
Min
Throughput
|
stop-transform
|
|
docs/s
|
|
Median
Throughput
|
stop-transform
|
|
docs/s
|
|
Max
Throughput
|
stop-transform
|
|
docs/s
|
percentile
latency
|
stop-transform
|
|
ms
|
percentile
latency
|
stop-transform
|
|
ms
|
percentile
latency
|
stop-transform
|
|
ms
|
percentile
latency
|
stop-transform
|
|
ms
|
percentile
latency
|
stop-transform
|
|
ms
|
percentile
service
time
|
stop-transform
|
|
ms
|
percentile
service
time
|
stop-transform
|
|
ms
|
percentile
service
time
|
stop-transform
|
|
ms
|
percentile
service
time
|
stop-transform
|
|
ms
|
percentile
service
time
|
stop-transform
|
|
ms
|
|
error
rate
|
stop-transform
|
%
similar
comment
earlier
%
similar
comment
earlier
%
similar
comment
earlier
%
Same
comment
comment
nested
function
parameters
re.sub
useful
comment
matchobject
hard
Python
docs
PR
forwards
https
//github.com/jd/tenacity
library
standard
Python
lot
flexibility
boolean
operations
update
national
clouds
duplicate
other
review
comments
tests
comments
utility
config
mount
unlock
disks
[
]
length
=
same
1-2
liner
more
other
functions
more
comments
comment
empty
point
similar
shorter
tests
github
issue
original
discussion
changes
slight
edit
docstring
geometry
single
PyGEOS
benchmark
useful
pygeos
actual
tree
first
query
least
conclusion
timing
comparison
rtree
regressions
part
course
suggestion
predicate
None
'intersects
'within
'contains
'overlaps
'crosses
'touches
optional
way
long
line
length
noqa
E501
suggestion
import
import
geopandas
consistency
documentation
full
documentation
examples
same
manner
table
name
docstring
pandas
version
comment
docstring
method
implicit
kwargs
edgecolor
docstring
line
informative
important
ones
docstring
face/edgecolor
linewidth
search
matplotlib
docs
many
mores
edgecolor
signature
non-default
value
discussion
https
//github.com/geopandas/geopandas/issues/318
/
completeness
test
other
example
@
martinfleis
correct
gdf.index
colors.index
same
order
colors
pd.Series
[
b
c
b
c
b
c
]
df.plot
colors
legend=True
prior
version
required
condition
ring
Which
np.array
[
geom.is_ring
geom
None
hasattr
geom
False
geom
data
]
something
crs
argument
pyproj.CRS
object
anything
pyproj.CRS.from_user_input
explicit
param
notation
docstring
metavar=PROFILES
click.argument
use
name
docstring
e.g
Delete
PROFILES
aiida
configuration
file
database
repository
Same
comment
above
Same
comment
sentence
suggestion
Calculate
next
scheduler
mistake
wrong
help
init
place
arguments
suggestion
args_help
=
parse_args_from_docstring
cls.__init__.__doc__
cls.__doc__
suggestion
try
new
version
old
self.checkpoint_callback.best_model_score
=
checkpoint.get
checkpoint.get
'checkpoint_callback_best
sure
long
line
suggestion
def
__call_eval_loop_hook_start
test_mode
self.__call_eval_loop_hook_evt
test_mode
'start
def
__call_eval_loop_hook_end
test_mode
self.__call_eval_loop_hook_evt
test_mode
'end
def
__call_eval_loop_hook_evt
test_mode
epoch_event
model
self.get_model
on_
[
train/validation
]
_epoch_start
hook
hook_root_name
=
'test
test_mode
hook_name
=
f'on_
hook_root_name
_epoch_
epoch_event
self.profiler.profile
hook_name
hook
getattr
hook_name
model
hooks
hook_name
getattr
model
hook_name
same
suggestion
Sanitize
callable
params
<
function_
*
*
*
*
*
*
*
*
>
>
*
*
*
*
Args
params
Dictionary
hyperparameters
Returns
dictionary
callables
kind
brief
docstring
values
norm
type
>
=
dict
suggestion
reduce_op
reduction
operation
Defaults
response
comment
]
https
//github.com/PyTorchLightning/pytorch-lightning/pull/1877
discussion_r427356889
suggestion
def
__init__
similarity
str
=
'cosine
zero_diagonal
bool
=
True
reduction
str
=
'mean
reduce_group
=
None
suggestion
similarity
embeddings
Example
>
>
>
embeddings
=
torch.tensor
[
[
]
]
]
>
>
embedding_similarity
embeddings
tensor
[
[
]
]
]
]
docstring
descriptive
name
_format_summary_table
same
comment
callbacks
on_validation
suggestion
reserve
keys
tensors
isinstance
val
torch.Tensor
key
=
val
val.detach
key
'hiddens
'checkpoint_on
self._assert_tensor_metric
key
val
logic
suggestion
def
get_batch_log_metrics
>
dict
suggestion
raise
RuntimeError
device
Please
use
module.to
new_device
suggestion
raise
RuntimeError
dtype
Please
use
module.to
new_dtype
suggestion
Verify
multiple
val
test
dataloaders
comments
others
readability
easier
code
default
behaviour
TODO
left
previous
lifetime
TODO
clip_gradients
same
thing
normal
clipping
operations
TPU
alright
change
PR
TPU
class
additional
logic
suggestion
works
optimizer_closure
extra
arguments
os.environ
'PL_DEV_DEBUG
]
=
suggestion
works
optimizer_closure
os.environ
'PL_DEV_DEBUG
]
=
suggestion
works
optimizer_closure
different
accumulated_gradient
frequency
os.environ
'PL_DEV_DEBUG
]
=
suggestion
works
optimizer_closure
accumulated_grad
os.environ
'PL_DEV_DEBUG
]
=
point
hp
comment
docs
Union
[
Any
]
better
straight
Any
examples
part
Docs
least
basic
documentation
brief
description
reference
resources
pls
pls
simple
class
particular
explanation
void
valid
labels
label
indexes
parameter
init
indexes
default
re-usage
]
same
comment
num_
*
suggestion
trainer
parameters
batch
size.
suggestion
Check
trainer
arg
bool
input.
suggestion
idx
on_epoch
prog_bar
enumerate
zip
[
on_steps
on_epochs
prob_bars
easier
[
example
]
https
//pytorch.org/docs/master/notes/amp_examples.html
working-with-multiple-models-losses-and-optimizers
misleading
retain_graph=True
bit
nothing
Amp
present
losses
outputs
multiple
models
backward
passes
same
model
graphs
first
backward
retain_graph=True
necessary
Amp
unclear
example
snippet
retain_graph=True
comment
retain_graph=True
Amp-related
suggestion
hparams_file
Optional
[
str
]
=
None
tags_csv
Optional
[
str
]
=
None
compatible
todo
v0.9.0
something
suggestion
model1
=
TestModel1
class
TestModel2
test
hparams
namespace
hparams
TestHparamsNamespace
model2
=
TestModel2
class
TestModel3
test
hparams
dict
hparams
TestHparamsDict
model3
=
TestModel3
class
TestModel4
case
model4
=
TestModel4
comment
data
type
helpful
integration
tests
load_load_balancer_v2s
load_load_balancer_v2_subnets
load_load_balancer_v2_target_groups
load_load_balancer_v2_listeners
general
tests
load_
*
functions
mock
data
good
place
copy
https
//github.com/lyft/cartography/blob/master/tests/integration/cartography/intel/aws/test_dynamodb.py
favor
'CanonicalHostedZoneNameID
None
empty
string
field
neo4j
python
driver
None
values
field
node
Same
comment
applies
other
empty
assignments
one
code
error
times
different
messages
time
First
second
return
value
function
get_zones_in_project
line
file
comment
third
exception
get_zones_in_project
Sync.run
fourth
program
crashes
due
uncaught
exception
harder
situation
Log-spam
immediate
issue
larger
question
exceptions
effect
execution
sync
general
comment
broader
discussion
immediate
ask
log-spam
somehow
good
way
link
rot
SHA
[
comment
]
Neat
code
👍
interested
foreign
accounts
parentless
projects
OPTIONAL
MATCH
little
refactoring
readability
partner.fiscalcode
mandatory
return
True
partner.company_type
==
'person
Person
case
partner.company_name
E-commerce
company_name
user
VAT
fiscalcode
field
Perform
same
check
Company
case
return
True
partner.fiscalcode
Check
fiscalcode
person
return
False
Company
case
return
True
Vedi
https
//github.com/OCA/l10n-italy/pull/927
issuecomment-460409952
Questa
parte
quindi
è
superflua
same
comment
https
//github.com/OCA/l10n-italy/pull/335
discussion_r117771373
Could
blank
line
blank
line
docstring
method
code
same
modification
method
name
]
=
value
enough
results
different
non-existing
key
d
=
SmartDict
a=None
d.a
=
[
k
v
]
d.b
=
[
k
v
]
d.a
]
.__class__
dict
d.b
]
.__class__
SmartDict
FER2013
kind
dataset
Dataset
format
please
same
docstring
conventions
suggestion
message
str
notification
message
please
docstring
overview
function
Ensure
parameters
Good
work
@
verenceLola
docstring
descriptive
return
type
Ref
[
Python3
Docs
]
https
//www.datacamp.com/community/tutorials/docstrings-python
Nice
work
michael-basweti
pytest
documentation
decorator
tests
actual
implementations
Please
share
reason
nit
publisher
model
UserModelChoiceField
nit
Swagger
UI
style
other
endpoint
docstrings
e.g
/api/v1/programs/
List
programs.
]
https
//github.com/edx/course-discovery/blob/b70e5fd45f5357c7b5231bfce9409356156bd1db/course_discovery/apps/api/v1/views/programs.py
L48
nit
fan
Bare
exceptions
chance
specific
May
something
organization
filter
thanks
McKenzie
comment
i
line
__init__
function
LMSAPIClient
Site
User
parameters
EdxRestApiClient
field
comment
field
definition
need
comment
sure
comment
comment
high
level
method
english
docstring
unique_together
Seat
complicated
currency
credit_provider
better
draft
state
id=seat.id
Same
comment
lookups
course
mode
better
draft
state
method
number
times
caveat
process
re-running
Cases
comments
comments
reason
part
script
other
people
comments
harmful
action
user
data
lose
Dry
method
docstrings
Just
method
new
class
Language
EnglishProductIndex
subclasses
BaseProductIndex
language
Just
thought
classes
base
👍
Thank
detailed
comment
expected
behavior
successful
replacements
non-existing
users
new
user
records
users
old
username
fine
case
docstring
api
comment
test
non-closed
tag
result
broken
HTML
page
possible
comment
PR
word
related
masters
programs
sounds
something
specific
URL
links
docstring
behavior
test
idea
whole
function
g.logged_in_user.get
role
=
ROLE.USER
everything
True
clearer
effects
admins
Move
configuration
checks
__init__
method
reserve_node
function
boolean
first
impression
variable
name
node
object
machine
node
nice
something
meaningful
minor
comment
same
doc
extra
variable
document
document
document2
TODO
move
Couchbase.DeleteVbucket
vbno
method
update
test
description
Can
comment
method
None
case
cachito
returns
empty
dict
reason
Orchestrator/worker/both
worker
sure
plugin
orchestrator
validate
json
changes
self.plugins_json
'schemas/plugins.json
self.plugins_json
=
json.loads
self.plugins_json
leftover
earlier
refactor
subclasses
same
arg
list
docstring
comments
test
many
runs
runtime
test
observables
other
states
Unable
qvm
server
port
use
Style
nit
line
closing
same
line
comment
line
same
comment
innocent
python
try
except
Exception
e
ANY
invalid
entities
raise
serializers.ValidationError
e
Same
comment
ARRAY_ACCESSOR_REGEX.match
field_name
[
suggestion
pass
@
adam2392
file
name
comment
generic
read_raw
reading
raw
file
KIT
data
*
read_raw
function
point
good
standard
read_raw
issues
other
comments
point
suggestion
Test
Annotations
events
bids_version
sure
files
compatible
BIDS
version
mess
different
versions
BIDS
example
line
suggestion
list
matching
paths
root
directory
Needs
agramfort
suggestion
use
list
entities
bids_path
use
list
entities
BIDS
comments
apply
docstring
parameter
parameter
documentation
error
future
PR
nice
attributes
w.r.t
comment
canonical
authority
super
clear
bit
correct
assertion
snapcraft
docstring
sign
docstring
force
arg
colaborators
case
fials
filename
cf
first
comment
proper
single-line
statement
Description
paragraph
editors
parent
docstring
TODO
comment
user
choice
non
ci/container
environments
same
comment
_is_on_store
multiple
results
nice
comment
reason
_
front
unroll
people
weird
comment
assemble_ubuntu_config
nicer
simpler
self.assertThat
config_file
FileContains
dedent
\
ACCEPT=y
ACCEPT=m
ACCEPT=y
ACCEPT
list
in-place
topdown
True
caller
dirnames
list
in-place
del
slice
assignment
walk
subdirectories
names
dirnames
]
question
docs
recursion
directories
dirnames
dirnames
empty
recursion
question
>
>
>
real
=
[
]
>
>
>
ref
=
real
>
>
>
real
[
]
>
>
>
[
]
>
>
>
ref
=
[
]
>
>
>
real
[
]
>
>
>
ref
[
]
>
>
>
ref
=
real
>
>
>
ref
[
]
>
>
>
real
[
]
>
>
>
ref
[
]
walk
directories
top
argument
mind
comment
file
bin/2
dir
foo
non
existent
order
comment
file
creation
part
diff
diff
git
a/tests/unit/pluginhandler/test_pluginhandler.py
b/tests/unit/pluginhandler/test_pluginhandler.py
index
..
a/tests/unit/pluginhandler/test_pluginhandler.py
+++
b/tests/unit/pluginhandler/test_pluginhandler.py
@
@
-1810,9
+1810,6
@
@
class
StateTestCase
StateBaseTestCase
def
test_clean_prime_state_inconsistent_files
self.assertRaises
errors.NoLatestStepError
self.handler.latest_step
self.handler.next_step
Equals
steps.PULL
bindir
=
os.path.join
self.prime_dir
bin
os.makedirs
bindir
open
bindir
w
self.handler.mark_done
steps.STAGE
@
-1820,6
+1817,11
@
@
class
StateTestCase
StateBaseTestCase
steps.PRIME
states.PrimeState
bin/1
bin/2
bin
foo
+
subset
files
directories
primed
+
bindir
=
os.path.join
self.prime_dir
bin
bindir
+
open
bindir
w
+
self.handler.clean_prime
self.handler.latest_step
Equals
steps.STAGE
type
annotations
docstrings
KeyError
warn
choice
side
comment
docstrings
functions
test
test
Cosmetic
https
//www.python.org/dev/peps/pep-0257/
suggestion
Setup
ROS
build
runtime
environment
suitable
snaps
part
text
docstring
phrase
period
function
method
effect
command
description
e.g
Returns
pathname
suggestion
new
string
suggestion
list
commands
build
step
line
next
https
//www.python.org/dev/peps/pep-0257/
suggestion
list
commands
source
ROS
workspace
little
easier
shell
work
wanted
step
pack_project
yadda
current
code
shell
/
shell_after
try/except
comments
equivalent
parallel
count
defaults
cpus
s/to/do/
helpful
comment
stuck_out_tongue
something
ELF
executable
configured
linker
Make
qbs
execution
build
graph
thanks
info
point
qbs
interested
toolchains
base
profiles
place
trouble
qbs
config
profile
.baseProfile
=
'clang
build
point
clang
detected
profiles
clang
yaml
few
Add
Make
Sorry
/usr/bin/make
sense
uuids
profile
issues
difficult
profile
possible
configuration
~/.config/QtProject/qbs/profiles
directory
uuid
difficult
multiple
duplicates
same
configuration
snapcraft
Which
messy
suggestion
Return
host
timezone
timezone_filepath
Etc/UTC
error
fine
upstream
documentation
first
step
section
snap
anchor/title
new
name
comment
docstring
ok
@
elopio
research
other
docstrings
elopio
good
time
+1
sphinx
docstrings
nicer
alternative
please
Please
something
https
//sphinx-rtd-tutorial.readthedocs.io/en/latest/docstrings.html
rest
code
base
Mostly
stylistic
comment
loop
code
single
return
point
new
approach
hard
snapcraft.internal.common.is_snap
fine
wrt
comments
same
comment
one
pip
log
fetches
installs
same
comment
one
pip
log
fetches
installs
nice
Thanks
last
pita
comment
suggestions
clean
code
book
vertical
organization
caller
method
method
functions
nicest
thing
source
code
file
top
_run_meson
context
build
first
context
_run_meson
internals
method
relevant
defs
build
[
]
def
_run_meson
[
]
def
_run_ninja_build_default
[
]
def
_run_ninja_install
[
speaking
None
self.run_on
=
self.build_on
elif
isinstance
run_on
str
self.run_on
=
[
run_on
]
self.run_on
_cache
snap_name
def
get
hash=None
revision
hash
latest
cached
item
same
comment
other
PR
syntax
nice
desktop_file_paths
common_ids
special
cases
top
level
snapcraft.yaml
keys
key_exclusion
=
'common_id
key
value
k
v
k
v
metadata_dict.items
key_exclusion
param
string
Python
dict
good
type
annotation
Code
points
dict
comment
comment
directory
similar
comment
tensorflow
directory
code
same
level
set
host
vars
params
self.want_hostcollections
True
python
omitted_vars
'hostgroup_title
'hostgroup_name
hostvars
=
self._get_hostvars
host
self.get_option
'vars_prefix
above
result
foreman_host_params
etc
set
host
vars
params
server_url/username/password/validate_verts
extends_documentation_fragment
foreman
end
documentation
block
https
//github.com/theforeman/foreman-ansible-modules/pull/230/
suggestion
'puppetclasses
'puppetclass_ids
same
scc
comments
other
PR
apply
comment
better
e.g
OpenTelemetry
plugin
Azure
client
libraries
create
blob
version
id
sure
version_id
empty
blob
blob
root
blob
check
overwritten
blob
version_id
check
root
blob
exists
snapshot
snapshot
share
docstring
same
comment
constructor
sample
concern
other
model
comment
note
reference
https
//github.com/kevin1024/vcrpy/blob/accffa8ea2a2d1c9c89f840b67171b9046b6fe11/vcr/stubs/aiohttp_stubs/__init__.py
L94-L108
Typo
path
error
message
Azure
user
Visual
Studio
Code
disinformation
feature
error
message
First
solution
mind
free
better
one
NotImplementedError
get_token
class
constant
JS
shared_access_key
shared_access_key_name
present
https
//github.com/Azure/azure-sdk-for-js/blob/112bb1da8c66ba90655413e3a76c0a899f2d1dee/sdk/servicebus/service-bus/src/util/connectionStringUtils.ts
L73-L81
python
correct
usual
way
pattern
more
request_id
=
unset
=
_Unset
request_id
unset
....
class
request_id
=
unset
=
object
request_id
unset
....
official
pattern
unique
pointer
memory
pointer
keyword
same
object
memory
rare
scenario
instance
memory
same
isinstance
way
expensive
simple
pointer
comparison
comment
code
discussion
comment
line
better
None
getattr
problem
form
ignore
Mypy
getattr
design
dynamic
comment
doc
^_^
StorageStreamDownloader
iterable
generator
Same
comment
loop
internal
self._executor
reason
someone
Nit
Let
name
test
github
issue
comment
external
site
test
P
comment
suggestion
ignore
different
verbiage
suggestion
def
test_queue_reconnect_send_after_long_wait
servicebus_namespace
servicebus_namespace_key_name
change
Please
toxinidir
argument
package
os.getcwd
setter
https
//docs.python.org/3/library/functions.html
property
python
class
C
def
__init__
self._x
=
None
@
property
def
x
x
property
return
@
x.setter
def
x
value
self._x
value
@
x.deleter
def
x
del
self._x
update
Comment
applies
comment
parts
async
iterator
case
list
comprehension
wont
work
failures
]
async
part
parts
part.status_code
[
]
failures.append
part
Kinda
painful
async
list
comprehensions
....
suggestion
ValueError
ServiceBusMessageError/ServiceBusError
base
client
validation
class
MessageAlreadySettled
ValueError
free
other
comment
big
things
different
different
understand
documentation
param
str
_str
suggestion
except
AzureError
e
error
operation
continuation_token
naive
question
test
cases
SB
empty
list
events
batch
results
opaque
error
ValueError
scenarios
OK
comment
SB
worth
sure
exception
message
clear
Please
issue
param
directive
keyword
parameter
keyword
docstring
bits
appear
same
cases
low-level
decoding/json
bits
free
major
blocker
absence
risk
mixin
other
comment
ask
unclear
handwaving
Worth
comment
message
deregisters
AutoLockRenew
pool
something
nature
spaces
comment
actual
class
SearchIndexingBufferedSender
@
johanste
PagedItem
get_datasources
same
comment
async
version
@
brjohnstmsft
only
one
service
side
indexes
list
line
break
suggestion
key
full
ID
class
parsed
contents
attributes
param
str
source_id
full
original
identifier
key
suggestion
Key
Vault
identifier
parsed
contents
param
str
source_id
complete
identifier
Key
Vault
tiniest
nit
suggestion
full
backup
Key
Vault
comment
sync
version
]
https
//github.com/Azure/azure-sdk-for-python/pull/13525/files
r482486160
suggestion
full
backup
Key
Vault
listized_synonyms
returned
result
documentation
SynonymMap
param
synonyms
series
synonym
rules
specified
synonym
map
format
rules
newlines
type
synonyms
str
paranoia-for-future-me-being-dumb
comment
incoming
commit
message
good
detail
usage
flags
outsider
sure
discoverable
readme/other
source
knowledge
identity
tests
perfect
world
proper
args
details
-h
hard
identity
possible
configuration
generic
pytest
setup
SearchIndex
longer
separate
check
elif
isinstance
exception
errors.AMQPConnectionError
compat.TimeoutException
await
closable._close_connection_async
Same
comment
applies
line
Do
comment
loud
_in
case_
outlook
curmudgeoning
things
forcing
function
e.g
*
IDE
harder
option
deeper
goal
case
stance
opportunity
normal
handwaving
P
@
annatisch
comment
much
TBH
same
statement
free
'Kieran
weird
philosophies
datapoint
Same
comment
timeout
keyword-only
parameter
async
operations
pep8
docstrings
encloses
triple
_double_
quotes
comments
code
s
==
s
[
:-1
]
line
useful
scheme
tooltips
menus
Triggers
sorcar
sc
receive
Tooltip
Receive
Mesh
Data
From
Sorcar
A
short
description
reader
node
code
<
-not
mandatory
links
interest.
clear
argument
directory_type
mix
strings
directory_type='XSD
list
directory_type=
[
'DTD
]
case
DTD
XSD
paths
internal
API
simpler
full
stop
end
docstring
helpful
docstring
checks
pydocstyle
D402
First
line
function
signature
Cross
reference
def
__str__
string
representation
Record
pydocstyle
Returns
Return
grammar
style
imperative
mood
helpful
docstring
checks
pydocstyle
D402
First
line
function
signature
Cross
reference
short
line
docstring
def
__init__
Initialize
new
record
reStructuredText
bullet
point
list
python
class
Record
object
Holds
info
KEGG
Gene
record
Attributes
entry
entry
identifier
name
list
gene
names
definition
definition
gene
orthology
list
2-tuples
orthology
id
role
organism
tuple
organism
id
organism
position
position
gene
list
2-tuples
database
list
link
ids
list
2-tuples
database
list
link
ids
https
//github.com/biopython/biopython/blob/biopython-170/Bio/KEGG/__init__.py
L25
http
//rst.ninjs.org/
useful
Cross
reference
python
Execute
step
Baum-Welch
algorithm
PRIVATE
iteration
Baum-Welch
sequence
output
value
lp_initial
lp_transition
lp_emission
place.
method
new
test
method
e.g
def
test_ResidueDepth_
self
Residue
depth
MSMS
prot_file
....
def
test_ResidueDepth_2BEG
Residue
depth
MSMS
prot_file
....
def
test_ResidueDepth_
self
Residue
depth
MSMS
prot_file
....
def
test_ResidueDepth_
self
Residue
depth
MSMS
prot_file
docstring
one-line
summary
misleading
Matrix
multiplication
Element-wise
matrix
multiplication
See
new
@
matrix
multiplication
operator
Python
able
early
Python
support
Same
comment
Element-wise
matrix
multiplication
PDB_TO_XYZR=
second
argument
PDB_TO_XYZR=None
document
obsolete
code
something
PDB_TO_XYZR
None
warning
error
API
change
way
scripts
default
Triple
docstring
Triple
docstring
Could
context
manager
python
open
filename
handle
code
handle
=
open
filename
code
handle.close
need
mode
r
default
files
directories
system
Biopython
tree
bad
idea
>
>
import
os
>
>
>
os.remove
ideal
similar
cases
e.g
https
//github.com/biopython/biopython/blob/biopython-173/Bio/SeqIO/SffIO.py
L228
Same
comment
above
folders
Biopython
source
tree
best
file
afterwards
code
snippet
black
indentation
style
Biopython
pip
install
black
black
Bio/GenBank/Scanner.py
CONTRIBUTING.rst
file
something
more
exact
line
malformed
comment
warn
carry
structured_comment_key
structured_comment_dict
warnings.warn
Structured
comment
%
s
%
consumer.data.name
BiopythonParserWarning
comment
something
simple
docstring
not-equal
operand
trailing
full
stop
docstrings
PEP257
please
likewise
rest
docstrings
.ref
.ref_db
things
contig
entries
trans-splicing
test
docstring
something
python
Implement
equality
location
old
pending
comment
range
days
API
query
nothing
API
documentation
timezone
things
days
sure
whole
lot
utc
important
suggestion
Generate
aggregate
object
Parameters
observations
list
datamodel.Observation
agg_def
dict
Text
metadata
datamodel.Aggregate
'observation
field
names
names
datamodel.Observation
observations
Returns
datamodel.Aggregate
=
[
]
subtraction
first
numpy
page
comment
day
mind
nanoseconds
seconds
comment
ProbabilisticForecastConstantValue
data
suggestion
timezone
report.
ordering
ErrorBandCost
Basically
bands
order
first
band
inclusion
endpoints
lots
masking
function
approach
easier
additional
parameter
bounding
other
benefit
ranges
sure
overlap
example
first
range
-2
inclusive
second
band
-inf
inf
first
band
[
-2
]
second
-inf
-2
inf
more
clear
separate
documentation
page
purpose
documentation
comment
items
None
color
palette
comment
HiddenToken
purpose
Good
point
quantile
score
single
probability
tau
times
formulation
*
enable
multiple
probabilities
docstring
references
Notes
section
Might
worthwhile
180-198
function
_calc_metric_for_category
df
index_category
ref_fx
normalizer
nervous
values
lists
nested
loops
function
scopes
problems
context
something
tp
=
np.sum
==
True
obs
==
True
cond
True
np.logical_and
function
flake8
efficient
numpy
documentation
np.count_nonzero
better/faster
np.sum
sorry
unclear
previous
comment
much
code
try/except
something
forecast_fill_method
==
drop
implementation
forecast_fill_method
==
'forward
forward
implemention
problem
float
try
const_fill_value
=
pd.to_numeric
forecast_fill_method
.astype
float
ValueError
float
descriptive
message
raise
ValueError
float-ish
reindex
fill
fill
float
implementation
arrays
floats
bools
ints
comment
None
__check_units__
variable
whole
job
units
different
irradiance
variables
suggestion
drop
last
word
fx_name
=
f
'.join
site_name.split
[
-1
]
suffix
CLUSTER
comment
different
strange
cases
space
file
path
general
explicit
possible
asserts
places
space
colon
part
filename
prefix
best
documentation
bus=1
port=0
default
[
'bus
]
[
'port
]
i.e
values
comment
PR
bus/port
number
print
difference
name
above
F-minor
documentation
syntax
point
tool
names
human-readable
way
mistakes
current
PR
sake
semantics
explanatory
comments
Important
test
change
_deserialize_host_http_
[
_api.host.add_host_list_
]
https
//github.com/RedHatInsights/insights-host-inventory/blob/9bf13d684743fd676f0093c113627f8748004f33/api/host.py
L76
state
tags
test
test
entries
deterministic
order
explicit
ORDER
BY
clause
good
comment
module
default
places
comment
schema
'record
record
rule.rule_name
'rule_description
rule.rule_function.__doc__
DEFAULT_RULE_DESCRIPTION
'log_source
str
payload.log_source
payload.type
rule.outputs
payload.service
'source_entity
payload.entity
rule.context
previous
comment
needing
dynamic
value
kwargs
'RequestItems
]
same
thing
self._generate_alerts
function
case
IE
same
items
=
self._generate_alerts
def
mock_batch_write_item
*
*
kwargs
Mock
client_dynamo.batch_write_item
items
return
'ResponseMetadata
self.ALERT_TABLE
items
self.boto_mock.return_value.batch_write_item.side_effect
=
mock_batch_write_item
self.forwarder._send_to_dynamo
items
@
ryandeivert
previous
comment
little
hesitating
line
users
point
little
rules
stage
rule-table
stage
unstage
rule1
rule2
user
friendly
version
subparser
command
rule-table
unstage
rule1
rule2
function
excluded_iocs
instance
property
call
__init__
confusion
property
__init__
users/maintainers
property
function
excluded_iocs
self
init
..
example
__init__
table
region='us-east-1
self.excluded_iocs
=
self._setup_excluded_iocs
excluded_iocs
def
_setup_excluded_iocs
config_excluded_iocs=None
config_excluded_iocs
return
set
set
set
Transform
IPs
IPNetwork
config_excluded_iocs
[
'ip
]
=
IPNetwork
ip
ip
config_excluded_iocs.get
[
]
config_excluded_iocs
way
instance
properties
__init__
_scope_
__init__
other
datasets
similar
docstring
class
description
Create
Dataset
Tedlium
item
tuple
form
[
waveform
sample_rate
transcript
talk_id
speaker_id
identifier
Librispeech
Create
Dataset
LibriSpeech
item
tuple
form
waveform
sample_rate
utterance
speaker_id
chapter_id
utterance_id
sure
big
constructor
class-level
design
pattern
users
questions
Which
one
phoneme_dict
get_phoneme_dict
differences
following
techniques
Use
internal
attribute
name
_phoneme_dict
users
access
object
attribute
prefixed
underscore
message
user
code
right
thing
okay
property
decorator
Lazy-initialization
property
attribute
@
property
def
phoneme_dict
self._phoneme_dict
None
self._phoneme_dict
=
dict
Fill
dictionary
return
self._phoneme_dict.copy
bellow
copy
hasattr
more
straight
forward
actual
attribute
object
constructor
None
such
self._phone_dict
=
None
check
self._phone_dict
None
concern
dictionary
reference
user
code
dictionary
subtle
bug
better
copy
dictionary
return
self._phoneme_dict.copy
shallow
copy
value
points
original
lists
user
code
lists
such
unintended
modification
self.phoneme_dict
[
content
]
]
=
tuple
content
[
]
description
arguments
retouching
*
power
equals
DB
power
DB
ref
ref
*
circle
Scaling
factor
*
code
torch.pow
ref
ref
*
*
Could
example
help
documentation
back
stft
[
torchaudio
istft
]
https
//github.com/pytorch/audio/blob/master/torchaudio/functional.py
L151
core
PyTorch
[
general
solution
]
https
//github.com/pytorch/pytorch/issues/22169
beforehand
consistency
back
stft
documentation
flags
etc
compliance
istft
example
clear
spectrogram
=
torch.rand
random
spectrogram
output
=
resblock
input
shape
docstring
load
user
able
function
part
private
backend
backend
function
module
unction
correct
doc
runtime
static
documentation
able
sense
single
docstring
load
function
Same
line
comment
resample
Kaldi
Same
comment
name
test
comment
name
parameters
algorithm
use
LinearResample
conclusion
cc
[
comment
]
https
//github.com/pytorch/audio/pull/735/files
r456481205
cleaner
def
build
async
def
_build
def
build
try
await
self._build
Exception
e
exchange
manager
exception
await
self.exchange_manager.stop
e
async
def
_build
previous
def
build
code
symbol
tf
work
global
retry
count
opinion
i
tab
comment
string
comment
harish-24
@
narasimhan-v
comment
good
@
PraveenPenguin
No
anything
disk
size
G
lsblk
-l
/dev/sde
output
SIZE
Better
regex
Do
comment
sleep
Docstring
interfaces
'n
interfaces
list
interfaces
yaml
file
other
comment
initial_freq
initial_governor
docstring
param
governer
same
output
variable
comment
inline
comment
function
function
assert_something
assert
important
Assert
statements
python
optimization
flag
assert_shape_equal
right
file
sure
best
certain
sort
functions
scikit-image
@
scikit-image/core
Thoughts
referenced
Paley2016
publication
section
computation
grad
computation
num_warps
loop
Hessians
*
*
H
*
*
publication
initialization
following
num_warps
loop
grad
computations
loop
Note
change
input
gradient
computation
Python
grad
=
np.array
np.gradient
reference_image
Local
linear
systems
creation
i
j
combinations_with_replacement
range
ndim
[
i
j
]
A
[
j
i
=
filter_func
grad
[
i
*
grad
[
j
]
loop
flow
b
moving_image_warp
warp
iteration
grad
test
suite
change
comment
function
space
computation
ndim
+
original
image
size
addition
image
below
allergic
nested
loops
external
counters
=
python
itertools
import
combinations_with_replacement
comb_with_replacement
k
i
j
enumerate
comb_with_replacement
range
ndim
coef
[
k
]
=
grad
[
i
*
grad
[
j
]
j
==
i
coef
[
ndim
]
=
grad
[
i
comment
intuition
coef
[
ndim
]
line
docstring
same
line
quotes
many
UIs
first
line
PEP257
suggestion
Calculate
Hausdorff
distance
nonzero
elements
images
suggestion
Calculate
Hausdorff
distance
nonzero
elements
images
Hausdorff
distance
]
_
maximum
distance
point
suggestion
r
Checks
coordinates
inclusiveness
convex
hull
2-dimensional
Create
montage
/
rectangular
collage
2-dimensional
'montage
dimensionality
3-/4-dimensional
single
line
single
sentence
format
montage
several
grey
color
images
second
paragraph
example
conversion
_from_
_RGB_
original
corresponding
figure
title
suggestion
data
morphology
util
skimage.io
module
imageio
package
skimage.io
discussion
good
habits
documentation
examples
wink
>
=
length
line
needs
longer
sphinx-gallery
new
block
text
artifact
https
//162-2014929-gh.circle-artifacts.com/0/doc/build/html/auto_examples/filters/plot_entropy.html
sphx-glr-auto-examples-filters-plot-entropy-py
figures
top
math
import
floor
top
file
=
floor
k/4
explicit
code
comments
logic
maths
paragraph
GitHub
issue
sufficient
several
lines
helpful
future
maintainers
great
description
recommendations
Notes
section
function
parameters
i.e
Higher
mu
values
lambda
use
whitespaces
line
lines
otehr
lines
_cv_calculate_variation
second
sentence
Notes
section
docstring
deprecation
cycle
option
note
TODO
forum
thread
discussion
edge
cases
results
edge
cases
docstring
issue
bias
Thanks
Notes
section
docstring
paragraph
example
lot
room
improvement
Sorry
fault
good
opportunity
border
objects
pixel
touch
border/mask
single-pixel-wide
removal
safe
own
copy
comment
@
scikit-image/core
DOI
please
notation
>
DOI
wrap
chars
https
//github.com/scikit-image/scikit-image/issues/2097
issuecomment-428118113
docstring
examples
code
lesson
everyone
multiple
times
coding
life
np.meshgrid
index='ij
sparse=True
suggestion
Convert
modes
ndi.correlate
indentation
suggestion
absolute
number
proportion
full
new
rephrasing
works
estimate
geometric
transformation
section
title
sentence
RANSAC
geometric
transformation
section
proportion
total
samples
absolute
number.
documentation
[
<
nb-samples
>
reword
docstring
new
API
Complete
docstring
May
abbreviation
HRModule
net
HRNet
docstring
blank
line
class
definition
docstring
blank
line
docstring
init
method
BP
x_normal
docstring
conventions
docstring
Add
comments
explanation
Shall
new
function
flattening
concatenation
score
bbox
predictions
predictions
final
loss
calculation
common
other
methods
function
reusable
major
difference
base
class
RetinaHead
summary
same
line
Docstring
comment
wrong
Type
proposals
List
[
Tensor
]
Pixel
Shuffle
upsample
layer
strict
criteria
docstring
necessary
parameter
function
simple
comment
statement
[
]
https
//github.com/open-mmlab/mmdetection/blob/c342781873fd8574fe9e5be279a0bf26e0c5c5a5/mmdet/core/mask/structures.py
L186
function
simple
Update
docstrings
real
arguments
summary
same
line
docstring
FCOSHead
nn.Module
Therefore
afraid
args
docstring
Most
docstring
other
arguments
docstring
docstring
class
Please
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
docstring
style
May
arxiv
url
quick
reference
classes
args
__init__
method
output
channel
whole
module
Summary
necessary
format
docstring
other
places
python
r
Implementation
paper
Enhancing
Geometric
Factors
Model
Learning
Inference
Object
Detection
Instance
Segmentation
<
https
//arxiv.org/abs/2005.03572
>
_.
empty
line
standard
docstrings
+1
comments
docstring
standard
docstring
argument
order
docstring
order
__init__
method
Docstring
main
difference
CoarseMaskHead
FCNMaskHead
usage
python
Convert
way
datasets
RepeatFactorDataset
function
get_cat_ids
docstring
other
related
documentation
e.g.
tutorials
dataset
usage
better
standard
docstrings
simple
line
Please
format
returns
sphinx
docstrings
python
Returns
tuple
[
Tensor
]
offsets
offsets_weights
bucket_labels
cls_weights
offsets
Fine
regression
targets
\
Shape
num_buckets
offsets_weights
Fine
regression
weights
\
Shape
num_buckets
bucket_labels
Bucketing
estimation
labels
\
Shape
num_buckets
cls_weights
Bucketing
estimation
weights
\
Shape
num_buckets
docstring
python
Anchor-free
head
NASFCOS
<
https
//arxiv.org/abs/1906.04423
docstrings
arguments
candidate
values
docstring
code
docstring
Intersection
Union
Metric
A
Loss
Bounding
Box
Regression
https
//arxiv.org/abs/1902.09630
Comment
comment
sense
function
linter
issues
absence
comment
google3
absence
FLAGS.beam_location
beam
source
code
base
repository
github
Specific
branch
selection
directory
presence
Great
Can
comment
fact
everything
good
comments
AWS
ebs-gp2
storage
type
GCP
PD-SSD
storage
type
future
versions
Azure
more
storage
types
AWS
GCP
Same
Docstrings
descriptions
command
pep
function
method
effect
command
description
e.g
Returns
pathname
same
blank
line
picky
space
https
//www.python.org/dev/peps/pep-0257/
comment
bit
incorrect
index
way
None
suggestion
index
overload
DataFrame.index
similar
Series.index
generated
func
multi-line
comment
top
function
docstring
short
example
func_text
example
mean
DF
column
sense
body
context
manager
python
redirect_stdout
f
t_start
=
time.time
sdc_process_data
t_end
=
time.time
easy
function
name
Please
comment
Let
such
block
everywhere
..
command-output
python
./series/series_head.py
cwd
..
/
..
/
..
result
examples
documentation
tests
test_fillna_numeric_inplace_false
test_fillna_numeric_inplace_true
generic
code
method
something
def
_test_fillna_numeric_inplace
pyfunc
cfunc
generic
code
method
tail
tests
Please
single
empty
line
lines
27-
sdc_pandas_series_str_docstring_template
better
median
value
other
genericity
example
inline
comment
e.g
suggestion
out_series
.quantile
Compute
median
values
window
least
comment
TODO
class
IterableType
stub
absence
iterator
support
Numba
first
glance
accessors
iterable
wrong
comment
size
part
array
window
useful
min
length
somehow
clear
name
function
suggestion
def
gen_sdc_pandas_rolling_overload_body
ctor
type
docstring
obscure
Maybe
better
state
code
overloaded
method
DataType
constructor
nit
docstring
summary
line
open-quote
need
Q
object
filter
Ah
page
page
reason
true
distinct
values_list
due
filter
sections
valid
asyncio.cancelled
situation
Correct
comment
please
+TODO
output
common
format
data
time
comparisons
Oops
promise.error_handler
run_async
handler
callbacks
custom
functions
Custom
functions
other
arguments
update
context
sense
special
error
handlers
use
case
def
custom_func
b
c=None
raise
RuntimeError
error_handler
update
context
b
c=None
print
f'The
error
context.error
custom_func
arguments
b
c
update
update
def
my_callback
update
context
stuff
context.dispatcher.run_async
custom_func
b
update=update
error_handler=error_handler
c=c
difference
promise.update
handler
callbacks
custom
functions
straightforward
good
options
mind
error_handler
helpful
custom
functions
signature
def
error_handler
update
context
*
args
*
*
kwargs
case
update
None
case
usual
error
handlers
errors
jobs
error_handler
dispatchers
usual
error
handlers
downside
access
parameters
function
error
usual
error_handlers
acces
pooled
functions
parameters
context
argument
context.error_
kw
complete
promise
changes
bit
distance
TODO
new
files
Could
comment
mess
first
place
okay
tests
proper
thing
let
bit
*
please
Defaults
run_async=False
look
other
tests
*
something
python
dp.bot.defaults
Defaults
run_async=True
try
actual
test
dp.bot.defaults
None
defaults
end
test
good
valid
English
dictionary
comment
Please
empty
line
Hmm
class
anything
h1
h6
[
id
]
[
href
]
Let
comments
field
sort
sneaky
wagtail
field
more
liner
python
block-of-string
comment
syntax
python
class
MozfestHomepage
MozfestPrimaryPage
description
class
banner_type
value
particular
banner_type
....
localization
issue
Does
root_path
something
little
worried
user
None
screening_percentile
order
screening
docstring
suggestion
self.screening_percentile_
case
self.screening_percentile
None
way
n_final_features
comments
block
suggestion
comments
example
class
markup
useful
comment
block
blank
line
cv
int
None
check_cv
StratifiedKFold
groups
https
//scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html
sklearn.model_selection.StratifiedKFold.split
@
bthirion
comment
subjects
train
test
Could
docstrings
doc
strings
comment
more
clear
same
comment
above
Update
class
JWS
Fuse
class
docstring
JWS
Fuse
Same
previous
comment
appropriate
documentation
params
returns
method
reusable
component
future
public
api
specific
module
comment
copy
paste
eap.py
Comment
Same
comment
above
same
host
scans
docstring
change
ang
>
specific
module
comment
copy
paste
eap.y
similar
comment
function
little
docstring
arguments
documented
https
//github.com/mozilla/pontoon/commit/4537eac40f36cff404fc36bc9f7a5c4c82b520e8
bug
comment
Handling
different
escape
sequences
mobile
Android
strings
eb5f8d5
data
migration
Translation
model
TranslationMemoryEntry
See
more
details
obvious
code
comment
comment
other
properties
interesting
comment
managers
available
TagsDataTool
properites
Nit
comments
tool
class
name
FilteredDataTool
naming
schema
descendants
comments
*
project_changes
]
entities
DB
string
comment
changes
key
doesn't
*
project_changes
]
entities
*
project_changes
]
entities
DB
project_changes
]
PKs
entities
Q
entities
same
timestamp
sync
Alternative
approach
changed_resources
sources
way
followup
PR
bigger
question
previous
review
fault
mixed
comment
different
cc
mathjazz
Can
comment
with_disabled
thing
default
value
queries
obvious
code
fine
fullest
such
little
used
function
way
comment
comment
clarifying
comment
migration
migration
base.0004
migration
tour.0001
comment
line
nice
e.g
Run
checks
translations
wink
NoCommentsOrSources
need
simple
quotes
dedent
likewise
useless
separate
actions
comment
type
arguments
translation
entity+locale
change
model
validation
migration
changes
lines
good
candidate
[
list
comprehension
]
https
//docs.python.org/3/tutorial/datastructures.html
list-comprehensions
payload
=
[
c.serialize
c
comments
percentages
pointless
sides
accurate
description
code
months
comments
code
intention
%
new
area
code
methods
type
params
docstring
helpful
Might
worth
docstring
test
part
changes
enterprise
catalog
service
easy
Same
suggestion
space
rest
method
role
ENTERPRISE_LEARNER_ROLE
return
rest
Adam
comment
worth
_any_
exception
worth
other
things
Anyway
nuanced
aggressive
end
state
feel
free
nit
unnecessary
waffle
flag/sample
example
same
tuple
waffle
flag
docstring
others
original
docstring
removed
test
e.g
get_course_and_course_run
method
tuple
None
None
content
items
nit
small
thing
test
naming
addition
docstring
explicit
PendingEnterpriseCustomerAdminUser
results
non-admin
customer
user
good
bibtex
reference
relevant
paper
hypre
implementation
one
https
//hypre.readthedocs.io/en/latest/ch-references.html
kova2009
firedrake_citations
Citations
Citations
Kolev2009
BIBTEX
STRING
Citations
.register
Kolev2009
Thanks
comment
OpenSSL
friendly
name
private
key
PKCS12
file
@
ryanpetrello
hacks
credential
module
Hopefully
none
hackery
necessary
inventory
source
module
v1-
>
v2
compatibility
work
%
group
module
playbook
inventory
source
module
v2
inventory
source
v1
verbose
documentation
module
pass-through
parameters
careful
omission
parameters
present
older
versions
Booleans
documentation
/
true
/
false
none
other
possible
forms
Order
wrong
openssl_certificate
other
openssl_cert
comments
separate
PR
Just
quick
comment
booleans
documentation
YAML
true/false/yes/no
suggestion
default
false
action
route
sure
description
points
backup
module
backups
action
plugins
bad
pattern
include_role
sense
role
logging
potential
leak
sensitive
information
data
commands
user
document
return
backup
way
file
location
module
local_action
ansible_connection=local
file
control
machine
module
ansible_connection=ssh
remote
machine
action_plugin
identical
backup
control
machine
comment
iosxr_interfaces
modules
Same
comment
iosx_interfaces
self._task.delegate_facts
more
conditional
pkg_mgr
module
=
facts.get
ansible_facts
.get
ansible_pkg_mgr
auto
uses
parameter
weird
people
list
dictionaries
lot
easier
list
dictionaries
dictionaries
yaml
fixed_ip_assignments
mac
aa
bb
cc
dd
ee
ff
ip
comment
Server
argspec
tldr
marked
private
pair
simple
accessor
functions
read-only
view
data
Example
implementation
bottom
marked
private
reasons
only
implementation
details
framework
easy
changes
implementation
instance
set
data
line
numbers
functions
people
framework
private
public
result
review
comment
review
comment
something
something
solution
public
wrong
things
*
general
things
framework
private
variables
framework
wrong
AnsibleModule
special
something
*
*
term
things
PRs
AnsibleModule
overgrown
god
object
separation
concerns
combination
god
object
process
apart
valid
private
values
pieces
instance
API
deprecated
AnsibleModule
API
private
variables
valid
use
case
*
case
fail_json
/exit_json
style
code
AnsibleModule
code
access
accumulated
warnings
deprecations
new
API
non-legacy
code
access
values
ability
framework
right
implementation
accessor
functions
Accessor
fancy
way
function
value
data
value
corresponding
mutator
function
proper
implementation
accessor
python
_global_warnings
[
]
def
get_warning_messages
tuple
warning
messages
run
program
return
tuple
_global_warnings
get_
prefix
function
name
thing
user
accessor
list
tuple
user
warnings
function
_messages
function
name
leeway
new
function
additional
information
future
dependency
tzlocal
use
UTC
timezone
python
class
UTC
datetime.tzinfo
=
datetime.timedelta
def
utcoffset
dt
return
self.ZERO
def
tzname
dt
return
UTC
def
dst
dt
return
self.ZERO
utc
=
UTC
value
=
datetime.datetime
tzinfo=utc
Example
tzinfo
classes
portion
[
tzinfo
documentation
]
https
//docs.python.org/2/library/datetime.html
tzinfo-objects
example
nice
PEP257
compliant
docstrings
public
interfaces
classes
functions
methods
module
Same
comment
above
Just
other
exceptions
Exception
documentation
individual
exceptions
things
raise
playbook
ie
laurentn-vsim1
run
Code
wit
documentation
documentation
RETURNS
section
expected
output
module
suggestion
Optional
comment
string
sure
something
RETURN
documentation
s/csr/filename
*
add
extendedUsage
module
nxos_linkagg
lib/ansible/modules/network/nxos/nxos_linkagg.py:0:0
E305
DOCUMENTATION.module
valid
value
dictionary
value
@
data
[
'module
]
Got
'nxos_portchannel
Does
quotes
cat
in_path
single
argument
able
quotes
list
2017-03-01
ERROR:312
RETURN
documentation
2017-03-01
ERROR:107
Imports
DOCUMENTATION/EXAMPLES/RETURN/ANSIBLE_METADATA
line
2017-03-01
ERROR:107
Imports
DOCUMENTATION/EXAMPLES/RETURN/ANSIBLE_METADATA
line
See
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
ret.sort
key=lambda
p
p.endswith
'windows
logic
Naming
wise
sockets
socket
comments
comment
failure
message
good
indication
Manager
service
resource
Had
earlier
comments
earlier
comments
Same
comment
Done
Message
case
check
mode
Done
sure
top
module
documentation
documentation
C
whole
point
M
something
link
module
documentation
people
link
link
pretty
moot
Note
imported
functionality
top
module
functionality
case
python
ansible.module_utils.basic
import
AnsibleModule
ansible.module_utils.urls
import
fetch_url
check-mode
support
Check-mode
support
case
possible
actual
message
way
sending
sort
/dev/null
bucket
great
module
credentials
connection
check-mode
sufficient
Ah
inline
comments
FIXME
statement
good
end-user
TBH
Beware
pylint
check
PEP8
long
lines
-/
Webhook
token
validation
text
/dev/null
url/channel
do
text
error
text
bad
webhook
token
Http
error
text
good
webhook
text
check
mode
tag
[
check_mode
]
sent
text
look
error
token
as-is
information
comments
someone
hints
guide
valid
feature-request
Mattermost
way
message
message
Thanks
Most
modules
result
variable
result
information
fail_json
exit_json
module
rekwargs
netconf_config
result
ret
easier
people
same
standard
IMO
Right
check_mode
anything
check_mode
code
implementation
https
//github.com/ansible/ansible/pull/19348/files
diff-473c3ae27a58aa5098bfcf29652164d8R141
solution
authentication
connectivity
credentials
sure
possible
possible
real
thing
example
documentation
true
false
False
best
practice
believe
Explicit
better
implicit
Full
API
documentation
U
https
//developer.ciscospark.com/endpoint-messages-post.htm
note
documentation
getattr
None
suggestion
version
C
cluster-stable
info
command
]
https
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
formatting
options
Good
job
months
documentation
examples
while
reason
inconsistency
..
thanks
+1
*
user
*
documentation
need
implementation
detail
Qalthos
explaining
comment
last
suboptions
options
arguments
support
sorry
broken
record
lots
hazards
future
large
undertaking
good
deal
congruency
_three_
different
forms
configuration
files
inventory
plugin
plugin
tower
tower_host
https
//localhost:8043/
tower_username
admin
tower_password
password1
tower_inventory
tower_verify_ssl
False
tower
modules
key=value
syntax
docs
several
ways
parameters
modules
host
https
//localhost:8043/
username
admin
password
password1
verify_ssl
False
tower-cli
config
[
general
]
host
=
http
//localhost:8013/
verify_ssl
=
=
most
part
environment
variable
keys
painful
inventory
config
format
odd-one
tower-cli
code
YAML
format
modules
free
other
variables
plugin
long
names
inventory
plugin
config
suggestion
Docker
API
>
docker-py
documentation
link
Scaleway
documentation
website
examples
name
comment
Use
multi-line
YAML
See
https
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
examples-block
more
info
big
fan
oneliners
suggestion
other
way
comments
readability
avoid
oneliners
possible
showstopper
state
DOCUMENTATION
default=True
large
change
behaviour
there
justification
dnf
command
line
client
defaults
answer
False
documentation
correct
format
only
documents
common
returns
return
content
variable
e.g
~~~
yaml
RETURN
items
lists
order
importance
people
lists
entry
documentation
generation
order
user
suggestion
choices
[
absent
present
need
quotes
strings
YAML
users
better
understanding
quoting
examples
documentation
integration
tests
Please
seealso
section
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
documentation-fields
suggestion
seealso
name
Documentation
Hetzner
Cloud
API
description
Complete
reference
Hetzner
Cloud
API
link
https
//docs.hetzner.cloud/
lines
untested
keys
[
data
[
'Key
]
page
paginator.paginate
Bucket=bucket
data
page.get
'Contents
[
]
@
ryansb
comment
first
page
state
code
documentation
right
state
absent
runlevel
action
command
program
proccessaction
action
simular
mkitab
command
action
state
comments
YAML
documentation
pretty
sure
tags
azure_tags
documentation
suggestion
Installs
uninstalls
updates
applications
Mac
App
Store
C
mas-cli
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
passwords
byte
strings
UnsafeProxy
extension
wrap_var
byte
strings
fix
py2
py3
py2
bytes
bytes
functionality
something
diff
diff
git
a/lib/ansible/utils/unsafe_proxy.py
b/lib/ansible/utils/unsafe_proxy.py
index
..
a/lib/ansible/utils/unsafe_proxy.py
+++
b/lib/ansible/utils/unsafe_proxy.py
@
@
-53,8
+53,8
@
@
__future__
import
absolute_import
division
print_function
=
type
ansible.module_utils.six
import
string_types
text_type
-from
ansible.module_utils._text
import
to_text
ansible.module_utils.six
import
binary_type
string_types
text_type
ansible.module_utils.common._collections_compat
import
Mapping
MutableSequence
Set
@
@
-69,14
+69,15
@
@
class
AnsibleUnsafeText
text_type
AnsibleUnsafe
pass
+class
AnsibleUnsafeBytes
binary_type
AnsibleUnsafe
+
pass
+
+
class
UnsafeProxy
object
def
__new__
cls
obj
*
args
*
*
kwargs
usage
unicode
strings
conditional
conversion
exists
values
input
isinstance
string_types
obj
=
to_text
errors='surrogate_or_strict
isinstance
binary_type
+
return
AnsibleUnsafeBytes
obj
elif
isinstance
text_type
return
AnsibleUnsafeText
obj
return
behavior
py2
code
due
change
suggestion
plugin
C
group
nodes
group
driver
e.g
digitalocean
more
info
]
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
style
docker_swarm
inventory
plugin
documentation
desirable
plugins
different
approaches
documentation
constraint
sub-options
L179
aggregate=dict
type='list
elements='dict
required_together=required_together
update
comments
ipaddress
line
second
netapp
host
documentation
destination_netapp_hostname
look
notes
documentation
links
environment
variables
FACTSPARAMS
variables
anything
unaware
documentation
generator
use
anything
DOCUMENTATION
Hello
able
documentation
FCNetworkModule
extends_documentation_fragment
oneview
oneview.validateetag
oneview_fc_network_module.rst
file
docs
List
Fibre
Channel
Network
properties
state
<
div
style=
font-size
small
presentabsent
desired
state
Fibre
Channel
Network
resource
<
code
>
present
<
/code
>
data
properties
compliant
OneView
<
code
>
absent
<
/code
>
resource
OneView
validate_etag
<
div
style=
font-size
small
True
ETag
Validation
request
current
ETag
resource
ETag
data
facts
modules
FACTSPARAMS
documentation
documentation
credentials_path
Great
idea
token
account
specificity
comment
random
comments
someone
module
Other
vmware
modules
cluster
cluster_name
nice
consistent
modules
type
conversion
operation
labels
description
labels_state
comments
Same
comment
below
minor
thing
copy-pasta
terminal
CliconfBase
and/or
change
docstring
explanation
TOML
strings
example
fixes
https
//github.com/toml-lang/toml/pull/62
issuecomment-14007822
https
//github.com/toml-lang/toml/issues/105
Let
follow
PEP
docstrings
suggestion
fingerprint
primary
key
Ref
https
//git.gnupg.org/cgi-bin/gitweb.cgi
p=gnupg.git
f=doc/DETAILS
hb=HEAD
l482
DOCUMENTATION
block
RETURN
block
Standard
indentation
YAML
spaces
spaces
description
options
EXAMPLES
nice
DOCUMENTATION
RETURN
block
markup
options
values
resolvers
option
documentation
/etc/resolv.conf
value
C
..
documentation
Please
documentation
block
nested
argument_spec
module
documentation
*
*
suboptions
*
entry
argument_spec
*
*
options
*
key
simple
example
iptables
module
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/system/iptables.py
L541-L545
A
extensive
example
closer
needs
meraki_mx_l3_firewall
module
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/meraki/meraki_mx_l3_firewall.py
L238
Use
argument_spec
list
local_luns
ideal
API
documentation
module
docs
nice
notes
choices
one_child
all_childs
]
algorithm
description
jborean93
results
validation
errors
lib/ansible/modules/cloud/azure/azure_rm_aks.py:0:0
E324
Value
default
argument_spec
None
auth_source
documentation
'auto
lib/ansible/modules/cloud/azure/azure_rm_aks.py:0:0
E324
Value
default
argument_spec
None
cloud_environment
documentation
'AzureCloud
lib/ansible/modules/cloud/azure/azure_rm_aks_facts.py:0:0
E323
append_tags
DOCUMENTATION.options
module
lib/ansible/modules/cloud/azure/azure_rm_aks_facts.py:0:0
E324
Value
default
argument_spec
None
auth_source
documentation
'auto
lib/ansible/modules/cloud/azure/azure_rm_aks_facts.py:0:0
E324
Value
default
argument_spec
None
cloud_environment
documentation
'AzureCloud
documentation
today
update
generic
comment
example
controller
other
examples
name
comment
purpose
requirement
clear
reader
IMO
documentation
fragment
provider
option
docs
Please
type
lines
DOCUMENTATION
block
example
data
lookup
comment
file
control
machine
people
head
new
ansible
contents
arbitrary
file
suggestion
Execute
task
suggestion
Manage
global
lldp
enable
configuration
able
Powershell
requirement
notes
section
visible
example
win_shell
documentation
[
]
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/windows/win_shell.py
lists
example
RETURN
=
msg
description
message
task
result
ok
type
string
sample
Module
PowerShellCookbook
Module
PowerShellCookbook
present
Needs
choices
http
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
documentation-block
problem
docs
documentation
clear
reflective
ok
text
vague/less
descriptive
better
explanation
[
PowerShell\PowerShellGet
]
https
//github.com/PowerShell/PowerShellGet
code
function
Get-LocationString
]
https
//github.com/PowerShell/PowerShellGet/blob/development/src/PowerShellGet/private/functions/Get-LocationString.ps1
uri
]
Uri
.Net
class
[
description
]
https
//docs.microsoft.com/en-us/dotnet/api/system.uri
view=netframework-4.7.2
deeper
weekend
issue
PowerShellGet
module
documentation
explanation
exact
command
Register-PSRepository
code
options
default
callback
plugin
way
other
callback
plugins
note
check_mode_markers
documentation
default
doc
fragment
setting
plugins
update
documentation
plugins
type
option
documentation
block
please
line
only
type
DOCUMENTATION
type
bool
choices
output
comment
incorrect
new
problem
area
return
comment
return
value
new
problem
[
[
'username
'service
]
documentation
port
use
zapi
error
false
case
netapp_utils.zapi.NaApiError
error
Error
denotes
to_native
error.code
return
False
Ahh
thanks
i
most
issue
pull
request
test
nicer
PEP257+PEP8
styled
docstrings
suggestion
Identify
package
manager
available
method
True
package
manager
usable
module
package-specific
implementation
such
check.
big
Exception
specific
JSON-ish
exceptions
try
pass
blah
blah
code
Python
json.decoder.JSONDecodeError
bad
JSON
ValueError
getattr
json.decoder
ValueError
e
module.fail_json
test_do_encrypt
part
passlib
first
part
current
method
one
pytest.skip
Sorry
previous
comments
clear
-/
set
nested
array
@
bcoca
documentation
individual
subkeys
cyberark_session
key
example
data
error
return
Asn
Pool
use
Asn
ASN
comment
few
lines
modules
Could
example
reply
comment
error
Hmm
@
jillr
comment
niggle
Please
add
'options
metric_transformation
definition
typo
jillr
suggestion
Cloudwatch
log
group
metric
filter
use
M
ec2_metric_alarm
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
suggestion
name
CloudWatch
metric
product
name
capitalization
documentation
picky
options
AnsibleModule
able
options
modules
examples
nic_edit
key
<
len
current_net_devices
vm_obj
self.params
'template
]
comment
device
single
line
invalid
YAML
shippable
error
2017-01-18
============================================================================
2017-01-18
lib/ansible/modules/network/avi/avi_api_session.py
2017-01-18
============================================================================
2017-01-18
TRACE
2017-01-18
simple
key
2017-01-18
<
string
>
line
column
2017-01-18
Avi
Controller
2017-01-18
^
2017-01-18
19:04:21
expected
2017-01-18
avi_api_session.DOCUMENTATION
line
column
2017-01-18
choices
put
post
2017-01-18
^
2017-01-18
ERROR
DOCUMENTATION
valid
YAML
Line
column
lines
imports
file
get_aws_connection_info
ec2_argument_spec
camel_dict_to_snake_dict
others
explicit
import
list
try
import
boto3
stay
top
module
wrong
values
other
facts
modules
such
[
ec2_asg_facts
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/ec2_asg_facts.py
few
occasions
lacking
documentation
same
way
documentation
original
documentation
wording
description
need
*
choices
valid
options
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
documentation-block
more
info
descriptions
full
sentences
i.e
capital
letters
fullstops
http
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
documentation-block
options
Hehe
comment
days
fix
documentation
[
documentation
]
http
//docs.ansible.com/ansible/common_return_values.html
stdout
stderr
common
values
modules
module
[
documentation
]
http
//docs.ansible.com/ansible/dev_guide/developing_modules_checklist.html
other
modules
ANSIBLE_METADATA
current
format
C
values
names
options
correct
DOCUMENTATION
block
options
common
DOCUMENTATION
suggestion
few
days
*
utils/module_docs_fragments/digital_ocean.py
*
*
Ansible
Digital
Ocean
utils
PR
generic
configurations
documentation
documentation
fragment
*
*
extends_documentation_fragment
digital_ocean.documentation
*
*
https
//github.com/Akasurde/ansible/blob/devel/lib/ansible/utils/module_docs_fragments/digital_ocean.py
@
Akasurde
new
requirement
quotes
documentation
variable
strings
errant
symbol
quotes
values
Example
doc
block
practice
cases
errant
symbol
parsing
error
@
gundalow
common
documentation
modern
PR
notice
group
Ideas
section
documentation
particular
PR
pg
modules
small
simple
PR
logic
such
data.get
'slug
Exception
handling
cyberarkpassword
lookup
source
loop
documentation
section
addition
comment
usage
documentation
docs/docsite/rst/playbooks_lookups.rst
error
specific
lookup
conjunction
other
modules
features
generic
documentation
today
meeting
lokup
loop
https
https
beneficial
cyberark
vault
confusion
someone
error
reference
ansible
vault
situation
docs
today
freeze
formatting
docs
docs/docsite/rst/playbooks_lookups.rst
time
forth
@
dharmabumstead
right
lot
lookups
page
single
example
section
end
section
detail
bcoca
ability
documentation
plugins
ansble-doc
website
release
in-plugin
documentation
mind
documentation
playbooks_lookups.rst
call
block
[
try
]
https
//docs.python.org/2/tutorial/errors.html
handling-exceptions
appropriate
try
tempfile.NamedTemporaryFile
outf
outf.close
[
]
IOError
OSError
e
module.fail_json
module.atomic_move
outf.name
path
atomic_move
IOError
OSError
atomic_move
method
Same
comment
previous
PRs
Use
documentation
fragment
Use
simpler
line
wrapping
comment
function
VM
something
get_vm_or_template
docstring
DOCUMENTATION
docs
type
bool
choices
C
C
high
performance
documentation
alias
documentation
environment
standard
python
environment
object
Same
comment
previous
PRs
concatenation
logic
same
object_to_string_new
comma
end
loop
empty
string
pop
last
comma
output.pop
.join
output
keys
values
DOCUMENTATION
block
//api.digitalocean.com
*
valid
cert
comment
field
Desired
state
different
primary
key
difference
easy
self.comment
None
IIRC
M
cyberark_authentication
cyberark_authentication
module
documentation
Please
connection
type
link
platform
guide
extends_documentation_fragment
resource
module
documentation
lookup
aws_profile
boto_profile
alias
documentation
fragment
access
mock
mocker
fixture
comment
lower
code
problem
changes
URL
WORLD_READABLE_TMPFILES
message
lower
down
Same
comment
previous
PRs
Purely
cosmetic
constant
comment
years
second
chance
user
comment
comment
log
example
output
debug
argument_spec
docker_common
point
parameter
output
file
debug.log
development
Check
docker_common
log
method
print
operations
local
environment
debug-option
documentation
purpose
Will
comments
docs
fragment
yes
values
state
module
present
absent
sense
module
https
//github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/cloudstack/cs_account.py
L343
module
API
many
cases
more
simple
intuitive
separate
param
matrix
functionality
~~~
resource
netscaler_service
state
present
true
~~~
~~~
resource
task
resource
netscaler_service
state
disabled
~~~
default
description
https
//docs.ansible.com/ansible/dev_guide/developing_modules_documenting.html
documentation-block
module
initial
code
documentation
NITRO
API
access
Netscaler
minimum
length
verbatim
copy
NITRO
API
documentation
option
imports
DOCUMENTATION
EXAMPLES
RETURN
strings
data
module
code
possible
wildcard
imports
ansible.module_utils.basic
import
*
imports
specific
things
ansible.module_utils.basic
import
AnsibleModule
acceptable
description
anything
choices
documentation
e.message
Python3
cases
module
AnsibleAWSModule
fail_json_aws
call
exception
Should
BotoCoreError
boto3
try
call
BotoCoreError
ClientError
e
pass
exception
first
argument
message
response
available
module.fail_json_aws
e
msg=
Optional
custom
error
message
lifecycle
configuration
msg
weight
option
comment
Add
key
default
global
description
part
argument
spec
exception
side
effects
@
willthames
last
task
test
suite
second
time
task
devel
long
time
fails
exception
things
side
note
state
absent
something
False
failure
unrelated
changes
point
module
possible
case
better
retry
decorator
find_address
specific
problematic
error
code
function
re-raise
other
exceptions
decorator
operation
lines
AWSRetry.jittered_backoff
def
find_address
ec2
module
public_ip
device_id
is_instance=True
try
addresses
ec2.describe_addresses
*
*
kwargs
is_boto3_error_code
Bypass
retry
logic
retry
decorator
module.fail_json_aws
e
msg=
list
Elastic
IP
addresses
find_address
BotoCoreError
ClientError
retry
failures
docs
AWS
acceptable
values
DOCUMENTATION
module
state
required
=
True
module
anything
option
expected
functionality
option
extra
dependency
requirements
section
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
documentation-block
nice
requirment
documentation
Note
requirment
size
parameter
user
access_modes
example
Please
connection
type
link
platform
guide
extends_documentation_fragment
resource
module
documentation
raw
string
r
failing
doc
sanity
check-
otherwise
C
\Users
Unicode
hex
literal
agenda
London
confident
plan
implementation
Exciting
windowsfeature
example
integration
tests
section
honest
complete
section
documentation
DSC
real-life
examples
main
bulk
people
Ansible
Windows
full
library
common
tasks
alternatives
Unix
modules
welcome
users
examples
annotate
documentation
https
//groups.google.com/forum/
topic/ansible-devel/ba4dL-YkMiA
only
thing
Powershell-based
module
order
check
mode
check_mode
parameter
parse-args
module
documentation
Roughly
mode
test-targetresource
DSC
function
would-be
result
set-targetresource
function
change
open
improvements
able
separate
doc
page
@
nitzmahone
meantime
suggestions
thanks
documentation
mismatch
actual
module
behavior
param
documentation
Name
much
valid
parameter
dsc
resource
parameter
name
RETURN
documentation
comment
get_config
flags=None
flags
value
get
configuration
command
appropriate
docker
API
documentation
docker-py
code
information
minimal
API
levels
options
[
API
documentation
]
https
//docs.docker.com/engine/api/v1.25/
operation/NetworkCreate
[
API
documentation
]
https
//docs.docker.com/engine/api/v1.26/
operation/NetworkCreate
docker-py
source
code
aliases
available
standard
name
sure
function
ie
display_name=dict
type=
str
aliases=
name
]
foo
=
module.params
[
display_name
]
foo
display_name
name
documentation
module
links
necessary
suggestion
description
Host
Zabbix
Triggers
problem
state
trigger
event
objects
API
documentation
zabbix
version
comment
valid
https
//github.com/ansible/ansible/pull/59048
issuecomment-511038554
general
purpose
public
utility
function
private
time
least
comment
permanent
public
playbook
snippet
name
Debug
ec2_eni
module
hosts
vars
NB
subnets
same
IP
ranges
different
VPCs
first_subnet_id
subnet-id-1
>
second_subnet_id
subnet-id-2
>
tasks
name
first
ENI
ec2_eni
subnet_id
private_ip_address
description
First
ENI
state
present
register
first_eni
name
second
ENI
ec2_eni
subnet_id
description
Second
ENI
private_ip_address
state
present
name
first
ENI
eni_id
ec2_eni
eni_id
[
'interface
]
[
'id
]
subnet_id
delete_on_termination
source_dest_check
name
second
ENI
subnet_id
private_ip_address
ec2_eni
subnet_id
private_ip_address
description
Second
ENI
required_together
constraint
bbe47b5
otherwise
Detach
ENI
instance
ec2_eni
eni_id
eni-xxxxxxx
instance_id
None
state
present
bit
one
example
format
own
local
test
block
notice
non-IPs
problem
*
*
work
sooner
*
*
anything
important
suggestion
great
typical
use
*
.mycorp.internal,198.51.100.15:12345
.internalservice
sure
more
robust
mamoth
block
sure
best
idea
documentation
pages
Please
type
documentation
check_args
import
above
comment
neighbors
results
none
documentation
ansible_net_neighbors
value
suggestion
Fns
liner
comment
function
output
more
documentation
normalize_interfaces
user
input
redundant
running-config
interface
names
L38-L40
Ansible
module
documentation
ranges
docs
User
documentation
valid
values
comment
.do_template
native
Same
review
comment
short_description
documentation
string
float
real
problem
best
practice
rajaspachipulusu17
Thanks
PR
last
PR
comment
state
param
mandatory
param
module
other
param
mandatory
True
respective
module
function
same
comments
FQCN
collection-based
module
same
comment
collection/fqcn
etc
protocol_mappers
more
explicit
arbitrary
dict
direct
documentation
specific
validation
argument
new
guidelines
number
http
//docs.ansible.com/ansible/devel/dev_guide/developing_modules.html
should-you-develop-a-module
comparisons
such
kind
usage
felixfontein
documentation
NONE
Dockerfile
parent
configuration
list-items
lines
documentation
need
section
program
TODO
rule
has_rule_description
full
reasons
other
comment
argspec
documentation
default
switch
comment
suggestion
untouched
purged_vars
C
false
purged_vars
C
true
booleans
true
/
false
/
documentation
Use
options
C
values
parameters
accessible
documentation
msg
module
failures
success
description
wrong
msg
standard
return
values
module
return
value
documentation
Simply
whole
msg
block
api_url
api_token
extends_documentation_fragment
component
name
minimum
version
documentation
text
Hmm
ROLLBACK_COMPLETE
return
same
manner
reason
sure
list
possible
states
http
//docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-describing-stacks.html
w1ab2c15c17c21c13
comment
states
spacing
fault
Note
syntax
python-2.7
greater
.format
positions
cmd
+=
uuid
more
pythonic
single
string
instance
cmd
=
cmd
uuid
=
'.join
cmd
uuid
compatible
python
less
.format
.join
method
percent
formatting
cmd
=
%
s
%
s
%
cmd
uuid
suggestion
tls
description
Use
TLS
false
tls_verify
description
TODO
false
key_path
description
TODO
false
cacert_path
description
TODO
false
cert_path
description
TODO
false
ssl_version
description
TODO
false
tls_hostname
description
TODO
false
Part
code
TLS
support
ListTopics
[
paginator
]
https
//boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sns.html
SNS.Paginator.ListTopics
problem
colon
whole
thing
>
>
DOCUMENTATION
=
>
>
import
yaml
>
>
>
docs
=
yaml.load
DOCUMENTATION
>
>
opt
docs
[
'options
]
print
opt
type
docs
[
'options
]
[
opt
]
username
<
type
'dict
>
elasticsearchsettings
type
'dict
>
servername
<
type
'dict
>
dynamodbsettings
type
'dict
>
serviceaccessrolearn
<
type
'dict
>
kmskeyid
<
type
'dict
>
dmstransfersettings
type
'dict
>
enginename
<
type
'dict
>
password
<
type
'dict
>
<
type
>
<
type
>
wait
<
type
'dict
>
certificatearn
<
type
'dict
>
tags
type
'dict
>
endpointtype
<
type
'dict
>
state
<
type
'dict
>
externaltabledefinition
<
type
'dict
>
<
type
>
<
type
>
sslmode
<
type
'dict
>
mongodbsettings
type
'dict
>
kinesissettings
type
'dict
>
s3settings
type
'str
>
better
name
forti_device
module_utils/fortios.py
type
better
AnsibleFortios
availability
dependency
pyfg
Typo
module
duplication
functionality
lookup
plugin
module
lookup
plugin
module
documentation
A
few
days
*
utils/module_docs_fragments/digital_ocean.py
*
*
Ansible
Digital
Ocean
utils
PR
generic
configurations
documentation
documentation
fragment
*
*
extends_documentation_fragment
digital_ocean.documentation
*
*
https
//github.com/Akasurde/ansible/blob/devel/lib/ansible/utils/module_docs_fragments/digital_ocean.py
niggle
suggestion
description
action
start
stop
state
machine
execution
Descriptions
https
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
documentation-block
suggestion
Name
command
same
string
problem
Check
line
comment
storage
domain
unattached
skip
step
question
yesterday
function
necessary
playing
ansible
example
body
[
user
foo
[
password
bar
@
|
M
]
[
submit
Sign
]
[
'user
]
[
'password
@
|
M
]
[
'submit
]
Which
urlencode
list
tuples
case
Please
add
documentation
function
urlencode
self.get_option
os.getenv
documentation
first
line
description
parameter
subsequent
lines
more
detailed
information
values
timezone
description
timezone
name
Time
zone
names
L
TZ
database
https
//en.wikipedia.org/wiki/List_of_tz_database_time_zones
timezone
name
case
sensitive
descriptions
upper-case
trailing
dot
exception
short_description
dots
documentation
index
suggestion
Wrapper
function
var
sources
dict
call
combine_vars
notes
VarsWithSources
docstring
caveats
limitations
source
__init__
signature
dict-compatible
ther
workaround
instance
problem
easier
wrokarounds
right
*
Set
sources
method
best
sources
something
object
*
Use
special
name
keyword
arg
chance
conflicts
best
chance
someone
conflicting
key
line
route
aware
Python2
flexible
Python3
Works
Python3
Python2
def
mine
*
args
__ansible_DEADBEEF64_source=
*
*
kwargs
print
args
print
__ansible_DEADBEEF64_source
print
kwargs
mine
mine
mine
data='test
mine
data='test
user
mine
data='test
user
special
variable
kwargs
compatible
Python2
suggestion
def
__getitem__
key
notes
VarsWithSources
docstring
caveats
limitations
Cosmetic
suggestion
Alternate
constructor
class
sources
bit
informative
method
suggestion
val
=
self.data
[
key
]
See
notes
VarsWithSources
docstring
caveats
limitations
source
change
argspec
docstrings
suggestion
DOCUMENTATION
=
r
suggestion
EXAMPLES
=
r
elasticache
key
info
exit_json
changed=
[
]
*
*
camel_dict_to_snake_dict
response
usage
elasticache_snapshot
[
args
]
register
snapshot_info
debug
var=snapshot_info.elasticache
[
things
debug
var=snapshot_info
[
things
facts
modules
sense
returns
namespace
user
register
comment
_get_item_label
end
colon
code
comment
Similar
local
connection
comment
python
ansible.module_utils._text
import
to_native
[
]
def
enable_ds
module
array
Enable
Directory
Service
try
array.enable_directory_service
=
True
Exception
e
module.fail_json
msg='Enable
Directory
Service
configuration
%
s
%
to_native
module.exit_json
thing
sure
array.enable_directory_service
change
users
Ansible
idempotence
*
state
playbook
task
module
state
match
playbook
module
returns
something
desired
state
changed=False
state
code
first
last
one
sure
array.enable_directory_service
specifc
exception
directory_service
specific
exception
set
changed=True
status
code
change
current
state
toggle
toggle
changed=False
module.exit_json
toggle
array.enable_directory_service
changed=True
module.exit_json
notes
changes
other
verbs
module
disable_ds
delete_ds
create_ds
comment
specific
frameworks
C
java
Use
documentation
fragment
extends_documentation_fragment
influxdb
required=True
DOCUMENTATION
comment
bit
useful
effect
change
suggestion
Append
ansible_collections
dirs
sys.path
end
collection
loader
Python
modules
Python
packages
PyPI
similar
indexes
users
Python
content
dists
PEP
Implicit
Namespace
Packages
conventions
Refs
*
https
//packaging.python.org/guides/packaging-namespace-packages/
*
https
//packaging.python.org/guides/creating-and-discovering-plugins/
using-namespace-packages
*
https
//setuptools.readthedocs.io/en/latest/setuptools.html
namespace-packages
*
https
//setuptools.readthedocs.io/en/latest/setuptools.html
find-namespace-packages
SECURITY
CONSIDERATIONS
place
Python
code
clear
users
places
modules/plugins
NOTE
possible
broken
namespace
package
NOTE
user
ability
NOTE
other
Python
packages
namespace
line
lines
path
search
pat
option
get_bin_path
fallback
present
[
Ansible
developer
documentation
]
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
options
suggestion
Time
UTC
relative
timespec
valid_from
valid_to
sorry
reason
comment
EXAMPLES
r
\
Standard
practice
module
doc
blocks
r
escape
r
\
string
PEP257
docstrings
pytest-mock
]
https
//docs.pytest.org/en/latest/monkeypatch.html
Pytest
I/O
file
descriptors
way
closer
unnecessary
patching
logic
[
fixture
warnings
]
https
//docs.pytest.org/en/latest/warnings.html
[
capsys
]
https
//docs.pytest.org/en/latest/capture.html
accessing-captured-output-from-a-test-function
variations
end
test
suggestion
ansible.playbook.collectionsearch
import
CollectionSearch
import
pytest
def
test_collection_static_warning
capsys
Test
collection
name
sure
users
warning
message
referenced
name.
cs
CollectionSearch
bar
cs._load_collections
None
[
'foo
bar
]
std_out
std_err
=
capsys.readouterr
assert
[
WARNING
]
collections
templatable
foo
bar
\n
==
std_err
_
DISCLAIMER
browser
UI
button
typos
name
plural
fact
parse_to_logical_rows
generator
logical
row
loop
iteration
explicit
loop
generator
name
good
explanation
list
comprehension
comment
line
kinda
idiomatic
Python
way
L
name
url
Examples
L
UCS
Platform
Emulator
https
//communities.cisco.com/ucspe
documentation
pleasing
balance
elaborate
documentation
bug
parser
doc
site
bug
other
option
description
context
instance
documentation
AnsibleModule
following
different
validation
options
main
module
=
AnsibleModule
argument_spec=dict
state=dict
default='present
[
'present
'absent
]
username=dict
type='str
password=dict
no_log=True
token=dict
no_log=True
priority=dict
type='int
'password
]
[
'username
'password
]
required_one_of=
[
[
'password
]
]
required_if=
[
'state
'present
[
'src
'priority
]
]
supports_check_mode=True
continue
match
need
other
matches
default
need
documentation
better
link
documentation
data
types
PEP
suggestion
Return
possibly
file
consumable
plugin
ref
https
//www.python.org/dev/peps/pep-0257/
Ah
overridable
subclasses
....
subclasses
able
staticmethod
regular
method
difficulty
method
staticmethod
pylint
warning
comment
method
method
subclasses
class
name
Please
update
generic
comment
valid
document
entry
same
comment
Default
default
value
documentation
string
same
comment
applies
name
check_
*
methods
exceptions
AnsibleModule
counterparts
listing
functions
caller
failure
useful
caller
list
end
exception
failure
access
exception
list
doc
fragment
duplication
https
//github.com/ansible/ansible/blob/devel/lib/ansible/utils/module_docs_fragments/zabbix.py
yaml
extends_documentation_fragment
zabbix
nice
validate_certs
option
zabbix_host
module
details
module
parameters
type
documentation
one
state
type
str
line
long
name
key
solution
things
action
name
key
most
explanation
comment
current
comment
shorter
comment
name
statement
honest
most
comment
previous
example
same
way
example
examples
rid
creates=
example
legacy
notation
much
first
example
list
>
exit
singular
sure
improvement
explanation
'args
Maybe
comment
readline
docs
future
obvious
code
suggestion
wrap_nonvisible_chars
comment
key
module
options
i.e
idempotency
note
function
suggestion
Test
path
mount
point
copy
upstream
version
ismount
workaround
Python
issue
older
versions
Python
upstream
fix
https
//github.com/ansible/ansible-modules-core/issues/2186
http
//bugs.python.org/issue2466
difference
state
present
state
update
little
strange
name
Change
role
type
user
purefa_user
name
ansible
role
storage_admin
state
present
<
fb_url
api_token
e31060a7-21fc-e277-6240-25983c6c4592
name
Change
role
type
user
purefa_user
name
ansible
role
storage_admin
state
update
fb_url
api_token
e31060a7-21fc-e277-6240-25983c6c4592
Uma
ideia
importante
é
pegar
o
diretório
temporário
chamada
uma
função
Python
invés
Use
essa
rotina
descrita
aqui
https
//stackoverflow.com/a/43418319/2698109
em
um
método
Eu
acredito
que
podemos
usar
um
bulk_create
aqui
Assim
suggestion
pautas
=
[
]
materia
MateriaLegislativa.objects.filter
id__in=marcadas
pauta
=
PautaReuniao
pauta.reuniao
=
reuniao
pauta.materia
=
materia
pautas.append
pauta
PautaReuniao.objects.bulk_create
pautas
vantagem
desse
método
é
que
se
forem
pautas
ao
invés
comandos
INSERT
BD
será
realizado
somente
um
comando
com
entradas
Mais
eficiente
e
consistente
ou
tudo
é
inserido
ou
nada
é
inserido
Me
causa
uma
certa
estranheza
termos
dois
um
elemento
em
file_extraction
que
ser
concatenadas
lá
frente
Parece
uma
forma
que
já
existe
com
o
novo
método
ta_extraction
este
sim
que
retorna
uma
lista
valores
Não
o
caso
string
extraída
em
file_extraction
e
daí
em
ta_extraction
fazer
o
join
e
uma
string
como
abaixo
r
+=
list
filter
lambda
x
x.strip
return
'.join
r
Daí
precisa
que
data
seja
um
array
basta
ser
uma
string
mesmo
E
o
final
extract_data
ficaria
algo
assim
data
+=
self.ta_extraction
value
return
data
Neste
caso
homogeiniza-se
o
contrato
os
Isto
é
devem
retornar
uma
string
texto
plano
que
será
indexada
WDYT
documentation
ONLY
registration
x
coordinates
@
neuromusic
assumption
users
FISH
data
misalignment
z-axis
correct
sure
python
dictionary
iteration
same
order
insertion
implementation
detail
mandatory
multiple
runs
code
different
orders
keys
list
CropParameters
python
language
level
edict
python
comment
complexity
minutes
way
round_to_z
Could
comment
alignment
y
x
same
alignment
z
confused
general
comment
useful
method
other
places
suggestion
def
_harmonize_enum
iterable
Iterable
[
Axes
]
>
Iterable
[
str
]
wisdom
person
[
comment
]
https
//github.com/spacetx/starfish/pull/647
discussion_r220971185
suggestion
def
_decode_numpy_array_to_numpy_array
array
naked
numpy
arrays
subprocesses
work
array
py
method
_decode_array_to_numpy_array
example
decoding
necessary.
suggestion
def
_decode_wrapped_array_to_numpy_array
wrapped_array
>
np.ndarray
numpy
array
memory
buffer
care
documentation
new
glossary
kevinyamauchi
max
>
np.amax
consistent
stated
functionality
documentation
getattr
code
special
cased
logical
discontinuity
documentation
physical
coordinates
correct
name
bit
tiles
filter_tiles
filter=None
bit
clearer
setter
self._data
attribute
property
comment
contributors
sure
code
Matlab
indexing
Python
indexing
Matlab
user
image
stack
creation
clear
documentation
indexing
suggestion
columns
r
ch
zplane
fovs
=
[
suggestion
<
https
//imagej.net/docs/guide/146-30.html
fig
The-ROI-Manager
>
_
ImageJ
FIJI
documentation
suggestion
pixel
value
rounds
channels
corresponding
target
gene
Contiguous
pixels
same
target
gene
RNA
molecule
pixel
vectors
codebook
euclidean
distance
pixel
vector
codewords
minimal
distance
gene
target
distance_threshold
code
suggestion
below
plot
aggregates
gene
number
single
cells
field
view
results
counts
MERFISH
paper
Note
Starfish
detects
lower
number
transcripts
authors
results
parameters
algorithms
suggestion
below
algorithm
point
spread
function
PSF
microcope
goal
deconvolution
resolution
more
spots
high
transcript
density
regions
data
assay
PSF
isotropic
gaussian
standard
deviation
sigma
number
iterations
important
parameter
careful
optimization
params
description
params
types
documentation
standard
style
typing
actual
function
declaration
styling
defaults
styling
defaults
earlier
PRs
defaults
earlier
comments
code
dense
worth
comments
suggestion
print
Gaussian
Low
Pass
namedtuple
data
type
TODO
experiment.json
docstring
dict
3-tuples
start
stop
step
indices
bit
clunky
least
able
one
i
guess
uniform
sub-sampling
xr.full_like
great
opportunity
long
docstring
API
error
work
confusion
worth
way
snip
comments
great
artist
Someone
chars
RFC
better
name
attr
inline
comment
results
SyntaxError
reference
forwarded_for
bit
unwieldy
Args
section
bottom
docstring
prose
sections
private
method
perfect
docstring
imperative
i.e
_Compile_
sentence
full
stop
period
functionality
create_http_method_map
breaking
change
issue
minor
point
release
new
function
map_http_methods
lieu
create_http_method_map
api.py:348
note
docstring
create_http_method_map
future
release
new
methods
conditional
suggestion
labels
[
label
label
ica.labels_
label.startswith
'ecg
sort
index
labels.sort
key=lambda
l
l.split
'/
:2
]
[
-1
]
logic
scikit-learn
documentation
>
logic
validation
parameters
corresponding
logic
parameters
fit
Check
loc
legal
location
MPL
subordinate
axes
something
noun
headline
please
@
larsoner
ok
h5py
externals.pymatreader
import
read_mat
read_mat
following
error
upstream
software
mat
file
type
version
python
/Users/rluke/Library/Python/3.7/lib/python/site-packages/scipy/io/matlab/mio.py:72
mat_reader_factory
mjv
get_matfile_version
byte_stream
def
get_matfile_version
fileobj
Return
major
minor
tuple
apparent
mat
file
type
return
ret
>
raise
ValueError
'Unknown
mat
file
type
version
%
s
%
s
%
ret
E
ValueError
Unknown
mat
file
type
version
suggestion
Reader
continuous
wave
SNIRF
data
..
note
standalone
Notes
section
true
event_id
dict
last
comment
epochs
different
event_id
keys
forbidden
ie
concatenate_epochs
[
epochs
[
'condition1
]
epochs
[
'condition2
]
Unless
different
event_id
keys
same
value
check
nitpick
EEGMEG
>
EEG/MEG
EEG+MEG
M/EEG
Prior
comment
periods
titles
warning
offending
line
possible
comment
scope
examples
@
agramfort
[
prior
comments
https
//github.com/mne-tools/mne-python/pull/4332
issuecomment-318177300
comment
please
refactor
_on_missing
msg
instances
forward
epochs
montage
same
pattern
NumPy
naming
least
subset
raise/warn/ignore
least
docstring
code
raise/error
painless
backward
compat
raw_csd
csd_evo
consistent
suggestion
evoked_csd
=
mne.preprocessing.compute_current_source_density
suggestion
=
mne.preprocessing.compute_current_source_density
@
alexrockhill
examples
one
comprehensive
plot_csd.py
anything
more
data
same
BVEF
file
read_montage
scaling
step
https
//github.com/mne-tools/mne-python/blob/d75bce15717ee4cbf2abbdb5c6e5148959000a91/mne/channels/montage.py
L337-L345
error
few
BrainVision
datasets
coordinates
section
tricky
step
recording
actual
hardware
couple
days
suggestion
meters
unit
auto
please
comment
comment
other
comment
Docstrings
imperative
mood
helper
_
raw
object
single
line
fit_params.setdefault
False
short
comment
magic
number
Maybe
comment
else
branch
corresponds
Surround
+
spaces
dot
files
]
[
-3
]
comment
pathlib
file
stem
extension
string
slicing
pathlib
better
replacement
os.path
separate
PR
visualization
support
ecog
right
source-level
stuff
AFAIK
issue
comment
something
PySurfer
data
Gitter
policy
avoid
unnecessary
cosmetic
changes
PRs
docstring
cross-reference
matplotlib.figure.Figure
sense
table
contents
top
long-ish
tutorial
private
type
suggestion
raise
TypeError
type
Brain
bit
wrong
commits
rebase
_test_raw_reader
changes
pandas
necessary
b
[
'birthday
]
wrong
Oh
comment
group_by
docs
comment
scalings.keys
units.keys
line
data
good
np.abs
sci
value
appropriate
np.corrcoef
-1
<
=
<
=
computation
something
meaningful
specific
data
quality
np.abs
sci
something
appropriate
test
line
RuntimeWarning
test
warning
test
sure
problem
comment
vars
self.mne.ax_list
=
axes
magic
things
lot
https
//21544-1301584-gh.circle-artifacts.com/0/dev/generated/mne.preprocessing.regress.html
mne.preprocessing.regress
TOC
document
sections
new
section
description
preparatory
steps
same
level
artifacts
regression
structure
end
code
inline
comment
front
comment
NumpyDoc/autodoc
params
target
Sphinx
warnings
errors
/home/circleci/project/mne/io/egi/egimff.py
docstring
mne.read_evokeds_mff:11
WARNING
py
obj
reference
target
condition
/home/circleci/project/mne/io/egi/egimff.py
docstring
mne.read_evokeds_mff:48
WARNING
py
obj
reference
target
fname
/home/circleci/project/mne/io/egi/egimff.py
docstring
mne.read_evokeds_mff:51
WARNING
py
obj
reference
target
fname
/home/circleci/project/mne/io/egi/egimff.py
docstring
mne.read_evokeds_mff:54
WARNING
py
obj
reference
target
fname
double-backticks
code
assert
statements
optimized
mode
internal
checks
true
active
comments
shapes
sizes
types
suggestion
_check_option
'condition
category
categories
*
if/else
invalid
category
names
mff.epochs
category
]
informative
error
full
block
text
inline
comments
Make
sure
docstrings
guide
clear
changes
contributing
guide
python
curry
need
comment
Add
XXX
.ceo
test
suit
docstring
Better
Array
integers
current
selection
property
user
function
original
docstring
cleaner
picks_all
short
clean
rid
docstring
date
list
local
import
renderer
test
better
control
backends
function
get_3d_backend
valid
backends
list
VALID_3D_BACKENDS
default
None
suggestion
def
test_get_3d_backend
Test
get_3d_backend
private
function
call
side-effects
Test
twice
first
call
side-effect
mne.viz.backends
import
renderer
backend_name
=
renderer.MNE_3D_BACKEND
assert
renderer.get_3d_backend
backend_name
assert
renderer.get_3d_backend
backend_name
code
anyhow
i
good
way
KIT
files
comments
io.rst
import
channel
names
different
FieldTrip
MNE
Python
extent
reliable
way
information
agramfort
rank
XXX
same
rank
int
None
|
dict
|
'info
|
'full
description
people
details
Travis
[
docstring
]
https
//travis-ci.org/mne-tools/mne-python/jobs/279898713
L3080
please
mne.datasets.hf_sef
list
[
]
https
//github.com/mne-tools/mne-python/blob/master/mne/tests/test_docstring_parameters.py
L27
Insert
blank
line
comment
import
good
idea
assert
statements
users
python
Better
event_desc.ndim
=
raise
ValueError
shape
%
s
%
event_desc.shape
fine
assert
code
tests
pytest
nice
things
use
assert
statements
code
dev
things
true
/
users
kind
active
comments
explicit
ix
dimensionality
y
explicit
call
e.g
y.shape
]
import
numbers
isinstance
self.estimator
numbers.Real
robust
np.int32
example
Please
docstrings
kind
comment
general
plasma
class
design
issue
sort
thing
Note
suggestion
Abstract
class
fit
functions
math
f
x
tools
function
set
data.
suggestion
def
simple_docstring
x
float
y
float
>
float
A
simple
docstring
return
x
+
y
@
staticmethod
def
complex_docstring
x
float
y
float
>
float
intent
more
clear
something
names
Ah
setting
sorry
complexity
CollectMultipleMetrics
number
different
outputs
metrics
files
same
directory
worth
comment
output
specification
Snakefile
first
output
file
os
import
path
=
path.join
path.dirname
snakemake.output
]
snakemake.wildcards.sample
suggestion
conversion
Int
Float
something
literal
eval
import
import
re
def
unescape
st
str_re
=
re.compile
r
P
<
slash
>
\\\\
|
P
<
dq
>
\\
P
<
>
\\
|
\\x
P
<
x
>
[
0-7
]
[
0-9a-fA-F
]
|
\\u
P
<
u
>
[
0-9a-fA-F
]
|
\\U
P
<
U
>
[
0-9a-fA-F
]
|
P
<
\\n
|
P
<
t
>
\\t
|
P
<
r
>
\\r
re.X
=
'\\
'\t
'\n
r
def
cb
m
g
=
m.lastgroup
try
return
subs
g
]
KeyError
pass
return
chr
int
m.group
g
return
str_re.sub
cb
st
=
\u0062
\U00001234
>
\
<
\\
\
\
\r
asd
print
x
print
unescape
x
print
ast.literal_eval
f
training
job
CPU
instance
Will
comment/link
Docstrings
method
Seems
early
commit
Eric
[
PEP
]
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
times
joy
one-liner
add
comment
lock
one
https
//github.com/aws/sagemaker-python-sdk/blob/master/tests/integ/test_local_mode.py
L31
nit
add
docstrings
functions
fill
Same
comment
SplitterFactory
nitpick
extra
newline
docstrings
file
please
comment
translate
function
bytearray
non-utf8
characters
doc
comment
clearer
buf
contains
binary
data
Returns
true
buf
non-utf-8
characters
Args
buf
bytes
data
Returns
True
data
binary
False
pylint
check
]
https
//devbuildsagemakerpythonsdkstackpdx-sage-buildlogs-1vw05gzut3ch7.s3.amazonaws.com/8f3c333d-8cd9-427c-bda1-0e34186e8972/build.log
AWSAccessKeyId=ASIASCMSNBKC2Y2WT27Y
Signature=a0gjPkOf02f9cQQGRXNjma69srA
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
Expires=1563898496
module
sorry
back
forth
suggestion
Tools
code
updates
docstring
Raises
section
+1
nice
examples
stronger
test
py
EDGE_SETS
=
[
edge
sets
@
pytest.mark.parametrize
'edges
[
perm
edges
EDGE_SETS
perm
itertools.permutations
edges
def
test_top_sort
edges
tr
Trace
n1
n2
edges
tr.add_edge
n1
top_sort
=
tr.top_sort
nodes
expected_nodes
=
n1
n1
n2
edges
n2
n1
n2
edges
top_sort
==
expected_nodes
top_sort
==
edge
ordering
ranks
=
n
rank
rank
n
enumerate
top_sort
n1
n2
edges
assert
rank
[
n1
]
<
rank
[
n2
]
environment
variable
idiom
'CI
os.environ
idiom
notebook
tutorials
difficult
command
line
arguments
script
tutorials
argparse
pass
options
script
test
test_examples.py
smoke_test
=
little
parser
version
check
__name__
__main__
assert
pyro.__version__.startswith
parser
=
argparse.ArgumentParser
description=
Toy
mixture
model
parser.add_argument
-n
num-steps
default=4000
type=int
=
parser.parse_args
main
args
plumbing
args
test_examples.py
add
num-samples=1
invocation
Hmm
MMD
plate
slices
valid
models
guides
nontrivial
dependency
structure
objective
InfoVAE
paper
InfoVAE
graphical
model
latent
variables
model
independent
correct
general
particle
dimension
batch
dimension
suggestion
=
independent_model_site
fn
]
model_samples
=
[
'value
]
model_samples
model_samples.transpose
-model_samples.dim
particle_dim
=
model_samples.view
model_samples.shape
]
-1
similar
guide_samples
correct
objective
probabilistic
program
big
black
box
internal
structure
one
InfoVAE
paper
general
algorithm
MMD
computation
arbitrary
graphical
models
mean-field
guides
available
conditional
independence
structure
model
InfoVAE
objective
trivial
special
case
kernels
Markov
blankets
model
individual
variables
similar
[
message-passing
algorithm
Stein
variational
gradient
descent
]
https
//arxiv.org/abs/1711.04425
message-passing
algorithm
Jensen-Shannon
divergences
neural
density
ratio
estimators
https
//arxiv.org/abs/1612.05048
way
scope
PR
fact
general
case
nice
paper
Note
@
fritzo
[
new
backend
Pyro
]
https
//github.com/pyro-ppl/funsor
such
algorithms
easier
ready
few
months
info_vec
precision
reshape
info_vec
good
solution
likes
def
find_unbroadcasted_new_shape
shape
unbroadcasted_shape
new_shape
return
expand_shape
unbroadcasted_new_shape
info_vec
work
Gaussian.reshape
operator
Btw
PR
example
performance
needs
docstring
description
hypernet
note
[
raw
strings
]
https
//docs.python.org/3/reference/lexical_analysis.html
string-and-bytes-literals
double
backslashes
single
backslashes
Feel
free
py
r
math
\sigma
small
docstring
condition
nit
plural
name
comment
dictionary
mapping
name
value
form
name
tensor
dimension
tensor
particles
I.e
struct
arrays
nice
easy
use
pytest
something
def
check_model
backend
name
get_model
=
MODELS
[
name
]
pyro_backend
backend
def
main
args
name
MODEL
check_model
args.backend
name
tests/pyro/generic/test_testing.py
import
MODELS
check_model
import
pytest
@
pytest.mark.parametrize
[
'pyro
]
@
pytest.mark.parametrize
MODELS
def
test_model
backend
name
check_model
backend
name
funsor/test/test_minipyro.py
import
MODELS
check_model
import
pytest
@
pytest.mark.parametrize
MODELS
def
test_model
name
check_model
'funsor
name
@
fehiepsi
PyroModule
change
purpose
PyroModule.__setattr__
effectful
i.e
effect
handlers
behavior
unchanged
description
docstring
Interesting
other
uses
upstream
pyro/nn/module.py
@
pyro_method
_method
misnomer
behavior
works
def
sample
module
assert
isinstance
module
PyroModule
submod
module.modules
private
_load_pyro_samples
room
future
unrelated
note
anything
short
simple
name
memorable
wordy
day
day
cholesky
version
docstrings
standard
other
libraries
name
better
plate_stack/unsqueezing
comment
nit
Could
default
comment
docstring
default
value
Currently
way
source
code
stricter
logic
asserts
unpacked
shapes
pyro.contrib.funsor
enumeration
value
log-probability
tensors
Pyro
useful
early
development
implementation
details
dimension
allocation
test
Could
comment
guide
optional
kwarg
observations
dict
@
neerajprad
Could
CDN
url
comment
url
nit
update
comment
Add
comments
effect
is_auxiliary
annotation
docstring
example
erroneous
assertion
file
better
env
code
single
function
import
contextlib
import
os
@
contextlib.contextmanager
def
modified_environ
*
remove
*
*
update
Temporarily
os.environ
dictionary
in-place
os.environ
dictionary
updated
in-place
modification
sure
situations
param
remove
Environment
variables
param
update
Dictionary
environment
variables
values
=
os.environ
update
=
update
=
remove
]
List
environment
variables
=
update.keys
|
env.keys
Environment
variables
values
exit
update_after
=
k
env
[
k
]
k
stomped
Environment
variables
values
exit
remove_after
=
frozenset
k
k
update
k
env
try
env.update
update
env.pop
k
None
k
remove
]
yield
env.update
update_after
env.pop
k
k
remove_after
]
@
pytest.fixture
def
start_yatai_server
proc
=
None
def
func
db_url=None
store=None
yatai_server_command
=
[
]
proc
=
subprocess.Popen
stdout=subprocess.PIPE
stderr=subprocess.PIPE
return
f'localhost
port
yeild
func
proc
proc.terminate
def
test_yatai_server_with_postgres_and_local_storage
get_yatai_server_url
temporary_docker_postgres_url
logger.info
address
BentoML
config
=
get_yatai_server_url
modified_environ
BENTOML__YATAI_SERVICE__URL=url
regular
BentoService
save
regular
BentoService
get
regular
BentoService
run
regular
delete
benoservice
=
f
\
bentoml/yatai-service
ADD
/bentoml-local-repo
RUN
pip
install
/bentoml-local-repo
docker_client.images.build
path=local_bentoml_repo_path
fileobj=BytesIO
dockerfile.encode
'utf-8
open
temp_docker_file_path
w
f
f.write
f
\
bentoml/yatai-service
ADD
/bentoml-local-repo
RUN
pip
install
/bentoml-local-repo
sanity
check
status.status_code
OK
NOT_FOUND
get_deployment_pb.status.status_code
status_pb2.Status.OK
rasie
BentoMLDeploymentException
.....
get_deployment_pb.status.status_code
=
status_pb2.Status.NOT_FOUND
rasie
BentoMLDeploymentException
.....
deployment
store
code
docstring
Could
example
usage
init
parameters
bentoml.adapters
docs
adapters
page
sure
docstring
something
follow
issue
XYZ
updates
Github
issue
issue
id
comment
quick
inline
comments
self.target_count
self._target_sema
blank
line
comment
Creating
sagemaker
endpoint
L234
L235
previous
comment
suggestion
Gas
estimation
transaction
works
Suggestion
readability
queries
least
source
code
singe
string
proper
indenting
SELECT
data
timestamp
FROM
state_events
WHERE
json_extract
data
._type
IN
json_extract
data
.token_network_address
json_extract
data
.target
OR
json_extract
data
.initiator
ORDER
BY
identifier
ASC
LIMIT
OFFSET
hackaugusto
need
anything
point
MS
good
check
sure
BP
correct
comment
nice
last
line
noqa
docstring
test
name
test
restarts
transfers
queue
argument
incremental_index
false
default
heavy
operation
standardize_range_index
chunk.index_value
chunk.columns
instances
IndexValue
to_pandas
comment
behavior
Leftover
comment
let
comment
case
system
error
error
part
user-framework
contract
e.g
type
error
case
error
something
wrong
computation
error
stack
Would
docstring
purpose
object
regular
Dagster
config
system
while
loop
worthy
comment
re
.1
Duplicate
comment
same
previous
commit
comment
HTTPError
base
classes
Comment
much
possible
reference
coefficients
e.g.
Cr
state
docstring
restriction
implementation
limitation
nit
better
practice
named
loggers
=
logging.getLogger
__name__
logger.info
happend
__future__
import
print_function
prerequisite
@
geigerj
comment
[
]
https
//github.com/googleapis/artman/pull/256/files
r134620455
error
Python
Nitpick
=
line
f.read
.splitlines
line
=
line.strip
line
expected.add
line
following
effects
Blank
lines
important
future
committer
editor
blank
lines
end
file
many
line
comments
baseline
file
future
suggestion
'Additional
information
passed
environment
variables
flags
shell
env
variables
name
env
variables
next
flag
capital
letter
same
comment
imports
PEP8
same
previous
comment
Let
clear
documentation
tokenization
steps
BasicTokenizer
name
bit
vague
convert
strings
invalid
chars
chars
tokenize
JCK
unicode
conversion
tokenizer
UnicodeTransform
described
comments
docstrings
docstrings
consistency
docstrings
Please
module
docstring
description
inference
Thanks
good
comment
hybridization
Block
Can
transform
BERTSentenceTransform
comment
docstring
comment
refactoring
issue
None
support
gluon
curious
same
evaluation.add_parameters
parser
etc
whitespace
least
examples
PEP
https
//www.python.org/dev/peps/pep-0257/
script
tokenizers
BERTTokenizer
https
//github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/data/transforms.py
L966
subsequent
subwords
BERTSPTokenizer
https
//github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/data/transforms.py
L1074
sentencepiece
subword
tokenization
example
http
//gluon-nlp.mxnet.io/master/api/modules/data.html
highlight=sentencepiece
gluonnlp.data.SentencepieceTokenizer
word
▁
subword
is_segment_start
method
BERTTokenizer
BERTSPTokenizer
token
starting
word
similar
above
comment
max_num_sentences
nit
update
documentation
Actually
function
API
Spec
grad_global_norm
parameters
max_norm=None
Calculate
2-norm
gradients
parameters
much
such
2-norm
max_norm
max_norm
gradients
more
context
parameter
trainer.allreduce_grads
gradients
first
2-norm
..
note
function
use
False
trainer
Example
trainer
=
Trainer
update_on_kvstore=False
x
y
mx.gluon.utils.split_and_load
X
[
mx.gpu
]
mx.autograd.record
y
=
net
x
loss
=
loss_fn
label
loss.backward
trainer.allreduce_grads
norm
=
grad_global_norm
.values
Parameters
parameters
list
Parameters
max_norm
NDArray
maximum
L2
norm
threshold
ratio
is_finite
Returns
NDArray
Total
norm
Shape
NDArray
Ratio
gradients
max_norm
s.t
grad
=
grad
/
ratio
total
norm
NaN
ratio
NaN
max_norm
Shape
NDArray
Whether
total
norm
finite
max_norm
Shape
unit
test
gluonnlp.utils.grad_global_norm
implementation
gluonnlp.utils.clip_grad_global_norm
grad_global_norm
moves
argument
.format
self.package_folder
bin
share
configure
script
suggestion
cross
building
conan
https
//github.com/conan-io/conan-center-index/pull/1179
issuecomment-603848593
https
//github.com/conan-io/conan-center-index/issues/1136
issuecomment-603897062
external
file
suggestion
FIXME
official
CMake
target
namespace
self.cpp_info.filenames
cmake_find_package
]
Celero
[
cmake_find_package_multi
]
Celero
https
//github.com/DigitalInBlue/Celero/tree/v2.6.0/cmake
OpenCV
component
name
different
target
name
find_package
OpenCV
REQUIRED
core
CONFIG
target_link_libraries
myapp
PRIVATE
opencv_core
trick
behaviour
conan
generators
companion
component
component
component
something
suggestion
TODO
OpenCV
target
namespace
component
components.items
self.cpp_info.components
component
]
.names
[
cmake_find_package
]
opencv_
+
component
self.cpp_info.components
[
component
]
.names
cmake_find_package_multi
]
opencv_
+
component
self.cpp_info.components
[
component
]
.libs
=
[
get_lib_name
component
]
self.cpp_info.components
[
component
]
.requires
self.settings.os
Linux
self.cpp_info.components
component
]
.system_libs
=
[
dl
m
pthread
rt
]
self.cpp_info.components
[
component
+
_alias
]
[
cmake_find_package
=
component
self.cpp_info.components
[
component
+
_alias
]
[
cmake_find_package_multi
=
component
self.cpp_info.components
[
component
+
_alias
]
=
[
component
]
self.cpp_info.components
[
component
+
_alias
]
=
[
]
self.cpp_info.components
[
component
+
_alias
]
=
[
]
self.cpp_info.components
[
component
+
_alias
]
=
[
]
suggestion
def
_patch_sources
self.options.with_snappy
tools.replace_in_file
self._source_subfolder
CMakeLists.txt
'check_library_exists
snappy
snappy_compress
HAVE_SNAPPY
build
self._patch_sources
suggestion
FIXME
crc32
tcmalloc
leveldb
official
conan
packages
available
similar
options
steinerthomas
uses
AUTOMAKE_CONAN_INCLUDES
ACLOCAL
environment
variables
extra
paths
scripts
posix
systems
multiple
paths
Windows
conan
feature
issue
suggestion
FIXME
conan
feature
join
character
lists
environment
variables
e.g
self.env_info.AUTOMAKE_CONAN_INCLUDES.joiner
tools.environment_append
AUTOMAKE_CONAN_INCLUDES
tools.get_env
AUTOMAKE_CONAN_INCLUDES
.replace
tools.chdir
self._source_subfolder
self.run
-fiv
run_environment=True
suggestion
def
_patch_sources
Use
cmake
module
files
self._source_subfolder
CMakeLists.txt
find_package
Leptonica
MINIMUM_LEPTONICA_VERSION
REQUIRED
CONFIG
find_package
Leptonica
MINIMUM_LEPTONICA_VERSION
REQUIRED
Variable
Leptonica_LIBRARIES
dependencies
cmake/pc
files
Conan
link
exported
target
autogenerated
CMake
file
cmake_find_package
information
dependencies
self._source_subfolder
CMakeLists.txt
Leptonica_LIBRARIES
Leptonica
:Leptonica
build
self._patch_sources
=
self._configure_cmake
Re-use
cmake
instance
configure
build
package
suggestion
self._cmake
return
self._cmake
=
CMake
Configure
CMake
library
build
self._cmake.definitions
EMBREE_STATIC_LIB
]
self._cmake.definitions
BUILD_TESTING
]
False
self._cmake.definitions
EMBREE_TUTORIALS
]
False
self._cmake.definitions
EMBREE_GEOMETRY_CURVE
]
=
self.options.geometry_curve
self._cmake.definitions
EMBREE_GEOMETRY_GRID
]
=
self.options.geometry_grid
self._cmake.definitions
EMBREE_GEOMETRY_INSTANCE
]
self.options.geometry_instance
self._cmake.definitions
EMBREE_GEOMETRY_QUAD
]
=
self.options.geometry_quad
self._cmake.definitions
EMBREE_GEOMETRY_SUBDIVISION
]
=
self.options.geometry_subdivision
self._cmake.definitions
EMBREE_GEOMETRY_TRIANGLE
]
=
self.options.geometry_triangle
self._cmake.definitions
EMBREE_GEOMETRY_USER
]
=
self.options.geometry_user
self._cmake.definitions
EMBREE_RAY_PACKETS
]
=
self._cmake.definitions
EMBREE_RAY_MASK
]
self._cmake.definitions
EMBREE_BACKFACE_CULLING
]
self._cmake.definitions
EMBREE_IGNORE_INVALID_RAYS
]
=
self._cmake.definitions
EMBREE_ISPC_SUPPORT
]
False
self._cmake.definitions
EMBREE_TASKING_SYSTEM
]
INTERNAL
self._cmake.configure
build_folder=self._build_folder
suggestion
def
package_info
self.cpp_info.libs
=
[
args
]
FIXME
project
namespace
https
//github.com/mbits-libs/args/blob/72f5f2b87ae39f26638a585fa4ad0b96b4152ae6/CMakeLists.txt
L152
_get_es_mapping_if_necessary
anything
lack
assignment
value
return
statement
big
deal
statement
function
data
flow
otherwise-getter
cache-filling
purposes
effect
comment
right
hand
side
call
issue
typo
suggestion
*
multiple
times
test
function
joli
bit
low
level
function
documentation
something
forked
dataset
distinct
meta-data
actual
data
original
version.
code
comment
Could
comment
necessary
TODO
comments
function
error
Could
format
docstrings
numpydoc
format
great
consistent
sure
strings
log
messages
https
//www.reddit.com/r/Python/comments/387oog/when_will_logging_use_newstyle_string_formatting/
reasons
Please
comment
mapping
e.g.
openml.tasks.task.py
class
TaskTypeEnum
object
SUPERVISED_CLASSIFICATION
SUPERVISED_REGRESSION
LEARNING_CURVE
=
task.task_type_id
TaskTypeEnum.SUPERVISED_CLASSIFICATION
such
stupid
little
nitpick
italic
ital
suggestion
Test
Whitelister
new
elements
attributes
Minor
note
class
Db
prefix
tiny
typos
suggestion
Test
Whitelister
span
element
attributes
allowed
element
<
span
>
attributes
v1.wagtail_hooks
comment
hallo
js
files
chance
time
function
super-fast
machine
file
case
loop
body
references
non-existing
variable
happen
reason
first
place
comment
actual
problem
variables
main
function
function
become
global
variables
reachable
functions
actual
warnings
pylint
single
variable
UPPER_CASE
style
global
many
other
random
functions
same
variable
names
name
<
name
>
outer
scope
main
function
something
inviting
code
function
variables
__PRIVKEY
similar
other
functions
main
function
separate
file
such
comment
use
Header
Slot
number
use
Body
big
comment
own
audit_checker/frame
compatible
bread
crumb
branch/tag/jira
issue
doc
blocks
spec
]
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
simple
way
line
self.filtered
lambda
x
x.line_type
==
'model
model_env
=
self.env
[
line.model_id.model
]
=
model_env.search_count
Note
inactive
records
sure
meaningful
account
term
performance
critical
feature
separate
comment
self.pool
usage
reasoning
separate
comment
Same
comment
super
class
init
docstrings
Yep
sense
target
gap
rows
target
value
row
n
estimator
row
n
+
gap
final
gap
rows
nan
extend
message
e.g
Permission
%
i
sure
Scapy
sudo
thousands
/dev/bpf
issues
comments
requested
simplified
format
suggestion
Global
R
suggestion
diag
Union
[
List
np.array
]
>
None
Create
new
Diagonal
circuit
diag
list
diagonal
entries
diagonal
gate
k
qubits
comment
TimeslotCollection
documentation
rules
suggestion
numpy.array
RCCCX
gate
suggestion
Create
new
RCCCX
gate
kwargs
target_qubit
consistency
table
https
//qiskit.org/documentation/release_notes.html
deprecation-notes
https
//github.com/Qiskit/qiskit-terra/pull/3788
suggestion
Test
creation
controlled
u1
gate
suggestion
Test
creation
controlled
y
gate
suggestion
Test
creation
controlled
z
gate
ScalarOp
QuantumChannel
Operator
ScalarOp
Operator
description
line
circ.add_calibration
h
]
q0_x180
h
qubit
same
last
test
test
custom
gate
qubit
error
custom
operation
gates
only
implementing
backend
interface
work
someone
different
plotter
suggestion
Format
appearance
canvas
suggestion
A
fake
qubit
backend
suggestion
Test
Qiskit
Instruction
class
quotes
single
line
code
style
consistency
sake
extra
spaces
beginning
end
docstrings
https
//www.python.org/dev/peps/pep-0257/
suggestion
log_passes
option
suggestion
A
n_qubit
circuit
qubits
suggestion
documentation
standard
suggestion
Implementations
boolean
logic
quantum
circuits
documentation
😄
suggestion
A
n_qubit
circuit
inner
product
registers
suggestion
A
n_qubit
circuit
inputs
Z2
sentence
shift
Z2
people
name
suggestion
def
count_cx
qc
number
CX
gates
return
qc.count_ops
.get
Non-blocking
feasible
useful
customization
graph
width
graph
height
sort
options
function
iplot_function
functionality-specific
errors
VisualizationError
class
sense
new
class
errors
pass
other
statements
suggestion
Callback
alignment
pulse
context
suggestion
Return
False
iff
gate
bit
documentation
NamedTuple
s
https
//stackoverflow.com/a/20388499
general
circuit
form
diagram
super
useful
better
..
parsed-literal
block
i
gate
documentation
sure
|0
>
beginning
circuits
errors
good
drawers
circuit
initial
state
suggestion
Assert
summation
w.r.t
set
weights
difference
pm.passes
pm.pass_sets
clear
names
suggestion
stabilizers
graph
state
expected
stabilizers
https
//arxiv.org/pdf/quant-ph/0307130.pdf
Eq
suggestion
GraphState
circuit
stabilizers
philosophical
documentation
suggestion
analysis
pass
depth
DAG
circuit
suggestion
analysis
pass
depth
DAG
circuit
suggestion
circuit
resources
property
set
'depth
'width
'count_ops
'num_tensor_factors
suggestion
analysis
pass
size
DAG
circuit
suggestion
analysis
pass
size
DAG
circuit
suggestion
analysis
pass
width
DAG
circuit
suggestion
analysis
pass
width
DAG
circuit
suggestion
Circuit
https
//github.com/Qiskit/qiskit-terra/issues/3516
comment
data_dict
qargs
cargs
information
edge
node
extra
info
nodes
easy
followup
c11f0f4
case
front=True
Gate
other
lot
extra
metadata
container
ExperimentResult
class
Counts
counts
part
result
additional
return
data
types
future
ExpectationValue
Probabilities
lot
duplication
unneeded
metadat
case
counts
creg_sizes
whitespace
bitstrings
conversion
memory_slots
creg_sizes
number
bits
hex-format
Shots
sum
dict
elements
time
name
metadata
unnecessary
suggestion
docs
]
qiskit.org/documentation/tutorials/circuits/3_summary_of_quantum_operations.html
Incomplete
docstring
sure
docstrings
accurate
optimization_level
pass_manager_config
old
todo
qobj
header
conf
circuits_to_aobj
suggestion
Unitary
class
relies
current
implementation
detail
isometry
phase
correct
global
phase
point
phase
trivial
circuit.global_phase
extra
cost
docstring
upto_phase
True
probabilities
global
phase
efficient
circuit.
suggestion
Basic
transformation
functions
Schedule
arguments
note
docstring
TODO
deletions
deprecations
post-0.8
PR
time
deprecation
update
documentation
Same
comment
https
//github.com/Qiskit/qiskit-terra/pull/3714/files
comment
https
//github.com/Qiskit/qiskit-terra/pull/3714/files
r382785476
suggestion
circuit
instruction
mapper
instance
suggestion
instruction
defined
instructions
qubits
suggestion
functions
def
cname
pyfunc_cname=__pyx_pf_
*
functions
cpdef
cdef
cname
func_cname=__pyx_f_
*
cases
cname
name
function
actual
code
cname
=
node.entry.pyfunc_cname
node.entry.func_cname
full
Python
hex
version
comparison
Py4.0
Ca
warning
strings
textwrap.wrap
line
separate
comment
lines
actual
feature
flag
call
invalid
suggestion
h_code.putln
CYTHON_PEP489_MULTI_PHASE_INIT
inline
C99
suggestion
h_code.putln
__GNUC__
||
h_code.putln
__deprecated__
%
s
%
s
__unused__
%
warning_string1.as_c_string_literal
h_code.putln
elif
h_code.putln
%
s
%
s
%
warning_string1.as_c_string_literal
h_code.putln
endif
h_code.putln
PyObject
*
__PYX_WARN_IF_INIT_CALLED
PyObject
*
suggestion
h_code.putln
PY_VERSION_HEX
>
warning
function
static
degrigis
command
function
def
state
Global
Offset
Table
sec
=
pwndbg.wrappers.checksec
i
guess
own
sure
relocs
proper
name
jmpslots
=
pwndbg.readelf.relocs
print
protection
%
s
|
GOT
functions
%
%
green
relro_status
relocs
address
name
got_addr
relocs
print
%
x
%
>
%
s
%
address_val
light_yellow
name
got_address
branches
differs
line.split
PIE
x86-32
anything
PIE
python
line
jmpslots.splitlines
address
info
rtype
value
name
=
line.split
:5
]
x86-64
columns
redundant
sure
last
comment
disconnect3d
more
thing
functions
module
wrappers
functions
better
classes
latter
methods
useful
different
support
functions
utility
f.i
checksec
class
different
methods
input
different
way
dictionary
raw
string
etc
function
pls
def
call_program
progname
args
program
=
pwndbg.which.which
progname
program
raise
OSError
%
s
command
PATH
%
progname
cmd
=
progname
tuple
args
case
someone
pass
list
try
return
subprocess.check_output
cmd
.decode
Exception
e
raise
OSError
execution
%
s
command
%
s
%
progname
e
ArgparsedCommand
command
description
ArgparsedCommand
upper
comment
custom_pages
List
custom
pages
vmmap_
*
family
comment
logic
Checks
records
readelf
relocs
<
binary
>
type
e.g
R_X86_64_JUMP_SLO
NOTE
NOT
entries
writeable
due
FULL
RELRO
type
good
future
_extract_jumps
line
TODO
comment
issue
feature
PR
string
argument
behavior
string
ioctl
fd
op
[
arg
[
mutate_flag
]
]
docstring
argument
mutable
buffer
mutable_flag
argument
false
behavior
string
behavior
future
releases
Python
argument
immutable
buffer
string
copy
buffer
operating
system
return
value
string
same
length
operating
system
buffer
length
arg
buffer
case
bytes
whitespace
width
entries
commands
history
gdb.execute
commands
to_string=True
.split
'\n
-2
]
.split
argument
whitespaces
matter
length
output
docs
[
]
str.split
S.split
[
sep
[
]
]
>
list
strings
Return
list
words
string
S
sep
delimiter
string
maxsplit
most
maxsplit
splits
sep
whitespace
string
separator
empty
strings
result
'-l
program-headers
docstring
easier
flag
suggestion
def
_read_targets_from_makefile
lines
List
[
str
]
>
Dict
[
str
List
[
]
]
Helper
method
information
targets
lines
Makefile.
comment
regex
Comment
code
HammerToolHooksTestContext
nice
point
large
amounts
copy
code
hairy
suggestion
@
api.model
def
_default_first_number
Default
first
number
custom
behaviour
return
suggestion
Check
generated
number
above
comment
different
logs
Can
comment
something
effect
doc
comment
arguments
E.g
absolute
filename
string
yaml
comments
Mark
words
reason
DiscoverSource
mutable
source
=
query.get_data_source
isinstance
source
DiscoverSource
filter
discover
sense
other
sources
source.set_table
table_source
only
code
logic
today
column_expr
docstring
only
place
transformation
Personal
preference
/
minor
style
comment
b
easier
b
true
type
__active_snapshot_msg
Ideally
design
class
docstring
comment
something
reader
class
themself
implementation
same
comment
FunctionCallMapper
function
function
translation
multi
table
storage
tables
pre-aggregated
FunctionCall
Column
function
count
column
aggregation
effort
translation
type
safe
CurreidFunctionCall
inner
function
Column
Though
inner
function
own
type
comment
problem
alias
separate
Column
type
first
iteration
AST
review
ther
reason
attribute
expression
clickhouse
something
viable
change
class
AliasedExpression
Expression
alias
str
expression
Expression
harder
aliases
expressions
present
AST
translatable
transformable
sure
connection
rest
comment
aliases
query
little
sense
similar
comment
snuba/query/conditions.py
files
order
generator
list
comprehension
early
exit
evaluate
True
Same
comment
re
logger
names
nit
case
good
practice
reason
_not_
suggestion
result
None
bunch
other
comparisons
None
same
JTCunning
columns
today
search
backend
groups
commented
ones
docstring
date
None
deletions
from_
*
constructors
deleted
flag
_process_delete
circumvents
from_wal
call
WAL
nice
fields
single
datatype
Optional
fields
logical
schema
concrete
ClickHouse
only
reason
idea
leaf
node
nodes
able
counterintuitive
api
=
Column
alias
column
table
col
c
yield
sole
reason
expression
NodeContainer
OrderBy
problem
visible
stage
mypy
fine
container
OrderBy
classes
container
Sequence
[
OrderBy
]
=
[
]
stuff
container
=
map
o.transform
func
container
matter
different
place
transformation
board
query
possible
solution
board
user
decide
parts
query
sequence
order
e
more
specialized
mapping
function
require
ORderBy
transform
expressions
board
content
OrderBy
Expression
Which
most
use
case
Query
api
approaches
comment
value
new
object
inevitable
function
leaf
node
func
returns
self
same
object
different
object
new
object
guarantee
immutability
expressions
immutability
point
number
implies
transform
current
object
new
anything
expressions
immutable
trivial
leaves
more
complex
expresisons
children
children
sequence
order
HierarchicalExpression
immutable
able
transformation
children
change
feasible
separate
HierarchicalExpression
time
transform
content
efficient
sense
new
comment
wrong
timestamp
%
consistency
Clickhouse
lot
more
ClicHouse
log
messages
comments
ClickHouseError
https
//github.com/getsentry/snuba/blob/3378bb1ec69525669669750be0d0d3311a3ae128/snuba/consumers/consumer_builder.py
L88-L94
codec
mine
snuba/cli/subscriptions.py:121
note
type
snuba.utils.streams.kafka.KafkaProducer
Tuple
[
snuba.subscriptions.scheduler.ScheduledTask
[
Tuple
[
snuba.subscriptions.data.SubscriptionIdentifier
snuba.subscriptions.data.SubscriptionData
fallback=snuba.subscriptions.data.Subscription
]
Subscription
]
[
builtins.str
[
builtins.str
Any
]
]
ClickhouseQueryResult
fallback=snuba.subscriptions.worker.SubscriptionResult
]
SubscriptionResult
]
documentation
Exception
better
custom
comment
action
anyone
comment
custom
message
suggestion
Replace
payload
own
FIXME
guillaume
rename
key
errors
dahsboard
transition
payload
=
errors_list
]
beautiful
soup
[
tokens
]
https
//arrow.readthedocs.io/en/latest/
supported-tokens
easier
reliable
url
Same
error
A
nitpick
difference
nuclear
data
rest
data
right
solar
+
unknown
comments
JP
data
production
data
rescue
system
unknown
system
proper
value
None
check
early
dedent
block
code
suggestion
referenced_file
break
break
suggestion
referenced_file
=
val
break
suggestion
'operation
operator.ne
operator.le
ids=
[
'eq
'ne
'le
]
def
test_matcherror_compare_invalid
other
operation
Check
MatchError
comparison
other
types
raises
pytest.raises
NotImplementedError
operation
MatchError
other
suggestion
def
test_matcherror_compare
Check
MatchError
instances
similar
attrs
equivalent
docstring
bit
misleading
object
fact
new
suggestion
stripped-off
task
structure
compatible
new
Ansible
helper
copy
incoming
task
keys
it.
Minor
comment
func
something
cast_type
similar
ambiguity
position
-edit-
later
wins
comment
surprise
other
values
name
shuffle
keyword
suggestion
index
str
list
str
Series
Index
DataFrame
_Frame
public
best
docstrings
Fixed
See
comment
General
comment
whole
file
good
code
intention
code
block
original
comment
Treat
empty
arrays
equivalent
right
mrocklin
comment
reasoning
if-else
clauses
test
specific
issue
real
behavior
errors
things
mean
object
series
informative
better
def
test_better_errors_object_reductions
GH2452
s
=
pd.Series
[
b
c
]
ds
=
dd.from_pandas
s
npartitions=2
pytest.raises
ValueError
err
ds.mean
err.value.message
==
object
series
suggestion
isinstance
index
list
curious
list
types
names
x
import
pandas
pd
df
=
pd.DataFrame
x
]
df.set_index
x
third
check
condition
Pandas
tuple
names
sequence
names
df
=
pd.DataFrame
[
]
df.set_index
[
x
]
Works
df.set_index
x
Fails
minor
tweaks
added
notes
docstring
assumptions
Dask
numpydoc
style
docstrings
http
//dask.pydata.org/en/latest/develop.html
docstrings
self.index.name
None
falsey
index
names
False
case
groups
index
columns
Nitpick
space
endline
first
header
line
empty
line
http
//numpydoc.readthedocs.io/en/latest/
http
//dask.pydata.org/en/latest/develop.html
docstrings
new
keyword
arguments
function
important
necessary
top
comment
PR
*
docstring
current
docstring
quite
sprase
Git
blame
fault
term
kernel
understood
users
term
function
docstring
familiar
novice
users
one-line
comment
small
docstring
nice
Same
comment
indexes
>
indices
docstring
dask.array
optimizations
able
persist
dask.array
advantageous
bad
advice
https
//github.com/dask/dask/pull/3000
part
top-level
dask.array
namespace
docstring
good
least
better
valid
chunk
downcast
array
type
example
method
small
Examples
section
Examples
>
>
>
df
=
dd.read_sql
'accounts
'sqlite
///path/to/bank.db
index_col='id
doctest
+SKIP
set_index
keeps
similar
values
same
partition
@
shoyer
comment
something
wrong
errors
numpy
arrays
anything
inspect.getmodule
returns
None
python
]
x
=
np.ones
]
package_of
x
AttributeError
Traceback
recent
call
last
ipython-input-25-427cf35109bf
>
<
module
>
>
package_of
x
ipython-input-14-209ff1f7b671
>
package_of
obj
http
//stackoverflow.com/questions/43462701/get-package-of-python-object/43462865
mod
=
inspect.getmodule
obj
base
_sep
_stem
=
mod.__name__.partition
return
sys.modules
base
]
AttributeError
'NoneType
object
attribute
Small
style
comment
optional
imports
https
//github.com/dask/dask/blob/7b4f90f0a708cbb97ebb498c78f7931d82ec99db/dask/diagnostics/tests/test_profiler.py
L15-L18
psutil
None
check
psutil
other
array
types
sparse.COO
cupy.ndarray
explicit
type
checks
np.ndarray
possible
cases
necessary
something
list
following
python
dask.utils
top
file
condition
condition
=
asarray
condition
docstring
Any
suggestions
small
data
structure
partition
size
proportional
number
partitions
serialization
time
things
large
partitions
python
]
p1
=
pq.PartitionSet
i
range
]
]
p2
=
pq.PartitionSet
[
i
range
]
]
partitions
pq.ParquetPartitions
]
partitions.levels
[
p1
p2
]
]
timeit
pickle.dumps
partitions
loops
best
µs
loop
few
times
dominant
cost
premature
optimization
dask.dataframe
+
pyarrow
data
tests
experience
distributed
scheduler
local
laptop
complex
environment
python
import
Client
client
=
Client
Starts
local
cluster
Registers
default
global
scheduler
normal
call
possible
pathological
cases
enough
partitions
func
delayed
partitions
iteration
loop
lot
unnecessary
work
sense
something
time
func
def
module
top
level
top
function
body
d_schema_from_pandas
=
delayed
pa.Schema.from_pandas
time
construction
delayed
partitions
d_partitions
df
[
sample
]
.to_delayed
line
loop
suggestion
_s
=
d_schema_from_pandas
d_partitions
i
[
sample
]
.to_delayed
good
loop
fewer
fewer
columns
iterations
sure
useful
docstring
class
docstring
fixture
function
pytest
fixtures
friendlier
Please
same
logic
aws
lambda
Do
sure
json
%
time
raw
data
Flask
request
object
json
property
available
static
string
class
member
comments
path
local
file
system
docker
container
Constant
Keep
imports
sections
PEP8
Python
standard
library
imports
dependencies
imports
modules
codebase
case
code
comment
strong
statement
true
bullet
list
assertion
Please
comment
patron
method
get_loans_by_patron_pid
returns
loans
history
cancelled
loans
huge
patrons
US1394
better
methods
loan
index
state
reason
PR
merge
US1394
item
=
Item.get_record_by_pid
loan.get
'item_pid
item
=
Item.get_record_by_pid
loan.item_pid
loan.get
'item_pid
object
Missing
params
understandable
return
False
statement
default
Same
comments
file
functions
parameters
return
value
more
details
comment
main
idea
consistency
database
search
index
documents
presents
database
present
search
index
vice
versa
docstring
comment
这句话可以放在
循环外面
PEP
imperative
style
sentence
docstring
title
suggestion
Build
install
flags
finder
CLI
options
Please
comment
assert
assert
self._next_line_to_process
'Internal
error
data
line
more
Please
bug
x.strip
entire
file
header
unit
tests
PyVCF
care
header
data
lines
integration
tests
likely
memory
way
large
samples
x
None
source
estimates
number
variants
samples
VCF
file.
estimates
extra
space
line
commentary
experimental
flags
Please
nit
fileformat
line
loop
array
nmousavi
TODO
point
tests
MergeDefinitions
combine_fn
ones
nit
file2
]
nit
Please
comment
Whether
INFO
fields
Number=A
store
alternate_bases
record
state
world
nit
closing
same
line
nit
google
style
first
comment
line
line
pylint
idea
1-line
summary
more
details
type
type
next
comment
anything
private
IntelliJ
PyCharm
nice
warnings
type
issues
warnings
presubmit
check
type
'Args
section
comment
line
function
definition
line
def
format_query
query
type
List
[
str
]
>
None
new
style
whole
code
Issue
details
full
class
simple
method
little
bit
over-designing
things
complex
future
comment
__init__
function
simple
function
new
class
change
QueryFormatter
instantiation
line
extra
complexity
nit
query
logic
query
parts
string
Replaces
table
query
..
query
List
[
str
]
Returns
..
single
string.
Again
Github
issue
PR
TODO
Feel
free
issue
TODO
nit
please
docstring
order
important
non-trivial
specific
reason
function
docstring
better
__init__
something
specific
Avro
same
code
variant_to_bigquery
rows
same
schema
changes
general
name
avro_records
common
parts
VariantToAvroFiles
TODOs
second
comment
yours
previous
pass
Flatten
IIUC
variants
list
PCollections
element
problems
code
Please
comment
code
mention
nit
more
clear
lists
e.g
malformed_vcf_records
malformed_header_lines
return
malformed_vcf_records
malformed_header_lines
code
self-explanatory
much
possible
comments
little
bit
question/comment
whole
PR
last
review
nit
such
such
Just
comment
qubits
reasonable
restriction
einsum
Other
correct
fine
measure_all
people
prog.measure_all
qpu.run
prog
qpu.run_and_measure
prog
public
methods
symmetrize_readout
run_symmetrized_readout
documentation
other
user
single
public
API
call
single
docstring
suggestion
method
private
documentation
class
toplevel
Need
more
comments
train_iter
major
interface
Trainer
more
comments
init_driver
major
interface
Trainer
Args
Returns
Comment
..
such
type
TDLoss
summary
=
>
_summary
other
classes
short
comment
spectator
better
comment
joint
loss
target_entropy_loss
EntropyTargetLossInfo
comment
TODO
Handle
input_tensor_spec
return
line
Returns
section
comment
arguments
tiles
format
needs
Docstring
format
needs
pre-commit
hooks
comment
accurate
storage
comment
comment
append
comment
arguments
format
fields
valid
values
levels
expected
arguments
rollout
>
rollout_step
mis-match
name
function
implementation
rollout
documentation
mixture
rollout
rollout_step
comments
other
args
comment
hard_reset
'hard_reset
semantic
'reset
gym.Env
reset
same
signature
function
such
start_new_life
class
Comments
q-networks
critic-networks
function
name
documentation
https
//github.com/HorizonRobotics/alf/blob/d58103f299558f5fdeae218bd23515aed5c9b557/alf/algorithms/algorithm.py
L147-L153
_on_collision
event.other_actor
carla.Actor
obvious
though
TODO
Carla
documentation
force
vector
impulse
comment
function
process
Should
leaves
scalars
intervals
case
Probably
comment
function
process
comment
state
comment
comment
strict=False
Comment
children
modules
comment
global_step
comment
global_step=
latest
global_step
type
comment
argument
return
value
shape
reason
readthedocs
tries
pybullet
error
pybullet
huge
most
training
users
comments
arguments
wrong
comment
update
ActionTimeStep
Comments
functionality
class
Please
meaning
type
arguments
style
functions
style
argument
comment
arg_name
type
explanation
comments
Comment
informative
comment
stepscheduler
possible
case
assertion
error
comment
need
episodic
information
processing
function
cost
data
Simply
previous
K
frames
FIRST
steps
earlier
steps
bit
base
class
amps
arduino
code
worry
comment
test
line
sure
real
way
weird
line
breaks
comment
other
comment
self.serial
self.ser.ser
consistent
mount
reason
way
create_dome_from_config
file
previous
review
quick
docstring
type
Second
match
comment
milliseconds
Same
pithier
comment
has_valid_observations
pocs.is_safe
pocs.is_safe
has_valid_observations
right
nice
docstring
shlex
quotes
final
value
stringified
value
single
quotes
single
quotes
present
float
something
Basically
flag
parsing
optional
documentation
only
single
quotes
suggestion
SDK
documentation
product
IDs
function
docstring
nit
please
measuring
unit
example
DEFAULT_SERVICES_NOTIFICATIONS_COOKIE_EXPIRY
=
value
nano
seconds
guidelines
https
//edx.readthedocs.io/projects/edx-developer-guide/en/latest/style_guides/python-guidelines.html
docstrings
See
comment
upgrade_settings
line
get_channel_idx_from_choice
function
fine
example
settings
test_colortogray
manual
examples
upgrade_settings
module
bit
special
channel
choices
actual
variable_revision_number
particular
reason
better
section
clause
dependent
variable_revision_number
sense
MeasurementProcessing
class
friendly
message
other
s
E.g.
err.message.startswith
many
columns
cellprofiler.gui.dialog.Error
Error
MySQL
Error
+
err.message
command
appliance.ssh_client.run_command
directory
changes
need
/var/www/miq/vmdb/
Same
^
command
appliance.ssh_client.run_command
directory
changes
need
/var/www/miq/vmdb/
ambiguous
property
logic
raw_vm_ssh_client_args
name
provider
type
comments
clear
different
rhevm
cases
others
vm_mgmt
temp
VM
raw
VM
*
*
REQUIRED
*
*
Needs
documentation
other
arguments
magic
numbers
indexing
single
character
vars
standing
headers
Let
comment
in-line
name
function
split
zero-index
Again
let
value
use
try/except
remove
item
checked
list
list
header
values
objects
list
headers
list
items
same
method
ComparisonView
class
function
test
module
way
re-usable
various
entities
MIQ
test
module
TODO
move
method
comparison
view
*
REQUIRED
*
*
%
sure
comment
function
one
liner
tenant.provider.refresh_provider_relationships
update
comment
Milan
%
s
logger
argument
docstring
is_displayed
property
inline
comment
storage
different
flavors
Is
case
*
*
REQUIRED
*
*
http
//cfme-tests.readthedocs.io/guides/dev_guide.html
code-style
>
PEP
triple-quoted
docstrings
double
quotes
docstrings
normal
multi-line
strings
single-quotes
latter
case
*
*
REQUIRED
*
*
collection
same
comments
'reset
provider
refresh
host
state
impacts
other
VMDB
objects
state
VMs
good
full
evm
refresh
sure
VMDB
in-line
comment
please
cloud/infra
mention
comment
digitronik
earlier
comment
function
scope
provider
setup
provider
test
first
test
provider
setup
pass
Same
comment
above
soft_assert
items
tempfile
https
//docs.python.org/3.7/library/tempfile.html
@
digitronik
reboot
db
evmserver
service
May
chance
kernel
update
reboot
self.reboot
self.db_service.restart
self.evmserverd.start
services
reboot
Thoughts
I.e
Same
comment
state
fauxfactory.gen_alpha
*
Required
*
*
suggestion
assert
vm_console.get_screen_text
VM
Console
screen
text
Empty
wait_for
anything
states
in-line
comments
assumptions
states
chance
race
condition
test
failure
anurag03
@
psav
other
comments
view
structure
PR
right
@
psav
Form
view
common
TimeProfileView
form
section
Add
Edit
pages
TimeProfileForm
class
views
TimeProfileAddView
nested
views
python
class
TimeProfileAddView
TimeProfileView
@
def
form
TimeProfileForm
=
Button
blah-blah-blah
way
nested
form
view
available
Add/Edit
views
part
TimeProfileAllView
form
@
nachandr
casecomponent
Tire
unable
caselevel
please
changes
comment
good
first
row
table
comment
index
ignore
TODO
please
try
test_snapshot_link_after_deleting_snapshot
test
appropriate
tier
meta
markers
Bugzilla
info
Forgot
bottlenecks.py
Fixed
comments
Please
other
comment
topic
approach
multiple
entities
suggestion
return
view.entities.summary
Properties
Chassis
name
comment
parent
super
self.__class__
custom
function
names
Ah
items
comment
View.fill
select
field
form/view
class
before_fill
method
fill
before_fill
BootstrapSelect
widget
provider
type
selection
selection
biggest
reasons
conversion
selenium
page
models
least
TODO
more
selenium
better
try
else
typo
'Reuturn
docblock
more
first
line
action/use
caller
comments
Returns
header
@
psav
@
izapolsk
only
'blocker
comment
better
ButtonGroupCollection
class
TODO/tech
debt
enum
class
type
constants
docstring
same
Just
general
comment
structure
comprehension
kinda
item._metadata
]
list
=
[
i
i
items
'automates
i._metadata
'coverage
i._metadata
]
bz_list
=
[
i._metadata.get
'automates
i
relevant_items
]
None
list
extend
metadata
value
list
[
bz_list.extend
i._metadata.get
'coverage
[
None
]
i
relevant_items
]
bz_list
=
[
bug.bug_id
isinstance
bug
BZ
bug
bug
bz_list
]
duplicates
convert
instances
None
drop
irrelevant
None
same
thing
basic
use
provider
marker
list
classes
required_flags
combination
module
provider
marker
function
setup_provider
fixture
intentional
Quadicon
tests
function
Quadicon
match_location
Widgetastic
equivalent
python
class
ResourcePoolView
BaseLoggedInPage
Base
view
header
nav
checking
navigatable
views
@
property
def
in_resource_pool
nav_chain
=
[
'Compute
'Infrastructure
Pools
]
return
self.logged_in_as_current_user
==
nav_chain
TODO
Widgetastic
match_location
controller='resource_pool
title='Resource
Pools
definitions
work
widget
class
module
other
module
VM
view
none
such
exists
provisional
view
widgets
TODO
correct
references
In-line
comment
pytest-polarion-collect
get_parsed_docstring
cache
issue
docstrings
function/module
fixture
method
access
session
request
docstrings
attribute
cache
parsed
docstrings
files
pytest-polarion-collect
cache
kwargs
collect-only
generate-json
meta-filter
startup
cost
fixtures
meta
free
comment
items
Use
google-style
docstrings
CFME
https
//gist.github.com/mfalesni/11694e0d563c80c3917ce6012400b93f
short
python
Summary
line
More
details.
applies
other
docstrings
in-line
comments
lot
readability
row
fill
checkbox
Same
comment
class
name
community
obvious
test
report
comment
plz
avoid
checks
isinstance
checks
general
case
level
level
isinstance
level
int
int
comment
string
comments
docs
code
clear
comment
items
url
....
resource_type
tenant
resource_name
=
uri
Same
previous
comment
sure
loops
first
one
current
folder
rpms
second
loop
dependencies
.spec.dependencies
file
Maybe
more
comments
See
comment
dicts
avoid
auth
flow
info
..
cda
comment
comment
comment
..
comment
..
Sure
ok
sure
comment
MCF
resolution
Place
typeOf
bad
equivalent
Find
entity
new
entity
None
entity_id
entity
=
self.client.get
self._get_key
entity
make_new
entity
datastore.Entity
self._get_key
utils.get_id
entity
entity
[
]
=
entity.key.name
entity
entity
entity_id
Entity
present
None
raise
ValueError
None
make_new
False
docstring
descriptive-style
Fetches
Bigtable
imperative-style
Fetch
Bigtable
https
//google.github.io/styleguide/pyguide.html
383-functions-and-methods
suggestion
Base
class
import
attempt
resource
example
comments
first
split
function
exception
stricter
checks
comment
example
nit
readable
const
input
=
uniprotkb
Q04439
uniprotkb
tabs
as-is
works
comment
num_beams
wierd
prophetnet
case
full
test
test_modeling_prophetnet.py
least
comment
model_tester.ngram
conditional
clear
prophetnet
thing
curiosity
.detach
tensors
documentation
py
loss
=
model
inputs
labels=inputs
safer
way
changes
input
IDs
labels
=
>
BertConfig
file
reference
Intentional
lot
blank
space
Same
comment
sure
DistilBERT
model
smile
suggestion
RetriBERT
model
documentation
proper
defaults
specific
other
model
configs
similar
docstrings
Falubert
models
people
BartForConditionalGeneration
docs
Please
updated
docstring
model
class
~transformers.PreTrainedModel
superclass
documentation
generic
methods
library
implements
model
such
input
embeddings
heads
model
PyTorch
torch.nn.Module
<
https
//pytorch.org/docs/stable/nn.html
torch.nn.Module
>
__
subclass
regular
PyTorch
Module
PyTorch
documentation
matter
general
usage
behavior
suggestion
docstrings
Same
comment
slice
tqdm
-c
'import
transformers
following
output
pkg_resources.DistributionNotFound
'tqdm
>
=4.27
normal
functioning
module
install
transformers
install
-e
dev
]
git
master
distribution
t
q
d
m
>
=
sure
t
q
d
m
>
=
correct
tqdm
>
=
Super
nit
docstring
usual
formatting
type-annotations
new
methods
np.asarray
condition
.nonzero
numpy
documentation
>
only
condition
function
shorthand
np.asarray
condition
.nonzero
nonzero
subclasses
https
//numpy.org/doc/1.18/reference/generated/numpy.where.html
np.ones_like
sure
note
TF
file
*
new
line
..
note
docstring
bad
way
new
line
model
functionality
loss
lm_labels
familiar
BartForConditionalGeneration
class
[
docstring
]
https
//github.com/huggingface/transformers/blob/47591763137f17021928e686ef171f25c240f076/src/transformers/modeling_bart.py
L1053-L1059
tokenizer
=
BartTokenizer.from_pretrained
'bart-large
model
=
BartForSequenceClassification.from_pretrained
'bart-large
input_ids
torch.tensor
tokenizer.encode
Hello
dog
cute
.unsqueeze
Batch
size
labels
torch.tensor
[
]
.unsqueeze
Batch
size
outputs
=
model
input_ids
labels=labels
loss
=
outputs
[
:2
]
better
API
Python
typing
model
[
own
models
obj
torch.nn.Module
same
way
🤗
Transformers
models
input
labels
tuple
loss
first
output
labels
class
Model
nn.Module
def
__call__
inputs
torch.Tensor
labels
torch.Tensor
>
Tuple
[
torch.Tensor
]
something
inputs
labels
loss
link
CSV
loading
page
datasets
Same
comment
confused
docstrings
need
public
documentation
comment
attribute
people
code
correct
docstring
suggestion
TF
BlenderBot
model
fairseq
repo
Marian
suggestion
TF
Marian
model
fairseq
repo
suggestion
TF
Pegasus
model
fairseq
repo
class
Tough
WDYT
@
python
TFEmbeddingsPointer
Wraps
TFSharedEmbeddingTokens
problem
weight
TFWrappedEmbeddings
TFCopiedEmbeddings
docstrings
please
use
sphinx
text
syntax
different
Markdown
object
backticks
italics
double-backticks
syntax
obj
obj
cur_len=0
same
rest
docstring
padding
right
case
model
documentation
uniform
format
section
Inputs
Args
readthedocs/sphinx
doc
generator
link
[
glossary
]
https
//huggingface.co/transformers/glossary.html
possible
re-use
similar
docstrings
possible
other
models
different
docstrings
different
vocabulary
users
Optional
[
glossary
]
https
//huggingface.co/transformers/glossary.html
information
seq2seq
models
great
lengthy
process
better
idea
BART
something
example
[
BERT
file
]
https
//github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py
L545-L587
track
point
comment
helpful
comment
Could
docstring
type
pre-processor
name
class
sufficient
same
reasons
expand_Conv1D
Onnx
export
identical
BatchNorm1d
BatchNorm2d
only
reason
due
way
torch
_check_input_dim
_BatchNorm
expansion
sanity
pytorch
graph
check
noop
def
_check_input_dim
*
return
True
setattr
b1
_check_input_dim
_check_input_dim
https
//github.com/pytorch/pytorch/blob/51861cc9b19d9c483598e39932661822a826d3a2/torch/nn/modules/batchnorm.py
L275
Needs
arguments
okuchaiev
Do
docstring
wait
Please
function
signature
IE
vocab_notation
vocab_punct
Please
types
comments
example
file
user
format
files
format
docstring
wrong
different
style
Google
Style
Pycharm
please
look
other
classes
e.g
core
configs
actual
test
LHS
config
RHS
config
user
misspells
random
args
defaults
error
keys
merge
cfg
None
user
exp
manager
return
Please
doctoring
supported
parameters
dataclass
docstring
user
code
docstrimg
implementation
detail
dataclass
v
[
TODO
]
document
helper
Simply
ModelPT
ModelPT
dataclass
update
class
Question
flag
dataloaders
optim
subconfigs
update_cfg
doesnt
sections
ModelPT
dataclass
Might
useful
/
harmful
Needs
discussion
bos_id
pad_id
class
add
comment
please
type
hint
+
docstring
actual
args
\__init\__
Use
open_dict
Omry
comment
https
//github.com/NVIDIA/NeMo/pull/1049
pullrequestreview-472987867
option
epsilon
other
tasks
Add
eps=1e-7
dont
use
character
names
variables
class
deleted
args
same
questions
member
email
reviewer
configuration_note
previous
loop
reviewers
area
chairs
group
submissions
right
dictionary
forum
IDs
submissions
index
blind_note.original
value
line
something
submissions_by_forum
=
n.forum
n
n
client.get_notes
invitation=config.SUBMISSION
loop
note
note
=
submissions_by_forum
[
blind_note.original
]
script
reviewers
AnonReviewer
group
AnonReviewer
Reviewers
group
docstring
type
hint
line
above
comment
cleaner
way
file
function
tempfile
library
Python
Example
tempfile.NamedTemporaryFile
suffix=
.png
t
Print
path
file
example
print
t.name
>
>
>
/var/folders/7g/64z6m5x92n12p21mspg9d384xwrlwt/T/tmp0bkf6n14
need
filesystem
file
memory
context
@
yaakovi
mandatory
widget
script
comment
same
behavior
today
comment
secret
please
type
hint
comment
case
till
layout
correct
add
comments
onwards
suggestion
Docstring
Please
docstring-doesnt-exits
Ensure
main
function
Spelling
index_
*
functions
index_bootcamps
index_programs
index_learning_paths
function
separate
index_
profile
comment
post
course
alternative
next
next
sort-of
lower-level
operation
something
use
Pythonic
python
english_captions
[
caption
caption
all_captions
caption.code
]
sort
auto-generated
captions
bottom
list
sorted_captions
english_captions
key=lambda
caption
auto-generated
caption.name
return
sorted_captions
]
sorted_captions
None
few
key
differences
non-english
captions
sort
property
bool
values
integer
auto-generated
ones
bottom
list
first
item
list
None
Can
new
arguments
docstring
Again
sure
production
course
program
MM
import
task
course
Program
model
other
example
@
pytest.mark.parametrize
has_account_id
has_secret_key
[
[
True
False
]
[
False
True
]
[
True
False
]
]
def
test_get_events_no_vars
client
user
settings
has_account_id
has_secret_key
settings
present
settings.LIVESTREAM_ACCOUNT_ID
account_id
has_account_id
None
settings.LIVESTREAM_SECRET_KEY
=
secret_key
has_secret_key
None
client.force_login
user
resp
=
client.get
reverse
livestream
resp.json
resp.status_code
==
status.HTTP_503_SERVICE_UNAVAILABLE
arguments
return
value
docstring
Same
comment
comment
filtering
action
query
comment
assert
Copy/paste…
comment
sense
suggestion
verification
anonymous
name
user
anonymise
.......
documentation
translate
french
Wording
good
one
Add
exception
Duplicate
code
comment
replacement
dedicated
function
class
UserConfig
DeclarativeBase
User
Config
definition
table
stores
parameters
Tracim
clients
Tracim
frontend
=
user_configs
user_id
=
Column
Integer
ForeignKey
users.user_id
CASCADE
CASCADE
primary_key=True
raw-string
literal
r
sense
comment
rule
method
=
tchar
%
/
*
+
/
^
_
|
~
/
DIGIT
/
ALPHA
token
=
*
tchar
reason
Path
>
>
Path
conversion
something
please
comment
Don
’
t
use
variable
annotations
syntax
error
type
hints
comment
python
MAX_TIME
=
datetime.datetime.max.replace
tzinfo=datetime.timezone.utc
type
datetime.datetime
’
t
type
hint
fine
suggestion
MAX_TIME
=
datetime.datetime.max.replace
[
Flake8
]
__
[
E122
]
continuation
line
indentation
<
Comment
[
SideCI
]
https
//sideci.com
>
Please
coding
standards
https
//github.com/inasafe/inasafe/wiki/Coding-Standards
doc-strings-and-comments
example
A
person
attendee
course
course
CourseAttendee
model
gender
sentences
use
fine
s/he
newline
first
line
docstring
subsequent
lines
docstring
Please
same
course-ceritificate
comment
newline
first
line
test
pass
condition
different
Take
care
conventions
First
line
<
full
stop
newline
multiple
lines
extended
description
citation
website
comment
Worth
comment
test
Fix
comment
explanation
Try
others
changes
easy
comments
benefit
value
low
amount
basket
free
checkout
page
checkout
page
bit
bit
functions
diff
comment
new
requests
operations
corresponding
edx-enterprise
view
order
extra
request
overhead
e.g
large
orders
See
previous
comments
PR
details
same
comment
code
docstring
https
//edx.readthedocs.io/projects/edx-developer-guide/en/latest/style_guides/python-guidelines.html
id4
Docstrings
chars
width
asadiqbal08
No
exception
exception
cases
enterprise
customer
voucher
logs
>
try/except
clauses
try
clause
absolute
minimum
amount
code
necessary
Again
avoids
bugs
ref
http
//legacy.python.org/dev/peps/pep-0008/
programming-recommendations
>
>
Yes
>
>
try
>
value
=
collection
[
key
]
>
KeyError
>
return
key_not_found
key
>
>
return
handle_value
value
>
No
>
try
>
Too
broad
>
return
handle_value
collection
[
key
]
KeyError
>
Will
KeyError
handle_value
return
key_not_found
key
problem
Did
order
point
Did
second
payment
call
Other
answer
different
problem
someone
problem
warning
Note
exception
info
reason
exc_info=True
parameter
NOTE
above
relevant
comment
code
further
investigation
EG-XXX
appropriate
comment
efficient
method
simple
product
delete
anything
python
try
product_class
=
ProductClass.objects.get
slug=WRONG_SLUG
product_class.slug
=
RIGHT_SLUG
DoesNotExist
nothing
pass
revert
same
constant
names
result
batch
tedious
devops
Again
class
def
_get_headers
headers
authenticated
JWT
access
token
access_token
__
=
self._get_access_token
self.headers
'Authorization
+
access_token
Similar
comment
]
https
//github.com/edx/edx-enterprise/pull/910/files
r469273710
default
everyone
variable
add
comment
variable
course_run_id
course_key
generic
name
course_ids
Great
Thank
minor
updates
docstring
”
”
Temporary
test
problem
SubmitPaymentView
invalid
voucher
waffle
switch
False
LEARNER-5719
”
”
Nit
tests
little
cleaner
start_time
variables
test
expired_end_time
’
actual
BusinessClient
model
name
field
limit
characters
https
//github.com/edx/ecommerce/blob/master/ecommerce/core/models.py
L591-L594
python
class
BusinessClient
models.Model
model
business
client
name
=
models.CharField
_
'Name
unique=True
max_length=255
i
function
name
self-explanatory
is_duplicate_seat_attempt
comment
fine
Please
comment
custom
exception
exception
rest
logging
below
logs
query
None
applicable_range
None
*
*
*
applicable_range
None
None
python
applicable_range
=
range
range
self.range
applicable_range
None
applicable_range.catalog_query
None
applicable_range.catalog_query
return
super
..
query
=
applicable_range.catalog_query
TODO
request
data
coupon
data
offer
voucher
needs
TODO
Update
Yes
something
marketing
user
scope
caching
marketing
user
anything
MARKETING_USER
=
def
test_countries_sorting
Verify
country
choices
country
data
=
self._generate_data
form
=
PaymentForm
data=data
[
country.alpha_2
country.name
country
pycountry.countries
]
x
x
]
actual
=
list
form.fields
[
'country
]
.choices
Choose
country
placeholder
self.assertEqual
actual
nit
docstring
help
text
link
top
comments
developer
likely
wonder
help
text
thanks
filehandle
open
CSV
government
website
entire
duration
file
processing
minutes
file
connection
times
file
file
worth
file
local
memory
+
process
connection
open
f
=
open
demofile.txt
r
=
f.readlines
read
file
array
strings
csv_rows
need
comment
current
display
scheme
self.unique
unique
id
id
See
Adams
comment
print
statements
code
Please
multiline
comment/description
function
blurb
function
inputs
format
outputs
disk
formats
Examples
most
other
scripts
utils
folder
df
descriptive
name
better
readability
comments
print
statements
code
side
comments
else
change
notation
distribution
Remove
blank
line
comment
code
earlier
comment
cell_neighbor_freqs
copy
code
block
earlier
comment
change
argument
enrichment_type
@
Bidibulke
link
previous
comment
package
slightly_smiling_face
OCD
suggestion
suggestion
DOCK
molecular
docking
program
drug
discovery
program
protein
site
small
molecule
tries
correct
mode
small
molecule
binding
site
associated
binding
energy.
longer
description
separate
paragraph
e.g
module
files
short
sentence
beginning
things
module
what-is
entire
docstring
informative
commands
module
info
something
cuda_arch
=
spec.variants
]
.value
cuda_arch
None
cuda_arch
]
_mark_plugins_for_rewrite
function
call
_preparse
OR
explanation
plugins
flag
mappings
JSON
other
comment
needs
work
relevant
values
anything
naive
reader
idea
relevant
anything
formats
examples
descriptions
formats
docstring
description
return
type
google
format
Arguments
Returns
sections
testability
clarity
dict
parameter
result
config.get
config
config.get
store-specific
logic
result
thing
dict
empty
comment
line
complicated
def
providers
parser
args
valid_virtuals
spack.repo.provider_index.providers.keys
arguments
list
virtual
packages
args.virtual_package
sys.stdout.isatty
tty.msg
'Virtual
packages
colify.colify
valid_virtuals
one-line
change
spack
list
needs
suggestion
NFS
Utilities
package
userspace
server
client
tools
following
dependencies
python_version
Enums
Python
<
'contextlib2
python_version
Python
contextlib
backport
Python
'numpy
<
=1.16.4
python_version
python_version
=
URL
documentation
tests
last
sentence
last
sentences
case
glob
expression
directories
function
wrong
<
somedir
>
/
*
.h
error
lot
dependency
versions
python
pkg_resources.parse_version
setuptools.__version__
<
pkg_resources.parse_version
raise
RuntimeError
cryptography
newer
upgrade
newer
version
setuptools
setup_requirements
cffi
>
=1.8
=1.11.3
python_requires=
>
=2.7
=3.0.
*
=3.1.
*
=3.2.
*
=3.3
*
asn1crypto
>
>
]
+
setup_requirements
python_version
<
enum34
ipaddress
]
test
pytest
>
=3.6.0
=3.9.0
=3.9.1
=3.9.2
pretend
iso8601
pytz
hypothesis
>
=1.11.4
=3.79.2
]
docs
sphinx
>
=
=1.8.0
sphinx_rtd_theme
]
docstest
doc8
pyenchant
>
twine
>
sphinxcontrib-spelling
>
]
pep8test
flake8
flake8-import-order
pep8-naming
]
extra
U-label
support
cryptography
deprecated
path
install
pip
install
cryptography
[
idna
]
idna
idna
>
]
extras
things
idna
variants
default
first
paragraph
docstring
short
description
package
many
places
e.g
module
files
something
suggestion
HAL
structure
index
multiple
genome
alignments
ancestral
reconstructions
HAL
graph-based
representation
several
advantages
matrix/block-based
formats
such
MAF
such
improved
scalability
ability
queries
respect
arbitrary
reference
subtree
super-small
comment
structure
symmetric
function
callable
maintainers_to_packages
packages_to_maintainers
lines
fine
solution
suggestion
depends_on
py-sphinx
when=
+docs
type=
build
prior
versions
vulnerability
comment
vulnerability
url
libpng
singularity
other
packages
open-ended
software
lot
comment
artificial
upper
limit
latest
tested
release
need
pass
function
docstring
configure_directory
=
Intel
compilers
conflicts
directives
other
compiler
comment
code
print
Independent
__future__
import
print_function
print
spec.to_yaml
python
suggestion
termios
available
old
settings
reverse
logic
environment
action
objects
value
variable
time
unset
TODO
appropriate
likely
effort
anyhow
suggestion
Burkhard
Morgenstern
al
..
comment
2-3
line
summary
discussion
py-simplejson
something
python
Serializes
data
JSON
format
AVRO
schema
question
sure
backgrounded
process
pipe
parent
process
False
case
docstring
circumstances
function
results
meaningful
sense
method
name
_
use
module
lines
flake8
tests
idea
necessary
above
flags
feeling
Homebrew
recipe
Spack
Does
anyone
things
disable-dependency-tracking
disable-silent-rules
Homebrew
package
most
Spack
packages
useful
default
arguments
AutotoolsPackage
base
class
worth
docstring
least
arguments
argument
reference
original
docstring
comment
standard
definition
comment
triple
quote
single
quote
string
@
run_after
'configure
def
skip_update_checks
Delete
bindir
/embossupdate
update
checks
bindir
/embossupdate
string=True
way
phases
phases
%
s
string
formatting
python
documentation
formatting
operations
obsolete
future
versions
Python
new
String
Formatting
new
code
case
able
INSTALL_DIR=
+
prefix.bin
ETC_DIR=
+
prefix.etc
Same
request
docstring
other
packages
smirk
line
earlier
comment
factory
code
substantial
performance
correctness
reason
function
docstring
blank
line
first
sentence
rest
docstring
newline
python
class
RDirichletmultinomial
RPackage
Dirichlet-multinomial
mixture
models
variability
microbial
metagenomic
data
package
interface
tgamblin
clearer
name
test_parse_filename_missing_slash
weirdly-namespaced
yaml
package
symptom
test
corresponding
check
test_parse_yaml_relative_paths
Test
command
spack
spec
libelf.yaml
specs
sp.parse
file_name
good
everything
order
confusion
similar
explanation
good
worthwhile
change
Same
requirements
preferences
depends_on
requirements
preferences
action
aside
constraints
depends_on
depends_on
type='build
when=
+cuda
trip
Spack
current
greedy
concretization
algorithm
combination
universal
constraint
constraint
condition
unlikely
problem
Spack
latest
possible
version
package
likely
problem
constraints
upper
bounds
More
https
//github.com/spack/spack/issues/5465
issuecomment-332027738
item
[
]
https
//github.com/spack/spack/wiki/Issue-Disambiguation
suggestion
Neo4j
world
leading
Graph
Database
high
performance
Unicode
suggestion
Support
software
Statistical
Analysis
Data
Display
Support
software
Statistical
Analysis
Data
Display
Second
Edition
Springer
ISBN
First
Edition
Most
other
packages
note
suggestion
export
SENTIEON_LICENSE=
[
FQDN
]
[
PORT
]
Note
manual
download
Spack
current
directory
download
file
file
mirror
Spack
instructions
mirror
http
//spack.readthedocs.io/en/latest/mirrors.html
package
fine
Spack
way
worth
Package
comment
license
other
FIXME
Spack
built0in
variant
cmake
packages
explicit
build_type
variant
Rather
version
restrictions
variant
dependency
specification
better
conflict
depends_on
variant
older
versions
support
LibFoo
variant
default=True
description='Support
LibFoo
conflicts
when=
@
:2.3
depends_on
conflicts
fork
new
name
least
comment
systems/python
versions
suggestion
include_regex
=
re.compile
r
*
regex
master
fact
first
glance
laughing
comment
simpler
modifications
works
first
match
non-greedy
more
tests
installation
run-test=root
flag
tests
something
prob
variant
main
page
documentation
minimum
Same
comment
long
shot
smart
quote
docstring
problem
Python
Python
regular
quote
suggestion
jdatetime
Jalali
implementation
Python
datetime
module
additional
requirements
py-six
requirements.txt
bedtools
optional-requirements.txt
matplotlib
optional-requirements.txt
htslib
optional-requirements.txt
ucsc-bigwigtobedgraph
optional-requirements.txt
ucsc-bedgraphtobigwig
optional-requirements.txt
ucsc-wigtobigwig
optional-requirements.txt
test-requirements.txt
test-requirements.txt
pyyaml
test-requirements.txt
sphinx
test-requirements.txt
sure
current
stand
test-requirements
optional
ones
variants
appropriate
Sry
long
nitpicky
comment
couple
hours
dependency
comment
transient
requirement
care
scheibelp
suggestion
patch
//github.com/hpcg-benchmark/hpcg/commit/e9e0b7e6cae23e1f30dd983c2ce2d3bd34d56f75.patch
sha256='23b9de83042eb7a8207fdddcfa79ae2cc1a17e8e623e2224c7751d7c328ee482
%
gcc
way
full
patch
repository
comment
https
//github.com/hpcg-benchmark/hpcg/commit/e9e0b7e6cae23e1f30dd983c2ce2d3bd34d56f75
older
GCCs
clause
many
dependencies
build
time
@
tgamblin
extra
@
davydden
consistent
license
header
Copyright
2013-2018
Lawrence
Livermore
National
Security
LLC
other
Spack
Project
Developers
top-level
COPYRIGHT
file
details
SPDX-License-Identifier
Apache-2.0
OR
MIT
documentation
default
note
mysql
sure
virtual
dependencies
variants
comment
fine
needs
package
description
boilerplate
needs
Can
docstring
descriptive
reason
other
Spack
package
custom
module
build_environment.py
easy
shortcut
m.env
=
depends_on
order
versions
https
//github.com/RadeonOpenCompute/rocm-cmake/blob/master/CMakeLists.txt
L5
VERSION
TODO
lowerbound
depends_on
name=value
bit
comment
strong
opinions
default
better
documentation
comment
MPI
flavors
spack-default
OpenMPI
comment
VTK
separate
CMake
variables
library
locations
mesa
unaware
historical
reasons
minute
OSMesa
offscreen
mesa
mesa
opengl
library
implementation
case
OPENGL_gl_LIBRARY
OPENGL_INCLUDE_DIR
library
libGL.so
OSMesa
library
libOSMesa.so
different
CMake
variable
case
PR
options
Good
question
many
options
VTK
reasonable
set
things
majority
people
wrong
selection
way
offscreen
hardware
option
VTK
EGL
additional
rendering
options
road
@
mathstuf
thoughts
lines
Build
documentation
Enable
building
documentation
-j8
Spack
-j
+
cores
install
-j8
lordec
docstring
document
return
type
document
urlparse
docstring
simpler
else
clause
CMake
things
dependencies
system
non-deterministic
builds
names
executables
particular
flavor
MPI
self.spec
[
]
friends
comment
concretizer
bug
todo
openmpi
constraint
concretizer
self.compiler.cc
actual
compiler
compiler
wrapper
possible
Spack
compiler
wrapper
docstring
anything
new
version
function
case
private
underscore
logic
comments
spack.yaml
IMO
test
test_config_update_can_handle_comments
test/cmd/config
clear
analogous
logic
ConfigScope
deepcopy
write
notion
wrong
@
goxberry
Can
short
period
broader
description
first
period
short
description
entire
docstring
long
description
link
website
https
//cea-hpc.github.io/modules/
link
documentation
portal
minor
comment
suggestion
ppOpen-APPL/BEM
software
boundary
element
analysis
parallel
computer
current
version
software
framework
parallel
BEM
analysis
H-matrix
library
framework
dense
matrix
computations
move
directory
'src/framework_with_template
H-matrix
library
move
'src/HACApK_with_BEM-BB-framework_1.0.0'.
change
module
files
first
paragraph
short
description
whole
docstring
longer
help
DAG
hash
list
binary
caches
binary
package
DAG
hash
member
comment
updated
name
self._mirrors_for_spec
comment
gdal
@
+python
comment
lin
line
PR
gcc
@
conflicts
conflicts
statement
older
versions
newer
versions
Might
comment
file
version
requirement
comment
message
environment
activate
deactivate
worth
docstring
package
Could
docstrings
log_path
install_log_path
build_log_path
sense
name
test_deprecate_already_deprecated_spec
longer
informative
test
functions
behavior
catalyst
code
requirement
+python
+catalyst
suggestion
catalyst
Python
conflicts
when='+catalyst
period
end
sentence
Last
Spack
newline
characters
indentation
docstring
spack
info
recon
way
MakefilePackage
base
class
<
build_targets
<
install_targets
default
build
targets
empty
default
install
targets
install
symlinking
step
installation
something
@
run_after
'install
def
symlink_foo
print
self.prefix
first
sentence
rest
docstring
python
class
Orthofinder
Package
OrthoFinder
fast
accurate
comprehensive
analysis
tool
comparative
genomics
orthologues
strict
requirement
[
triple
strings
]
https
//docs.python.org/3/library/stdtypes.html
text-sequence-type-str
docstrings
Could
Little
typo
suggestion
Easy
HDF5
C++
Serial
Parallel
HDF5
mono
variant
declarations
variant
TODO
points
condition
moment
False
suggestion
Code
base
U.S.
EPA
Community
Multiscale
Air
Quality
Model
unicode
failing
unit
tests
CMake
package
helper
function
defines
boolean
string
variants
suggestion
options.append
self.define_from_variant
'DEAL_II_COMPONENT_DOCUMENTATION
easier
sort
layout
@
pytest.mark.parametrize
'config
[
API
V1-only
build
arrangement
version
'pulp_push
True
True
'pulp_pull_in_orchestrator
False
[
]
[
application/json
]
API
V1+V2
build
arrangement
version
>
=
schema2-capable
Pulp
'pulp_push
True
False
'pulp_pull_in_orchestrator
True
[
application/vnd.docker.distribution.manifest.v1+json
application/vnd.docker.distribution.manifest.v2+json
application/vnd.docker.distribution.manifest.v2.list+json
]
[
application/json
application/vnd.docker.distribution.manifest.v1+json
application/vnd.docker.distribution.manifest.v2+json
application/vnd.docker.distribution.manifest.v2.list+json
]
verb
plugin
name
fine
comment
line
concepts
manifest
list
people
code
able
E265
block
comment
comment
code
auths
key
exists
vs
[
value
]
None
re-write
'auths
self.json_secret
self.json_secret
=
self.json_secret
[
]
str
assert
object
fail_reason=False
valid
image_id
method
True
bool
self._fail_reason
falsy
value
fail_reason
scenario
>
>
>
BuildResult
fail_reason=None
image_id='spam
Good
>
>
>
BuildResult
fail_reason=True
image_id='spam
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
File
atomic_reactor/build.py
line
__init__
Either
fail_reason
image_id
AssertionError
fail_reason
image_id
Either
fail_reason
image_id
Good
Error
>
>
BuildResult
fail_reason=False
image_id='spam
True
Uh
right
comment
main
discussion
E265
block
comment
docstring
list
lists
component
dicts
method
name
get_component_list
list
components
get_components_from_workers
doc
string
worker
build
component
list
single
worker
build
Find
components
worker
build
return
inaccurate
list
component
lists
JSON
great
data
object
program
picky
syntax
comments
YAML
easier
comments
file
likely
hand-edited
time
time
likely
benefit
comments
Other
formats
comments
example
INI
something
common
use
data
>
YAML
easier
comments
good
point
stick
comments
possible
json
other
javascript
code
python
interpreter
strict
please
change
logic
fine
expected
platforms
good
values
early
platform
complicated
concept
line
commentary
helpful
comment
more
different
behavior
rollout.flatten_trajectories
process_trajectories
brief
docstring
value
necessary
great
summaries
other
SB
Will
comment
docstring
output
subdirectories
mean_logger
clear
problem
Add
comment
Same
comment
name
prohibit
NotImplementedError
suggestion
elif
spec.max_episode_steps
None
check
https
//github.com/openai/gym/pull/1626
Ah
old
implementation
infinite
horizon
recursion
comment
om
stands
occupancy
measure
docstring
One-liner
docstrings
newline
closing
helpful
comment
check
existence
file
suggestion
def
test_config_modification
In-memory
modification
project
configuration
version
unit
test
change
project
configuration
immutable
easier
future
devs
file
comment
obvious
suggestion
Context
manager
read
write
operations
first
paragraph
doc-string
line
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
comment
meaning
hard-coded
id
compatibility
feature
rapidjson
sure
plain
json
module
documentation
JSONEncoder
suggestion
def
is_base_type
cls
data
Check
data
same
base
type
such
list
dict
class
pass
description
algorithm
code
comment
comment
correct
TODO
room
future
improvement
suggestion
loop
synced
collections
performance
TODO
Potential
improvements
code
i
range
min
data
Previous
discussion
https
//github.com/glotzerlab/signac/pull/336
discussion_r446540980
Please
dfs
depth-first
traversal
docstrings
traversal
acronym
obvious
suggestion
Update
instance
SyncedList
data
depth-first
traversal
documentation
AttrDict
suggestion
Add
_validator
attribute
subclass
validators
data
other
files
easier
instances
data
=
validator.validate
data
returns
validators
tests
easy
line
returns
docstring
formatting
param
jobs
implies
jobs
specific
argument
clear
variable
number
arguments
difficult
work
docs
best
recollection
correct
way
python
r
Find
differences
list
jobs
state
points
diff
dictionary
keys
job
ids
values
job
state
point
intersection
jobs
state
points
param
*
jobs
more
jobs
state
points
returns
dictionary
keys
job
ids
values
unique
parts
job
state
point.
raw
string
r
beginning
backslash
literal
backslash
more
documentation
function
line2reads
nice
such
file
format
good
comment
line
comment
need
teardown
evidence
object
path
ambitious
other
docstrings
docstring
class
log
file
JSON
format
other
tests
Sorry
instance
before
kind
similar
type
risky
parsing
port
example
other
things
'password
line
something
TODO
update
password
regex
output
split
concerned
spaces
.strip
spaces
method
list
image
objects
list
image
IDs
worth
format
list
log2timeline
style
guide
comment
id
attributes
images
Sorry
bit
last
comment
valid
TurbiniaTaskResult
object
errors
other
checks
fine
error
short
term
self.result
exists
new
TurbiniaTaskResult
object
similar
validate_result
call
self.result.setup
self.log
message
logging.error
traceback_=trace
second
PR
places
TurbiniaTaskResult
single
method
setup
methods
exception
handling
non-trivial
things
risk
more
exceptions
exception
handling
valid
results
server
task
sorry
dupe
comment
nice
input
parameters
function
requester
info
notification
person
Turbinia
request
requester
username
though
EMAIL_DOMAIN
config
notify
method
turbiniactl
Add
docstring
appropriate
exceptions
things
invalid
json
de.py
command
Add
documentation
items
list
deleted
users
ids
comment
right
thing
nice
block
comment
respect
class
Docker
API
Add
high-level
comment
Yeah
documentation
pretty
flaky
API
string
unclear
stderr
stdout
logs
command
live
container
check
python
sdk
format
same
http
API
format
function
Already
earlier
comment
vect
variable
Add
comment
value
docstring
more
explicit
decorator
correct
None
prediction
table
primary
key
docstring
parameters
section
docstring
private
function
comment
NO_SKLEARN_BACKEND
better
name
ll
true
future
scikit-learn
versions
joblib
module
scikit-learn
isn
’
t
installed.
difference
uuid
value
one
today
comment
ok
models_library/settings
place
change
packaging
settings
flat
list
names
permutations
same
strategy
docker-compose
[
deploy
constraints
https
//docs.docker.com/compose/compose-file/
deploy
policies
configs
etc
First
hierarchies
e.g
service
client
policy/config
separate
entry
service
python
class
RetryPolicy
BaseModel
wait
Optional
[
PositiveInt
]
=
None
tenacity
defaults
clients
class
EntryPoint
BaseModel
host
port
client-focus
common
settings
class
StorageClientSettings
BaseSettings
retry_policy
Optional
[
RetryPolicies
]
=
None
request_timeout
PositiveInt
=
Field
description=
SOMETHING
INFORMATIVE
class
Config
env_prefix
STORAGE_CLIENT_
class
DirectorClientSettings
BaseSettings
retry_policy
Optional
[
RetryPolicies
]
=
None
stop_request_timeout
PositiveInt
class
Config
env_prefix
DIRECTOR_CLIENT_
way
*
retry
policies
redis
[
postgres
https
//github.com/ITISFoundation/osparc-simcore/blob/d0acfaf96dc729b2bca5b7056c9b24893f941b74/packages/service-library/src/servicelib/aiopg_utils.py
place
generic
models
https
//pydantic-docs.helpmanual.io/usage/models/
generic-models
propagate_mode
option
message
ID
threshold
https
//zulipchat.com/api/update-message
parameters
basic
documentation
itertools.islice
overkill
lines
~~~
issue_prs
=
re.finditer
....
requests
denial-of-service
issuer_prs
=
issue_prs
[
:5
]
~~~
Technically
error
message
somebody
tries
requests
line
if/else
duplication
comment
other
statements
comment
code
models
future
assert
expected
case
please
comment
comment
works
CSV
header
row
dict
headings
keys
goods
new
application
please
goods
old
app
new
app
comment
other
applicable
methods
test
scenario
comments
Docstrings
Add
comment
is_background_task
tin
Move
private
function
exception
handling
wee
comment
View
class
particular
reference
filtering
needs
kind
comment
comment
please
Please
process
arguments
Gim
comments
context
expectations
regards
format
data
TODO
Complementary
previous
comment
good
feeling
test
invalid
input
substitute
option
exception
place
check
LombScarglePeriodogram.from_lightcurve
lc_with_nans
further
discussion
willing
methods
to_periodogram
/
from_lightcurve
NaN
input
Examples
section
Parameters
section
something
def
remove_outliers
One-line
sentence
method
Longer
explanation
method
Examples
>
>
>
code
output
code
Parameters
param1
type
description
param1
etc
Thanks++
bit
worried
following
mission
property
base
class
worried
non-standard
TPFs
to_lightcurve
generic
object
mission
property
safer
Python
fig.xaxis.axis_label
=
days
try
lc.mission
fig.xaxis.axis_label
=
AttributeError
mission
keyword
available
pass
docstring
strings
function
obvious
code
sphinx
docs
page
function
code
default
confusion
Kepler
absolute
pixel
scale
~4
arcsec
pixel
docstring
something
Pixel
scale
stretch
parameter
i.e
numbers
PRF
model
needs
column
row
directions
focus
changes.
comment
cholesky
dense
matrix
fine
sense
choose
parsers
little
strange
blob
timestamp
options
timestamp_format
option
sense
function
add_timestamp_parser
session
timestamp
parser
session
config
way
timestampy
functionality
function
easier
something
safer
current
code
consistent
positions
items
python
positions
itertools.count
disabled_positions
itertools.count
item
form_items
key=attrgetter
'position
pos
=
next
positions
item.is_deleted
else
disabled_positions
item.position
=
step
whole
regform
python
section_positions
itertools.count
disabled_section_positions
itertools.count
section
regform.sections
key=attrgetter
'position
section_active
=
section.position
=
next
section_positions
section_active
else
disabled_section_positions
consistent
field
positions
itertools.count
disabled_positions
itertools.count
child
section.children
child_active
=
child.position
=
next
positions
child_active
else
disabled_positions
Los
compute
que
empiecen
por
_compute_
query
injection
Use
proper
form
cr.execute
UPDATE
ir_model_data
SET
name
=
%
s
WHERE
name
=
%
s
AND
module
=
list
[
key
]
key
se
si
es
necesaria
palabra
aeat
este
método
pero
la
lo
mismo
que
arriba
Revisa
todos
los
__openerp__.py
docstring
[
triple-double
]
https
//en.wikipedia.org/wiki/Double-double_
basketball
Triple-double
Triple
single
quotes
harder
suggestion
Add
tag
built-in
conditions
graph
detection
suggestion
JobOperation
_JobOperation
_JobOperation
test
@
b-butler
previous
comment
_JobOperation
JobOperation
single
job
argument
raise
custom
DirectivesError
error
class
example
https
//stackoverflow.com/a/29442282
Search
code
base
example
error
class
docstring
something
python
class
DirectivesError
Exception
pass
raise
DirectivesError
err
suggestion
actual
number
processes/threads
suggestion
_Directives
class
suggestion
_DirectivesItem
class
suggestion
OpenMP
prefix
omp_num_threads
directive
*
omp
*
legitimate
abbreviation
OpenMP
bit
precise
documentation
first
line
doc-string
proper
sentence
therefore
len
check
optimization
comment
effect
check
conditions
equivalent
[
]
evaluates
>
new
[
]
length
=
same
comment
new
>
Resource
URI
READ
ONLY
[
]
length
=
quote
mark
most
time
convention
docstrings
tools
doc
string
unittest
package
imports
import
json
stdlib
import
requests_mock
third
party
config
import
TestingConfig
project
response_operations_ui
import
create_app
tests.views
import
ViewTestCase
Same
logging
comments
function
comment
part
implementation
Same
comment
new_account_exists
doens't
need
new
endpoint
template
description
good
Python
try
user
=
User
response_json.get
'user_id
token
session
server
side
redis
session
'token
]
=
response_json
[
'token
]
login_user
user
session
return
redirect
session
[
'next
]
return
redirect
url_for
'home_bp.home
KeyError
return
render_template
form=form
part
early
return
chunk
True-branch
Related
earlier
comment
publish
same
thing
places
thisisshi
re
comment
variables
consistency
class
caps
underscore
name
variable
actual
schema
previous
comments
directory
creation
outputs
caller
context
handler.py
static
name
hard
next
person
re-record
people
sub
Might
random
number
something
group
name
test
setup
least
available
able
storage
names
random
time
tools/c7n_azure/tests/test_storageutils.py
setup_account
storage
account
e.g
account
=
self.setup_account
=
https
//
+
account.name
+
.blob.core.windows.net/testcc
queue
messages
example
same
file
e.g
Pull
messages
messages
=
StorageUtilities.get_queue_messages
*
queue_settings
messages
Read
message
queue
message
messages
self.assertEqual
message.content
u
hello
queue
StorageUtilities.delete_queue_message
*
queue_settings
message=message
wrt
threading
towards
consistency
patterns
usage
ie
concurrent.future
submit
worker
pool
resource
set
concurrent
futures
overhead
general
amount
work
execution
ie
pseudo
python
code
c7n.utils
chunks
futures
[
]
results
[
]
thread
pool
context
manager
following
block
resource_set
chunks
resources
futures.append
w.submit
client
resource_set
f
futures
f.exception
log
results.extend
f.result
results
question
i
thread
safety
azure
client
instances
i
thread
safe
swagger
static
gen/urllib3/requests
comms
project
sure
sense
set
.filter
below
releases
deleted
project
index
something
special
release
make
sense
comment
scripts
better
one
hard
indicative
name
reasonable
length
docstring
functionality
link
API
docs
please
json.dumps
argument
json_data
true
subsequent
uses
BaseClient._http_request
comment
update
add
fields
regards
comments
func
main
return
type
hint
dont
generic
http_request
token
url
need
proxy
param
section
COMMANDS
MANAGER
/
SWITCH
PANEL
section
lets
comment
better
functions
datetime-Python3
dateutil
possible
add
args
args
get_indicators_command
entry_context
[
discussion
]
https
//demisto.slack.com/archives/CRT0G4Y82/p1579600127004000
human_readable
raw_response
Make
sure
docstring
test
playbook
raw_response
entry_context
test
playbook
returns
docstring
accurate
update
docstring
suggestion
ioc_value
=
item.get
domain
*
ioc_value
item
type
]
=
FeedIndicatorType.DomainGlob
item
[
value
=
value
string
need
str
same
attachments
comments
ones
last
update
time
test
comment
entry
difference
result1
please
explain
docstring
function
Please
description
accurate
lets
style
add
comment
logic
add
return
print
many
lines
log
print
add
docstring
google
style
content
worth
function
name
explanation
comment
easy
code
flow
type
hints
suggestion
Disable
stdout
exit
same
comment
Provide
example
docstring
docstring
set_remote_init_builder
set_initializer
enough
codes
understanding
implementation
proxy
=
node_frame
=
Frame
def
remote_init_fn
shape
dtype
ctx
name
proxy.init_data
shape
dtype
name
data
empty_shared_mem
btw
name
empty
confusing
content
*
*
empty
data
remote_init_fn
tensorflow
backend
Add
documentation
class
methods
code
raw
input
node
features
code
Remove
Empirically
atomic
numbers
C
N
O
F
S
CI
documentation
Note
current
elements
H
C
N
O
F
Simple
configurations
integers
strings
argparse.ArgumentParser
command
line
arguments
current
way
docstring
possible
values
Please
comments
Docstrings
RPC
methods
same
same
comments
Add
behavior
Seems
argument
nlp
requirement
Add
documentations
docstrings
errors
loss
add
comments
btw
previous
comment
Python
comments
class
function
definition
docstring
share_ndata
share_edata
share_ndata
bool
optional
True
node
features
reversed
graph
same
original
graph
False
graph
node
features
Default
True
share_edata
bool
optional
True
edge
features
reversed
graph
same
original
graph
False
graph
edge
features
Default
False
dataset
'test
elif
hoster
==
'test
comment
comments
https
//github.com/coala/community/pull/160/files
r200812800
_
prefix
denotes
private
local
variable
private
_
prefixes
local
variables
proper
variable
name
issues
E265
block
comment
*
Origin
PycodestyleBear
E265
Section
all.python.default
code
PEP8
*
Origin
PEP8Bear
Section
all.python.default
issue
following
patch
diff
a/tmp/tmpqnuuwufy/meta_review/handler.py
+++
b/tmp/tmpqnuuwufy/meta_review/handler.py
@
@
-76,7
+76,8
@
@
record
comment
id
reaction_data
[
'comment_id
]
=
comment
[
'id
]
parse
time
reaction_data
[
]
=
parse_time
reaction_data
[
'createdAt
]
+
reaction_data
[
'createdAt
]
=
parse_time
+
reaction_data
[
'createdAt
]
self.reactions
reaction_data
[
'id
]
]
=
reaction_data
save
participants
memory
invalid
own
docs
bear
bug
someone
pydocstyle
bear
compliant
bears
single
line
syntax
consistent
other
docstrings
more
explanation
Foo.
Hard
comment
separate
ERROR
constant
code
data
docstring
wrong
something
main
method
docstring
wrong
something
main
loop
Status
bar
queue
priorities
node
patch
diff
git
a/src/network/addrthread.py
b/src/network/addrthread.py
index
a/src/network/addrthread.py
+++
b/src/network/addrthread.py
@
@
-32,12
+32,12
@
@
class
AddrThread
StoppableThread
i
connections
randomshuffle
chunk
=
[
]
stream
peer
source
chunk
+
stream
peer
source
chunk
i.destination
peer
source
continue
stream
i.streams
filtered.append
stream
peer
time
filtered.append
stream
peer
self.logger.warning
addr
len
%
s
diff
git
a/src/network/bmproto.py
b/src/network/bmproto.py
index
..
b496e2b0
a/src/network/bmproto.py
+++
b/src/network/bmproto.py
@
@
-457,7
+457,7
@
@
class
BMProto
AdvancedDispatcher
ObjectTracker
peers
knownnodes
knownnodes
flood
addrQueue.put
stream
peer
self.destination
addrQueue.put
stream
peer
self.destination
seenTime
True
def
bm_command_portcheck
careful
signature
mask_subtrace
jit
cache
transformations
'static
arguments
case
master
polymorphic_shapes
function
way
changes
logical
shapes
problem
python
]
import
jax
import
np
import
functools
[
]
@
functools.partial
jax.mask
in_shapes=
[
'n
]
def
padded_sum
x
return
jax.jit
np.sum
x
print
padded_sum
[
np.array
[
]
]
dict
n=3
[
]
print
padded_sum
[
np.array
[
]
]
dict
n=2
sure
right
incorrect
😁
f
TODO
TF
kernels
lax_name
invalid
values
k
comment
comment
end
line
suggestion
total
number
partitions
PartitionSpecs
jaxpr
inline
comment
benchmark
import
refers
Works
JAX
JAX
custom
implementation
deserves
generated
documentation
bit
documentation
differences
behavior
negative
out-of-bounds
indices
lax_description
argument
useful
function
obvious
useful
benchmarking
library
funcs
param_list
exact
order
latter
param_names
printing
purposes
following
alternate
API
easier
specialization
benchmark
function
list
parameters
construction
specialized
function
name
prepare
Callable
[
[
Dict
]
Callable
]
params_list
List
[
Dict
]
name
str
function
several
combinations
parameters
Args
prepare
kwargs
benchmark
function
kwargs
params_list
list
kwargs
benchmark
name
name
benchmark
suite
textwrap.dedent
nice
way
multi-line
string
correct
indentation
import
textwrap
=
textwrap.dedent
\
fine
textwrap.dedent
common
spaces
line
http
//google.github.io/styleguide/pyguide.html
310-strings
note
LAX-backend
implementation
pinv
look
matmul
docstring
code
example
https
//jax.readthedocs.io/en/latest/_autosummary/jax.numpy.matmul.html
https
//jax.readthedocs.io/en/latest/_modules/jax/numpy/lax_numpy.html
matmul
suggestion
Transfers
input
specified
devices
ShardedDeviceArrays
comment
input
ShardedDeviceArrays
already-sharded
data
function
ok
current
name
gon
prior
bias
@
_wraps
scipy.linalg.expm
docstring
SciPy
see
lax_description
argument
JAX
specific
details
few
thoughts
Naming
upper_triangular
isuppertriangular
little
hard
Backwards
compatibility
potential
conflicts
SciPy
own
new
keyword
arguments
expm
keyword
argument
def
expm
A
*
Documentation
JAX
specific
documentation
argument
use
lax_description
SciPy
F
expressions
calculation
DB
python
django.contrib.gis.db.models.functions
import
Area
Transform
django.db.models
F
SpatialUnit.objects.exclude
geometry=None
.update
area=Area
Transform
'geometry
main
concern
SpatialUnit.objects.all
results
default
field
row
SpatialUnit
table
memory
concerns
server
production
track
record
PR
grain
salt
😉
@
comment
calculation
SpatialUnit
instances
geometries
single
transaction
much
DB
familiar
rows
prod
DB
DB
server
capabilities
issue
.update
F
expression
batches
queryset
queryset
batches
paragraph
single
lines
summary
line
line
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
Sorry
confusion
rough
look
docs
better
near
class
Snake
python
class
Snake
tf.keras.layers.Layer
Snake
layer
periodic
functions
trainable
frequency
scalar
f
x
x
+
cos
*
frequency
*
x
/
*
frequency
frequency
learned
scalar
[
Neural
Networks
Fail
Learn
Periodic
Functions
How
]
https
//arxiv.org/abs/2006.08195
more
details
Arguments
frequency_initializer
Initializer
frequency
scalar
frequency_regularizer
Regularizer
frequency
scalar
frequency_constraint
Constraint
frequency
scalar.
doc
parametric
activation
[
PReLU
]
https
//www.tensorflow.org/api_docs/python/tf/keras/layers/PReLU
Feel
free
point
code
hard
readable
way
early
]
return
Shape
static
shape
]
==
batch_size
*
beam_width
return
shape.ndims
=
[
]
==
batch_size
shape
]
==
beam_width
shape
]
None
return
tf.get_logger
.warn
....
places
default
Goes
self.assertAlmostEqual
cast
docstring
args
returns
https
//github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py
L499
Could
empty
line
Mind
test
multi-class
enough
echo
state
property
max
W
order
property
weights
reservoir
spectral_radius/max
W
tensorflow
function
tf.linalg.eig
exponential
complexity
alternative
implementation
approximation
norm2
refers
[
p-norm
]
https
//en.wikipedia.org/wiki/Matrix_norm
Special_cases
function
p=2
upper
bound
spectral
radius
echo
state
property
satisfied
[
Wikipedia/MaxNorm
]
https
//en.wikipedia.org/wiki/Matrix_norm
[
paper
]
2-norm
same
purpose
Done
thanks
comment
formatter
line
doc
works
less
words
r
Noisy
dense
layer
Describe
details
layers
plain
text
section
paper
[
Noisy
Networks
Explanation
]
https
//arxiv.org/pdf/1706.10295.pdf
more
details
whole
descriptions
first
line
Title
line
foo
bar
zzz
l_ambda
name
convention
constraint
lambda_
docstring
constraint
better
self.learning_rate
same
self.lamda
self._set_hyper
learning_rate
learning_rate
new
attr
self.learning_rate
definition
_set_hyper
def
_set_hyper
name
value
hyper
name
value
value
callable
tensor
numeric
isinstance
value
trackable.Trackable
self._track_trackable
value
name
overwrite=True
name
self._hyper
self._hyper
[
name
]
=
value
prev_value
self._hyper
[
name
]
callable
prev_value
isinstance
prev_value
int
float
learning_rate_schedule.LearningRateSchedule
isinstance
value
learning_rate_schedule.LearningRateSchedule
self._hyper
[
name
]
=
value
backend.set_value
self._hyper
[
name
]
value
self._get_hyper
'learning_rate
Fix
format
Construct
conditional
gradient
optimizer
learning_rate
Lambda
python
r
Short
descriptions
first
line
line
Detailed
descriptions
Args
foo
foo
bar
bar
Usage
>
>
>
code
snippet
>
>
>
code
snippet
Note
Note
Reference
[
Name
paper
]
linktothepaper
python
apply_gradient
method
list
tf
ops
Name
variable
serialization
deserialization.
NIT
Discriminative
Layer
Training
Optimizer
TensorFlow
__init__
Returns
Could
test
loss
compatible
tf.keras.Model.compile
shape
input/output
example
docstring
wrong
comments
private/public
API
lookahead.py
tf.executing_eagerly
python
code
snippet
testable
doctest
https
//github.com/tensorflow/addons/blob/master/CONTRIBUTING.md
testing-docstrings
doctest
+NORMALIZE_WHITESPACE
doctest
+NORMALIZE_WHITESPACE
axis
int
support
FC
layer
checks
NIT
comments
class
LGTM
mistakes
function
operations
True
GPU
available
something
use_gpu
=
on_gpu
tf.test.is_gpu_available
test_utils.device
use_gpu
something
docstring
other
metrics
format
method
ditto
Please
docstring
use
blank
line
pairwise_distance_np
good
example
tf.reduce_mean
def
crf_filtered_inputs
inputs
TensorLike
tag_bitmap
TensorLike
>
tf.Tensor
inputs
certain
tags
time
step
tags
input
time
step
useful
output
time
step
needs
set
tags
Args
inputs
[
batch_size
max_seq_len
num_tags
]
tensor
unary
potentials
input
CRF
layer
tag_bitmap
[
batch_size
max_seq_len
num_tags
]
boolean
tensor
active
tags
index
unnormalized
score
Returns
filtered_inputs
[
batch_size
]
vector
unnormalized
sequence
scores.
devices
Comment
device_4
GPR.2
Please
blank
line
line
canonical
data
reference
comment
below
track
standard
exceptions
exception
message
example
def
TestClass
unittest.TestCase
def
test_raises_meaningful_exception
self.assertRaisesWithMessage
ValueError
raise
ValueError
'meaningful
message
Utility
methods
setUp
try
self.assertRaisesRegex
AttributeError
self.assertRaisesRegex
=
self.assertRaisesRegexp
def
assertRaisesWithMessage
exception
return
self.assertRaisesRegex
exception
*
*
r
.+
*
comment
function
elif
property
==
private_key_is_random
block
Generally
bad
practice
infinite
loops
something
python
little
surprised
flake8
best
practice
Exception
specific
exception
BaseException
Exception
subset
BaseException
unittest
method
exceptions
track
variant
raise
ValueError
stuff
def
test_should_raise_exception
self.assertRaisesWithMessage
ValueError
do_the_thing
Utility
functions
setUp
try
self.assertRaisesRegex
AttributeError
self.assertRaisesRegex
=
self.assertRaisesRegexp
def
assertRaisesWithMessage
exception
return
self.assertRaisesRegex
exception
r
.+
couple
things
assertRaisesRegex
assertRaisesRegexp
Python
RE
[
track
README
]
https
//github.com/exercism/python/blob/054ba4c3ba4fd501129f203a22d7431cb55e465b/README.md
conventions
specific
error
messages
@
smalley
version
comment
line
consistency
ie
blank
lines
Minor
point
version
comment
line
ie
blank
lines
comment
version
canonical-data.json
tests
aplicable
format
Tests
problem-specifications//canonical-data.json
@
v1.0.0
docstring
nice
📓
self.isBonusRoll
readability
ValueError
'Failure
details
same
other
cases
consistency
version
line
ie
blank
lines
comment
comment
version
canonical-data.json
tests
aplicable
format
Tests
problem-specifications//canonical-data.json
@
v1.0.0
overall
comment
size
pixels
output
type
images
Typically
size
number
e.g
number
pixels
image
shape
number
pixels
axis
size
>
shape
test
following
case
data
=
A
A
A
B\none
one.1
two\n0,40,34,0.1
nice
code
more
test
case
~~~python
data
A
A
A
B\none
two\n0,40
~~~
pandas_dtype
_validate_dt64_dtype
IIRC
comment
beinga
costly
call
result
validate_
call
blank
line
lines
sorry
small
comments
sphinx
/
rst
nitpickly
order
html
online
documentation
DataFrame
docstring
hasattr
checks
mypy
prevalent
optimisation
premature
hasattr
checks
preferable
class
MyClass
pass
cls
=
MyClass
%
timeit
hasattr
cls
ns
ns
loop
mean
±
std
dev
runs
loops
class
MyClass
_max_cols_fitted
=
None
cls
=
MyClass
%
timeit
None
ns
ns
loop
mean
±
std
dev
runs
loops
reason
property
'tw
means
part
original
docstring
examples
way
stata
function
explanation
useful
great
May
date
column
sense
variables
date_range
much
information
value
single
DataFrame
beginning
useful
functions
something
more
real
example
better
impression
[
]
examples
animals
pandas/core/generic.py
parametrize
http
//pandas.pydata.org/pandas-docs/stable/contributing.html
using-pytest
issue
number
comment
suggestion
actual
array
Series
Index
nlevels
MultiIndex
comment
Rather
large
test
few
comment
block
logical
splitting
point
other
comment
re
_constructor
blank
line
comments
ExtensionArray
length
zero
array
comment
instance
dtype
object
array
opinion
poor
API
design
empty
constructor
certain
result
explicit
class
method
_get_dtype_type
result
ExtensionDtype
NOT
ExtensionArray
sense
Series.values
object-typed
NumPy
array
ship
Series.values
NumPy
array
github
issue
number
comment
other
tests
GH31944
enough
blank
line
comment
Minor
stylistic
comment
glob
path
lib
iterating
results
bit
glob
stable
xml
docs
name
future
pls
add
blank
lines
comments
blank
line
cases
lot
e.g
comment
type
error
comment
types
returns
transform
function
non-time
transform
hit
tests
better
self._is_in_terminal
return
self._get_max_rows_fitted_in_terminal
return
self._adjust_max_rows
self.max_rows
other
PR
comment
multiple
e.g
str
same
question
@
jbrockmendel
nice
helper
functions
IIIRC
followup
comment
clearer
rewriting
clinebuf
line
clinebuf
elements
previous
lines
essential
code
problem
sure
small
comment
issue
number
comment
variable
to_excel
]
normal
docstring
to_excel
method
Styler
@
doc
_shared_docs
[
to_excel
]
@
doc
NDFrame.to_excel
code
readable
direction
other
docstrings
much
indentation
whole
docstring
spaces
opening
code
comment
smile
issue
number
comment
test
same
comment
preface
assert_
function
name
check
ok
assert_
inline
codebase
docstring
useful
developers
OP
error
message
same
comment
blank
line
comment
easier
tests
expected
dataframe
e.g
list
data
tm.assert_frame_equal
+1
quality
comment
A
docstring
great
>
expected_difference
Seems
level
=
[
b
]
general
comment
follow
imports
global
space
module
init
applicable
module
subclass
__init__
comment
comment
different
idiom
issue
discussion
issue
number
comment
general
rule
nice
issue
number
GH-xxxxx
comment
docstring
nice
comment
Timedelta/Datetime/Timestamp
helpful
comment
future
reader
test
pls
issue
number
comment
blank
line
comments
implies
DataFrames
seperate
test
issue
number
comment
reverse
op
single
element
elements
list
sure
xfail
reasons
issue
number
commentary
i
helper
function
hard
folks
i
hard
Can
number
comment
comment
try-except
comment
>
comparison
ops
Index
*
defer
Series
Is
good
reason
inconsistency
time
Make
docstring
pytest
fixtures
bit
descriptive
return
type
comment
period
ones
prefix
check
validation
header
afterwards
Hmm
sure
issue
right
sort
comment
file
something
>
bit
dichotomy
test
file
pandas/formats/test_formats.py
level
functionaility
test_formats
lower
consistent
comment
top
file
meth
categories
*
CategoricalDtype
comment
Changes
great
validate_docstrings.py
docstrings
everything
ok
script
params
docstring
suggestion
DataFrame
TextParser
raw
strings
general
readable
sep=r'\s+
comment
line
docstring
read_fwf
value
self-referencing
like
@
pytest.mark.parametrize
[
Timestamp
'2018-01-01
Timestamp
'2018-01-01
tz='UTC
Timestamp
'2018-01-01
tz='US/Pacific
Timestamp
]
def
test_timestamp_utc_true
GH
result
=
to_datetime
ts
utc=True
result
==
sense
tz-aware
behavior
different
behavior
equivalent
tz-aware
datetime
object
tz
related
conventions
python
]
ts
=
pd.Timestamp
'2018-01-01
]
dt
=
ts.to_pydatetime
]
dt
]
datetime.datetime
tzinfo=
<
DstTzInfo
'US/Pacific
PST-1
day
STD
>
]
pd.to_datetime
dt
utc=True
]
Timestamp
TDI
PeriodIndex
elif
separate
else
clause
comments
entire
condition
dtype
=
None
type
Optional
[
PeriodDtype
]
freq
dtype
=
PeriodDtype
freq
rationales
Variable
Annotations
PEP
https
//www.python.org/dev/peps/pep-0526/
rationale
syntax
Hi
@
WillAyd
@
jreback
part
quite
conversations
i
something
i
re-designed
implementation
bit
detailed
comment
issue
result
self._aggregate
mangle_lamdbas
index
results
callable
name
e.g
sum
>
np.max
>
case
e.g
>
parsed
lambda
func
e.g
lambda
x
min
x
>
<
lambda
>
index
call
function
df.agg
aa=
C2
sum
C1
max
C1
np.max
C2
lambda
x
min
x
C1
sum
order
functions
C1
[
max
sum
]
C2
[
sum
]
something
C2
C1
<
NaN
amax
NaN
max
NaN
func
name
index
position
reordering
s
reorder_mask
clause
afterwards
names
names
users
call
e.g
ab
ae
reason
mask
result
DataFrame
column
aggregation
e.g
df.agg
aa=
C1
sum
C1
mean
re-sort
index
order
same
function
lot
confusions
i
many
scenarios
corner
cases
solution
good
overall
things
index
name
aggregated
dataframe
same
order
appearance
call
column
names
dataframes
same
order
appearance
column
names
call
aggregated
result
mapping
correct
Many
thanks
precious
time
PR
feedbacks
thanks
advance
@
WillAyd
@
jreback
issue
comment
whey
comment
1-line
comment
block
FutureWarning
im
raises
produces_warning
ie
pytest.raises
ValueError
match=msg
GH
inplace
kwarg
cat.remove_unused_categories
inplace=value
comment
further
index
None
....
check
touch
higher
index
None
data
data
[
data
]
index
=
com._default_index
data
manager
isinstance
data
SingleBlockManager
dtype
None
data
=
data.astype
dtype=dtype
errors='ignore
copy=copy
check_dtype
Can
output
example
docstring
docstring
example
new
code
https
//github.com/pandas-dev/pandas/pull/27921/files
diff-bfee1ba9e7cb79839776fac1a57ed940R1742
comments
backwards
way
second
case
necessary
fine
plain
tuple
tuple
version
comment
particular
file
casual
glance
similar
Ok
comment
Cna
comment
github
issue
number
issue
number
comment
datetime64
timedelta64
footguns
internal
consistency
[
cut/paste
ndarrays
function
inputs
outputs
comment
null
groups
AbstractMethodError
Reference
PR
number
comment
Same
comment
better
expected
value
parametrization
local
dict
Can
comment
line
something
python
bins
_convert_bin_to_numeric_type
bins
dtype
cast
overflow
bins.astype
'float64
.any
issue
number
comment
lint
error
try
exceptions
test
failure
comment
other
cases
future
reader
comment
lines
test
permutations
index
types
test
combinations
new
test
issue
number
comment
other
comments
_dti
array-like
versions
more
explicit
something
_add_datelike_scalar
others
clear
comments
types
test
wrong
section
ValueError
decreasing
breaks/arrays
section
relevant
test
deleted
rename
test_deprecation
issue
number
comment
similar
comment
True
>
quotes
string
blank
line
comments
ohlc
case
comment
effect
Parameters
section
docstring
S3
files
test
key
pytest.raises
logic
comment
github
issue
number
first
thing
test
e.g
@
pytest.mark.parametrize
key
[
]
]
def
test_get_value_errors
key
GH
idx
=
comment
line
clause
Can
docstring
Python
[
inspect.getdoc
]
https
//docs.python.org/3/library/inspect.html
inspect.getdoc
parent
class
docstrings
overridden
Basically
CategoricalDtype.construct_from_string.__doc__
None
things
help
docstring
parent
class
sure
other
reasons
__doc__
attribute
comment
methods
limit_direction
limit_area
link
//github.com/pandas-dev/pandas/issues/26796
first
module-level
docstring
float64
behavior
as-is
overall
takeaway
well-maintained
Sparse
EA
github
issue
comment
comment
result
/
comment
test
case
describing
easier
parameterize
things
great
easy
thinking
sure
FrameOrSeries
correct
comment
FrameOrSeriesUnion
DataFrame
Series
E.g
def
func
FrameOrSeriesUnion
>
FrameOrSeriesUnion
means
Series
Series
DataFrame
DataFrame
DataFrame
Series
__init__
anything
FrameOrSeriesUnion
Series
DataFrame
sure
nothing
@
topper-123
suggestions
comment
example
wrong
information
falcon
legs
sure
better
worse
DataFrame
num_wings
column
rid
parrot
df2
content
clearer
small
detail
other
df2
other
docstrings
example
values
list
constructor
content
original
Dataframe
i.e
>
>
>
df
docstring
clearer
real
world
example
example
index
animal
name
columns
num_legs
num_wings
df.isin
[
]
True
falcon/wings
easy
much
foo
kind
example
multiindex
name
fill
>
ffill
half-sentence
GH
ref
original
problem
total
nitpick
kindness
pattern
GH
GH
references
bad
methods
function
bad
element
sure
example
plot
above
test_missing_kwargs
kind
*
*
kwargs
Kwargs
argument
parameters
section
Parameters
kind
str
Kind
matplotlib
plot.
def
test_parameter_colon_spacing
kind
Space
colon
Parameters
kind
str
Kind
matplotlib
plot.
def
test_parameter_description_period
kind
Parameter
description
dot
Parameters
kind
str
Kind
matplotlib
plot
def
test_parameter_description_capital
kind
parameter
descriptions
capital
Parameters
kind
str
kind
matplotlib
plot.
def
test_parameter_blank_line
kind
Blank
line
parameters
title
first
parameter
Parameters
kind
str
Kind
matplotlib
plot.
class
docstring
example
sure
class
docstrings
issue
number
comment
PR
number
issue
comment
module
comment
accessors
relevant
ones
afterwards
test
e.g
klass
Ah
comment
useful
clear
least
comment
cythonized
files
sdist
issue
number
comment
Could
same
comment
test
name
issue
number
comment
new
test
issue
number
comment
pls
test
cases
comment
/
guarantees
example
nice
same
comment
e.g
bit
u
same
comment
review
useful
new
github
feature
changes
icon
+-
icon
comment
way
afaik
user
change
single
click
suggestion
sys.version_info
=
comment
sure
warning
helpful
issue
reference
comment
except
comment
sufficient
StringDType
EA
dtype
Hmm
sure
worth
actual
implementation
docstrings
various
Examples
preferable
Example
Series
DataFrame
code
changes
property
things
return
comment
fine
possible
pattern
list
comment
GH
number
comment
comment
__init__
PEP8
conventions
classes
i.e
SetopCheck
parameters
section
docstring
op_name
Tick
docstring
annotation
Can
issue
line
e.g
gh-16905
Rename
comment
definition
blank
line
comment
sort
fixture
location
>
'__nat_unpickle
comments
comment
issue
number
blank
line
KeyError
raise
comment
python
blank
line
other
cases
loop
comment
applies
list
'public
api
whatsnew
note
is_subperiod/is_superperiod
ok
PY2
comment
ref
CPython
bug
report
comments
option
comment
parametrization
GH
comments
case
nulls_fixture
+
pd.NA
pd.NA
former
current
parametrization
super
useful
OK
first
case
body
test
add
gh
issue
number
comment
refernce
bug
comment
comment
issue
number
separate
test
PY36
part
skipif
PY36
decorator
use
result
=
=
tm.assert_frame_equal
result
int64
later
paramaterization
1-liner
comment
blank
line
comment
comment
attribute
backward
compat
API
annotations
things
little
place
Timestamp
/
Timedelta
instances
pass
other
functions
..
@
WillAyd
diff
diff
git
a/pandas/core/frame.py
b/pandas/core/frame.py
index
..
a/pandas/core/frame.py
+++
b/pandas/core/frame.py
@
@
-1971,8
+1971,7
@
@
class
DataFrame
NDFrame
mypy
Incompatible
types
assignment
kwargs
version
=
version
type
ignore
mypy
Too
many
arguments
StataWriter
writer
=
statawriter
type
ignore
+
writer
=
statawriter
path
diff
git
a/pandas/io/stata.py
b/pandas/io/stata.py
index
a/pandas/io/stata.py
+++
b/pandas/io/stata.py
@
@
-2103,6
+2103,7
@
@
class
StataWriter
StataParser
time_stamp
Optional
[
datetime.datetime
]
=
None
data_label
Optional
[
str
]
=
None
variable_labels
Optional
[
Dict
[
Label
str
]
]
=
None
+
*
*
kwargs
dummy
parameter
compat
StataWriter117
super
.__init__
=
convert_dates
None
ignore
diff
diff
git
a/pandas/core/frame.py
b/pandas/core/frame.py
index
..
b44d594d1
a/pandas/core/frame.py
+++
b/pandas/core/frame.py
@
@
-1962,14
+1962,13
@
@
class
DataFrame
NDFrame
mypy
Name
'statawriter
import
pandas.io.stata
import
StataWriterUTF8
statawriter
type
ignore
kwargs
=
kwargs
Dict
[
str
Any
]
=
version
version
=
strl
conversion
supported
>
=
kwargs
[
convert_strl
=
version
version
=
version
UTF8
mypy
Incompatible
types
assignment
kwargs
version
=
version
type
ignore
+
[
version
=
version
mypy
Too
many
arguments
StataWriter
writer
=
statawriter
type
ignore
small
doc
string
github
issue
lines
read_html
able
Path
GH
next
comment
issue
number
comment
comment
issue
number
ci
failure
suggestion
return
list
color
type
ignore
[
arg-type
]
please
ignore
previous
comment
expected
open
close
tags
True
/
False
values
space
op
colon
numpy
standard
long
version
http
//pandas.pydata.org/pandas-docs/stable/contributing_docstring.html
same
issue
number
comment
ndarray
same
w.r.t
asserts
Same
comment
other
PR
include
indent
level
CI
sub-section
comment
lines
sub-sections
Same
comment
Same
comment
Similar
comments
https
//github.com/pandas-dev/pandas/pull/29455
~~~python
@
pytest.mark.parametrize
kwargs
[
dict
dict
other=None
]
def
test_df_where_with_category
df
=
DataFrame
np.arange
.reshape
columns=list
ABC
mask
=
np.array
[
[
True
False
True
]
[
False
True
True
]
]
Change
type
df.A
=
df.A.astype
category
df.B.astype
category
df.C.astype
category
=
Construct
result
result
=
df.A.where
mask
[
]
*
*
kwargs
tm.assert_series_equal
result
~~~
i
comments
fixture
names
Could
Github
issue
number
comment
GH
comment
short-circuits
hit
following
path
close
method
only
place
things
comments
Nit
whole
block
first.tz
isinstance
freq
Tick
statement
index_tz
=
first.tz
isinstance
Timestamp
None
=
index_tz
None
raise
ValueError
origin
same
timezone
index
epoch
epoch
timezone
similar
result
timezones
=
Timestamp
1970-01-01
tz=index_tz
check
incorrect
=
np.array
[
]
dtype=np.int8
a.dtype
==
False
dtype
functions
pandas.dtypes.common
is_numeric_dtype
None
>
optional
Description
next
line
https
//pandas.pydata.org/pandas-docs/stable/contributing_docstring.html
First
sentence
less
characters
end
Timedelta
interval
NaTs
2-D
comment
Docstrings
line
triple
quotes
issue
number
comment
newline
comment
issue
number
Very
minor
comment
reason
test_container_shift_negative
negative
periods
'container
superfluous
routine
re-factoring
something
_conv_value
val
doc-string
is_integer
val
val
=
int
val
elif
is_float
val
val
=
float
val
elif
is_bool
val
val
=
bool
val
elif
isinstance
val
datetime
timedelta
pass
comment
val
=
str
val
return
val
additional
tests
expanded
docstring
Parameters
Returns
section
guess
comment
comment
similar
e.g
psutil
open
files
Reference
issue
comment
def
test_boolean
line
return
assign
return
Same
comment
f-strings
image
descriptive
previous
review
descriptive
much
everytime
name
location
usage
other
image
image_spec
please
yoru
fault
comment
stale
Capitalize
GCB
comments
please
Comment
buildkit
other
comment
thread
dependency
gsutil
PR
comment
sense
tool
cover
other
commands
Class
name
rsync
talks
test_rsync_no_flags
test_rsync_options
Same
comments
above
pytest.raises
straightforward
test
nit
docstring
parameters
nit
date
thanks
Change
comment
True
Google
Cloud
Storage
extra
space
beginning
end
docstring
comment
global
PY_DEPENDENCIES_CACHE
line
characters
local
variable
'input_folders
<
br
backslash
redundant
brackets
empty
default
added
documentation
GROUP_RULE_1
arbitrary
name
test
GROUP_RG
specific
name
clouddriver
heuristics
case
method
policy
names
documentation
clarity
future
tests
arbitrary
names
intentional
ones
standard
spinnaker
frigga
naming
names
record
yaml
format
parsing
easier
=
arrow_forward
nested
list
same
structure
change
=
comment
hostname
timestamp
Nit
class
name
general
purpose
docstring
treats
Window
main
purpose
class
suggestion
Returns
list
lines
output
file
more
things
type
Python
sob
t
t
isinstance
t
type
]
isinstance
None
excluded_types
validate
input
recipe
Delete
code
files
unique
other
props
suggestion
'none
FIXME
Change
ip6
tests
support
P
See
comment
privilege
method
other
privileges
Comment
posterity
sure
source_name
comments
full
unabbreviated
source
name
DB
Comments
methods
helpful
most
people
parent
class
sure
existing
comment
API
sentence
start
START_CHAR
great
comments
numbers
Could
comments
functions
Input
Output
class
doc
lot
comment
arg
parser
magic
default
templating
Micro-nit
space
end
docstrings
other
lines
module
nit
Score
more
clear
concise
logs
please
length
argument
requirement
machine
person
benchmarks
README
worth
module
cast
Check
speed
check
@
reedwm
guess
no-op
cast
fine
conditionals
case
sure
comment
someone
future
thinking
gee
no-op
cast
features
dtype
fp32
comment
depth
multiplier
feature
layers
ambiguous
name
other
layers
pooling
ones
final
layer
block
parameters
layers
becomes
block_sizes
num_blocks
stride_sizes
becomes
block_strides
comment
block
parameters
block_fn
block_sizes
block_strides
docstrings
inputs
code
subprocess
comment
Could
more
information
dataset
comments
README
dataset
size
long
comments
flag
comment
is_
prefix
Please
comment
code
Please
docstring
NumPy
format
Descriptions
parameters
spaces
suggestion
policy_date
int
str
datetime.date
date
policy
system
groups
list
group
list
groups
parameters
Default
parameters
Returns
params_dict
dict
Dictionary
parameters
policy
system
compartments
groups
policy_func_dict
dict
Dictionary
time
dependent
policy
reforms
Keys
variable
names
suggestion
Legislation
force
2005-01-01
2005-09-30.
suggestion
Legislation
force
2005-10-01.
suggestion
Abs
Alg
II-V.
suggestion
II
docstring
briefly
function
few
bits
old
docstring
soli
tax
base
Please
use
.format
CISCO_API_URL
global
variable
comment
@
tmehlinger
prescient
https
//sqbu-github.cisco.com/WebexIntelligence/joint_bert_model/pull/1
Let
state
types
function
mypy
function
arguments
types
checks
action
AnnotatorAction.ANNOTATE.value
rules
self.config
[
AnnotatorAction.ANNOTATE.value
]
action
AnnotatorAction.UNANNOTATE.value
rules
self.config
[
AnnotatorAction.UNANNOTATE.value
]
action
AnnotatorAction.ANNOTATE
rules
self.config
[
AnnotatorAction.ANNOTATE
]
action
AnnotatorAction.UNANNOTATE
rules
self.config
[
AnnotatorAction.UNANNOTATE
]
Nit
allowed_intents
allowed_nlp_classes
much
hassle
comment
new
functionality
minimal
example
Notebook
API
MNIST
example
import
import
torch
torch.nn
import
functional
F
torch.utils.data
import
DataLoader
catalyst
import
dl
catalyst.contrib.data.transforms
ToTensor
catalyst.contrib.datasets
MNIST
catalyst.utils
import
metrics
=
torch.nn.Linear
optimizer
=
torch.optim.Adam
model.parameters
lr=0.02
=
train
DataLoader
MNIST
train=True
download=True
transform=ToTensor
batch_size=32
valid
DataLoader
MNIST
download=True
transform=ToTensor
batch_size=32
class
CustomRunner
dl.Runner
def
predict_batch
batch
model
inference
step
self.model
]
.to
self.device
.view
]
.size
-1
def
_handle_batch
batch
model
train/valid
step
x
y
=
batch
self.model
x.view
x.size
-1
loss
=
F.cross_entropy
accuracy01
accuracy03
=
metrics.accuracy
topk=
self.batch_metrics.update
loss
loss
accuracy01
accuracy01
accuracy03
self.is_train_loader
loss.backward
self.optimizer.step
self.optimizer.zero_grad
runner
=
CustomRunner
model
training
runner.train
model=model
optimizer=optimizer
loaders=loaders
logdir=
./logs
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
D102
public
method
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
D101
public
class
style
please
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
DAR202
Excess
Returns
+
return
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
DAR201
Returns
return
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
DAR101
Missing
parameter
s
sampler_inbatch
doc
Google
style
format
Easy-to-go
setup
https
//github.com/catalyst-team/catalyst/blob/master/CONTRIBUTING.md
documentation
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
F821
name
't
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
DAR201
Returns
return
Hi
state
dict
key
check
mechanics
error
key
informative
something
wrong
<
checkpoint-file-name
>
.pth
example
https
//gist.github.com/Ditwoo/5de19670d9946c80916dee75e93ef545
please
python
inplace
return
something
output
=
self.save_grad_norm
model=state.model
prefix=self.grad_norm_prefix
norm_type=self.norm_type
update
state.batch_metrics
output
explanation
clear
commit
P.S
confusion
fact
first
comment
lines
121-123
125-127
green
parts
diff
js-code
var
myPlayer
=
projekktor
playera
addplugins
[
'ima
]
//platforms
'browser
'flash
]
//platforms
'browser
'ios
'flash
]
platforms
'browser
'ios
'flash
]
js_to_json
lines
js-code
comma
dict
json.loads
short
comment
replacements
suggestion
URL
unauthenticated
users
login
suggestion
async
function
current
user
theme.yaml
docstring
copy-pasta
docstring
method
request
comment
helpful
please
print
lines
type
selector
comment
name
selector
example
CASE_REFERENCE_ID
CASE_REFERENCE
=
case_reference
id
spaces
comment
begins
space
add
add
docstring
Could
docstring
idea
comment
necessary
@
ivanpauno
consider
suggestion
LaunchDescription
declarative
launch
file
Blast545
nit
suggestion
Construct
AnonName
substitution
wrong
name
@
ivanpauno
nit
suggestion
substitution
command
output
@
pbaughman
reasons
@
pbaughman
same
comment
if-block
good
Same
other
blocks
curious
dissimilar
array
substitution
type
particular
True
TextSubstitution
text='foo
[
TextSubstitution
True
]
nitpick
style
python
variable_name
=
[
vertical
alignments
message_id
[
]
length
=
details
nothing
message_id
auto-generated
data
e.g
data
UTF-8
string
type
user
>
exception
false
[
]
length
=
failure
good
reason
>
'application/json
[
]
length
=
body
>
event_sender
[
]
length
=
same
comment
readme
global
event_sender
interpreter
local
Same
cancel_sender
>
auth_provider
[
]
length
=
same
comment
current
code
X2
=
np.tile
tes
n_voxels
mu.T
/
t2s
calculation
t2S
variable
metrics
bit
new
lines
158-183
section
few
more
comments
replacement
removable
t2s
something
Could
comment
link
SO
people
unique
approach
Note
top
line
docstring
reference
References
section
notes
z-scored
suggestion
forked_query
=
Query
name=u'Copy
self.id
self.name
Alerts
states
unknown
normal
elif
unknown
case
normal
[
DB
Documentation
]
https
//docs.databricks.com/integrations/bi/jdbc-odbc-bi.html
odbc-data-source-name-dsn-configuration-for-the-simba-odbc-driver
backslashes
line
string
better
form
implicit
line
continuation
braces
suggestion
origin_query_text
=
table
execution_times
select
id
retrieved_at
data_source_id
query
runtime
query_results
order
desc
triple
quotes
suggestion
origin_query_text
=
create
table
execution_times
select
id
retrieved_at
data_source_id
query
runtime
query_hash
query_results
order
desc
comments
good
tests
.call
.run
methods
cfg
file
cfg
files
several
params
certain
steps
certain
modes
data
case
calwebb_detector1.cfg
ipc
step
.call
method
pipeline
ipc
step
non-standard
output
ability
params
arguments
command
line
example
=
[
calwebb_detector1.cfg
steps.jump.rejection_threshold=150
save_results=True
]
Step.from_cmdline
args
course
cfg
file
s
calwebb_detector1.cfg
file
input
data
directory
artifactory
jump.rejection_threshold
lot
unnecessary
time
lots
bogus
jumps
same
time
ability
least
*
jumps
look
log
jump
step
least
>
pixels
jumps
rejection_threshold
bit
appropriate
sweet
spot
Same
comment
image
x/y
dimensions
comment
pathloss.py
incorrect
regard
NRS_MSASPEC
comment
number
shutters
shutter
number
number
other
test
other
tests
matter
result
shutter
number
number
shutters
Same
comment
print
statements
SlitModel
getattr
situation
None
same
check
slit
case
code
targ_ra
=
None
targ_dec
=
None
slit
None
targ_ra
=
getattr
targ_de
=
getattr
elif
isinstance
input_model
....
targ_ra
=
getattr
targ_dec
=
getattr
None
targ_dec
None
targ_ra
=
input_model
targ_dec
=
input_model
source_type
schema
hasattr
true
attribute
great
[
]
model
datamodels.ImageModel
]
model.meta.wcsinfo.roll_ref
[
]
model.save
foo.fits
Out
]
'foo.fits'
]
fitsinfo
foo.fits
Filename
Ver
Type
Cards
Dimensions
Format
PRIMARY
PrimaryHDU
SCI
ImageHDU
BinTableHDU
x
[
]
]
foo.fits
HDU
foo.fits
SIMPLE
=
T
/
conforms
FITS
standard
BITPIX
/
array
data
type
NAXIS
/
number
array
dimensions
EXTEND
=
T
DATE
=
/
[
yyyy-mm-ddThh
mm
ss.ss
UTC
date
file
cre
FILENAME=
/
Name
file
DATAMODL=
'ImageModel
/
Type
data
model
HDU
foo.fits
XTENSION=
'IMAGE
/
Image
extension
BITPIX
/
array
data
type
NAXIS
/
number
array
dimensions
PCOUNT
/
number
parameters
GCOUNT
/
number
groups
EXTNAME
=
'SCI
/
extension
name
WCS
parameters
ROLL_REF=
/
[
deg
]
V3
roll
angle
ref
point
N
E
foo.fits
XTENSION=
'BINTABLE
/
binary
table
extension
BITPIX
/
array
data
type
NAXIS
/
number
array
dimensions
NAXIS1
/
length
dimension
NAXIS2
/
length
dimension
PCOUNT
/
number
group
parameters
GCOUNT
/
number
groups
TFIELDS
/
number
table
fields
TTYPE1
=
'ASDF_METADATA
TFORM1
=
'523B
EXTNAME
=
'ASDF
/
extension
name
]
model.meta.wcsinfo.roll_ref
None
]
model.save
foo.fits
Out
]
'foo.fits'
]
fitsinfo
foo.fits
Filename
Ver
Type
Cards
Dimensions
Format
PRIMARY
PrimaryHDU
BinTableHDU
x
[
]
]
foo.fits
HDU
foo.fits
SIMPLE
=
T
/
conforms
FITS
standard
BITPIX
/
array
data
type
NAXIS
/
number
array
dimensions
EXTEND
=
T
DATE
=
/
[
yyyy-mm-ddThh
mm
ss.ss
UTC
date
file
cre
FILENAME=
/
Name
file
DATAMODL=
'ImageModel
/
Type
data
model
HDU
foo.fits
XTENSION=
'BINTABLE
/
binary
table
extension
BITPIX
/
array
data
type
NAXIS
/
number
array
dimensions
NAXIS1
/
length
dimension
NAXIS2
/
length
dimension
PCOUNT
/
number
group
parameters
GCOUNT
/
number
groups
TFIELDS
/
number
table
fields
TTYPE1
=
'ASDF_METADATA
TFORM1
=
'509B
EXTNAME
=
'ASDF
/
extension
name
comment
nonsensical
design
IMHO
comment
values
values
xmin
xmax
ymin
OK
numpy
documentation
docstrings
single
backticks
variables
minor
comment
space
comma
same
comment
applies
lines
code
PEP8
*
PEP8Bear
severity
NORMAL
section
autopep8
issue
following
patch
diff
a/coala_quickstart/generation/Bears.py
+++
b/coala_quickstart/generation/Bears.py
@
@
-92,7
+92,7
@
@
[
lang
]
=
lint_task_info
=
extracted_info.get
LintTaskInfo
[
]
project_dependency_info
=
extracted_info.get
ProjectDependencyInfo
[
]
project_dependency_info
=
extracted_info.get
ProjectDependencyInfo
[
]
Use
lint_task_info
bears
lang
lang_bears
candidate_bears.items
Alors
refactorer
du
code
dans
coin
je
ce
bout
code
Pour
moi
problèmes
sont
les
suivants
générique
duplication
code
entre
le
trop
dans
try
ne
sait
pas
quelle
ligne
va
lever
une
exception
Je
propose
quelque
du
genre
py
try
response
=
redirect
next_page
Ajouter
l'exception
question
response
=
redirect
reverse
'homepage
set_old_smileys_cookie
response
profile
return
response
show_options=False
show_defaults=True
nothing
most
full
set
defaults
regard
current
settings
useful
docstring
ring
least
looks
docstring
sure
right
matplotlib
codes
paths
False
default
interpolation
default
result
same
upsampling
linear
interpolation
results
different
docstring
interpolation
parameter
upsample=False
interpolation
methods
data
nearest
Philipp
behavior
sense
bit
more
clarification
docstrings
case
docstring
improvement
source
array
smaller
requested
array
behavior
upsample=False
implementation
detail
specific
MultiInterface
reasons
part
public
interface
API
template
suggests
implementation
detail
specific
MultiInterface
reasons
template
part
public
interface
API
method
interfaces
public
API
number
methods
underscored
method
>
template
suggests
template
best
name
individual
element
list
data
entries
operate
efficiency
purposes
data
entry
appropriate
couple
comments
d
data
giant
iterable
image
array
wrong
type
data
little
bit
type
checking
My
basic
assumption
input
list
d
interface
dims
interface
value
_
extra_kws
loop
final
return
init
corresponds
values
last
interface
data
empty
loop
extra_kws
interfaces
loop
sort
validation
consistency
return
MultiInterface.init
correspond
return
last
interface
little
odd
word
'component
bits
multi-interface
comments
_component_dataset_template
long
reply
part
comment
receiver
ENROLL_STATUS_CHANGE
def
join_group_on_nodebb
sender
event=None
user=None
*
*
kwargs
pylint
disable=unused-argument
event
==
EnrollStatusChange.enroll
Same
comments
query
=
SELECT
id
FROM
stock_quant
WHERE
round
quantity
:numeric
%
d
round
reserved_quantity
:numeric
%
d
params
=
precision_digits
precision_digits
self.env.cr.execute
query
params
quants_ids
self.env
[
'stock.quant
]
.browse
i
[
i
self.env.cr.fetchall
Ah
right
master
'config_id
search
Right
much
way
difference
behavior
master
multiple
rescue
sessions
same
pos.config
master
example
rescue
field
python
'state
'closing_control
'=
True
'=
closed_session.config_id.id
something
python
'state
'closing_control
RESCUE
FOR
rescue
field
'config_id
'=
closed_session.config_id.id
sure
advantage
additional
divergence
versions
major
downside
approaches
something
more
generic
easier
@
api.multi
def
_get_linked_records
list
records
records
self
payment
token.
=
model_list
=
[
model
field
id
payment
token
'sale.subscription
'payment_token_id
]
r
self
res
r.id
]
=
[
]
m
model_list
records
self.env
[
m
]
]
.search
[
m
]
'=
r.id
]
records
res
r.id
]
.append
records._description
records
return
docstring
longer
pen
components
pyls
completion
item
json.JSONDecoreError
kind
documentation
JSONDecodeError
msg
str
doc
str
pos
int
\n\nSubclass
ValueError
following
additional
properties
\n\nmsg
unformatted
error
message\ndoc
JSON
document
parsed\npos
start
index
doc
failed\nlineno
line
column
sortText
aJSONDecodeError
insertText
JSONDecodeError
detail
json
label
JSONDecodeError
documentation
line
breaks
Screenshot
2020-05-08
]
https
//user-images.githubusercontent.com/153197/81387444-fc836900-9116-11ea-926a-e2fc40a5a0a0.png
hard
line
breaks
HTML
something
mdpopups.md2html
view
html.escape
content
same
escape
suggestion
RE
=
re.compile
r
P
<
entity
>
[
<
>
]
|
P
<
url
>
https
//
[
\w\d
%
/
\+\-=\\\.
]
*
flags=re.IGNORECASE
ENTITY_MAP
=
amp
<
lt
>
gt
def
text2html
view
sublime.View
content
str
popup_width
Optional
[
int
]
=
None
>
str
popup_width
None
popup
width
many
caracters
line
wrap_width
=
int
popup_width
/
view.em_width
content
=
<
br
>
.join
textwrap.wrap
content
width=wrap_width
def
replace_match
match
>
str
entity_match
=
match.group
'entity
entity_match
return
ENTITY_MAP
[
entity_match
]
url
=
match.group
'url
href=
>
<
/a
>
.format
url
url
content
=
re.sub
RE
replace_match
content
.replace
<
br
>
.replace
nbsp
nbsp
more
spaces
nbsp
re.sub
r
|
[
\xc2\xa0
]
lambda
match
nbsp
match.group
content
fixes
link
non-breaking
spaces
alignment
tables
disabled
text
wrapping
more
harm
good
<
>
s
places
line
line
language
MarkedString
dict
return
mdpopups.md2html
view
\n
.format
language
value
MarkedString
return
mdpopups.md2html
view
value
check
SessionBuffer.on_diagnostics_async
present
method
diagnostics
data
line
session_buffer.py
Documentation
bit
formal
mypy
Tuple
[
object
[
int
str
str
]
kind
=
cast
Tuple
[
int
str
str
]
tuple
sublime
cant
import
cast
typings
results
run-time
error
type
ignore
ok
Interesting
approach
nice
idea
public
API
comments
relationship
capability
wins
session_name
checked
capability
command
same
time
orig_view.sel
cursors
comments
past
undesirable
orig_view.sel
original
selection
choice
branch
type-hinted
suggestion
orig_sel
=
[
]
type
List
sublime.Region
worth
comment
full
name
list
name
[
flake8
]
__
*
[
E111
]
indentation
multiple
<
Comment
[
SideCI
]
https
//sideci.com
linker
flags
state
other
flags
such
-Wl
start-group
-Wl
as-needed
export-dynamic
flags
no-export-dynamic
default
behaviour
rest
libraries
separate
de-dup
step
.to_native
redundant
push/pop
state
flags
iterate
args
mark
specific
push-state
flag
duplicate
push-state
flags
pop-state
duplicate
pop-state
flags
push-state
course
easy
build
system
linker
flags
-Wl
as-needed
start-group
comma
separate
-Wl
arguments
doable
iterator
cherry
top
Wl
push/pop-state
multiple
state
flags
corner-cases
[
Flake8
]
__
[
W291
]
whitespace
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
F821
]
name
b'
<
Comment
[
SideCI
]
https
//sideci.com
>
nitpicking
AFAIK
meson
mesonlib
import
MesonException
mlog.debug
print
log_file
effect
guess
__
[
Flake8
]
__
[
E128
]
continuation
line
under-indented
visual
indent
<
Comment
[
Sider
]
https
//sider.review
>
__
[
Flake8
]
__
[
E226
]
whitespace
arithmetic
operator
[
link
]
https
//sider.review/gh/repos/19784232/pulls/5296
issue-3997116
sub
>
Sider
<
/sub
>
__
[
Flake8
]
__
[
E221
]
multiple
spaces
operator
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
F811
]
redefinition
unused
line
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E701
]
multiple
statements
line
colon
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E211
]
whitespace
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E704
]
multiple
statements
line
def
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E306
]
blank
line
nested
definition
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
F841
]
local
variable
'ENABLE_VIRTUAL_TERMINAL_PROCESSING
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E124
]
bracket
visual
indentation
<
Comment
[
Sider
]
https
//sider.review
>
__
[
Flake8
]
__
[
F401
]
..
mesonlib.EnvironmentException
unused
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
F811
]
redefinition
unused
'ArmarLinker
line
<
Comment
[
Sider
]
https
//sider.review
>
__
[
Flake8
]
__
[
W391
]
blank
line
end
file
<
Comment
[
Sider
]
https
//sider.review
>
__
[
flake8
]
__
*
[
E201
]
whitespace
[
*
[
E202
]
whitespace
]
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E741
]
ambiguous
variable
name
l'
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
F401
]
'shlex
unused
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
F401
]
unused
<
Comment
[
SideCI
]
https
//sideci.com
Do
libpath
/
confusing
absolute
path
format
Text
formatting
format
%
latter
something
meson
libpath
=
os.path.join
+=
[
-L
@
BUILD_ROOT
@
/
%
s
.format
os.path.dirname
libpath
[
Flake8
]
__
[
E231
]
whitespace
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
Flake8
]
__
[
E226
]
whitespace
arithmetic
operator
<
Comment
[
SideCI
]
https
//sideci.com
>
comment
abstract
methods
abc
abc.abstractmethod
def
make_homeserver
reactor
clock
docstring
NotImplementedError
comment
impenetrable
following
test
password
right
error
code
test
password
good
previous
tests
one
test
same
value
comment
please
particular
type
server
merge
separate
PR
list
connections
comment
accurate
hard
suggestion
Request
validation
token
email
address
user
account
suggestion
error
template
spacing
weird
suggestion
Get
information
devices
database
results
device
keys
self-signatures
*
cross-signing
signatures
get_e2e_device_keys_and_signatures
Thanks
comment
bit
d06fd486f43f144af029edc6bcf991dadfb5006a
sense
hrm
set
dict
members
members.add
ev.sender
members
ev.sender
ev
itertools.chain
results
]
results
event
]
results
events_after
]
Note
sample
config
pairs
extra_attributes
dict
s/copy/move/
docstring
somebody
rule
conditions
code
easy
fix
python
conditions
rule.get
conditions
[
]
c.get
room_id
pattern
old_room_id
c
conditions
move
comment
useful
imho
suggestion
self._scheduled_expiry
=
None
type
Optional
[
IDelayedCall
]
readable
assert
hs.config.worker_app
good
sanity
check
form
documentation
master
understanding
events
prev
events
rejections
description
idea
first
line
one-line
description
function
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
one-liner
bit
opaque
Find
transitive
predecessors
events
rejections.
comment
bit
transaction
events
ephemeral
persistent
comment
limit
ephemeral
persistent
event
types
suggestion
import
attr
import
Optional
@
attr.s
class
_TestImage
image
expected
results
data
raw
image
content_type
type
image
content
type
e.g
image/png
extension
extension
format
e.g
.png
expected
bytes
cropped
thumbnailing
None
test
success
expected
bytes
thumbnailing
None
test
valid
image
returned.
data
=
attr.ib
type=bytes
=
attr.ib
type=bytes
extension
attr.ib
type=bytes
=
attr.ib
type=Optional
[
bytes
=
attr.ib
type=Optional
[
bytes
suggestion
Test
ACL
suggestion
Test
ACL
everyone
cycle
loop
sort
thing
constructor
errors
startup
import
cycles
least
bit
cough
*
*
cough
*
suggestion
Test
email
profile
suggestion
Test
email
suggestion
Test
email
suggestion
Test
email
documentation
please
suggestion
url.rstrip
/
isinstance
url
str
None
comment
necessary
sure
comment
tests
*
absolute
time
*
countdown
time
clear
enough
Please
type
hints
docstrings
methods
class
suggestion
documentation=
Number
requests
token
try
count
Note
initial
try
Was
copy-and-paste
error
comment
dependencies
constructor
things
startup
problem
dependencies
comment
GH
/
docstring
test
briefly
multiline
literal
please
i.e.
lot
easier
suggestion
Test
room
suggestion
Determine
user
alias
comments
nice
comment
comment
comments
mean
docstring
ownership
None
suggestion
user_id
NOT
IN
.format
suggestion
Servlet
trace
room
database
sure
doubt
comment
XXX
something
effect
whole
swathe
comments
situation
key
correct
thing
*
official
*
Suggest
comment
license
Vector
BLF
>
No
official
specification
binary
logging
format
available
implementation
Toby
Lorenz
C++
library
Vector
BLF
GPLv3
https
//bitbucket.org/tobylorenz/vector_blf
Start
issue
TODO
suggestion
minimum
major
version
recent
micro
version
minor
suggestion
Configuration
network
requests
resolver
diff
test
git
diff
diff
git
a/pex/util.py
b/pex/util.py
index
..
a/pex/util.py
+++
b/pex/util.py
@
@
-176,12
+176,9
@
@
class
CacheHelper
object
target_dir_tmp
=
target_dir
+
+
uuid.uuid4
.hex
name
zf.namelist
name.startswith
source
name.endswith
'/
prefix
+
target_name
=
os.path.join
dependency_basename
name
[
len
source
]
contextlib.closing
zf.open
name
zi
safe_open
target_dir_tmp
target_name
'wb
fp
shutil.copyfileobj
zi
fp
+
zf.extract
name
target_dir_tmp
+
os.rename
target_dir_tmp
source
+
os.path.join
target_dir_tmp
dependency_basename
rename_if_empty
target_dir_tmp
target_dir
dist
=
DistributionHelper.distribution_from_path
target_dir
perm-perserving
logic
zips
https
//github.com/pantsbuild/pex/blob/b2beec7ea48abdaf288ed40ac2b7644afa549c09/pex/common.py
L81-L102
nice
higher-level
zip
apis
own
comments
re
uniformity
validation
_private
check
3.0-3.2
Pex
versions
brief
comment
block
PY2
PEX
3.0-3.2
suggestion
Handle
Webex
Teams
comment
line
module
suggestion
Same
other
comment
suggestion
Message
'otheruser
general
None
'Hello
suggestion
Message
'user
general
None
'Hello
[
comment
]
https
//github.com/opsdroid/opsdroid/pull/1587/files
r474656706
suggestion
return
correct
single_state_key
False
key
state_key
single_state_key
True
value
=
event
content
[
key
]
suggestion
Use
room
state
room
default
docstring
base
class
key
string
list
strings
parameter
blocks
suggestion
data
=
data.content
suggestion
Use
room
state
room
message
default
suggestion
_LOGGER.error
f
State
event
self._event_type
state
key
state_key
google
style
docstrings
whole
code
base
docstrings
google
style
ones
user
new
format
modules
dict
strange
behaviour
modules
dict
deprecation
warning
other
warning
notice
list
point
people
documentation
docstring
docstring
overall
module
first
None
relation_id
None
isinstance
relation_id
int
raise
ModelError
first
comment
ternary
operators
such
cases
need
way
comment
suggestion
fake_script
[
=
db0
]
=
format=json
]
else
echo
ERROR
value
option
-r
relation
>
exit
fi
self.network_get_out
TODOs
final
docs
nit
header
comments
URLs
new
location
consider
URLs
uploaded
files
Drop-by
comment
curious
validation
age
valid
format
records
web
UI
API
safe
exception
meaning
enum
value
FYI
repository
admin
page
documentation
state
implies
comment
per-repository
'deactivated
setting
bit
weird
internal
dict
use
.items
filter
action
registries
resource
registry
separate
mapping
key
expr
body
comment
resource_parameters
client
instance
zone
removal
delay
self.recording
wait
record
deletion
time.sleep
cases
resource
state
transition
call
case
pr
logs
singletons
log
instance
base
action
class
class
attribute
imo
whitelist
docs
provide
e.g
[
'Engine
]
minor
nit
suggestion
Value
filter
ELBv2
nit
other
places
comment
class
i
deprecate
release
inconsistent
configuration
common
filter
previous
comment
action
instance
loop
resource
.addCleanup
equal
..
Right
similar
line
@
something
suggestion
def
__eq__
other
Equality
subclass
new
attributes
isinstance
other
Patch
return
False
return
Patch.__eq__
other
==
https
//lgtm.com/rules/9990086/
qtilde
arg
documentation
better
docstring
LaTeX
representations
unicode
readability
doc
consistency
nice
docstrings
style
tensor
result
docs
https
//scikit-hep.org/pyhf/_generated/pyhf.tensor.pytorch_backend.pytorch_backend.html
pyhf.tensor.pytorch_backend.pytorch_backend.clip
Given
comment
PR
good
alpha
similar
API
upper
limit
suggestion
def
upperlimit
data
model
scan
alpha=0.05
return_results=False
below
limits
=
[
_interp
alpha
resarary
[
i
[
:-1
]
scan
[
:-1
]
i
range
]
docstring
name
assert
blocks
easier
new
line
relevant
comment
suggestion
_extra_cxx_compile_args
=
[
-std=c++11
+
_ccx_warns
[
gh-1422
]
Isse
RHEL6
_extra_cxx_compile_args
+=
[
-D__STDC_FORMAT_MACROS
suggestion
details
doclink
return
helpmsg
suggestion
helpmsg
=
textwrap.dedent
leading
newline
suggestion
r
suggestion
todo_include_todos
=
False
PEP8
suggestion
value=sum
hard
larger
example
@
cocotb.coroutine
def
custom_clock
True
dut.clk
<
yield
Timer
high_delay
dut.clk
<
yield
Timer
low_delay
high_delay
=
low_delay
cocotb.fork
custom_clock
yield
Timer
high_delay
=
low_delay
change
clock
speed
yield
Timer
Note
initial_delay
runtime
sense
purpose
file
good
mentions
makefile
special
great
_name
comment
docs
rc
file
readable
textwrap.dedent
suggestion
rc_body
=
textwrap.dedent
<
WinUser.h
>
LANGUAGE
ISOLATIONAWARE_MANIFEST_RESOURCE_ID
RT_MANIFEST
BEGIN
<
xml
version=
encoding=
UTF-8
standalone=
>
<
assembly
xmlns=
urn
schemas-microsoft-com
asm.v1
manifestVersion=
>
<
assemblyIdentity
name=
%
s
version=
type=
win32
processorArchitecture=
%
s
>
<
file
name=
%
s
%
s
END
%
name
archtitecture
filename
.join
dependencies
https
//cocotb
cocotb.triggers.Lock
suggestion
lock
asynchronous
context
manager
keyword
async
statement
async
lock
stuff
docstring
one
docstring
ReturnTypes
str
None
bool
is_valid_taxid
False
Do
False
taxid
valid
docstring
ReturnTypes
str
None
bool
is_valid_taxid
False
part
reference
top
part
docstring
implies
merged.dmp
taxid
function
arguments
parameters
docstring
Note
rank_name
returns
dict
.get
'rank
default
value
rank_dict
=
self.nodes.get
taxid
rank_dict
'rank
taxid
self.nodes
=
rank_dict.get
'rank
rank_dict
==
pass
rank_name
==
pass
suggestion
rank_name
=
self.nodes.get
taxid
.get
'rank
rank_name
==
comment
names
nodes
docstring
other
comments
anything
docstring
above
wrong
self.names
self.nodes
isins
Python
documentation
isinstance
clause
interesting
find
appropriate
exception
AmbiguityError
specific
purpose
docstring
]
https
//github.com/django/django/blob/e18156b6c35908f2a4026287b5225a6a4da8af1a/django/db/migrations/exceptions.py
L4
error
quite
application
specific
unsure
django
exceptions
old
ValueError
@
ppicka
@
ggainey
wdyt
redundant
line
browser.click
ensure_page_safe
anyways
nice
example
widgets
widgets
call
Please
entity
helpers
doc
string
Release
object
models.py
Attributes
list
documentation
good
link
bug
report
comment
block
future
readers
limit
extra
re
comment
line
line
comment
line
lines
function
docblock
comment
kind
good
docblock
new
behavior
comment
rate
=
loss
output_shape
i
shape
check
informative
softmax
class
prediction
better
readability
options
one-class
prediction
block
n_pred_ch==1
place
@
comment
L53
applies
logic
util
function
save_key_metric
checkpoint
session
value
key_metric
higher
previous
values
training
top
N
checkpoints
sessions
value
key
metric
order
Suggest
[
torch.as_tensor
]
https
//pytorch.org/docs/stable/torch.html
torch.as_tensor
latest
PyTorch
programming
Thanks
network
anisotropic
kernels
case
kernels
such
conv
kernels
key
feature
anisotropic
design
confusions
docstring
implementation
inherit
ChannelSELayer
python
class
ResidualSELayer
ChannelSELayer
squeeze-and-excitation
layer
residual
connection
:py
class
monai.networks.blocks.ChannelSELayer
return
+
super
.forward
x
deter_flag
upsampling
particular
module
comments
choices
upsample_mode
reproducibility
intuitive
future
upsampling
mode
same
logic
few
other
modules
deter_flag
use
functools.warps
__name__
anything
docstrings
https
//docs.python.org/2/library/functools.html
functools.wraps
parameter
number
upgrade
test
comment
scylla
issue
link
scylla
issue
allow
argument
function
filter
kind
docstring
comment
need
shell
marker
utils
function
random
string
length
N
complex
nobody
main
type
subtype1
parent
complex
break
separate
methods
docstring
comment
cfstats
bug
Scylla
decorator
self.cql_connection_patient
node
truncate_ks
USE
truncate_ks
helper
functions
watcher
output
verbose
param
todo
output
please
use
code
TODO
work
avocado
params
logic
complex
something
template
python
import
Template
all_scylla_version_urls
=
set
scylla-manager
noarch
arch_list
=
[
x86_64
noarch
]
'scylla-manager
version_url
x86_64
]
arch
[
x86_64
noarch
]
all_scylla_version_urls.add
Template
version_url
.substitute
basearch=arch
releasever=
excessive
use
variable
thing
hard
forth
docs
personal
preference
reST/sphinx
format
google
https
//stackabuse.com/python-docstrings/
suggestion
snapshot
internal
simulator
representation
better
way
catch
result
is_user_a_host_of_challenge
has_user_participated_in_challenge
appropriate
variable
else
condition
something
is_participant
form
submission_params
[
'challenge_phase__challenge
]
=
challenge
ChallengeSubmissionManagementSerializer
SubmissionSerializer
variable
suggestion
difficulty
suitable
commented
format
data
API
submission
worker
helpful
code
future
proper
comment
criteria
submission
successful
digging
updating
code
future
follow
numpy
docstring
style
https
//numpydoc.readthedocs.io/en/latest/format.html
great
comment
something
TODO
hardcoded
cluster
configuration
such
instance_type
subnets
AMI
configuration
Good
set
comments
something
response
data
/
comment
line
action
response
Same
Please
comment
line
action
sure
case
=
torch.tensor
[
]
print
a.sum
>
tensor
'now
function
kind
reference
good
commit
message
docstring
Backticks
comment
moment
input
checks
self.x
e.g.
num_chains
n_dims
additional
checks
==
necessary
comment
code
==
consistency
Variable
fort
Add
comment
means
correct
login_retries
relevant
case
total
tries
Rather
=
clearer
i
args.login_retries
initial
try
+
login_retries
i
<
args.login_retries
clarity
long
time
other
DNS
plugins
10-60
seconds
unlikely
interactive
user
seconds
DNS
changes
impact
someone
many
distinct
certificates
renewal
process
certificate
process
_across_
certificates
sure
change
part
PR
completeness
documentation
clear
pattern
@
bmw
Could
other
plugins
specific
version
number
cc344bfd1
equivalent
comment
other
setup.py
files
Remember
local-oldest-requirements.txt
minimum
acme/certbot
version
same
commit
local-oldest-requirements.txt
file
root
plugin
familiar
change
more
comment
conversation
function
same
behavior
function
Python
os.rename
Windows
different
behavior
Bonus
points
implementation
rename
worried
implementation
PR
suggestion
Ensure
src
dst
platforms
months
nota
bene
method
private
TODO
nice
ClientV2
terms
service
attribute/method
info
TOS
user
class
knowledge
fine
TODO
meaningful
error
message
assert
Python
command
line
fine
function
copy_group
effect
Windows
understandable
documentation
parameter
below
current
implementation
queue
specific
signal
values
coordination
START/LOCKED/STOP
test
method
event
Oh
good
point
devs
things
problem
Commenting
great
idea
+1
comment
response
values
nice
thing
function
unit
tests
file
hashes
good
idea
comments
developer
constants
configurator.py
fix
test
failures
ah
couple
comment
formatting
error
table
line
edge
column
number
=
characters
top
bottom
lines
spacing
other
lines
html
certbot-dns-sakuracloud/docs
directory
venv
@
bmw
automatic
check
sort
documentation
package
nit
part
public
API
josepy.JSONDeserializable
defines
method
fields_to_partial_json
comment
https
//github.com/certbot/certbot/pull/7176
issuecomment-567718597
fields_to_partial_json
to_partial_json
assumptions
internals
josepy.JSONDeserializable.to_partial_json
methods
resource
cases
Bonus
points
code
reuse
sane
limited
teardown
main
python
process
finishes
cases
mind
teardown
teardown
pytest
general
teardown
official
documentation
https
//docs.pytest.org/en/latest/usage.html
calling-pytest-from-python-code
teardown
occurring
end
pytest
invocation
end
python
script
Done
respective
docstring
ACMEServer
specific
actions
find_comments
case
sensitive
worth
higher
level
docstring
find_directives
search
case
insensitive
arguments
comments
comment
error
changes
system
Ubuntu
ssl_module
self.parser.modules
case
line
macOS
Error
command
[
'apache2ctl
'-t
'-D
]
runtime
parameters
certbot.errors.MisconfigurationError
Error
Apache
parameters
[
'-t
'-D
]
relevant
part
traceback
>
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/configurator.py
_deploy_cert
cert_key
self.prepare_server_https
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/configurator.py
prepare_server_https
>
self.prepare_https_modules
temp
self.ensure_listen
port
https=True
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/configurator.py
prepare_https_modules
self.parser.aug.load
>
self.parser.reset_modules
Reset
new
ssl_module
path
openssl
version
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/parser.py
reset_modules
self.modules
self.update_modules
self.parse_modules
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/parser.py
update_modules
>
matches
=
apache_util.parse_modules
self.configurator.option
ctl
mod
matches
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/apache_util.py
parse_modules
DUMP_MODULES
]
>
return
parse_from_subprocess
mod_cmd
r
*
_module
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/apache_util.py
parse_from_subprocess
stdout
=
_get_runtime_cfg
command
return
re.compile
regexp
.findall
stdout
/my/local/path/certbot/certbot-apache/certbot_apache/_internal/apache_util.py
_get_runtime_cfg
Error
Apache
parameters
.format
command
Small
errors
behavior
test
cache
performance
reasons
able
within-run
information
while
re-parse
server
blocks
time
same
server
block
reference
get_vhosts
ephemeral
cleaner
safer
way
use_if
way
users
class
vhosts
method
cache
raw
blocks
comment
method
only
way
new
vhost
nit
part
public
API
[
]
https
//certbot.eff.org/docs/api/certbot.util.html
part
left
documentation
Fixed
pathological
situations
CTRL+C
docker-compose
situation
process
Python
object
associated
system
process
PID
terminate
fail
scope
OSError
comment
Same
comment
global
setting
fair
comment
side
effects
kind
things
general
approach
side
effects
cleanup
callback
_setup_primary_node
cleanup
mechanism
afterwards
suggestion
new
<
IfMod
mod
>
path
comment
accurate
todo
ebp
PR
new
knowledge
launchpad
build
least
architecture
comment
sure
code
thing
able
exit
status
snapcraft
remote-build
build
something
IDisplay
complex
years
call
IDisplay.checklist
force_interactive=True
interactivity
plan
]
https
//github.com/certbot/certbot/issues/5551
issuecomment-377004693
domains
certificate
non-interactive
MissingCommandlineFlag
Missing
command
line
flag
config
entry
setting
Which
domain
names
selected
enhancements
force_interactive
parameter
False
default
cert_domains
call
generic
choose_values
function
values
additional
parameters
function
Thanks
meaningful
documentation
[
PEP
]
https
//www.python.org/dev/peps/pep-0257
[
style
guides
]
https
//certbot.eff.org/docs/contributing.html
coding-style
multi-line
docstrings
line
summary
blank
line
longer
description
Ideally
convention
line
issues
documentation
[
developer
installation
instructions
https
//certbot.eff.org/docs/contributing.html
running-a-local-copy-of-the-client
virtual
environment
documentation
-C
docs
clean
html
certbot/certbot-dns-google
directory
error
syntax
raises
description
syntax
]
http
//www.sphinx-doc.org/en/stable/domains.html
info-field-lists
line
exception
type
distro.version
pretty
different
current
behavior
value
user
agent
LTS
bionic
example
distro.name
pretty=True
empty
string
call
.join
get_python_os_info
full_name=True
comment
function
comment
time
function
os.path.isdir
self.config.config_dir
true
error
self._data
None
error
branch
Similar
Erica
comments
sure
user
class
function
case
private
_csr_obtain_cert
_csr_obtain_cert
analogous
analogous
lines
_csr_obtain_cert
le_client
paths
clear
None
thing
comment
_report_new_cert
cert_path
fullchain_path
None
dry
run
same
dry
run
ok
_report_new_cert
comment
false
dry
run
config.dry_run
cert_path
raises
case
account
colon
ConflictError
links
docs
https
//certbot.eff.org/docs/contributing.html
updating-the-documentation
docs
exists
exist
correct
sense
get_eligible_coupons
def
get_valid_coupon_versions
product
user
code=None
.....
ids
latest
coupon
versions
CouponEligibility.objects.select_related
coupon
.filter
product=product
coupon__enabled=True
code
product_coupon_query
=
product_coupon_query.filter
coupon__coupon_code=code
cv_latest
=
CouponVersion.objects.select_related
coupon
.filter
coupon__in=product_coupon_query.values_list
.order_by
coupon
-created_on
coupon
.values_list
pk
complex
simple
explain
data
docstring
text
module
Nit
sure
docstring
method
right
way
familiar
namedtuple
way
enum
appropriate
sorry
SimpleNamespace
[
doc
]
https
//docs.python.org/3/library/types.html
types.SimpleNamespace
something
PEARSON_FILE_TYPES
=
SimpleNamespace
EAC='eac
VCDC='vcdc
Usage
exams.pearson.constants
import
PEARSON_FILE_TYPES
def
is_eac_file_type
file_type
filetype
PEARSON_FILE_TYPES.EAC
return
nice
namedtuple
et
al
PEARSON_FILE_TYPES
values
PEARSON_FILE_TYPES.CAND
etc.
different
PR
please
comment
field
able
docstring
current
style
design
Values
powers
bitmask
explanation
docstring
Did
comment
authorize_for_latest_passed_course
docstring
more
sense
class
level
open
discussion
course
team
emails
docstring
header
POST
body
docs
https
//documentation.mailgun.com/en/latest/user_manual.html
tracking-bounces
please
docstring
arg
corresponding
argument
good
tests
trigger
error
conditions
e.g.
pytest.raises
ValueError
something
wrong
small
additional
clean-up
Python
function
signature
function
align
*
objects
join='inner
copy=True
fill_value=dtypes.NA
indexes=None
calls
small
win
efficiency/clean
code
Could
brief
comment
special
logic
dask.array
index
NumPy
array
dask
array
suggestion
LooseVersion
cftime.__version__
<
LooseVersion
dayofwk=-1
dayofwk
dayofyr
attributes
returned
date
object
versions
cftime
versions
cftime
greater
return
date.replace
year=year
month=month
day=day
dayofwk=-1
return
date.replace
year=year
month=month
day=day
distutils.version
import
LooseVersion
top
module
suggestion
LooseVersion
cftime.__version__
<
LooseVersion
dayofwk=-1
dayofwk
dayofyr
attributes
returned
date
object
versions
cftime
versions
cftime
greater
[
dayofwk
=
-1
comment
link
numpy
bug
first
comment
e.g.
writing
first
explicit
test
https
//stackoverflow.com/questions/45671803/how-to-use-pytest-to-assert-no-warning-is-raised
Put
logic
context
manager
e.g.
@
contextlib.contextmanager
def
setup_files
create_tmp_file
tmpfile1
create_tmp_file
tmpfile2
ds1
ds2
=
self.gen_datasets_with_common_coord_and_time
data
temporary
files
ds1.to_netcdf
tmpfile1
ds2.to_netcdf
tmpfile2
yield
[
tmpfile1
tmpfile2
]
def
test_open_mfdataset_does_same_as_concat
self.setup_files
files
setUp
/
tearDown
methods
ExitStack.enter_context
[
pandas
documentation
]
https
//pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html
sense
values
base
frequencies
>
frequencies
day
“
aggregated
intervals
example
‘
’
frequency
base
Defaults
Does
mean
non-zero
base
arguments
frequencies
day
values
zero
frequency
multiple
value
first
bin
error
spots
docstrings
xarray.Dataset
xarray.DataArray
xarray.Variable
decode_bytes
names
attributes
attributes
please
previous
comment
NotImplementedError
https
//github.com/pydata/xarray/pull/2674
generic
Dataset
DataArray
Variable
version
def
rolling_exp_nanmean
array
*
axis
window
import
numbagg
axis
==
return
*
array
cast
return
numbagg.rolling_exp_nanmean
array
axis=axis
window=window
class
RollingExp
def
mean
return
self.obj.reduce
rolling_exp_nanmean
dim=self.dim
window=self.alpha
little
strange
other
veggies
integers
shape
sparse
repr
https
//github.com/pydata/xarray/issues/2528
issuecomment-434456201
support
max_width
closing
Obv
need
helpful
comment
fixture
data
need
instance
lines
pprint_str
few
more
intermediate
variables
continuations
parentheses
\
comment
use
sum
tuples
unusual
dedent
clause
guard
clause
pattern
comment
necessary
way
easier
suggestion
Remove
levels
MultiIndex
unused
categories
CategoricalIndex
Array
use
xarray.core.pycompat
import
dask_array_type
isinstance
data
dask_array_type
dask
Nit
consolidated
suggestion
formatting
little
bit
has_access
request.user
course_key
private_managed
courses
non-admin
users
members
teams
=
[
ts.teamset_id
ts
course_module.teamsets
ts.teamset_type
==
TeamsetType.private_managed
]
=
CourseTeam.objects.filter
*
*
result_filter
.exclude
topic_id__in=private_topic_ids
=
CourseTeam.objects.filter
topic_id__in=private_topic_ids
membership__user__username=request.user
queryset
=
public_teams
private_managed_teams_of_user
queryset
=
CourseTeam.objects.filter
*
*
result_filter
docstring
superfluous
code
self-explanatory
method
sentence
method
name
example
async_update_courses
unnecessary
confusion
different
names
module
generate_course_overview
versus
update_select_courses
latter
subtasks
former
python
assert_not_called
mock
library
version
python
python
mock
external
library
part
standard
lib
@
aed-mbp
devstack
master
lms-shell
docker
exec
-it
env
TERM=xterm-256color
/edx/app/edxapp/devstack.sh
open
root
@
lms
/edx/app/edxapp/edx-platform
./manage.py
lms
>
>
>
import
mock
>
>
>
m
=
mock.Mock
>
>
dir
m
'assert_called_once_with
'assert_called_with
'assert_has_calls
'attach_mock
'call_count
'configure_mock
'method_calls
'mock_add_spec
'mock_calls
'reset_mock
'return_value
]
reason
statement
exception
mock
objects
attributes
i.e
mocked_retire.foobar
valid
statement
nit
change
view
name
PasswordResetView
view
docstring
top
function
purpose
data
available
Optimizely
experiments
different
name
cant
think
anything
'remove_user_from_existing_memberships
kinda
user
user
memberships
Idk
..
note
input
users
test
docstring
Add
endpoint
Edge
library
way
bullet
point
format
python
need
optional
Same
comment
utility
URL
learner
portal
Nit
comment
worthy
inclusion
command
doc
string
Esto
podría
hacer
una
forma
mejor
Odoo
tiene
funciones
nos
dan
el
precio
una
tarifa
para
un
producto
así
que
se
podría
hacer
depenedes
que
la
forma
en
tu
función
si
la
tuviese
devolvería
resultado
correctamente
api.multi
@
api.depends
'standard_price
api.onchange
'standard_price
def
_get_pvm
pricelist
=
self.env
[
'product.pricelist
]
.search_read
[
'name
'=
'PVM
]
[
'id
]
new_ctx
=
dict
context
[
'pricelist
]
=
pricelist
]
[
'id
]
product
self.with_context
new_ctx
se
si
funciona
sino
habría
que
instanciar
los
self.ids
el
contexto
un
browse
o
usar
api.one
pero
así
nos
evitamos
que
una
entrada
múltiple
haya
que
hacer
el
search_read
tarifas
cada
entrada
product.pvm_price
=
product.price
este
campo
es
calculado
y
nos
el
precio
del
prodiucto
según
la
tarifa
contexto
acepta
también
otros
GET_line_found
=
False
....
loop
GET_line_found
=
True
....
loop
assert
GET_line_found
failure
message
assert
GET_line_found
==
True
explicit
First
steps
test
host
collections
Create
host
collections
same
org
>
host
Lots
small
nitpicks
wrong
case
typos
redundant
spaces
Please
custom
user
attempt
lifecycle
environment
admin
user
@
id
768b647b-c530-4eca-9caa-38cf8622f36d
@
BZ
@
Steps
admin
user
additional
lifecycle
other
Library
user
administrator
privileges
role
following
permissions
*
Miscellaneous
access_dashboard
Lifecycle
Environment
*
edit_lifecycle_environments
promote_or_remove_content_views_to_environment
*
view_lifecycle_environments
*
Location
view_locations
Organization
view_organizations
created
role
custom
user
custom
user
Log
Navigate
Content
>
Lifecycle
Environments
@
Assert
additional
lifecycle
environment
viewable
accessible
custom
user
CaseLevel
Integration
in-line
comment
string
great
reason
default
approach
overloaded
method
e.g
def
navigate_to_entity
Navigate
Compute
Profile
entity
page
Navigator
self.browser
.go_to_compute_profiles
nice
comment
wait_until_element_is_not_visible
vs
wait_until_element_exists
message
account
menu
trivial
first
look
list
services
sense
Just
services
Non-blocking
comment
previous
version
Satellite
RHEL
version
test
execution
sense
outside
loop
resources
condition
same
iteration
visible
impact
test
execution
time
non-blocking
comment
var
code
python
group_name
=
'foobargroup
string
Travis
line
test-docstrings
branch
travis
decorators
BZ
information
history
nitpick
Create
composite
content
view
component_ids
option
ids
different
content
views
next
test
case
same
Original
BZ
location-id
organization-id
org/loc
names
test
ok
need
please
implement
one
entity
ids
item
]
]
]
]
variables
=
item
]
little
easy
next
person
test
personal
thought
nonblocking
comment
last
assertion
way
test_case_status
FAILED
intention
code
failure
fail
test
re-raise
caught
exception
python
try
ssh.upload_file
'custom-hiera.yaml
'/etc/foreman-installer
Exception
self._custom_hiera_file_creation
mongodb_type
default
other
cleanup
code
raise
arguments
exception
handler
exception
indentation
jenkins
@
new
global
params
necessary
assert
len
glob_param_list
perpose
comments
external
user
docstring
external
AND
internal
users
sufficient
python
file
existent
sftp
session
comment
representation
page_objects
placement
fine
dict
method
dict
@
rochacbruno
python
class
TestCase
unittest2.TestCase
=
[
]
def
self.assertNotRaise
use
self._default_value_handlers_classes
values_handlers
class
APITestCase
TestCase
Test
case
API
tests
=
True
=
[
APIRaisesValueHandler
]
class
CLITestCase
TestCase
Test
case
API
tests
=
True
=
[
CLIRaisesValueHandler
]
suggestion
def
add_item
item
Add
repository
collection
param
BaseRepository
item
Item
returns
None
suggestion
def
add_items
items
Add
multiple
repositories
collection
param
list
items
List
BaseRepository
objects
returns
None
suggestion
Create
new
http-proxy
attributes
update
delete
Same
comment
other
PR
coverage
discussion
consideration
coverage
everything
run
value
test
coverage
longer
periods
time
implementation
ok
var
names
confusing
wrong
Virtual
machine
access
host
ssh
key
host
access_hostname
optional
function
i
smth
ssh
key
host
known_hosts
case
func
separate
ones
ssh
key
few
known_hosts
Second
local_key_path
remote_ssh_path
'local
satellite
key
path
vm
path
vm
helper
vm
perspective
naming
opposite
path
local
key
remote
🙂
So
i
different
approach
let
sat_key_path
vm_ssh_path
confusion
abalakh
exception
setting
none
same
comment
above
..
ignore
comment
steps
part
setup
search
configuration
read
status
search
results
status
values
previous
comment
widgets
python
values
session.virtwho_configure.read
name
[
'deploy.command
'overview.status
]
command
values
]
[
'command
]
status
=
values
'overview
]
[
'status
]
code
more
better
get_virtwho_status
service
status
error
status
rhsm.log
such
def
get_virtwho_status
Return
status
virt-who
service
virt-who
configure
file
_
logs
=
runcmd
/var/log/rhsm/rhsm.log
error
=
len
re.findall
r'\
[
*
ERROR
\
]
logs
ret
stdout
=
runcmd
'systemctl
status
virt-who
=
[
running
'Active
active
]
stopped_status
=
[
'is
'Active
inactive
dead
]
ret
=
return
key
stdout
key
running_stauts
return
key
stdout
key
stopped_status
return
elif
error
=
return
return
restart_virtwho_service
get_virtwho_status
==
Org
creation
test
case
common
fixture
sync
plan
cases
@
pytest.fixture
scope='class
def
setup_org_for_syncplan
Create
organization
re-used
tests
=
entities.Organization
.create
yield
org
org.delete
Same
comment
redundancy
multicast=True
[
]
True
mac
=
gen_mac
multicast=True
locally=True
mac.startswith
'fe
break
breaks
faux_factory
first
octet
https
//github.com/omaciel/fauxfactory/blob/master/fauxfactory/__init__.py
L630
comment
mac
fe
try/except
block
deletion
possible
smth
python
pytest
import
raises
ExceptionNameHere
session.partitiontable.delete
name
ExceptionNameHere
exception
NoSuchElementException
deletion
locked
ptable
Please
assertion
audit
comment
print
Manipulates
Satellite
oscap
policy
steps
verification
comment
CV
exc
exception
variables
good
consistent
–
logger.exception
way
better
message
uid
Error
e
suggestion
Test
filtering
global_ultimate_duns_number
good
comment
purpose
line
additional
spf=pass
check
good
f-string
%
>
approach
visible
code
reminder
things
example
stellargraph.layers.experimental
import
RGCN
approach
users
annotation
documentation
warning
code
lines
def
decorator
decl
msg
=
f
experimental
decl.__doc__
..
warning
dedent
decl.__doc__
def
new_decl
*
args
*
*
kwargs
warnings.warn
msg
return
decl
*
args
*
*
kwargs
return
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
python
convention
line
summary
own
paragraph
graph
log
likelihood
loss
function
https
//arxiv.org/abs/1710.09599
different
code
Potentially
ways
length-ing
database
integer
potentially-large
feature
vectors
network
avoiding
list
dict
structures
+
data
single
result
Py2neo
special
case
function
operation
https
//py2neo.org/v4/database.html
py2neo.database.Transaction.evaluate
https
//py2neo.org/v4/database.html
py2neo.database.Cursor
queries
single
value
single
record
evaluate
method
first
value
next
record
None
field
record
present
suggestion
RETURN
size
node.features
=
self.graph_db.evaluate
feature_query
backticks
node_id_constraint
=
CREATE
CONSTRAINT
ON
n
paper
ASSERT
n.ID
IS
UNIQUE
tx
=
graph.begin
autocommit=True
tx.evaluate
node_id_constraint
graph.run
db.constraints
.data
'name
'description
'CONSTRAINT
ON
paper
paper
ASSERT
paper.ID
UNIQUE
value
cases
matter
worth
error
case
e.g
convert_nodes
throws
exception
nodes
None
branch
out
actual
nodes
edges
nodes_from_edges
nodes
None
nodes_after_inference
=
pd.DataFrame
[
]
index=nodes_from_edges
nodes_after_inference
=
nodes
nodes
None
try
self._nodes.ids.to_iloc
KeyError
e
Hm
output
indices
shape
num_outputs
comment
briefly
E.g
appropriate
labels
number
outputs
batch
full
batch
methods
output
indices
tensor
batch
shape
×
num_out
features
×
num_nodes
Rather
hard-code
smallest
batch
shape
right
one
following
home
point
suggestion
output_batch_shape
=
min
inp.shape
[
self.num_batch_dims
inp
inputs
required
action
issue
FIXME
comment
general
name
specific
solution
classification
one
flexibility
bit
right
name
suggestion
@
experimental
reason=
unit
tests
[
]
good
explanation
issue
description
part
docstring
arguments
particular
obvious
query
length
target
distance
most
cases
slice
None
whole
sequence
someone
particular
slice
e.g
slice
training
examples
target_distance
Thoughts
return
other
method
😄
Add
more
comments
code
block
nice
catch
Shall
docstrings
parameters
private
methods
useful
code
future
issues
tasks
more
suggestion
@
experimental
reason=
more
thorough
testing
documentation
issues=
[
issue
number
]
graph
edge
weights
timestamps
format
interpretation
timestamps
seconds
minutes
hours
format
e.g.
HH
MM
SS
such
explanation
available
comment
purpose
parameter
clear
infinite
loops
enough
data
graph
random
settings
more
parameter
behaviour
progress
bar
much
data
percent
user
decide
process
progress
bar
'infinite
loop
behaviour
class
docstring
generic
name
peculiar
bilinear
transform
general
PyTorch
layer
layer
matrix
Weight
*
matrix
+
Bias
pretty
arbitrary
dimensions
only
matrix
*
Weight
*
vector
matrix.shape
[
]
==
vector.shape
]
addition
documentation
name
bilinear
transform
docs
focus
mention
DGI
scope
small
PR
happy
something
specific
e.g
suggestion
class
DeepGraphInfoMaxDiscriminator
Layer
suggestion
class
DGIDiscriminator
Layer
other
things
future
possible
migration
path
users
layer
Sorry
new
comment
suggestions
right
bit
code
See
previous
comment
Sequence
few
lines
sure
~.JSONEncoder.encode
Please
building
sphinx
order
suggestion
meth
JSONEncoder.encode
own
process
suggestion
Check
family
lil
typo
suggestion
Makes
points
directed
clockwise
suggestion
func
~.space_ops.shoelace_direction
direction
suggestion
point
direction
point
order
Wishlish
non-blocking
rendered
example
pretty
cool
something
other
PR
case
small
example
look
documentation
manim_directive.py
manim
directive
video
docstring
Comment
asymmetry
output
last
line
case
lines
other
suggestion
manim
import
*
scenes
following
python
quality
m
manim
example_scenes.py
SquareToCircle
-p
Use
flag
quality
l
rendering
lower
quality
Use
-s
end
final
frame
Use
-p
preview
animation
image
-s
Use
-n
<
number
>
n'th
animation
scene
Use
-r
<
number
>
resolution
example
-r
video
Code
documentation
@
giovannicimolin
valid
symbol
character
validator
swalladge
check_celery
task
feature
import
error
task
heartbeat
checks
details
]
https
//github.com/open-craft/opencraft/pull/340
issuecomment-412379171
issue
release/branch
add
conditionals
branches
production
fix
suggestion
Execute
collect_activity.yml
playbook
statistics
pcockwell
method
usage
@
pcockwell
same
comment
previous
unit
test
one
appserver
default
active
appservers
@
giovannicimolin
similar
concerns
comment
new
zone
version
right
comment
Sorry
noise
replaceafill
nit
Could
comment
ephemeral.yml
function
docstring
intention
class
attribute
important
data
distinct
actions
suggestion
Test
get_parameters
sets
suggestion
output
shape
evaluation
tape
prob
outputs
same
docstring
next
test
Just
own
understanding
specifying
coefficients
useful
observables
terms
Hamiltonian
worth
docstring
Oops
Good
find
joy
suggestion
complement
commutativity
graph
adjacency
matrix
list
suggestion
complement
anticommutativity
graph
adjacency
matrix
list
docstring
example
fallback
differences
case
@
ixfoduap
operations
PR
ones
suggestion
r
Checks
terms
Hamiltonian
products
diagonal
Pauli
gates
class
class
~.Identity
suggestion
r
rotation
angles
uniformly
Y
rotation
Add
Mottonen
line
comment
line
review
Small
comment
Operation
unitary
many
functionalities
Operation
class
worth
convention
unitarity
Operator
free
comment
details
suggestion
r
Base
class
quantum
channels
few
line
comments
suggestion
r
two-qubit
exchange
gate
math
\mathrm
ex
suggestion
init_state
array
[
int
]
length
len
wires
vector
Hartree-Fock
state
wires
suggestion
multiple
prob
outputs
autograd
pytorch
impossible
tape.jacobian
res
params
trainable
parameters
empty
list
params
_tape_
logic
TensorFlow
jacobian
method
certain
input
case
docstring
evaluation
suggestion
Test
tensorflow
interface
tape
suggestion
Test
get_parameters
sets
good
sure
same
default
mixed
array
size
docstring
QubitDevice
output
shape
only
reason
repetition
suggestion
Test
cost
correct
gradient
function
Users
decorator
private
method
unlikely
users
docstring
JacobianQNode._grad_method
😆
Jacobian
method
same
grad
method
bit
function
name
docstring
suggestion
Test
device
gates
suggestion
Test
Torch
interface
tape
test
different
case
suggestion
Test
quantum
tape
incorrect
output
dimension
evaluation
suggestion
Test
decomposition
device
supported
gate
suggestion
Test
gamma=0.1
correct
Kraus
matrices
Same
comment
|alpha
>
=
reason
t_
prefix
matrix_elements
argument
observable
function
clear
docstring
Great
@
agran2018
suggestion
r
circuit
controlled
application
unitary
suggestion
r
heuristic
VQE
ansatz
quantum
chemistry
simulations
suggestion
r
two-qubit
exchange
gate
math
\mathrm
ex
nice
description
classes
docstring
classes
__call__
method
convention
bottom
docstring
good
docstring
similar
one
other
strategy
Maybe
minor
TODO
comment
options
fields
target
other
arrays
time
axis
time
dependent
features
HybridRecurrentCell
Minor
convention
type
docstring
input
arguments
name
line
indented
description
default
folling
lines
from_hyperparameters
Estimator
classes
Predictor
general
sure
clean
solution
Forecaster
union
type
approach
need
need
noop
train
call
other
problems
assertion
rid
mypy
complaints
bottom
log
https
//ci.mxnet.io/blue/rest/organizations/jenkins/pipelines/GluonTS-py3-cpu-unittest/branches/PR-553/runs/9/nodes/42/steps/66/log/
start=0
side
effect
other
comment
False
classes
nice
docstring
Iterable
type
sequence
X
yields
sequence
Y
”
docstring
case
’
good
references
[
bibliography.rst
]
https
//github.com/awslabs/gluon-ts/blob/master/docs/bibliography.rst
Check
]
https
//github.com/awslabs/gluon-ts/blob/master/src/gluonts/model/deepar/_estimator.py
L62
DeepAR
estimator
description
PoC
comment
intention
mechanic
function
responsible
update
internal
stable
counter
Please
function
something
_update_stable_counter
comment
docstring
Pairs
cpu_target_l/cpu_target_r
mem_target_l/mem_target_r
l
r
end
range.
little
comment
algorithm
comment
posterior
code
prior
code
great
PR
please
dont
comments
major
criticism
someone
code
alive
much
possible
schools
code
place
helpful
clear
global
reused
Slight
nudge
function_1
function_2
something
more
human
recognizable
numba_func
numpy_func
something
docstring
if-else
blocks
only
sense
history
sense
someone
future
else
blocks
>
Returns
appropriate
function
numba
speedup
Numba
argument
documentation
picky
lot
keyword
arguments
dict
theyre
same
boken
mpl
bokeh
suggestion
@
pytest.mark.skipif
running_on_ci
reason=
test
bokeh
def
test_set_bokeh_circular_ticks_labels
Assert
axes
ticks
tick
labels
circular
plots
import
bokeh.plotting
bkp
test
whole
file
function
definition
suggestion
all_groups
prior
posterior
suggestion
Plot
unfitted
distributions
plots
distributions
ways
little
shorter
code
allow_none
arg
process
look
same
def
make_iterable_validator
scalar_validator
length=None
Validate
value
iterable
datatype
matplotlib
_listify_validator
function
def
validate_iterable
value
allow_none
value
isinstance
value
str
none
return
None
isinstance
value
str
allow_auto
value.lower
auto
auto
val
tuple
v.strip
[
]
v
value.split
v.strip
np.iterable
value
isinstance
value
elif
val
tuple
scalar_validator
v
v
value
length
None
val
=
length
raise
ValueError
Iterable
length
.format
length
return
val
raise
ValueError
iterable
values
valid
validate_iterable
Docstring
Indentation
docstring
i
check
separate
self._is_only_database
method
comment
docstring
port
docstring
truth
Ditto
let
comment
service
file
comment
unit
file
TODO
everything
RPMs
Thanks
comment
instances
certificate
manager
different
name
instruction
comment
similar
way
other
is_active
etcd
CA
cert
same
permissions
directory
permissive
postgres
directory
inaccessible
permissions
permissive
i
i
separate
methods
i
error
handling
same
able
docstring
example
response
big
issue
status
everything
.get
optional
great
uncertainty
data
Зачем
здесь
выводить
c
если
потом
все
будет
выведено
в
print
words
что
если
число
встречается
в
одном
столбике
дважды
matrix
=
[
[
]
]
]
]
docstring
value
change
update
TypeError
string
pythonic
ways
things
possible
startswith
call
BeginsWith
self.attribute
prefix
begins_with
documentation
function
Github
issue
openapi
spec
validator
GRR
test
package
dependency
TODO
import
top
issue
above
comments
sure
much
exceptions
underscore
prefix
internal
function
docstrings
docstring
minor
name
parameter
k
self-explanatory
code
comment
problem
function
caller
e.g
random_az_selector
region
k=2
default_value=
minor
comment
wrong
second
part
name
example
docstrings
new
function
Tox
Similar
quick
assertion
sure
wrong_os
=
os
Minor
implementation
ok
function
name
description
more
generic
To-do
items
test
generic
region
future
code
example
something
@
pytest.fixture
def
subnet_without_instance_type
vpc_stack
Subnet
functionality
invalid
subnet
AZs
user
instance
types
Hard
implementation
us-east-1
create
subnet
AZ
c5.xlarge
m6g.xlarge
Use
use1_az3
AZ
c5.xlarge
m6g.xlarge
To-do
code
arbitrary
region
arbitrary
instance
types
comment
function
cluster_enabled_value
Curious
How
class
variables
convention
response
earlier
comment
tuples
visible
sentence
test
list
nit
add
marker
integration
@
pytest.mark.integration
'dlc_major_version_label
something
accuracy
comments
first
[
comments
]
bug
[
comments
]
comment
assertions
commit
Ensure
backout
commit
ec01c146f756b74d18e4892b4fd3aecba00da93e
c
[
node
]
c
retrieved_commits
Python
assert
excluded_commit
c
[
node
]
c
retrieved_commits
excluded_commit
excluded_commits
part
schedule_job
note
comment
dupeme
bugs
case
Nit
TODO
suggestion
documentation
BubBug
http
service
platform
Bugzilla
Machine
Learning
projects
comment
rationale
Basically
suggestion
issue
comment
comment
metrics
minimum
fine
comment
optional
..
easy
index
I.e
https
//firefox-ci-tc.services.mozilla.com/api/index/v1/task/gecko.v2.autoland.latest.taskgraph.decision/artifacts/public/target-tasks.json
way
hgmo
latest
push
mozci.Push
index
path
decision
task
parameters.yml
tutorial
Horovod
GluonCV
suggestion
DALI
Pipeline
COCO
Reader
SSD
training
transform
further
review
change
Add
more
descriptions
PAM
module
CAM
module
paper
please
paper
title
link
toolchain
purpose
transparent
possible
little
modifications
consumer
makefiles
toolchain
options
behavior
CXXFLAGS
users
default
behavior
Remove
decorator
small
docstring
parameters
function
key
winreg
key
six.moves
Right
new
docstring
suggestion
condition
.join
%
s
==
%
s
%
k
v
k
v
props
suggestion
name
.join
%
s
%
v
_
v
props
comment
packages
function
returns
pool
entry
recipe
suggestion
Ninja
default
profile
build
Windows
Debug
suggestion
Ninja
default
profile
build
Windows
Release
better
idea
possible
options
@
property
methods
@
property
def
cflags
cflags
self.info
command
assign
return
self.info
[
'cflags
]
commented
lines
toolchain
thing
interface
map
<
filename
>
<
>
content
>
sense
way
print
statements
toolchain
class
toolchains
output
same
style
understanding
https
//github.com/conan-io/conan/issues/6660
issuecomment-598198641
Conan
Cygwin
platform.system
CYGWIN-xxxx
fix
PR
CRLF
>
LF
VirtualEnvGenerator
SH_FLAVOR
platform
condition
refactor
right
place
condition
Unnecessary
Linux
test
Comments
robcopy
parameters
mind
clang
gcc
pure
gcc
last
comment
@
https
//github.com/conan-io/conan/issues/2231
test
server
uploading
....
self.rootpath
need
value
other
comment
different
approaches
suggestion
Component
class
pointer
parent
rootpath
same
problem
above
least
editable
packages
layouts
property
functions
argument
get_xxxx_paths
rootpath
self.rootpath
<
>
value
components
ideas
quick
look
PR
*
*
bad
ideas
*
right
value
rootpath
Comment
way
same
tests
windows
linux
OS
Battery
tests
https
//github.com/conan-io/conan/pull/4181/files
diff-b2d334bb20f76d192915fdaa29673cb7R22
comment
open
Remove
TODO
Add
comment
process_options
something
Do
options
package
id
easier
full
JSON
following
asserts
hard
self.assertEqual
bo.items
json.loads
[
[
[
f3367e0e7d170aa12abccb175fee5f97:5ab84d6acfe1f23c4fae0ab88f26e3a396351ac9
]
]
[
[
Package_ID_unknown
]
f3367e0e7d170aa12abccb175fee5f97:5ab84d6acfe1f23c4fae0ab88f26e3a396351ac9
]
]
[
[
Package_ID_unknown
]
unchanged
PR
D'oh
function
same
test_enum_editor
name
same
difference
index
qt
editor
control
equivalent
test
docstring
better
double
backticks
code
API
documentation
tester.find_by_name
ui
.locate
locator.WidgetType.textbox
branch
👍
tests
toolkits
branch
something
new
pattern
elif
branch
helper
method
easier
framework
docstring
signature
elif
new_toolkit
implementation
easier
function.register
def
function
signature
implementation
comment
Section
applies
Nit
docstring
helpful
value
instance
traitsui.editor.Editor
code
next
person
code
target
instance
_IndexedSimpleEditor
_IndexedSimpleEditor.target_class
SimpleEditor
word
target
same
place
bit
confusing
comment
target
_IndexedEditor
_IndexedEditor.target_class
trait
class
previous
comment
warning
due
UI
Mac
issue
noticeable
wider
community
issue
warning
editor
wx
docstring
typo
Maybe
mention
Possible
test
interaction
Linux
test
run
own
likely
test
reason
console
issue
applies
Qt
is_linux
is_backend_qt4
Oops
Typo
suggestion
A
locator
nested
textbox
widget
UI
docstrings
Nit
docstring
type
registry
similar
process
sphinx.ext.autodoc
additional
process
warnings
nice
warnings.catch_warnings
warnings.filterwarnings
ignore
logging.skip_warningiserror
__import__
self.modname
NOT
output
UDF
list
output=
[
dt
]
same
output=dt
udf
decorator
Note
real
'result
inside
ScopeItem
pandas
backend
Series
DataFrame
Groupby
window
execution
line
other
backends
type
sense
Indentation
Docstring
indentation
second
line
Parameters
section
use
f-strings
comment
good
mean
reason=
xfail
result
Hard
code
description
TODO
ref
tests
comment
blank
line
cases
Callable
point
variable
Returns
documentation
subject
users
comments
Same
comment
first
geo
selection
value
tmp
kind
error
ibis.common.exceptions
style
single
line
comment
quotes
same
line
Style
single
line
comment
quotes
same
line
char
limit
Style
comment
blocks
same
line
opening
Just
other
comment
slack
DeviceAdapterError
interface
jlink
structure
version
comments
record
changes
function
core
functionality
return
type
nones
return
function
values
callbacks
callbacks
_process_scan_event
function
case
more
comment
naive
reader
rebut
minute
diverted
case
only
reason
__convicted
/
acquitted
charge.py
changes
files
side-effects
relationship
other
charge
subclasses
expunger
fact
likely
good
/bug-fixing
side-effects
more
explicit
side-effects
future
reader
PR
__convicted
/
changes
duii.py
file
full
coverage
DispositionStatus
Enum
switch/case
imitation
following
self.disposition
dismissed_type_eligibility
TypeEligibility
EligibilityStatus.NEEDS_MORE_ANALYSIS
reason='Further
Analysis
Needed
charge
Diverted
unknown_type_eligibility
=
cases
DispositionStatus.CONVICTED
TypeEligibility
EligibilityStatus.INELIGIBLE
reason='137.225
Traffic
offenses
ineligible
DispositionStatus.DISMISSED
dismissed_type_eligibility
DispositionStatus.NO_COMPLAINT
dismissed_type_eligibility
DispositionStatus.DIVERTED
DispositionStatus.UNKNOWN
unknown_type_eligibility
assert
len
cases
DispositionStatus
someone
something
DispositionStatus
Unknown
case
cases.get
self.disposition.status
unknown_type_eligibility
separate
PR
__convicted
/
changes
comments
expunger
Does
second_mrc.disposition
exist
mypy
comment
type
ignore
line
docstring
function
suggestion
self.assertIn
f
pid=
os.getpid
output
previous
comment
TODO-make
_
TODO-improve
description
mention
empty
string
Wrong
private
method
comment
Ok
docstring
future
ok
someone
optional
x
keyword
arguments
addition
features
argument
such
x
y
features
signature
function
other
functionality
thing
best
docstring
format
docstrings
new
format
correct
docstring
style
correct
docstring
style
extra
indent
docstring
final
level
AppVeyor
problem
hobbies
corpus
issue
meantime
following
@
pytest.mark.xfail
==
win32
reason=
Issue
class
DispersionPlotTests
VisualTestCase
DatasetMixin
possible
docstring
format
sure
much
effort
worries
__init__
class
KneeLocator
object
definition
description
class
parameters
numpydoc
style
documentation
RST
file
utils
API
Good
use
copy
important
need
change
thing
_penn_tag_map
_uni_tag_map
duplicate
code
tagset
only
thing
different
functions
names
dictionary
functions
ensured
same
mutable
object
e.g
same
reason
copy
goal
YB
sure
code
understandable
new
contributors
way
code
constants
list
tags
helper
function
internal
tag
constructor
functions
easy
new
tags
code
bit
readable
others
python
PENN_TAGS
=
[
noun
verb
adjective
adverb
preposition
determiner
pronoun
conjunction
infinitive
wh-
word
modal
possessive
existential
punctuation
digit
non-English
interjection
list
symbol
other
]
UNIVERSAL_TAGS
=
[
]
class
PosTagVisualizer
TextVisualizer
def
self._penn_tag_map
Returns
return
self._make_tag_map
PENN_TAGS
def
self._uni_tag_map
Returns
return
self._make_tag_map
UNIVERSAL_TAGS
def
_make_tag_map
map
tagset
counter
stack=True
map
labels
map
tagset
zeros
]
*
len
dict
zero
counter
tag
self.stack
return
label
dict
zip
tagset
zeros
label
self.labels_
return
dict
zip
tagset
zeros
Lines
150-162
interesting
solution
problem
part
speech
tags
class
novel
idea
bar
time
bar
size
pass
self._handle
methods
cumulative
issue
slight
mismatch
visual
stacks
data
user
self.pos_tag_counts_
total
chart
different
stacks
thing
conscious
computations
visualization
relevant
user
diagnostic
purposes
user
break
down
part
speech
distribution
class
e.g
stack=True
able
access
self.pos_tag_counts_
E.g
cases
stack
False
self.pos_tag_counts_
==
NN
NNP
VBG
stack
True
books
NN
NNP
VBG
cooking
NN
NNP
VBG
amount
work
fit
unique
labels
y
np.unique
None
self._
*
_tag_map
advantage
present
self._handle_
*
methods
input
correct
output
above
self.pos_tag_counts_
stack
count
last
stack
marker
small
change
big
impact
usability
visualizer
willing
changes
sense
note
docstring
self.labels_
nice
rewrite
exception
section
interesting
EAFP
easier
forgiveness
permission
LYBL
style
more
pythonic
programming
idea
stack=True
exception
type
correct
stack=False
case
line
code
stack
helper
function
things
something
important
comments
sure
contributor
future
months
time
code
safety
flaw
nothing
try/except
different
type
error
bugs
pos_tag_sum=None
pass
least
allow
None
type
errors
program
line
code
docstring
Good
test
only
thing
transform
e.g
@
pytest.mark.parametrize
n_components
def
test_transform
n_components
Test
transform
implements
Xprime
=
PCADecomposition
projection=n_components
.fit_transform
*
Xprime.shape
==
n_components
better
way
visualizers
bottom
file
old
name
backward
compatibility
Alias
PCA
PCADecomposition
=
PCA
Good
comment
docstring
something
Test
Manifold
quick
method
single
target.
Thanks
docstring
boundaries
important
end
beginning
document
comment
changes
original
implementation
docstring
input
data
list
words
list
documents
generator
list
documents
Good
point
comment
Tick
finalize
thing
comments
draw
Rank2D
change
necessary
fact
future
refactoring
lines
thank
tick
labels
couple
scenarios
reason
user
feature
case
features
first
case
self.ax.set_xticklabels
None
rotation=90
ha='left
default
case
good
test
second
case
features
unreadable
models
Rank2D
something
open
suggestions
PR
following
option
RankDBase
show_feature_names
something
labels
issue
Better
feature
name
RankD
methods
various
strategies
Strategies
first
last
feature
axes
Rank2D
Rank3D
other
feature
name
axes
certain
number
dimensions
interactive
graphs
hover
feature/pair
features
preference
YellowbrickValueError
yellowbrick.exceptions
yellowbrick
exceptions
numpy
scikit-learn
exceptions
extends
YellowbrickError
ValueError
python
try
PCADecomposition
ValueError
catches
sure
best
way
auxiliary
data
dependencies
SpaCy
critical
path
requirements
Could
_deselect_all
method
comment
everything
code
comment
statement
EDL
gaps
record
timeline
input_object
feels
abstract/ambiguous
Composition
Timeline
general
term
documentation
Could
documentation
types_to_prune
types_to_filter
clear
python
classes
typical
thing
something
Transition
new
Track
Transitions
Same
comments
Same
comment
configuration
options
property
name
meaningful
some_request.request
property
returns
property
public
reason
Celery
users
last
thing
docstring
property
@
thedrow
part
bit
obscure
suggestion
key
=
already_stored_data
=
key
'old_value
=
x._connection.get
=
MagicMock
return_value=already_stored_data
updated_data
=
key
'new_value
x.set
key
updated_data
[
'value
]
x._connection.get.assert_called_once_with
key
Dictionary
next
assertion
assert
get.return_value
==
updated_data
x._connection.save.assert_called_with
updated_data
sub-device
class
interpretation
non-true
value
device-specific
comment
devices
previous
comment
Tuple
need
docstring
pass
parameters
implementation
Could
example
response
class
docstring
lambda
expression
def
many
blank
lines
earlier
comment
user
resources
available
flag
inventory
list_resources
list
resources
super
helpful
documentation
flag
inventory_loader.py
keys
REQUIREMENTS_MAP
TODO
nit
please
newline
class
See
comment
specific
message
unsupported
api
comment
requested
algorithm
nit
same
variable
list
string
*
list
list
*
rules
comment
sure
sort_rules
case
comma
'IPProtocol
sort_rules
None
empty
string
key
nit
comment
Hm
possible
dict
comment
dicts
non-deterministic
printing
issue
super
knowledgeable
network
interfaces
GCP
contents
dicts
network
interface
properties
InstanceNetworkInterface
dicts
uniqueness
properties
hash
@
advice
nit
comment
s/
/
please
Thanks
mistake
issue
few
comments
*
list
scanner_index_id
parameter
scanner_index_id
violations
inventory_index_id
scanner_index_id
last
SUCCESS
ScannerIndex
table
found
scanner_index_id
violations
last
scanner_index_id
*
doc
ones
proper
Google
style
docs
single
scanner
pipelines
moment
ok
sys.exit
future
TODO
error
nit
nice
args
description
e.g
information
application
Args
project_id
id
project.
better
job
documentation
self._execute
request
self.rate_limiter
base
class
request
rate
limiter
Example
https
//github.com/GoogleCloudPlatform/forseti-security/blob/master/google/cloud/security/common/gcp_api/cloud_resource_manager.py
L69
other
changes
new
line
Args
section
method
doc
summary
line
indentation
Args
section
spaces
class
ForsetiSystemDao
dao.Dao
Data
access
object
DAO
Forseti
system
management
Args
global_configs
dict
Global
config
db_name
TODO
care
nit
method
doc
consistency
style
Helper
list
seq
list
size
Integer
desired
chunk
size
Returns
tuple
chunked
seq.
hard
state
config_integration
config_integration.trace_integrations
possible
hard
comment
return
statement
values
future
return
purposes
nit
Punctuation
capitalization
comments
cleaner
elif
config
immutable
TankCoreUpdater.UPDATE_BLOCKED_BY_CONFIG
old
code
FIXME
Devs
clients
import
LogManager
everything
same
comment
Suggest
[
urlparse
]
https
//docs.python.org/2/library/urlparse.html
library
url
=
file
///path/to/some/file.txt
results
=
urlparse
url
ParseResult
scheme='file
path='/path/to/some/file.txt
params=
query=
results.scheme
file
paths.append
urllib.unquote
results.path
docstring
i
hook
methods
great
docstring
user
useful
simple
use
case
hooks
useful
comments
helpful
concrete
example
something
follwing
main
docstring
params
cases
target
content
url
beforehand
example
url
https
//my-site.shotgunstudio.com/thumbnail/full/Asset/1227
https
//some-site/path/to/a/thumbnail.png
such
cases
use_url_extension
parameter
method
file
extension
url
filename
location
parameter
urls
following
results
location=
/path/to/file
use_url_extension=False
/path/to/file
location=
/path/to/file
use_url_extension=True
/path/to/file.png
point
blocker
tear-down
code
commented-out
reminder/helper
docstring
variables
s
pc
something
descriptive
great
fw_name
fw_inst_name
name
similar
way
more
code
tweak
variable
names
comments
source
param
docstring
property
returns
part
docstring
comment
Manne
Thanks
comment
likely
versions
PySide
issue
Stale
comment
users
optional
name
use
piglow
default
binary.threshold
sensor
test
implementation
test
full
hass
environment
mind
@
callback
decorator
tests
true
appropriate
solution
Async
docstring
side
note
pylintrc
travis
designate
docstrings
public
methods
ease
contribution
appropriate
modification
files
part
PR
order
methods
documentation
feedback
hope
best
way
possible
function
documentation
Add
decorator
@
callback
async
loop
Async
documentation
matters
return
value
False
turn
return
value
False
Stale
comment
wrong
place
lines
official
integration
outdated
link
comment
headers
line
characters
Same
comment
availability
mixin
same
MQTT
platforms
more
clear
last
comment
full
exception
exc_info=ex
logs
lines
side
effects
entity
state
properties
Please
logging
Please
f-strings
str.format
undefined
name
'Channels
docstring
line
characters
Please
line
characters
clause
something
something
Docstring
Sorry
earlier
least
spaces
inline
comment
<
br
>
inline
comment
url
docstring
Just
first
line
code
references
setup
log
message
Just
Setup
configuration
line
characters
line
characters
state
update
callback
information
available
vol.Required
vol.Optional
easier
documentation
sync
api
key
valid
error
return
documentation
host
IP
address
Most
users
own
DNS
server
home
traceback
lookup
Update
docstring
coroutine
Stale
efficient
separate
new
method
argument
True
sure
update
state
new
method
state
update
callback
async_added_to_hass
def
update_callback
state
update
self.schedule_update_ha_state
True
mock
states
services
Let
use
👍
[
docs
]
https
//docs.pytest.org/en/latest/parametrize.html
way
test
Turn
supported
domains
import
pytest
@
asyncio.coroutine
@
pytest.mark.parametrize
domain
[
'light
]
test_api_turn_off
hass
domain
…
config
entry
component
config
entry
JSON
client
restful
whole
test
class
test
function
root
level
Use
hass
parameter
test
function
new
test
instance
def
test_setup_component
Initialize
demo
platform
mailbox
component
config
=
mailbox.DOMAIN
assert_setup_component
mailbox.DOMAIN
setup_component
hass
mailbox.DOMAIN
config
new
instance
Freepybox
update
init
instance
attribute
docstring
Docstring
comment
self.vacuum.connect
I/O
handler
creation
job
*
*
better
*
*
handler
connect
setup
initiated
handler
VacuumDevice
python
vacuum
=
Roomba
address=host
blid=username
password=password
cert_name=certificate
continuous=continuous
_LOGGER.info
Initializing
connection
host
%
s
username
%
s
host
username
I/O
yield
hass.async_add_job
vacuum.connect
need
hass
object
auth
option
handler
roomba
=
RoombaVacuum
vacuum
odd
reason
previous
comment
attributes
matter
_is_on
state
data_out
=
ATTR_FORECAST_TIME
data_in.get
DATETIME
ATTR_FORECAST_CONDITION
cond
[
condcode
]
Stale
docstring
@
asyncio.coroutine
def
async_get_media_image
Fetch
media
image
current
playing
image
new
method
parent
method
signature
yield
asyncio
idiom
comment
@
asyncio.coroutine
unexpected
indentation
line
characters
Sorry
comment
wrong
line
state.state
STATE_OPEN
STATE_CLOSED
values
truthy
position
comment
reason
prefix
]
https
//github.com/home-assistant/home-assistant-polymer/blob/master/src/util/hass-util.html
L37
identify
filter
specific
attributes
table
battery
level
other
entity
better
approach
@
pvizeli
comment
there
documentation
behavior
docstring
config
flow
entry
end
config
flow
TODO
issues
code
connect/send
other
comment
DOMAIN
friendly
names
underscore
least
spaces
inline
comment
<
br
>
inline
comment
<
br
>
line
characters
comment
docstring
[
PEP257
]
https
//home-assistant.io/developers/development_guidelines/
Stale
docstring
much
protocol
specific
hardcoded
constants
something
OK
python
yield
self._device.color.move_to_color_temp
temperature
duration
API
cluster
better
way
fine
definitions
move_to_color
lib
Stale
comment
block
good
PR
comment
sense
more
comment
similar
comments
device
map
comments
comments
device
map
access
Comments
Stale
docstring
Docstring
Test
removal
discovered
vacuum
Test
update
discovered
vacuum
filter
+
lambda
url
docstring
first
line
[
link
]
https
//developers.home-assistant.io/docs/en/development_guidelines.html
file-headers
documentation
return
False
new
documentation
third-party
imports
inside
functions
re
added
efficiency
example
Alexa
registry
__init__.py
homeassistant.util.decorator
import
Registry
TYPES
=
Registry
cover.py
import
TYPES
@
TYPES.register
'Cover
class
Window
HomeAccessory
…
cover
file
setup
TYPES
constant
comment
specific
exception
Remove
broad
exceptions
specific
exceptions
None
FortiOS
API
None
debug
message
same
docstring
current_position
'requests
unused
Can
SENSOR_TYPES
lambda
extract
info
lambda
item
item
mnt_point
reason
password
optional
somebody
router
password
HA
call
monitor
phone
book
lookup
documentation
phone
book
support
username/password
default
values
right
fact
copy
paste
error
same
Fritz
device
tracker
platform
[
requests
documentation
]
http
//docs.python-requests.org/en/master/user/quickstart/
custom-headers
[
own
]
https
//home-assistant.io/developers/rest_api/
block
comment
Stale
REMOTE_KEYS
proposes
keys
comments
py
MEDIA_PLAYER_KEYS
=
Rewind
FastForward
SERVICE_MEDIA_PLAYER_PAUSE
Just
support
flag
volume
comments
current
code
feature_list
first
comment
block
most
unnecessary
callback
method
first
comment
Please
new
async
/
await
syntax
few
PRs
comments
one
http
//stackabuse.com/python-async-await-tutorial/
simple
tutorial
new
component
sure
ready
possible
least
remove
todo
comment
todo
👍
Just
style
comment
weird
code
'devices
CONF_DEVICES
IMO
Home
Assistant
lenient
config
few
places
single-element
dictionaries
lists
example
configuration
devices
id
something
switches
pin
name
Switch1
python
vol.Optional
CONF_SWITCHES
vol.All
config_validation.ensure_list
[
_SWITCH_SCHEMA
]
homeassistant.helpers.config_validation
cv
shorthand
python
homeassistant.helpers
import
config_validation
cv
favor
solution
comment
guard
clause
error
values
error
update
method
sensor
client
keyword
argument
positional
argument
None
comment
url
docstring
Just
first
line
platform
schema
PLATFORM_SCHEMA
=
PLATFORM_SCHEMA.extend
vol.Optional
CONF_PROFILES
default=
[
]
vol.All
cv.ensure_list
[
vol.In
SUPPORTED_PROFILES
]
async_get_engine
async
def
async_get_engine
hass
config
return
GoogleCloudTTSProvider
config.get
CONF_PROFILES
Default
option
config
option
def
default_options
return
CONF_PROFILES
self._profiles
async
def
async_get_tts_audio
message
language
options=None
=
options.get
CONF_PROFILES
option
default
option
witch
equal
config
option
None
comment
future
reference
IGNORE_REQ
=
<
=1
Windows
requirement
check_config
Stale
docstring
Sorry
comment
voluptuous
Please
other
comments
Stale
Please
comment
call
pointless
end-to-end
other
tests
tests
homekit
bridge
new
accessories
runtime
c
incrementing
entity
map
refreshing
entities
superfluous
i
test
impact
coverage
terms
Done
User
latitude
longitude
component
configs
home
latitude
longitude
Documentation
home-assistant/home-assistant.github.io
Broad
action
exception
bad
combo
Preferably
specific
error
line
characters
Stale
comment
None
double
Double
underscore
attribute
names
class
conflicts
attribute
names
classes
case
Just
_
comment
Sorry
thoughts
first
comments
direction
prefix
Stale
docstring
comment
Stale
comment
block
comment
blank
lines
Please
comment
Support
iTach
IR
Devices
more
details
platform
refer
documentation
https
//home-assistant.io/components/remote.itach/
Details
documentation
entity
ID
list
entity_ids
needs
union
extract_entities
results
comment
list
entity_ids
templates
python
entity_ids
device_config.get
CONF_ENTITY_ID
template_entity_ids
comment
block
comment
<
br
>
line
characters
comment
<
br
>
line
characters
Stale
Optional
[
AbstractOAuth2Implementation
]
type
ignore
python
lazy
object
variable
initializing
correct
type
python
comments
code
Use
<
comment
>
let
guard
clause
python
interval
=
request.query.get
'interval
interval
None
await
camera.handle_async_mjpeg_stream
request
return
try
interval
=
float
interval
line
characters
kwargs
args
short
comment
readable
anyone
create
constants
turn_on
turn_off
Common
practice
device_state_attributes
property
simple
–
e.g
@
property
def
device_state_attributes
state
attributes
return
logic
self._attrs
update
way
property
easier
Must
something
Set
Docstrings
[
PEP257
]
https
//www.python.org/dev/peps/pep-0257/
validation
line
characters
Example
configuration
documentation
Stale
Simple
stylistic
suggestion
pleasant
=
Address
'description
'Description
'Model
'Category
'Subcategory
'Firmware
'Product
Key
same
functionality
attributekeys
last
comment
let
👍
suggestion
Test
notify
works
url
docstring
Just
first
line
Add
default=
Xiaomi
TV
check
line
Style-wise
boolean
*
bit
*
bad
async_setup_platform
s
booleans
course
_async_setup_platform
proxy
async_setup_platform
good
syntax
same
style
old
way
bit
nicer
async
def
_async_setup_platform
hass
HomeAssistantType
config
ConfigType
async_add_entities
discovery_info
info.friendly_name
None
HTTP
dial
able
remove_handler
PlatformNotReady
async
def
async_setup_entry
hass
config_entry
async_add_entities
=
await
asyncio.wait
[
_async_setup_platform
hass
cfg
async_add_entities
None
cfg
config
]
timeout=10
[
__doc__
]
https
//docs.python.org/3.5/library/collections.html
collections.somenamedtuple._fields
field
named
tuple
Other
instances
namedtuple
home-assistant
comment
inclusive
top
file
docstring
test
[
PEP257
]
https
//www.python.org/dev/peps/pep-0257/
id16
place
path
place
event
helpers
Stale
docstring
./segment/
.ts
relative
playlist
url
Stale
comment
line
characters
comment
branch
code
someone
future
heck
comment
Same
Nothing
return
value
Just
return
comment
block
comment
registries
time
sensitive
config
entry
remove
block
comment
requirements
pypi
line
characters
extra
state
update
entity
default
state
update
end
service
call
link
docstring
Just
first
line
connection
object
async_step_zeroconf
continuation
line
under-indented
visual
indent
documentation
comment
comment
light
init
update
controller
Please
use
loader
access
other
component
https
//github.com/home-assistant/home-assistant/blob/dev/homeassistant/helpers/entity_component.py
L221
Sounds
good
thanks
bit
bad
TODO
list
Done
something
sys.modules
patch
configure
patch
import
wrapt
try
..
python
pytest.raises
pynamodb.exceptions.ScanError
self.conn.scan
OtherTable
=
self.get_spans
spans
=
spans
]
assert
span.name
==
pynamodb.command
rest
assertions
exception
test
important
exception
test
anything
e.g
algoliasearch.page
algoliasearch.query.page
[
self.assert_structure
]
https
//github.com/DataDog/dd-trace-py/blob/4313f388383b90ccf2bcbca9d7ef1c400c827ece/tests/utils/span.py
L367
pretty
cool
python
self.index.search
....
self.assert_span_count
self.assert_structure
dict
service='algoliasearch
name='algoliasearch.search
span_type=SEARCH_SPAN_TYPE
error=0
'firstname
lastname
'number_of_hits
extra
meta
meta
/
metrics
python
self.assert_structure
meta
metrics
root
=
self.get_root_span
Assert
attributes
meta
root.assert_meta
'firstname
lastname
root.assert_metrics
new
patterns
test
suite
own
test
self.reset
case
generic
enabled
/
flag
monkey
stdlib
obvious
reasons
many
different
ways
default
interesting
automatic
full
ON
/
full
OFF
functionality
better
bit
generic
helper
function
Context
Task
_create_task
helper
function
run_in_executor
[
ref
]
]
explicit
context
new
task
python
ddtrace.contrib.asyncio
import
helpers
context
helpers.create_task
coro
context
loop.create_task
coro
main
reason
cases
automatic
propagation
new
tasks
e.g
long-running
Task
minutes
stats
users
requests
other
hand
helper
enough
BaseEventLoop.create_task
someone
default
reasonable
function
helper
loop.create_task
code
base
_create_task
first
building
block
anyone
Context
default
moment
more
generic
helper
patterns
]
https
//github.com/thehesiod/dd-trace-py/blob/b9a41ec6cd7f8636cdbddb2134eaab88604f085e/ddtrace/contrib/asyncio/helpers.py
L36
suggestion
..
py
data
ddtrace.config.starlette
]
Might
worth
environment
variable
other
comments
rid
lessEqual
constraints
whitespace
https
//github.com/facebookresearch/ParlAI/blob/b412c4d88298a7c531eaab9b5e105ab5588f3a87/parlai/core/torch_agent.py
L1468-L1474
list
comprehensive
_build_candidates
function
docstring
TRA
general
thing
\
lines
wrap
parentheses
lines
case
comment
question
[
'turn_id
]
context
first
turn
question_txt
=
story
+
'\\n
+
question
[
'input_text
]
question_txt
=
question
[
'input_text
]
more
pythonic
statement
block
python
open
outpath
dtype
+
'.txt
w
fout
use
fout
fout
'test
maps
datatype
=
dt
]
==
else
same
above
comment
datatype
python
Same
default
teacher
__SILENCE__
entries
first
speaker
first
utterance
skipped.
violation
type
comment
closest
useful
note
docstring
descriptions
violation
type
sync
violation
comment
please
comments
helpful
fairseq
implementation
unpickling
error
own
exception
Did
docstring
classes
docstring
data
pre-shuffled
comment
helper
module
Shared
good
choice
accident
Nit
newline
multiline
docstrings
nit
docstring
report
docstring
multiprocess_eval
main
module
training
Which
comment
-1
Prefer
url
=
/
url
=
//
/
+
fname
noqa
E501
lot
indentation
sense
out
def
_handle_paragraph
paragraph
output
=
[
]
story
=
return
.join
output
python
line
data
paragraph
line
[
'paragraphs
]
fout.write
_handle_paragraph
paragraph
Super
nitty
doc
comment
extended
reasoning
little
unclear
intended
effect
upgrade_opts
implies
new
models
new
default
requirement
upgrade_opts
older
models
behavior
old
models
consistent
upgrade_opts
new
option
present
loaded
opts.
backwards
compatibility
term
works
way
lol
please
document
weirdness
class
level
nit
update
bit
confusing
entire
model
note
docstring
function
returns
AFAIK
InteractiveWorld
interactive
script
task
module
jaseweston
comment
same
cents
>
dollars
change
amount
var
dollars
dollar_amount
TODO
worlds
length
..
TODO
error
fixed
candidates
comment
docstring
comment/docstring
available
data
besides
dialogue
anything
dialogue
dataset
lot
more
substance
message
log
general
TODO
aware
later
half
DictionaryAgent
truly
abstract
current
DA
ParlaiDictionaryAgent
years
grossness
brief
sentences
high
level
dummy
encoder
*
helpful
top
right
way
i
class
TestParlaiInternal
unittest.TestCase
def
setUp
copying
tearDown
rm'ing
def
test_load_internal_agent
setup
everything
test_
yml
several
PR
comments
@
pedrobaeza
reference
matter
comment
https
//github.com/Azure/sonic-mgmt/pull/2193
s
end
get_critical_group_and_process_list
empty
line
following
comment
NotImplementedError
tests
API
result
HTTP
server
fix
[
]
https
//github.com/Azure/sonic-mgmt/pull/1822
HTTP
server
NotImplementedError
None
value
None
comment
comment
NotImplementedError
reference
script
module
example
documentation
result
empty
list
[
]
case
result
None
test
case
comparison
result
=
[
]
result
Just
suggestion
Test
syslog
server
>
Test
syslog
message
server
yield
return
test_message
result
uniform
way
skip
similiar
pr
https
//github.com/Azure/sonic-mgmt/pull/1468
@
wangxin
@
yxieca
comments
prev
diff
message
outdate
extra
general
best
practice
class
docstrings
one-line
summary
more
detailed
description
AdvancedReboot
information
Etc
comment
log
message
output
logging
level
DEBUG
level
DEBUG
previous
call
shell
module
module
execution
result
logs
level
Similar
comments
other
logger.debug
script
output
top
different
different
platforms
dx010-4
output
root
@
str-dx010-acs-4
~
top
-d
-n
-b
top
users
load
average
Tasks
total
running
sleeping
zombie
%
Cpu
s
sy
ni
id
wa
hi
si
st
MiB
Mem
total
free
buff/cache
MiB
Swap
total
free
avail
Mem
Mem
*
*
MiB
*
*
*
*
KiB
*
*
other
method
mem
usage
TODO
TODO
above
comment
message
more
generic
chassis
interfaces
data
Suggest
lines
platform.json
available
platform
DUT
facts
complete
platform
information
Addressed
review
comments
move
new
comment
style
minor
more
comment
block
log
message
something
specific
IP
Installing
explicit
route
mgmt
route
VIP
startswith
strip
startswith
strip
suggestion
Base
class
DHCP
packet
test
test
DHCP
packets
T1
device
one-liner
easier
opinion
suggestion
=
textwrap.dedent
https
//access.redhat.com/containers/
tab=tags
/registry.access.redhat.com/ubi8-minimal
LABEL
com.redhat.index.delivery.version=
v4.5
operator_dir.join
previous
comment
check
test
Typo
double
variable
names
RST
docstring
suggestion
IIBError
resolved_distribution_scope
lesser
scope
SQLAlchemy
smart
changes
database
same
value
statement
comment
docstring
intuitive
first
method
jsonify
class
cool
example
format
docstring
ditto
jsonify
logger
please
Guess
game
def
add_new_tags
tags=
[
]
tags.append
'blurgh
tags.append
'fire
return
tags
=
add_new_tags
tags_2
=
add_new_tags
tags_3
=
add_new_tags
print
tags_3
]
output
chunk
code
[
Answer
Explanation
]
http
//python-guide-pt-br.readthedocs.io/en/latest/writing/gotchas/
recall_weight
purpose
comment
FIXME
configurable
constant
Same
comment
right
docs
list
entries
database
mypy
redundancy
auto-documentation
tools
n
=
tuple
O
right
speed
differences
%
timeit
bytecode
real
differences
tuple
native
LOAD_CONST
'svd
'als
LOAD_CONST
frozenset
'als
size
memory
frozenset
bytes
computer
two-element
tuple
bytes
computer
better
enum
integer
values
tuple
set
fact
difference
day
hell
Mangaki
memory
consumption
future
users
hardware
[
Dropbox
]
blog.kevmod.com/2017/02/personal-thoughts-about-pystons-outcome/
own
JIT
PyPy
existence
Right
comment
Random
rants
young
student
please
tuples
JJV
start_date
lot
codebase
let
jut
comment
field
bit
shame
logic
comment
form
JSON
object
something
next
person
code
@
MalekMFS
imports
code
share
inference
auto
annotation
app
IEPlugin
device=
CPU
IE_PLUGINS_PATH
]
self._check_instruction
plugin.add_cpu_extension
IE_PLUGINS_PATH
libcpu_extension_avx2.so
elif
self._check_instruction
plugin.add_cpu_extension
IE_PLUGINS_PATH
libcpu_extension_sse4.so
Exception
Inference
engine
support
avx2
sse4
versions
OpenCV
@
azhavoro
optimal
algorithm
Hi
@
jrjbertram
comments
code
width
height
None
sense
code
loop
same
values
small
optimization
comment
DHCP
Just
case
future
env
MTU=1400
problem
space
comment.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Argument
position
keyword
constructor
call
]
https
//app.codacy.com/app/tensorlayer/tensorlayer/pullRequest
prid=1460721
n_filter
bitW
bitA
comment
Typo
comment
embedding_layer
tl.Layer
layer
e.g
tl.layers.Embedding
documentation
suggestion
Performs
users
specific
group
specific
scheduled
activity
suggestion
Everyone
one
self.assertEqual
eligible
users
poll
.format
%
comment
production
many
activities
multiple
blocks
week
columns
blocks
nice
docstring
Ok
comment
idea
original
story
much
additional
check
random
Artifact
db
checksums
present
ALLOWED_CONTENT_CHECKSUMS
user
variable
post-content-being-saved
ImproperlyConfigured
set
set
attributes
Artifact
SImilar
comment
suggestion
Data
module
pre-calculated
datasets
GBS
simulations
Note
changes
bit
module
]
https
//strawberryfields
module-strawberryfields.apps.data
suggestion
Test
features
matrix
data
dataset
correct
dimensions
fine
check
🙂
e.g.
pylint
disable=too-many-instance-attributes
default
good
check
sure
class
hard
fast
rule
code
cleaner/easier
developers
more
attributes
fine
disable
Nitpick
nice
docstrings
more
info
good
small
docstring
fixture
use
suggestion
Mock
function
same
time
users
variable
name
accessible
acceptable
q
documentation
Note
'pure
blackbird
printed
regref
names
q0
q1
Might
worth
same
SF
delta
rid
sentence
normal
modes
Same
comments
apply
suggestion
indentation
couple
other
comments
shape
code
*
necessary
'flat
sequence
type
Sequence
suggestion
product
samples
modes
Args
samples
ndarray
photon
number
samples
shape
shots
modes
modes
Sequence
indices
modes
expectation
value
Note
special
dunder
methods
docstring
something
__getindex__
negative
integers
inherited
method
Python
parent
methods
docstring
Minor
suggestion
suggestion
Makes
instance
class
callable
function
suggestion
def
test_exp_features_shape
dim
m
weights
jacobian
correct
shape
range
different
sizes
input
Just
bit
style
other
test
methods
modes
*
ordered
needs
other
docstrings
sentence
suggestion
returned
state
requested
modes
order
i.e.
suggestion
r
Calculate
kernel
matrix
set
input
points
suggestion
r
correctness
kernel
matrix
set
point
coordinates
suggestion
r
average
number
photons
math
\text
data
suggestion
r
value
Kullback-Liebler
divergence
cost
function
suggestion
r
gradient
Kullback-Liebler
cost
function
respect
right
docstring
Might
Kwargs
Returns
subsection
docstring
x
ranges
variable
docstring
bit
cleaner
later
PR
suggestion
gate_parameters
gate_name
]
=
Ranges
*
range_list
Minor
suggestion
bit
strange
__init__
certain
arguments
way
layout
modes
compiler
gate_parameters
separate
method
__init__
suggestion
reference/drawing.html
module-networkx.drawing.layout
>
fault
previous
suggestion
suggestion
NetworkX
<
https
//networkx.github.io/documentation/latest/
final
version
grin
edge_coords
private
public
specific
users
private
case
autosummary
suggestion
coordinates
graph
nodes
input
graph
layout
good
plotting
dependency
SF
suggestion
Converts
graph
nodes
purposes
suggestion
dict
[
str
list
]
lists
x
y
coordinates
keys
dictionary
suggestion
coordinates
graph
input
graph
layout
suggestion
<
https
//plot.ly/
>
__
plot
input
graph
little
scope
nice
method
programs
equal
syntax
blackbird
minor
comment
thing
more
explicit
last
command
sure
right
example
something
python
assert
isinstance
p_func.circuit
[
-1
]
.op
sf.ops.MeasureThreshold
case
p
suggestion
r
Generate
samples
vibrational
quantum
dynamics
input
Fock
state
clear
equation
different
function
[
image
]
https
//user-images.githubusercontent.com/49409390/86519291-5c407c80-be07-11ea-83bf-62cfc20423c4.png
order
different
m
term
comment
matrix
inversion
large
matrices
numerical
errors
problem
diagonal
matrices
good
possibility
l0_inv
need
matrix
inversion
same
comment
d
+1
proper
documentation
Per
docstring
dictionary
small
comment
fact
instance
Stochastic
calls
Stochastic.evaluate
Minor
suggestion
applicable
further
docstrings
suggestion
Test
evaluate
method
expected
value
VGBS
class
suggestion
r
file
tfbackend/ops.py
import
pytest
import
numpy
np
tf
=
pytest.importorskip
tensorflow
suggestion
pylint
disable=expression-not-assigned
following
lines
codefactor/pylint
problems
https
//www.codefactor.io/repository/github/xanaduai/strawberryfields/pull/390
anything
wrong
style
circuits
SF
disable
pylint
warning
special
cases
pylint
disable=error-to-disable
Similar
comment
mc
non
mc
similar
true
suggestion
r
sf
operation
Doktorov
operator
learning
process
Dunders
docstrings
suggestion
n_max
float
Maximum
number
photons
sample
number
suggestion
Base
name
files
sample
data
./data/
directory
Samples
convention
short
summary
docstring
remainder
docstring
easier
above
module
attribute
documentation
times
documentation
risk
place
__init__
docstring
instance
Done
indent
default
question
[
Annotation
2019-09-03
]
https
//user-images.githubusercontent.com/49409390/64208457-d82b0a80-ce6c-11e9-9592-6ca29a47493c.png
default
top
enough
worth
user
defaults
parameters
section
defaults
apps
documentation
need
ixfoduap
suggestion
iterations
int
number
steps
algorithm
default
value
function
signature
Sphinx
docstring
type
docstring
param
str
dirname
newline
docstring
description
params
code
indent
spaces
contiguous
comments
next
line
spaces
first
line
param
str
foo
comment
comment
proper
documentation
syntax
[
str
]
clear
=None
redundant
description
clear
Similar
next
comment
better
use
brackets
\
new
line
return
incorrect
documentation
Fix
comments
consistent
Write
time
batch
return
Never
assign
attributes
unexpected
behavior
bugs
case
instance
..
tuple
top
first
logic
single
branch
other
context_window
logic
ctx_left
/
ctx_right
logic
_get_context_window_left_right
attributes
suggestion
self.command_group
'datadog
link
is_experimental=True
g
operations_tmpl
right
CliCommandType
datadog_custom
__init__.py
https
//github.com/Azure/azure-cli-extensions/blob/676abc83e6205e6232e8c223ea515b349a3bfbbc/src/datadog/azext_datadog/__init__.py
L24-L28
delete
actual
success
u
comment
available
value
get_enum_type
load_arguments
better
single
quotation
new
files
*
args
*
*
comment
original
image
upside-down
line
helpful
code
full
docstrings
methods
parent
class
docstring
equivalent
please
documentation
items
numpy
arrays
allow
dicts
garage.envs.util
import
flat_dim
=
bounds
env.action_space
sorry
previous
comment
unclear
arg
paths
convention
codebase
function
paths_to_tensors
input/output
shape
documentation
please
canonical
imports
garage.envs
import
HalfCheetahVelEnv
class
comprehensive
documentation
input/output
types
methods
properties
_build
interface
_build
implementations
number
positional
args
*
inputs
kwargs
code
def
_build
dist
user
Python
error
equivalent
assert
nonlinearities
constructor
pickleable
pickleable
strings
arguments
strings
utility
own
def
tf_from_string
==
'tanh
return
tf.nn.tanh
==
'tf.nn.softmax
return
tf.nn.softmax
NotImplementedError
part
pickling
code
pickler
things
tf.nn.tanh
pickled
dict
arguments
docstring
compliant
i.e
bullets
types
shape
documentation
EnvSpec
use
shape
documentation
EnvSpec
i
name
API
Worker
broadcast
broadcast_to_n_workers
update
comments
CONTRIBUTING.md
extra
effort
formatting
documentation
generator
fixed-width
style
args
something
fixed
width
e.g
shapes
backticks
markdown
Docstring
mismatch
properties
property
attribute
e.g
@
property
def
terminal
bool
TimeStep
termination
condition
return
self.step_type
StepType.TERMINAL
descriptive
comments
Consult
Chang
Keren
advice
purpose
class
document
constructor
class
please
docstring
new
format
please
import
packages
stdlib
easier
dependencies
form
e.g
import
abc
class
Sampler
abc.ABC
etc
argument
documentation
advantage
calculation
function
subtle
formulation
easy
wrong
day
Please
block
comment
method
nice
below
examples
users
argument
yapf
disable
comment
code
action
actions
comment
early
suggestion
list
block_ids
list_item_id
list_name
same
comment
open
docstring
first
line
documentation
and/or
comments
function
lot
logic
hard
helpful
multiple
returns
statements
easier
different
cases
comment
logic
suggestion
FCIDump
package
doc
guidelines
whitespaces
full
sentences
least
pseudo-sentences
period
end
suggestion
FCIDump
dumper
suggestion
QMolecule
instance
FCIDump
file
documentation
additional
type
specification
suggestion
QMolecule
instance
minimal
set
data
suggestion
FCIDump
Driver
clear
function
name
initializer
slightly_smiling_face
suggestion
linebreak
suggestion
Python
implementation
FCIDump
driver
suggestion
References
Knowles1989
Peter
J.
Knowles
Nicholas
C.
Handy
A
determinant
full
configuration
interaction
program
Computer
Physics
Communications
Volume
Issue
Pages
ISSN
https
//doi.org/10.1016/0010-4655
specific
suggestion
QiskitChemistryError
fcidump_input
str.
super
.__init__
isinstance
fcidump_input
str
raise
QiskitChemistryError
FCI
dump
input
str
.format
fcidump_input
suggestion
FCIDump
parser
suggestion
Almost
Equal
suggestion
Almost
Equal
new
component
module
docs
circuit
entry
ml
init
file
new
submodule
docstring
entry
RawFeatureVector
class
table
form
class
library
heading
qiskit.ml.circuit.rst
stub
file
apidocs
others
better
description
documentation
user
better
idea
class
prior
class
text
describing
things
Similar
comment
earlier
See
comment
similar
code
suggestion
difficult
example
Credit
Risk
Analysis
docstring
implementation
bit
tricky
__getitem__
OptimizationResult
simpler
Users
access
value
variables
OptimizationResult.x
[
i
i
integer
OptimizationResult.variables_dict
[
name
]
name
string
@
adekusar-drl
method
__getitem__
return
type
OperatorBase
right
string
string
forward
ref
ref
location
same
comment
couple
other
modules
string
suggestion
sequence
Pauli
matrices
suggestion
equivalent
state
function
type
DictStateFn
docstrings
docstrings
updated
👍
IsingToQP
QPToIsing
warning
code
past
visible
docs
RY
var
form
class
RY
VariationalForm
r
RY
Variational
Form
RY
trial
wave
function
layers
math
rotations
entanglements
DEPRECATED
start
main
docstring
part
single
line
description
tables
new
use
Same
comment
None
feature
map
i.e
valid
value
Similar
comment
Is
reason
isinstance
expected
outcome
opflow
operator
part
base
class
interface
docstring
base
class
self
implementation
present
abstract
error
name
more
update_masses
name
molecule
update_from_molecule
felt
more
future
proof
other
items
future
return
docstring
invalid
suggestion
Checks
integer
slack
mode
problem
self._src
=
None
type
Optional
[
QuadraticProgram
]
self._dst
=
None
type
Optional
[
QuadraticProgram
]
suggestion
self._src
=
None
type
Optional
[
QuadraticProgram
]
self._dst
=
None
type
Optional
[
QuadraticProgram
]
suggestion
Exception
errors
Optional
Missing
Libraries
need
comments
opensensus.stats
import
stats
opencensus.stats.stats.stats.stats_recorder
typo
many
stats
Indent
argument
better
testability
def
quickstart
project_id
member
TODOs
__name__
==
clause
little
confused
line
metadata
case
test
comment
helpful
Please
something
following
format
TODO
developer
topic
subscription
dead
letter
policy
project_id
your-project-id
way
developer
line
value
variables
specific
format
helpful
string
name
info_type
https
//github.com/GoogleCloudPlatform/python-docs-samples/blob/88ca408d9575de50cdc37546253ca23ae794bafa/dlp/inspect_content.py
L40-L41
suggestion
item
string
text
info_types
list
strings
info
types
full
list
info
type
categories
API
Minor
nit
docstrings
inconsistent
terms
spacing/line
breaks
functions
Nit
memcache
comments
Thoughts
text
target_language
below
response
=
client.translate_text
parent=parent
contents=
[
Hello
world
]
mime_type=
text/plain
mime
types
text/plain
text/html
source_language_code=
en-US
target_language_code=
fr
online_one_request
io
function
definition
code
snippet
documentation
page
import
nit
mime_type
variable
input_config
=
vision.types.InputConfig
content=content
mime_type='application/pdf
Other
mime_types
image/tiff
comment
stale
stale
comment
Does
mutate_rows
anything
printed
value
response
problem
comment
errors
-1
line
comment
keyword
arguments
optional
purpose
part
couple
comments
functionality
function
comment
Comment
suggestion
db_socket_addr
=
os.environ.get
DB_HOST
Extract
host
port
socket
address
db_host
=
db_socket_addr
]
db_port
=
int
db_socket_addr
]
Test
LGTM
client
library
subprocess
change
todo
python
google.cloud
import
storage
storage_client
=
storage.Client
blobs
=
storage_client.list_blobs
//
/pubsub/'.format
BUCKET
blobs.length
bucket
=
storage_client.get_bucket
bucket_name
bucket.delete
standard
imports
third
party
imports
local
imports
docstring
descriptive
imports
second
section
imports
Nit
Prefer
active
tense
keys
data
argument
suggestion
function
Python
script
context
argument
pass
non-null
value
data
TODO
topic
afterwards
nice
explanation
possible
moment
Go
other
languages
entire
sample
part
comments
relevant
part
client
//
Create
client
custom
endpoint
//
Use
client
custom
endpoint
texts
image
code
sample
consistency
users
runnable
piece
code
something
comment
method
nice
example
dot
parameter
URL
shape
query
param
example
link
type
data
structure
info_types
nit
suggestion
Create
equivalent
term
sets
glossary
Glossary
words
variable
function
Please
sense
docstring
user
function
pytest
fixtures
]
https
//docs.pytest.org/en/latest/fixture.html
fixture-finalization-executing-teardown-code
resources
@
pytest.fixture
def
topic_path
topic
=
publisher_client.create_topic
topic_path
yield
topic.name
publisher_client.delete_topic
topic_path
docstring
function
HTTP
handler
Function
case
Flask
good
way
error
errors
variable
's3
TODO
need
date
type
support
class
function
method
docstring
comment
please
Can
IndexedConstraint
particular
collections
API
IndexedConstraint
API
weirdness
efficiency
implementational
benefits
IndexedComponent
inherit
suggestion
Check
permission
OCP-on-ALL
data
more
instance
API
function
generated
UUID
uncertain
server
Postgres
PK
likely
sequence
multiple
Status
objects
sequence
increments
status
object
pk=2
Status.objects.all
.first
first
entry
regardless
pk
above
comment
multiple
servers
@
dlabrecq
API
filter
[
time_scope_units
]
=month
filter
[
time_scope_value
]
=-1
filter
[
resolution
]
last
months
data
forecast
less
days
data
current
month
correct
Same
comment
Dayle
comments
update
openshift_project
openshift_node
suggestion
Tear
test
suggestion
Test
task
docstring
docstring
task
wrong
😅
retrospect
obvious
tests
few
minutes
method
available
users
customer
user
follow
description
doc
string
team
style
exception
api
doc
formatting
docstrings
particular
docstring
style
Plug
Google
docstring
style
readable
comments
point
next
suggestion
https
//hydra.cc/docs/next/tutorials/basic/running_your_app/tab_completion
zsh-instructions
discussion
function
sea
points
national
timezones
nautical
timezones
degree
longitude
bands
Greenwich
meridian
comments
couple
places
lot
docstring
more
improvements
clarity
notes
docstrings
cube
generic
structure
note
self.ltng_cube
comment
line
docstring
helpful
better
more
comments
weather
codes
nighttime
equivalent
night
e.g
Sunny
Day
Clear
Night
DayNight
mask
values
day
night
points
weather
code
value
list
need
-1
+
maskvalue
added.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=1835416
process
Docstrings
with_output
tests
least_significant_figure
brief
docstring
verify_checksum
path
available
exception
messages
change
None/Optional
allcaps
constant
issue
code
different
way
Suggest
Cube
orographic
enhancement
forecasts
lead
times
extrapolation
nowcast
required.
Default
None
type
statements
docstring
comment
different
x/y
names
equal
areas
coordinate
system
coordinate
system
e.g
matches
improver.grids
STANDARD_GRID_CCRS
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
class
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=2559558
bit
more
docstring
comment
shape
output
array
behaviour
numpy
choose
documentation
helpful
description
Create
reordered
copy
data
array
matching
index
array
condition
Please
numpy
choose
documentation
Codacy
issue
[
range
built-in
]
https
//app.codacy.com/manual/metoppv_tech/improver/pullRequest
prid=6350585
data
type
correction
list
coordinates
code
associated
aux
coords
docstring
please
different
interpolated_cube
docstring
function
check_coord_datatypes
dangerous
value
None
line
value
grid
square
units
data_smoothing_radius_km
clearer
comment
line
clearer
perhap
change
variables
data_smoothing_radius_km=7
data_smoothing_radius=7
Done
general
docstrings
unit
tests
style
https
//github.com/metoppv/improver/wiki/Code-Style-Guide
unit-testing
unit
tests
first
line
docstring
case
file
different
style
happy
line
adjust_nsize_for_ens
behaviour
unintentional
magic
number
km
radius
class
member
WindDirection
constant
necessary
appropriate
justification
docstrings
something
resembling
__init__
self.nb_radius
=
comment
use
NeighbourhoodProcessing
call
suggestion
CLI
reliability
table
cube
suggestion
def
test_manipulate_minimum_forecast_count
tmp_path
Test
manipulation
reliability
table
reduced
minimum
forecast
count
amend_metadata
docstring
metadata
dictionary
edit
docstring
bit
precise
cloud
area
fraction
precipitation
rate
cube
defaults
CLI
cloud
area
fraction
docstring
minimum_forecast_count
arg
agreement
accumulations
straight
sum
rates
eg
accumulation
period
0-15
minutes
rates
0-14
ignore
alternative
files
half-weighting
radar
rate
valid
exact
time-stamp
same
nowcast
Otherwise
accumulation
validity
-0.5
OK
great
docstring
units
standard
particular
case
other
cases
eg
neighbourhooding
mid-points
first
result
*
cube0+cube1
etc
good
length
test
comment
test
list
files
series
minute
accumulations
input
fields
minute
list
files
subsets
files
multiples
complete
subsets
fields
warning
while
bit
more
explanation
test
docstrings
users
please
tracemalloc
count
towards
RSS
snapshot
subsequent
checking
cycle
Second
subsequent
cycles
behaviour
memory
space
snapshot
exists
similar
understanding
correct
function
maxrss
second
frequency
possible
eg
due
memory
usage
rapid
turnover
allocation/deallocation
numpy
array
operation
snapshot
maxrss
snapshot
seconds
close
estimate
maximum
memory
usage
worth
comment
people
memory
profiles
aware
situation
suggestion
Test
_apply_minimum_precip_rate
method
suggestion
Test
_apply_orographic_enhancement
method
useful
Kelvin
end
docstring
docstring
method
references
extrapolation
function
optical
flow
function
spatial.py.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3722226
Suggest
output
test
case
Again
convention
slice
Done
Added
extended
documentation
mismatch
docstring
probability
snow
surface
return
statement
mentions
probability
snow
surface
other
limit
data
interpolated
difference
docstring
clearer.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3830094
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3830094
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3830094
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
class
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3830094
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
class
]
https
//app.codacy.com/app/metoppv_tech/improver/pullRequest
prid=3830094
Codacy
issue
[
function
method
]
https
//app.codacy.com/manual/metoppv_tech/improver/pullRequest
prid=5718468
new
behaviour
test
docstrings
standard
form
improver
uses
unused
suggestion
Test
expected
result
simple
collapse
suggestion
Converts
speed
direction
individual
velocity
components
ease
commit
ignore_dst=False
flag
test
inclusion
dst
tests
dst
Please
related
comment
ignore_dst
variable
comment
use
single
file
summer
winter
results
identical
time
coordinate
daylights
savings
time
same
same
comment
html
python
try
self._add_upstream
src_repo
logic
upstream
_add_upstream
method
Cause
upstream
type
method
conditions
methods
example
python
try
remote_name
self._add_upstream_from_remote
..
sure
relevance
add_upstream
self._add_upstream_from_repo
PathInfo
situation
more
types
block
PR
sign
comments/reasons
comment
bare
repo
self.dvc.reproduce
B.dvc
downstream=True
list
stages
fragile
parsing
logs
google
style
docstrings
Add
comment
dict
key
CID
values
dict
ranks
ids
current
way
setup
computation
synchronous
key
end
computation
scenario
>
keys
wrong
docstring
Outdated
comment
suggestion
backward
Replicated
Shared
Tensor
sense
call
chain
RST
example
create_grad_objects
suggestion
def
simplify
worker
AbstractWorker
tensor
ReplicatedSharingTensor
>
tuple
function
attributes
ReplicatedSharingTensor
tuple
Args
tensor
ReplicatedSharingTensor
ReplicatedSharingTensor
Returns
tuple
tuple
unique
attributes
NotImplemented
message
user
little
bit
something
Transfer
Syntaxes
table
pydicom
documentation
libraries
exact
link
danger
obsolete
table/section
title
least
Returns
section
needs
Could
fixtures
anything
__name__
__main__
fixutres
wrong
term
fixture-parametrize
]
https
//docs.pytest.org/en/latest/parametrize.html
tests
write
something
@
pytest.mark.parametrize
uid
UID
VR
Little
Endian
]
def
test_valid_uid
uid
assert
self.uid
==
uid
@
pytest.mark.parametrize
uid
UID
VR
Little
Endian
]
def
test_invalid_uid
uid
assert
self.uid
=
uid
test
raise
something
..
question
__name__
__main__
diff
diff
git
a/test/regression.py
b/test/regression.py
index
..
a/test/regression.py
+++
b/test/regression.py
@
@
-69,7
+69,7
@
@
cclib.parser
import
Psi4
cclib.parser
import
QChem
cclib.parser
import
Turbomole
-from
cclib.io
import
ccopen
cclib.io
import
ccopen
ccread
assume
cclib-data
repository
specific
location
cclib
repository
better
natural
@
@
-671,10
+671,10
@
@
def
testGAMESS_WinGAMESS_dvb_td_trplet_2007_03_24_r1_out
logfile
def
testnoparseGAMESS_WinGAMESS_H2O_def2SVPD_triplet_2019_06_30_R1_out
filename
molden
writer
unrestricted
ROHF
case
data
=
cclib.io.ccread
filename
writer
=
cclib.io.moldenwriter.MOLDEN
data
Check
size
Atoms
section
self.assertEqual
writer._mo_from_ccdata
data.gbasis
data.mocoeffs
data
=
ccread
filename
+
writer
=
moldenwriter.MOLDEN
data
+
Need
Sym=
Ene=
Spin=
Occup=
+
assert
len
writer._mo_from_ccdata
==
+
data.nbasis
data.nmo^M
paper
Eq
docstring
line
doi
case
wrong
paper
trial
ID
range
data
TODO
GPFA-related
issue
behaviour
next
issue
fix
people
Discussion
Please
reply
bic
comment
Please
use
border
correction
sense
case
window='valid
everything
full
overlap
same
amount
bins
calculation
bin
loss
edges
fact
correct
order
border
correction
case
issue
calculation
correction
wrong
PR
reviews
github
possible
lines
PR
new
PR
case
warning
window='valid
border_correction=True
sense
comment
comment
copy-pasta
documentation
query
param
X-Amz-Security-Token
capitalization
JSON
POST
bodies
[
Sentry
reports
]
https
//sentry.io/organizations/hypothesis/issues/1214722226/
referrer=github_integration
[
issue
]
https
//github.com/hypothesis/h/issues/5713
upper
lower-case
variants
query
param
various
services
sure
comparison
case
insensitive
tests
variants
X-Amz-Security-Token
canonical
capitalization
docs
Sorry
rSt
PR
complex
docstrings
proxy
naming
part
docstring
helper
class
comment
pre-existing
code
asserts
different
properties
group
test
test
comment
pre-existing
code
silly
use
parametrize
asserts
method
comment
pre-existing
code
clearer
test
name
suggestion
single
JSON
API
data
object
request
response
good
suggestion
docstring
function
Same
comment
remove
comment
comments
line
comment
case
old
version
db
gas
usage
Extra
gas
costs
various
factors
new
account
op
CALL
ext.account_exists
value
extra_gas
+=
Value
transfer
value
extra_gas
+=
function
name
use
Orphan
loaded
word
something
way
something
possible
afterthought
something
up-for
..
elements
following
*
fsentry
objects
METS
agents
Archivematica
Agent
model
events
fsentry
fsentry
fsentry
objects
agent
information
events
Pair
extracted
event
agents
agent
Archivematica
data
structure
eventual
METS
reingest
right
different
interpretation
docstring
descriptive
function
name
_orphan_agents
_extract_event_agents
function
comment
proper
docstring
further
discussion
introduction
black
long
lines
Docstrings
comments
bit
special
[
pep8
https
//www.python.org/dev/peps/pep-0008/
id19
>
okay
line
length
limit
characters
comments
docstrings
characters
bits
execution
context
useful
Executor
useful
method
first
time
future
new
job
exception
useful
context
line
*
code
code
self-describing
idea
]
https
//google.github.io/eng-practices/review/reviewer/looking-for.html
comments
Line
inconsistencies
Trailing
whitespaces
*
Origin
SpaceConsistencyBear
Section
python
issue
following
patch
diff
a/tmp/tmpn3csfg_a/tests/coalaCITest.py
+++
b/tmp/tmpn3csfg_a/tests/coalaCITest.py
@
@
-140,7
+140,7
@
@
'-b
settings
debug=debug
self.assertIn
'Line
contains
self.assertIn
'Line
contains
stdout
Result
message
self.assertIn
Applied
'ShowPatchAction
stderr
self.assertEqual
retval
Line
inconsistencies
Trailing
whitespaces
*
Origin
SpaceConsistencyBear
Section
python
issue
following
patch
diff
a/tmp/tmpbb8h46vf/tests/coalaDebugFlagTest.py
+++
b/tmp/tmpbb8h46vf/tests/coalaDebugFlagTest.py
@
@
-113,7
+113,7
@
@
bear_test_module
prepare_file
[
fixme
]
None
lines
filename
patch.dict
'sys.modules
ipdb=mocked_ipdb
self.assertRaisesRegex
RuntimeError
+
self.assertRaisesRegex
RuntimeError
mode_json
RaiseTestBear
independency
bears
one
https
//docs.microsoft.com/en-us/dotnet/visual-basic/programming-guide/program-structure/comments-in-code
coalib
multiple
delimiters
Create
issue
please
LocalBear
comment
implementation
file
unused
source
code
*
Origin
PyUnusedCodeBear
Section
flakes
issue
following
patch
diff
a/coalib/results/result_actions/GeneratePatchesAction.py
+++
b/coalib/results/result_actions/GeneratePatchesAction.py
@
@
-38,8
+38,6
@
G
patches
import
execute_section
coalib.output.ConsoleInteraction
import
acquire_settings
=
ConsolePrinter
bears_class
=
[
]
possible_options
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/coalib/results/result_actions/GeneratePatchesAction.py
+++
b/coalib/results/result_actions/GeneratePatchesAction.py
@
@
-53,7
+53,7
@
return
guess_lexer_for_filename
filename
file
+
'found
class
DefaultBear
readable
comments
flow
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/coalib/results/result_actions/GeneratePatchesAction.py
+++
b/coalib/results/result_actions/GeneratePatchesAction.py
@
@
-14,6
+14,8
@
@
def
show_possibilities
console_printer
i
action
console_printer.print
[
]
Apply
patch
\
\
i
action
+
def
define_arg
files
bears
function
default_arg_parser
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/tests/coalaDebugTest.py
+++
b/tests/coalaDebugTest.py
@
@
-82,7
+82,7
@
@
bear_test_module
prepare_file
[
fixme
]
None
lines
filename
\
self.assertRaisesRegex
RuntimeError
r
mode_json
+
mode_json
RaiseTestBear
independency
bears
Hmm
dynamicly
docstrings
comment
comment
i
new
function
code
Shouldnt
similar
apply
action
action
Anyway
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmp2bvkzfnl/coalib/core/PersistentHash.py
+++
b/tmp/tmp2bvkzfnl/coalib/core/PersistentHash.py
@
@
-25,6
+25,7
@
order
task-objects
sets
+
def
__init__
arg_dict
self.arg_tuple
=
arg_tuple
self.arg_dict
=
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/tests/bears/BearTest.py
+++
b/tests/bears/BearTest.py
@
@
-270,7
+270,7
@
@
class
BrokenReadHTTPResponse
BytesIO
HTTPResponse-like
reader
chunks
fails
+
HTTPResponse-like
reader
chunks
fails
def
__init__
chunks
*
args
*
*
kwargs
self.read_count
newline
small
comment
ie
special
target
transform
regressor
thing
theoretical
case
gordo
base
model
gordo
model
Know
Keras
ie
default
people
optimizer
compile
kwargs
default
something
comment
relevant
line
conditional
something
lstm_symmetric
previous
comment
bit
strange
default
args
ValueError
function
OOH
advanced
line
Many
strange
things
Python
long
lines
comments
generall
default
serialized
PythonModel
objects
file
concerned
logical
perspective
code
data_path/loader_module
pathway
example
default
PythonModel
provided
loader_module
main
downside
approach
cloudpickle
pyfunc
model
environments
severe
Anyway
least
comment
point
code
default
addition
module-level
documentation
concepts
PythonModel
serialization
saving
pyfunc
models
wrong
distinction
@
shrinath-suresh
comment
favor
issue
PytorchLightning
track
details
action
Thse
lines
metric_funcs
=
sklearn.metrics.precision_score
average
average
classifier_metrics
=
[
_SklearnMetric
name=
training_
.format
func.__name__
arguments=dict
sample_weight=sample_weight
*
*
kwargs
func
metric_funcs.items
Q
internal
methods
__all__
import
*
methods
_get_git_commit
_get_git_commit
etc
other
modules
public
API
mlflow.tracking.flow
e.g
mlflow.tracking.flow.get_git_commit
module
code
robust
future
refactors
mlflow.tracking.flow
metric
timestamp
integer
value
millisecond
resolution
fluent
API
https
//github.com/mlflow/mlflow/blob/055978cdd425ac7c328069d80230f5bc50265df8/mlflow/tracking/fluent.py
L443
suggestion
self.data.append
Metric
key
value
int
current_timestamp
*
step
XGBoost
example
logs
file
store
operating
timestamp
content
float
form
integer
form
/Users/czumar/mlflow/mlflow/xgboost.py:412
DeprecationWarning
inspect.getargspec
Python
use
inspect.signature
inspect.getfullargspec
=
inspect.getargspec
original
]
pylint
disable=W1505
]
train-mlogloss:0.74723
[
]
train-mlogloss:0.54060
[
]
train-mlogloss:0.40276
[
]
train-mlogloss:0.30789
[
]
train-mlogloss:0.24052
[
]
train-mlogloss:0.19087
[
]
train-mlogloss:0.15471
[
]
train-mlogloss:0.12807
[
]
train-mlogloss:0.10722
[
]
train-mlogloss:0.09053
/Users/czumar/mlflow/mlflow/xgboost.py:387
UserWarning
MLflow
invalid
literal
int
base
try_mlflow_log
mlflow.log_artifact
filepath
/Users/czumar/mlflow/mlflow/xgboost.py:465
UserWarning
MLflow
invalid
literal
int
base
try_mlflow_log
mlflow.log_artifact
filepath
/Users/czumar/mlflow/mlflow/xgboost.py:501
UserWarning
MLflow
invalid
literal
int
base
input_example=input_example
Interestingly
error
encountered
subsequent
artifact
operations
file
store
logged
metric
files
kind
gross
best
solution
linter
errors
noqa
pylint
disable=E402
import
line
described
https
//github.com/PyCQA/pycodestyle/issues/264
Maybe
short
doc
comment
predict
Nit
Documentation
top
quotes
documentation
links
<
img
width=
alt=
Screen
Shot
2020-04-10
PM
src=
https
//user-images.githubusercontent.com/39497902/79031692-4ea38f80-7b55-11ea-9e96-ab066dbd6996.png
>
fix
suggestion
<
https
//docs.microsoft.com/python/api/azureml-core/
azureml.core.webservice.aks.aksservicedeploymentconfiguration
>
_
<
https
//docs.microsoft.com/en-us/python/api/azureml-core/azureml
.core.webservice.aci.aciservicedeploymentconfiguration
>
way
test
function
look
tests/projects/test_projects.py
tests
Git
small
local
Git
repos
purpose
able
new
test
ValueError
RuntimeError
cool
name
currently-installed
plugins
help
string
bulleted
list
something
help=
Deployment
target
URI
e.g
'sagemaker
Run
mlflow
deployments
<
target-name
>
more
details
URI
format
config
options
target
Currently-supported
targets
other
deployment
targets
instructions
support
https
//mlflow.org/docs/latest/plugins.html
community-plugins
supported_targets
.format
supported_targets=
\n
.join
[
%
s
%
target
target
list_of_targets_from_plugin_registry
]
test
reloaded
model
same
raw
output
original
model
addition
correctness
_FastAiModelWrapper
output
e.g
something
test_model_save_load
fastai_model
model_path
model
fastai_model.model
mlflow.fastai.save_model
fastai_learner=model
path=model_path
reloaded_model
=
mlflow.fastai.load_model
model_uri=model_path
Verify
model
computes
same
predictions
original
model
test_data
TabularList.from_df
fastai_model.inference_dataframe
model.data.add_test
test_data
=
map
lambda
output
output.numpy
model.get_preds
DatasetType.Test
reloaded_model.data.add_test
test_data
=
map
lambda
output
output.numpy
reloaded_model.get_preds
DatasetType.Test
np.testing.assert_array_almost_equal
real_preds
reloaded_preds
np.testing.assert_array_almost_equal
Verify
pyfunc
same
output
raw
model
reloaded_pyfunc
=
pyfunc.load_model
model_uri=model_path
pyfunc_predictions
reloaded_pyfunc.predict
fastai_model.inference_dataframe
assert
pyfunc_predictions
real_preds
pyfunc_predictions.columns
predictions
target
i
prediction_arr
enumerate
pyfunc_predictions
predictions
]
np.testing.assert_array_almost_equal
real_preds
[
i
prediction_arr
i
target
enumerate
pyfunc_predictions
target
]
assert
real_target
[
i
==
target
suggestion
client
=
mlflow.tracking.MlflowClient
Get
versions
model
name
model_name
=
CordobaWeatherForecastModel
filter_name
=
.format
model_name
results
=
client.search_model_versions
filter_name
print
res
results
print
version=
.format
res.name
res.run_id
res.version
version
model
run_id
run_id
e14afa2f47a040728060c1699968fd43
filter_runid
run_id=
.format
run_id
results
=
client.search_model_versions
filter_runid
print
res
results
print
version=
.format
res.name
res.run_id
res.version
suggestion
models
save_format
PluginContextProvider
return
need
Move
comment
top
file
easier
doc
comment
whole
file
method
something
slice
train_data.data
free_raw_data
sample
=
train_data.data
[
:5
]
model
=
original
*
args
*
*
kwargs
==
lgb.train
something
sample
previous
comment
len
args
train_data
case
MLflow
LightGBM
confusing
UX
comment
e.g.
tag
backwards-compatibility
least
release
source
type
NOTEBOOK
/
JOB
/
PROJECT
/
LOCAL
/
UNKNOWN
change
documentation
built-in
source
types
values
docs
page
default
tags
MLflow
similar
REST
API
docs
suggestion
param
lgb_model
LightGBM
model
instance
lightgbm.Booster
understanding
correct
save_model
log_model
load_model
APIs
work
lightgbm.Booster
models
models
[
scikit-learn
API
]
https
//lightgbm.readthedocs.io/en/latest/Python-API.html
scikit-learn-api
good
clarification
docstrings
log_model
load_model
documentation
autolog
train
export_saved_model
runs
everything
single
run
user
training
logic
mlflow.start_run
comments
https
//github.com/mlflow/mlflow/pull/2095
try_mlflow_log
comment
filter
mapper
parameters
comment
suggestion
'content
'comment
parameterize
everything
works
p.set_dir
few
points
coverage
*
sub/
directory
nested
set_dir
package
right
thing
disk
least
comment
nested/sub
tests
certain
keys
values
new
keys
something
assert
set
pkg.keys
==
[
good
inputs
]
whole
unit
test
A
B
*
A
B
initial
state
*
merge
*
Prove
adds/modifies/deletes
comments
quick
update
CSV
files
few
lines
minimum
i
fine
legacy
short
hashes
chars
comment
constant
MIN_SHORTHASH_LEN
docstrings
type
annotation
suggestion
def
convert_weights_disk_format
params
mx.gluon.parameter.ParameterDict
shape
comment
*
max_output_length
encoded_source_length
__add_frozen
See
next
comment
great
little
bit
more
documentation
function
e.g
state
member
related
note
possible
function
return
bucket_batch_sizes
batching
cases
Sentence-based
batch
size
bucket
batch
sizes
same
layers
argument
sure
comments
fname
Missing
docstrings
huge
fan
iter1
=
iter
sentence_reader
el1
=
iter1.next
=
iter
sentence_reader
iter
el2
=
iter1.next
first
element
second
time
self._iter
None
kind
usage
method
aux
params
devices
module.get_params
call
internal
method
method
overall
current
module
parameters
file
return
value
type
new
fallback
behavior
chunked
inputs
code
little
bit
something
python
chunk_id
i
enumerate
range
Constrained
decoding
chunked
TranslatorInputs
Constraints
first
chunk
chunk_id
constraints
self.constraints
None
solution
code
warning
same
place
warning
function
work
Make
sure
more
docstring
clarity
developers
Same
comments
last
Args
docstring
conciseness
leading
description
quantile
q
lazy
computation
Same
earlier
docstring
circular
import
alphabetical
order
summary
more
Returns
metric
comparison
compute
functions
HindcastEnsemble
initialized
reconstruction
observations
annual
time
series
grid
HindcastEnsemble
initialized
reconstruction
observations
nlat
spatial
dimensions
S
Refers
date
*
L
Refers
time
*
M
Refers
ensemble
member
member
good
new
user
mind
docstring
API
default
comment
comment
developers
/
check
input
datasets
values
NaN
Great
comment
different
approaches
sections
python
Example
boolean/logical
function
binary
scoring
>
>
>
def
pos
x
return
Option
Pass
keyword
logical
>
>
>
hindcast.verify
metric='brier_score
comparison='m2o
dim='member
alignment='same_verifs
logical=pos
Option
Pre-process
binary
forecast
verification
product
>
>
>
hindcast.map
pos
.verify
metric='brier_score
comparison='e2o
Add
comment
Loop
observations
multiple.
Add
comment
pre-allocated
entries
empty
such
'uninitialized'.
dim
docstring
name
more
clear
Broadcast
general
term
different
indices
single
dimension
many
times
select_bootstrap_indices_ufunc
something
similar
brief
docstring
line
code
obvious
indices
bootstrapped
dimension
iterations
Can
private
function
important
one
E.g
python
Return
ensemble
iterations
new
dimension
init
xr
object
ensemble
bootstrap/iterations
int
Number
iterations
dim
str
Dimension
[
'member
'init
]
Default
'member
bool
True
resample
replacement
Default
True
Returns
dataset
iterations
new
dimension
bootstrap
test
nice
Hard
tests
Is
way
Sefarian
References
convention
end
docstrings
Matt
Newman
NOAA
ESRL
active
predictability
community
fac
docs
page
comments
docstrings
potential
problem
implementation
Group
label=
type_string='user
Group
label=
type_string='auto.import
path
=
GroupPath
type_string=None
path.group
filters
single
group
NotExistent
case
MultipleObjectsError
example
Did
decision
something
lifetime
PR
out
bit
rest
functionality
honest
sure
type_string
way
GroupPath
specific
type
groups
least
label
uniqueness
docstrings
deprecated
parameters
more
info
such
version
Done
documentation
top-level
command
help
help
command
groups
suggestion
Class
data
export
process
bit
actual
usage
base
class
dummy
interface
class
nothing
tqdm
practice
suggestion
total
=
+
include_logs
+
include_comments
comment
sure
understood
good
quick
comment
literal
repeat
first
few
lines
Set
same
node
setter
item/attribute
suggestion
suggestion
list
labels
computers
DB
extra
docstring
attribute
Thanks
checking
nitpick
test
comment
sure
line
File
caller_tb.filename
..
/home/sph/code/aiida/env/dev/aiida-core/aiida/orm/nodes/node.py:62
AiidaDeprecationWarning
Node.read
context
manager
<
ForceConstantsData
uuid
6444b4db-4c69-484d-87d1-5ab6d38d8e46
unstored
>
Please
use
<
node
>
.open
aiida-core==2.0.0
/home/sph/code/aiida/env/dev/aiida-quantumespresso/aiida_quantumespresso/data/force_constants.py
line
module
set_file
/home/sph/code/aiida/env/dev/aiida-quantumespresso/aiida_quantumespresso/data/force_constants.py
line
set_file
content
=
handle.read
.splitlines
warnings.warn
msg
AiidaDeprecationWarning
pylint
disable=no-member
idea
suggestion
def
total
>
int
Return
total
iterations
return
self._total
suggestion
Migration
extras
column
DbGroup
model
suggestion
Migration
extras
column
DbGroup
model
suggestion
Downgrade
Drop
extras
column
'db_dbgroup
table
suggestion
i
indices
enumerate
ii
Calculate
z-score
z
[
i
]
_
=
calculate_zscore
chain
[
indices
]
suggestion
def
create_optimization_result_nan_inf
Create
result
object
nan
inf
function
values
prior_type_entry
string
initializationPriorType
objectivePriorType
[
PEtab
parameters
table
]
https
//petab.readthedocs.io/en/stable/documentation_data_format.html
parameter-table
fails
strings
short
docstring
suggestion
plottable_indices
result
results
parameter
indices
profiles
tmp_indices
[
par_id
par_id
prof
enumerate
result.profile_result.list
[
profile_list_id
]
prof
None
]
profile_indices
parameter
indices
least
results
profile
exists
tmp_indices
plottable_indices
code
sx
None
opinion
consistency
nn.Module
wrapper
free
functions
easy
nn.Sequential
possible
free
functional
following
signature
def
zca_whitten
input
torch.Tensor
mean
Optional
[
torch.Tensor
]
=
None
transform
Optional
[
torch.Tensor
]
=
None
>
torch.Tensor
mean
None
transform
None
transform
mean
=
zca_mean
input
huge
fan
state
functions
least
point
view
low
level
libs
use
open
proposal
direction
Could
comment
numbers
opencv
output
=
kornia.filters.SpatialGradient3d
input
purpose
methods
comments
vague
ones
suggestion
complex
conversion
rule
incompatible
units
LIKE
statement
description
field
huge
numbers
item
query
slow
index
description
Please
https
//github.com/frappe/erpnext/blob/develop/erpnext/controllers/queries.py
L174
indentation
comments
required
tests
need
loop
commented
code
more
test
repeat
orders
suggestion
UPDATE
tabItem
Price
unit
tests
explanatory
documentation
case
nice
docs
something
more
generic
Ditto
name
class
something
docstring
method
cleanup
dead
workers
records
heartbeat
current
worker
quick
comment
empty
lists
suggestion
redis
connection
connection
pool
kinds
gradients
little
weird
kinds
user
interface
docstring
_EvaluationJob.__init__
Function
__init__
unifies
cases
consistent
structure
Function
report_evaluation_metrics
calculates
metrics
structure
Function
get_evaluation_summary
returns
calculated
metrics
logger
returned
metrics
get_evaluation_summury
metrics
similar
form
user
interface
docstring
args
documentation
function
datasets
available
Otherwise
developers
function
available
user
writes
functional
api
size
model
note
docstring
function
tensor
object
new
Tensor
object
python
deserialize_tensor_pb
tensor_pb
tensor
tensor.set
Wrong
comment
function
master
client
first
letter
docstring
same
questions
following
docstrings
same
line
blank
line
Parameters
comment
hardcoded
string
match
logic
bit
overcomplicated
Start
has_match
=
False
coinc
coinc
matches
*
relevant
parameters
tc
mass1
mass2
spin1z
spin2z
network
SNR
everything
matches
has_match
true
j
loop
keep
looping
log
message
parameter
*
*
match
sure
necessary
Travis
test
test
verbose
local
check
log
message
code
bit
lines
first
sigmas
second
log
network
sensitive
volume
something
'benchmark_logvol
log
sensitive
volume
edit
comment
eg
number
ifos
mean
time
ifos
coinc
need
comment
pivot
ifo
num_ifos-1
modes
co-precessing
frame
radiation
frame
radiation
frame
important
above
other
X
radiation
frame
docstrings
precessing
waveforms
real
>
imaginary
docstring
docstring
real
number
magnitude
Y_lm
previous
NewSNR
calculation
above
lines
nsnr
=
nsnr_all
[
]
[
i
aesthetics
Similar
comment
coinc_fail
log.error
'Coincident
trigger
test
failed
'spaces
operator
comment
t.upper
Docstrings
fine
function
beginning
clear
functions
redundant
Please
screenshot
output
reply
comment
python
complex
numbers
[
]
round
TypeError
Traceback
recent
call
last
ipython-input-1-81fdcefa71b7
>
<
module
>
>
round
TypeError
type
complex
__round__
method
separate
round
real
imaginary
parts
common
workaround
reason
tests
pass
numpy
types
most
part
*
[
]
import
np
]
round
np.complex128
]
[
]
round
np.complex64
]
[
]
round
np.complex
TypeError
Traceback
recent
call
last
ipython-input-4-48bae1814ad4
>
<
module
>
>
round
np.complex
TypeError
type
complex
__round__
method
]
round
TypeError
Traceback
recent
call
last
ipython-input-5-81fdcefa71b7
>
<
module
>
>
round
TypeError
type
complex
__round__
method
comment
*
separate
rounding
real
imaginary
parts
*
unit
test
dirac_notation
native
complex
type
amplitudes
state
separate
nodes
first
time
update
updates
efficient
few
nodes
original
text
attributes
spam_depolarization
cycle_depolarization
coefficient
decay_constant
Please
update
Applies
Returns
section
docstring
purity_depolarizing_model
Add
mention
batch
calibration
documentation
pasta
coincidental
terminology
conflict
batch
clarity
test
default
label
documentation
offline
comments
Bloch
vector
size
sufficient
detuning
comment
confusing
results
sure
functionality
comment
CPMG
follow-up
PR
Spin
Echo
other
comment
better
angles
google
style
docstrings
Args
op
bla
bla
bla
Returns
bla
bla
Nit
empty
line
bla
bla
summary
line
Nit
alignment
doc
string
word
wrap
Similar
other
methods
Same
comment
descriptive
text
following
function
kak_vector
entry
api.rst
kak_decomposition
documentation
output
note
sigma
symbol
[
image
]
https
//user-images.githubusercontent.com/79941/66352191-f8d6fc00-e913-11e9-81cb-16ceec01c6bc.png
docstring
meanings
docstring
comment
name
execution
strategy
problem
someone
@
dstrain115
nice
plan
Device
interface
future
rid
hack
issue
issue
number
comment
diagrams
docstring
file
single
class
protocol
act_on
protocol
piece
Clifford
simulation
act_on
protocol
comment
significance
letter
Just
inline
moment.operations
nit
extra
newline
extra
indent
issue
TODO
TODO
Docstring
arguments
Annotate
types
code
Note
Create
issue
TODO
PR
normal
matrix
body
docstring
definition
short
remark
unitary
Hermitian
matrices
normal
counterexample
e.g
creation
annihilation
operators
normal
Applies
Args
section
docstring
wrong
many
contexts
anything
example
autocomplete
popups
IDEs
parameter
docstring
class
clearer
Triple
quote
comment
other
cases
comment
external
documentation
exists
>
bunch
comments
>
bit
worried
fact
unnoticed
>
assert_all_implemented_act_on_effects_match_unitary
>
>
np.testing.assert_allclose
np.reshape
>
stabilizer_ch_form.state_vector
protocols.qid_shape
qubits
>
state_vector
>
atol=1e-07
err_msg=
inconsistent
stabilizer
ch
form
>
>
>
>
testing.assert_allclose_up_to_global_phase
np.reshape
>
stabilizer_ch_form.state_vector
protocols.qid_shape
qubits
>
state_vector
>
atol=1e-07
>
>
benefits
CH-form
phase
sensitive
unitary
consistency
phase
insensitive
way
gate
implementations
reason
factor
I.e
np.testing.assert_allclose
state_vector
*
SvgCircuit
bit
confusing
circuit_to_svg
_disjoint_qubits
similar
people
documentation
method
default
value
description
function
display
value
samples
Rename
similar
docstring
clearer
something
itertools
comment
comment
moot
Style
guide
short
one-line
summary
same
line
Style
guide
short
one-line
summary
same
line
complicated
body
nit
period
end
comments
args
Nit
space
docstring
top
one-liner
description
greedy
strategy
function
private
docstring
argument
list
Add
brief
docstrings
functions
example
usage
class
something
fact
function
name
out=None
fine
numpy
documentation
separate
class
following
method
def
MS
rads
float
>
XXPowGate
return
ops.XXPowGate
exponent=rads
*
np.pi
global_shift=-0.5
intuitive
isinstance
program
ops.Gate
convert
program
=
program.on
*
line.LineQubit.range
program.num_qubits
program
=
circuits.Circuit.from_ops
program
docstring
Note
stabilizer
correct
global
phase
e.g
Z
stabilizer
|0
>
|1
>
-Z
comments
steps
implementation
relate
stages
superdense
process
quick
docstring
See
_simulator_iterator
nit
blank
line
initial
summary
rest
module
docstring
class
docstring
sufficient
matter
separate
files
tag
bit
overkill
physical
z
tag
calibration
tag
single
tags.py
file
worth
developer-centric
docstring
private
method
mandatory
nice
Hmm
Re
comment
more
alias
Avoid
use
comments
[
style
guide
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
Return
user
form
tests
example
failures
inline.has_delete_permission
request
obj
expected
behavior
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
wrap
docstrings
chars
logic
loop
separate
hook
Chris
separation
iteration
exceptions
tracebacks
def
get_traceback_frames
=
[
]
No
exceptions
exceptions
return
frames
case
exception
traceback
self.tb
exc_value
=
exceptions.pop
tb
self.tb
exceptions
frames.extend
self.get_inner_traceback_frames
exc_value
tb
exceptions
exc_value
=
exceptions.pop
=
self.get_inner_traceback_frames
exc_value
exc_value.__traceback__
frames.extend
exc_frames
frames
def
get_inner_traceback_frames
tb
frames
[
]
exc_cause
=
self.explicit_or_implicit_cause
exc_value
exc_cause_explicit
=
getattr
exc_value
'__cause__
True
tb
None
Support
__traceback_hide__
few
libraries
exc_cause
exc_cause_explicit
tb
'django
module_name.startswith
'user
filename
'function
function
lineno
'vars
self.filter.get_traceback_frame_variables
self.request
tb.tb_frame
id
tb
pre_context
context_line
post_context
pre_context_lineno
tb
=
tb.tb_next
return
params
suggestion
[
self.index_name
]
Docstrings
state
behavior
omit
prefixes
Tests
tests
things
[
Python
style
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
good
example
most
people
problem
unicode_literals
clarity
concern
extra
comment
something
verbose
previous
comment
tdir
discussion
MiddlewareMixin
class
deprecation
tool
new-style
middleware
rid
DJango
fact
middleware
facility
pre-
-post
get_response
code
same
__call__
method
difficult
decoration
tool
apollo13
interested
plan
use
case
MiddlewareMixin
useful
deprecation
part
decoration
sync/async
properties
django/middleware
custom
middleware
documentation
class
Use
double
quotes
wrap
docstrings
characters
chars
Use
indent
[
Python
style
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
example
self.assertEqual
words
-5
ipsum
dolor
sit
consectetur
elit
tempor
incididunt
ut'
other
places
PR
style
comment
_property_names
]
https
//github.com/django/django/blob/6a3801e3ab76cf9a10ee171b1be4909743331371/django/db/models/options.py
L833
comment
new
use
state
deprecation
risk
logging
suspicious
session
def
decode
session_data
try
return
signing.loads
session_data
salt=self.key_salt
serializer=self.serializer
deprecation
signing.BadSignature
logger
=
logging.getLogger
'django.security.SuspiciousSession
'Session
data
Exception
ValueError
unpickling
exceptions
happen
empty
dictionary
empty
session
pass
return
Exception
return
self._legacy_decode
session_data
python
_cls
=
None
unused
first
glance
tests
thinking
Sorry
comments
slight
difference
assertRaisesMessage
assertEqual
assertIn
intentional
decision
reason
assertIn
first
place
case
code
docstring
comment
overall
change
line
py
secure
=
key.startswith
'__Host-
[
str.startswith
]
https
//docs.python.org/3/library/stdtypes.html
str.startswith
tuple
values
subTest
python
model
pk_pos
Book
-1
Unmanaged
origin
model
Author
Unmanaged
related
model
self.subTest
model=model
pk_pos=pk_pos
mock.patch.object
model._meta
False
_
_
=
queryset.query.get_compiler
using='default
self.assertEqual
model._meta.fields
self.assertIn
Author._meta.pk.name
[
pk_pos
]
]
index
field
enumerate
model._meta.fields
self.assertIn
field.name
[
index
+
pk_pos
]
]
assert_queryset_results
queryset
readable
much
value
docstring
function
has_colorama
much
top-level
import
bit
🤔
—
clearer
function
horrible
comment
suggestion
Collation
change
elif
getattr
'db_collation
None
=
getattr
new_field
'db_collation
None
new_collation
=
getattr
new_field
'db_collation
None
fragment
=
self._alter_column_collation_sql
new_field
new_type
new_collation
actions.append
fragment
old
code
field
type
collation
change
same
time
e.g
CharField
db_collation='foo
>
TextField
db_collation='bar
docstring
same
wait_page_loaded
case
docstring
difference
methods
status
code
request
method
following
reads
Preserve
request
method
post-redirect
responses.
much
test
data
use
solid
understanding
window
functions
difficult
output
potential
issues
test
data
various
window
functions
someone
unfamiliar
easier
future
test
data
smaller
line
explanation
results
example
Lead
expression
>
Display
salary
person
next
row
hiredate
duplication
documentation
verification
results
big
paragraphs
text
possible
short
explanation
sentence
review
elegant…
>
…
little
obscure
comment
it…
fair
round
today
felixxm
Any
chance
Thanks
wsgiref
https
//github.com/python/cpython/blob/master/Lib/wsgiref/handlers.py
L191
comment
iterable
item
memory
anyways
>
Documentation
comments
docstrings
characters…
>
—
[
Coding
style
guidelines
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
test
IntegrityError
e.g
def
test_order_by_update_on_unique_constraint_annotation
annotate
references
self.assertRaises
IntegrityError
UniqueNumber.objects.annotate
number_inverse=F
'number
.update
number=F
'number
docstring
docstring
comment
useful
behaviour
KeyboardInterrupt
old_field.db_index
old_field.unique
unique=True
indexes
least
https
//code.djangoproject.com/ticket/24082
comment
hidden
ValueError
non-pairs
break
next
try
block
Tests
sure
value
human_name
=
group_name
group_choices
ValueError
test
case
exception
possible
separate
try/except
large
isinstance
key
str
subclasses
SafeExceptionReporterFilter
use
pattern
hidden_settings
diff
diff
git
a/django/views/debug.py
b/django/views/debug.py
index
..
a/django/views/debug.py
+++
b/django/views/debug.py
@
@
-91,18
+91,18
@
@
class
SafeExceptionReporterFilter
value
dictionary
keys
dictionary.
try
self.hidden_settings.search
key
=
self.cleansed_substitute
elif
isinstance
value
dict
=
k
self.cleanse_setting
k
v
k
v
value.items
elif
isinstance
value
list
=
[
self.cleanse_setting
v
v
value
]
elif
isinstance
value
tuple
=
tuple
[
self.cleanse_setting
v
v
value
]
=
value
+
is_sensitive
=
self.hidden_settings.search
key
TypeError
key
regex-able
as-is
+
is_sensitive
=
False
+
is_sensitive
+
=
self.cleansed_substitute
+
elif
isinstance
value
dict
+
=
k
self.cleanse_setting
k
v
k
v
value.items
elif
isinstance
value
list
+
=
[
self.cleanse_setting
v
v
value
]
+
isinstance
value
tuple
+
=
tuple
[
self.cleanse_setting
v
v
value
]
+
value
callable
]
https
//github.com/django/django/pull/12422
issuecomment-585463877
original
PR
abbreviations
months
Algerian
Arabic
N
formats
N
>
F
thinking
need
nit
ways
parameter
class
names
various
functions
schema_classes
class_names
consistency
class_names
comments
case
please
schema_classes
class_names
consistency
documentation
case-insensitive
iterable
Changed
thing
comment
more
explanation
moment
something
_wbemconnection_mock
refernce
conn.default_namespace
Question
default
conneciton
namespace
Google
style
please
Do
Google-style
docstring
style
class
docstring
__init__
please
Add
comment
function
json
comment
ocaml
code
old_person
Optional
[
Person
]
type
ignore
test
cases
other
actuator
tests
imagination
eg
tmcm_test
actuator_test
least
.position
move
simulator
good
closed
loop
open
loop
modes
Please
add
docstrings
fails
fine
current
implementation
state
function
callback
Just
call
self.reference
comment
background
update
docstrings
dict
positions
int
0-
>
len
tree
-1
array
special
code
positions
caller
[
None
None
]
afterwards
final
array
[
]
graph
positions
numpy.zeros
num_rows
num_cols
start
shift
tile
positions_flat
=
positions.reshape
*
num_cols
tiles
idx
notation
while
loop
positions_flat
special
handling
tiles
dict
sorting
return
positions
suggestion
Type
alias
tensor-like
types
most
TensorFlow
NumPy
GPflow
operations
NOTE
multipledispatch
package
tuples
typing.Union
multiple
types
Dispatcher
register
method
@
conditional.register
decorator
TensorLikeTypes
paths
[
]
.attr.attr
[
-1
]
implications
docs
example
case
bit
lines
x
mu
N
D
assert
L
N
N
docstrings
L
D
D
mismatch
Might
good
__init__
docstring
pass
base=
*
arguments
case
SquaredExponential
base
kernel
suggestion
pytest.param
kernels.Periodic
marks=pytest.mark.xfail
lambda
kernels.White
lambda
kernels.White
class
num_latents
equals
output_dimensionality
shape
comments
big
fan
Check
comment
test
printing
*
custom
class
suggestion
app.connect
'autodoc-skip-member
autodoc_skip_member_callback
suggestion
getattr
__doc__
None
None
return
False
methods
suggestion
return
False
function/method
suggestion
def
autodoc_skip_member_callback
app
name
obj
skip
options
color
scheme
light
green
invisible
specific
thing
end
lots
redundancy
Separate
class
Please
URL
same
line
line
length
indentation
bit
weird
blank
line
third-party
imports
imports
current
package
Generally
imports
import
time
built-in
imports
import
sys
blank
line
import
torch
third-party
imports
torch
import
blank
line
texar.torch.core
import
layers
imports
current
package
i.e
url
good
users
docs
Executor
more
details
network
model
use
same
input
vocab
size
vocab
effect
vocab_size
==
None
Pls
clear
docstring
class-level
docstring
key
information
users
order
way
word
char
unigram
comment
lines
685-708
logic
same
e.g
class-level
dictionary
mapping
modes
functions
List
[
Tuple
[
float
float
]
]
list_of_points
List
tuples
floats__
general
type
annotations
data
types
comments
comments
data
important
suggestion
Parameters
arr
List
sorted
elements
val
Element
list
Returns
index
element
array
element
above
comment
suggestion
number
possible
prize
strings
particular
number
__for
i
c
enumerate
poly
__
lines
suggestion
elif
target_vertex
suggestion
>
>
>
equality
[
]
test
Place
docstrings
def
line
parameters
return
value
Please
Google
Python
docstrings
conventions
https
//www.datacamp.com/community/tutorials/docstrings-python
second-head
Replace
lines
Python
builtin
__sum
__
count
=
sum
digitsum
str
i
i
range
def
print_results
s
str
passes
bool
>
None
print
f
passes
work
print_results
test_rotations
>
>
>
pytests
cool
test
call
chaining
tree
=
RedBlackTree
.insert
-16
.tree.insert
.insert
.insert
.insert
.insert
lines
tree
tests
>
>
>
left_shift
>
>
>
XOR
Please
doctest
CONTRIBUTING.md
>
>
>
mixed_keyword
college
UNIVERSITY
doctest
+NORMALIZE_WHITESPACE
C
B
C
P
E
U
F
Z
G
O
H
B
J
J
Q
K
V
L
L
'D
K
O
R
P
W
Q
E
R
F
'M
U
X
V
G
W
H
X
'N
Y
'T
Z
Y
Move
main
tests
doctest
__stooge_sort
__
__stooge_sort
__
function
__stooge
__
function
lines
line
blank
lines
def
stooge_sort
arr
>
>
>
=
[
]
>
>
>
stoogesort
arr
>
>
print
arr
]
stooge
arr
def
stooge
arr
i
h
Descriptive
variable
names
accuracy
estimation
Python
standard
library
math.py
__name__
__main__
import
doctest
doctest.testmod
math
import
pi
prompt
=
Please
desired
number
Monte
Carlo
simulations
number_of_simulations
int
input
prompt
number_of_simulations
print
f
estimate
PI
my_pi
accuracy
abs
my_pi
pi
kind
new
doctests
general
doctest
exception
suggestion
def
solution
limit
int
>
int
solution
problem
doctest
function
answer
answer
part
[
script
]
https
//github.com/TheAlgorithms/Python/blob/master/project_euler/validate_solutions.py
Authorization
tokens
tuple
request
headers
Please
documentation
return
type
hint
needs
descriptive
import
Dict
[
type
key
type
value
GitHub
Dict
[
Any
Any
]
suggestion
def
support_vector_regressor
x_train
list
x_test
list
train_user
list
>
float
Matches
docstring
next
line
mistake
Fix
way
comment
function
return
get_sub_domain_name
url
-2
]
make_tree
>
Node
root
=
Node
root.left
=
Node
root.right
=
Node
root.left.left
=
Node
root.left.right
=
Node
return
root
def
preorder
root
PreOrder
traversal
visit
root
node
left
subtree
right
subtree
>
>
preorder
make_tree
utility
function
doctest
test
home
python3
doctest
-v
binary_tree_traversals.py
doctests
other
traversal
functions
set
comprehension
suggestion
maximum
non-adjacent
sum
integers
nums
list
Type
hints
careful
naming
functions
variables
lot
comments
unnecessary
boilerplate
def
tells
function
self-documenting
function
name
function
type
hints
nums
list
integers
type
hint
return
value
SiddhantBobde
Kindly
docstrings
type
parameters
return
types
https
//www.geeksforgeeks.org/python-docstrings/
~
text=Python
%
%
%
%
%
%
%
%
eg
def
sum
b
sum
func
summation
b.
Args
>
int
>
int
Returns
int
return
a+b
def
sum
int
b
int
>
int
sum
func
summation
b
return
automated
tests
====================================
ERRORS
====================================
_______
ERROR
linear_algebra/src/python-polynom-for-points.py
_______
linear_algebra/src/python-polynom-for-points.py:11
<
module
>
x=int
input
number
points
.strip
/
..
/
/virtualenv/python3.7.1/lib/python3.7/site-packages/_pytest/capture.py:661
read
raise
IOError
reading
stdin
output
OSError
reading
stdin
output
stdout
number
points
please
following
lines
__name__
__main__
AXIS_A
Wikipedia
article
comments
equatorial
radius
=
same
value
AXIS_A
RADIUS
descriptive/accurate
name
video
argument
docstring
variables
en
file
sure
matter
MONTH_DAY_FORMAT
=
j
F
imporant
FIRST_DAY_OF_WEEK
=
sure
en
default
Sunday
DECIMAL_SEPARATOR
=
sure
default
en
fi
THOUSAND_SEPARATOR
=
'\xa0
Non-breaking
space
sure
default
en
nbsp
fi
fi
iso
stuff
python
DATE_INPUT_FORMATS
=
[
%
d.
%
%
Y
%
d.
%
%
y
%
d/
%
m/
%
Y
%
d/
%
m/
%
y
%
%
m-
%
d
'2006-10-25'
]
DATETIME_INPUT_FORMATS
=
[
%
d.
%
%
Y
%
H.
%
M.
%
S
%
d.
%
%
Y
%
H.
%
M.
%
S.
%
f
%
d.
%
%
Y
%
H.
%
M
%
d.
%
%
%
H.
%
M.
%
S
%
d.
%
%
%
H.
%
M.
%
S.
%
f
%
d.
%
%
%
H.
%
M
%
Y-
%
m-
%
d
%
H
%
M
%
S
'2006-10-25
%
%
m-
%
d
%
H
%
M
%
S.
%
f
'2006-10-25
%
%
m-
%
d
%
H
%
M
'2006-10-25
%
d/
%
m/
%
Y
%
H
%
M
%
S
%
d/
%
m/
%
Y
%
H
%
M
%
S.
%
f
%
d/
%
m/
%
Y
%
H
%
M
%
d/
%
m/
%
%
H
%
M
%
S
%
d/
%
m/
%
%
H
%
M
%
S.
%
f
%
d/
%
m/
%
%
H
%
M
]
reference
*
fi
https
//github.com/django/django/blob/master/django/conf/locale/fi/formats.py
values
file
*
en
https
//github.com/django/django/blob/master/django/conf/locale/en/formats.py
values
file
en_GB
https
//github.com/django/django/blob/master/django/conf/locale/en_GB/formats.py
reference
values
GB
i.e.
better
defaults
surprised
simple
fix
case
x
scalar
lambda
x
x
np.expand_dims
x
axis=0
@
fehiepsi
docstring
i
better
Hmm
pmap
lax.map
supports
batching
None
clear
init_params
None
rng
init_params
=
init
method
samples
map_fn
rngs
init_params
nit
property
redundant
useful
usage
comment
test
following
code
works
generates
distribution
constant
global
key
steps
incorrect
distribution
def
cond_function
val
i
_
_
_
=
val
return
i
~jnp.all
def
body_function
val
i
key
_
w
=
val
uni_ukey
uni_vkey
key
=
random.split
key
u
=
random.uniform
key=uni_ukey
shape=shape
dtype=dtype
minval=-1.
maxval=1
z
=
jnp.cos
jnp.pi
*
u
w
=
jnp.where
w
s
*
z
/
s
+
z
Update
y
=
concentration
*
s
w
v
=
random.uniform
key=uni_vkey
shape=shape
dtype=dtype
minval=-1.
maxval=1
=
y
*
y
=
v
|
jnp.log
y
/
v
=
y
return
i
key
|
u
w
init_done
=
jnp.zeros
shape
dtype=bool
init_u
=
jnp.zeros
shape
init_w
=
jnp.zeros
shape
_
_
_
u
lax.while_loop
cond_fun=cond_function
body_fun=body_function
init_val=
jnp.array
key
init_done
init_u
init_w
=
site
[
fn
domain
line
self._init_locs
=
above
comment
nit
models
sequences
plates
outside
transition_fn
users
enumeration
variables
plates
timesteps
issues
same
trick
plate
trace
substitute
plate
handler
inside
scan
wrapper
bad
nit
comment
example
old
new
shapes
fn
value
maintainability
Sorry
diag_embed
TODO
better
solution
diagonal
matrix
self.cov_diag
[
np.newaxis
]
*
np.identity
self.loc.shape
[
-1
]
line
SpanPredictionTask
s
QAMR
single-GPU
mode
recent
call
last
File
/home/pcy214/jiant/main.py
line
<
module
>
raise
re-raise
exception
case
debugger
/home/pcy214/jiant/main.py
line
<
module
>
main
sys.argv
]
/home/pcy214/jiant/jiant/__main__.py
line
main
phase=
target_train
File
/home/pcy214/jiant/jiant/trainer.py
line
train
output_dict
=
self._forward
batch
task=task
/home/pcy214/jiant/jiant/trainer.py
line
_forward
task.update_metrics
model_out
batch
/home/pcy214/jiant/jiant/tasks/tasks.py
line
update_metrics
=
sum
[
n_exs
]
.item
TypeError
'int
object
iterable
minimal
fix
type
int
s
single-GPU
mode
little
versions
WikiText103
data
*
version
train.txt
valid.txt
test.txt
[
wiki103-classif
task
]
https
//github.com/nyu-mll/jiant/blob/master/jiant/tasks/tasks.py
L2129-L2144
train.sentences.txt
valid.sentences.txt
test.sentences.txt
version
data
filename/comments
final
version
data
data
repo
\
*
Side
note
more
versions
data
data
repo
different
patterns
Same
comment
clear
lines
code
lines
edits
code
header
comment
Cut
sure
part
bit
commentary
looks
rename
convenient
one
clear
does/fixes
bit
default
libraries
top
group
sources
Rather
package
names
prefixes
separate
function
dict
local
package
names
versions
compare_versions
local
package
versions
logic
E.g
error
handling
python
local_package_versions
get_local_package_versions
distro_package_versions
get_distro_package_version
=
compare_versions
local_package_versions
distro_package_versions
PackageReport
function
package
versions
compare_versions
check
parameter
python
local_package_versions
get_local_package_versions
distro_package_versions
get_distro_package_versions
Produce
report
name
local_version
local_package_versions
report.add_to_report
name
distro_package_versions.get
name
local=
local_version
untested
code
Same
comment
ValueError
>
Exception
notes
docstrings
methods
context
manager
while
checks
reports
robust
something
import
warnings
warning_format
msg
cat
filename
linenum
file=None
line=None
'testtesttest
%
s
%
s
%
s
%
s\n
%
filename
linenum
cat.__name__
msg
class
CustomWarningFormat
def
__enter__
self._old_format
=
warning_format
def
__exit__
t
v
tb
=
self._old_format
Run
checks/reports
statement
warning
warnings.warn
'old
format
CustomWarningFormat
warnings.warn
'custom
format
warnings.warn
'old
format
Results
python3
warn.py
warn.py:18
UserWarning
old
format
warnings.warn
'old
format
testtesttest
warn.py
UserWarning
custom
format
warn.py:23
UserWarning
old
format
warnings.warn
'old
format
Similar
previous
comment
catch
error
failure
message
previous
comment
line
function
return
None
case
success
AFAICT
get_service_types
srv/
namespace
reason
namespace
names
function
Same
other
get_
_types
functions
suggestion
list
available
interface
types
package
suggestion
list
packages
interfaces
docstring
ros2topic
follow
PR
Same
similar
blocks
importer
view
comment
setting
float64
helpful
dtype
lanczos
good
class
class
DualFormulation
object
def
__init__
self.lzs_dtype
=
tf.float64
dtype
Lanczos
algorithm
def
construct_lanczos_params
self.m_min_eig
self.m_min_vec
=
self.min_eigen_vec
self.matrix_m_dimension
self.lzs_params
]
dtype=self.lzs_dtype
way
dtypes
E501
line
characters
E501
line
characters
suggestion
raise
ValueError
time
argument
integer
.format
time
little
pedantic
tests
test_init_datetime
test_init_datetime_subclass
test_init_datetime_long_timespan
short
comment
subclass
test
E231
whitespace
suggestion
def
_aggregate_recursive
df
variable
components=None
method=np.sum
Recursive
aggregation
variable
tree
docstring
hard
official
Params
Returns
section
General
comment
kwarg
name
future
current
eyes
e.g.
deprecation_warning
..
type=
..
suggestion
Read
timeseries
data
meta-indicators
frictionless
Data
Package
suggestion
Convert
notice
file
package
something
message
recent
runs
users
TODO
source
good
opportunity
early
os.path.exists
file_path
return
None
code
indented
type
stuff
wrong
overboard
/
kinda
enum
cool
closer
comments
small
nit
black
reformats
comments
single
line
parens
line
comment
own
line
Can
docstring
bit
context
cbsa
code
Please
_some_
sort
comment
motivation
somebody
future
comment
Could
docstring
property
@
property
def
indexed_data
return
bit
symmetry
accessing
self.data
self.indexed_data
implementation
char
state
fips
code
docstring
deep
code
loading
dfs
wrappers
docstring
function
fact
results
cumulatives
gotcha
easier
documentation
function
df
data
region
state
county
docstring
suggestion
Truncate
tables
suggestion
Store
boto3
connectors
Flask
application
context
API
terrible
function
top-level
presence
arg
different
functions
date
suggestion
Mark
CNUM
pid
record
suggestion
Override
single
condition
deleted
pids
user
cataloger
superuser
PIDDeletedError
raised.
hls.py
moment
https
//github.com/streamlink/streamlink/blob/096bc7a486f45201af2dce464f172cf4693186ec/src/streamlink/stream/hls.py
L366
suggestion
phot_data
Pandas
minor
docstring
cleanup
suggestion
storage_filename
str
small
adjustment
Sphinx
docstring
idea
https
//github.com/spacetelescope/drizzlepac/pull/307
issuecomment-481776421
manifest
empty
look
manifest
loop
specific
change
line
'pass
statement
lone
'raise
line
proper
Python
Section
Python
documentation
something
ValueError
Git
version
code
good
Python
practice
Same
comment
routine
convert
comparisons
lower-
upper-case
HDF5
file
CVS
file
point
variables
comments
file
format
agnostic
level
code
code
pandas_utils.py
fine
only
code
CSV
HDF5
portion
code
input
file
General
comment
entire
function
exact
metadata
terms
dictionary
keys
dict
metadata
trivial
keywords
1-to-1
relation
FITS
keywords
example
ID
'proposal_id
private
_
beginning
function
name
docstring
inputs/outputs
commentary
part
keyword
MEANNEXP
MEDNEXP
[
Mean|Median
]
*
*
_number
*
exposures
suggestion
master_list
=
metafunc.config.option.master_list
Check
file
exists
current
working
directory
os.path.exists
master_list
default
file
installation
directory
Find
module
install_dir
=
os.path.dirname
__file__
default_file
=
os.path.join
install_dir
master_list
os.path.exists
default_file
Copy
file
REQUIRES
'import
shutil.copy2
default_file
more
info
/
[
EAFP
]
https
//docs.python.org/2/glossary.html
term-eafp
try
KeyError
ValueError
KeyError
ValueError
issue
level
float
part
comment
function
decorator
@
add_common_docstring
*
*
_variables_for_parse_time_docstring
field
intended
reason
built
documentation
comment
line
sure
such
user
report
different
locations
LocalFile
DiracFile
GoogleFile
addition
default
upload
mechanism
GoogleFile
following
signatures
report
report
job=jobs
]
report
filetype=LocalFile
docstring
report
function
file
object
such
myreport
=
report
blank
line
docstring
blank
line
docstring
functions
file
present
API
reference
core.common
add
docstrings
directives
rst-files
need
types
arguments
docstring
name
universal_handlers
attributes
class
attributes
docstring
Todos
class
docstring
initialization
parameters
return
values
__call__
method
docstring
order
parameters
better
consistent
method
signature
suggestion
Reads
BoolQ
dataset
files
test
logs
Python
https
//stackoverflow.com/a/34677735/101923
===================================
FAILURES
===================================
____________
TestClientUpload.test_schema_from_json_with_file_path
_____________
=
<
tests.unit.test_client.TestClientUpload
object
>
def
test_schema_from_json_with_file_path
google.cloud.bigquery.schema
import
SchemaField
file_content
=
[
description
quarter
mode
REQUIRED
name
qtr
type
STRING
description
sales
representative
mode
NULLABLE
name
rep
type
STRING
description
total
sales
mode
NULLABLE
name
sales
type
FLOAT
=
[
SchemaField
qtr
STRING
REQUIRED
quarter
SchemaField
rep
STRING
NULLABLE
sales
SchemaField
sales
FLOAT
NULLABLE
total
sales
]
client
=
self._make_client
mock_file_path
/mocked/file.json
open_patch
=
mock.patch
read_data=file_content
>
open_patch
_mock_file
tests/unit/test_client.py:5202
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
.nox/unit-2-7/lib/python2.7/site-packages/mock/mock.py:1353
__enter__
self.target
=
self.getter
.nox/unit-2-7/lib/python2.7/site-packages/mock/mock.py:1523
<
lambda
>
getter
=
lambda
_importer
target
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
target
=
def
_importer
target
components
target.split
import_path
=
components.pop
thing
=
__import__
import_path
E
ImportError
module
builtins
Python
Python
version
[
sys.version_info.major
]
https
//stackoverflow.com/a/9079062/101923
actual
arguments
assert_called_once
docstring
create_bucket
same
pattern
BigQuery
type
param
Sphinx/RST-style
Google-style
Docs
Google-style
https
//sphinxcontrib-napoleon.readthedocs.io/en/latest/
example
file
https
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
example-google
BigQuery
method
Google-style
Nit
Import
pytz
same
import
group
google-cloud-bigquery
_pandas_helpers.list_columns_and_indexes
indexes
test
string
index
BigQuery
STRING
data
type
index
matches
table
https
//github.com/googleapis/google-cloud-python/blob/master/bigquery/google/cloud/bigquery/_pandas_helpers.py
L209
temporary
variable
set
iteration
columns_and_indexes
=
frozenset
_pandas_helpers.list_columns_and_indexes
dataframe
job_config.schema
=
[
field
field
table.schema
field.name
columns_and_indexes
comment
method
caller
_pause_resume_lock
added
all_entries
entries
same
comment
All
_Batch
code
self.entries
log_struct
nothing
commit
sure
docstring
necessary
space
i.e
more
field
print
logic
more
column
suggestion
query
=
SELECT
name
SUM
number
total_people
FROM
bigquery-public-data.usa_names.usa_1910_2013
state
=
GROUP
BY
name
state
ORDER
BY
total_people
DESC
LIMIT
new
comment
line
Comments
code
Run
documentation
example
snippets
TODO
add
delay
sleep
time
slower
keyboard
interrupt
test
futures.concurrent.wait
loop
example
people
Bucket
object
string
implementation
same
mechanism
reload
somehow
bucket
date
change
line
get_bucket
my-bucket-name
next
call
comment
Time
program
bucket
meantime
latest
state.
comment
L339
'dev
type
vim.Device
better
global
definition
VMGROUP
name
line
self.assert_parse_error
VMGROUP
+
create
comment
changes
same
comment
need
lines
Nit
readability
single
string
nicer
INSERT
IGNORE
....
SELECT
Need
documentation
liner
whole
message
Mark
comments
message
functionality
DB
removal
irreversible
operation
Please
use
local
flag
DB
SingeNode
mode
use
DB
MultiNode
mode
Note
shared
DB
current
ESXi
host
DB
config
rm
ESXi
hosts
DB
actual
DB
file
storage
sleep
HOSTD_RECONNECT_ATTEMPT
poweroff
events
shuklanirdesh82
>
comment
section
test-esx
ran
forgot
night
Stand
refresh
@
shaominchen
>
function
thing
thing
Well
Code
definition
different
things
code
reuse
besides
attach/detach
operation
thing
thing.
least
eyes
code
identical
taste
preference
different
taste
preference
mind
Return
error
None
OK.
def
attachVMDK
vmdk_path
vm_name
bios_uuid
vc_uuid
logging.info
*
*
*
attachVMDK
%
%
s
VM
uuid
=
%
s
vmdk_path
vm.config.name
vm_uuid
vm
=
findVm
vmdk_path
vm_name
bios_uuid
vc_uuid
return
disk_attach
vmdk_path
vm
Return
error
None
OK.
def
detachVMDK
vmdk_path
vm_name
bios_uuid
vc_uuid
logging.info
*
*
*
detachVMDK
%
%
s
VM
uuid
=
%
s
vmdk_path
vm.config.name
vm_uuid
vm
=
findVm
vmdk_path
vm_name
bios_uuid
vc_uuid
return
disk_detach
vmdk_path
vm
def
findVm
vmdk_path
vm_name
bios_uuid
vc_uuid
logging.info
*
*
*
findVm
vmdk_path=
%
w
%
s
bios_uuid=
%
s
%
s
vmdk_path
vm_name
bios_uuid
vc_uuid
vm
=
None
vc_uuid
vm
=
findVmByUuid
vc_uuid
vm
vc_uuid
VM
VC
uuid
logging.warning
VM
VC
UUID
%
s
BIOS
UUID
%
s
bios_uuid
vm
=
findVmByUuid
bios_uuid
vm
VM
VC
BIOS
uuid
msg
=
VM
%
s
%
s
%
s
%
vm_name
bios_uuid
vc_uuid
logging.error
msg
return
err
msg
vm.config.name
=
vm_name
logging.warning
vm_name
vSocket
%
s
VM
%
s
vm_name
vm.config.name
return
vm
big
concern
call
Thanks
Please
pylint
disable
statements
custom
command
group
nothing
calls
CalledProcessError
such
raise
CLIError
Thank
PR
<
>
safe
users
new
<
>
stdin
stdout
redirection
[
execution
]
https
//www.gnu.org/software/bash/manual/html_node/Command-Grouping.html
>
b
Output
ab
-bash
syntax
error
unexpected
token
%
safe
Windows
Command
Prompt
https
//ss64.com/nt/syntax-percent.html
security
team
best
solution
Possible
solutions
first
character
letter
number
rest
characters
punctuation
-_.~
warning
password
something
password
shell
interpretation
in_cloud_console
block
normal
exit
path
users
[
Ctrl+C
]
proxy
process
KeyboardInterrupt
Let
command
finish
user
presses
Ctrl+C
]
return
in_cloud_console
TODO
Better
error
requests.post
//localhost:8888/closeport/8001
Application
change
application
global
variable
unexpected
behaviour
Method
long
lack
comments
//CC
@
lmazuel
private
fields
Feel
free
adjustments
things
maintainable
e2e
test
coverage
fine
nit
extra
lines
comment
places
comment
right
section
block
comments
Everything
params.py
whole
docstring
comments
tests
self
explanatory
comments
approach
test
self-explanatory
comment
few
useful
ones
test
statement
clear
comment
perfect
example
over-commenting
sql
server
firewall
create
next
line
code
blocking
issue
PR
template
PEP8
Okay
comments
print
functions
import
line-too-long
bad-continuation
good
reasons
easy
important
readability
disable
inline
use
entire
file
gzrs_name
=
self.create_random_name
prefix='cligzrs
length=24
=
'Standard_GZRS
above
lines
suggestion
https
//docs.microsoft.com/azure/azure-stack/user/azure-stack-version-profiles-azurecli2
connect-to-azure-stack
[
PEP257
]
https
//www.python.org/dev/peps/pep-0257/
one-line-docstrings
triple-double-quote
custom_path
+
format
little
bit
.format
function
others
X
format
whilst
custom_path
+
variable
commands
same
method
variable
enum
case
value
changes
future
Python
kwags
[
'edition
]
=
MyEnum.DataWarehouse.value
.value
enum
type
validator
better
base
string
variable
Python
custom_path
=
'azure.cli.command_modules.documentdb.sdk.operations.database_accounts_operations
cli_command
'documentdb
list
custom_path.format
'DatabaseAccountsOperations.list_by_resource_group
cf_documentdb
first
examples
simple
usage
command
specific
condition
other
aks
subcommands
documentation
argument
resource-group
variables
use
_
style
derekbekoe
final
comment
group
fine
only
concern
global
config
meaning
easy
group
lots
other
things
none_default
use_enabled_disabled
clear
names
descriptive
name
method
comments
args
comment
sure
default
value
function
None
line
comments
intention
helpful
suggestion
self.cmd
digitaltwin
key
list
-e
endpoint
-r
[
'id
]
comments
raise
CLIError
[
]
length
=
PR
help
text
help
text
help.py
double
quote
pylint
check
dictionary
able
sensitivity
label
class
python
sdk
guids
Use
SDK
https
//docs.microsoft.com/en-us/python/api/azure-mgmt-sql/azure.mgmt.sql.models.samplename
view=azure-python
adventure-works-lt
Python
def
_get_parsed_resource_ids
resource_ids
cmd_str
Validates
parses
item
resource_ids.
resource_ids
return
None
rid
resource_ids
rid
raise
CLIError
resource
%
s
error
argument
ids
invalid
ResourceId
value
%
s\
%
cmd_str
rid
return
parse_resource_id
rid
rid
resource_ids
_get_res_util_from_parsed_id
parsed_id
api_version
return
_ResourceUtils
parsed_id
[
'resource_group
]
parsed_id
[
'resource_namespace
]
parsed_id
[
'resource_parent
]
parsed_id
[
'resource_type
]
parsed_id
[
'resource_name
]
None
api_version
def
_create_parsed_id
resource_group_name=None
resource_provider_namespace=None
parent_resource_path=None
resource_type=None
resource_name=None
return
resource_group_name
resource_provider_namespace
parent_resource_path
resource_type
resource_name
def
_single_or_collection
default=None
obj
return
default
isinstance
list
return
return
obj
fine
clear
CMD
sure
case
clear
shell-supported
keyword
exit
quit
clear-history
alternative
syntax
bash
users
clear
CMD
users
cls
crazy
CMD
user
shell
cls
little
weird
clear
shell
cls
intuitive
damn
C
snuck
head
help
entry
rules
command
group
scenario
sense
list
linter
union
something
Python
def
find_command_or_group_help
name
Return
help
entry
specified
command
command
group
None
return
self._master_help.get
name
None
comment
way
Aladdin
period
time
repeated
errors
scenarios
user
air-gapped
cloud
able
service
way
model
query
service
cycles
endpoint
user
temporary
internet
outage
disabling
time
limit
feature
Same
comment
DbfsApi
test
name
test_deploy_valid_stack_status
clear
test_deploy_config
main
method
docstring
deploy_config
method
correct
status
suffice
WARNIN
bad
style
program
more
sense
comments
status
file
warning
PR
docstring
ditto
true
true
stdlib
semaphore
one
exception
number
available
leases
larger
value
class
documentation
afraid
misleading
Please
comment
meaning
return
value
particular
users
case
failed
release
anything
release
function
user
scenario
likely
scenario
connection
lease
ID
internal
tracking
many
times
exception
stand-alone
documentation
somewhere
small
docstring
motivation
small
example
following
client
Client
client.to_scheduler_file
'scheduler.json
client2
=
Client
scheduler_file='scheduler.json
connect
previous
client
scheduler
changes
Thanks
comments
pentschev
question
docstrings
duration
attribute
total
time
same
group
prefix
duration_average
weighted
average
scale
requests
current
scale
request
scale
Spec
correct
state
task
start
task
scale
returns
scale
Spec
previous
call
progress
state
new
workers
Spec
tasks
sync
multiple
await
calls
_correct_state_internal
worker_spec
different
different
points
function
potential
bugs
naive
solution
background
task
event
await
self._spec_updated.wait
update
workers
spec
clear
event
things
date
things
date
self.spec_matches_current_state
self._spec_updated.clear
_correct_state
def
_correct_state
event
loop
synchronization
tons
tasks
event
self.sync
async
def
self._state_updated.set
likely
other
ways
dask-gateway
task
worker/scheduler
spec
unfinished
tasks
new
ones
previous
scale
call
progress
cluster
scale
call
Note
only
blocks
internal
task
state
new
tasks
tasks
more
few
threads
test
test
other
test
thread
few
tests
text
comment
>
Anecdotally
blosc
numeric
data
such
numpy
arrays
pandas
dataframes
lz4
better
choice
data
other
sources
memoryview
strong
signal
data
numeric
data
current
approach
old
behavior
example
image
data
blosc
better
choice
Small
nitpick
suggestion
WorkerPlugin
local
file
workers
small
docstring
least
API
documentation
important
small
docpage
rewrite
lot
looping
dict
building
necessary
client
scheduler
need
nodes
dict
node_packages
dict
logic
pseudocode
preprocessing
node_packages
building
loop
top
complicated
client
=
client
dict
packages
=
scheduler
dict
packages
workers
workers
mapping
id
>
dict
packages
packages
client
scheduler
worker
package
packages
versions_dont_all_match
errs.append
notes_mismatch_package
notes.append
suggestion
class
sticker
image
suggestion
sticker
messages
nothing
message
suggestion
class
datetime.datetime
sticker
creation
time
UTC
naive
datetime
suggestion
class
datetime.datetime
sticker
creation
time
UTC
suggestion
Optionally
class
sticker
image
way
current
implementation
last
column
label
column
documentation
messages
users
documentation
method
purpose
documentation
reference
model
Trainer
object
method
documentation
much
shorter
get_oof_pred
documentation
bit
worried
users
names
Predictor.leaderboard
documentation
leaderboard
df
worth
suffix
pred_time_val
_full
suffix
Options
suffix
_base
_extra
_solo
_marginal
user
output
i.e
internal
operations
Otherwise
statement
documentation
Transforms
label
objects
y
correct
type
distillation
regression
targets
binary
one-hot
labels
multiclass
TODO
disable
early
stopping
refit_full
small
comment
old
code
enumerate
Include
small
example
documentation
function
bit
opaque
example
argument
PEP8
semantic
name
nontrivial
function
similar
minor
nit
comments
readability
PEP8
violation
IDE
line-length
limit
PEP8
recommendation
most
others
such
new
lines
def
class
new
lines
imports
code
critical
code
afterwards
something
mind
future
PR
process
smoother
loss
function
confusion
E501
line
characters
E262
inline
comment
sure
DeprecationWarning
choropleth
threshold_scale
parameter
favor
bins
parameter
ideal
way
script
error
online
python
warnings.warn
choropleth
threshold_scale
parameter
favor
bins
parameter
DeprecationWarning
Notebook
unit
test
other
hand
suggestion
suggestion
return
_only_
run
test
sentence
function
safe_infer
pylint.checkers.utils
function
None
astroid.Uninferable
sure
values
=
safe_infer
node.slice.value
elem
elem
astroid.Uninferable
check
isinstance
astroid.Instance
Instances
classes
getattr
check
simple
value
right
hand
side
string
Const
guard
something
lines
trick
isinstance
rhs
astroid.Const
isinstance
rhs.value
str
return
=
utils.safe_infer
rhs
return
isinstance
astroid.Const
isinstance
inferred.value
str
message
ids
messages
pylint
enable=C0103
instance
case
sense
check
something
use-symbolic-message-instead
something
lines
hippo91
access
ids
multi-line
docstrings
Same
comment
operation
_ENCRYPT
Comments
origins
Docstring
set
_literal_
function
call
literal
item
item
item
minor
comment
readable
try
import
pyi_example_package
pass
ValueError
]
https
//github.com/pyinstaller/pyinstaller/blob/924f461a5dc87af05a8a3ff2d1618ddea5f65981/PyInstaller/utils/hooks/gi.py
L45
GdkPixbuf
behavior
b
contrary
comment
Did
@
BenHenning
comment
comment
line
something
Note
audio
files
asset
downloads
See
notes
use
cli
comments
comment
Python
HTML
CSS
more
smile
True
False
please
use
self.assertTrue
..
reference
functions
unittest
module
documentation
[
]
https
//docs.python.org/2/library/unittest.html
unittest.TestCase.assertTrue
comment
correct
line
code
time
function
state
name
right
right
arg
list
function
least
multi
version
others
other
functions
more
work
full
lists
states
mappings
comment
orthogonal
discussion
function
state
name
multiple
state
names
next
line
more
info
internal
structure
dict
other
docstrings
examples
platform
parameter
registry
end-to-end
flow
change
admin
panel
admin
panel
Per
comment
tests
one
>
checks
getter
response
correct
>
checks
parameters
services
no-prechecking
test_post_flag_changes_correctly_updates_flags_returned_by_getter
>
pre-update
getter
check
update
post-update
getter
check
different
cases
suggestion
POST
requests
Evaluates
returns
feature
docstring
Handles
GET
request
Add
documentation
member
variables
python
Method
member
variables
handler
Attributes
exp_issues
TYPE
DOCSTR
issue_schema_version
TYPE
DOCSTR.
few
comments
method
name
more
issue
list
index
separate
issue_type
customization_args
part
single
object
sense
entire
object
pieces
equivalent
playthrough
exact
identical
playthrough
present
code
python
lsts
[
[
]
]
]
l
lsts
doc
False
print
[
]
code
True
index
print
[
]
==
l
sense
nit
use
temporary
variable
issue
=
self.exp_issues.unresolved_issues
issue_index
]
line
shorter
Add
playthrough_id
changes
input
arguments
pass
*
args
*
*
Python
def
__init__
args
*
*
kwargs
super
StorePlaythroughHandler
self
.__init__
*
args
*
*
kwargs
initialize
members
class
future
changes
base.BaseHandler
kind
information
test
name
comments
something
def
test_base_class_get_instance_id_raises_not_implemented_error
commented-out
code
comments
way
more
explanation
context
rootdir
filename
Please
developers
idea
function
docstring
skill_domain.Skill
@
classmethod
unit
tests
https
//github.com/oppia/oppia/pull/4952/files
diff-f539af1da991345c436a49a41821b7e3R820
similar
comment
[
]
https
//github.com/oppia/oppia/pull/4952
discussion_r192573612
contrast
previous
comment
object
redirect
least
assertion
redirects
correct
response
first
place
Ditto
other
topic_services.delete_story
topic
story_id
method
topic.delete_story
changelist
sure
lists
story_ids
canonical
ones
way
future
prominent
note
docstring
NOTE
TO
DEVELOPERS
present
only
canonical
story
IDs
latter
course
action
better
Please
description
docstrings
typeinfo
current
codebase
convention
args
yields
parts
docstring
wrong
function
dict
suggestion
email
content
info
objects
key
information
docstrings
types
errors
property
properties
documentation
suggestion
timedelta_obj
datetime.timedelta
Datetime
formatting
consistent
other
docstrings
suggestion
Unit
tests
core.domain.recomendations_validators
more
change
topic
property
backlink
updated
such
change
commit
process
interesting
change
topic
story
vice
versa
design
topic-to-story
mapping
particular
part
topic
topics
info
reverts
topics
sure
user
anything
Please
backend
test
case
worth
docstring
circumstances
handler
E.g
something
handler
user
least
exploration
story
Remove
space
Domain
suggestion
Unit
tests
core.domain.classifier_validators
previous
line
one-line
docstrings
Hi
@
michaelw54
great
IAstroidChecker
[
IToken
comments
related
checks
wrong
string
comment
core.platform.datastore
future
possible
field
values
strings
comments
Please
*
*
docstrings
*
order
errors
format
Id
documentation
similar
changes
function
name
Args
Returns
docstring
Could
comments
Please
docstring
prose
description
E.g
creation
users
users
private
explorations
other
user
public
collection
User
subscribes
Etc
example
state
world
GCS
compatibility
copy
comment
cloudstorage.copy2
line
use
copy2
docstring
normalization
normalized
version
python
library
name
Normalization
library
name
[
]
suffixes
reason
examples
ambiguities
process
catches
something
lowercase
google-api-core
[
grpc
]
means
[
]
something
lines
Please
double
check
previous
comments
end
previous
line
one-line
docstrings
new
commit
doc
strings
corrections
@
seanlip
above-mentioned
indent
comments
end
sean
comment
implementation
None
Please
case
docstring
Make
sure
docstrings
value
Write
descriptions
self-contained
Someone
familiar
logic
exact
format
user
data
dictionary
able
descriptions/docstring
names
attributes
comment
keyname
different
thing
data
url
more
first
arg
None
None
sentinel
value
state
belongs
Question
docstring
State.validate
incomplete
list
Drop
specific/actionable
TODOs
requirements
fine
added
new
feature
file
contents
_mock_get_all_actions
class-level
function
BaseSkillEditorControllerTest
Add
short
permissions
mock
non-admin
users
indentation
wrong
other
docstrings
rest
Python
code
sure
strings
version
number
int
documentation
Test
docstrings
Test
Please
fix
minor
comment
good
practice
xrange
range
Done
Sorry
different
approach
implementation
docstrings
next
time
See
previous
comment
args
Please
args
implementation
consistent
other
functions
See
previous
comment
Raises
separate
section
Returns
above
comment
rewrite
number
models
failure
messages
default
maximum
errors
multiple
errors
same
type
Note
behaviour
subclass
more
errors
yield
statement
values
first
comment
is/what
ids
types
please
docstring
bit
unhelpful
message
docstring
something
message
Save
output
stream
docstrings
write
mention
pylint
Args
=
sign
thread.message_count
=
feedback_models.GeneralFeedbackMessageModel.get_message_count
thread.id
@
apb7
@
space
pylint
pragma
lint
checks
test
more
robust
case
output
NO-OP
Drop
space
TODO
Explain
TODO
link
issue
state_name
property_name
docstring
v1
job
Wrong
re
naming
other
comments
e.g
specific
skill
ID
problematic
Hi
@
abeerunscore96
suggestions
clearer
request
handler
internal
requests
taskqueue
workers
request
invalid
Error
page
succinct
different
cases
addition
inline
comment
docstring
line
lines
Internal
requests
X-AppEngine-TaskName
header
cloud.google.com/appengine/docs/standard/python/taskqueue/push/
line
top-level
docstring
implementation
detail
good
thanks
URL
great
ids
exploration
line
Sorry
last
comment
clear
test
bit
clearer
descriptive
earlier
comment
English
clauses
e.g
test_simple_story_is_deleted_when_
Ditto
Ditto
domain
objects
other
docstrings
Raises
previous
comment
other
comment
valid
asciimath
expression
subset
asciimath
docstring
method
definition
validity
file
non-private
exploration
summaries
recommendations
concepts
sure
rationale
test
least
explanation
comments
total
same
comment
re
clearer
documentation
keys
values
None
check
subprocess
API
many
Python
developers
brief
comment
conditional
means
e.g
more
output
process
loop
something
similar
next
line
multiline
docstrings
general
brief
comments
block
block
code
removes
skills
subtopics
topic
block
code
deleted
skills
topics
general
reviewer
something
explanatory
comment
code
something
code
obvious
fellow
developer
next
request
reviewer
please
comments
code
round
review
way
prod
validation
jobs
I.e
requirement
subtopic
topic
deleted
skills
suggestion
provided
interaction
Android
args
confused
'answers
list
string
other
places
inline
comment
transaction
context
future
folks
code
period
end
ditto
comment
sure
html
files
Could
obvious
inline
comment
Use
domain
objects
possible
other
docstrings
type
list
ndb.Model
docstring
description
incomplete
return
value
input
value
list
management
caller
example
[
[
'CompletedActivitiesModel
[
user_id
another_user_id
]
]
[
'IncompleteActivitiesModel
[
user_id
]
]
]
return
value
[
[
CompletedActivitiesModel1
CompletedActivitiesModel2
]
[
IncompleteActivitiesModel1
]
]
'handler
arg
suggestion
Checks
validation
errors
valid
exploration
general
avoid
pylint
pragmas
necessary
suggestion
actual_output
=
job_id
pylint
disable=line-too-long
suggestion
Checks
type
variable
'any'
TypeScript
files
docstring
reference
fact
job
v1
statistics
special-casing
Add
single
space
OK.
field
>
field_name
[
]
==
data
dict
docstring
use
len
list
mistake
something
cls._rte_components
docstring
dict
mapping
RTE
component
IDs
definitions
similar
swap
explanation
surface
relation
CAN_SEND_EMAILS
register_failure
method
side-effects
docstring
Description
function
name
Please
fix
Done
docstring
groups
Ah
good
catch
comment
check
weird
check
first
one
later
part
string
check
docstring
good
better
way
line
number
completion
Wrong
fileoverview
docstring
equal
from_version
to_version
exception
Raises
section
docstring
Ditto
Re
Function
comments
re
formatting
one-line
comment
v1
devs
anomaly
different
commmitter_id
creator_id
comment
code
clear
developer
code
addition
something
random_user_id
implicit
association
IDs
explanation
IIUC
case
committer
ID
creator
ID
same
person
reason
conceptual
baseline
user
user_id
Hm
vision
controller
topic
viewer
page
Renders
topic
viewer
page
right
field
name
docstring
entire
suggestion_services
domain
object
dimensions
nested
dicts
keys
structure
complex
other
comments
docstrings
explanation
comments
Hopefully
purpose
paths/rules
docstring
rules/patterns
things
confusing
arg
important_patterns
Please
docstrings/argname/descriptions
profile
users
functionality
previous
discussion
review
comments
handler
similar
build_files
Yep
incorrect
file_formats
None
filename.endswith
p
p
file_formats
task
=
target=minify_func
args=
source_path
target_path
file_hashes
filename
Skip
files
format
continue
task
=
target=minify_func
args=
source_path
target_path
file_hashes
filename
tasks.append
task
continue
statement
key
type
elements
list
e.g
list
int
list
str
end
docstring
file
>
files
Ah
design
doc
comment
above
suggestion
other
functions
contract
more
exploration
id
....
docstrings
standard
format
Args
Returns
Nit
full
stop
end
docstring
wrong
Hmm
full
names
args
attrs
convention
include
docstrings
Need
docstrings
pattern
e.g
top
user_services.py
docstring
function
case
model
case
practice
case
mapping
spelling
corresponding
docstring
central
point
method
message
IDs
list
message
IDs
read
user
models
method
feedback
user
models
threads
method
original
comment
extra
feedback
thread
user
models
equivalent
feedback
thread
user
model
instances
first
suggested
revision
second
parallel
structure
....
output
doctest
documentation
current
code
docstring
useful
fixture
useful
]
test
object
e.g.
class_list
def
test_listed_cmap_3_classes
vals_missing_plot_list_cmap
Test
legend
cmap
user
classes
legend
classified
image
user
1-5
im_ax
arr
=
vals_missing_plot_list_cmap
class_list
=
list
range
leg
=
ep.draw_legend
im_ax
classes=class_list
=
[
i.get_facecolor
i
leg.get_patches
assert
len
legend_cols
class_list
plt.close
2-dim
arr
fixture
[
np.newaxis
]
third
dimension
Docstring
2-dimensional
arr
ValueError
few
suggestions
array
array
2-dim
arr
axis
first
test
docstring
2-dimensional
array
shape
Same
suggestion
plot_bands
line
jlpalomino
i
patch
GH
line
lines
text
renders
text
comments
hey
important
information
order
data
Will
part
docstring
Same
comment
important
information
docstring
information
cmap
example
optional
defaule
value
cols
same
fixture
clarity
Get
titles
comment
unnecessary
method
e.g.
def
test_two_plot_title
image_array_3d
Test
default
title
band
array
plot
fig
ax
=
es.plot_bands
image_array_3d
ax
=
fig.axes
num_plots
image_array_3d.shape
]
plot_titles
[
[
i
.get_title
i
range
num_plots
assert
plot_titles
[
]
im_arr
environment
function
harder
test
fixture
im_arr
e.g.
image_array_3d
fixture
test
way
objects
test
def
test_num_titles
image_array_3d
user
titles
single
band
array
function
error
title
list
different
length
array
errors
single_band
=
image_array_3d
]
pytest.raises
ValueError
es.plot_bands
arr=single_band
Title1
Title2
]
pytest.raises
ValueError
es.plot_bands
arr=image_array_3d
Title1
Title2
Title3
]
Same
comment
test
module-level
data
object
fixture
def
test_num_axes
image_array_3d
band
array
plot_bands
axes
default
fig
ax
=
es.plot_bands
image_array_3d
assert
fig.axes
TODOs
username
Example
TODO
chaseriley
Move
loop
Same
comment
zip
docstring
informative
shapes
tensors
unneeded
import
use
brackets
pylint
remove
code
jit
command
code
Add
pytype
disable=wrong-arg-types
line
build
Same
comment
tests
tests/
modules
Delete
code
pylint
check
loop
Delete
code
update
comment
update
comment
single
site
version
todos
Last
comment
validator
+
switch
order
language-specific
tokenizer
use
test
suite
pytest.raises
error
test_noun_chunks_is_parsed_de
de_tokenizer
Test
Value
Error
'de
language
Doc
test
Doc
new
Vocab
sure
noun
chunks
doc
=
de_tokenizer
Er
lag
auf
seinem
=
False
pytest.raises
ValueError
list
doc.noun_chunks
tokenizer
language
lg_tokenizer
language
lg
other
comment
name
mandatory
URL
params
dict
requests
readable
python
params
=
'yes
%
s
%
str
c
c
categories
'clear-new
params=params
requests
suggestion
error
message
OP
error
error
message
error.message
field
response
comments
helpful
valid
values
method
kinds
keyword
arguments
prefix
r
string
regular
expression
refactor
sense
fixture
@
pytest.fixture
def
args
=
_random_identifier
'TestModel
model
=
ml.create_model
ml.Model
*
*
args
yield
model
args
_clean_up_model
model
pytest.fixture
scope='module
def
tflite_format
Create
model
format
file
return
Thought
bit
module-scoped
fixture
things
bit
@
pytest.fixture
def
full_model
tflite_format
tflite_format
fixture
=
_random_identifier
'TestFullModel
[
'test
]
tflite_format
model
=
ml.create_model
ml.Model
*
*
args
yield
model
args
_clean_up_model
model
def
test_create_simple_model
name_only_model
model
args
=
name_only_model
check_model
model
args
call-site
sure
multiple
calls
same
fixture
identifiers
part
more
times
anything
concrete
Same
applies
verbose
description
something
lines
def
convolution_matrix
n
mode='full
Construct
convolution
matrix
dense
matrix
one-dimensional
convolution
]
_
=
convolution_matrix
n
[
]
matrix
such
A
@
v
equivalent
convolve
v
[
]
input
array
triplet
[
x
y
z
]
default
mode
partial
overlaps
effects
[
x
]
[
y
x
]
[
z
y
x
]
'valid
mode
rows
complete
overlap
occurs
top
rows
example
invalid
'same
mode
max
row
number
partial
overlaps
sufficient
rows
suggestion
multivariate
t-distributed
random
variable
rendering
top
level
stats
page
[
image
]
https
//user-images.githubusercontent.com/6570539/92642386-f522c680-f294-11ea-9ba3-780015e238b3.png
Mahalanobius
distance
variable
names
[
]
https
//github.com/scipy/scipy/blob/master/scipy/stats/_multivariate.py
L474
Happy
comment
unclear
correct
PSD
docstrings
multivariate_normal
code
_PSD
utility
class
references
positive
definite
positive
semidefinite
nice
periodicity
similar
[
]
p1
=
PPoly
[
]
]
]
]
]
p1
[
]
]
array
[
]
]
p2
=
PPoly
[
]
]
]
]
extrapolate='periodic
]
p2
[
]
+
period
=1
Out
]
array
[
]
review
comment
latest
commit
OK
change
next
comment
docstring
reference
>
Yes
lines
characters
sense
preference
conform
noqa
E501
s
necessary
violations
PEP8-compatible
code
easier
next
person
easier
CIs
green
1-2
char
ones
PR
pretty
easy
readability
suggestion
trapezoid.__doc__
=
trapezoid.__doc__.replace
cumsum
'numpy.cumsum
noqa
E501
end
line
fine
overkill
noqa
ing
PEP8
violations
adjust
scipy-PR-reviewing
criteria
flexible
stuff
lint
noqa
E501
typo
suggestion
test
correctness
implemented
Taylor
Windowing
CIs
line
length
error
suggestion
noqa
E501
/home/circleci/repo/build/testenv/lib/python3.7/site-packages/scipy/signal/windows/windows.py
docstring
scipy.signal.windows.taylor:69
WARNING
Exception
scipy-signal-windows-taylor-1
/home/circleci/repo/doc/source/generated/scipy.signal.windows.taylor.rst
Traceback
recent
call
last
/home/circleci/repo/venv/lib/python3.7/site-packages/matplotlib/sphinxext/plot_directive.py
line
run_code
exec
code
ns
<
string
>
line
<
module
>
AttributeError
module
'scipy.signal
attribute
suggestion
>
>
>
window
=
signal.windows.taylor
sll=100
suggestion
shuffle_input=True
maxiter=30
tol=0.05
order
randomization
parameters
adjacent
termination
criteria
adjacent
Docstrings
suggestion
solution
quadratic
assignment
problem
graph
matching
problem
text
documentation
text
__init__.py
rid
comment
error
pytest.raises
ValueError
match='some
regex
expected
error
clear
fforword
self.data
shape=self.data.shape
]
axes=
correct
approach
comment
Thanks
helpful
similar
case
relevant
part
result
closer
bit
wary
numbers
level
1e-7
rate
comment
calculation
number
hand
way
x
y
difference
ranks
elements
other
words
notation
wikipedia
https
//en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient
d_i
times
sum
d_i
*
*
=
denominator
*
=
mixed
fraction
couple
powers
+
extra
+
+
Spearman
rho
minus
value
final
answer
-1/2666666
3.75e-7
>
>
>
/
3.7500009375002346e-07
good
returned
value
[
-1,1
]
region
~21.341
fix
machine
correct
answer
robust
different
kinds
precision
problems
possible
numbers
such
way
returned
value
region
[
-1,1
]
unlikely
_more_
someone
future
checks
function
sure
output
bounds
[
-1,1
]
Pearson
calculation
>
small
artifact
point
arithmetic
r
=
min
r
r
=
max
r
-1.0
someone
same
thing
Spearman
calculation
bounds
[
-1
]
non-functional
regression
test
scipy.special
function
ppf
explicit
rvs
method
much
faster
http
//www.stat.rice.edu/~dobelman/textfiles/DistributionsHandbook.pdf
first
links
Google
rejection
method
uniform
random
variables
kind
methods
cython
numpy.random
b
scale
parameter
super
class
comment
similar
one
_pdf
code
suggestion
string
size
output
documentation
correlate
more
information
<
=
wlen
readable
None
wlen
=
operators.index
int-ness
raise
ValueError
Always
code
Minor
comment
lwork
=
_compute_lwork
gels_lwork
m
routine
scipy.linalg.lapack
import
_compute_lwork
intervals
double-checking
kind
odd
able
*
pi
input
half-open
intervals
docstring
incorrect
open
interval
>
pi
checks
_closed_
interval
LSQSphereBivariateSpline
]
consistent
Please
comment
numbers
imagine
years
line
someone
stares
lines
comment
numbers
line
implicit
scipy
docstring
examples
references
class
documentation
methods
Use
appropriate
value
rtol
assert_almost_equal
preference
docstring
assert_almost_equal
suggestion
assert_allclose
HG
NHG
rtol=1e-10
code
more
thought
SVD
necessary
QR
decomposition
simplified
code
_geometric_slerp
start
end
t
orthogonal
basis
QR
decomposition
basis
=
np.vstack
[
start
]
Q
R
=
np.linalg.qr
basis.T
signs
np.sign
np.diag
R
Q
=
Q.T
*
[
R
=
R.T
*
[
]
start
=
Q
angle
c
=
np.dot
start
end
s
=
np.linalg.det
R
=
np.arctan2
s
c
interpolate
s
=
np.sin
t
*
omega
c
=
np.cos
t
*
omega
start
*
c
[
np.newaxis
]
+
*
s
[
]
relationship
SVD
QR
https
//en.wikipedia.org/wiki/QR_decomposition
Connection_to_a_determinant_or_a_product_of_eigenvalues
arrays
smaller
Be
consistent
markup
f
text
\
f\
\
f\
\
\
f\
fine
\
c\
c
numpy
standard
single
backticks
parameters
f
parameter
name
pdf
same
Might
single
backticks
isolated
occurrences
A
R
double
backticks
expressions
Text
single
backticks
italics
double
backticks
monospace
text
i.e
code-like
perfect
limitation
reStructuredText
possible
use
math
markup
mathematical
variables
expressions
unrendered
docstrings
web
versions
heavy
use
LaTeX
markup
fine
*
backticks
*
mathematical
*
variables
expressions
actual
function
parameter
names
Python
code
everyone
acceptable
variable
case
example
set
A
=
v
<
u
<
=
sqrt
f
v/u
+
c
OK
mini-rant
limitations
Sphinx
reStructuredText
only
change
*
consistent
Sorry
hashmap
*
*
*
name
*
*
*
docstring
something
Create
hashmap
bin
ids
values
bins
Reason
Hungarian
notation
types
names
good
idea
duck
languages
private
function
future
kind
descriptive
names
future
implementation
hashmap
other
data
structure
name
hashmap
implementation
something
independent
name
bit
magic/hackery
safer
underlying
array
names
various
formats
many
distinct
cases
way
comment
good
magical
please
comment
r
such
\
math
environment
issues
refguide_check
Should
comment
part
code
people
mind
_build_dns_conf
result
loop
Sorry
😕
P
comment
sense
difference
schema
process
schema
parameter
self.schema
added
field
schema
Rename
variable
comment
difference
Just
idea
sense
function
docstring
Please
example
concise
py
import
Callable
pydantic
import
BaseModel
class
Foo
BaseModel
callback
Callable
[
[
int
]
int
]
m
=
Foo
callback=lambda
x
x
print
m
Foo
callback=
<
function
<
>
>
Taken
verbatim
other
plugins
format
consistent
doc
strings
useful
methods
rename
get_flat_models_from_fields
reuse
get_flat_models_from_model
/definitions/
many
times
Better
global
variable
default_prefix
ref_prefix=None
ref_prefix
=
ref_prefix
noqa
C901
complexity
today
changes
way
recent
changes
method
comment
docstring
comment
PR
docstring
comment
tp
None
crappy
code
conlist
fact
cython
cant
handle
Generic
inheritance
See
comment
work
new
feature
documentation
above
thanks
fix
TypeX
=
TypeVar
'TypeX
TypeY
=
TypeVar
'TypeY
TypeZ
=
TypeVar
'TypeZ
class
BaseClass
GenericModel
Generic
[
TypeX
TypeX
]
x
TypeX
y
TypeY
class
ChildClass
BaseClass
[
int
TypeY
]
Generic
[
TypeY
TypeZ
]
z
TypeZ
x
type
int
y
z
type
str
print
ChildClass
[
str
str
]
x=1
y=
y
z=
z
Raises
section
Please
correct
docstring
list
comprehension
likely
=
>
_SUPPORTED_KEYS
=
frozenset
LINE_STRUCTURES.keys
repeat
previous
comment
docstring
fix
Returns
user
Let
mention
docstring
do
definition
class
string
ack
note
exact
todo
parsers
event
data
update
event_data_identifier
event_data_row_identifier
event
update
docstring
update
event_data_identifier
event_data_row_identifier
event
tag
update
docstring
@
kprzerwa
UI
real
cover
placeholder
more
customization
solution
extra
field
is_placeholder
true/false
final
return
is_overbooked
=
document.get
circulation
.get
None
NOTE
document
field
abort
elif
is_overbooked
==
True
raise
InvalidLoanExtendError
extension
due
high
demand
literature
Please
library
loan
extension
LoanOwnerPermission
loan
Add
comment
please
minor
docstring
Docs
comments
file
need
Item
EItem
consideration
previous
comment
record
[
state
]
ACCEPTED
report
same
comment
multiple
times
moderator
error
decision
backend
earlier
reports
archival
bit
cringe-y
better
idea
possibility
view
function
commentset.views.url
Sentence
case
New
comment
]
docstring
keys
insert
functionality
assumed
order
rows
keys
way
more
clarification
documentation
clear
usage
parameters
function
current
documentation
rows
keys
examples/adding
clarification
docstring
Suggestions
sure
general
comment
function
example
usage
helpful
documentation
insufficient
way
clean
code
order
importance
modular
self-explanatory
well-documented
example
usage/tutorial
need
list
code
complexity
example
nice
compact
complex
piece
code
point
great
standard
readability
sake
maintainability
developer
efficiency
more
succinct
logs
expected
error
None
asset
=
self.create_dataset_asset
self.assertLogs
level=
ERROR
logger
url
=
asset.generate_file_url
self.assertIn
presigned
URL
]
self.assertIsNone
url
comment
ticket
serializer_class
OrderingFilter.get_default_valid_fields
part
self.get_ordering
request
queryset
view
view
'get_serializer_class
try
serializer_class
=
view.get_serializer_class
AssertionError
default
implementation
serializer_class
serializer_class
=
None
serializer_class
=
getattr
view
'serializer_class
None
views
serializer_class
serializer_class
request
method
view.get_serializer_class
TODO
following
classes
docstrings
non-sparse
classes
link
documentation
standard
api
endpoint
complete
sense
documentation
new
sparse
endpoints
process
test
approval
something
original_justification
withdrawal_request.comment
start
test
target.withdrawal_justification
var
approval
view
concern
build
node
way
first
node
message
comments
email
form
digest
email
notification
email
actions
time
period
action
single
node
multiple
nodes
user
access
node
result
notification
other
node
setting
node
correct
docstring
lines
possible
refactor
python
True
local_flow
=
self.state.local_flow_control_window
stream_id
connection_flow
=
flow
=
min
local_flow
connection_flow
flow
await
self.receive_events
timeout
flow
current
implementation
docstring
property
practice
chunk
content
least
better
names
.can_replay
.can_read_multiple_times
.is_isomorphic
🤣
docstring
base
implementation
docstrings
public
Developer
Interface
near
future
😉
suggestion
response.cookies.get
test_ignore_transfer_encoding_header_if_content_length_exists
linking
issue
Rather
time
NETRC_FILES
module
level
def
get_netrc_files
NETRC
os.environ
return
[
NETRC
]
return
os.path.expanduser
~/.netrc
~/_netrc
NETRC_FILES
=
get_netrc_files
params
case
insensitive
Requests
implementation
normal
dictionary
able
behavior
import
requests
=
requests.Session
[
]
b
assert
session.params
A
]
b
sess.params
b
nice
comment
different
options
docker
mesos
containers
permutations
someone
familiar
semantics
incomprehensible
@
Gilbert88
app
definitions
command
base_app
functions
base_app
definition
good
defaults
=
TEST_APP_NAME_FMT.format
test_uuid
....
test_
functions
=
copy.deepcopy
base_app
app
[
'container
]
[
]
=
'image
other
similar
modifcations
app
test
code
smaller
important
question
images
deployments
images
*
exercise
*
*
functionality
base
dcos
mesos
code
docstrings
methods
opportunity
refactor
gen.generate
top
function
gen_out
bottom
bit
separate
config
generation
genconf/serve/
Quick
sketch
def
onprem_generate
config
return
gen.generate
config.as_gen_format
extra_sources=
[
gen.build_deploy.bash.onprem_source
]
def
make_serve_dir
gen_out
subprocess.check_call
[
'mkdir
'-p
SERVE_DIR
]
gen.build_deploy.bash.generate
gen_out
SERVE_DIR
make_serve_dir
onprem_generate
config
gen_out
gen_out
=
onprem_generate
config
make_serve_dir
gen_out
do_something_else_with
gen_out
comment
much
value
clear
upgrade
script
list
moment
great
docstring
updated
Expand
configurable
options
comment
better
line
version
prefix
strings
version
prefix
information
useful
point
Oops
earlier
comment
methods
update
same
treatment
possible
class
methods
earlier
version
PR
Same
comment
re
line
continuation
character
parentheses
docstring
self.directory
None
special
handling
original
code
code
comment
FileCache.get
self.directory
None
other
places
code
TypeError
wrong
tests
https
//github.com/pypa/pip/blob/5a1b97d572937a3b671e998fc1d9a1ef1730593f/src/pip/_vendor/cachecontrol/caches/file_cache.py
L106
good
use
comments
code-based
documentation
class
code-based
documentation
class
class
Report
Base
Class
description
code-based
documentation
function
description
return
import
comment
relative
import
uniformity
periods
end
comment
blocks
strong
opinion
same
board
__
[
flake8
]
__
*
[
E122
]
continuation
line
indentation
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
E225
]
whitespace
operator
<
Comment
[
SideCI
]
https
//sideci.com
>
comment
fct
QgsExpressionFunction
__
[
flake8
]
__
*
[
E225
]
whitespace
operator
<
Comment
[
SideCI
]
https
//sideci.com
>
Landscape
Volcano
Buffer
Implementation
same
line
duplication
description
other
comment
Sorry
something
def
minimum_needs_path
Return
path
minimum
needs
path
=
folder
path'
old_folder
=
folder
path'
old_folder
exists
old
new
folder
copy
fine
old
folder
path
new
folder
Can
comment
legacy
things
InaSAFE
<
ah
sure
first
comment
check
destination
file
folder
destination
lot
__
[
flake8
]
__
*
[
F401
]
'safe.definitions.constants.ANALYSIS_MULTI_SUCCESS
unused
*
[
F401
]
'safe.definitions.constants.PREPARE_MULTI_SUCCESS
unused
*
[
E501
]
line
characters
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
W391
]
blank
line
end
file
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
F401
]
'safe.utilities.i18n.tr
unused
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
E501
]
line
characters
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
E501
]
line
characters
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
F401
]
'safe.impact_function.impact_function.ImpactFunction
unused
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
F401
]
'qgis.testing.TestCase
unused
<
Comment
[
SideCI
]
https
//sideci.com
>
ah
sorry
one
other
comment
Can
comments
ismailsunni
__
[
flake8
]
__
*
[
E999
]
SyntaxError
invalid
syntax
<
Comment
[
SideCI
]
https
//sideci.com
delimitedtext
other
part
code
URI
delimiter
tests
Windows
TS
layer
=
QgsVectorLayer
%
s
delimiter=
%
layer_uri
layer_name
driver
consistent
gensim
import
utils
utils.open
fin
gensim.utils
import
open
utils.open
bit
helpful
suggestion
Build
model
vocabulary
relations
public
method
good
docstring
look
other
docstrings
code
examples
good
one
concrete
example
something
Process
raw
Wikipedia
dump
XML.bz2
format
example
https
//dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2
English
Wikipedia
articles
sections
plain
text
python
-m
gensim.scripts.segment_wiki
-f
enwiki-20171001-pages-articles.xml.bz2
-o
enwiki-20171001-pages-articles.json.gz
output
format
parsed
Wikipedia
*
json-lines
*
article
line
JSON
example
Python
iterate
file
line
smart_open
'enwiki-20171001-pages-articles.txt.gz
decode
JSON
Python
object
article
=
json.loads
line
article
title
section_titles
section_texts
fields
print
Article
title
%
s
%
article
[
'title
]
section_title
section_text
zip
article
[
]
article
[
'section_texts
]
print
Section
title
%
s
%
section_title
print
Section
text
%
s
%
section_text
comment
place
basic
validation
RELEASE
var
Please
[
numpy-style
format
]
https
//github.com/RaRe-Technologies/gensim/wiki/Developer-page
docstrings
Add
parameters
description
respond
comment
comment
code
helpful
obvious
code
obvious
source
code
clearer
particular
case
code
OK
rid
comment
exception
sure
error
state
warning
Many
people
docstring
result
function
string
Please
comment
normalisation
important
load_data
function
example
Wikipedia
text8
bit
import
magic
comments
load
models/files
setUp
method
several
times
error
message
online
vocabulary-update
model
prior
vocabulary
First
vocabulary
model
corpus
online
update
@
gojomo
sense
error
till
update_weights
few
changes
file
Note
change
github
local
following
code
change
def
build_vocab
sentences
trim_rule=None
progress_per=10000
update=False
Build
vocabulary
sequence
sentences
once-only
generator
stream
sentence
list
unicode
strings.
update
self.wv.vocab
raise
RuntimeError
online
vocabulary-update
model
prior
vocabulary
First
vocabulary
model
corpus
\
online
update
self.scan_vocab
sentences
progress_per=progress_per
trim_rule=trim_rule
initial
survey
self.scale_vocab
keep_raw_vocab=keep_raw_vocab
trim_rule=trim_rule
update=update
trim
min_count
precalculate
downsampling
self.finalize_vocab
update=update
build
tables
arrays
cases
import
gensim
nltk.corpus
import
brown
movie_reviews
treebank
b_sents
=
brown.sents
b
=
gensim.models.Word2Vec
b_sents
b.build_vocab
b_sents
trim_rule=None
progress_per=10000
update=True
b.train
b_sents
error
message
suggestion
Limit
size
FastText
ngram
buckets
RAM
reasons
See
https
//github.com/RaRe-Technologies/gensim/issues/2790
BUCKET
=
[
numpy-style
]
https
//github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt
better
full
nitpick
multiline
docstring
empty
line
i.e
last
text
docstrings
stuff
docstrings
file
numpy-style
previous
comment
https
//github.com/RaRe-Technologies/gensim/pull/1780
discussion_r157712393
Please
use
numpy-style
docstrings
]
http
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html
advantage
extra
lines
comment
example
class
docstring
better
top-level
module
initializer
method
docstring
more
initializer
method
suggestion
Save
NmslibIndexer
instance
file
numpy-style
docstring
gensim
https
//numpydoc.readthedocs.io/en/latest/format.html
docstring-standard
https
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html
Empty
line
end
Please
documentation
[
numpy-style
]
https
//github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt
Googe-style
docstring
sure
comment
several
PRs
beginning
line
same
line
start
Args
specification
method
others
Thanks
suggestion
Read
count
floats
fin
big
example
comments
suggestion
unclear
public
API
class
methods
private
sense
underscore
embedding
clear
documentation
code
Initialize
new
line
first
sentences
[
example
]
http
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html
<
nitpick
>
inconsistent
empty
lines
Sometime
last
line
docstring
empty
other
times
first
line
docstring
empty
other
times
none
Ordnung
muss
sein
<
/nitpick
>
style
empty
line
docstring
own
line
harder
r
empty
lines
regexps
+
please
comment
regexp
punctuation
string.punctuation
Coding
style
docstring
Python
imperative
mode
Does
X
style
docstrings
imperative
mode
Does
X
Coding
style
PEP257
blank
line
PEP8
/
PEP257
blank
line
function
body
new
ENUM
same
update
operator
latest
changes
Good
idea
example
section
docstring
excessive
Emphasis
need
file
custom
callback
docstrings
operator
good
default
value
docstring
indentation
docstrings
PR
consistent
indent
tab
blank
line
description
params
def
stop_query
query_execution_id
Cancel
athena
query
param
query_execution_id
Id
athena
query
blank
line
https
//www.python.org/dev/peps/pep-0257/
id17
>
Multi-line
docstrings
consist
summary
line
one-line
docstring
blank
line
elaborate
description
Minor
stuff
empty
line
line
docstring
Sphinx
applicable
line
Need
blank
line
https
//www.python.org/dev/peps/pep-0257/
id17
>
Multi-line
docstrings
consist
summary
line
one-line
docstring
blank
line
elaborate
description
properties
class
line
class
comment
__init__
parity
other
hooks/operators
sleep_time
configurable
queries
Proper
documentation
Please
order
arguments
congruent
docstring
other
way
s/ID/name/
GCP
ID
last
segment
slash-separated
path
resource
name
entire
path
suggestion
projects/
*
/locations/
*
/keyRings/
*
/cryptoKeys/
*
*
docstring
helpful
docstring
same
order
arguments
__init__
Add
region
name
docstring
please
Letter
first
word
https
//github.com/apache/incubator-airflow/pull/4170/files
diff-04eb39668423c2050c58af9488a17562R263
consistent
URL
//docs.generic-mapping-tools.org/latest/cookbook/cpts.html
built-in-color-palette-tables-cpt
GMT
GMT_GRID_PIXEL_REG=1
if-else
statement
code
node_offset
registration
int
region.extend
[
coord.min
coord_inc
*
node_offset
coord.max
coord_inc
*
]
suggestion
perspective=
]
Azimuth
SouthEast
Elevation
awesome
Just
minor
suggestion
list
perspective
inline
comment
https
//github.com/GenericMappingTools/pygmt/pull/575
list
inputs
documentation
info
good
application
GMTTempFile
w/
usage
example
https
//github.com/GenericMappingTools/pygmt/blob/2884fd04a20ef6281c33d75de6c4521ba968b032/pygmt/helpers/tempfile.py
L27
Check
existence
images
actual
diff
directory
function
docstring
better
rid
necessary
parameters
get_revisions
revert_revision
layer
indirection
difficult
code
docstrings
similar
AUSTable
parameters
appreciated
review
free
time
work
home
haha
comments
history.py
code
commits
unnecessary
punctuation
operators
bit
tough
binTransInclusionProof
+
'tialsproof834charpartialsproof834charpartial
Note
parenthesis
unnecessary
double
quotes
value
single
quotes
double
comment
logic
restore_states
generates
other
kind
error
system
simple
line
description
WHY
great
InvalidConfigError
=
FaucetEventOrderError
Add
comment
True
values
escaped
strings
additional
escaping
comment
True
values
original
value
them.
Done
documentation
arguments
JsonObject
comment
class-level
documentation
abstraction
comment
same
method
EmpiricalMarginal
Importance
sites=observation_labels
design
observations
mu_t
enclose
iarange
context
mu.dim
pyro.sample
u
loc=mu
covariance_matrix=Ku
iarange
u
mu.shape
]
minibatch
size
right
pyro.sample
u
covariance_matrix=Ku
reshape
.reshape
extra_event_dims=1
mu_t
=
mu.t
mu.dim
else
mu
pyro.sample
u
loc=mu_t
covariance_matrix=Ku
.reshape
everything
forms
equivalent
discrete
parameters
e.g
mixture
kernels
iarange
form
nit
standard
format
py
First
line
description
paragraph
longer
description
characters
fits
help
messages
Jupyter
easy
vim
lines
gq
<
ENTER
>
dangerous
mutable
values
default
arguments
instances
share
mutable
values
Prefer
None
None
checks
def
__init__
X
y
kernel
noise=torch.ones
priors=
noise
None
noise
X.new
]
.new
noise
correct
cuda
device
priors
None
priors
docs
conf.py
diff
diff
git
a/docs/source/conf.py
b/docs/source/conf.py
index
..
a/docs/source/conf.py
+++
b/docs/source/conf.py
@
@
-175,6
+175,7
@
@
texinfo_documents
[
intersphinx_mapping
=
//docs.python.org/3/
None
//pytorch.org/docs/master/
None
+
//networkx.github.io/documentation/stable/
None
document
class
constructors
__init__
methods
links
Identical
attr
networkx.DiGraph.nodes
attr
correct
others
meth
nit
__init__
self._name
=
derived
classes
little
safer
Add
doc
linear
model
formula
expectation
conditional
\tilde
y
y
dependent
covariance
term
Flaw
correlation
variables
example
Update
comment
wow
cool
low
priority
comment
sensible
rsample
samples
differentiable
results
differentiable
wrt
samples
result
differentiable
wrt
weights
@
martinjankowiak
wdyt
param
float
radius
docstring
Example
section
usage
scale
radius
guarantee
docstring
nit
.items
half
hashing
frozensets
py
ordinal
terms
log_probs.items
self._log_probs
[
ordinal
]
=
sum
terms
cool
trick
+
x
tensor
ops
nit
comment
class-level
comment
__init__
comment
nit
py
i
child_node
enumerate
sorted_ordinals
proper
documentation
sure
X
Y
types
param
separate
line
type
kernel1
X
Y
sphinx
documentation
param
callable
iwarping_fn
input
function
param
list
owarping_coeff
list
polynomial
coefficients
output
returns
warped
kernel
rtype
destin_attr.__doc__
change
subclasses
docstrings
base
class
code
settled
docstring
couple
usage
examples
nit
comments
wider
print
jupyter
notebooks
free
nit
pro
tip
vim
position
cursor
top
paragraph
type
gq
<
ENTER
>
torch.trtrs
grad
cuda
.inverse
Combining
much
faster
inverse
times
case
trtrs
performance
similar
place
Monte
Carlo
above
comments
Did
right
comment
attribute
clearer
comments
example
code
same
comment
above
worth
update
equation
docstring
nit
@
copy_docs_from
Distribution
trivial
method
docstrings
other
distributions
usage
nit
Could
docstrings
most
characters
wide
.sample
important
users
Jupyter
Notebooks
help
MultivariateNormal
prints
necessary
comment
comment
sort
complex
logic
easy
tag_set_list
task_tags
data
structure
[
]
comment
index
]
if-branch
python
mixed
alert
types
regressions
[
alert
alert
sorted_alerts
alert.is_regression
]
improvements
[
alert
alert
sorted_alerts
alert.is_regression
]
top_regressions
self._ensure_platform_variety
regressions
top_regressions
top_regressions
[
-1
]
=
improvements
]
resulted_alerts_list
=
top_regressions
repository
id
are-
future
variable
comments
clearer
error
message
comment
line
Taskcluster
credentials
PerfSheriffBot
bug
filter
API
key
environment
variable
BUGZILLA_API_KEY
API
keys
name
specific
clearer
someone
Heroku
environment
variables
name
bugzilla
Commenter
external
service
etc
something
open
alternatives
Prior
PR
BUG_FILER_API_KEY
places
BUGZILLA_API_KEY
whilst
BUGZILLA_API_KEY
place
production
*
*
BUG_COMMENTER_API_KEY
all_params
bit
unclear
Really
list
comments
comments
argument
name
print_or_submit_comments
comment
redundant
constructor
argument
change
bug
bug
comment/
sending
comment
function
Likewise
short
comment
purpose
class
nice
line
long
way
sense
messages
specific
run
test0
test1
]
suggestion
messages
test
%
d
%
d
d
range
]
same
comment
re
shakedown
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmph6sm5upz/tests/python/requirements/PySafetyBearTest.py
+++
b/tmp/tmph6sm5upz/tests/python/requirements/PySafetyBearTest.py
@
@
-21,7
+21,7
@
@
avoid
pragma
cover
=
[
mock.Mock
data=
None
mock.Mock
data=
True
+
mock.Mock
data=
True
mock.Mock
data=
[
]
https
//github.com/coala/coala-bears/pull/1597
discussion_r122217556
wrong
comment
box
comment
blank
line
file
unused
source
code
*
PyUnusedCodeBear
severity
NORMAL
section
flakes
issue
following
patch
diff
a/tests/vcs/git/GitCommitBearTest.py
+++
b/tests/vcs/git/GitCommitBearTest.py
@
@
-490,7
+490,7
@
@
section.append
Setting
'shortlog_check_imperative
'False
=
False
bear
=
GitCommitBear
None
section
self.msg_queue
+
GitCommitBear
None
section
self.msg_queue
self.assertFalse
GitCommitBear._nltk_data_downloaded
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/tests/general/KeywordBearTest.py
+++
b/tests/general/KeywordBearTest.py
@
@
-200,7
+200,7
@
@
dependency_results=self.dep_results
result
self.assertEqual
]
.message
line
keyword
'result
match
regex
+
match
regex
=
[
bla
bla
bla
good
CAN_DETECT
other
place
comments
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpm_2hgcvp/bears/documentation/DocumentationStyleBear.py
+++
b/tmp/tmpm_2hgcvp/bears/documentation/DocumentationStyleBear.py
@
@
-88,7
+88,6
@
@
indent
=
use_spaces
stripped_desc
=
line
else
indent
*
+
line
line
stripped_desc
new_desc
=
stripped_desc
Done
filename
results
console
file
changes
stdin
output
stdout
usage
>
elm-format
stdin
Format
input
stdin
https
//github.com/avh4/elm-format
usage
more
details
console
<
>
link
\+
>
little
summary
language
tool
link
documentation
DocComment.parse
documentation
comment
docstring/file
data
explicit
tests
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/tests/documentation/DocGrammarBearTest.py
+++
b/tests/documentation/DocGrammarBearTest.py
@
@
-119,7
+119,7
@
@
test
case
test_language_french
=
unittest.skipIf
platform.system
==
'Windows
language-check
test
windows
+
fails
test
windows
test
main_desc='il
monte
haut
si
il
veut.\n
main_desc='Il
monte
s
’
il
veut.\n
review
comments
decorator
Indent
class
es
struct
s
blocks
stuct
blocks
dict
value-parameters
settings_map
=
indent
None
use_spaces
None
use_spaces
<
else
expression
bit
D
style
+=
k
k
v
settings_map.items
v
v
None
sure
better
something
longer
documentation
header
line
possible
values
few
sentences
+1
indentation
size
+=
k
k
v
rules_map.items
v
[
]
intermediate
list
variable
name
valid_file_without_end_comments
something
comments
Darwin
installs
patch
darwin
tests
darwin
insensitive
sensitive
HFS+
AFS
case
casesensitive
darwin
install
new
test
FS
case
sensitivity
binary
name
IMHO
is_darwin
is_caseinsensitivefs
account
@
AndreMiras
comment
lld
https
//github.com/kivy/python-for-android/pull/1744
pullrequestreview-215858810
block
code
conditional
other
modification
pr
lld
code
branches
more
similar
able
something
AF_INET
SOCK_STREAM
default
explicit
such
low-level
lib
closing
socket.socket
socket.AF_INET
socket.SOCK_STREAM
sock
Timeout
initial
sock
sock.settimeout
self.timeout
try
self.enable_ssl
sslsocket
closing
context.wrap_socket
sock
server_hostname=self.host
ssock
return
self._get_data
ssock
command
return
self._get_data
sock
command
socket.timeout
socket.error
raise
ZKConnectionFailure
test
fine
assertion
failure
test
session
================================================================================
platform
darwin
Python
pytest-4.6.4
py-1.8.0
pluggy-0.12.0
/Users/alexandre.yang/repos/dd/integrations-core/oracle/.tox/py27-oracle/bin/python
cachedir
.tox/py27-oracle/.pytest_cache
benchmark
defaults
timer=time.time
disable_gc=False
min_rounds=5
min_time=0.000005
max_time=1.0
calibration_precision=10
warmup=False
warmup_iterations=100000
rootdir
/Users/alexandre.yang/repos/dd/integrations-core/oracle
plugins
benchmark-3.2.2
cov-2.7.1
mock-1.10.4
datadog-checks-dev-0.31.1
items
/
/
tests/test_e2e.py
:test_check
FAILED
%
]
=====================================================================================
FAILURES
======================================================================================
____________________________________________________________________________________
test_check
_____________________________________________________________________________________
dd_agent_check
=
<
function
run_check
>
@
pytest.mark.e2e
def
test_check
dd_agent_check
aggregator
=
dd_agent_check
metric
METRICS
>
aggregator.assert_metric
metric
tests/test_e2e.py:46
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
..
/datadog_checks_base/datadog_checks/base/stubs/aggregator.py:193
assert_metric
self._assert
condition
msg=msg
expected_stub=expected_metric
submitted_elements=self._metrics
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
condition
=
False
msg
=
least
candidates
'oracle.cursor_cachehit_ratio
expected_stub
=
MetricStub
name='oracle.cursor_cachehit_ratio
type=None
value=None
tags=None
hostname=None
=
defaultdict
<
type
'list
>
u'oracle.tablespace.offline
[
MetricStub
name=u
o
oracle
oracle-alexandre-yang-rh1o0xhw
P004
]
hostname=u'docker-desktop
staticmethod
def
_assert
condition
msg
expected_stub
submitted_elements
new_msg
=
msg
condition
costly
message
similar
metrics
failure
new_msg
=
.format
msg
build_similar_elements_msg
expected_stub
submitted_elements
assert
condition
new_msg
E
AssertionError
least
candidates
'oracle.cursor_cachehit_ratio
E
E
MetricStub
name='oracle.cursor_cachehit_ratio
type=None
value=None
tags=None
hostname=None
E
Similar
E
Score
Most
similar
E
MetricStub
name=u'oracle.buffer_cachehit_ratio
type=0
value=99.47377014160156
tags=
[
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.library_cachehit_ratio
type=0
value=84.85789489746094
tags=
[
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.memory_sorts_ratio
type=0
value=100
tags=
[
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.physical_reads
type=0
value=387.40399169921875
tags=
[
]
hostname=u'docker-desktop
MetricStub
type=0
value=3.7200944423675537
tags=
u'tablespace
EXAMPLE
]
hostname=u'docker-desktop
MetricStub
type=0
value=2.3855221271514893
tags=
u'tablespace
SYSTEM
]
hostname=u'docker-desktop
MetricStub
type=0
value=1.7452248334884644
tags=
u'tablespace
SYSAUX
]
hostname=u'docker-desktop
MetricStub
type=0
value=0.23498547077178955
tags=
u'tablespace
UNDOTBS1
]
hostname=u'docker-desktop
MetricStub
type=0
value=0.0051498436369001865
tags=
u'tablespace
USERS
]
hostname=u'docker-desktop
MetricStub
type=0
value=0
tags=
u'tablespace
TEMP
]
hostname=u'docker-desktop
MetricStub
type=0
value=0
tags=
[
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.tablespace.size
type=0
value=34359721984
tags=
u'tablespace
USERS
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.tablespace.size
type=0
value=34359721984
tags=
u'tablespace
UNDOTBS1
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.tablespace.size
type=0
value=34359721984
tags=
u'tablespace
TEMP
]
hostname=u'docker-desktop
MetricStub
name=u'oracle.tablespace.size
type=0
value=34359721984
tags=
u'tablespace
SYSTEM
]
hostname=u'docker-desktop
E
False
..
/datadog_checks_base/datadog_checks/base/stubs/aggregator.py:235
AssertionError
seconds
======================================================================
ERROR
InvocationError
command
/Users/alexandre.yang/repos/dd/integrations-core/oracle/.tox/py27-oracle/bin/pytest
-v
code
______________________________________________________________________________________
summary
______________________________________________________________________________________
ERROR
py27-oracle
commands
documentation
code
Will
config
method
bit
suggestion
thread
=
Thread
target=self._query_sample_loop
name=self.class_name
thread.daemon
=
True
Python
daemon
Thread
constructor
parameter
different
comment
Let
metric
value
iteritems
type_overrides
value
comment
suggestion
use
relation
bit
misleading
results
relation
specific
meaning
realm
SQL
AFAIK
synonym
table
actual
use
Eg…
python
where_clauses
[
]
Append
where_clauses
where_clause
=
OR
where_clauses
cursor.execute
query.format
comment
suggestion
SQL_QUERY_SCHEMA_SIZE
SELECT
table_schema
IFNULL
SUM
data_length+index_length
/1024/1024,0
total_mb
FROM
information_schema.tables
GROUP
BY
table_schema
readable
suggestion
SQL_INNODB_ENGINES
SELECT
engine
FROM
information_schema.ENGINES
WHERE
engine='InnoDB
support
=
support
=
place
cli
stuff
command
pass
comment
structure
value
something
more
secure
default
check
logic
least
default
blacklist
credentials
agent
logs
ideal
Oops
—
comment
Nit
Consider
code
exception
case
readability
purposes
suggestion
Allow
debug
check
state
Uncaught
psutil
exceptions
Error
state
try
processes
proc.name
proc
self.process_list_cache.elements
psutil.NoSuchProcess
pass
self.log.debug
Unable
process
%
s
processes
%
s
processes
same
comment
Do
Windows
wait_on_docker_logs
common.CASSANDRA_CONTAINER_NAME
[
]
private
attribute
OpenMetricsScraperMixin
.clear_http_handlers
public
method
situations
false
positive
case
sentences
jpg
png
.jpg
cases
images
repo
Shall
image
present
expected
path
comment
ReplicaSetDeploymentType
suggestion
repl_set_payload
=
admindb.command
replSetGetStatus
replset_name
=
repl_set_payload
name
]
replset_state
=
repl_set_payload
[
myState
self.deployment_type
=
ReplicaSetDeploymentType
replset_name
replset_state
suggestion
ntlm
Agent
other
comment
Please
add
comment
one
docstring
something
stub
check
Agent
e.g
tests
development
datadog_checks.utils
package
method
extra
documentation
suggestion
value
=
root.get
[
-1
]
None
isinstance
root
dict
None
queue_totals
list
dict
Few
things
parsing
logic
l.strip
.split
split
safe
space
quote
same
split/strip
avoid
suggestion
import
re
KEY_VALUE_PATTERN
=
re.compile
r
=
constant
compile
input_line
=
LABEL=
MY
LABEL
UUID=
5eea373d-db36-4ce2-8c71-12ce544e8559
TYPE=
ext4
device
data
input_line.split
key
value
re.findall
KEY_VALUE_PATTERN
data
print
key
value
.format
key
value
OUTPUT
key
LABEL
value
MY
LABEL
key
UUID
value:5eea373d-db36-4ce2-8c71-12ce544e8559
key
TYPE
value
constant
Make
sens
least
priority
health
check
Which
next
comment
memcached_socket
fixture
uncomment
bit
use
anything
cleanup
nit
free
tuple
get_version
natural
def
get_version
db
return
raw_version
def
parse_version
raw_version
return
version
caller
@
property
def
version
self._version
None
raw_version
get_version
self.db
self._version
=
parse_version
raw_version
self.set_metadata
'version
raw_version
return
self._version
methods
AgentCheck
better
idea
heavier
refactoring
Same
comment
other
collector
function
large
out
separate
function
docstring
blank
output
commands
ofek/add-upgrade-task
◼
❯❯❯
-l
⏎
Available
tasks
test
tests
Agent-based
checks
comment
else
clause
sure
python
arguments
positional
ones
error
none
workaround
bug
invoke
help
invoke
task
ofek/add-upgrade-task
◼
❯❯❯
upgrade
-h
required
positional
arguments
~/d/integrations-core
ofek/add-upgrade-task
◼
❯❯❯
-h
upgrade
Usage
inv
[
]
[
core-opts
]
upgrade
[
options
other
tasks
]
Docstring
none
Options
-e
Whether
output
-p
STRING
package
integrations
STRING
version
package
e2e
assertion
error
test
session
=================================================================================
platform
darwin
Python
pytest-4.6.4
py-1.8.0
pluggy-0.12.0
/Users/alexandre.yang/repos/dd/integrations-core/istio/.tox/py27/bin/python
cachedir
.tox/py27/.pytest_cache
benchmark
defaults
timer=time.time
disable_gc=False
min_rounds=5
min_time=0.000005
max_time=1.0
calibration_precision=10
warmup=False
warmup_iterations=100000
rootdir
/Users/alexandre.yang/repos/dd/integrations-core/istio
plugins
benchmark-3.2.2
cov-2.7.1
mock-1.10.4
datadog-checks-dev-0.31.1
items
/
/
tests/test_e2e.py
:test_e2e
FAILED
%
]
======================================================================================
FAILURES
======================================================================================
______________________________________________________________________________________
test_e2e
______________________________________________________________________________________
dd_agent_check
=
<
function
run_check
>
@
pytest.mark.e2e
def
test_e2e
dd_agent_check
aggregator
=
dd_agent_check
rate=True
metric
MESH_METRICS
+
NEW_MIXER_METRICS
+
GALLEY_METRICS
+
PILOT_METRICS
+
CITADEL_METRICS
>
aggregator.assert_metric
metric
tests/test_e2e.py:16
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
..
/datadog_checks_base/datadog_checks/base/stubs/aggregator.py:193
assert_metric
self._assert
condition
msg=msg
expected_stub=expected_metric
submitted_elements=self._metrics
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
condition
=
False
msg
=
least
candidates
'istio.pilot.mcp_sink.recv_failures_total
expected_stub
=
MetricStub
name='istio.pilot.mcp_sink.recv_failures_total
type=None
value=None
tags=None
hostname=None
=
defaultdict
<
type
'list
>
u'istio.galley.go.memstats.stack_sys_bytes
[
Metr
ation_seconds.count
type=0
value=32
tags=
[
]
hostname=u'docker-desktop
staticmethod
def
_assert
condition
msg
expected_stub
submitted_elements
new_msg
=
msg
condition
costly
message
similar
metrics
failure
new_msg
=
.format
msg
build_similar_elements_msg
expected_stub
submitted_elements
assert
condition
new_msg
E
AssertionError
least
candidates
'istio.pilot.mcp_sink.recv_failures_total
E
E
MetricStub
name='istio.pilot.mcp_sink.recv_failures_total
type=None
value=None
tags=None
hostname=None
E
Similar
E
Score
Most
similar
E
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/rbac/v1alpha1/serviceroles
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/rbac/v1alpha1/servicerolebindings
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/rbac/v1alpha1/rbacconfigs
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/rbac/v1alpha1/clusterrbacconfigs
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/rbac/v1alpha1/authorizationpolicies
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/networking/v1alpha3/virtualservices
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/networking/v1alpha3/sidecars
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/networking/v1alpha3/serviceentries
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/networking/v1alpha3/gateways
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/networking/v1alpha3/envoyfilters
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/networking/v1alpha3/destinationrules
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/mixer/v1/config/client/quotaspecs
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/mixer/v1/config/client/quotaspecbindings
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/config/v1alpha2/httpapispecs
u'connectionID:0
]
hostname=u'docker-desktop
MetricStub
name=u'istio.pilot.mcp_sink.request_acks_total
type=2
value=0
tags=
[
u'collection
istio/config/v1alpha2/httpapispecbindings
u'connectionID:0
]
hostname=u'docker-desktop
E
False
..
/datadog_checks_base/datadog_checks/base/stubs/aggregator.py:235
AssertionError
seconds
=======================================================================
ERROR
InvocationError
command
/Users/alexandre.yang/repos/dd/integrations-core/istio/.tox/py27/bin/pytest
-v
code
______________________________________________________________________________________
summary
_______________________________________________________________________________________
ERROR
py27
commands
validations
hostname
comment
bit
confusing
trail
something
'host
suggestion
'query
'select
WAREHOUSE_NAME
sum
CREDITS_USED_COMPUTE
CREDITS_USED_COMPUTE
CREDITS_USED_CLOUD_SERVICES
CREDITS_USED_CLOUD_SERVICES
CREDITS_USED
CREDITS_USED
WAREHOUSE_METERING_HISTORY
start_time
>
=
date_trunc
day
current_date
group
docstrings
mark
use
test
purposes
Examples
CogniteClient
experimental
namespace
As
general
comment
<
b
>
<
/b
>
free
good
docstring
comment
reference
second
comment
factory
concern
subsequent
comment
double
defaulting
pep-257
nit
docstring
phrase
period
function
method
effect
command
description
e.g
Returns
pathname
building
factory
pep-257
nit
first
line
docstring
short
line
Multi-line
docstrings
consist
summary
line
one-line
docstring
blank
line
elaborate
description
summary
line
automatic
indexing
tools
important
line
rest
docstring
blank
line
current
docstring
implies
DictOf
config.Type
DictOf
spec_dict
usage
mode
comment
agree
@
AlexAndorra
docstring
distribution
able
mixtures
multivariate
distributions
vectorized
manner
docstring
important
inline
assert
s
exceptions
antipatterns
flag
i
ValueError
RuntimeError
custom
error
least
TODO
useful
work
anyone
flag
small
comment
line
shape-handling
link
issue
scipy
Code
<
details
import
theano.tensor
tt
first
variant
ann_input
=
pm.Minibatch
X_train
=
pm.Minibatch
Y_train
neural_network
=
construct_nn
neural_network
inference
=
pm.ADVI
theano.configparser.change_flags
compute_test_value='off
obj1
=
tt.grad
inference.objective
inference.approx.params
=
theano.function
[
]
obj1
second
ann_input
=
tt.matrix
=
X_train
[
:1
]
=
tt.vector
=
Y_train
[
:1
]
neural_network
=
construct_nn
neural_network
inference
=
pm.ADVI
theano.configparser.change_flags
compute_test_value='off
def
create_minibatch
data
rng
=
np.random.RandomState
True
Return
random
data
samples
set
size
iteration
ixs
=
rng.randint
data
size=50
yield
data
[
ixs
]
minibatches
zip
create_minibatch
X_train
create_minibatch
Y_train
=
tt.grad
inference.objective
inference.approx.params
=
theano.function
[
ann_input
ann_output
]
obj2
def
fn2
return
fn2_
*
next
minibatches
%
timeit
fn1
%
timeit
fn2
/details
>
length
separator
better
comment
use
self.separator
=
len
self.separator
clearer
=
sum
len
field
space
field
[
date
time
]
sure
real
template
json
case
Ca
real
template
json
lambda
json.dumps
obj
string
json
object
fp.read
string
actual
file
inputs/config_map.json
root
project
file
fp
open
INPUTS_PATH
config_map.json
fp
.and_return
flexmock
read=lambda
fp.read
json
object
point
Never
mind
comment
decode
generator
line
return
line.decode
utf-8
line
logs
logs
NOTE
comment
let
code
block
dependency
Just
docstring
variable
docstring
use
validation
test
TODO
user
way
Scikit-learn
_passthrough_scorer
https
//github.com/scikit-learn/scikit-learn/blob/3b5abf76597ce6aff76192869f92647c1b5259e7/sklearn/metrics/scorer.py
L226-L228
public
text
more
robust
ways
share
docstrings
scope
docstrings
test
validation
explanation
clear
docstring
>
>
import
dask.datasets
>
>
import
pandas
pd
>
>
>
df
=
dask.datasets.timeseries
>
>
df
doctest
+SKIP
Dask
DataFrame
Structure
id
name
x
y
npartitions=30
2000-01-01
int64
object
float64
float64
2000-01-02
2000-01-30
2000-01-31
Dask
Name
make-timeseries
tasks
input
*
output
*
python
session
May
import
BlockTransformer
start
example
docstring
scikit-learn
other
comment
StopOnPlateauSearchCV
build_graph
comment
deprecation
warning
private
module
lazy
dask
support
TPOT
release
PR
call
Docstring
Someone
interested
e.g
trigger
times
simulation
information
warnings
sure
Documentation
output
Parameters
Imo
mask
pixels
pixels
cleaning
example
necessary
survivors
signal
comment
cleaning
functions
able
event
source
module
level
import
top
file
module
level
import
top
file
<
br
>
unused
module
level
import
top
file
<
br
>
sa
unused
Okay
cool
comment
something
many-to-many
comment
xD
doc
string
args
methods
method
ones
stuff
Ah
sorry
change
while
intentional
subplots
Python
0-based
subplot
indices
plot
[
idx
]
sense
0-based
axes
numbers
docstring
typos
type
annotations
I.e
__init__
name
srt
instrument
SR830
channel
int
imho
fine
types
doc
strings
@
Rubenknex
stable
way
trouble
line
endings
fault
documentation
instrument
line
endings
instruments
\r\n
line
.startswith
better
Again
git
work
comments
code
docstrings
necessary
InstrumentBase
docstring
add_submodule
method
submodules
docstring
case
integration
Config
Flow
PR
anything
underlying
lib
only
implements
Config
Flow
scope
PR
weird
good
side
note
....
Please
lowercase
snakecase
string
abort
reason
sure
Stale
comment
difference
corresponding
instance
suggestion
import
DOMAIN
pylint
disable=unused-import
comment
suggestion
errors
base
]
unknown
return
self.async_create_entry
title=whole_data
[
title
]
data=whole_data
suggestion
assert
result2
errors
==
patch
homeassistant.components.progettihwsw.async_setup_entry
patch
homeassistant.components.progettihwsw.async_setup
return_value=True
=
await
hass.config_entries.flow.async_configure
[
flow_id
]
need
values
second
step
result3
[
type
]
create_entry
assert
result3
errors
==
result3
data
]
assert
result3
data
host
]
assert
result3
data
port
key
claritys
dict
ac_key
Same
comment
suggestion
return
f
self.coordinator.data
system
[
rid
]
self.ac_key
unique
platform
multiple
climate
entities
same
data
source
-climate
suffix
same
comment
valid
zone
entity
Nothing
return
value
suggestion
errors
await
self.async_set_unique_id
api.gateway_id
self.async_create_entry
title=api.smile_name
data=user_input
zwave_
prefix
useful
device
info
page
show
info
suggestion
raise
UpdateFailed
f
Update
def
async_update_weather_data
data
self.weather.init_data
self.async_refresh
track_home
changes
HA
home
setting
self._unsub_track_home
=
self.hass.bus.async_listen
EVENT_CORE_CONFIG_UPDATE
self.async_update_weather_data
suggestion
Stop
tracking
changes
HA
home
setting
suggestion
Update
data
suggestion
async
def
_async_update_weather_data
Update
data
self.weather.init_data
self.async_refresh
=
self.hass.bus.async_listen
suggestion
Start
changes
HA
home
setting
WIP
suggestion
class
MetDataUpdateCoordinator
DataUpdateCoordinator
[
Device
]
Class
Met
data
def
__init__
hass
Initialize
global
Met
data
updater
=
MetWeatherData
hass
config_entry.data
hass.config.units.is_metric
super
.__init__
hass
_LOGGER
update_interval=SCAN_INTERVAL
def
_async_update_data
>
Device
Fetch
data
Met
try
return
await
this.weather.fetch_data
Exception
err
raise
UpdateFailed
f
Update
suggestion
self._unique_id
=
entry.entry_id
entry.unique_id
None
Use
entry
unique
id
device
id
possible
self._unique_id
=
suggestion
Custom
TCPSite
https
//github.com/aio-libs/aiohttp/pull/4894
merged.
valid_values
Humidifier
Dehumidifier
Humidifier
Dehumidifier
DEVICE_CLASS_HUMIDIFIER
Humidifier
Dehumidifier
Humidifier
DEVICE_CLASS_DEHUMIDIFIER
Humidifier
Dehumidifier
Dehumidifier
device
de-humidify
/
humidify
able
valid_values
type_thermostats
modes
suggestion
async
def
start_websocket
event=None
Start
websocket
await
suggestion
errors
base
]
unknown
errors
user_input
[
CONF_USERNAME
]
return
self.async_abort
reason=
self.async_create_entry
title=info
[
title
]
data=user_input
host
hub
host
address
=
entry.data
[
CONF_HOST
]
entry
self._async_current_entries
CONF_HOST
entry.data
return
host
existing_hosts
user_input
[
CONF_HOST
]
return
self.async_abort
reason=
something
username
sure
duplicate
config
entries
url
docstring
Just
first
line
suggestion
Make
sure
coordinator
hass.data.setdefault
DOMAIN
suggestion
Set
PoolSense
config
entry
poolsense
=
PoolSense
=
await
poolsense.test_poolsense_credentials
aiohttp_client.async_get_clientsession
hass
entry.data
[
CONF_EMAIL
]
[
CONF_PASSWORD
]
api_key_valid
return
False
suggestion
Initialize
PoolSense
config
flow
async
executor
suggestion
async
def
call_later_listener
Handle
call_later
callback
self.debounce
None
await
self.hass.async_add_executor_job
func
purpose
list
raw
header
CoordinatorEntity
https
//github.com/home-assistant/core/blob/62c4e072f5e21ccd057e343c700d2f81a0a50b2e/homeassistant/helpers/update_coordinator.py
L195
suggestion
def
_async_create_entry
Handle
create
entry
suggestion
Validate
MQTT
data
suggestion
Generate
MQTT
file
suggestion
Validate
MQTT
file
Debug
next
step
await
return
step
form
suggestion
@
property
def
available
Return
device
available
return
self._state
None
def
update
>
None
suggestion
MediaPlayer
platform
Roon
integration
py
zone_id
zone
self.roonapi.zones.items
suggestion
async
def
async_will_remove_from_hass
>
None
Run
entity
hass
self._light.disconnect
entity
container
set
track
light
addresses
suggestion
_LOGGER.exception
Unknown
error
%
s
err
step
step
form
Please
helper
method
try
same
methods
suggestion
await
self._handle_errors
self._update
def
_update
Update
media_player
state
=
self._control.get_mute
=
self._control.get_volume
self.state
=
STATE_ON
self.available
=
True
async
def
_handle_errors
*
args
Handle
errors
func
available
try
await
self.hass.async_add_executor_job
func
*
args
_LOGGER.error
connection
TimeoutError
URLError
OSError
self.state
STATE_OFF
self.available
=
False
await
self.async_create_remote_control
suggestion
Initialize
internal
timeout
context
manager
suggestion
class
_FreezeNull
empty
freeze
timeout
zone
freeze
tests.
async
def
__aexit__
exc_type
Type
[
BaseException
]
exc_val
BaseException
exc_tb
TracebackType
>
Optional
[
bool
]
return
None
async
def
__aenter__
>
_FreezeNull
return
line
try
suggestion
try
valid_token
=
await
self.hass.async_add_executor_job
self.auth
pin
BlinkSetupError
errors
base
]
cannot_connect
Exception
pylint
disable=broad-except
_LOGGER.exception
exception
errors
base
]
unknown
return
self._async_finish_flow
errors
base
]
invalid_access_token
comment
earlier
thread
https
//github.com/home-assistant/core/pull/28693
discussion_r352879490
smart
humidifiers
control
humidity
level
other
controls
integration
category
suggestion
Error
zone
exists
account
suggestion
turn
command
ISY994
switch
suggestion
def
__init__
name
api
sensor_type
sensor
self._sensor
=
SENSOR_TYPES
[
sensor_type
]
self._name
=
f
name
self._sensor
[
CONF_NAME
]
self._api
=
api
self._sensor_type
=
sensor_type
comment
above
example
coordinator
update
coordinator
data
entities
suggestion
async
def
async_update
>
None
Update
OVO
Energy
entity
await
self.coordinator.async_request_refresh
entity
listener
coordinator
coordinator
new
data
need
updates
class
example
async
def
async_added_to_hass
>
None
Connect
entity
data
notifications
self.async_on_remove
self.coordinator.async_add_listener
self.async_write_ha_state
other
way
Stale
fixture
@
pytest.fixture
def
mock_notifier
hass
events
[
]
@
callback
def
record_event
event
Add
event
events.append
event
hass.services.async_register
notify.DOMAIN
NOTIFIER
record_event
return
events
tests
mock_notifier
args
test
old
async
def
test_fire
hass
new
async
def
test_fire
hass
mock_notifier
value
mock_notifier
fixture
events
repeat
scaffold
comments
suggestion
Test
lock
CONFIG_SCHEMA
=
vol.Schema
DOMAIN
vol.All
CONF_EXTRA_HTML_URL
invalidation_version=
CONF_EXTRA_HTML_URL_ES5
invalidation_version=
vol.Optional
CONF_FRONTEND_REPO
cv.isdir
vol.Optional
CONF_THEMES
vol.Schema
cv.string
cv.string
cv.string
vol.Optional
CONF_EXTRA_HTML_URL
vol.All
cv.ensure_list
[
]
vol.Optional
CONF_EXTRA_MODULE_URL
vol.All
cv.ensure_list
[
]
vol.Optional
CONF_EXTRA_JS_URL_ES5
vol.All
cv.ensure_list
[
]
options
vol.Optional
CONF_EXTRA_HTML_URL_ES5
cv.match_all
vol.Optional
CONF_JS_VERSION
cv.match_all
suggestion
sms
gateway
…
…
suggestion
self.values.mode
Z-Wave
uses
list
modes
presets
Iterate
Z-Wave
ThermostatModes
hvac
modes
presets
val
self.values.mode.value
[
VALUE_LIST
]
val
[
VALUE_ID
]
MODES_LIST
treat
value
hvac
mode
hass_mode
=
ZW_HVAC_MODE_MAPPINGS.get
val
[
VALUE_ID
]
[
hass_mode
]
=
val
[
VALUE_ID
]
treat
value
hvac
preset
all_presets
val
[
VALUE_LABEL
]
]
=
val
[
VALUE_ID
]
all_modes
HVAC_MODE_HEAT
]
=
None
pass
True
update
coordinator
latest
data
suggestion
_
model
mac_address
=
controller_unique_id.split
_
suggestion
entry_data
[
suggestion
entry_data
[
CONF_DIRECTOR_MODEL
]
=
controller_name.split
_
]
.upper
suggestion
_LOGGER.debug
new
tokens
hass
data
comment
bit
confusing
tokens
config
entry
.storage/core.config_entries
access
board
variable
suggestion
assert
result
type
RESULT_TYPE_FORM
f-strings
concatenation
general
practice
everything
config
entry
hass.data
[
DOMAIN
]
[
config_entry.entry_id
]
Please
earlier
review
comment
suggestion
data_update_coordinator
=
hass.data
[
DOMAIN
]
[
config_entry.entry_id
]
[
COORDINATOR
]
suggestion
async
def
test_websocket_api
hass
generic_data
hass_ws_client
Test
websocket
api
timeout
see
Modbus
TCP
Client
Transport
Implementation
class
ModbusTcpClient
BaseModbusClient
Implementation
modbus
tcp
client
def
__init__
host='127.0.0.1
port=Defaults.Port
framer=ModbusSocketFramer
*
*
kwargs
client
instance
param
host
host
param
port
modbus
port
param
source_address
source
address
tuple
default
param
timeout
timeout
socket
Defaults.Timeout
param
framer
modbus
framer
ModbusSocketFramer
note
host
argument
ipv4
ipv6
hosts
self.host
host
self.port
=
port
self.source_address
=
kwargs.get
self.socket
=
None
self.timeout
=
kwargs.get
Defaults.Timeout
BaseModbusClient.__init__
framer
ClientDecoder
*
*
kwargs
Same
comment
info
warning
Same
comment
info
warning
comment
import
element
cases
Let
comment
Remove
old
outdated
categories
model.
clear
all_categories
cache
None
obvious
many
other
log_and_notify
calls
fan
args
action=
many
arguments
easier
reason
double
whitespaces
style
bit
wrong
something
lines
python
Returns
account
notifications
user
defaults
returned.
pep08
other
style
guides
imho
Let
name
filters
comment
free
self
undecided
items
VALUES
QUERYSET_LOOKUP
error
drive-by
comment
[
'AB
'CD
]
X-Country-Code
request
I.e.
reason
test
excluded_regions
bit
easier
style
def
get_url
_is_developer
lambda
self.context
[
'is_developer
]
'is_developer
self.context
else
obj.is_developer
_is_adminish
=
user
acl.action_allowed_user
amo.permissions.USERS_EDIT
None
own
profile
url
developers
request
=
self.context.get
'request
None
user
=
getattr
request
'user
None
request
None
None
==
user
_is_adminish
user
_is_developer
return
absolutify
least
feels
easier
comment
*
fixed
comment
code
comment
comment
nit
test
cases
difficult
check_subscription_for_approval
I.e.
True
False
good
idea
real
use
case
different
issue
use
case
manifest.json
locale
files
former
tricky
locale
files
something
bit
different
variables
filename
rules
content
file
name
anything
'is_json_file
zip_info.filename.endswith
'.json
'is_manifest
zip_info.filename
==
'manifest.json
better
way
strings
python
'is_locale_file
zip_info.filename.contains
'_locales
zip_info.filename.endswith
'messages.json
better
way
https
//developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Internationalization
Localized_string_selection
functions
comments
logic
conditions
comment
twice…
hunks
above
diff
newline
changes
GIT_DIFF_LINE_CONTEXT_EOFNL
/
normal-eofnl
scenario
case
new_line_number
change
line
something
aware
Nit
Same
comment
shortcut
]
actual
usage
other
comment
get_version_object
implementation
ReviewAddonVersionMixin
tests
true
line
serializer
tests
views
tests
suspicious
comment
little
clearer
hard-delete
queryset
method
part
comment
weights
equal
y=0
docstring
incorrect
method
comparisons
TP
FP
single
number
test
bit
weird
comment
test_grid_search
quorum
ViewChangeDone
msgs
different
real
view
change
viewNo
Primary
CurrentState
messages
Node
comment
blank
Please
add
comment
reason
sleep
comments
Precision
nanoseconds
most
filesystems
ntfs
windows
Anyway
file
systems
ext3
.1
enough
.5
same
precision
solution
comment
filesystems
test
comment
high-level
explanation
class
Eg
class
common
testing
environment
utility
functions
Cabot
test
cases
common
environment
users
schedules
checks
service
utility
function
test
states
set_test_states
service
statuses
....
comments
details
m
thinking
opts.force
whole
try
whole
try
spider
file
opts.force
try
part
code
sense
check
own
method
opts.force
self._spider_exists
name
return
…
def
_spider_exists
name
later
approach
pass
KeyError
additional
checks
try
early
returns
indentation
test
synthetic
comment
lines
specific
Failure
references
Response/Request
objects
context
test
docstring
reference
memory
leak
docstring
works
ItemLoader
class
method
output
reasonable
class
docstring
more
sense
e.g
attribute
docs
Please
docstrings
next
test
target_address
something
same
test
different
target_address
.exclude
methods
fact
queryset
methods
queryset
double
assignment
block
small
function
same
module
same
comment
information
message
group
Same
comment
field
required
attribute
necessary
b/c
mixin
part
care
declarations
consistent
module
level
variable
common
constant
formats
Python
Django
only
thing
able
comment
Date
Time
String
Format
ECMA-262
specification
same
comment
get_form
method
django_comments
app
methods
__init__.py
convention
tests
issues/bug
commit
msg
doc
string
method
mine
opinion
convention
project
comment
similar
comments
above
last
scenarios
pointless
current
code
bug
POST
request
browser
additional
comments
Delete
last
test
scenarios
Same
comment
above
sense
b/c
line
text
comment
form
sense
post_data
correct
previous
code
substitute
something
unrelated
See
previous
comments
section
Wrt
permission
tests
tests
permission
label
need
more
granual
permission
label
nothing
tests
negative
scenario
user
permission
same
comments
i
same
comment
retry
bellow
backoff
use
suggestion
str
mirrored
image
link
logic
setup
teardown
functions
docstring
several
Exceptions
Raises
sections
previous
comment
change
previous
comment
Your
e
right
demo
reasons
good
message
comment
log
WDYT
info
fixture
Pleas
more
information
comment
parameters
e.g
scenario
etc
class
Return
value
raises
Any
workload
'workloads/workload_name/
<
>
directory
general
note
please
more
comments
code
hard
everything
documentation
timeout
sleep
mention
default
values
default
def_value
below
Please
description
comment
code
Writing
content
new
file
seconds
seconds
sleep
device
space
5-10
seconds
device
Leave
empty
line
Returns
eg
Returns
str
String
testrun
ID
suggestion
Get
object
Returns
OCP
Object
localvolume
svt
update
comment
align
quotation
Please
more
details
docstring
class
keesturam
mark
https
//github.com/red-hat-storage/ocs-ci/pull/2119
final
comment
travis
due
line
bool
value
cluster
state
capacity
May
check
add_capcity
exit
criteria
Comment
same
other
ops
system
healthy
operation
Pease
MiB/s
helpful
PVCs
better
debugging
number
volumes
blanket
value
podman
requirement
ocs-ci
documentation
Vaibavi
deployment
docs
dep
logging
other
action
Empty
line
Returns
section
Return
>
Returns
Write
TODO
comment
something
TODO
cluster
old
version
terraform
old
version
destroy
open
issue
please
comment
https
//github.com/red-hat-storage/ocs-ci/pull/1550
discussion_r388410227
code
wait_for_resource
side
add_capacity
function
assert
self.check_cluster_health
Cluster
healthy
EC2
Instances
self.instances_in_az
Args
suggestion
assert
finished_in_time
storage
space
check_timeout
seconds
likely
product
bug
misconfiguration
same
comment
last
PR
template
load
consistency
scripts
easier
empty
line
end
docstring
Good
actual
values
error
message
sorry
topic
class
constructors
actual
resource
creation
IMO
consistency
class
instantiation
resource
creation
comment
<
=
date
kubernetes
latest
version
Just
grasp
change
add
functions
file
Tired
ThreadPoolExecutor
ThreadPoolExecutor
lot
time
Threads
thread
evaluation
i.e
loop
~100th
thread
first
thread
Execution
testcase
magna
machine
error
due
threads
local
laptop
execution
same
logic
problem
PVC
bound
state
sampler
bool
upgrade
better
current
version
case
sampler
False
suggestion
ocp_upgrade_version
=
config.UPGRADE.get
'ocp_upgrade_version
logic
.get
few
times
other
comments
minutes
upgrade
Please
function
version
config
https
//github.com/red-hat-storage/ocs-ci/pull/1662/files
diff-68bc5ed905b5a4cefbac287573f4f60fR1856
python
target_image
=
config.UPGRADE.get
'ocp_upgrade_version
target_image
ocp_channel
=
config.UPGRADE
[
'ocp_channel
]
default
config
e.g
stable-4.3
ocp_upgrade_version
=
get_latest_ocp_version
channel=ocp_channel
target
image
contain
architecture
name
other
value
ocp_arch
=
image
=
config.UPGRADE
[
'ocp_arch
]
target_image
f
ocp_upgrade_version
ocp_arch
approach
comment
line
indent
comments
align
quotation
marks
good
docstring
👍
comment
Test
precision
recall
F1
>
Test
precision
recall
something
suggestion
Index
array
scipy.sparse
NumPy
version
Thanks
suggestion
indices
bool
int
str
array-like
slice
suggestion
Extract
values
items
Returns
set
items
list
values
none_is_missing
comment
numpy
<
part
fact
X
=
X
element-wise
object
dtype
def
_object_dtype_isnan
X
return
X
=
X
docstring
_prune_tree
misprint
documentation
show_weights
True
weights
Just
misprint
sure
dedent
lines
expected_report
dedent
|
feature_1
<
|
|
class
-1
|
feature_1
|
|
class
.lstrip
leaves
first
level
comment
test
comment
clear
default
threshold
max_features
right
place
comment
suggestion
scorer
comment
decision_function
_PredictScorer
predict_proba
_ThresholdScorer
suggestion
Return
True
cache
beneficial
comment
IIUC
dict
iff
scorer
dict
dataframe
render
following
css
trick
https
//github.com/scikit-learn/scikit-learn/pull/13227/files
diff-1ddeb568bd409df15775919c69128c75
documentation
General
comment
whole
example
missingness
NaN
entire
example
educational
place
missingness
replacing
people
note
user
guide
guide
informative
such
details
description
docstring
super
series
elements
index
array
feature
bug
last
IndexError
latter
comment
more
test
comment
sure
comment
docstring
train_test_split
Just
comment
such
def
test_clamping_toy
non-regression
test
inline
comment
state
non-regression
test
Performance
test
regression
test
title
first
line
example
verbose
least
rational
number
reason
[
SO
]
https
//stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks
def
chunks
l
n
Yield
successive
n-sized
chunks
l.
i
range
l
yield
l
[
i
i
n
]
test
test_
prefix
@
pytest.mark.parametrize
[
'score_samples
]
def
method
predict
exception
unfitted
estimator
Unfitted
estimators
NotFittedError
rng
=
np.random.RandomState
X
=
rng.randn
kde
=
KernelDensity
pytest.raises
NotFittedError
getattr
method
X
function
comment
easy
Please
comment
get_support
boolean
mask
features
Returns
support
boolean
array
shape
[
input
features
element
True
iff
corresponding
feature
retention.
docstring
Given
previous
comment
clear
separate
test
behaviour
zero_divison
tiny
unexplicit
piece
larger
test.
tests
lot
readable
use
functools.partial
previous
version
readability
better
names
comment
https
//github.com/scikit-learn/scikit-learn/pull/10110/files
r150681672
suggestion
Helper
function
values
[
n_uniques
lexicographic
order
comment
strict
API
contract
docstring
.0
please
noise
nitpick
windows
case
insensitive
filenames
comments
WDYT
suggestion
check
invalid
max_samples
values
suggestion
test
toy
example
separable
bootstrap
size
suggestion
Return
response
positive
label
@
jnothman
discussion
other
related
PR/issues
topic
inactivity
past
months
Shall
single
backtick
glossary
documentation
private
classes
future
review
useful
suggestion
pca.explained_variance_ratio_.sum
decimal=1
comment
CheckingClassifier
case
assertion
assert_raises
suggestion
parameters
estimator
suggestion
[
False
estimators
classes
suggestion
True
]
original
features
iris
self.drop
None
block
cleaner
self.drop
None
to_drop
=
self.drop_idx_.reshape
-1
.copy
=
X_int
=
to_drop
n_values
[
]
i
cats
enumerate
self.categories_
n_cats
cats
to_drop
i
]
None
set
cardinality
X_int
to_drop
i
=
n_cats
n_cats
n_values.append
n_cats
X_int
[
X_int
>
to_drop
]
X_mask
=
n_values
[
len
cats
cats
self.categories_
]
name
klass
color
better
suggestion
@
pytest.mark.parametrize
X
[
[
]
]
]
[
]
[
]
]
]
def
test_iterative_imputer_one_feature
X
check
single
feature
imputer
=
IterativeImputer
.fit
X
imputer.n_iter_
reference
pandas
documentation
select_dtypes
Short
comment
please
e.g
>
Functional
test
column
transformer
+
column
selector
test
proper
docstring
Compute
weighted
percentile
Note
array
2-D
array
percentile
axis
Parameters
inconsistent
reference
docstring
axis
array
2-D
sample_weight
1-D
python
]
X
2-D
array
samples
features
X
=
np.random.randn
weight
samples
sample_weight
=
np.random.randn
_weighted_percentile
X
sample_weight
ValueError
Traceback
recent
call
last
ipython-input-3-0716f7c3f0e0
>
<
module
sample_weight
=
np.random.randn
>
_weighted_percentile
X
~/Documents/packages/scikit-learn/sklearn/utils/stats.py
_weighted_percentile
array
sample_weight
percentile
array
=
array.reshape
array.shape
=
sample_weight.shape
>
sample_weight
=
sample_weight.reshape
array.shape
sorted_idx
=
np.argsort
array
axis=0
sorted_weights
=
_take_along_axis
sample_weight
sorted_idx
axis=0
ValueError
array
size
shape
]
_weighted_percentile
X
np.repeat
sample_weight.reshape
]
array
[
-0.38490779
]
solution
sample_weight
_num_samples
array
==
_num_samples
sample_weight
previous
comment
See
previous
comments
fix
different
mine
https
//github.com/scikit-learn/scikit-learn/pull/12316/commits/8cdcda2dfea2841bc2699b90219296020c481532
i.e
laplacian
=
laplacian
+
1e-5
*
sparse.eye
laplacian.shape
]
norm_laplacian
=
False
effect
function
_set_diag
May
comment
diagonal
shift
1e-5
Laplacian
eigenpairs
textwrap.dendent
correct
indentation
suggestion
def
test_pipeline_missing_values_leniency
pipeline
values
validation
transformers
predictors
small
comment
outputs
same
comment
seen.It
>
suggestion
pytest.mark.parametrize
sparse_constructor
[
sp.csc_matrix
sp.csr_matrix
]
def
test_incr_mean_variance_axis_dim_mismatch
sparse_constructor
Check
proper
error
axis=1
dimension
mismatch
Non-regression
test
https
//github.com/scikit-learn/scikit-learn/pull/18655
test
@
pytest.mark.parametrize
'estimator
RandomForestClassifier
n_estimator=2
MultiOutputClassifier
RandomForestClassifier
ClassifierChain
RandomForestClassifier
]
def
test_multi_output_classes_
estimator
estimator.fit
X
y
assert
isinstance
list
assert
estimator.classes_
==
n_outputs
estimator_classes
expected_classes
zip
classes
assert_array_equal
estimator_classes
expected_classes
file
other
tests
specific
name
explanation
suggestion
def
test_newrand_bounded_rand_int
orig_range
n_pts
Test
bounded_rand_int
uniform
distribution
file
other
tests
specific
name
explanation
suggestion
def
test_newrand_seed
seed
val
Test
set_seed_wrap
bounded_rand_int_wrap
tiny
bit
redundant
use
reason
hard
everything
time
others
comments
comment
line
lines
*
multiply
Earth
radius
distance
km
small
comment
eps
suggestion
'documentation
'documentation.html
redirects
index
comment
Random
order
same
order
helpful
reader
Just
docstring
Return
section
Could
purpose
test
comment
bit
strange
pass
redundant
side
suggestion
data_id
Australian
dataset
version
_monkey_patch_webbased_functions
monkeypatch
data_id
True
suggestion
Estimator
n_features_in_
version
number
scikit-learn
line
version
number
scikit-learn
line
end
line
[
TYPE_CHECKING
docs
]
https
//docs.python.org/3/library/typing.html
typing.TYPE_CHECKING
performance
reasons
case
comment
Please
docstring
way
threshold
code
same
note
discrepancy
code
docstring
formula
docstring
+1
Ps
variable
names
meaning
way
comment
state
suggestion
Insert
error
results
suggestion
single
metric
case.
test
pytest
same
behaviour
regressor
classifier
suggestion
@
pytest.mark.parametrize
MLPEstimator
[
MLPClassifier
MLPRegressor
]
def
test_warm_start_full_iteration
MLPEstimator
Non-regression
test
https
//github.com/scikit-learn/scikit-learn/issues/16812
Check
MLP
estimator
accomplish
max_iter
warm
estimator
use
case
warm_start
increase
max_iter
more
iterations
py
clf.fit
X
y
assert
clf.n_iter_
first
iterations
trains
more
iterations
clf.set_params
max_iter=7
clf.fit
X
y
assert
clf.n_iter_
case
warm_start=True
unchanged
max_iter
second
call
noop
todo
true
function
partial_dependence
grid
values
_grid_from_X
X
[
]
percentiles
grid_resolution
Looks
anything
Bunch
idea
https
//github.com/scikit-learn/scikit-learn/issues/13448
issuecomment-483807326
idea
https
//github.com/scikit-learn/scikit-learn/issues/13448
issuecomment-479512520
usable
comment
different
test
multitarget
Use
plt.subplots
more
modern
matplotlib
nitpick
duplicated
line
if/else
comment
ptp
numeric
precision
issues
constant
features
TODO
easier
big
deal
_compute_small_trainset_indices
comment
docstring
>
efficiency
training
scores
scorers
returned
indices
same
different
calls
warm
start
context
rng
better
name
comment
Maybe
small
comment
print
text
appropriate
color
sure
text
color
appropriate
suggestion
top
middle
ICE
suggestion
dependency
plots
parameter
individual
controls
behaviour
suggestion
variable
Hence
ICE
plots
PDP
docstring
classes
n_nodes-1
sure
redundant
test
beginning
test
feature
selection
method
correlation
todo
list
data
function
Hmm
Nit
pep8
parameter
number
times
Same
other
parameters
Please
short
description
e.g
Make
sure
feature
target
higher
importance
available
unavailable
point
comment
line
beginning
sentence
point
comment
line
worth
line
comment
purpose
test
handle_unknown
behaviour
handle_unknown
param
description
class
docstring
intercept
https
//github.com/scikit-learn/scikit-learn/issues/3020
issuecomment-648035624
docstring
alpha_
best_score_
etc
new
shapes
Many
function
names
verbose
accuracy_recall
comment
compare_cv_results_multimetric_with_single
sufficient
check_multimetric_cv_results
comment
Same
comment
subset
hard-coded
combinations
set
tests
less
full
Cartesian
product
laptop
Please
comment
state
w
warning
context
Could
dosctring
RidgeCV
metric
value
cv
parameter
Currently
scoring
string
callable
None
optional
default
None
string
model
evaluation
documentation
scorer
callable
object
/
function
signature
scorer
estimator
X
y
cv
int
cross-validation
generator
iterable
optional
Determines
cross-validation
splitting
strategy
Possible
inputs
cv
None
efficient
Leave-One-Out
cross-validation
integer
number
folds
term
splitter
iterable
yielding
train
test
arrays
indices
integer/None
inputs
binary
multiclass
class
sklearn.model_selection.StratifiedKFold
class
sklearn.model_selection.KFold
Refer
ref
User
Guide
<
cross_validation
>
various
cross-validation
strategies
efficient
Leave-One-Out
cross-validation
Generalized
Cross
Validation
plot
output
message
'\n
output
message
strange
[
page
]
https
//15098-843222-gh.circle-artifacts.com/0/home/ubuntu/scikit-learn/doc/_build/html/stable/auto_examples/preprocessing/plot_discretization_classification.html
test
weak
fact
error
message
StratifiedShuffleSplit
X
=
[
[
]
]
]
]
]
y
=
[
]
gbc
=
GradientBoostingClassifier
validation_fraction=0.5
non-stratified
random
splits
class
y
error
_
range
gbc.fit
X
y
error
message
please
e.g
assert_raises_regex
My
old
comment
valid
Agreed
list
something
plotting
funs
https
//github.com/scikit-learn/scikit-learn/pull/17856
issuecomment-656302895
active
comment
slow
ignore_warnings
comment
Please
comment
non-regression
test
PR
corresponding
issue
Please
comment
FIXME
square_distance=True
default
.A
sparse
matrices
docstring
explicit
X_trans_csr.toarray
X_csr.toarray
assert_array_almost_equal
X_dense
integer
dtype
test
np.float32
np.float64
integers
addition
check
expected
dtype
standard
scaling
point
values
output
with_std=False
consistency
old
comment
past
review
free
PR
same
comment
something
https
//github.com/scikit-learn/scikit-learn/pull/9492
issuecomment-321190011
regression
test
less
magical
known
answer
provenance
clear
Hey
@
lesteve
thanks
comment
test
suggestion
Non-regression
test
https
//github.com/scikit-learn/scikit-learn/issues/10529
Check
UserWarning
non-finite
score
GridSearchCV
user
guide
mathematical
details
Read
User
Guide
link
other
class
docstrings
Please
comment
date
column
unique
category
case
column
unique
category
value
doctest
+ELLIPSIS
comment
small
comment
issue
Non-regression
test
https
//github.com/scikit-learn/scikit-learn/issues/15312
araujobsd
@
skarekrow
idea
line
@
igalic
FYI
point
such
docstrings
copy
funciton
name
wink
Improve
good
comment
non
integer
counters
error
TO
drop
global
variable
use
nonlocal
def
processor_factory
processors
None
def
inner
nonlocal
processors
processors
None
processors
load_processors
return
processors
get_processors
processor_factory
cloud_sync_router
processors
get_processors
Same
comment
Class
name
capital
letter
inner
classes
worth
class
test
data
dict
data
description
docstring
comment
..
Forgot
way
check
programming
error
case
AssertionError
preferable
last
increment
first
use
codebase
recursiveUpdate
unused
docstring
>
update
target
dictionary
source
dictionary
unfound
keys
place
different
dict.update
target
keys
source
case
example
target
keys
source
Such
behavior
docs
surprising
dict.update
recursive
dicts
reason
existence
use
recursiveUpdate
comment
test
definition
separate
function
test_vsp_init
rePool
Remove
blank
line
assertion
constant
values
block
comment
multiline
string
commented
print
statements
intentional
worth
comment
Python
built-in
dict
thread-safe
such
promise
alphabetical
order
comment
url
link
//cloud.google.com/appengine/docs/flexible/python/how-instances-are-managed
health_checking
google-cloud-python
code
https
//github.com/GoogleCloudPlatform/google-cloud-python/blob/master/logging/google/cloud/logging/handlers/transports/background_thread.py
L65
doc
comments
code
same
code
feasible
comments
handler
registry
comment
reference
TraceSpan
class
comment
pk
primary
key
django.contrib.auth.models.User
comment
link
documentation
test
app
better
appearance
insecurity
SECRET_KEY
=
str
uuid.uuid4.hex
something
curious
options
MetricsExporter.__init__
comment
trace
context
headers
code
Zipkin
headers
excessive
comments
useful
function
name
from_headers
comment
code
Prometheus
tag
values
strings
need
none
empty
string
See
https
//github.com/census-instrumentation/opencensus-python/issues/480
tag_values
=
list
cast_none_to_empty_str
tag_values
comment
numerical
observations
observer
UI
comment
generic
operator
validation
>
comment
numerical
observations
observer
UI
Implemented
comment
numerical
observations
observer
UI
Implemented
agree
possible
schema
validation
marshmallow
schema
Will
comment
bellow
case
JSON
schemas
validate
Could
check
DRY
present
couple
different
endpoints
CI
logs
line
i.e
pylint
disable=line-too-long
end
row
more
rows
linter
impossible
downgrade
Maybe
comment
suggestion
populate
engine
alias
name
engine
dictionary
engine_alias
attribute.engine_aliases
[
]
engines
engine_alias
]
=
full_table_name
used
line
line
sql
=
f
CREATE
TABLE
str
table
one_or_none
query
better
error
handling
comment
assert
Hmm
bigger
question
cases
backend
able
actual
reason
same
error
code
Error
datasource
datasource
large
unusual
load
suggestion
return
statements_without_comments.startswith
EXPLAIN
return
statements_without_comments
]
.startswith
EXPLAIN
pylint
disable=no-self-use
description
=
Column
text
column
report/alert
internal
documentation
purposes
context_markdown
=
Column
text
context
alert/report
part
email
empty
single
field
purposes
Nit
docstring
string
unnecessary
DatasourceSecurityManager
realistic
order
messages
python
result
results
client
all_clients
people
other
messages
response
someone
true
individual
clients
messages
bursts
end
lot
Same
comments
ones
great
kind
hard
sure
space
https
//www.python.org/dev/peps/pep-0008/
block-comments
comment
following
code
function
readability
static
method
code
peole
write
comments
act
comments
future
reference
multiline
strings
spaces
edge
strings
words
line
break
suggestion
Number
active
games.
Includes
games
lobby
games
games
game_service
dict
parameter
https
//github.com/GoogleCloudPlatform/cloud-opensource-python/blob/7ab0f4c47a913b3200d76512bb6caaa82f51be12/badge_server/utils.py
L106
recursive=True
controllable
parameters
invocation
clone
raises
ValueError
docstrings
good
practice
easier
reason
function
docstring
Same
other
places
PR
CreatorsMixin
creator
object
docstring
😄
D103
public
function
other
comment
suggestion
DOI
record
retrieved
record
id
suggestion
Import
data
party
provider
line.strip
check
reason
whitespace
sensitive
something
template_text
=
line.strip
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
Attribute
'_user_identity
__init__
]
https
//www.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=1144717
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
Attribute
'_api_path
__init__
]
https
//www.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=1144717
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Line
]
https
//www.codacy.com/app/MatthewScholefield/mycroft-core/pullRequest
prid=935421
See
comment
function
name/docstring
Same
comment
nit
docstring
level
parameter
super
nit
properties
auto
docstring
getter
setter
getter
http
//manticore.readthedocs.io/en/latest/api.html
manticore.Manticore.verbosity
verbatim
reason
language
Hm
clear
decision
interface
global
Manticore
class
@
feliam
//github.com/trailofbits/manticore/issues/431
issuecomment-320025228
honest
options
manticore
import
Manticore
m
=
Manticore
'/bin/ls
m.verbosity
m.run
manticore
import
Manticore
set_verbosity
m
=
Manticore
'/bin/ls
set_verbosity
m.run
former
namespace
clutter
set_verbosity
Thoughts
rlp
Nit
types
docstring
TODO
comment
Note
able
Z3Solver.instance
API
performance
implications
behavioral
differences
suggestion
Note
single
mode
_most
likely_
True
problem
docstring
suggestion
PMAXUB
returns
maximum
packed
unsigned
byte
integers
dest
operand
dest_value
dest.read
FD
tests
outdated
comment
let
docstring
path
something
param
str
path
termination
SIGTERM
first
SIGKILL
comment
reason
name
someone
submodule
something
package
better
name
test_find_submodule_in_module
docstring
please
unittest
prints
method
name
verbose
mode
former
easier
failing
test
formatting
PEP
Sorry
other
test
class
original
comment
similar
test
help_about
Terry
necessary
branch
OS
comments
link
issue
https
//github.com/python/cpython/pull/2380
config
rename
function
move
level
+def
get_user_directory
+
filesystem
directory
user
config
files
+
self.userdir
=
userDir
=
self.GetUserCfgDir
self.userdir
=
userDir
=
get_user_directory
def
GetUserCfgDir
filesystem
directory
user
config
files
test_config
python
+class
FunctionTest
unittest.TestCase
+
Test
module
functions
+
+
def
test_get_user_directory
+
getdir
=
config.get_user_directory
+
etc
getdir
call
code
Move
test_warn
same
class
SetOption
active
theme
keys
lot
docstring
code
test
config
dialog
separate
boolean
themes
keys
kind
Meaning
user
custom
user
theme
boolean
false
is_builtin_theme
user
default
keyset
boolean
true
are_builtin_keys
first
check
default
test
boolean
value
kind
theme
user
rest
name
theme
keys
user
default
Hum
value
test
self.assertEqual
compiler.executables
'compiler
]
dots
case
task
cancellation
*
*
result
*
*
exception
OK
something
async
def
inner
try
await
asyncio.sleep
asyncio.CancellationError
return
FooException
'Function
FontTab
docstring
form
Function
load_general_cfg
tk
variables
helplist
idleConf
'sets
var
x_y
FontTab
docstring
Var
var
variable
explicit
'var
abbreviation
StringVar
IntVar
etc
clear
'extract
class
issues
function
become
class
bpo-31004
bpo-31050
IMO
tk_var
startup_edit
backtick
hard
comment
entry_win_height
entry_win_width
comment
code
new
comment
bpo-31051
result
clear
save_all
need
save_all
suggestion
state
NFA
deterministic
finite
automata
docstrings
tests
docstring
newline
comment
IRIX-specific
code
code
necessary
tests
e.g
Linux
ONLCR
terminal
translation
mode
ONLCR
Posix
default
least
Linux
sys.exc_info
corresponding
_GeneratorContextManager
code
acceptance
implementation
PEP
common
needs
exceptions
BaseException
fine
BaseException
form
comment
synchronous
version
way
purpose
code
consistent
branch
contextlib2
backport
suggestion
pipe
probe
comment
default
Windows
CMD
Back
NT
CMD
default
.COM
NT
support
additional
scripting
languages
.JS
.WS
MMC
console
files
.MSC
Windows
default
*
value
*
.COM
encoded
scripts
.JSE
mixed-language
scripts
.WSH
CMD
current
default
.WS
supported
Windows
Scripting
file
extension
nowadays
Which
better
CMD
default
value
os.system
subprocess
shell=True
bit
outdated
default
value
Move
class
RecvChannel
top
file
sense
things
comment
_NOT_SET
class
RecvChannel
module
suggestion
def
recv_nowait
default=_NOT_SET
recv
default
function
low-level
implementation
channel_recv_wait
test
AsyncMock
instances
comment
more
clear
test
Which
methods
example
comment
Same
question
elif
method.ident
check
unreadable
simple
readable
though
short
comment
short
comment
purpose
loop
Alternative
proposal
sizeof
c_wchar
UTF-16
surrogate
pair
wchar_t
non-BMP
characters
outside
[
U+0000
U+FFFF
]
range
+1
NUL
character
size
=
sum
ord
c
c
init
bit
wchar_t
wchar_t
Unicode
character
+1
NUL
character
size
=
len
init
Drop
parentheses
left
=
module
style
DottedPrettyPrinter
times
test
method
Please
comment
Docstrings
public
API
class
implementation
detail
comment
please
explicit
text
NB
method
sync
decorate_callable
same
comment
decorate_callable
comment
bpo-37933
Calling
cancel_dump_traceback_later
dump_traceback_later
test
sure
docstring
super
useful
IMHO
docstring
useless
much
tests
users
way
tests
[
Function
arguments
Expected
output
[
'first
]
second\n
[
'first
]
'first\n
[
]
[
]
'\n
try
loneno
end_lineno
AttributeError
None
docs
comment
thing
enter_result
parameter
attribute
name
comment
necessary
comment
function
waiter
second
result
future
waiter
cause
KeyError
future
reference
example
>
>
concurrent.futures
import
Future
>
>
>
=
Future
>
>
fs
=
Future
>
>
fs_finished.set_result
>
x
as_completed
[
fs
Future
]
fs.set_result
None
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
File
/home/grzegorz/cpython/Lib/concurrent/futures/_base.py
line
pending.remove
future
KeyError
<
Future
NoneType
>
error
version
Future.set_result
Future.set_exception
>
Executor
implementations
unit
tests
case
_SpecialGenericAlias
reason
comment
better
warning
case
matter
style
context
manager
first
warning
TIL
future
Other
changes
good
+1
@
contextmanager
def
test
msg
test.assertWarnsRegex
RuntimeWarning
msg
cm
yield
non-CPython
implementations
Python
deallocation
garbage
collector
gc.collect
space
below
errors
AssertionError
coroutine
'AsyncMockMixin._execute_mock_call
test.assertTrue
str
.endswith
AssertionError
False
true
coroutine
'AsyncMockMixin._execute_mock_call
repr
least
@
ammaraskar
repr
code
bytes
Python
-b
option
>
bytes
bytes
bytes
errpipe_data
comment
@
gpshead
python
implementation
local
experiments
lines
c
module
early
C_
constant
caps
more
accepted
style
list
short
comment
change
first
read
change
inefficient
>
Same
style
comment
>
Resolve
’
t
docstrings
way
OK
reference
Comment
fix
Please
comment
number
blank
line
delete
blank
line
obvious
comment
following
method
previous
one
comment
better
context
font
effect
font
change
text
effect
font
change
context
vice
versa
review
comment
Possible
code
=
idleConf.GetFont
self.root
'EditorWindow
self.codecontext
None
self.codecontext.update_font
newfont
change
sig
self.text
[
'font
]
=
None
good
practice
file
open
script
subprocess
support.TESTFN
filename
use
self.addCleanup
support.TESTFN
file
unittest.mock
object
logic
diff
diff
git
a/Lib/test/test_gc.py
b/Lib/test/test_gc.py
index
..
a/Lib/test/test_gc.py
+++
b/Lib/test/test_gc.py
@
@
-12,6
+12,7
@
@
import
textwrap
import
import
time
import
+import
unittest.mock
try
_testcapi
import
with_tp_del
@
@
-996,13
+997,7
@
@
class
GCTests
unittest.TestCase
callback
objects
invalid
states
wr_callback_was_run
=
False
def
callback
wr
callback
access
objects
invalid
states
due
objects
trash
nonlocal
wr_callback_was_run
wr_callback_was_run
True
+
callback
=
unittest.mock.Mock
class
__slots__
=
[
y
]
@
-1024,7
+1019,7
@
@
class
GCTests
unittest.TestCase
del
wr_cycle
gc.collect
callback
bug
self.assertFalse
wr_callback_was_run
+
class
GCCallbackTests
unittest.TestCase
docstring
line
def
get_no_fold_literal
value
no-fold-literal
=
[
*
dtext
]
suggestion
watcher
main
thread
code
python
request
[
]
==
request
[
-1
]
[
]
request
[
-1
]
request
=
request
-1
comment
comment
Btw
comment
https
//github.com/python/cpython/pull/23058/files
r515498221
Python
older
UUID
object
additional
attributes
pickling
anybody
tests
maintained
release
need
following
code
def
__getstate__
state
=
self.is_safe
=
SafeUUID.unknown
is_safe
SafeUUID
instance
value
un-pickled
older
Python
versions
SafeUUID
state
*
*
state
self.is_safe.value
return
state
def
__setstate__
state
self.__dict__.update
state
is_safe
unknown
self.__dict__
[
'is_safe
]
=
SafeUUID
state
[
'is_safe
]
state
SafeUUID.unknown
logic
area
cname
c
logging.Formatter
c
=
_resolve
cname
c
logging.Formatter
validate
parameter
use_validate
=
True
validate
=
config.get
'validate
True
c
validate
parameter
use_validate
=
False
trouble
validate
parameter
care
number
things
c
fmt
dfmt
style
arguments
c
class
logging.Formatter
either
__init__
first
case
safe
use_validate
True
second
Formatter
subclass
developer
validate
parameter
class
config
post-3.8
design
configured
value
idea
__init__
validate
signature
guarantee
*
*
validate
parameter
bool
idea
True
value
safest
case
c
class
Formatter
idea
__init__
fmt
dfmt
style
parameters
issubclass
c
logging.Formatter
'__init__
c.__dict__
use_validate
=
True
'validate
config
user
OK
use_validate
=
True
signature
checking
inspect
signature
Note
parameter
'kwargs
someone
*
*
kw
example
specific
parameter
p
such
==
inspect._VAR_KEYWORD
use_validate
result
=
c
fmt
dfmt
style
result
=
c
fmt
dfmt
style
validate
comment
case
someone
test
weird
Test
cases
strings
children
first
node
docstrings
sure
False
positives
line
way
import
tkinter.messagebox
tkMessageBox
tkinter.messagebox
import
showerror
tkMessageBox.
same
deletion
other
existing
patches
Please
line
first
line
docstring
https
//www.python.org/dev/peps/pep-0257/
First
line
docstring
empty
Reformat
base
class
ExitStack
AsyncExitStack
Disassemble
classes
functions
other
compiled
objects
e.g
generators
below
comment
applicable
function
*
inconsistent
@
serhiy-storchaka
notes
preferred
layouts
ones
opening
triple-quote
last
option
PEP
inconsistent
ones
left
edits
likely
indentation
part
change
affected
docstring
docstring
left
side
likely
nobody
other
way
multiline
docstrings
left
side
harder
right
characters
comment
public
correct
confusing
Disassemble
classes
methods
functions
function-like
objects
code.
objects
code
objects
correct
-ish
functions
top-level
public
docstring
_get_code_object
mechanical
definition
clearer
better
generic
phrase
generators
asynchronous
generators
coroutines
wrong
generators
other
cost
living
Happy
convention
inconsistent
dis.py
compare
e.g
_try_compile
Instruction
_get_name_info
right
_disassemble
get_instructions
get_instructions_bytes
alignment
git
blame
light
inconsistent
alignments
same
patch
trim
PEP
dummy
maxint
docstrings
equivalent
PEP
mentions
foo
bar
~~~~
def
foo
multi-line
docstring.
def
bar
multi-line
docstring.
def
baz
multi-line
docstring.
~~~~
Best
code
methods
~~~~
Disassemble
classes
methods
functions
objects
code
argument
last
traceback
objects
generator
objects
async
generator
objects
coroutine
objects
code
special
attributes.
~~~~
Using
other
odd
Disassemble
classes
methods
functions
other
compiled
objects
necessary
code
objects
first
line
fact
other
compiled
objects
output
compile
call
obvious
assumption
Good
question
commit
history
calls
mock
trouble
tests
events
test
suite
lines
patch
other
code
cleanup
comments
lines
part
typo
feder
comment
issue
number
Add
comment
meaning
-1
mention
docstring
@
berkerpeksag
version
readline
implementation
libedit|GNU
readline
little
nicer
PyModule_AddIntConstant
m
_READLINE_VERSION
RL_READLINE_VERSION
hasattr
check
libedit
tests
=
readline.__doc__
libedit
readline.__doc__
>
So
hasattr
check
idea
test_readline
unchanged
Python
implementations
other
CPython
Tests
*
private
*
tests
@
comment
rationale
>
is_editline
Right
flag
other
attributes
available
rl_library_version
private
attribute
able
test_readline
subtle
differences
readline
versions
is_editline
flag
check
something
@
classmethod
def
_is_subnet_of
cls
b
Implementation
subnet_of
other
return
self._is_subnet_of
other
def
supernet_of
other
return
self._is_subnet_of
other
docstring
same
cache
docstrings
try
itemgetter_object
doc
=
cache
[
index
]
KeyError
itemgetter_object
doc
=
cache
[
index
]
=
_itemgetter
index
f'Alias
field
number
index
class_namespace
[
name
]
=
property
itemgetter_object
doc=doc
code
giant
detect_modules
function
lines
function
scope
PR
include_dirs
other
include_dirs=
parameters
bad
name
clashes
giant
function
'package
common
practice
common-word
parameter
names
docstrings
Just
TypeError
IndexError
OverflowError
ValueError
ill-formed
values
docstrings
comments
part
branch
visible
[
files
top
_Object
changes
_create_tree
docstring
setup
revised
test
hard
part
revised
comparison
function
Comments
docstrings
consist
multiple
sentences
periods
end
sentences
first
line
docstring
period
rest
comment
Calls
function
Makes
sure
exception
function
other
exception
retest
suggestion
name
argument
bpo-37641
free
helpful
anyone
reason
Style
nit
reST
markup
docstrings
change
good
FTP.__init__
public
method
docstring
Please
short
comment
bpo-35717
rationale
test
wr
=
weakref.ref
f
del
p
del
f
self.assertIsNone
wr
docstring
name
parameter
code
values
function
as-is
code
little
possible
clear
same
comment
options
scripts
old
new
pegen
vs
cpython
relevant
snippet
documentation
proper
docstring
safe
__name__
__main__
other
classes
enums
class
unpickable
robust
self-explanatory
test
pywbem
version
least
import
pywbem
import
packaging.version
PYWBEM_VERSION
=
packaging.version.parse
pywbem.__version__
PYWBEM_VERSION.release
>
=
beta
version
dev
version
PYWBEM_VERSION.is_devrelease
dev
release
PYWBEM_VERSION.is_prerelease
alpha
beta
release
TODO
unrelated
code
function
CIMCLass
object
issue
GetClass
GetClass
TODO
better
log
messages
used
unhandled
null
conditional
step
warning
name
user
better
step/port
responsible
unhandled
null
general
add
documentation
parts
same
style
rest
toil
code
guide
docstring
code
necessary
second
check
Bug
reduced_cube.ancillary_variables
+
reduced_cube.cell_measures
single
loop
ok
docstrings
methods
_lists_
iterables
combination
lazy
cubes
method
fact
current
code
da.compute
accepts
non-dask
objects
worth
docstrings
method
_co_realise_lazy_arrays
@
pp-mo
Change
with_landmask_field
previous
comment
requests
wink
clear
code
comment
purpose
..
keyword
argument
callable
cubes
required
name
callable
name
'None
cubes
required
name
something
lines
placeholders
module
people
description
new
column
upstream
existing
column
own
documentation
sync
people
issues
mega-sync
terminal
up-to-date
list
columns
like
people
available
placeholders
other
modules
list
placeholders
control
date
info
word
performance
word
performance
word
performance
word
performance
word
performance
word
performance
condition
stream.has_more_samples
Suggestion
Perceptron
performance
Same
comment
Better
default
value
error
documentation
\
sphinx
next
line
part
definition
parameter
part
description
format
documentation
suggestion
Calculates
Dice
Coefficient
Confusion
Matrix
comment
example
get_lr_scheduler
example
line
users
starting
point
need
cast
code
https
//github.com/pytorch/ignite/blob/92455594401681bbd3e675a664072b905401274b/ignite/contrib/engines/common.py
L596-L598
isinstance
models
nn.Module
=
model
models
type
Dict
[
str
nn.Module
]
=
models
comment
something
Binary
case
map
classes
categorical
something
docstring
incomplete
TODO
Update
description
+
explain
arrays
example
code
quick
description
docstring
helpful
other
users
few
lines
test
case
suggestion
mixsimulator.MixSimulator
import
MixSimulator
type
ignore
..
base
import
ExperimentFunction
standard
order
more
general
specific
external
first
internal
afterwards
comment
new
documentation
docstrings
D
Pareto
list
args
kwargs
tuple
tuple
dict
Parameters
size
int
optional
subset
full
pareto
front
maximum
size
subset
str
method
subset
random
loss-covering
domain-covering
Returns
list
elements
pareto
front
self.num_stocks
num_dams
clearer
comment
f
beginning
string
formatting
len
num_vars
optimizers
previous
comment
comment
f
total
number
variables
sum
num_vars
different
dimension
self.dimension
comment
assert
num_optims
num_vars
f
number
optimizers
num_optims
equal
length
variables
len
num_vars
nit
int
cast
main
scenarios
apply_network_config
True
False
net
config
primary
nic
dhcp4
+
dhcp6
ipv6s
non-empty
return
configure
metadata
mac
nic_name
need
apply_network_config
logic
uptime
implementation
boottime
timestamp
value
boottime
slight
change
implementation
original
order
boottime
right
time.time
call
temp
variables
way
*
BSD
codepath
uptime_str
=
str
time.time
boottime
lot
discussion
feature
flags
conclusions
documentation
few
months
grin
suggestion
release
exception
url_error
=
UrlError
exception
diagnostic
event
url_error.cause
UrlError
<
str
exception
>
url_error
=
exception
url_error.cause
<
str
exception
>
former
logs
>
same
question
*
Same
answer
grin
>
same
wait_for_phys_devs
conversation
outcome
above
comment
TODO
line
TODO
tools
todos
review
release
please
user_data
cloud_config
test
code
test
infrastructure
code
TODO
PR
easier
only
cases
rule
invalid
URLs
e.g
foo_.example.com
foo-.example.com
invalid
anything
PR
TODO
nit
review
double
negative
logic
hurts
simple
brain
suggestion
excluded_handlers
handler_key
excluded_handlers
continue
skip
handler
handler.publish_event
event
log
fine
..
obvious
comment
Module
frequency
instance
PER_ALWAYS
'contents
work
func
adjust_ipv6_iface_file
path
contents
util.load_file
path
NM_CONTROLLED
IPV6
lines
dropline
=
lambda
l
l.startswith
IPV6ADDR
l.startswith
IPADDR6
l.startswith
IPV6INIT
l.startswith
NM_CONTROLLED=
lines
contents.splitlines
lines
[
l
l
lines
l
lines.append
NM_CONTROLLED=no
open
interface_file
w
fp
fp.write
.join
lines
\n
easy
unit
test
temp
file
function
contents
easier
contents
contents
reading
side
function
i
rid
full
paths
first
path
comment
PATH
order
=
os.environ.get
'PATH
add_path
orig_path
def
add_path
orig_path
RSCT_PATH
standard
path
So
thet
cloud
init
RECFGCT
new
node_id
RSCT_PATH
LOG.error
RSCT
package
try
suff
orig_path
orig_path
os.environ
'PATH
]
=
RSCT_PATH
+
suff
Exception
util.logexc
LOG
RSCT
path
second
part
comment
pre-requisite
module
line
module
RSCT
package
OddBloke
Curious
reason
rule
similar
change
following
test
suggestion
def
test_handle_args_root_processes_user_data
ud_expected
vd_src
capsys
paths
tmpdir
Support
multiple
user-data
file
content
types
user_data
self._setup_paths
ud_val=ud_src
vd_val=vd_src
self._setup_paths
user_data
/
vendor_data
b
arguments
suggestion
return
True
trailing
comment
please
retry
comment
time.sleep
line
comments
extra
explanation
code
good
comment
regex
files/classes/tests
bugs
docstring
top
bug
number
comment
bug
number
able
file/class/test
name
test
docstring
arguments
index
bit
un-authed
user
list
users
projects
low
risk
lists
projects
leak
information
comment
fine
update
class
comment
valid
index
service
legacy
support
mode
point
small
usage
everyone
new
approach
docstring
load
write
similar
call
__verify_package_version
gtmunit2
gtmunit3
logic
separator
path
separator
bit
general
add
docstrings
method
file
vague
log
message
useful
bit
code
execution
count
https
//github.com/gigantum/gigantum-client/blob/activity_error_handling/packages/gtmcore/gtmcore/activity/monitors/monitor_jupyterlab.py
L218
clear
tag
anything
worth
DOING
anything
comment
ex
tag
redundant
execution_count
ActivityProcessor
attribute
cell
as-is
comments
comments
branch
branch
sure
next
test
case
commentary
methods
currency
value
comment
Nit
extra
line
comment
Create
text
ad
object
similar
comment
prior
comment
status
raw
enum
value
+1
David
suggestion
See
comment
same
comment
LIMIT
use
.next
print
resource
names
resource
name
prefix
*
*
Nitpick
*
*
multi-line
docstring
https
//www.python.org/dev/peps/pep-0257/
mysterious
i+1
[
:15
]
middle
time_hi_and_version
:13
]
:18
]
https
//en.wikipedia.org/wiki/Universally_unique_identifier
Format
Thanks
better
comment
line
string
same
line
example
AdWords
API
please
comment
comment
comment
golden
https
//github.com/googleads/google-ads-php/blob/3dc0d995dd292a3cb77671917da6528011f7a3d2/examples/AdvancedOperations/AddSmartDisplayAd.php
L66
good
candidate
comment
short
multi
line
comment
line
version
someone
familiar
case
text
issue
little
modification
bug
[
best_match
]
https
//github.com/dbtsai/python-mimeparse/blob/master/mimeparse.py
L155-L184
docstring
>
value
'supported'
>
list
mime-types
list
supported
mime-types
>
order
desirability
case
situation
>
tie
'application/json
last
quality
values
equal
comment
good
functions
@
property
def
current_state
return
self._api_state_to_serverstate
self.current_api_state
@
abstractproperty
def
current_api_state
subclass
current
server
state
API
name
better
function
current
state
subclass
_api_state_to_serverstate
better
copy-paste
interface
code
comments
something
special
Q
arguments
optional
defaults
None
func
definition
cpu=None
ram=None
Optional
cpu
isfile
[
]
length
=
unexpected
reboot
file
Could
reason
code
comment
Good
wordy
Try
auto-restart
feature
container
s
docstring
longer
characters
parameter
docstring
https
//github.com/pallets/click/issues/486
method
method
Example
@
feature.command
'autorestart
short_help=
Show
auto-restart
feature
container
s
Many
commands
groups
docstrings
Click
library
docstrings
present
usage
information
user
part
'help
text
Could
files
missing
docstrings
brief
description
group/command
Test
group/command
help
flag
platforms
script
general
platform
last
commit
context
line
ctx
last
commit
logic
printall
period
options
printall
sense
errors
rate
period
feature
handy
use
subcommands
comments
rate
Please
briefly
command
help
message
comment
such
TODO
Stub
place
body
Please
briefly
command
help
message
comment
such
TODO
Stub
place
body
similar
comment
ipaddress.ip_interface
dst_ip
.ip.version
cli
due
earlier
comments
Suggest
group
alphabetical
order
comment
NAT
comment
Add
groups
other
modules
aaa.aaa
config.add_command
aaa.tacacs
config.add_command
feature.feature
config.add_command
kube.kubernetes
nat.nat
config.add_command
vlan.vlan
lot
code
single
function
FYI
comments
well
variables
fantastic
renaming
suggestion
rename
participantId
column
df
=
df.rename
columns=
'person_id
short
summary
blank
line
paragraph
https
//www.python.org/dev/peps/pep-0257/
multi-line-docstrings
sure
opt_nit
comment
sentence
much
comparison
code
feels
something
copy-pasted
lot
boilerplate
possible
someone
current
other
drive-backed
table
same
scope
issue
solution
minimum
parameters
query
str
external_data_scopes
List
[
str
]
docstring
😄
Please
due
diligence
<
hour
token
client
somehow
anything
Glad
different
package
utils.auth
get_access_token
scope
s
parameter
scope
List
[
str
]
😄
function
get_sandbox_tablenames
appropriate
rule
usage
get_query_specs
helper
name
sandbox
table
rule
rule
more
sandbox
table
get_sandbox_tablenames
purpose
list
position
one
helper
function
rule
more
sandbox
table
base_name
parameter
something
suggestion
def
get_sandbox_table_name
return
f
self._issue_numbers
]
.lower
def
get_sandbox_tablenames
return
[
get_sandbox_table_name
Krishna
use
COALESCE
COUNT
*
count
value
positive
number
COUNT
*
count
empty
value
line
return
bool
check_pid_df.get_value
'count
return
check_pid_df.get_value
'count
zero
python
positive
numbers
truthy
test
due
logic
errors
errors
get_date_info_for_pids_tables
functions
get_date_info_for_pids_tables
entire
function
calls
external
resources
return
values
comment
retract_deactivated_pids.py
more
info
error
comments
unit
error
purpose
automated
documentation
blank
line
line
summary
sting
single
bigquery
script
lot
efficient
suggestion
self.load_test_data
[
f
insert_observation_query
insert_concept_query
insert_concept_relationship_query
]
indices
bit
sketchy
regex
least
obvious
assertion
input
value
e.g
error
expected
prefix
correct
length
worth
example
value
comment
clear
nit
odd
comment
import
ordering
error
passing
sandbox-tables
field
argument
function
get_sandbox_table_names
error
value
recent
call
last
File
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
<
module
>
main
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
main
globals
debugger.run
setup
[
'file
]
None
None
is_module
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
run
return
self._exec
is_module
entry_point_fn
module_name
file
globals
locals
/Applications/PyCharm
CE.app/Contents/helpers/pydev/pydevd.py
line
_exec
pydev_imports.execfile
file
globals
locals
script
File
/Applications/PyCharm
CE.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py
line
execfile
exec
compile
contents+
\n
file
'exec
glob
loc
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
<
module
>
main
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
main
write_csv_report
args.output_filepath
args.data_stage
args.fields
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
write_csv_report
required_fields_dict
=
get_stage_elements
stage
fields_list
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/reporter.py
line
get_stage_elements
value
getattr
instance
func
data
/Users/aimeemcgrenera/Documents/dev/curation/data_steward/cdr_cleaner/cleaning_rules/clean_mapping.py
line
get_sandbox_tablenames
NotImplementedError
Please
NotImplementedError
Please
strip
Suggestion
=
input_line.strip
line
empty
input_line
=
b
cols
input_lint.split
b
opt
issue
input
CSV
files
way
someone
CSV
value
DROP
TABLES
insert
meaningful
BigQuery
injection
comment
project_id
deactivated
participants
table
project
project_id
same
value
third
parameter
project
deactivated_pids
table
]
parameter
documentation
error
label
suggestion
self.assertRaises
RuntimeError
update_labels_and_tags
self.dataset_id
existing_labels_or_tags=
'apples
'oranges
print
s
merging
previous
comment
comment
fast
magic
array
assignment
conversion
abstract
class
concrete
example
@
richardjgowers
comment
instance
suggestion
concrete
example
transformation
group
atoms
z-axis
center
geometry
fixed
increment
time
step
meth
rotation
angle
time
transformation
class
spin_atoms
object
def
__init__
atoms
dphi
Rotate
atoms
dphi
degrees
time
step
z
axis
self.atoms
atoms
=
dphi
self.axis
=
np.array
[
]
self.phi
def
__call__
ts
self.atoms.rotateby
self.phi
self.axis
return
ts
transformation
u
=
mda.Universe
PSF
DCD
u.trajectory.add_transformations
spin_atoms
u.select_atoms
protein
nglview
notebook
example
conversion
relevant
user
library
–
comment
code
thinking
motivation
specific
developer
section
text
sense
someone
code
historical
knowledge
shoes
someone
first
time
docstring
__init__
documents
inputs
RDKITReader
docstring
_Readermeta
separate
test
multiple
times
comments
bit
pedantic
comment
patch
version
try
sure
atoms
Issue
ag_or_ts
=
obj.atoms
velocities
ag_or_ts.velocities
names
ag_or_ts.names
resnames
AttributeError
isinstance
base.Timestep
ag_or_ts
=
obj.copy
=
itertools.cycle
X
missing_topology.append
resnames
=
itertools.cycle
'UNK
missing_topology.append
TypeError
Timestep
obj
argument
todo
Just
TODO
comment
asserts
good
solution
comment
case
case
atoms
single
Atom
comment
suggestion
..
documentation
parameters
[
numpy
standard
]
https
//numpydoc.readthedocs.io/en/latest/format.html
docstring-standard
MDA
formats
format
section
Memory
https
//docs.mdanalysis.org/1.0.0/documentation_pages/coordinates/init.html
id23
e.g
INPCRD
line
idea
near
future
format
BaseTest
reason
WIP
quick
comment
reason
AnalysisBase
Unnecessary
comment
suggestion
Write
information
obj
current
frame
trajectory
TODO
Remove
timestep
logic
suggestion
Write
information
obj
current
frame
trajectory
suggestion
Test
timestep
ts
periodic
box
suggestion
Write
information
ag
current
frame
trajectory
suggestion
Write
information
ag
current
frame
trajectory
suggestion
Write
information
obj
current
frame
trajectory
suggestion
Write
information
ag
current
frame
trajectory
need
hint
review
lots
docs
changes
nice
next
time
real
fix
python
frame_results.append
[
h.index
a.index
h.index
a.index
h.resname
h.resid
h.name
a.resname
a.resid
a.name
dist
]
atom
information
tuple
h.resname
h.resid
h.name
a.resname
a.resid
a.name
mangled
name
unambiguous
data
_timeseries
timeseries
previous
output
other
methods
generate_table
count_
*
timeseries_by_type
unambiguous
data
own
data
structures
unambiguous
time
series
data
issue
_reformat_hb
way
same
timeseries
previous
versions
principle
atom
indices
Please
link
definition
file
format
public
documentation
file
format
description
docs
record
code
AmeyaHarmalkar
@
zemanj
comment
https
//github.com/MDAnalysis/mdanalysis/pull/2627
discussion_r399829470
few
residues
atoms
elements
atom-wise
@
lilyminium
comment
https
//github.com/MDAnalysis/mdanalysis/pull/2627
discussion_r399722309
set
comparison
elements
elements
=
i
i
set
elements
element
SYMB2Z
element
elem_set
attrs.append
Elements
np.array
[
i.capitalize
i
elements
]
dtype=object
Note
other
attrs
numpy
arrays
consistent
reason
fail
travis
line
comment
refers
year
old
OS
clear
method
AtomGroups
list
AtomGroups
atoms
group
example
TIP4P
water
bonds
such
import
MDAnalysis
mda
MDAnalysisTests.datafiles
import
GRO
u
=
mda.Universe
GRO
=
u.select_atoms
SOL
name
OW
name
HW1
'residue
=
u.select_atoms
SOL
name
OW
name
HW2
'residue
=
u.select_atoms
SOL
name
OW
name
MW
'residue
u.add_bonds
ow_hw1
+
ow_hw2
+
ow_mw
smarter
way
nit
docstring
exception
hardcode
TODO
config
TODO
mbarbella
old
clusterfuzz-tools
client
id
nit
empty
line
comment
line
older
comment
specific
attention
count
query
anything
potential
problems
weights
fine
metrics
thing
case
bigquery
fuzzer
weights
datastore
entity
comment
query
name
bit
odd
rest
context
constant
query
more
fixed
probability
BANDIT_PROBABILITY_QUERY
something
lones
clear
comment
add
define
ISSUE_VIEW_RESTRICTIONS
security
env.yaml
security
strings
comment
Nit
docstrings
logs.log
mutator_plugin_path
TODO
Did
comment
design
doc
i
yaml
.options
info
name
feels
hacky
sure
sense
libfuzzer
get_fuzz_timeout
specific
syzkaller
specific
loop
loop
something
whitespace
=
[
]
whitespace_index
range
index
testcase.tokens
testcase.strip
whitespace.append
whitespace_index
next
non-whitespace
comma
hypothesis
comments
period
Ideally
names
meaningful
understanding
comments
minimizer
e.g
test_try_catch_hypothesis
bit
complicated
attempt
description
current
scheme
Nit
docstrings
test
functions
certain
messages
tests
nit
comment
comment
ENTITY_SIZE_LIMIT
actual
code
protobuf-generated
code
e.g
https
//github.com/protocolbuffers/protobuf/issues/4420
issuecomment-377630565
linting
file
license
comment
lint.py:177
Globals
easier
e.g
local
lint
complains
lowercase
look
constant
_PY_INIT_FILENAME
constant
Same
comment
above
INITIAL_DELAY_SECONDS
MAXIUM_DELAY_SECONDS
var
name
default
names
+clarity
lib
=
seconds
seconds
_DEFAULT_DEADLINE
*
seconds
comment
unused
args
unrelated
function
build_id
target
=
settings.get_kernel_info
repro_filename
=
settings.get_symbols_filename
'repro.prop
other
helper
function
docstring
statuses
same
jira
projects
different
docstring
suggestion
check
settings
Microsoft
region
prefix
settings.MT_MICROSOFT_REGION
None
region
region
.format
settings.MT_MICROSOFT_REGION
self._cognitive_token_url
=
TOKEN_URL.format
region
settings.MT_MICROSOFT_COGNITIVE_KEY
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmps_qbtuf9/config.py
+++
b/tmp/tmps_qbtuf9/config.py
@
@
-24,7
+24,7
@
@
BOT_ADMINS
=
os.environ.get
.split
*
@
localhost
Text
special
case
BACKEND
==
BOT_ADMINS=
@
localhost
BOT_ADMINS
=
@
localhost
BOT_IDENTITY
=
os.environ.get
'COBOT_TOKEN
printing
note
worth
docstring
last_modified_date
datetime
timezone
start_time
/
end_time
offset-aware
datetimes
None
docstring
value
__init__
docstring
input
expectation
descriptions
sure
unsure
f_namemax
max
length
filename
component
entire
path
way
base_tmp_dir
+
task_name
path
packages.tar
bit
f_namemax
max
total
path
length
issue
max
length
component
path
base
path
pl_model.search
[
'id
pricelists
simpler
@
jbeficent
enough
partial
reconciliations
account
env.cr.execute
UPDATE
account_move_line
SET
payment_id
=
FROM
account_voucher_line
avl
JOIN
ON
av.id
=
WHERE
avl.move_line_id
=
AND
av.voucher_type
IN
'receipt
'payment
AND
av.state
IN
'draft
AND
NOT
IS
NULL
OR
NOT
IS
NULL
sure
pytest
documentation
usage
pytest.raises
python
pytest.raises
RuntimeError
excinfo
def
f
f
f
maximum
recursion
str
excinfo.value
@
todo
change
TODO
*
explanation
docstring
different
SLR
Perfect
D
Just
example
2020-07-20T10:19:28.1178646Z
======================================================================
2020-07-20T10:19:28.1178800Z
ERROR
test_docstring
tests.test_docstrings.operation_output_GetSingle
2020-07-20T10:19:28.1179927Z
Traceback
recent
call
last
2020-07-20T10:19:28.1180484Z
File
/home/runner/work/dffml/dffml/tests/test_docstrings.py
line
testcase
2020-07-20T10:19:28.1180684Z
run_doctest
state
File
/home/runner/work/dffml/dffml/tests/test_docstrings.py
line
run_doctest
2020-07-20T10:19:28.1181213Z
raise
Exception
2020-07-20T10:19:28.1181343Z
Exception
Trying
2020-07-20T10:19:28.1181469Z
import
2020-07-20T10:19:28.1181590Z
nothing
2020-07-20T10:19:28.1181715Z
ok
2020-07-20T10:19:28.1181833Z
Trying
2020-07-20T10:19:28.1181958Z
dffml
import
2020-07-20T10:19:28.1182080Z
Expecting
nothing
2020-07-20T10:19:28.1182200Z
ok
2020-07-20T10:19:28.1182304Z
Trying
2020-07-20T10:19:28.1182438Z
URL
=
Definition
name=
URL
primitive=
string
nothing
2020-07-20T10:19:28.1182691Z
ok
2020-07-20T10:19:28.1182808Z
Trying
2020-07-20T10:19:28.1182936Z
ORG
=
Definition
name=
ORG
primitive=
string
nothing
2020-07-20T10:19:28.1183182Z
ok
2020-07-20T10:19:28.1183298Z
Trying
2020-07-20T10:19:28.1183428Z
dataflow
=
DataFlow.auto
GetSingle
nothing
2020-07-20T10:19:28.1183672Z
ok
2020-07-20T10:19:28.1183789Z
Trying
2020-07-20T10:19:28.1183912Z
dataflow.seed.append
2020-07-20T10:19:28.1184041Z
Input
2020-07-20T10:19:28.1184181Z
value=
[
Repo
Link
URL.name
ORG.name
]
2020-07-20T10:19:28.1184329Z
definition=GetSingle.op.inputs
spec
2020-07-20T10:19:28.1184463Z
nothing
2020-07-20T10:19:28.1184807Z
ok
2020-07-20T10:19:28.1184925Z
Trying
2020-07-20T10:19:28.1185046Z
async
def
main
2020-07-20T10:19:28.1185191Z
async
ctx
results
MemoryOrchestrator.run
dataflow
[
2020-07-20T10:19:28.1185335Z
Input
2020-07-20T10:19:28.1185509Z
value=
https
//github.com/intel/dffml
2020-07-20T10:19:28.1185666Z
definition=URL
2020-07-20T10:19:28.1185798Z
2020-07-20T10:19:28.1185930Z
Input
2020-07-20T10:19:28.1186064Z
value=
Intel
2020-07-20T10:19:28.1186200Z
definition=ORG
2020-07-20T10:19:28.1186329Z
2020-07-20T10:19:28.1186457Z
]
2020-07-20T10:19:28.1186587Z
print
results
2020-07-20T10:19:28.1186710Z
nothing
2020-07-20T10:19:28.1186829Z
ok
2020-07-20T10:19:28.1186944Z
Trying
2020-07-20T10:19:28.1187065Z
asyncio.run
main
2020-07-20T10:19:28.1187186Z
Expecting
2020-07-20T10:19:28.1187596Z
'Intel
Link
'https
//github.com/intel/dffml
2020-07-20T10:19:28.1187761Z
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
2020-07-20T10:19:28.1188138Z
File
/home/runner/work/dffml/dffml/dffml/operation/output.py
line
GetSingle
2020-07-20T10:19:28.1188658Z
example
2020-07-20T10:19:28.1188793Z
asyncio.run
main
2020-07-20T10:19:28.1188915Z
Exception
2020-07-20T10:19:28.1189046Z
Traceback
recent
call
last
2020-07-20T10:19:28.1189526Z
File
/usr/share/miniconda/lib/python3.8/doctest.py
line
__run
2020-07-20T10:19:28.1189734Z
exec
compile
example.source
filename
single
2020-07-20T10:19:28.1190244Z
File
<
doctest
GetSingle
]
>
line
<
module
2020-07-20T10:19:28.1190413Z
asyncio.run
main
File
/usr/share/miniconda/lib/python3.8/asyncio/runners.py
line
2020-07-20T10:19:28.1190863Z
return
loop.run_until_complete
main
2020-07-20T10:19:28.1191158Z
File
/usr/share/miniconda/lib/python3.8/asyncio/base_events.py
line
run_until_complete
2020-07-20T10:19:28.1191461Z
return
future.result
File
<
doctest
GetSingle
]
>
line
main
2020-07-20T10:19:28.1191904Z
async
ctx
results
MemoryOrchestrator.run
dataflow
[
2020-07-20T10:19:28.1192219Z
File
/home/runner/work/dffml/dffml/dffml/df/base.py
line
2020-07-20T10:19:28.1192402Z
async
ctx
results
octx.run
inputs
2020-07-20T10:19:28.1192656Z
File
/home/runner/work/dffml/dffml/dffml/df/memory.py
line
2020-07-20T10:19:28.1192832Z
raise
exception
2020-07-20T10:19:28.1193100Z
File
/home/runner/work/dffml/dffml/dffml/df/memory.py
line
run_operations_for_ctx
2020-07-20T10:19:28.1193267Z
output
=
2020-07-20T10:19:28.1193521Z
File
/home/runner/work/dffml/dffml/dffml/df/memory.py
line
<
dictcomp
>
2020-07-20T10:19:28.1193687Z
output
=
2020-07-20T10:19:28.1193937Z
File
/home/runner/work/dffml/dffml/dffml/df/memory.py
line
run_stage
2020-07-20T10:19:28.1194116Z
yield
operation
2020-07-20T10:19:28.1194420Z
File
/home/runner/work/dffml/dffml/dffml/df/memory.py
line
2020-07-20T10:19:28.1194589Z
outputs
=
inputs
File
/home/runner/work/dffml/dffml/dffml/operation/output.py
line
2020-07-20T10:19:28.1195220Z
want
=
await
super
inputs
File
/home/runner/work/dffml/dffml/dffml/operation/output.py
line
key
value
want.items
2020-07-20T10:19:28.1195724Z
RuntimeError
dictionary
keys
iteration
comment
FileSourceTest
couple
little
tests
comments
basic
functionality
suggestion
@
unittest.skip
def
test_tag
suggestion
docstring
description
First
line
short
summary
empty
line
body
bit
more
detail
Please
return
data
type
docstring
dict
None
suggestion
https
//access.redhat.com/articles/4055961
article
accessible
public
customers
information
[
Python
RHEL
blog
post
]
https
//developers.redhat.com/blog/2018/11/14/python-in-rhel-8/
RHEL
beta
release
notes
https
//access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8-beta/html-single/configuring_basic_system_settings/index
using-python3
Add
please
function
library
https
//github.com/oamg/leapp-repository/blob/master/CONTRIBUTING.md
code-style
functions
visible
actors
please
std
indentation
other
docstrings
valid
doc
dict
optional
repositories
RepositoriesMap
RepositoriesMap
messages
map
dict
optional
repositories
RHEL
system
CRB
repositories
RHEL
RepositoriesMap
model
..
python
NEW_QUIRKS
=
CANON_DR
'/etc/sane.d/cardscan.conf
CARDSCAN
'/etc/sane.d/dll.conf
DLL
'/etc/sane.d/epjitsu.conf
EPJITSU
FUJITSU
'/etc/sane.d/canon.conf
CANON
'/etc/sane.d/xerox_mfp.conf
XEROX_MFP
Dictionary
configuration
files
Args
x.start_frame
<
return
list
[
int
obj
SSNInstance
str
]
open
r
f
anet_labels
[
x.strip
x
f
]
docstring
aiozipkin
turn
synchronous
zipkin
client
suggestion
sure
suggestion
is_eligible
=
is_eligible_for_indexing
None
même
pour
les
prochains
tests
Hmm
COPY
FROM
way
transactional
Postgres
https
//dba.stackexchange.com/questions/184032/postgresql-how-does-copy-from-behave-inside-a-transaction
comment
logic
other
times
logic
same
small
changes
example
requirements
https
//github.com/rtfd/readthedocs.org/issues/1621
issuecomment-400010083
v1
behavior
v1
code
wrong
meaningful
docstring
user
check
unlinked_references
help
serialization
records
OK
result
parse_delimited_table
loop
dicts
same
keys
list
lower
keys
same
dicts
chance
keys
uppercase
better
lower
time
e.g
content
[
]
=
content
]
.lower
parse_delimited_table
PS
subsys_name
keys
subsys_name
hierarchy
num_cgroups
Same
comment
return
[
i_subsys_name
]
[
]
check-condition
utilities
parse_delimited_table
line-53
python
parse_delimited_table
content
heading_ignore=
[
'subsys_name
]
header_substitute=
[
subsys_name
'subsys_name
]
Same
comment
Better
change
CommandParser
base
python_-m_insights.tools.cat
command
below
host
~~~
~
]
cat
insights-vm37-39.gsslab.pek2.redhat.com-20190222010448/insights_commands/python_-m_insights.tools.cat_
no-header_rhev_data_center
/usr/bin/python
module
insights.tools
~~~
issue
insight-client
sure
parser
robust
output
list
~~~
kpatch
list
Loaded
patch
modules
kpatch_7_0_1_el7
patch
modules
kpatch-7-0-1-el7.ko
3.10.0-121.el7.x86_64
kpatch-7-0-1-el7.ko
3.10.0-123.el7.x86_64
line
loaded
part
sense
exit
condition
thread
function
return
value
def
_sdnotify_loop
ret
=
True
ret
global
ret
Python
goofy
variable
scoping
works
=
_systemd_notify
pid
way
needs
reason
non-zero
exit
code
systemd-notify
Popen
failure
child
process
thread
ernestask
please
examples
documented
[
]
https
//insights-core.readthedocs.io/en/latest/docs_guidelines.html
docstring-details
flake8
errors
CI
results
flake8
project
test
pytests
Documentation
generation
documentation
[
]
https
//insights-core.readthedocs.io/en/latest/docs_guidelines.html
testing-your-docstring
lstrip
reserved
keyword
python
l_strip
list
times
inefficient
unnecessary
implementation
10-15x
faster
def
lines_stripped_faster
lines
empty
lines
Returns
list
lines
empty
lines
end
list.
lines
=
self.lines
[
]
index
range
self.lines
-1
-1
lines
[
index
]
del
lines
[
index
]
return
lines
Please
docstring
method
default
base
class
method
self.vm_name
content
sub-classes
above
logic
corresponding
sub-class
comment
same
comment
above
simple
way
index
below
Exception
such
line
index
=
[
i
i
l
enumerate
content
l.startswith
Aggregate
Broker
Statistics
index
raise
ParseException
Incorrect
Content
..
BLABLA
....
index
=
index
]
duplicate
code
current
parsers
bit
similar
base
class
duplicate
codes
tab
indent
second
line
html
docstring
number
correct
cases
corresponding
explanation
comment
number
below
line
https
//access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/deployment_guide/s2-proc-stat
Same
comment
above
applies
properties
attributes
class
JoySnow
docstring
public
method
Normally
attributes
Attributes
keyword
documentation
guidelines
structure
data
attribute
example
Attributes
data
list
dict
List
input
lines
line
dictionary
keys
Attributes
docsting
class
documentation
good
LegacyItemAccess
case
self.data
list
ok
comments
JoySnow
@
deprecation
feature
method
[
document
]
https
//insights-core.readthedocs.io/en/latest/api.html
feature-deprecation
please
warning
docstring
users
[
'Cores
socket
]
[
example
]
https
//github.com/RedHatInsights/insights-core/blob/827faf50b5b34d78a2fd21167d69b9ea2aff3abc/insights/parsers/nfs_exports.py
L142
Same
comment
above
Please
corresponding
documentation
new
attribute
e.g
Attributes
docstring
class
BTW
parse_content
__init__
base
class
self.server_role
parse_content
re-implentmentation
__init__
above
docstring
server_role
must-exist
attribute
parser
OK
value
None
current
logic
Server
role
line
spec
OR
ParseException/SkipException
case
psachin
.file_name
.file_path
attributes
parser
path=
attribute
need
Did
assert
Same
comment
other
tests
_bridge_name
bridge_name
attribute
attribute
flow_dumps
list
attribute
combiner
things
dictionary
parser
bridges
parser
documentation
rendered
output
[
core
docs
]
https
//insights-core.readthedocs.io/en/latest/docs_guidelines.html
documentation-guidelines
errors
docs
Attributes
same
level
parse_content
Examples
data
attribute
class
interface
Better
move
class
docstring
same
re
code
Filter
system
framework
frames
stacktrace
order
better
similar
logical
application
paths.
docstring
concise
way
Exception
Message
Processor
documentation
status
comment
helper
constructor
zero-sized
quotas
effective
use
other
kind
constructor
documentation
purposes
reason
several
internal
APIs
such
get_key_quota
base.py
BasicRedisQuota
tuples
code
tuples
limited
vs
unlimited
__init__
branches
something
limited
unlimited
constructor
knowledge
BasicRedisQuota
follow-up
refactor
BasicRedisQuota
base.py
problems
quotas
service
relay
project
config
endpoint
service
abstraction
further
follow-up
pr
minutes
times
seconds
lot
simpler
time
minutes
intervals
shifted
interval_start
=
minutes
duration
+
jitter
interval_start
>
previous
interval
interval_start
=
interval_start
duration
next
interval
nothing
sense
IF
happy
person
jitter
proof
concept
cache
rate
jitter
Comment
wrong
details
@
mgaeta
Nit
get_owners
function
TODO
something
https
//github.com/getsentry/sentry/blob/9c87c1ae59f6d1eae39e2bcecee0b192cb8bf3f5/src/sentry/search/django/backend.py
L241-L251
https
//github.com/getsentry/sentry/blob/master/src/sentry/interfaces/message.py
L24-L37
message
only
field
fallback
formatted
available
aware
branch
grimacing
https
//github.com/getsentry/sentry/blob/master/src/sentry/interfaces/message.py
L47-L50
jaded
comment
type
validation
time
Oh
jeez
https
//github.com/getsentry/sentry/blob/81ff9121563efffc99bb09d75e324a5be7af48fd/src/sentry/event_manager.py
L346-L371
Yeah
last
part
comment
query
O
times
Organization
objects
orgs
=
org.id
org
org
integration.organizations.all
Repository.objects.filter
....
self._handle
event
orgs
[
repo.organization_id
]
repo
right
Azure
comments
....
PUT
requests
full
set
widgets
request
order
elements
PUT
data
ordering
user
explicit
order
field
Magic
number
alert
—
sure
constant
value
setting
somewhere…
cases
single
load
method
def
load
key
id
chunks=None
chunks
None
single
fetch
chunks
chunk
ids
return
result
same
set
please
get_chunk
set_chunk
addition
cache
good
idea
consumer
iirc
comment
@
mgaeta
project_list
Jira
Sentry
projects
docstrings
right
request
method
@
pierredup
earlier
comment
clarity
something
[
project_name
repo_name
]
=
repo.name.split
/
subsequent
invocation
get_commits
bit
easier
Is
something
other
data
bind_nodes
method
data
parameter
default
value
parameter
Long-winded
comment
incoming
*
necessary
*
se
fetch_bucket_frequencies
felt
natural
move
same
behavior
inner
functions
long
complex
functions
few
reasons
lot
easier
overall
control
flow
[
lines
207-230
]
https
//github.com/getsentry/sentry/blob/5b044a8924b9056a58868c6072e2c7fa18de3a5d/src/sentry/similarity.py
L207-L230
able
subroutines
front
name
hope
first
code
functions
idea
inputs
outputs
concerned
*
program
bucket
frequencies
keys
*
Redis
promises
bucket
values
questions
specific
implementation
code
implementation
details
likelihood
unintentional
name
long
function
names
responses
key
band
fewer
local
variables
play
independent
function
easier
number
local
variables
frame
case
Sentry
stacktrace
debugging
*
methods
class
part
private
interface
signals
specific
purpose
method
personal
vendetta
public
methods
different
methods
same
class
definition
practical
reason
overridden
docstring
sure
context
MinHashIndex
part
class
definition
Nit
BitHandler
stuff
comment
Helpful
comment
first
comment
good
place
struct
hits
limit
most
logic
get_result
comment
readable
dict
comprehension
=
model
to_project_filter_model_query
reason
dataset
aggregate
course
return
function
reason
model
FILTER_STAT_KEYS_TO_VALUES.items
clear
same
comment
single
query
test_todo
suggestion
Widgets
dashboard
validated_data
channel
ID
able
user
messages
channel
channel
name
prefix
@
user
better
more
generic
name
name
generic
Same
comment
regard
enumeration
ordinal
placeholder
due
counts
least
comment
direct
translation
suggestion
column
]
==
transform
project
transform
group
project_id
groupby.append
column
]
golf
@
Nit
existing_data_exports
docstring
behavior
docstring
see
finish_pipeline
method
integrations.pipeline
module
integration
band
integration
external_id
named
tuple
ExistingIntegrationRef
exeternal_id=
state
[
'identity
]
[
'bitbucket_client_id
]
finish_pipeline
get_or_create
get
organization
integration
webhook
pipeline
organization
'publicKey
return
ExistingIntegrationRef
exeternal_id=
state
[
'identity
]
[
'bitbucket_client_id
]
principal_data
=
state
'principal
]
user_data
state
[
'user
]
return
'bitbucket
state
'clientKey
]
principal_data
]
state
'publicKey
]
state
[
]
state
'baseApiUrl
]
principal_data
'links
]
[
'html
]
[
'href
]
.replace
//
principal_data
'links
]
[
'avatar
]
[
'href
]
'user_identity
'bitbucket
user_data
]
user_data
]
user_data
]
user_data
'links
]
[
'avatar
]
[
'href
]
TODO
change
compatible
Might
bad
idea
outcomes
*
*
result
set
time
range
different
organization
query
conditions
docstring
function
good
task
assertion
examples
other
tests
Same
comment
test
documentation
[
scipy.stats.mstats.mquantiles
]
https
//docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mstats.mquantiles.html
scipy.stats.mstats.mquantiles
masked
array
suggestion
sense
_pygit_
versions
functions
pygit.Commit
objects
arguments
versions
cluttered
suggestion
Bug
representation
pygit2.Commit
class
monospaced
font
enclose
backticks
docstrings
class
names
functions
clear
program
constructs
general
concepts
e.g.
pygit2.Commit
vs
commit
nouns
general
lowercase
actual
class
names
course
number
short
notice
docstring
nice
Mock
return_value
functions
Other
members
autospeccing
mock
same
interface
real
object
tests
other
tests
pass
chance
example
first
test
case
suggestion
mock
issue
correct
labels
=
create_autospec
Label
bug_label.name
bug
irrelevant_label
=
create_autospec
Label
irrelevant_label.name
good
first
issue
issue
=
create_autospec
Issue
=
[
irrelevant_label
bug_label
]
issue.id
=
sane
mock
issue
event
issue_event_bug
=
create_autospec
IssueEvent
issue_event_bug.event
=
issue_event_bug.commit_id
issue_event_bug.issue
=
issue
mock
issue
event
commit
issue_event_no_commit
=
create_autospec
IssueEvent
issue_event_no_commit.event
=
issue_event_no_commit.commit_id
=
None
issue_event_no_commit.issue
=
issue
suggestion
Analysis
step
phasar
IDELinearConstantAnalysis
project
suggestion
Currently
value
option
suggestion
configuration
dict
config
values
sub
class
Implementations
subclasses
super
._extend_config
first.
suggestion
configuration
dict
config
values
sub
class
Implementations
subclasses
super
._extend_config
first.
suggestion
Maps
function
range
commits
>
problem
synapsetool
external
package
Btw
chance
Spack
chain
near
future
i
comment
synapse-tool
external
package
dependencies
neurodamus
bad
suggestion
git
ssh
//bbpcode.epfl.ch/hpc/SpatialIndex
url
=
ssh
//bbpcode.epfl.ch/hpc/SpatialIndex
Makes
easier
diy
fantasy
versions
suggestion
homepage
https
//bbpcode.epfl.ch/code/
/admin/projects/hpc/SpatialIndex
_expr_eq
extra
cost
None
checks
unlikely
cost
improved
clarity
clear
logical
comparison
blaze
expressions
least
same
logical
check
case
something
perf
much
local
comment
suggestion
Return
anything
/bin/bash
parity
AWSWorkerManager
@
percyliang
@
Logic
changes
above
comments
line
line
future
logic
matched
private
worker
program
bundle
other
available
workers
program
*
*
exact
match
*
*
*
*
bundle.metadata.request_queue
*
*
*
*
worker
tag
*
many
/
statements
something
make_condition
key
getattr
cl_user.c
key
value
documentation
uls
CLI
command
hard
docstrings
sync
details
keywords
something
documentation
cl
uls
information
keyword
structure
Add
suggestion
Does
image
service
mention
job
definitions
function
complicated
things
directories
Can
method
level
documentation
logic
able
logic
logic
method
reason
worth
refactor
clear
invariants
system
relationship
local
directory
dependencies
file
comment
accurate
function
consistent
versus
kind
name
change
clearer
name
comment
Add
overview
file
Add
comment
necessary
docstring
logic
obvious
role
FINAL_STATES
plays
Black
thins
indentation
backslash
dedent
\
[
metadata
]
Could
requests
docstring
assertion
clear
reader
last
comment
change
loop
mistake
example
advantage
Cachito
multiple
workers
suggestion
submitted_requests
[
]
initial_responses
[
client.create_new_request
payload
_
range
requests_amount
]
initial_response
initial_responses
initial_response
submitted_requests.append
initial_response
[
id
]
@
tkdchen
comment
@
tkdchen
comment
nice
optimization
archive
latest
Git
history
suggestion
filenames
glob.glob
self.package_dir
*
.tar.gz
]
Get
newest
archive
likely
newest
Git
history
previous_archive
=
max
filenames
key=os.path.getctime
]
search
match
comments
end
non-comment
line
nice
unit
test
such
case
params
docstring
comment
purpose
field
CharField
DateTime
others
explicit
COURSE_MEMBERSHIP
other
membership
URIs
future
ones
suggestion
COURSE_MEMBERSHIP
=
//purl.imsglobal.org/vocab/lis/v2/membership'
earlier…
suggestion
def
short_user_role_list
roles
return
role.split
]
role
roles
TODO
better
comment
function
description
iI
better
fact
abstract
method
wait
serial
runs
comment
need
serial
runs
need
serial
runs
run
submit
serial
run
same
process
result
avaiable
method
implementation
abstract
method
simple
return
need
distributed
runs
brief
docstrings
classes
http
SSL
case
future
better
way
port
import
ssl
import
socket
import
contextlib
host
exposed_hosts.split
contextlib.closing
ssl.wrap_socket
socket.socket
sock
pytest.raises
ssl.SSLError
sock.connect
top
specific
versions
protocol
ssl.wrap_socket
socket.socket
ssl_version=ssl.PROTOCOL_TLS
NOTE
ymmv
python
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
invalid
syntax
<
string
>
line
]
https
//app.codacy.com/app/fossasia/open-event-orga-server/pullRequest
prid=3749505
least
spaces
inline
comment
<
br
>
inline
comment
whitespace
SyntaxError
invalid
syntax
good
documentation
unexpected
indentation
unexpected
indentation
comment
indentation
unexpected
indentation
comment
请统一按照VOC来设置。
best_box_ap_list的定义应该在eval_func函数的外面
init
Nit
same
comment
=
foo
z
x
=
foo
z
option
results
narrower
lines
docstring
comment
argument
consistent
from_bundle
comment
addition
comment
other
PR
task_lifecycle
runtime_result
something
more
action-y
get_runtime_result
docstring
string
literal
first
statement
module
function
class
method
definition
PEP
Conventions
comment
module
overall
top
own
subtest
parameters
better
test
results
specific
cases
*
Bonus
*
*
subtests
subtest
test
case
parameter
subtest
currents
string
docstring
test
case
thanks
Headers
code
extra
reviewable
future
NL
everything
subsequent
lines
+4
subject
contents
previous
line
comment
requirement
Boolean
XOR
=
obsolete
above
comment
comment
cant
file
SCMB
connector
information
suggestion
Harmony
time
series
data
visualization
augmented
affinity
matrix
suggestion
Self-Assembling
Manifolds
single-cell
RNA
analysis
tool
right
i
class
indexing
AnnData
objects
class
shape
checks
easy
loop
function
file
copied
code
boolean
docstring
Change
=
False
TA_role.save
reference
BEP
reader
complete
context
validation
documentation
places
conclude
sounds
action
election
function
check
is_concluded
has_concluded
sure
semantic
docstring
election
election
function
test
differ
somehow
comment
example
value
running_tm_ver
clear
split
genesis
marker
sufficient
comment
https
//github.com/bigchaindb/bigchaindb/pull/1471/files
r118944529
ssh
tunnel
request
handler
file
utilities
necessary
ssh
connections
commands
Use
quote
character
/
layer
names
TF
something
real
docstring
such
ImageDataGenerator.__doc__
Please
real
docstring
codebase
necessary
modify
features
Same
comment
Same
comment
Same
comment
Please
Example
section
docstring
Numpy
array
example
Similar
script.py
shorter
simpler
Same
comment
format
不然这是个死循环。永远都会卡到这步
默认值的可以用defaultdict简化一点
python
]
collections
defaultdict
]
=
defaultdict
Init
signature
defaultdict
/
*
args
*
*
kwargs
Docstring
defaultdict
default_factory
[
]
>
dict
default
factory
default
factory
arguments
new
value
key
present
__getitem__
defaultdict
equal
dict
same
items
arguments
same
dict
constructor
keyword
arguments
File
/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/collections/__init__.py
Type
type
]
=
defaultdict
dict
]
[
x
]
Out
[
]
]
[
y
]
Out
[
]
哪些平台没
cpu_freq
属性初始化应该放在任何实际行为之前
譬如conn_change_cb可能会开始使用lock了
保持这个习惯先属性后行为
可以减少出错的几率
classes
__init__
imports
try
doc
string
suggestion
Backend-agnostic
base
class
collections
[
EntryResource
[
optimade.models.EntryResource
]
suggestion
total
number
entries
collection.
bit
stdlib
main
use
[
]
https
//docs.python.org/3/library/warnings.html
Please
one-line
description
docstrings
Returns
section
Better
way
def
softmax
data_format=None
elif
ndim
==
data_format
=
K.image_data_format
==
user
data_format
fallback
K.image_data_format
one-line
description
same
line
Same
comment
rest
file
Please
docstring
example
task
data
look
model
Users
able
code
Returns
Returns
n
+
D
hot
representation
input
Returns
one-hot
tensor
proper
docstring
Arguments
section
problem
search
Keras
directory
anything
useful
docs
information
https
//keras.io/search.html
q=Keras+directory
file
better
information
comment
appropriate
file
separate
pull
request
need
description
code
current
master
re-downloads
file
time
path
Keras
database
datadir_base='~/.keras'
cache_subdir='/path/to/new/destination'
datadir
=
os.path.join
datadir_base
cache_subdir
print
datadir
datadir
clever
good
worthwhile
way
absolute
path
destinations
downloaded/extracted
files
Same
comment
indentation
general
docstrings
indentation
problem
lines
first
one
level
spaces
Please
docstring
conventions
codebase
Same
docstring
format
formatting
one-line
summary
period
dosctring
Arguments
Returns
section
One-line
description
period
One-line
description
line
end
period
few
typos
fix
/
rephrase
same
shape
x
=
K.ones
]
y
=
K.ones
]
y
Does
Thanks
documentation
Please
behavior
usage
example
Please
proper
docstring
different
behaviors
other
docstrings
Keras
examples
format
line
first
line
docstring
Same
docstring
\\n
website
actual
new
line
docs
page
deeper
cleaner
solution
r
raw
triple
double
qoutes
docstring
https
//www.python.org/dev/peps/pep-0257/
ValueError
assert
docstring
method
private
purpose
failing
test
Raises
section
ValueError
https
//travis-ci.org/fchollet/keras/jobs/282558708
Please
fix
typos
Nit
first
line
one-line
summary
line
end
period
good
explicit
example
Example
section
message
part
computational
graph
Please
example
self-explanatory
Shapes
docstring
Format
docstring
style
other
docstrings
codebase
particular
Arguments
Returns
Raises
style
purposes
first
line
docstring
line
dot
tf-keras
codebase
compliant
Please
add
comments
capacity
min_after_dequeue
good
comment
keyword
Returns
section
Raises
section
code
markers
code
keywords
.e.g
Please
docstring
LeCun
scheme
way
ref
lecun_uniform
docstring
initializers
*
_normal
*
_uniform
lecun_uniform
initializer
initializer
normal
version
significant
inconsistency
code
keywords
docstrings
..
unimplemented
method
useful
docstring
specs
add
message
sure
LTIException
suggestion
Launch
request
referer
ALLOWED_HOSTS
browser
referer
header
value
referred-to
referred-from
value
https
//bit.ly/35CvPXa
sure
readability
uploaded_on__isnull=False
most
filters
suggestion
resource
playlist
consumer
site
Q
playlist__lti_id=lti.context_id
playlist__consumer_site=consumer_site
|
Q
Q
uploaded_on__isnull=False
Q
resource
playlist
same
consumer
site
portable
Q
playlist__is_portable_to_playlist=True
resource
consumer
site
portable
playlist
portable
consumer
sites
Q
playlist__is_portable_to_consumer_site=True
playlist
portable
playlist
|
Q
playlist__in=playlist_reachable_from
playlists
consumer
site
resource
portable
consumer
site
|
Q
playlist__consumer_site__in=consumer_site.reachable_from.all
organization
None
global
permissions
null=True
comment
test
verifying
organization
None
implies
global
permissions
Might
good
inline
comment
something
effect
old-style
programs
more
level
deep
program/curricula
tree
course
runs
docstring
new
behavior
method
list
objects
permission
least
majority
functions
fields
class
OrganizationGroup
something
python
class
OrganizationGroupMixin
object
fields
methods
class
OrganizationGroup
OrganizationGroupMixin
Group
org-specific
stuff
class
ProgramOrganizationGroup
OrganizationGroupMixin
Group
program-specific
stuff
Organization
permissions
name
more
clear
Nice
comment
global
permissions
program-specific
permissions
docstring
APIPermissionBase
subclass
list
user
permissions
Cool
None-
>
global
thing
docstring
logic
same
dict
time
function
top-level
constant
permissions.py
def
_build_db_to_api_permissions
dict
database
permission
string
name
APIPermissionBase
instance.
logic
DB_TO_API_PERMISSIONS
=
_build_db_to_api_permissions
addition
re-usability
easier
case
nonsense
value
bug
get_user_api_permissions
line
second
part
method
issue
comment
b64
b58
opposite
Please
crosscheck
lot
repetitive
patterns
samples
incorrect_loop_template
True
way
testing
@
pytest.mark.parametrize
'keyword
[
'break
'return
'raise
]
test_whatever
keyword
code
template.format
keyword
nested
keyword
python
True
template
generation
process
python
stop_iteration_generator_function
def
check_stop_iteration
Things
yield
yield
some_parameter
yield
generator
print
generator
case
violation
mode
fixture
def
>
async
def
need
explicit
def
functions
Only
functions
methods
example
https
//github.com/wemake-services/wemake-python-styleguide/blob/master/tests/test_visitors/test_ast/test_functions/test_complex_default_values.py
L32
😆
link
previous
violation
python
class
~ProtectedModuleViolation
same
ProtectedModuleViolation
please
empty
line
branch
super
Test
something
branch
super
Test
part
Maybe
worth
experimental
Same
comment
speech
use
case
-1e8
-inf
NaN
https
//github.com/pytorch/fairseq/blob/928dc47e7e72f3e6ed96e50942e7fb8892cdcf32/fairseq/modules/transformer_layer.py
L108-L112
sense
configurable
comment
similar
above
comment
meant
bias_k
bias_v
Same
previous
comments
part
note
important
likely
test
behavior
tests
see
chr
issue
current
files
implicit
constraint
files
test
ax.pie
vs
pyplot.pie
sure
pyplot.pie
thin
wrapper
Axes.pie
someone
more
experience
matplotlib
tests
e.g
_axes
_pyplot
comment
various
ways
points
y
Move
plot
function
use
fig
=
fig
ax2
=
ax
single
Axes
error
important
error
file
pure
python
mode
See
Does
PR
implement
issue
work
@
types
decorator
docstring
arguments
docstring
numpydoc
documentation
[
]
https
//numpydoc.readthedocs.io/en/latest/format.html
sections
Parameters
variable_name
variable_type
Description
typo
expression
s
letters
natural
beginning
sentence
Python
C
Numpy
Please
try/except
statement
possible
KeyError
user
function
neat
Same
comment
above
Same
comment
FYI
enough
changes
favorite
features
Python
*
suggestion
def
assert_counts
result
Sequence
[
str
]
lang
str
*
num_files
int
blank
int
comment
int
code
int
>
None
anything
star
keyword
argument
kwargs
anyways
language
bit
cleaner
is_executable
pex_file_path
PEX
pex_file_path
interpreter
pep-257
[
summary
]
[
rest
]
python
with-context
zip
files
Passes
positional
docstring
good
idea
handy
comment
task
./pants
login
OAuth2
subsytem
infra
/
config
comment
sense
linter
modification
[
]
https
//github.com/pantsbuild/pants/blob/6f51c0f56d8956f82df7f840d976531d64daf580/src/python/pants/engine/build_files.py
L247
sense
info
needs
prettier
exception
exception
docstring
fine
callers
suggestion
A
publishable
Python
distribution
https
//www.pantsbuild.org/docs/python-setup-py-goal.
discussion
docstring
word
root
AFAIK
mixins
constructors
method
middle
mixin
constructor
payload
=
payload
Payload
etc
dance
payload
docstring
changes
subclasses
docsite
help
subclass
See
Daniel
comment
https
//github.com/pantsbuild/pants/commit/42079bf1ffa3bf7be91c616df1ea95c32d3dd0d9
r33534265
comfortable
change
else
Pants
macOS
Worth
behaviour
case
file
places
Thank
docs
type
hints
%
correct
concern
TODO
classes
work
variants.
comment
usage
clear
variants
ux
unsure
exact
purpose
should_report_workunits
variable
code
idea
user
facing
option
should_report_zipkin_spans
use
something
appropriate
concerned
name
bit
confused
feel
free
mind
possible
smile
times
seconds
frequent
default
reporting
pretty
large
cost
millisecond
many
milliseconds
comfortable
times
per
second
guess
comment
decision
data
expensive
last
poll+callback
thread_runner
join
join
fact
last
loop
strange
background
polling
poll
knowledge
other
comment
subclasses
able
fields
relevant
such
field
snapshot
results
goal
original
provenance
useful
comment
True
str
anti-pattern
good
alternative
comment
>
field
WARNING_MESSAGE
purposes
worth
lot
time
way
track
messages
workaround
E.g
https
//github.com/pantsbuild/pants/blob/94d06ad77779c7d514b81e63d37c26ea284c0cba/tests/python/pants_test/backend/jvm/tasks/test_coursier_resolve.py
L211-L221
Totally
style
thing
context
manager
statement
formatted
value
assertion
code
statements
minimum
possible
code
context
related
idiom
Python
try-except-else
try
run_command_that_may_raise_an_exception
handle_error
exception
run_the_rest_of_the_code
try
block
1-2
lines
most
logic
code
error
helpful
>
Prepares
Python
sources
e.g
Pytest
./pants
source
root
__init__.py
files
>
NB
Python
rule
example
autoformatters
Black
relative
imports
code
original
source
files
source
roots
lot
Request
pattern
use
right
thing
good
return
types
way
rules
ie
rule
ChrootedPythonSources
HydratedTargets
reasons
way
something
example
ChrootedPythonSources
other
input
rule
graph
hundreds
ways
Digest
various
imports
type
rule
graph
more
output-centric
smaller
number
rules
able
ChrootedPythonSources
blocking
comment
thought
Nothing
union
likely
isolated
backend
test
failures
union
play
instance
union
member
UnionMembership
matching
repl
instance
something
first
instance
case
targets_to_python_repl
rule
instance
union
member
TODO
right
repl_impl
=
next
union_membership.union_rules
[
ReplImplementation
]
Get
[
ReplBinary
]
ReplImplementation
repl_impl
addresses
user
get
behavior
BUILD
file
setup_py_commands
field
good
documentation
field
field
name
value
worried
namespace
clashes
something
rid
underlying
method
kind
sketchy
Please
documentation
comment
accurate
subprocess_dir
necessary
TODO
unnecessary
costly
IT
A
goal
option
similar
other
subsystem
files
zip
entire
archive
zip
compresses
file-by-file
comment
files
zip
compression
class
name
Docstrings
comments
weight
E.g.
reporter
workunit
data
JSON
structure
fact
file
immediate
interest
https
//github.com/pantsbuild/pants/blob/master/src/python/pants/backend/jvm/tasks/bundle_create.py
root
targets
create
symlink
vt.target
self.context.target_roots
self._store_results
vt
bundle_dir
archive_path
app
behavior
Python
bundles
thinking
same
logic
codepaths
time
as-is
best
users
view
AFAICT
PythonBinary
targets
pex
product
safe
assert
comments
long-term
generic
bundle
task
deployable
archive
multiple
binaries
different
languages
use-case
jvm_app
external
script
pex
archive
Will
comment
better
copy/paste
options
bundles
consistent
options
opportunity
BundleBase
future
bundles
more
languages
language-neutral
bundle
target
comment
temp
dir
doc
comment
subsystem
goal
options
name
root
scope
options
subsystem
comment
Pylint
direct
dependencies
chroot
imports
valid
direct
dependencies
transitive
dependencies
docstring
comments
field
change
lazy
docstring
cleanup
absolute
path
MaterializeDirectoryResult
docstring
full
output
paths
kind
absolute
paths
theory
multiple
s
different
root
paths
output
paths
relative
same
directory
something
merged_directory
=
yield
Get
Snapshot
DirectoriesToMerge
tuple
d.directory_digest
d
directories_to_merge
full
set
outputs
root
relative
return
value
False
default
osx
checks
EINTR
codebase
comment
effect
Nit
CI
run
docstring
method+class
good
format
python
open
self.PANTS_INI
w
f
f.write
[
GLOBAL
]
pants_version
.format
pants_version
python_version
None
f.write
'pants_runtime_python_version
\n'.format
python_version
Thanks
comments
Great
comment
TODO
Could
first
sentence
docstring
single
line
examples
https
//www.python.org/dev/peps/pep-0257/
order
timeout
line
comment
clear
timeout
daemon_threads
line
TODO
effect
link
hm
module
magic
first
place
sense
statements
final
position
assumption
quick
comment
assignment-less
yield
end
Aaaaand
_still_
realistic
ways
binary
found
same
output
rule
trigger
re-run
rules
data
wrong
only
cases
fix
list
applicable
binary
search
path
applicable
binary
search
path
applicable
binary
search
path
upgraded
likely
contents
discovered
binaries
CAS
hack
binary
CAS
more
make_process_volatile
comment
storage
bloat
Ideally
engine
intrinsic
fingerprint
object
absolute
path
python
rule
code
expense
heavy
IO
parallelism
machine
biggest
binary
/usr/bin/packer
@
~400ms
pure
python
code
typical
python
binary
@
~50ms
case
follow-up
folks
amenable
suggestion
TODO
https
//github.com/pantsbuild/pants/issues/10819
tracks
comment
shape
return
value
worried
parameters
hand
nice
redundancy
OTOH
people
exports
exports
dependencies
people
synonym
dependencies
hard
towards
Stu
comment
counterpoint
comment
classname
stale
name
ChangeCalculator
point
method
bit
obscure
one-line
comment
semantics
sense
python
indices
[
]
use
no-index
indices
[
foo
]
pass
index
indices
None
Pex
anything
indices
None
equivalent
field
BUILD
file
ticket
clean-all
red-flag
least
deserves
comment
copyright
statement
copied
code
ie
Copyright
Pants
project
contributors
CONTRIBUTORS.md
Copyright
Twitter
Inc.
Apache
License
Version
LICENSE
use
get_data
other
_data
variant
product
data
structure
older
use
target
base
dirs
other
annoyances
pants.goal.products.Products
details
Thank
original
V1
confused
references
comment
https
//github.com/pantsbuild/pants/issues/8912
issuecomment-572388758
building
distributions
preparation
modern
Python
much
simpler
json_str
=
Path
self._args.input
.read_text
reason
excinfo.match
comment
parenthesis
code
comment
endorsement
suggestion
r
Shortcut
.makefile
.py
extension
Highlighting
single
block
source
e.g
def
test
print
pdbpp
source
similar
regard
prefixes
pdb
general
separate
private
method
_highlight
theren
tw.write
result
Makes
unit
test
suggestion
checks
path
deletable
lock
file
suggestion
Test
faulthandler
earlier
pytest
typo
sense
little
obscure
docstring
comment
helpful
IMO
problem
issue
little
obscure
long
paths
familiar
Windows
paths
bit
py
extended-length
version
path
Windows
Windows
default
maximum
length
path
MAX_PATH
characters
operations
paths
longer
fail
possible
path
extended-length
form
operation
https
//docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file
maximum-path-length-limitation
Windows
function
extended-length
absolute
version
path
other
platforms
path
unchanged.
suggestion
Ensure
long
paths
works
Windows
kill
provider.cancel
test_simple
idea
tester
hand
Remove
blocksize
PR
submit
API
blocksize/task_per-node/job_name
invocations
case
something
early
case
unexpected
shell
example
change
other
comment
understanding
logic
extra
top
process
change
retcode
stdout
stderr
=
channel.execute_wait
-TERM
.format
+
retcode
stdout
stderr
=
channel.execute_wait
-TERM
.format
commentary
other
comment
block
rid
most
docstring
ParslExecutor
duplicate
comment
line
same
final
comment
manual
configurations
parts
equivalent
manual
configurations
comments
code
CSS
login
Login
method
search
torrent
downloads
=
self.username
self.password
self.session.post
self.urls
[
]
data=login_params
response
=
self.session.get
self.url
response
log.warning
'Unable
False
'Ces
identifiants
sont
invalides
response.text
log.warning
'Invalid
username
password
settings
False
'Mon
compte
response.text
return
True
log.warning
'Unable
False
more
mind
😇
reason
way
log
message
wrong
credentials
other
unexpected
issue
ban
logging
@
p0psicles
medariox
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Parameters
overridden
'search
method
]
https
//www.codacy.com/app/pymedusa/Medusa/pullRequest
prid=648782
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
Parameters
overridden
'search
method
]
https
//www.codacy.com/app/pymedusa/Medusa/pullRequest
prid=648782
same
code
different
places
better
way
na
language
value
=
indexerApi
show_obj.indexer
.api_params.copy
[
'banners
]
=
indexer_lang
==
app.INDEXER_DEFAULT_LANGUAGE
l_indexer_api_params
[
'language
]
=
indexer_lang
show_obj.dvdorder
=
l_indexer_api_params
'dvdorder
]
=
True
self.indexer_api
=
indexerApi
show_obj.indexer
.indexer
*
*
l_indexer_api_params
indexer_show_obj
=
self.indexer_api
[
Comment
PlexFallback
comment
please
excessive
amount
code
list
comprehensions
lot
commonalities
view
code
moment
more
more
generic
less
something
common/filters.py
class
TamatoFilterBackend
filters.BaseFilterBackend
search_fields
sid
def
get_search_term
request
return
request.query_params.get
search
def
filter_queryset
request
queryset
view
search_term
=
self.get_search_term
request
return
queryset.annotate
search=SearchVector
*
self.search_fields
.filter
search=search_term
filters.SearchFilter
.filter_queryset
request
queryset
view
additional_codes/filters.py
COMBINED_ADDITIONAL_CODE_AND_TYPE_ID
=
re.compile
r
P
<
>
[
A-Z0-9
]
P
<
>
[
A-Z0-9
]
class
AdditionalCodeFilterBackend
TamatoFilterBackend
Filter
additional
code
type
ID
additional
code
ID
=
type__sid
code
def
get_search_term
request
queryset
view
search_term
=
request.query_params.get
search
match
=
COMBINED_ADDITIONAL_CODE_AND_TYPE_ID.match
search_term
match
.join
copy-pasta
TARIC
documentation
only
concern
comment
reason
hidden
lines
anyone
git
blame
convenient
test_ansible_args_correctly_passed
more
need
following
comment
title
imperative
mood
Set
Sets
typical
styling
things
first
line
imperative
end
period
single
quotes
unit
framework
units
docstrings
necessary
python
geopotential
height
blank
line
end
docstring
quotes
good
idea
docstring
accurate
URL
HTML
source
PWD
something
env.get
None
PWD
list
variables
Env
class
handles
different
PR
same
comment
applies
other
places
access
PWD
single
variant
python
variant
'precision
default='single
appropriate
values=
'mixed
'double
[
PEP257
]
https
//www.python.org/dev/peps/pep-0257/
docstring
python
CLAMR
code
cell-based
adaptive
mesh
refinement
AMR
mini-app
testbed
hybrid
algorithm
development
MPI
OpenCL
GPU
code.
excerpt
Abinit
BLAS/LAPACK/SCALAPACK-ELPA
linalg
=
spec
[
'lapack
]
.libs
+
[
'blas
]
.libs
'+scalapack
spec
oapp
with-linalg-flavor=custom+scalapack
=
spec
[
'scalapack
]
.libs
+
elif
'+elpa
spec
oapp
with-linalg-flavor=custom
oapp
with-linalg-libs=
linalg.ld_flags
https
//pypi.io/packages/source/c/cryptography/cryptography-1.8.1.tar.gz
something
depends_on
same
error
dependency
BSD-make
filename
[
GNU
documentation
]
https
//www.gnu.org/software/make/manual/make.html
first
name
GNUmakefile
most
makefiles
name
makefile
specific
GNU
other
versions
make
Other
make
programs
makefile
Makefile
GNUmakefile
Docstrings
newline
character
spaces
https
//github.com/marcelm/cutadapt/blob/master/setup.py
L15
documentation
date
setup.py
tells
http
//www.sphinx-doc.org/en/stable/ext/autodoc.html
directive-autoattribute
>
module
data
members
class
attributes
documentation
comment
special
formatting
comment
docstring
definition
docstrings
documentation
http
//spack.readthedocs.io/en/latest/spack.html
multi-line
ones
docstring
more
sense
multi-line
comment
docstring
flake8
tests
string
BundlePackage
comment
file
>
thanks
p.s
IMO
comment
changes
line
whole
comment
understood
line
comment
@
alalazo
request
https
//github.com/LLNL/spack/pull/3377
issuecomment-290334034
critiques
comment
right
python
name
executable
generic
python
python
package
something
specific
sure
packages
[
PEP
]
https
//www.python.org/dev/peps/pep-0394
single
executable
function
look
[
Recommendation
]
https
//www.python.org/dev/peps/pep-0394/
recommendation
section
PEP
>
general
python
command
version
Python
same
version
Python
python2
command
distributions
python3
command
Rationale
Migration
Notes
Python
python3
true
recommendations
PEP
>
*
order
differences
platforms
new
code
Python
interpreter
python
specific
python2.x
python3.x
versions
Migration
Notes
distinction
shebangs
shell
script
system
call
other
context
*
exception
scripts
source
compatible
Python
Such
scripts
python
shebang
line
portability
way
Python
extensions
able
python2
python3
python
compatible
expectations
packages
Packages
Python
compatible
spec
[
'python
]
.python2
Packages
Python
compatibale
spec
[
'python
]
.python3
Packages
single-source
spec
[
'python
]
.python
dual-source
packages
install
source
version
Python
compatible
version
Python
version
able
Spack
package
specific
Python
*
*
accessor
pythonX
X
pythonX.Y
*
Packages
dual-source
specific
Python
interpreters
different
versions
Python
spec
[
'python
]
.pythonX
logic
externals
*
correct
error
python2
Python
package
python3
Python
package
*
error
python
external
refers
other
installation
python
e.g.
Arch
linux
system
Python
external
Python
python
Python
interpreter
error
Python
exeternal
python
*
*
error
present
Python2
interpreter
python
-V
sure
version
reasonable
PEP
things
complex
off-topic
recommendation
PEP
>
*
interpreter
Python
script
sys.executable
hardcoded
assumptions
interpreter
location
preferred
approach
ramifications
@
alalazo
spack.environment.from_sourcing_files
python
sys.executable
PythonPackage
😄
Please
change
version
'153dc8be94badc4072016ceeac7808dc
url
https
//pypi.python.org/packages/d9/c8/8c7a2ab8ec108ba9ab9a4762c5a0d67c283d41b13b5ce46be81fdcae3656/psutil-5.0.1.tar.gz
md5=153dc8be94badc4072016ceeac7808dc
need
separate
url=
@
adamjstewart
use
PythonPackage
please
empty
line
comments
very-well
documented
feature
HeaderList
=
spec
[
'lapack
]
.headers
spec
[
'blas
]
.headers
http
//spack.readthedocs.io/en/latest/llnl.util.html
highlight=HeaderList
llnl.util.filesystem.HeaderList
packages
ag
cpp_flags
var/spack/repos/builtin/packages/
libxc.headers.cpp_flags
with-netcdf-incs=
netcdff.headers.cpp_flags
var/spack/repos/builtin/packages/cp2k/package.py
spec
[
'fftw
]
spec
[
'fftw
]
spec
[
fortran
]
spec
[
pexsi
fortran
]
.headers.cpp_flags
var/spack/repos/builtin/packages/environment-modules/package.py
cpp_flags
[
]
'CPPFLAGS=
+
'.join
cpp_flags
cc
*
[
'-c
check.c
+
[
'hdf5
]
.headers.cpp_flags.split
include_flags
spec
[
'openblas
]
.headers.cpp_flags
cflags
spec
[
pocl
]
.headers.cpp_flags.split
var/spack/repos/builtin/packages/superlu-dist/package.py
spec
[
'parmetis
]
.headers.cpp_flags
spec
[
'metis
]
.headers.cpp_flags
@
adamjstewart
module
file
line
few
Python
dependencies
Cython.Build
import
cythonize
extensions
cythonize
extensions
cython
build
py-cython
type='build
dependency
python
install_requires
click
numpy
>
future
>
scipy
>
>
>
]
HACK
backward-compatibility
QIIME
pyqi
pyqi
project
sys.version_info
]
install_requires.append
pyqi
sure
best
way
pyqi
dependency
rest
'test
[
nose
>
flake8
]
[
h5py
>
]
py-h5py
only
optional
dependency
+hdf5
variant
dependency
release
fine
GCC
bug
report
problem
tests
patches
problem
tests
Perl
fine
tests
preferred
version
fine
base
class
brevity
documentation
@
run_after
'build
def
build_node
does/is
bash
'-c
python=
PYTHON
install
bash
'-c
./ext/node/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js
python=
PYTHON
rebuild
cmake_args
rest
setuptools
run
dependency
package
comment
obvious
%
time
while
comment
people
better
comments
last
commit
homepage
//www-03.ibm.com/systems/spectrum-computing/products/mpi/
url
class
SpectrumMpi
empty
lines
Flake8
Sorry
difference
licence
versions
part
version
string
necessary
commit
d3d87ea
spack
file
full
suffix
.gpl.tgz
install
cppad
==
>
Installing
cppad
==
>
cmake
/Users/jp/Programs/GitHub/Spack/spack/opt/spack/darwin-elcapitan-x86_64/clang-7.3.0-apple/cmake-3.6.1-dbk37r7pllmngnjzo4umf4hbszv2j7i7
==
>
Fetching
http
//www.coin-or.org/download/source/CppAD/cppad-20170114.tgz
%
curl
URL
error
Found
==
>
http
//www.coin-or.org/download/source/CppAD/cppad-20170114.tgz
>
Error
FetchError
fetchers
cppad-20170114-jm5ietsxi6c4zz53o3e3q4fhwe7udkvz
/Users/jp/Programs/GitHub/Spack/spack/lib/spack/spack/package.py:965
do_fetch
def
do_fetch
stage
directory
tarball
package
directory
stage
directory
self.spec.concrete
raise
ValueError
Can
concrete
packages
start_time
=
time.time
spack.do_checksum
self.version
self.versions
tty.warn
checksum
file
%
s
%
self.spec.format
@
Ask
user
checksum
we're
interactive
non-interactive
ck_msg
=
Add
checksum
use
no-checksum
check
ignore_checksum
=
False
sys.stdout.isatty
ignore_checksum
=
tty.get_yes_or_no
Fetch
default=False
ignore_checksum
tty.msg
checksum
ck_msg
raise
FetchError
Will
%
s
%
self.spec.format
@
ck_msg
>
self.stage.fetch
self._fetch_time
=
time.time
start_time
spack.do_checksum
self.version
self.versions
self.stage.check
self.stage.cache_local
change
class
Kaldi
Package
Does
Autotools
@
adamjstewart
docstring
description
querying
mechanism
tomorrow
error
docstring
bit
few
more
comments
case
Python
futures
python
depends_on
@
type=
'run
concretization
problems
similar
things
spack
spec
py-bokeh
sure
dependency
least
build
most
license
managers
variables
license
file
many
installation
prefix
case
rid
license_file
license_comment
license_file
empty
http
//spack.readthedocs.io/en/latest/packaging_guide.html
licensed-software
license
file
comment
symbol
license
file
location
env
MOLCAS_LICENSE
set
Licensing
=
True
=
[
'MOLCAS_LICENSE
]
package
installation
Spack
license
file
users
license
key
yours
license_comment
comment
symbol
license
file
Spack
set
text
file
text
most
time
sure
exact
syntax
documentation
own
other
documentation
@
tgamblin
config
suite-sparse
versions
higher
>
~
>
Downloads
>
SuiteSparse-4.5.1
>
config
SuiteSparse
package
compilation
options
SuiteSparse
Version
SuiteSparse
top
folder
/Users/oxberry1/Downloads/SuiteSparse-4.5.1
Package
LIBRARY=
PackageNameWillGoHere
Version
VERSION=
x.y.z
SO
version
SO_VERSION=
x
System
UNAME=
Darwin
Install
directory
INSTALL=
Install
libraries
INSTALL_LIB=
/Users/oxberry1/Downloads/SuiteSparse-4.5.1/lib
Install
files
INSTALL_INCLUDE=
Install
documentation
INSTALL_DOC=
/Users/oxberry1/Downloads/SuiteSparse-4.5.1/share/doc/suitesparse-4.5.1
Optimization
level
OPTIMIZATION=
-O3
BLAS
library
BLAS=
-framework
Accelerate
LAPACK
library
LAPACK=
-framework
Accelerate
Intel
TBB
library
TBB=
Other
libraries
LDLIBS=
-lm
static
library
AR_TARGET=
PackageNameWillGoHere.a
library
full
SO_TARGET=
PackageNameWillGoHere.x.y.z.dylib
library
main
SO_MAIN=
PackageNameWillGoHere.x.dylib
library
short
SO_PLAIN=
PackageNameWillGoHere.dylib
library
options
SO_OPTS=
-L/Users/oxberry1/Downloads/SuiteSparse-4.5.1/lib
-dynamiclib
-compatibility_version
x
-current_version
x.y.z
dynamic_lookup
library
name
tool
SO_INSTALL_NAME=
install_name_tool
-id
ranlib
static
libs
RANLIB=
static
library
command
ARCHIVE=
rv
copy
file
CP=
cp
-f
move
file
MV=
file
RM=
-f
pretty
Tcov
tests
PRETTY=
|
indent
-bl
-nce
-bli0
-i4
-sob
-l120
C
compiler
CC=
cc
C++
compiler
CXX=
CUDA
compiler
NVCC=
CUDA
root
directory
CUDA_PATH=
OpenMP
flags
CFOPENMP=
C/C++
compiler
flags
CF=
-O3
-fexceptions
-fno-common
LD
flags
LDFLAGS=
-L/Users/oxberry1/Downloads/SuiteSparse-4.5.1/lib
Fortran
compiler
F77=
f77
Fortran
flags
F77FLAGS=
Intel
MKL
root
MKLROOT=
Auto
detect
Intel
icc
AUTOCC=
UMFPACK
config
UMFPACK_CONFIG=
CHOLMOD
config
CHOLMOD_CONFIG=
SuiteSparseQR
config
SPQR_CONFIG=
CUDA
library
CUDART_LIB=
CUBLAS
library
CUBLAS_LIB=
METIS
CHOLMOD/Partition
configuration
METIS
library
MY_METIS_LIB=
metis.h
MY_METIS_INC=
METIS
CHOLMOD/Partition
module
next
line
METIS
CHOLMOD
Partition
config
CHOLMOD
Partition
libs
-lccolamd
-lcamd
/Users/oxberry1/Downloads/SuiteSparse-4.5.1/lib/libmetis.dylib
CHOLMOD
Partition
-I/Users/oxberry1/Downloads/SuiteSparse-4.5.1/CCOLAMD/Include
-I/Users/oxberry1/Downloads/SuiteSparse-4.5.1/CAMD/Include
-I/Users/oxberry1/Downloads/SuiteSparse-4.5.1/metis-5.1.0/include
paranoid
>
~
>
Downloads
>
SuiteSparse-4.5.1
>
find
-name
Makefile
|
xargs
grep
FFLAGS
./CHOLMOD/Demo/Makefile
F77
FFLAGS
readhb
readhb.f
./CHOLMOD/Demo/Makefile
F77
FFLAGS
-o
readhb2
readhb2.f
./CHOLMOD/Demo/Makefile
F77
FFLAGS
-o
reade
reade.f
oxberry1
>
~
>
Downloads
>
SuiteSparse-4.5.1
>
find
-name
Makefile
|
xargs
grep
F77FLAGS
./AMD/Demo/Makefile
F77
F77FLAGS
amd_f77demo
amd_f77demo.f
..
/Lib/libamdf77.a
\
./AMD/Demo/Makefile
F77
F77FLAGS
amd_f77simple
amd_f77simple.f
\
./AMD/Demo/Makefile
F77
F77FLAGS
amd_f77cross.f
amd_f77wrapper.o
\
./AMD/Lib/Makefile
F77
F77FLAGS
..
/Source/amd.f
-o
amd.o
./AMD/Lib/Makefile
F77
F77FLAGS
..
/Source/amdbar.f
-o
amdbar.o
./SuiteSparse_config/xerbla/Makefile
COMPILE
=
F77
F77FLAGS
xerbla.f
./UMFPACK/Demo/Makefile
F77
F77FLAGS
readhb
readhb.f
F77LIB
./UMFPACK/Demo/Makefile
F77
F77FLAGS
readhb_size.f
F77LIB
./UMFPACK/Demo/Makefile
F77
F77FLAGS
readhb_nozeros
readhb_nozeros.f
F77LIB
./UMFPACK/Demo/Makefile
F77
F77FLAGS
umf4hb
umf4hb.f
umf4_f77wrapper.o
LIBS
./UMFPACK/Demo/Makefile
F77
F77FLAGS
umf4zhb
umf4zhb.f
umf4_f77zwrapper.o
LIBS
./UMFPACK/Demo/Makefile
F77
F77FLAGS
umf4hb64
umf4hb64.f
umf4_f77wrapper64.o
LIBS
FFLAGS
F77FLAGS
SuiteSparse
package
compilation
options
SuiteSparse
Version
SuiteSparse
top
folder
/Users/oxberry1/Downloads/SuiteSparse-4.5.5
Package
LIBRARY=
PackageNameWillGoHere
Version
VERSION=
x.y.z
SO
version
SO_VERSION=
x
System
UNAME=
Darwin
Install
directory
INSTALL=
Install
libraries
INSTALL_LIB=
/Users/oxberry1/Downloads/SuiteSparse-4.5.5/lib
Install
files
INSTALL_INCLUDE=
Install
documentation
INSTALL_DOC=
/Users/oxberry1/Downloads/SuiteSparse-4.5.5/share/doc/suitesparse-4.5.5
Optimization
level
OPTIMIZATION=
-O3
BLAS
library
BLAS=
-framework
Accelerate
LAPACK
library
LAPACK=
-framework
Accelerate
Intel
TBB
library
TBB=
Other
libraries
LDLIBS=
-lm
static
library
AR_TARGET=
PackageNameWillGoHere.a
library
full
SO_TARGET=
PackageNameWillGoHere.x.y.z.dylib
library
main
SO_MAIN=
PackageNameWillGoHere.x.dylib
library
short
SO_PLAIN=
PackageNameWillGoHere.dylib
library
options
SO_OPTS=
-L/Users/oxberry1/Downloads/SuiteSparse-4.5.5/lib
-dynamiclib
-compatibility_version
x
-current_version
x.y.z
dynamic_lookup
library
name
tool
SO_INSTALL_NAME=
install_name_tool
-id
ranlib
static
libs
RANLIB=
static
library
command
ARCHIVE=
rv
copy
file
CP=
cp
-f
move
file
MV=
file
RM=
-f
pretty
Tcov
tests
PRETTY=
|
indent
-bl
-nce
-bli0
-i4
-sob
-l120
C
compiler
CC=
cc
C++
compiler
CXX=
CUDA
compiler
NVCC=
CUDA
root
directory
CUDA_PATH=
OpenMP
flags
CFOPENMP=
C/C++
compiler
flags
CF=
-O3
-fexceptions
-fno-common
LD
flags
LDFLAGS=
-L/Users/oxberry1/Downloads/SuiteSparse-4.5.5/lib
Fortran
compiler
F77=
f77
Fortran
flags
F77FLAGS=
Intel
MKL
root
MKLROOT=
Auto
detect
Intel
icc
AUTOCC=
UMFPACK
config
UMFPACK_CONFIG=
CHOLMOD
config
CHOLMOD_CONFIG=
SuiteSparseQR
config
SPQR_CONFIG=
CUDA
library
CUDART_LIB=
CUBLAS
library
CUBLAS_LIB=
METIS
CHOLMOD/Partition
configuration
METIS
library
MY_METIS_LIB=
metis.h
MY_METIS_INC=
METIS
CHOLMOD/Partition
module
next
line
METIS
CHOLMOD
Partition
config
CHOLMOD
Partition
libs
-lccolamd
-lcamd
/Users/oxberry1/Downloads/SuiteSparse-4.5.5/lib/libmetis.dylib
CHOLMOD
Partition
-I/Users/oxberry1/Downloads/SuiteSparse-4.5.5/CCOLAMD/Include
-I/Users/oxberry1/Downloads/SuiteSparse-4.5.5/CAMD/Include
-I/Users/oxberry1/Downloads/SuiteSparse-4.5.5/metis-5.1.0/include
URL
other
version
shortened
pypi.io
link
https
//pypi.io/packages/source/p/py2bit/py2bit-0.2.1.tar.gz
https
//pypi.io/packages/source/p/pyBigWig/pyBigWig-0.3.4.tar.gz
https
//pypi.io/packages/source/p/pysam/pysam-0.11.2.2.tar.gz
easier
way
stream
package
example
FileFilter
documentation
]
http
//spack.readthedocs.io/en/latest/llnl.util.html
llnl.util.filesystem.filter_file
valid
options
documentation
different
directory
Manpages
prefix.man.man1
prefix.share.man.man1
TeX
docs
prefix.share
llvm
add
conflicts
%
intel
conflicts
%
gcc
sure
no-one
tries
comment
@
tgamblin
tags
full-text
search
purposes
comment
tags
Docstrings
newline
character
doc
tests
same
level
start
documentation
tests
docstring
newline
character
else
Sphinx
Travis
happy
today
documentation
tests
package
Sphinx
docstring
newline
character
Technically
valid
docstring
problem
[
Package
List
]
http
//spack.readthedocs.io/en/latest/package_list.html
docstrings
spack
list
format=rst
last
package
list
newline
start
docstring
rst
Description
Zstandard
zstd
short
version
fast
lossless
compression
algorithm
real-time
compression
scenarios
zlib-level
better
compression
ratios
newline
indentation
space
code
newline
characters
printing
um
matlab
extension
Hell
sure
multiple
extensions
activate
flann
restriction
damn
python
setup.py
help
no-user-cfg
option
python
setup.py
install
help
prefix
option
order
no-user-cfg
install
prefix
safe
setup.py
no-user-cfg
no-user-cfg
setup.py
doc
tests
space
beginning
docstring
comment
ignore=
clause
Spack
bit
explanation
comment
ignore=
clause
Spack
bit
explanation
comment
ignore=
clause
Spack
bit
explanation
%
intel
spec
comp
variant
above
Flake8
space
comment
symbol
something
funny
handcoded
configure
script
with-python-path
with-python3-path
bit
TODO
list
please
@
jppelteret
stuff
boilerplate
spack
create
example
few
projects
*
clearer
comment
package
configure
script
dependencies
various
autotools
packages
way
specific
resources/guides
put
autotools
package
[
packaging
guide
]
https
//spack.readthedocs.io/en/latest/packaging_guide.html
packaging-guide
tutorial
]
https
//spack.readthedocs.io/en/latest/tutorial_sc16_packaging.html
highlight=autotools
guidance
other
brute-force
approach
nothing
build
errors
project
documentation
dependent
libraries
priori_
practical
way
project
depends_on
depends_on
depends_on
'libtool
apologies
expert
build
systems
least
autotools
dependencies
package
line
depends_on
fine
first
phase
build
process
line
least
@
citibeth
comment
bash
==
>
Building
ccache
[
AutotoolsPackage
]
==
>
Executing
phase
==
>
Executing
phase
==
>
Executing
phase
==
>
Executing
phase
==
>
Successfully
ccache
@
alalazo
priority
documentation
different
build
systems
OT
@
alalazo
@
adamjstewart
@
davydden
anyone
[
Google
format
]
https
//sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html
[
rest
format
]
https
//stackoverflow.com/questions/3898572/what-is-the-standard-python-docstring-format
readable
Sphinx
fine
Napoleon
Sphinx
extension
formats
documentation
Google-style
guess
>
path
build_prefixes
comment
line
Fair
documentation
vcsh
only
important
thing
comment
makefile
someone
install
hot
unfinished
discussion
https
//github.com/LLNL/spack/issues/2380
issuecomment-265125696
https
//github.com/LLNL/spack/issues/2779
enough
single
variant
ah
comment
tests
autoconf
release
tags
uncommon
wrapper
script
https
//pypi.io/packages/source/M/MDAnalysis/MDAnalysis-0.15.0.tar.gz
different
versions
same
URL
package
fact
several
other
dependencies
install_requires=
[
>
=1.5.0
>
=1.59
>
=1.0
'GridDataFormats
=0.3.2
>
=1.4.0
]
extras_require=
[
>
=1.0
]
AMBER
netcdf
HDF5
netcdf-4
'analysis
[
'scipy
heat
map
nearest
neighbor
PSA
]
optional
dependencies
support
variants
problem
name
rationale
spec
Needs
fortran
bool
self.compiler.fc
True
Has
fortran
adamjstewart
unmatched
intelligent
documentation
error
>
Inline
text
phrase
reference
start-string
end-string
Please
pre-release
version
checksummable
eg
Pre-release
version
version
git='https
//github.com/quinoacomputing/ndiff
alalazo
ping
case
system
library
stuff
Change
Change
attribute
UI
queries
build
system
base
class
Same
fix
comments
CMakeClass
info
eccodes
documentation
newline
characters
more
punctuation
below
while
sense
great
comment
same
short
time
other
reason
problem
preference
bit
unclear
meta
data
worried
jupyter
notebook
annotations
notebook
output
description
warning
suggestion
Return
True
axis
true
layer
viewer
label
editing
tools
input-array
in-place
copy
labels
layer
=
viewer.add_labels
data.copy
painting/editing
result
=
layer.data
Python
built-in
names
case
value
minimal
suggestion
logger.debug
f
event
event.type
refactor
layers
complete
events
value
property
try
value
event.value
logger.debug
f
value
value
AttributeError
logger.debug
f
event
event.type
Update
event
value
component
self.components_to_update
update_method_name
=
f
event.type
_change
suggestion
nested
index
return
nested_parent_index
row
Parameters
section
full
docstring
reference
cheat
sheet
ReStructuredText
syntax
docstrings
https
//thomas-cokelaer.info/tutorials/sphinx/rest_syntax.html
inserting-code-and-literal-blocks
suggestion
example
patch_func
import
wrapt
def
_my_patcher
parent
CallableParent
callable
str
label
str
@
wrapt.patch_function_wrapper
parent
callable
def
my_announcer
instance
args
kwargs
print
f
Announce
label
return
*
args
*
*
kwargs
list
functions
/
data
same
test_napari.py
test_viewer.py
file
further
duplicate
code
only
difference
use
viewer
=
view_layer_type
layer_type
data
ndisplay
viewer
=
Viewer
layer
=
viewer.add_layer_by_type
layer_type=layer_type
data=data
viewer
instantiated
lots
duplicate
code
inside
bits
tests
same
bunch
comments
test_viewer.py
suggestion
current
=
layer.overwrite
layer.overwrite
current
yield
key
release
layer.overwrite
=
current
shift
key
current
setting
nothing
overwrite
False
Note
return
type
@
property
suggestion
Test
surface
display
other
comment
class
docstrings
results
vispy.sys_info
windows
users
info
problems
see
//github.com/napari/napari/issues/558
issuecomment-537569931
easier
dialog
box
more
users
familiar
command
line
results
Windows-10-10.0.18362-SP0
Python
default
Apr
[
MSC
bit
AMD64
Backend
PySide2
GL
version
MAX_TEXTURE_SIZE
Qt
qtpy
version
actual
Qt
version
python
qtpy
import
QtCore
QtCore.__version__
actual
Qt
version
code
bunch
comments
clear
sure
much
big
comments
file
event
original_event
Same
comment
performance
new
information
link
IMO
strings
integers
big
deal
How
similar
data
representation
https
//github.com/napari/napari/issues/539
issuecomment-564328904
request
properties
list
>
dict
change
sense
contribution
applications
section
tutorials
https
//github.com/napari/tutorials/tree/master/applications
tracks
layer
tracks
data
[
cell
]
https
//public.celltrackingchallenge.net/documents/Naming
%
%
%
%
[
SWC
]
http
//www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html
file
suggestion
Initialize
current_
edge
face
_color
empty
layer
heck
lot
work
thumbnail
work
code/computation
variable
name
processing
black
formatting
single
call
index
current
pyramid
level
downsampled_indices
np.clip
indices
not_disp
]
/
self.downsample_factors
[
-1
]
.astype
int
self.level_shapes
-1
not_disp
]
docstring
....
Incorrect
grimacing
suggestion
Convert
dataframe
Points.properties
dictionary
Similar
formatting
suggestions
docstrings
=
docstring
descriptive
bit
narrative
viewer.layers
first
run
layer
layer
present
data
Add
comment
live_tiffs_generator.py
comment
last
thing
accumulator
trackpad
scrolling
fractional
something
vertical_delta
=
event.delta
]
int_delta
=
int
vertical_delta
vertical
fractional_delta
=
self._cumulative_delta
+=
vertical_delta
int_delta
self._cumulative_delta
int_delta
self._cumulative_delta
complicating
factors
need
positive
negative
deltas
above
cumulative
delta
certain
time
other
event
fractional
scrolling
minutes
next
scroll
merge
fractional
deltas
issue
fractional
deltas
same
newline
comment
test
explanatory
comments
heart
suggestion
Normalize
array
values
range
]
*
data
users
call
format
nilearn
least
transpose
own
line
comment
top
line
transpose
data
n_vertices
x
n_timepoints
x
n_trials
napari
vertices
last
NumPy
broadcasting
rules
while
key
whole
process
dims
model
dimensions
L
+
D
current
values
index
axes
-D
]
comment
effect
suggestion
list
points
colinear
fixed
nicer
max_layer
kwarg
able
call
camera
viewer.add_pryamid
earlier
comment
Function
part
docstrings
Nick
answers
[
comment
]
https
//github.com/jni/napari/pull/5
issuecomment-589027107
qt_layerlist
event
parent
widget
child
widget
anything
parent
event
comment
monkeypatch
fixture
pytest
logic
comments
comment-at-start-of-line
comment-at-end-of-line
logic
thing
syntax
/
n_new_shapes
variables
variables
code
harder
suggestion
np.array
data
]
==
single
array
shape
n_new_shapes
data
🤷‍♂️
https
//github.com/napari/napari/pull/1023
issuecomment-604996010
[
pluggy
docs
]
https
//pluggy.readthedocs.io/en/latest/
wrappers
comment
]
https
//github.com/napari/napari/pull/1023/files/cd19161ac9ea86f17963ead631aae6eb3927b767
r392614235
comment
code
Ah
docstring
vague
clue
usage
example
docstring
sure
problem
description
comment
comment
real
event
whole
comment
block
ideas
Seems
better
suggestion
Test
shear
lower
triangular
matrix
suggestion
transform
=
Affine
shear=mat.copy
Check
shear
lower
triangular
np.testing.assert_almost_equal
mat
Set
same
value
=
mat.copy
Check
shear
lower
triangular
np.testing.assert_almost_equal
mat
Set
same
value
=
mat.copy
anything
=P
[
PEP257
]
https
//www.python.org/dev/peps/pep-0257/
specifies
one-liner
docstrings
closing
triple-quote
same
line
grammar
files
sure
renaming
files
open
segmentation
open
points
Could
comment
dictionary
suggestion
Determine
slice
image
indices
False
worth
comment
function
intuitive
False
invalid
shape
love
functions
return
type
kwargs
tlambert03
Zulip
.__call__
>
return
result
.call_with_impl
>
object
result
implementation
other
metadata
discussions
scikit-image
e.g
[
]
https
//github.com/scikit-image/scikit-image/issues/3892
issuecomment-591819705
[
meeting
notes
]
https
//github.com/scikit-image/meeting-notes/blob/master/2020/2020-02-27
BIDS-core-dev-meeting.markdown
search
API
policies
sofroniewn
docstring
view
camera
@
z4y4ts
share
instance
statistics
Paranoid+
level
CELERYBEAT_SCHEDULE
settings
schedule
declaration
admin
way
attractive
comment
try
block
different
module
Too
long
longer
chars
sorry
change
perfect
Multiline
docstrings
title
main
text
empty
line
umm
mappings
available
error
self.get_mapping_dump_name
func
change
good
comment
OSError
vs
IOError
suggestion
individual
record
user
listening
activity
time
range
timestamp
start
end
time
range
listen
count
suggestion
individual
record
user
listening
activity
time
range
timestamp
start
end
time
range
count.
test
comment
step
something
actual
size
typo
values
descriptor
redundant
-style
docstrings
way
Sphinx
individual
docstrings
lists
dictionaries
like
useful
type
contents
docstring
suggestion
expressions
list
ObserverExpression
review
question
idea
NameError
traitsui
tutor.py
useful
issue
someone
following
comment
valid
GitHub
docstring
comment
https
discussion_r406257875
>
bit
tempted
group
handler
target
object
other
places
object
methods
equals
weakrefs
live
later
other
pieces
something
Where/how
Lark
string
constant
token
types
comment
check
necessary
context
first
thought
line
good
assumptions
Python
assumptions
fine
future
alternative
duplication
Parameters
Attributes
NumPy
documentation
cases
tuple
docstring
self.values
tuple
@
kitchoi
Sorry
comment
suggestion
change
scan_width
Nit
Returns
block
docstring
same
semantics
original
code
extra
bool
call
return
bool
event.old
==
event.new
bool
conversion
likely
equality
rare
equality
check
less
rare
interpretation
result
boolean
e.g.
NumPy
rid
exception-swallowing
behaviour
point
PR
Please
issue
Same
comments
_change_accepted
suggestion
function
value
str
original
default
value
TraitDictObject.pop
Undefined
Undefined
way
default
value
default
value
key
KeyError
>
>
x
=
>
>
>
x.pop
fail
KeyError
c
My
apologies
second
pass
change
comment
first
review
branch
inconsistent
below
event
key_validator
value
notification
consistent
change
dict
Could
test
behaviour
test
fix
def
test_update_with_tranformation
td
=
TraitDict
self.notification_handler
]
td.update
self.assertEqual
td
self.assertEqual
self.assertEqual
self.assertEqual
lines
validated_key
self
[
validated_key
]
=
[
validated_key
]
test
suggestion
Remove
key
value
pair
tuple
KeyError
comment
check
necessary
_key_validator
necessary
comment
Super-picky
nitpick
suggestion
A
trait
type
value
NumPy
array
consistency
suggestion
A
trait
type
value
NumPy
array
docstring
similarity
function
other
comments
default
argument
None
method
signature
Remember
docstring
change
list
available
initializers
Same
keras
people
useful
thing
event
registry
builtin
initializers
code
registry
mapping
strings
classes
Same
comment
wrt
all_regularizers
comment
separate
tests
discussion
part
docstring
file
formats
parameter
description
Indentation
Joel
comment
Same
comment
name
generic
StackedBidirectionalLSTMWithOutputProjecetionAndResidualConnection
docstring
inconsistent
one
class
definition
repetitive
hard
need
things
multiple
places
single
change
idea
function
output
predictions
model
Instance
predictions
labels
targets
Instance
gradients
model
predicted_
model
multiple
things
NER
multiple
spans
predictions
separate
labels
gradients
span
name
predictions
labels
instance
Just
add_labels
bit
/
descriptive
other
ideas
Eric
free
first
paragraph
docstring
bad
comment
type
more
comment
Somehow
github
previous
comment
sense
loss
computation
pretty
loss
motivation
way
targets
inputs
only
reason
better
data
API
way
more
functions
signature
suitable
easy
training
comment
inputs
comment
benefits
model
PyTorch
model
abstract
class
model
Rather
raw
torch
model
richer
API
more
metadata
tensors
implementations
easier
generation
model
inputs
documentation
PyTorch
API
code
same
comment
Sorry
explanation
token_str
reverse
lookup
token_id
latter
other
comments
PR
_pretty
sure_
nothing
indexing
pipeline
token.text
pretrained
transformer
indexer
text_id
type_id
token.text
point
change
offsets
easier
+
len
text
order
character
offsets
problem
easier
idx
end_index
semantics
token.text
same
issue
prints
docstring
state
biggest
batch
block
instances
fit
memory
docstring
true
type
mismatches
docstring
signature
Rather
file
stdout
something
completed_process
=
subprocess.run
[
perl
self._srl_eval_path
predicted_path
gold_path
]
check=True
text=True
line
completed_process.stdout.split
\n
do
docs
https
//docs.python.org/3/library/subprocess.html
subprocess.CompletedProcess
comment
general
nice
shell
expansion
security
sake
paths
developer
safe
better
docstring
parameters
comments
particular
patterns
underscores
dashes
future
reference
private
methods
good
obvious
names
such
detailed
docstrings
harm
need
way
much
regexes
words
words
Words
regex
patterns
stopwords
blank
line
end
docstring
same
previous
comment
Can
fact
weights
trainable
docstring
line
BERT
Please
brief
comment
abstract
class
important
functions
comments
purpose
convention
lowercase
hyphens
registered
names
suggestion
@
Sampler.register
top-k
class
TopKSampler
Sampler
Sampler
probability
mass
function
top
k
choices
subset
logits
tensor
log-probabilities
k
number
highest-probability
options
returned
choice
temperature
probabilitis
tokens
temperature
sharper
probability
distribution
temperature
flatter
probability
distribution
Sampler
name
top-k
suggestion
@
Sampler.register
top-p
class
TopPSampler
Sampler
Sampler
probability
mass
function
top
choices
cumulative
probability
least
subset
p
minimum
cumulative
probability
highest-probability
options
returned
choice
temperature
probabilitis
tokens
temperature
sharper
probability
distribution
temperature
flatter
probability
distribution
Sampler
name
top-p
type
annotation
int
comment
bit
confused
same
comment
moreso
contrast
list
comprehension
lines
fix
comment
tuple
much
nicer
way
indexer
fine
PR
least
open
issue
Seems
important
SQuAD
more
comment
first
line
create
directories
target
lines
archive
summary
first
one
os.makedirs
os.path.split
extraction_path
]
comment
empty
spaces
matrix
minutes
thinking
mind
motivation
check
call
fail
tensor
packed
sequence
sequences
rnn
tensor
same
comment
better
documentation
functional
private
class
class
_itself_
from_params
classmethod
staticmethod
outer
class
WrappedPytorchRnn
classes
characters
come
inside
separate
private
function
instance
WrappedPytorchRnn
from_params
few
issues
_Wrapper
module
namespace
confusing
worth
_Wrapper
class
module
init
lot
more
clear
registry
dictionaries
Dict
[
str
Type
[
Something
]
]
from_params
Something.from_params
thing
dict
__call__
method
mimics
Something.__init__
from_params
method
mimics
Something.from_params
[
]
WrappedPytorchRnn
class
instantiated
pytorch
RNN
constructor
from_params
API
assumptions
info
docstring
_Wrapper
module
__init__.py
from_params
WrappedPytorchRnn
better
_Wrapper
practical
significance
decision
_Wrapper
encoder
type
lstm
input_dim
other
JSON-encodable
pytorch
LSTM
parameters
_Wrapper
encoder
type
wrapped_type
lstm
input_dim
other
JSON-encodable
pytorch
LSTM
parameters
WrappedPytorchRnn
strings
RNN
classes
single
mapping
module
init
WrappedPytorchSeq2
Seq
Vec
Encoder
similar
wrapper
classes
identical
names
different
packages
same
class
same
name
idea
point
encoders
params
better
LSTM
pytorch
note
docstrings
classes
effect
comments
class
type
annotation
tweak
mask
docstring
date
output
projection
shape
tensor
comment
addition
below
note
OrderedDict
efficiency
method
implementation
comments
Dict
needs
first
comment
parameter
code
experiments
documentation
couple
TODOs
documentation
hard
overall
design
concrete
example
API
usage
[
from_params
]
writing
few
API
straw-clients
API
details
kind
get
nice
name
pointer
params
thing
[
APIs
downstream
def
embed_text_field
input_tensors
name
def
get_recurrent_layer
name
def
get_recurrent_cell
name
def
from_params
cls
params
Params
concrete
objects
API
Christian
comment
data
flow
explicit
good
templates
better
bit
magic
user
easier
lower
level
details
class
current
method
fallback
behavior
string
defaults
difficult
barrier
others
code
understanding
encouraged
pattern
client
code/config
nlp.get_recurrent_cell
name=
my_rnn
experiment.json
my_rnn
seq2seq
nice
simple
concrete
[
precise
]
example
right
overview
docstring
nit
hard
brain
comoment
someone
typo
comment
co_moment
😀
Could
docstring
excess
in-place
Same
feedback
applies
string
show
triple
white-spaces
example
Python
>
>
>
hello
world
>
>
>
print
f
hello
world
>
>
>
Same
comment
discovery
expected
behavior
successful
replacements
non-existing
users
new
user
records
users
old
username
fine
case
docstring
api
comment
test
Remove
TODO
string
formatting
kwargs
=
site_name
BEGIN
Create
django.forms.models
model_to_dict
command_kwargs
=
model_to_dict
self.site_configuration
Allow
overrides
'site_name
site_name
site_id
command_kwargs
[
'site_id
]
=
site_id
END
Create
self.command_name
*
*
command_kwargs
fine
Pythonic
way
try
.private
import
*
pylint
disable=import-error
ImportError
pass
unrealistic
race
condition
filename
Python
better
subclass
ModuleNotFoundError
SiteConfiguration
object
Site
multi-tenancy
site
first
one—either
site_id=1
multiple
SiteConfigurations
singleton
ditto
suggestion
sdf
=
self._internal.spark_frame.select
self.spark.column
NATURAL_ORDER_COLUMN_NAME
max_value
=
sdf.select
F.max
scol_for
sdf
[
]
F.first
NATURAL_ORDER_COLUMN_NAME
max_value
]
None
raise
ValueError
attempt
argmax
empty
sequence
max_value
]
None
return
-1
natural
sequence
seq_col_name
=
verify_temp_column_name
sdf
__distributed_sequence_column__
=
InternalFrame.attach_distributed_sequence_column
sdf.drop
NATURAL_ORDER_COLUMN_NAME
seq_col_name
maximum
multiple
locations
first
row
position
return
sdf.filter
scol_for
sdf
[
]
max_value
]
.head
]
support
ks.Series
[
]
.argmax
delay
distributed
sequence
right
column
name
docstring
key
@
ueshin
comments
kind
hard
nit
Could
line
next
line
other
oops
i
haha
😅
correct
previous
comment
whole
data
beneficial
data
big
dataframe
single
column
count
operation
head
self
]
@
ueshin
Thanks
inplace
DataFrame
error
schema
inference
pandas
self._internal
=
result._internal
elif
should_return_series
series_name
=
]
]
return
result
[
series_name
]
should_return_scalar
series_name
=
]
]
return
result
[
series_name
]
]
return
result
Are
different
version
doc
https
//github.com/pandas-dev/pandas/blob/v0.24.2/pandas/core/frame.py
L1558-L1741
line
comment
test
NumPy
Paramters
underscores
typical
sphinx
docstring
..
note
..
Notes
method
Pandas
DataFrame
lot
comments
exception
script
output
strings
strings
block
code
more
minor
comment
self
adopted_task_timeouts
comprehensive
self.adopted_task_timeouts
ti.key
]
=
ti.queued_dttm
+
self.adoption_timeout
similar
names
other
look
good
comment
behaviour
project_id
inconsistent
code
comment
Readers
suggestion
Set
end
file
_serialized_fields
Optional
[
FrozenSet
[
]
]
=
None
isort
isort
skip
documentation
UPDATING.md
documentation
constant
comment
reason
change
suggestion
state_count
=
session.query
TaskInstance.pool
func.count
.filter
TaskInstance.state.in_
list
EXECUTION_STATES
TaskInstance.pool
calculate
metrics
pools
dict
state_count
variable
name
more
easy
suggestion
def
assert_log_line
text
logs_list
Get
Log
Line
Entry
exists
text
logging_mixin
line
log
line
duplicate
loggigng
[
2020-06-24
]
logging_mixin.py:91
INFO
[
2020-06-24
]
=
[
log
log
logs_list
text
log
]
self.assertEqual
log_lines
log_line
=
]
expect_from_logging_mixin
suggestion
import
importlib.resources
importlib_resources
ImportError
Try
PY
<
importlib_resources
import
importlib_resources
importlib_resources
call
old
quasi-deprecated
name
whole
selection
providers
sources
packages
setup.py
selection
criteria
complex
airflow/providers/manager.py
instal
anything
case
able
case
providers
warning
airflow.providers
checks
sure
none
code
core
airflow.providers
stuff
class
webserver
CLI
API
imports
airflow.providers
providers
package
provider
implementation
provider
management
'plugin_manger
py
POC
management
good
place
latest_scheduler_heartbeat
=
None
scheduler_status
=
metadatabase_status
=
statuses
=
metadatabase_status
scheduler_status
latest_scheduler_heartbeat
health_schema.dump
payload
approach
fixed
release/url
URL
high
risk
future
parameters
documentation
additional
assumptions
users
aware
users
data
error
parameters
broad
exception
https
//boto3.amazonaws.com/v1/documentation/api/latest/guide/error-handling.html
highlight=exception
catching-exceptions-when-using-a-resource-client
empty
different
certain
Oracle
https
//github.com/apache/airflow/pull/4895
discussion_r268388705
sure
strings
code
more
strings
BTW
type
comments
docs
worth
type
context
etc
Minor
comment
list
prevents
short-circuiting
content.endswith
ext
ext
self.template_ext
tearDown
method
hanging
Xcom
DR
data
tests
suggestion
Language
support
Python
Scala
param
job_name
unique
job
name
AWS
Account
empty
line
documentation
header
param
section
suggestion
type
run_id
str
look
documentation
Please
order
params
same
__init__
type
hints
python
comment
Need
docstrings
Add
example
case
docstrings
May
example
operator
docstrings
Similar
//github.com/apache/airflow/blob/master/airflow/contrib/operators/gcs_list_operator.py
L51
Both
arguments
Same
comment
Optional
[
Callable
]
other
comment
runAsUser
please
different
label
something
slightly_smiling_face
suggestion
type
warehouse
Optional
[
str
docstrings
types
rtype
attribute
linking
other
libraries
documentation
documentation
Reference
http
//www.sphinx-doc.org/en/master/usage/extensions/intersphinx.html
correct
syntax
documentation
class
constructor
same
time
option
options
process
building
documentation
comment
try
block
WDYT
suggestion
result
=
sqs_conn.delete_message_batch
QueueUrl=self.sqs_queue
sqs_conn
yesterday
comment
WDYT
description
self-referrential
guess
name
method
doc
comment
please
doc
value
suggestion
Checks
read
operation
current
log
handler
suggestion
Log
handler
logs
bit
bool
allow_random_task_selection
allow_random_location_selection
similar
bit
overkill
'random
string
only
strategy
thought
ok
other
strategies
mind
future-compatible
future
able
interface
other
strategies
bit
trap
documentation
bit
trap
*
simplest
possible
way
new
parameters
future
case
initial
idea
callable
good
complex
cases
better
imaginary
'choose_first
'fifo
etc
etc.
case
random
bool
bool
flag
callable
such
case
str
strategy
sttrange
'str
strategy
future
new
field
random
flag
example
strategy
subset
tasks
THEN
random
choice
strong
opinion
fix
least
fields
fields
full
stops
documentation
suggestion
docs
param
type
documentation
Airflow
mypy
type
hints
suggestion
convention
super
nit
picky
parameters
suggestion
@
parameterized.expand
[
'GET
]
@
requests_mock.mock
def
test_json_request
method
mock_requests
obj1
=
b
c
[
d
]
def
match_obj1
request
return
request.json
obj1
mock_requests.request
method=method
url='//test:8080/v1/test
additional_matcher=match_obj1
mock.patch
'airflow.hooks.base_hook.BaseHook.get_connection
side_effect=get_airflow_connection
Send
obj1
JSON
mock
HttpHook
method=method
.run
'v1/test
json=obj1
parameterization
suggestion
i
few
things
inline
comments
suggestion
create_build_from_file
=
CloudBuildCreateOperator
task_id=
create_build_from_file
project_id=GCP_PROJECT_ID
body=str
CURRENT_FOLDER.joinpath
'example_cloud_build.yaml
params=
'Airflow
[
END
howto_operator_gcp_create_build_from_yaml_body
description
behaviour
docstring
docstring
bit
misleading
last_modified_time
behaviour
object
last_modified_time
tzinfo
UTC
something
better
objects
last_modified_time
tzinfo
UTC
suggestion
import
subprocess
import
import
pytest
@
pytest.fixture
autouse=True
scope=
session
def
upgrade_helm
Upgrade
Helm
subprocess.check_output
[
helm
repo
add
stable
https
//kubernetes-charts.storage.googleapis.com/
]
subprocess.check_output
[
helm
dep
update
[
]
]
code
module
level
results
bad
end
user
experience
Pytest
command
black
screen
long
time
message
change
tests
fixutres
part
tests
suggestion
OperationalError
ProgrammingError
=
b'\nCREATE
TABLE
test_table\n
\n
id
int
auto_increment
primary
key
\n
params
json\n
query
query
_mysql
releases
GIL
immutable
buffer
isinstance
query
bytearray
query
=
bytes
query
self.waiter
None
self.send_query
query
self.waiter
self.fileno
self.read_query_result
>
_mysql.connection.query
E
_mysql_exceptions.OperationalError
Table
'test_table
exists
/usr/local/lib/python3.7/site-packages/MySQLdb/connections.py:280
OperationalError
API
change
current
Airflow
interface
Airflow
process
reading
class
handler
data
option
airflow.cfg
https
//github.com/apache/airflow/blob/master/airflow/config_templates/default_airflow.cfg
L191-L193
log
API
improvement
scope
PR
comment
API
issues
https
//github.com/apache/airflow/pull/5177
issuecomment-557788417
suggestion
return
SnowflakeHook
instance
rtype
SnowflakeHook
empty
line
inbetween
invalid
docstring
return
SnowflakeHook
places
following
better
WDYT
suggestion
airflow.www.api.experimental
import
endpoints
purposes
module
link
default_auth
app.config
[
]
import
importlib
importlib.reload
endpoints
app.register_blueprint
e.api_experimental
url_prefix='/api/experimental
app.extensions
]
.exempt
endpoints.api_experimental
suggestion
test
binary
secret
other
comment
webserver
plugin
cos
Link
plugin
normal
plugin
mechanism
module
same
python
module
name
same
key
sys.modules
import
class
name
careful
user/API
input
sort
thing
possible
recipie
arbitrary
python
classes
Vulns
suggestion
ignore_file_name
str
>
Generator
[
str
None
None
]
Search
file
path
file
param
base_dir_path
base
path
param
ignore_file_name
file
name
regular
expression
pattern
ctx
manager
python
open
file
file.write
*
*
kwargs
More
question
comment
docstr
correct
[
Task
]
<
<
Task
list
operators
less
https
//github.com/apache/airflow/blob/75bd2f180e4afb591b08ee5d2cdb9b85737258b8/airflow/api_connexion/schemas/enum_schemas.py
drop
java
name
template
structure
language
suggestion
stream
=
glacier_data
[
body
]
file
content
chunks
StreamingBody
https
//botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html
chunk
stream.iter_chunks
chunk_size=1024
temp_file.write
chunk
boto3
docs
https
//boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glacier.html
Glacier.Client.get_job_output
https
//botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html
botocore.response.StreamingBody.iter_chunks
Enter
documentation
peoject
change
log
format
log
FORMATTER
%
s
FORMATTER
https
//github.com/apache/airflow/pull/4804
more
detail
reason
https
//github.com/apache/airflow/pull/4804
issuecomment-468594870
Links
GCP
documentation
fields
useful
suggestion
module
Google
Cloud
Dataflow
sensor
nit
params
order
init
variables
same
suggestion
xcomarg
=
XComArg
any_op
xcomarg
=
any_op.output
pass
key
safe
https
//github.com/apache/airflow/pull/4895
issuecomment-471385356
suggestion
def
to_k8s_client_obj
object
return
kubernetes.client.models.V1EnvVar
super
Could
example
ARN
comment
Makes
easier
parts
suggestion
type
params
dict
..
seealso
https
//thomas-cokelaer.info/tutorials/sphinx/rest_syntax.html
colored-boxes-note-seealso-todo-and-warnings
suggestion
type
params
Dict
Ash
comment
>
method
Serialzied
*
class
suggestion
Sphinx
event
handler
regular
expression
explaining
form
[
inline
comments
https
//docs.python.org/3/library/re.html
re.VERBOSE
Please
docstrings
method
suggestion
connection
Google
Sheets
new
line
new
line
documentation
UserMoveProcess
api
+3
comment
date
future
greeter
chain
Chain
instance
line
class
Chain
Need
lines
copy
trinity/plugins/eth2/beacon/plugin.py
eth2.beacon.operations.attestation_pool
import
AttestationPool
attestation_pool
=
AttestationPool
chain
=
chain_config.beacon_chain_class
db
attestation_pool
chain_config.genesis_config
reason
likely
code
eth-utils
https
//github.com/ethereum/eth-utils/blob/386863e6b7d95ac5acb11f6ba81619dc88ed6eb9/eth_utils/logging.py
L78-L81
stdlib
module
caches
logger
instances
code
logger
instance
logger
class
better
way
something
'trinity
name.startswith
use
get_logger
use
logging.getLogger
Request
justifiable
spec
changes
method
harder
files
worth
suggestion
data
=
ResourceFactory.as_dict
data
]
=
'file
explicit
readable
IMO
negative
zero
ints
following
def
isposint
s
avoid
zero
strings
return
s.isdigit
[
]
==
return
isposint
s
[
]
==
isposint
s
]
s
left
right
docstring
Hmm
sure
best
thing
consistent
option
fallback
type
okay
least
TODO
comment
other
ABCs
least
TODO
item
raw_options
]
comment
entries
list
comment
good
better
[
]
things
unimported
,exprs
example
options
disallow-any
config
file
empty
string
raw_options.split
raw_options
empty
list
empty
element
function
ArgumentError
empty
string
valid
option
comment
code
argparse
whitespace
safer
comment
Add
docstring
discuss
least
things
*
Purpose
class
global
state
build
daemon
shutdown
*
Invariants
subtype
caches
class
semantic
effect
perf
Style
nit
Indents
github
diff
view
Just
extra
clear
indents
py
class
Foo
First
line
Second
line
space
indent
comment
correct
updated
mutable
state
better
error
codes
enabled/disabled
sets
other
comments
additional
context
sure
docstring
implementation
s
type
variable
name
name
possible
multiple
matches
variable
name
unique
docstring
Style
nit
Add
line
consistency
short
docstring
example
name
fixing
Ah
right
placeholder
intelligent
hash
comments
indentation
case
size
change
file
invalid
worth
simple
hash
place
docstring
Add
particular
different
base
class
kind
confusing
anything
class
individual
test
case
least
needs
docstring
Add
comment
something
only
classes
DataSuite
test
cases
DataSuite
class
Style
nit
separate
line
multi-line
docstrings
sense
test
case
doc
argument
type
available
return
type
return
type
sure
property
type
different
return
type
annotation
precedence
comment
place
Bogus
first
file
understanding
few
places
name
fullname
None
type
Btw
name
several
bugs
fullname
None
situation
name
None
actual
problems
analogy
fullname
suggestion
Check
node
current
statement
next
line
need
subsequent
blank
line
modules
process
multiple
SCCs
process_fresh_scc
function
name
misnomer
function
mention
docstring
SCC
Nit
Missing
period
end
docstring
Add
comment
is_upper_bound=True
comment
purpose
Add
mention
multi-assignment
union
type
Final
other
types
such
type
variables
worth
TODO
comment
error
cases
reachable
number
targets
differs
number
elements
top-level
tuple
python
import
*
class
A
def
__enter__
>
Tuple
[
int
int
]
pass
def
__exit__
x
y
z
pass
A
b
A
c
d
type
int
int
int
pass
error
messages
identical
errors
store_declared_types
order
object_rprimitive
confusing
Add
comment
real
type
second
argument
pointer_rprimitive
cleaner
random
idea
new
primitive
type
*
*
object_pointer_rprimitive
long
module
names
names
3-5
letters
readable
long
lines
\
comment
order
things
line
IIUC
line
numbers
error
messages
consistent
Add
purpose
function
Add
ctx
contains
information
dependencies
pre-condition
feels
phrasing
more
similar
docstring
conditional_type_map
Add
comment
kind
unexpected
future
TestCase
test
files
inherit
Suite
alias
other
helper
classes
ambiguity
cast
Could
type
comment
first
assignment
mypy/checkexpr.py:4131
error
isinstance
unexpanded
types
clean
way
type
ignore
okay
other
suggestions
documentation
caller_has_lock
business
useful
Python
users
understanding
documentation
useful
C
user
access
things
RAII
context
managers
checkErr
macros
fun
gotos
vote
def
lock_session
context
manager
caller_has_lock
def
unlock_session
parameters
thing
functions
duck-typing
reasons
naming
rlock
little
bit
new
line
part
comment
functions
suggestion
A
lazy
link
Span
URL
None
optional
type
annotations
bad
args
practice
part
documentation
None
values
Tried
opentelemetry.ext.flask.tests
importable
path
function
private
noise
generated
documentation
suggestion
order
balance
observability
expenses
traces
process
decision
span
Style
nit
readability
docstrings
short
first
line
longer
text
line
https
//github.com/open-telemetry/opentelemetry-python/pull/61
pullrequestreview-266303416
A
short
single-line
description
function
A
longer
description
class
.SphinxStuff
Args
arg
Short
description
need
type
Returns
thing
Yields
context
managers.
suggestion
Implementation
class
.Exporter
stores
memory
suggestion
status
Span
dict
type
comment
missing
docstrings
intentional
minor
other
files
blank
line
copyright
comment
great
consistent
users
consistent
way
django
apps
user
Instrumenter
path
middleware
settings.py
application
importance
instrumenter
DJANGO_INSTRUMENT
text
examples
configuration
section
README
docstrings
file
Well
attributes
dbapi
library
more
popular
libraries
likely
people
mistakes
more
documentation
good
more
details
suggestion
Implementation
MetricsExporter
stores
metrics
memory
comment
record
implementation
great
confusion
try
meter
provider
assertion
meter_provider.start_pipeline
try
meter_provider.shutdown
enumerate
suggestion
Aggregator
ValueRecorder
metrics
histogram
values
suggestion
Implementation
MetricsExporter
prints
metric
handles
@
Oberon00
mypy
actual
return
type
parameter/function
Union
[
comment
]
https
//github.com/open-telemetry/opentelemetry-python/pull/160
discussion_r328792447
Union
Just
comment
worthy
test_X
method
method
tests
results
add_link
SpanContext
later
suggestion
trace.get_tracer
global
tracer
source
block
specific
expectation
format
batch_map
general
error-prone
value
right
pair
tuples
key
value
refactoring
direct
manipulation
batch_map
helper
methods
way
clear
documentation
structure
key-value
pairs
key-value
pairs
example
code
comments
nice
better
names
registered
observers
test
same
observer
times
Add
comment
iterators
good
TODO
thoughts
first
question
bwa
mem
RG
headers
custom
function
deplete_bwa_bam
output
point
BWA
other
depletion
methods
inBam-
>
outBam
Picard
FilterSamReads
important
sure
BWA
mem
headers
actual
argument
JVMmemory
nice
Java-free
command
same
name
change
comment
klasses/api_test.py
function
side
effects
order
complete_successful_order
something
better
name
case
code
view
API
method
various
responsibilities
usefulness
high
level
view
API
views.py
def
post
request
*
args
*
*
kwargs
order
=
get_the_order
request
receipt
stuff
errors
order
decision
=
CYBERSOURCE_DECISION_ACCEPT
handle_rejected_order
order
complete_successful_order
order
order
sync_hubspot_deal_from_order
order
return
Response
api.py
def
complete_successful_order
order
status
flag
API
order
status
function
xpro
benefit
function
way
management
commands
own
scripts
successful
order
completion
bootcamp_name
Bootcamp
body
bootcamp_name
fine
today
correct
NOW
effective
sure
exceptions
raise_for_status=False
example
mailgun
due
network
outage
try
block
set
raise_for_status=True
class
decorator
argument
func
cls
decorator
decorator
lib_decorator
decorator
higher
precedence
separate
comment
implementation
arguments
decorator
@
library
version=
@
library
keyword
Tests
library
'_get_var_data
complex
Same
naming
Sorry
other
GitLab
modules
auth_basic
docs
fragment
server_url
module
docs
fragment
extends_documentation_fragment
community.general.auth_basic
ansible_collections.community.general.plugins.module_utils.gitlab
import
gitlabAuthentication
GitLab
suggestion
DOCUMENTATION
=
r
suggestion
Launch
Nomad
job
seealso
https
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
documentation-block
e.g
seealso
name
APIC
Management
Information
Model
reference
description
Complete
reference
APIC
object
model
link
https
//developer.cisco.com/docs/apic-mim-ref/
Nomad
upper-case
short_description
rest
documentation
nomad
correct
form
suggestion
description
Complete
documentation
Nomad
API
jobs
FWIW
migrate.py
version_added
DOCUMENTATION
migration
suggestion
true
true
/
false
/
YAML
documentation
suggestion
description
Toggle
C
true
plugin
host
facts
server
C
values
https
//docs.ansible.com/ansible/devel/dev_guide/developing_modules_documenting.html
linking-within-module-documentation
absent
not_installed
string
enum
comment
suggestion
results=ret
documentation
results
stack_facts
_facts
info
modules
suggestion
DOCUMENTATION
=
r
line
lines
module
code
Please
https
//github.com/ansible-collections/overview/issues/45
issuecomment-627922948
suggestion
EXAMPLES
=
r
suggestion
default
https
//docs.ansible.com/ansible/latest/dev_guide/developing_modules_documenting.html
examples-block
examples
boolean
options
yes/no
values
documentation
boolean
values
yes/no
examples
values
module
documentation
consistent.
suggestion
instance_id
'50968a80-2909-4e5c-b1af-a2e19860dddb'
name
backup
suggestion
EXAMPLES
=
r
suggestion
RETURN
=
r
suggestion
See
GitLab
documentation
acceptable
values
masked
variable
U
https
//docs.gitlab.com/ce/ci/variables/
masked-variables
suggestion
DOCUMENTATION
=
r
suggestion
type
dict
note
Supports
check_mode
suggestion
value
=
data
[
item
]
isinstance
value
discord.Object
expensive
cases
item
value.id
setattr
item
value
comment
correct
catch
catch
discord.HTTPException
suggestion
TODO
Add
documentation
input/output/exceptions
status
status
activities
purple
circle
suggestion
a.type
user.activities
statusemoji
\N
LARGE
PURPLE
CIRCLE
elif
user.status.name
==
online
\N
LARGE
GREEN
CIRCLE
elif
user.status.name
==
offline
\N
MEDIUM
WHITE
CIRCLE
elif
user.status.name
==
dnd
\N
LARGE
RED
CIRCLE
elif
user.status.name
==
idle
\N
LARGE
ORANGE
CIRCLE
//
comment
🤔
All
comments
apply
command
change
Red
empty
name
suggestion
name
name
Hyphen
instance
names
issues
sure
instance
name
name
print
new
line
aesthetics
method
comment
welcome
method
comment
function
welcome
rename
_
parameter
interfers
translation
function
Odoo
args
more
pythonic
nit
Can
line
lengths
chars
few
places
black.py
todo
i
someone
PR
utility
function
easier
utils
>
auth.py
Same
above
comment
execution
options
test
comments
portion
variable
artifacts
ok
bash
clear
BTW
bash
https
//stackoverflow.com/questions/2792650/python3-error-import-error-no-module-name-urllib2
python
try
Python
urllib.request
import
Request
urlopen
urllib.error
import
URLError
ImportError
Python
urllib2
import
Request
URLError
urlopen
correct
compatibility
Python
Python
alternative
third
party
dependency
such
[
requests
http
//docs.python-requests.org
]
https
//pythonhosted.org/six
Please
comment
non-CAI
resource
types
fake
CAI
resource
type
worth
FAKE_CAI_RESOURCE_TYPE_MAPPING
comment
comment/code
single
test
temporary
workaround
same
hack
other
tests
better
vein
above
comment
worth
constant
bool
goal
state
update
Remove
empty
quotes
comment
>
Reports
signal
/health
[
]
length
=
comment
documentation
is_healthy
PID
/var/run/dhclient.pid
customized
Same
comment
OSError
IOError
let
comment
good
test
current
changes
comment
sure
test
failures
agent
example
PUT
call
fails
ProtocolError
intention
test
name
test
comments
messages
asserts
code
impression
basic
test
get_ext_conf
data
function
matches
intention
test
simple
docstring
reader
test
with_uri
part
test
name
comment
codes
e.g
CRP
signature
constructor
changes
new
limit
earlier
comment
CGroups
constructor
design
constructor
right
Suggestion
__init__
cgroup_name
thresholds=none
self.cpu_limit
=
thresholds
cpu
]
thresholds
cpu
thresholds
self.get_default_cpu_limits
cgroup_name
self.memory_limit
=
thresholds
memory
]
thresholds
memory
thresholds
self.get_default_memory_limits
cgroup_name
comment
Same
thing
Same
docstring
possible
return
values
Same
comment
above
Comment
applies
triple
quotes
indentation
string
indentation
source
code
message
indentation
string
shellutil.CommandError
cmd_err
msg
[
]
[
stderr
]
.format
p7m_file
stdout
stderr
logger.error
msg
try
/
comment
code
current
implementation
dict
_errors
case
failure
try/except
logic
get_storage_classes
try/except
function
def
list_volumes
api_client
minion_id
try
storage_classes
get_storage_classes
api_client
APIException
HTTPError
exc
return
[
]
current
body
object
whole
method
simpler
syntax
cluster-version
annotation
specific
kube-system
namespace
real
value
namespace
object
def
get_cluster_version
namespace
=
coreV1.read_namespace
name=
kube-system
annotation_key
=
'metalk8s.scality.com/cluster-version'
annotation_key
namespace.metadata.annotations
pillar
_errors
namespace.metadata.annotations
[
annotation_key
]
big
comment
docstring
method
thread
suggestion
Name
FASTQ
file
usalt
conventions
sample_flowcell_lane_read.fastq.gz
suggestion
Test
file
suggestion
Test
file
exists
empty
suggestion
vogue
load
flowcells
Great
work
thoughts
Thank
comments
method
vcf
dict
docstring
hard
soft
couplings
different
applications
@
adriesse
spirit
new
functions
documentation
additional
assumptions
model
development
e.g
hourly
data
zenith
restrictions
times
fashion
backward
compatible
warning
message
new
behavior
More
comment
docstring
backward
compatibility
times
times
conflicts
weather.index
Same
comment
prepare_inputs
index
weather
DataFrame
times
Same
comment
prepare_inputs
correct
easier
way
angle
refraction
thetar_deg
=
tools.asind
aoi
/
n
reflectance
transmittance
normal
incidence
light
rho_zero
=
/
tau_zero
=
np.exp
-K
*
L
reflectance
parallel
perpendicular
light
rho_para
=
tools.tand
thetar_deg
aoi
/
tools.tand
thetar_deg
+
aoi
rho_perp
=
tools.sind
thetar_deg
aoi
/
tools.sind
thetar_deg
+
aoi
transmittance
non-normal
light
tau
=
np.exp
-K
*
L
/
tools.cosd
thetar_deg
iam
non-normal
normal
incidence
light
reflected
portion
iam
=
+
rho_perp
/
rho_zero
tau
/
tau_zero
angles
produce
nan
iam
small_angle
1e-06
iam
=
np.abs
aoi
<
small_angle
iam
angles
degrees
tiny
negative
values
result
calculation
precision
physical
model
iam
=
iam
<
iam
light
plane
none
module
iam
=
aoi
>
iam
negative
angles
logical
iam
=
aoi
<
iam
Thanks
detailed
explanation
refer
Docstring
access
@
mikofski
line
issue
example
noqa
E501
stickler
case
better
plus
sign
end
line
separate
paragraph
blank
line
potential
paragraph
fine
line
api.rst
file
documentation
readthedocs
link
CI
box
bottom
PR
reference
conditions
]
Same
comment
lines
Remove
parameters
docstring
renders
readthedocs
sign
pvlib-python
project
list
versions
branch
version
branch
readthedocs
PR
outer
parentheses
inner
parentheses
comma
python
]
]
]
Out
[
]
]
]
outer
little
bit
clarity
ok
Key
optimize_result
rest
parameters
comment
dni
get_dni
calculate_dni
better
opinion
parameters
part
API
documentation
name
Leftover
auto
code
IDE
module-level
docstring
good
idea
M
documentation
success
results
dictionary
entries
KeyError
assignment
result
[
'cmod_success
]
Assign
everything
Assign
nan
fit_sde_sandia
behavior
v_mp
i_mp
v_oc
i_sc
alpha_sc
*
i_sc
beta_voc
*
v_oc
gamma_pmp
cells_in_series
temp_ref
celltype
[
'monoSi
'multiSi
'polySi
'cis
'cigs
'cdte
'amorphous
]
ivtools.fit_cec_sam
celltype
v_mp
i_mp
v_oc
i_sc
alpha_sc
beta_voc
gamma_pmp
cells_in_series
temp_ref
Improved
Coefficient
Calculator
CEC
Parameter
Photovoltaic
Module
Model
SAM
SDK
documentation
NIT
fan
docstring
style
inconsistent
pvlib
[
pep8
]
https
//pep8.org/
documentation-strings
other
packages
pandas
scipy
mpl
dedent
undent
outdent
same
indentation
Test
get_psm3
multiple
error
scenarios
*
Bad
api
key
>
HTTP
forbidden
api_key
Bad
>
Coordinates
NSRDB
*
Bad
name
>
names
available
options
Bad
interval
single
year
>
intervals
minutes
better
Test
get_psm3
multiple
error
scenarios
*
Bad
api
key
>
HTTP
forbidden
api_key
Bad
>
Coordinates
NSRDB
*
Bad
name
>
names
available
options
Bad
interval
single
year
>
intervals
minutes
thanks
comments
loop
assert
statements
way
Please
something
descriptive
such
azi
azimuth
helpful
%
s
context
presentation
example
>
%
s
context
presentation
>
example
full
message
Braille
focus
context
presentation
Fill
display
context
changes
length
example
colon
brevity
linguistic
correctness
important
kinds
things
prefix
setting
name
setting
names
long/unique
context
clear
Double
space
comment
suggestion
try
field
=
controlStack.pop
IndexError
root
descendant
object
range
case
_iterRecursiveText
end
object
None
range
invalid
nothing
log.debugWarning
root
dead
[
copyright
https
//github.com/nvaccess/nvda/wiki/Copyright-headers
scripts
useful
comment
comment
specific
option
same
term
Marked
highlight
concern
people
intention
Marked
text
explanation
user
guide
purpose
feature
way
clarity
suggestion
elif
addon.isPendingEnable
install
addon.isPendingInstall
addons
restart
globalVars.appArgs.disableAddons
Comma
police
docstring
suggestion
Copyright
C
2006-2019
NV
Access
Limited
Aleksey
Sadovoy
Peter
Vágner
Joseph
Lee
Bill
Dengler
file
new
line
coding
UTF-8
bit
ambiguous
types
built-in
python
module
built-in
one
suggestion
import
types
Python
core
module
big
deal
line
many
commas
@
jcsteh
https
//github.com/nvaccess/nvda/pull/7599
issuecomment-389812530
async
True
Similar
suggestion
_pendingEventCountsByNameAndObjId=
Thanks
extra
tests
moment
hard
'actual
lot
lines
Could
following
way
suggestion
=
self._replace
string=
pattern=r
P
<
foo
>
\d
name
group
'foo
single
digit
name=
foo
replacement=
most
paths
hard
glance
good
happy
path
test
smaller
examples
paths
least
paths
_replaceGroups
function
many
more
combinations
due
internal
loop
Please
independent
test
path
tests
documentation
expectations
function
unfamiliar
developer
different
things
function
error
case
appropriate
doc
string
method
suggestion
Override
L
textInfos.TextInfo.setEndPoint
UIA
bug
Windows
end
endpoint
collapsed
empty
text
range
comparisons.
line
doc
string
comment
@
Jcsteh
code
way
intermediate
variable
driver
drivers
dictionary
value
DefaultDict
latter
something
regular
dict
Note
_getDriver
USB
Bluetooth
info
driver
specific
dictionary
recursive
extra
complexity
function
several
things
skipped
indexes
part
_pushNextSpeech
initial
feeling
efficient
bulk
necessary
shame
sequence
indexes
_removeCompletedFomQueue
way
recursive
approach
same
_handleIndex
index
synth
such
OneCore
indexes
index
text
content
indexes
handleIndexes
[
]
oldIndex
need
copy
<
index
log.debugWarning
Handling
index
%
s
%
oldIndex
handleIndexes.append
oldIndex
handleIndexes.append
index
concise
approach
handleIndexes
self._indexesSpeaking.sort
Note
order
indexes
use
s
=
indexOfIndex
=
self._indexesSpeaking.index
index
=
[
indexOfIndex
]
valid
endOfUtterance
=
False
False
i
handleIndexes
try
self._indexesSpeaking.remove
i
ValueError
log.error
Unknown
index
%
s
%
i
break
rest
unexpected
path
i
=
index
log.debugWarning
Handling
index
%
s
%
i
following
index
any/all
end
utterance
trigger
_pushNextSpeech
_valid
_endOfUtterance
=
self._removeCompletedFromQueue
i
valid
=
valid
_valid
endOfUtterance
=
endOfUtterance
_endOfUtterance
_valid
callbackCommand
=
index
None
callbackCommand
try
callbackCommand.run
log.exception
Error
speech
callback
endOfUtterance
many
indexes
next
speech
self._pushNextSpeech
False
comment
better
name
Office2010VersionMajor
major
part
required
feature
intent
clearer
version
comparison
translators
comments
while
interesting
int
value
list
reference
C
concept
boxing
value
types
similar
concept
python
Re
previous
comment
problematic
native
UIA
windows
Might
good
inner
function
rid
inner
function
fact
_processSpeechSequence
needs
update
year
docstring
output
input
text
dialog
full
width
screen
something
lines
max
length
sText
=
sHelper.addItem
wx.StaticText
label=message
wx.Window
handle
import
windowUtils
=
windowUtils.getWindowScalingFactor
self.GetHandle
sText.Wrap
self.scaleFactor
visual
user
acceptable
machine
string
suggestion
self._deviceID
=
arg.rstrip
b
.decode
latin-1
Assumption
same
bool
int
data
False
data
b
byte2bool
ordinal
byte
boolean
value
comment
eurobraille
protocol
real
numbers
boolean
values
updated
copyright
header
Copyright
C
2006-2018
NV
Access
Limited
yourname
Please
docstring
following
Provides
character
support
keyboard
handler
events
console
output
changes
adjacent
cursor
Explain
keyboard
handler
toUnicodeEx
flag
keyboard
state
above
NVDA
char
events
NVDA
char
events
typed
passwords
better
reporting
tab
press
See
comment
_calculateNewText
Clarify
comment
How
impact
behavior
example
objects
App
module
None
following
suggestion
check
window
class
name
checks
isOfficeApp
isBefore2016Version
windowClass
NetUIHWND
appModule
NetUIHWND
various
controls
MS
Office
IAccessible
NetUIHWND
versions
older
Fixes
lack
focus
reporting
Fixes
strange
reporting
context
menu
items
fixes
able
ribbon
sections
edit
field
Office
newer
IAccessible
NetUIHWND
focus
changes
ribbon
shows
controls
proper
events
NVDA
isOfficeApp
=
appModule.productName.startswith
Microsoft
Office
Microsoft
Outlook
isBefore2016Version
int
appModule.productVersion.split
]
isOfficeApp
isBefore2016Version
parentHwnd
=
winUser.getAncestor
hwnd
winUser.GA_PARENT
parentHwnd
winUser.getClassName
parentHwnd
Net
UI
Tool
Window
MsoCommandBar
return
False
parentHwnd
=
winUser.getAncestor
parentHwnd
winUser.GA_PARENT
copyright
statement
Copyright
C
2014-2017
NV
access
Limited
Dinesh
Kaushal
Updated
comment
sound
error
sounds
release
sure
indentation
consistent
rest
repo
docstring
style
few
updates
more
bits
information
nice
_x_count
restrictive
description
_x_count
disallowed
validate
function
different
regular
FoldedContextField
separate
class
Bonus
points
name
above
difference
readers
code
docstring
distinction
–
confusion
regular
FoldedContextField
objects
new
objects
reason
codes
blocks
functions
container
info
locations
inputs
outputs
tags
query
docstring
exact
same
documentation
places
better
docstrings
descriptions
query_metadata_table
compiler
i.e
QueryMetadataTable
object
information
query
none
>
None
target
docstring
function
name
Can
block
filters
fold
scopes
bit
documentation
check
get_fields_eligible_for_pagination
function
complicated
docstring
parts
macro
edge
best
schema
queries
schema
docstring
block
Nice
lot
bonus
points
numbered
list
bullet
points
comments
code
numbered
list
hard-core
approach
inspiration
_compile_vertex_ast
function
compiler_frontend.py
unfortunate
code
>
Traverse
errors
docstrings
type
sense
value
error
consistent
.parse_value
functions
GraphQLScalarType
objects
ValueError
input
invalid
type
value
mention
ValueError
docstring
following
ValueError
value
appropriate
type
ValueError
base
case
exceptions
GraphQL
parsers
same
comment
Bojan
indentation
AssertionError
error
due
value
GraphQLScalarType
GraphQLScalarTypes
docstring
indicative
compiler/server
side
bug
user
error
nit
indentation
Sorry
indentation
issue
code
comment
Github
code
formatting
kind
weird
Same
comments
above
custom
message
Did
TODO
case
code
sure
docstring
documentation
check
case
docstring
bit
general
vertex_edge_counts
uniformity
assumption
nit
inbound
reverse
docstring
functions
docstrings
purpose
code
difficult
@
bojanserafimov
@
idea
pydocstyle
fact
docstrings
pylint
wrong
introspection_types
subscriptable
type
FrozenDict
subtype
Dict
suggestion
pylint
disable=unsubscriptable-object
__Schema
=
cast
GraphQLObjectType
[
__Schema
]
=
cast
GraphQLObjectType
[
__Directive
]
__DirectiveLocation
cast
GraphQLEnumType
[
__DirectiveLocation
]
__Type
=
cast
GraphQLObjectType
[
__Type
]
=
cast
GraphQLObjectType
[
__Field
]
=
cast
GraphQLObjectType
[
__InputValue
]
=
cast
GraphQLObjectType
[
__EnumValue
]
=
cast
GraphQLEnumType
[
__TypeKind
]
pylint
enable=unsubscriptable-object
free
issue
https
//github.com/PyCQA/pylint
good
reproducible
example
bug
suggestion
More
details
hints
suggestions
use
methods'
docstrings
available
suggestion
Check
unsupported
renaming
suppression
operations
type
hints
int
None
docstrings
copy-pasted
other
file
mentioning
parameterized.expand
comment
docstring
docstring
function
nit
blank
comment
line
properly-indented
comments
comment
necessary
custom
nothing
parse
ints
ints
floats
floats
something
non-obvious
worth
newline
sections
sections
python
Headline
line
[
Optional
additional
text
many
lines
same
indentation
triple-quotes
]
Args
foo
explanation
bar
explanation
Returns
[
function
returns
something
]
return
value
description
name
return
values
[
function
something
non-obvious
]
description
errors
newlines
Args
Returns
reason
functions
underscore
private
add
docstrings
compliant
docstring
https
//github.com/kensho-technologies/graphql-compiler/pull/499/files
headline
line
rule
more
line
function
obvious
one-line
summary
+
description
underneath
+
Returns
sections
sure
dialects
other
mssql
assertion
mssql
dialect
docstring
function
nit
sure
user
resulting
query
part
IR
something
query
path
columns
query
IR.
nit
BIT
type
such
right
comment
Additional
validation
example
column
types
comparable
unique
index
columns
TODO
validation
everything
suggestion
linear
sequence
operations
execution
query
transformation
sequence
operations
actual
execution
order
single
thread
execution
actuation
iterables
adapter
function
yields
operation
types
prior
class
docstring
type
annotations
clear
additional
information
suggestion
A
complete
immutable
recording
execution
query
InterpreterAdapter
nit
i
entity
enumerate
..
few
paragraphs
documentation
page
https
//github.com/lyft/flytesnacks/blob/cookbook/cookbook/workflows/recipe_5/index.rst
Feel
free
branch
commit
own
PR
street
nit
same
comment
caller
making
dict
statement
lv
None
lv
comment
someone
latter
future
wrong
dsl
_exists_
found_account
ok
get_chart
function
simple
lookup
dict
return
charts
chart_name
]
type
..
meaning
chart_name
KeyError
....
try
chart_class
=
chart_manager
.....
KeyError
something
chart_name
....
something
comment
name
similar
comments
other
manager
comment
value
Remove
line
newline
Allocates
neater
docstring
Entry
point
analyzer
event
Returns
code-block
kind
docstrings
tests
result
shots
variance
fact
variance
provided
shots
value
test
ok
test
docstring/comments
suggestion
samples
sample
function
suggestion
wires
set
operators
suggestion
A
qubit
device
CV
operations
suggestion
A
qubit
device
CV
observables
suggestion
Test
UCCSD
exception
parameters
part
docstring
needs
Other
requirement
supported
simulators
other
points
docstring
changes
code
PR
suggestion
Loads
Program
objects
converter
suggestion
QNodeCollection
QNodes
QNode
keep
sneaking
first
line
docstring
good
short
concise
possible
eigenvalues
tensor
product
observable
implementation
details
i.e.
pre-stored
eigenvalues
middle
docstring
ambiguity
None
set
[
]
docstring
None
argument
indices
trainable
suggestion
Check
gradient
QNode
result
gradient
correct
wire
permutations
updates
test
clearer
*
circuit
wire
permutations
non-zero
expectation
values
statement
results
decorator
=
b
=
test_data
=
[
[
]
np.cos
*
np.cos
b
[
-2
*
np.cos
b
*
np.sin
-np.cos
*
np.sin
b
]
[
]
-np.cos
b
*
np.sin
b
-np.cos
b
+
np.sin
b
]
]
@
pytest.mark.parametrize
w
expected_res
expected_grad
test_data
def
test_non_diff_wires_argument
w
expected_res
expected_grad
tol
Test
wires
non-differentiable
positional
argument
results
expected
QNode
result
gradient
dev
=
qml.device
default.qubit
wires=2
@
qml.qnode
dev
interface=
tf
def
circuit
wires
params
qml.Hadamard
]
qml.CNOT
wires=
[
wires
]
[
]
]
qml.RX
params
]
[
]
qml.RY
params
]
[
]
qml.CNOT
wires=
[
wires
]
[
]
]
qml.RX
params
]
[
]
qml.RY
params
]
[
]
return
qml.expval
qml.PauliZ
tf.Variable
[
]
tf.GradientTape
tape
res
circuit
w
params
circuit.get_trainable_args
assert
np.allclose
res
expected_res
atol=tol
rtol=0
grad
=
tape.gradient
res
params
circuit.get_trainable_args
assert
np.allclose
grad
expected_grad
atol=tol
rtol=0
comments
same
comment
respect
quotes
nicer
italics
len
wires
string
confusing
error
message
qml.RX
wires=
qubit0
wires
suggestion
.format
self.name
self._wires
suggestion
Check
error
return
types
observables
analytic
expression
_or_
commands/comments
result
suggestion
Test
basis
state
preparation
decomposition
suggestion
PennyLane-Qiskit
dependency
lack
better
place
Curious
following
submodules
benchmark/revisions/default_qubit_performance
benchmark/revisions/v0.8.0
Same
comment
suggestion
check
device.supports_operation
proper
errors
Note
Sphinx
summary
first
line
first
period
everything
first
sentence
summary
table
best
sentence
best
new
line
period
Oops
test
stronger
docstring
😆
suggestion
step
cost
steps
suggestion
Test
_inv_dict
exception
value
unhashable
dictionary
refactor
suggestion
r
pennylane.ops.MeanPhoton
wires
docstring
refactor
Let
TODO
comment
suggestion
Test
expval
interface
works
suggestion
TODO
qml.expval.Observable
test
suggestion
expval
function
general
suggestion
module
classes
functions
quantum
neural
networks
QNodes
suggestion
<
https
//www.tensorflow.org/api_docs/python/tf/keras/layers/Layer
add_weight
>
suggestion
module
classes
functions
QNodes
Keras
layer
API
comment
suggestion
Test
values
tensor
product
observables
suggestion
tensordot
axes
wires
first
positions
suggestion
TODO
use
multi-index
vectors/matrices
states/gates
aware
fix
master
suggestion
Simulator
default.qubit
template
test_integration
tests
Instructions
docstring
test
file
comment
multiple
tests
test
function
make
test
functions
_class_
contents
class
test
methods
e.g.
python
class
TestGradientUnivar
gradients
univariate
unidimensional
functions
qml.grad
def
test_sin
tol
gradient
sin
function
x_vals
np.linspace
-10
g
=
qml.grad
auto_grad
=
[
g
x
x
x_vals
correct_grad
=
np.cos
x_vals
np.allclose
auto_grad
correct_grad
atol=tol
rtol=0
bit
suggestion
quantum
circuit
graph
operations
observables
circuit
graph
index
variables
suggestion
Test
creation
hash
CircuitGraph
incorrect
todo
list
minimal
example
function
similar
GBS
guys
Strawberry
Fields
NumPy
documentation
suggestion
*
*
Example
*
*
>
>
>
qc
=
qiskit.QuantumCircuit
>
>
>
qc.rz
]
>
>
qc.cx
>
>
>
my_circuit
=
qml.load
qc
name='qiskit
>
>
>
>
>
@
qml.qnode
dev
>
>
def
circuit
x
>
>
>
qml.RX
wires=1
my_circuit
wires=
>
>
return
qml.expval
qml.PauliZ
important
docs
function
own
page
enough
context
function
..
note
docstring
pennylane.ai/plugins.html
page
user
available
plugins
documentation
more
details
conversions
Best
way
sense
user
documentation
suggestion
Load
external
quantum
assembly
quantum
circuits
frameworks
PennyLane
templates
suggestion
r
OpenFermion
class
~.QubitOperator
operator
Pennylane
VQE
observable
returning
type
Hamiltonian
Pennylane
sense
doc
pennylane.Hamiltonian
general
observables
Hamiltonians
Thanks
@
zeyueN
docstring
resursive
approach
one
described
https
//stackoverflow.com/questions/38738835/generating-gray-codes
larger
systems
machine
qubits
Simple
script
nice
import
time
def
so_gray_code
n
def
gray_code_recurse
g
n
g
n
=0
return
i
range
k-1
-1
-1
char=
[
i
g.append
char
i
range
k-1
-1
-1
g
[
i
=
[
i
gray_code_recurse
g
n-1
g=
[
]
gray_code_recurse
g
n-1
return
g
def
gray_code
rank
Gray
code
rank
Args
rank
int
rank
Gray
code
i.e
number
bits
return
b
.format
i
i
rank
i
range
<
<
rank
]
def
func
n
start
=
time.time
=
gray_code
n
print
time.time
-start
b
=
so_gray_code
n
print
time.time
-start
machine
ran
seconds
so_gray_code
seconds
difference
seconds
negligable
N
equal
docstring
statement
line
checks
suggestion
marginal
analytic
probability
computational
basis
state
docstrings
bit
explanation
example
OK
🙂
>
>
>
possible
times
code-block
multiline
statement
statement
function
declaration
>
>
>
case
doctest
numpy
docstring
style
guide
https
//numpydoc.readthedocs.io/en/latest/format.html
docstring-standard
idea
minimal
example
docstring
additional
examples/further
usage
UsageDetails
examples
_too_
hidden
avoids
user
details
first
load
suggestion
r
Rotoselect
gradient-free
optimizer
good
example
users
docs
page
context
example
minimal
template
decorator
better
first
line
something
purpose
technical
description
following
first
line
quantum
template
PennyLane
Vaguer
PL
stack
less
technical
users
suggestion
Test
decorator
template
Nice
example
Quick
comment
*
@
mariaschuld
Wires
class
Observables
above
example
[
X0
Y1
X2
Y3
]
etc
Wires
class
re-introduced
above
bug
output
Hamiltonian
class
sure
hard
able
last
lines
new
standard
docstrings
examples
Args
Returns
https
//pennylane.readthedocs.io/en/latest/development/guide/documentation.html
functions-and-methods
suggestion
r
many-body
observable
expectation
value
PennyLane
Fixed
God
docstring
styles
-1
unit
test
multi-line
single-line
docstring
discussion
Docstrings
runtime
discoverability
actual
downside
testcase
methods
testrunners
display
failed
tests
past
idea
current
testrunners
bug
descriptive
method
names
comments
Done
comment
InternalServerError
subclasses
content
predicate
exception
transient
API
error
following
server
errors
transient
HTTP
INTERNAL
HTTP
RESOURCE_EXHAUSTED
sure
[
equivalent
]
]
UNKNOWN
DATA_LOSS
]
https
docstring
unit
test
argument
applies
one-line
docstring
summaries
multiple
lines
pity
phenomenon
docstring
meaning
behavior
dict.get
docstring
nose
output
test
runner
footgun
@
jonparrott
comment
response.iter_content
stream.writelines
tradition
Args
class
docstring
__init__
None
__init__
class
Indent
[
Django
middleware
documentation
]
https
//docs.djangoproject.com/en/1.11/topics/http/middleware/
methods
===============================================
FAILURES
===============================================
___________________________
TestUnicode.test_fetch_object_and_check_content
____________________________
=
<
tests.system.TestUnicode
testMethod=test_fetch_object_and_check_content
>
def
test_fetch_object_and_check_content
client
storage.Client
bucket
=
client.bucket
'storage-library-test-bucket
Note
files
public
Normalization
form
C
single
character
e-acute
URL
Cafe
%
CC
%
Normalization
Form
D
ASCII
e
U+0301
character
URL
Caf
%
C3
%
A9
test_data
=
u'Caf\u00e9
b'Normalization
Form
C
u'Cafe\u0301
b'Normalization
Form
D
blob_name
file_contents
test_data.items
blob
=
bucket.blob
blob_name
self.assertEqual
blob.name
blob_name
self.assertEqual
file_contents
tests/system.py:265
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
_
/.nox/c749df86/local/lib/python2.7/site-packages/google/cloud/storage/blob.py:405
self.download_to_file
string_buffer
client=client
/.nox/c749df86/local/lib/python2.7/site-packages/google/cloud/storage/blob.py:351
download_to_file
self.reload
/.nox/c749df86/local/lib/python2.7/site-packages/google/cloud/storage/_helpers.py:98
reload
method='GET
path=self.path
query_params=query_params
..
/.nox/c749df86/local/lib/python2.7/site-packages/google/cloud/storage/blob.py:171
path
return
self.path_helper
self.bucket.path
self.name
/.nox/c749df86/local/lib/python2.7/site-packages/google/cloud/storage/blob.py:146
path_helper
return
bucket_path
+
'/o/
+
quote
blob_name
safe=
safe
=
def
quote
s
safe='/
quote
def
>
%
part
URL
e.g
path
info
query
etc.
different
set
reserved
characters
RFC
Uniform
Resource
Identifiers
URI
Generic
Syntax
reserved
characters
/
|
@
=
+
|
characters
component
URL
default
quote
function
path
section
URL
'/
character
typical
usage
quote
function
path
slash
characters
reserved
characters.
fastpath
s
None
raise
TypeError
object
s
cachekey
=
safe
always_safe
try
quoter
safe
_safe_quoters
cachekey
]
KeyError
safe_map
=
_safe_map.copy
safe_map.update
[
c
c
c
safe
]
quoter
=
safe_map.__getitem__
safe
=
always_safe
+
safe
_safe_quoters
cachekey
]
=
quoter
safe
safe
return
>
return
.join
map
quoter
s
KeyError
u'\u0301'
/usr/lib/python2.7/urllib.py:1288
KeyError
seconds
bad
lack
clarity
indicative
something
Suggest
time
Batch
constructor
mock_time.return_value
batch
=
self._make_one
topic
client=client
max_interval=5
batch
stuff
Move
time
batch
old
mock_time.return_value
batch
batch_ctx
reason
Batch.__enter__
returns
self
PEP257
grumble
grumble
Suggestion
python
nested
key
key
separator
e.g
key
first
instance
subkey
>
>
>
_resolve_subkeys
a.b.c
b.c
>
>
_resolve_subkeys
'd|e|f
separator='|
e|f
subkey
data
None
>
>
>
_resolve_subkeys
'foo
None
google-style
docstrings
necessary
previous
comment
observation
Just
reason
old-style
docstrings
I.e
Args
start_time
class
start
time
span
type
param
style
reason
different
issue
clean
everything
single
consistent
style
day
Create
AppProfile
space
read-only
constructor
metadata
key
query
parameters
name
whole
thing
most
circumstances
metadata
key
metadata
key
documentation
parameter
Documentation
note
more
key
least
query
parameters
E.g
tags
alt=json
output
format
reasonable
security
implications
reminds
default
exists
AppVeyor
chemelnucfin
Can
new
APIs
'timeout
make
constants
private
public
please
Same
comment
plz
please
A
short
comment
docstrings
public
methods
[
commit
]
https
//github.com/modin-project/modin/commit/0a3bea4a719470690abd7673f9e81a34a64a4de8
order
inconsistencies
pandas
explanation/description
[
]
https
//github.com/modin-project/modin/pull/2196
issue-496793251
]
https
//github.com/modin-project/modin/commit/0a3bea4a719470690abd7673f9e81a34a64a4de8
diff-506c226c0b2753ce3bbf33ea6c4de22796376d982b483a4d9bbbb3e3e6561a9dR15
instance
Added
comments
clear
Request
docstring
docstrings
new
classes
check
comment
case
[
]
comment
check
necessary
way
suggestion
isinstance
objs
]
.axes
[
axis
]
pandas.MultiIndex
same
comment
dimensions
previous
styler
easier
pylint
suggestion
Nit
rid
comment
line
applicable
IMHO
style
use
None
None
comment
log
message
path
corner
case
standard
mount
point
string
tmpfs
name
true
worth
todo
comment
better
approach
future
first
test
x
y
attributes
comment
string
>
str
conversion
new
string
dtype
master
boolean
>
bool
PR
dictionary
conversions
TODO
RuntimeError
worth
comment
explanation
test
suggestion
respective
elements
other
GeoSeries
GeoDataFrame
information
contents
note
last
sentence
paragraph
more
words
sentence
Notes
sentences
notes
@
jdmcbr
reason
explicit
list
classifiers
k
number
bins
exception
comments
only
avenue
pyproj
access
listing
EPSG
codes
comment
filterwarnings
warning
actual
array-level
op
comment
set_isolated_mode
variable
None
TypeError
reason
parser_class
None
comment
protected
self._root_gpu
Trainer.__init__
suggestion
def
inner_f
queue
func
*
*
kwargs
pragma
cover
%
sure
codecoverage
parts
example
inner_f
new
process
pretty
sure
codecoverage
comment
function
better
None
test
normalization
incorrect
Could
examples
something
https
//scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html
need
fit
self.datamodule
=
datamodule
methods
trainer.datamodule
suggestion
checkpoints
dir
self._log_model
bit
line
mind
comment
case
suggestion
>
>
>
=
float
int
string
abc
bool
True
list
[
]
namespace
Namespace
foo=3
layer
torch.nn.BatchNorm1d
>
>
>
import
pprint
>
>
>
pprint.pprint
LightningLoggerBase._sanitize_params
params
doctest
+NORMALIZE_WHITESPACE
True
'int
<
class
'torch.nn.modules.batchnorm.BatchNorm1d
>
[
]
'Namespace
foo=3
comment
kind
hack
training
Just
small
comment
[
Name
[
-1
]
looks
E.g
something
[
Name
[
-1
]
name.some.fqdn.net
comma
scope
needs
format
merge
better
early
self.dataset.pre_processor
None
return
self.session.run
self.next_batch
normal
pre_processor
AVX
Added
True
False
flag
CPU
architecture
redundant
cpu_name
==
comment
return
eles
self.fail
cpu_name
%
s
%
cpu_name
comment
line
retries
@
verenceLola
New
York
rooms
person
rooms
string
format
unstructured
data
filter
first
characters
comment
Translations
message
quality
pylint
no-member
pylint
disable=no-member
super
CourseRun
self
call
below
validation
comment
comment
data
set
Please
add
comment
others
special
logic
EDX_STATUS
column
Might
easier
future-proof
__init__
args
*
*
kwargs
super
.__init__
*
args
*
*
kwargs
import
statement
Ww
official
version
point
defensive
parenthesis
@
amangano-edx
course_run
enrollment_start
future
possible
candidate
seat
need
past
tomorrow
comment
determination
seat
v.
'candidate
seat
short
comment
reader
understand
great
>
need
extra
variable
request.GET.get
returns
None
default
value
single
line
queryset
object
need
extra
query
L58
CourseUserRole.objects.filter
course__organizations__in=
[
obj.organization
]
role=obj.role
.update
user=obj.user
state
something
plan
new
seat
type
sense
implementer
new
seat
type
method
comment
code
clearer
comment
sense
sure
case
error
types
Other
seat
types
logic
present
applicable
seats
course
run
upgradeable
rule
Lines
Querysets
MatthewPiatetsky
seat_types
misleading
Seat
model
circular
import
course_discovery.apps.course_metadata.models
Seat
Do
things
Seat
worth
comment
list
comprehension
order
ambitious
courses
entitlements
undocumented
api
quick
comment
unprivileged
user
ddt
dual
test
obvious
case
calls
other
start
end
times
bit
confusing
call
comment
comment
Sorry
whole
PR
comment
test
stable
versions
reason
stable
version
ditto
other
occurrences
suggestion
value
None
MNE
skip
warn
'Unable
hand
value
MNE
subject
handedness
suggestion
check_version
pragma
cover
updated
day
today
https
//data.iana.org/TLD/tlds-alpha-by-domain.txt
Last
Updated
Wed
Jun
UTC
new
TLDs
comment
line
Let
TODO
python3
issue
TODOs
look
@
cprov
comment
Right
specification
space
fine
specialty
internap
-/
Anyway
previous
comment
working
worth
internap
hacks
Other
👍
Side
note
Final
typing
dictionary
parts
args
clean
command
part
rest
TODO
comment
situation
place
comment
test
good
previous
comment
something
self.expected_details
self.assertThat
state.assets
'source-details
]
[
self.expected_details.key
Equals
self.expected_details.value
source-commit
key
value
tuples
informational
comment
everything
something
simple
base
snap
execution
environment
snap
Wait
wait
fetch/reset
Hmm
good
call
good
testing
order
reset
recurse
submodules
something
lines
http
//stackoverflow.com/a/17871677
uh
best
idea
common.internal
good
bits
is_snap
public
API.
tests
logic
other
internal
module
snapcraft.internal.common
import
is_snap
_is_snap
code
comment
module
docstring
p_flags
bit
mask
segment
man
mode
elftools.elf.constants.P_FLAGS.PF_X
=
True
Added
comments
comment
PHI
variables
typical
experience
typical
small
docstring
behavior/parameters
rejigger
things
current
push
internal
code
P
comment
line
required
param
scenario
valid
endpoint
http
wording
consistent
Azure-core
https
//github.com/Azure/azure-sdk-for-python/blob/cd25de58e00d624511b5154e9fe8683826020bc0/sdk/core/azure-core/azure/core/pipeline/policies/_authentication.py
L55
actual
logger
configuration
hard-coded
much
usage
cli-log-level
stuff
free
Please
comment
retry
count
others
Sure
positional
parameter
method
call
change
>
>
>
def
foo
print
>
>
foo
>
>
>
def
foo
b
print
>
>
foo
Traceback
recent
call
last
File
<
stdin
>
line
<
module
>
TypeError
foo
positional
argument
b'
need
Really
dumb
maintainability
nit
uninitiated
side
maps
mgmt
vs
May
comment
tiny
bit
clarity
thought
configuration
suggestion
Instantiate
default
credential
credential_type
def
get_default_credential
authority_host_alias=None
alias
=
authority_host_alias
os.environ.get
AZURE_AUTHORITY_HOST_ALIAS
=
host_alias_map.get
alias
KnownAuthorities.AZURE_PUBLIC_CLOUD
return
self.credential_type
authority=authority_host
models
aio
namespace
nice
input
arguments
numpy
array
unclear
argument
name
array
mesh
merging
meshes
magical
[
]
suggestion
def
mesh_join_np
verts
edges
pols
out_np
accum_vert_lens
np.add.accumulate
[
len
v
v
chain
[
[
]
]
verts
=
len
]
is_edges_first_object
e_out
=
np.concatenate
[
edg
+
l
edg
l
zip
edges
accum_vert_lens
e_out
=
np.array
[
]
np.int32
is_pols_first_object
=
len
pols
]
is_something_else
=
out_np
]
is_pols_first_object
is_something_else
is_array_of_lists
pols
]
.dtype
==
is_array_of_lists
p_out
=
[
np.array
p
l
pol
l
zip
pols
accum_vert_lens
p
pol
]
p_out
=
np.concatenate
[
pol
+
l
pol
l
zip
pols
accum_vert_lens
p_out
=
[
[
v
+
l
v
p
]
pol
l
zip
pols
accum_vert_lens
p
pol
]
=
np.concatenate
verts
v_out
e_out
magic
numbers
idea
node
property
equal
output
name
great
imho
explicit
more
explicit
more
lines
code
self.coordinates
z
elif
theta
Just
case
something
check
Exception
coordinates
type
.format
self.coordinates
@
zeffii
socket
new
way
connections
expected
behaivour
user
point
view
e
double
traceback
comment
Took
while
PHYML
CPUs
single
line
comment
single
automated
testing
======================================================================
FAIL
test_integer_none
test_Entrez_parser.ESummaryTest
Test
ESummary
XML
Integer
Traceback
recent
call
last
File
C
\projects\biopython\Tests\test_Entrez_parser.py
line
test_integer_none
self.assertIsNone
record
TautomerCount
]
AssertionError
NoneElement
attributes=
None
one
https
//github.com/biopython/biopython/blob/master/Bio/Entrez/Parser.py
L55
object
None
special
None
value
back
self.assertEqual
please
noqa
A502
comment
flake8
comment
v1.8
beta
PR
sense
blank
line
problem
flake8
./Tests/test_PDB.py:911:1
D202
No
blank
lines
function
comment
line
D202
black
disagreement
comment
line
suggestion
index
post
Sept
GEFS
init_time
pd.Timedelta
'195hr
cloud_cover_mixed.index
suggestion
e.g
Prob
o
<
f
%
Forecast
units
obs
constant
value
%
object.__setattr__
cls
'constant_value_units
%
explanation
something
suggestion
save_image
=
image2
use_image2
else
image
pygame.image.save
save_image
saveX-
:04
.format
save_counter
core
suggestion
whole
save
call
note/comment
checksum
non-ASCII
characters
Action
wait
strategy
upfront
confusion
@
ryandillinfelton
https
//projects.engineering.redhat.com/browse/RHCLOUD-3562
relaxed
enforcement
system
id
i.e
entire
api
operation
other
words
function
comment
applies
statement
relevant
Whatever
part
code
responsible
KafkaConsumer
responsible
closing
I.e
initialized
reference
instance
part
code
loop
control
https
//github.com/RedHatInsights/insights-host-inventory/blob/master/inv_mq_service.py
L35
Consider
comment
clear
necessary
i
i
excluded
ioc
hash
key
below
case
line
little
different
parenths
necessary
comment
disable
decorator
user
rule
good
catch
comments
Please
assert
error
message
total_scale
==
hop_lengths
document
requirement
function
anticipation
future
short
existence
open
function
error
comment
checks
comment
module
name
skimage
display
skimage.submodule
submodule
skimage.submodule.subsubmodule
ignore
logic
something
module_name
continue
module_name
display_name
=
module_name
]
elif
len
module_name
display_name
=
module_name
]
w
'-
<
.html
__\n'.format
display_name
module_name
test
flatten
expected_warnings
Just
btw
arg
std
:unordered_map
default
older
versions
gcc
Linux
builds
https
//stackoverflow.com/a/3973692/224254
comment
Rather
clamping
better
negative
eigenvalues
ie
eigvals
np.clip
eigvals
None
+1e-13
suggestion
point
precision
problems
positive
semidefinite
matrix
eigenvalue
negative
problems
line
set
values
zero
hack
ok
image
shapes
equal
suggestion
result
=
np.zeros_like
image
Ach
proponent
functional
programming
next
guy
friendly
Python
newcomers
example
python
ratio
use
half
samples
=
int
ratio
*
len
src
sample
size
better
comments
above
codes
positive
bbox
feats
comments
change
necessary
previous
code
more
general
Data
Augmentation
Strategies
Object
Detection
<
https
//arxiv.org/abs/1906.11172
>
double
quotes
docstrings
comment
users
processed
image
channels
self.mean
==
self.mean
]
comments
target
binary
comments
neg_loss
gaussian
target
GaussianFocalLoss
lot
pr
comment
line
order
img_metas
'_img_metas
'aug_img_meta
'aug_img_metas
consistent
'aug_proposals
comments
dcn
Res2Net
bottleneck
ModuleList
sure
copy
all_params
good
comment
fact
series
params
signature
DF
method
i.e
something
suggestion
parameters
part
signature
Series
method
same
corresponding
DataFrame
method
series_call_params_str
=
all_params
]
func_definition
=
_reduce_impl
all_params
recommendation
PR
[
pep8
recommendation
]
https
//www.python.org/dev/peps/pep-0008/
string-quotes
triple-quoted
strings
double
quote
characters
consistent
convention
PEP
>
comment
docs
changes
file
testing
changes
critical
separate
PR
overridden
class
issue
change
review
app
comment
etc
look
other
day
something
exc.args
+=
user_friendly_info
Necessary
hasattr
exc
'msg
exc.msg
+=
+
repr/str
ImportError
objects
Python
comment
correct
new
position
comment
future
maintainers
easier
time
statement
print
results
Please
spaces
lack
tests
[
Travis
report
]
https
//travis-ci.org/mozilla/pontoon/builds/594658552
utm_source=github_status
utm_medium=notification
hard
sync
task
https
//github.com/mozilla/pontoon/commit/dd5e48051abb2f02f4d3591c1566ca7f9ab9f1ec
diff-2be3ba079451045c9badba06c960b1d0
logs
things
case
Translation
Entity
Locale
sense
element
logs
become
useless
users
different
scenario
properly
delete
users
possible
on_delete
property
User
foreign
key
comment
line
validation
error
something
ActionLog
entry
needs
least
translation
entity
locale
'en-GB
piece
line
comment
bugs
references
objects
tricky
comment
infact
pipelines
nit
comment
entry
comment
attribute
flink
operator
space
comma
function
arguments
spaces
equal
signs
self.first_play_test
C
seed=1
guideline
PEP8
several
more
instances
tuples
space
comma
stylish
way
D
C
Ok
thank
same
Hello
@
MariosZoulias
few
comments
PEP8
PEP8
style
guide
python
code
tips
code
look
nice
readable
smile
space
comment
space
>
Thus
Player
Desperate
vs
Cooperator
SEED
comments
above
suggestion
+=
f
render_decorator
func
func.name
render_return
func
pass
stylistic
thing
'nan
codebase
np.nan
prevalent
matters
sure
%
sXpath
%
s
intentional
bit
weird
Everything
fine
TODO
NOTE
comment
lack
namespace
checks
child
elements
blocker
small
optimization
elif
check
fail_msg
None
Can
comment
token
_______
comment
pop
JAPH
days
result
nothing
value
point
i
'supports
mode
module
comment
other
unit
test
failure
due
difference
uuid5
Python
Python
Python
uuid5
needs
bytes
def
uuid5
namespace
name
Generate
UUID
SHA-1
hash
namespace
UUID
name
hashlib
import
sha1
hash
=
sha1
+
name
.digest
return
UUID
bytes=hash
[
:16
]
version=5
Python
bytes
bytes
text
def
uuid5
namespace
name
Generate
UUID
SHA-1
hash
namespace
UUID
name
hashlib
import
sha1
hash
=
sha1
bytes
name
utf-8
.digest
return
UUID
bytes=hash
[
:16
]
version=5
suggestion
uuid.uuid5
bytes
Python
bytes
text
Python
return
to_text
uuid.uuid5
uuid_namespace
to_native
errors='surrogate_or_strict
suggestion
b_colldirs
=
list_collection_dirs
coll_filter=coll_filter
New
functions
PEP
type
hints
comment
description
docstring
inventory
files
C.DEFAULT_HOST_LIST
list
sure
self.options.inventory
=
C.DEFAULT_HOST_LIST
comment
_cache
return
disabled
i
Please
required=False
required=False
implicit
comment
code
someone
git
PR
reasoning
matter
frozenset
tuples
immutables
sets
python
BASE
=
frozenset
'role
FROM_ARGS
=
frozenset
OTHER_ARGS
=
frozenset
'private
'allow_duplicates
VALID_ARGS
=
frozenset
BASE.union
FROM_ARGS.union
OTHER_ARGS
different
reason
code
good
purpose
comment
BASE
FROM_ARGS
OTHER_ARGS
reason
separate
adhoc
extra
config
bin_ansible_callbacks
Any
reason
line
suggestion
ImportError
self.client
danger
comments
exception
comment
valid
ComputerSystem
Storage
resource
SimpleStorage
resource
Drives
system
original
SimpleStorage
Storage
SimpleStorage
Stroage
resoures
present
result
drive
info
'SimpleStorage
data
'Storage
data
return
'ret
False
'msg
SimpleStorage
Storage
resource
'SimpleStorage
data
original
SimpleStorage
logic
'Storage
data
new
Storage
logic
logic
right
*
failed==False
module
side
play_context
no_log
IIRC
module
_ansible_no_log
failed==True
failed=False
module-side
failed=True|False
check
code
check
invocation
needs
play_context.no_log
False
case
no_log
True
invocation
security
guarantees
no_log
Please
exception
simple
key
check
simple
condition
expression
evaluation
assignment
dest
linux_mounts
m
=
linux_mounts
dest
]
elif
m
[
'src
]
src
is_mounted
=
True
abadger
diff
None
path
vendored
file
history
upstream
patches
vendored
libs
[
'Status
]
[
'Addr
]
worse
url
begin
https
//
TLS
least
module_utils/docker/common.py
code
Kali
branch
Please
note
upstream
package
link
upstream
PR
Please
line
YAML
something
closer
filters
example
C
vm_state
'active
free
others
code
avoid
byte
text
strings
pgp_regex
string
python2
pgp_regex
byte
string
python3
pgp_regex
text
string
string.decode
string
text
string
text
bytes
python2
better
way
python
ansible.module_utils._text
import
to_native
[
]
return
bool
re.match
pgp_regex
to_native
errors='surrogate_or_strict
re.DOTALL
to_native
string
type
unadorned
literal
byte
string
returns
'surrogate_or_strict
error
handler
python3
surrogate
values
non-utf8
characters
python2
traceback
*
bool
return
value
function
byte-oriented
regex
match
text-oriented
regex
match
different
versions
python
Callers
truthiness
bool
something
undocumented
little
bug
executable_arguments
list
mutable
container
[
dry-run
]
container
python
mutable
containers
reference
caller
executable_arguments
dry-run
undesirable
previous
code
identifier
executable_arguments
new
list
copy
parameter
executable_arguments
additional
element
dry-run
obvious
code
copy
executable_arguments
def
module
name
easy_install
executable_arguments
Copy
arguments
executable_arguments
=
executable_arguments
[
]
executable_arguments.append
dry-run
rc
=
install_package
module
name
easy_install
executable_arguments
rc
module.fail_json
msg=err
return
Trick
credit
https
//twitter.com/raymondh/status/967927989752098816
lot
docstring
sure
exact
index
slices
size
much
safer
work
chunks
python
vlan_id
name
state
interfaces
[
v.replace
.strip
v
current_line.split
please
python
so-called
snake_case
variables
java
js
line
Please
add
comment
double
quotes
name
oVirt
resources
possible
space
name
suggestion
See
https
//www.suse.com/support/kb/doc/
id=000019341
SLES
SAP
os.path.islink
'/etc/products.d/baseproduct
os.path.realpath
'/etc/products.d/baseproduct
.endswith
'SLES_SAP.prod
sure
channels
mutable
default
arg
same
reference
calls
method
wrong
behavior
subscribe
default
arg
place
module
main
'channels
var
list
default
channels
list
_clean_data
variable
need
isinstance
check
comment
function
json
useful
error
constraints
Packet
API
e.g.
device
provisioning
state
json
order
HTTP
responses
error
descriptions
Teria
como
colocar
criação
casa
construtor
Serializer
__init__
args
*
*
kwargs
super
SessaoPlenariaSerializer
self
.__init__
args
kwargs
casa
=
CasaLegislativa.objects.first
*
Se
funcionar
não
precisa
pesquisar
casa
para
cada
método
que
usa
*
*
Corrigido
para
todos
os
casos
IntensityTable
LocalMaxPeakFinder
i
awhile
comment
only
columns
x
y
z
radius
quality
something
hmmm
TODO
harder
fourier
registration
args.ds
long-form
name
expressive
idea
default
result
default
cookie
flag
great
pattern
docs
minimum
Result
docstring
cookies
property
cookies
subsequent
requests
annotations
=
self.info
[
'meas_date
]
@
larsoner
nicer
suggestion
note
Spherical
leadfield
center
semidefinites
problem
tests
warnings.simplefilter
line
==
datetime
instance
proper
timezone
less
much
lines
comment
1e-6
FYI
private
functions
Compute
ExG/ref
components
find_bads_ecg
find_bads
eog
find_bads_ref
details.
code
bit
easier
end
things
more
DRY
docstrings
sync
anyway
more
harm
good
indentation
problem
pytest
mne/preprocessing/tests/test_eog.py
flake8
mne/preprocessing/tests/test_eog.py
comment
case
gfp
necessary
chunk
large
existing
functions
comments
workflow
amount
comments
few
possible
code
functions
events
idx
]
.duration
event.duration
this_duration
event.duration
ndarray
contents
slower
long
tube
thousands
tens
thousands
single
tubes
much
worse
overhead
versus
single
contiguous
tube
mode='continuous
vs
mode='separate
something
different
modes
array
shape
n_segments
contiguous
tubes
separate
n_segments
single
contiguous
tube
best
solution
PyVista
VTK
different
GuillaumeFavelier
point
good
deeper
PyVista
Mayavi
VTK
level
long
run
able
properties
ton
objects
rob-luke
comment
TODO
performance
problem
future
..
footbibliography
People
suggestion
other
evoked
data
e.g
mne.write_evokeds
all_evokeds
warnings.catch_warnings
tests
way
users
DeprecationWarnings
use
due
upstream
lib
bugs
Parameters
other
docstrings
Ah
label.subject
None
comment
nobody
tries
sure
good
idea
user
private
function
potential
option
prop
value
LSLClient
source_id
user
sure
unique
machine
criteria
multiple
items
client
ok
change
latest
breaks
things
recent
call
last
File
examples/io/plot_objects_from_arrays.py
line
<
module
>
raw
=
mne.io.RawArray
data
info
<
string
>
line
__init__
File
/home/larsoner/custombuilds/mne-python/mne/utils.py
line
verbose
return
function
*
args
*
*
kwargs
/home/larsoner/custombuilds/mne-python/mne/io/array/array.py
line
__init__
raise
ValueError
array
shape
n_channels
ValueError
Data
array
shape
n_channels
n_samples
revert
separate
PR
fix
circle
build
master
other
words
undo
*
fix
version
works
Neo
latest
change
older
versions
Exception
wrapped
function
keyword
to_hz
*
*
kwargs
opinion
wrapped
function
keywords
purpose
decorator
namurphy
@
StanczakDominik
ways
def
wrapper
*
args
*
*
kwargs
_result
=
fn
*
args
*
*
kwargs
to_hz
return
_result.to
u.Hz
equivalencies=
[
u.cy/u.s
u.Hz
]
return
_result
def
wrapper
*
args
*
*
kwargs
to_hz
=
'to_hz
False
_result
=
fn
*
args
*
*
kwargs
to_hz
return
_result.to
u.Hz
equivalencies=
[
u.cy/u.s
u.Hz
]
return
_result
fundamental
difference
former
readable
concise
bound_args
given_params
decorators
decorators
function
parameters
suppose
comment
main
PR
thread
documentation
wrapped
function
statement
beginning
comment
reference
wrapped
function
code
delete
previous
comment
wrapper
awhile
tests
ionization_balance
Z_bal_
Z_bal_
ionization_balanced
old
code
condition
entire
loop
getattr
sense
tests
transaction
tag
benefit
del
Let
use
NotImplementedError
https
//docs.python.org/3/library/exceptions.html
NotImplementedError
endpoint
local
session
Should
suffice
recommendation
user
endpoint
logging
message
normal
case
little
esoteric
logging
developer
documentation
Succeed
default
bucket
note
role
path
i
num_quant_bins
nit
comment
necessary
change
comment
sure
useful
TransformReparam
TransformReparam
following
site
=
pyro.sample
x
TransformedDistribution
dist.Normal
Affine
loc
scale
usage
similar
comment
code
purpose
computation
Could
comment
use
NonreparameterizedNormal
Normal
ditto
longer
namedtuples
type
loss
torch_item
loss
nit
little
comment
munging
comment
field
boto3
response
comment
change
A
small
comment
nice
floor
division
gas_limit
gas_limit
suggestion
exception
same
above
comment
default
high
comment
small
explanation
number
Years
Comments
workarounds
error
type
ut
tests
traceback
worth
comment
i
key_type
value_type
nice
documentation
perspective
functions
comment
oh
man
pretty
nasty
minimum
comment
worthy
special
case
condition
data
latest_non_cve_version
blank
logger.error
msg
Dont
add
exception
error
msg
Please
comment
line
thing
list
comprehension
likewise
pease
comment
nit
todo
error
possible
chain
easy
flat
error
'paths
git_repo
raise
RuntimeError
git
repository
entry
artman
YAML
module
paths
Note
path
spots
appropriate
error
good
idea
error
error
pipeline
construction
WDYT
Empty
list
whereas
[
]
sense
opt-in
problem
error
paths
proposal
okay
csharp
layout
latest
code
TODO
PR
@
jskeet
FYR
well
help2man
makeinfo
tools
arguments
simple_output_script
thing
bit
hacky
considerable
amount
work
CMake
targets
//github.com/tristanpenman/valijson
how-to-add-this-library-to-your-cmake-target
>
target_link_libraries
your-executable
ValiJSON
:valijson
suggestion
del
self.options.fPIC
Same
effect
more
pythonic
Le
un
peu
normalement
c'est
pour
tester
qu'au
un
des
éléments
liste
est
True.
Ici
c'est
plutôt
un
len
que
j'aurai
fait
Ou
[
char.isupper
char
password
]
Same
TODO
slow/fast
discussed
offline
morning
documentation
[
]
https
//docs.djangoproject.com/en/3.0/topics/migrations/
data-migrations
best
practice
Django
model
classes
migration
something
py
EnforcementActionStatus
=
apps.get_model
'EnforcementActionStatus
top
module
reason
sure
code
historical
model
state
time
migration
comment
vm_class
unmodified
layer
inheritance
chain
functionality
pipermerriam
@
gsalgado
typings
generic
stuff
non-generic
object
generic
fan
Generics
other
languages
bloody
Python
newbie
implications
whole
block
something
python
qiskit.quantum_info
import
Statevector
sv
=
Statevector.from_label
*
circuit.num_qubit
sv
=
sv.evolve
circuit
=
sv.probabilities
i
num_ancillas
part
sure
couplingdict
couplinglist
clearer
code
]
comment
cregs
isinstance
Gate
op
circ.data
sure
global_index_map
mapping
Qubit
wire
dag.wires
integer
index
ordered
list
register
wire
pairs
register
dag.qregs.values
index
ordering
wire
register
Qubit
wires
desired
order
mapping
indices
list
something
global_index_map
wire
idx
idx
wire
enumerate
dag.qubits
equivalent
min
np.dot
state
[
i
state
[
i
.conj
.real
message
true
pass
layout
Could
text
deprecation
policy
text
https
//qiskit.org/documentation/contributing_to_qiskit.html
deprecation-warnings
Both
list
list
bits
insane
examples
case
hacky
way
exception
possible
better
exception
catch
suggestion
qubit
self.qregs
layer.set_qubit
qubit
Barrier
suggestion
def
__new__
cls
name
uuid=None
pylint
disable=unused-argument
suggestion
qiskit.quantum_info.operators
import
Operator
pylint
disable=cyclic-import
list
similar
items
tuple
items
different
status
semantics
suggestion
h
files
smaller
list
sections
=
[
'h_code
'utility_code_proto_before_types
'type_declarations
suggestion
FIXME
try
put_var_decref
code.put_var_xdecref
entry
have_gil=not
lenv.nogil
special-casing
general
type
case
case
type
iterable
tuple
list
sure
guess
least
current
code
transformation
tight
worth
current
special-casing
regression
way
good
comment
headers
docstrings
thing
deallocation
machinery
deallocation
code
code
refcount
object
alive
/
arbitrary
user
code
alias
plan
command
classes
ArgparsedCommand
logic
aliases
None
pwndbg
brva
function
alias-like
logic
docstring
refactoring
hint/warn/error
valid_values
few
SAIF
activity
factors
activity_file
VCD/VPD
waveform_file
addition
Colin
lowercase
cache
specific
install.path
suggestion
install.path
tech_cache
something
records
V13
records
value
compute
call
__
[
Flake8
]
__
[
E501
]
line
characters
Comment
[
Sider
]
https
//sider.review
>
__
[
flake8
]
__
*
[
E301
]
blank
line
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
E731
]
lambda
expression
def
<
Comment
[
SideCI
]
https
//sideci.com
>
__
[
flake8
]
__
*
[
E127
]
continuation
line
over-indented
visual
indent
<
Comment
[
SideCI
]
https
//sideci.com
suggestion
validation
item
WorkbenchResearcherEducation
item.get
'education
POST
GET
PUT
rdr_service/main.py
BiobankSpecimenApi
same
comment
new_params
comment
mind
query
AST
comment
rid
trivial
implementation
example
https
//github.com/getsentry/snuba/compare/scheduler
diff-22926dd5eda88654f5e7bb17ae6165aaR18-R26
Should
wrap
self.__source.get_table_file
self.__dataset_table
try
/
error
good
justification
able
subscription
id
results
producer
fine
updates
subscriptions
end
subscription
store
subscription
id
subscription
huge
deal
Same
comment
regard
comment
least
version
clickhouse
driver
ip
addresses
Please
TODO
distributed
version
same
local
table
materialization
columns
distributed
version
CREATE
TABLE
default.transactions_dist
event_id
UUID
trace_id
UUID
span_id
UInt64
transaction_name
LowCardinality
transaction_hash
UInt64
transaction_op
LowCardinality
transaction_status
UInt8
start_ts
DateTime
start_ms
UInt16
finish_ts
DateTime
finish_ms
UInt16
duration
UInt32
platform
LowCardinality
environment
LowCardinality
Nullable
release
LowCardinality
Nullable
dist
LowCardinality
Nullable
sdk_name
LowCardinality
sdk_version
LowCardinality
ip_address_v4
Nullable
IPv4
ip_address_v6
Nullable
IPv6
DEFAULT
user_id
Nullable
user_name
Nullable
user_email
Nullable
tags.key
Array
tags.value
Array
String
contexts.key
Array
contexts.value
Array
String
partition
UInt16
UInt64
message_timestamp
DateTime
retention_days
UInt16
UInt8
ENGINE
=
Distributed
snuba_transactions
default
transactions_local
cityHash64
span_id
suggestion
NOTE
sileht
bool
int
case
environment
PR
suggestion
consumption
=
load
suggestion
Identify
other
object
same
rule
match
comment
docstring
same
thing
line
suggestion
hash
value
MatchError
instance
module
AbstractReportXlsx
Ditto
other
files
something
broken
links
change
sphinx
configuration
SyntaxError
Python
string
eval
following
python
]
x
[
]
eval
x
+
x
]
comment
values
Misindent
Ditto
test
current
master
AssertionError
assert
<
possible
full
results
output
Python
deterministic
dict
doctest
+NORMALIZE_WHITESPACE
pragma
styling
something
following
>
>
>
_slice_1d
]
slice
-3
doctest
+NORMALIZE_WHITESPACE
slice
-8
-3
slice
-21
-3
slice
-21
-3
slice
-21
-3
slice
-21
-3
comment
//github.com/pandas-dev/pandas/issues/32934
minor
comment
work
set
dependency
code
little
bit
something
python
work
k
=
work.pop
dependencies_k
=
get_dependencies
k
as_list=True
fuse
[
k
]
=
[
]
dependencies
[
k
]
=
dependencies_k
d
dependencies_k
d
seen.add
d
work.add
d
dependencies
aware
though
planning
future
useful
PANDAS_GT_0250
suggestion
added
DatetimeIndex.mean
check_raises
dds
pds
test
use
network
file
Update
comment
type
Could
comment
sentry_init
pytest
fixture
bogus
DSN
linter
order
type
comment
docstring
timeout_thread
condition
clearer
timeout_thread
None
way
timeout_thread
None
timeout_thread.stop
stop
event
true
unblocking
thread
nothing
main
thread
lambda
handler
undesirable
comment
Add
typedef
docstring
pretty
slick
example
file
newbies
good
idea
least
comment
line
multiple
lines
QuantumComputer
roll_die
better
compilation
steps
work
case
qvm
qpu
Can
comment
copy
necessary
>
A
copy
necessary
self.live_qubits
list
consequences
traversal
comment
actors
vehicles
pedestrians
something
following
readable
tf.logical_and
self._debug_summaries
common.should_record_summaries
TODO
order
matters
comment
Empirical
comment
Ah
comment
thing
bson
datetime
timezone
information
timezone
information
current_time
Basic
math
naive
datetime
timezone-aware
datetime
tzinfo
same
behaviour
change
datetime=True
timezone
aware
timezone
config
file
implications
scope
PR
Will
issue
suggestion
Items
common
observation
time
self.common_properties
None
comment
python
Returns
object
EdlyUserProfile
object.
User
registeration
possible
LMS
sub
org
LMS
site
edly_sub_org
=
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Method
function
]
https
//app.codacy.com/manual/Ona/onadata/pullRequest
prid=5585241
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
Method
function
]
https
//app.codacy.com/manual/Ona/onadata/pullRequest
prid=5585241
Uhh
syntax
error
os.environ
'CP_JAVA_HOME
os.environ
*
*
REQUIRED
*
*
So
comment
need
wait_for
method
actual
wait_for
end
update
method
*
*
REQUIRED
*
method
bad
provider
bad
future
error
advantage
cached
property
reports
collection
self.collections
property
*
*
Question
*
*
wrapanapi
mac
address
CFME
0th
index
Same
comment
clarification
izapolsk
right
TODO
intention
add
support
upload
file
move
collection
@
ganeshhubale
automation
FA
+1
Throw
TODO
comment
flash.get_messages
delay=2
fail_condition=
[
]
fail_func=tb.refresh
flash.get_messages
delay=2
test
fails
FlashMessageException
info
flash
message
'Order
Request
[
]
sel.sleep
Added
TODO
block
agree
small
comment
cache
*
*
Required
*
*
Lets
comment
index
Same
comment
*
*
REQUIRED
*
TODO
*
*
TODO
*
only
reason
context
manager
Collections
please
use
noqa
definition
standard
*
*
REQUIRED
*
*
Use
snake_case
nested
views
NOQA
Hehe
condition
people
statement
parameters
wait_for
wait
Please
TODO
Comment
template_type
Understood
comment
code
assumption
last
character
Might
TODO
scope
view
first
page
Q
way
indices
difficult
pages
safer
mixin
user
compare
fine
test
small
line
comment
proper
pattern
framework
instances
assert
view_obj.is_displayed
test
suggested
comment
y
dict
yaml
stream
comment
y
dict
yaml
stream
TODO
legacy
things
widgetastic
comment
broker
setup
port
substring
user
port
deployment_id
live
deployment
id
TODO
check
performance
most
likely
more
prefetch
test
unused
Can
little
comment
suggestion
suggestion
suggestion
>
>
>
model
=
EncoderDecoderModel.from_encoder_decoder_pretrained
pretrained_model_name_or_path
pretrained_model_name_or_path
previous
Unrelated
comment
generate
doesnt
work
comment
way
simpler
Models
token_type_ids
output
XLM
use
wrong
tokenizer.encode_plus
model-specific
output
e.g
BERT
py
bert_tokenizer.encode_plus
hey
'input_ids
[
]
'token_type_ids
[
]
[
]
whereas
DistilBERT
py
distilbert_tokenizer.encode_plus
hey
'input_ids
[
]
[
]
chain
methods
py
inputs
=
tokenizer.encode_plus
xxx
model
*
*
inputs
comment
numbers
comment
please
comment
suggestion
changed_files
'README
changed_files
]
let
comment
desc.md
_image.png
.yml
rn
suggestion
suffix
output
file
name
output_filename
=
file_name_suffix.join
os.path.splitext
output_filename
comment
condiition
checks
betaintegation
scheme
naming
content_revision
context
manager
revision_deletion
previous
code
cause
dry
run
suggestion
update
dict
await
self._throttle_dns_events
key
]
=
\
Space
character
comment
sure
line
most
chars
obvious
comment
someone
future
Same
comment
Order
able
rid
changes
test
https
//docs.djangoproject.com/en/1.9/topics/testing/tools/
transactiontestcase
nit
self.timestamp
random
timestamp
easier
arguments
management
command
CouponVouchers
coupon_vouchers
CouponVouchers
vouchers
create_vouchers
coupon_vouchers.add
*
vouchers
comment
temporary
ticket
username
entitlement
refunds
docstring
comments
multiple
product
basket
case
Sailthru
lines
lines
same
lines
return
waffle
flag
template
Please
JIRA
ticket
switch
future
comment
line
TODO
LEARNER-XXXX
Clean-up
validation
code
further
investigation
Note
LEARNER-5603
open
LEARNER-5603
open
ticket
Thanks
Nice
use
fixture
Suggestion
model
serializer
assignements
data
extra
field
methodfield
serializer
serializer
count
assignment
object
serializers
short
update
read-only
serializer
https
//www.django-rest-framework.org/api-guide/serializers/
read-only-baseserializer-classes
Ah
line
self.course_seat_types
value
parameter
value
None
Good
chance
conditional
logic
course_seat_types
error
catalog_query
course_catalog
error
catalog_query
course_catalog
error
easier
nit
comment
course
catalog
field
sure
reason
range
parameters
course_seat_types
developer
catalog_query
suggested
conditions
range
parameters
good
way
worth
explicit
elif
additional
product
types
somepoint
documentation
case
newer
version
endpoint
comment
NFKD
comment
nit
please
comment
final
URL
API
call
something
GET
/api/v1/catalogs/
catalog_id
course_run_ids=
course_run_id
@
clintonb
basket
page
priority
[
BasketSingleItemView
]
https
//github.com/edx/ecommerce/blob/master/ecommerce/extensions/basket/views.py
L43
Enterprise
entitlements
voucher
request
much
sense
multiple
entitlement
vouchers
calculate
endpoint
sku
[
part
]
https
//github.com/edx/ecommerce/blob/master/ecommerce/extensions/api/v2/views/baskets.py
L364
endpoint
enough
single
product
try
Enterprise
entitlement
voucher
products
voucher
=
get_entitlement_voucher
request
products
]
newest
comment
necessary
suggestion
https
//github.com/tensorflow/tensorflow/issues/40688
depends_on
'py-numpy
@
type=
'run
@
depends_on
'py-numpy
@
type=
'run
more
robust
API
breaking
change
older
versions
order
comment
pkgconfig
line
note
homebrew
comment
Debian
default
bash
builds
comment/reference
line
cyclic
dependency
So
+nccl
CUDA
AFQMC
+cuda
CUDA
real-space
QMCPACK
best
independent
description
nccl
variant
CUDA
NCCL
libraries.
rid
comment
fact
string=True
problem
Fujitsu
compiler
file
time
>
ERROR
/tmp/ihara/spack-stage/spack-stage-bazel-0.29.1-lmznhxdrwncyrhhmvalccpvzi25ggvpr/spack-src/thi
rd_party/ijar/BUILD:74:1
error
.d
file
/tmp/bazel_tni6ciH6/out/execroot/io_bazel/baze
l-out/aarch64-opt/bin/third_party/ijar/_objs/zipper/zip_main.d
such
file
directory
problem
serial
serial
Fujitsu
compiler
Therefore
idea
bootstrap
spec
prefix
+
self.spec.satisfies
%
fj
+
parallel
=
False
bash
=
'bash
bash
'./compile.sh
suggestion
url
=
https
//pypi.io/packages/source/C/CherryPy/CherryPy-18.1.1.tar.gz
above
python
fs.tmp_cwd
env_dir
mkdtemp
cruft
permissive
env_dir
suggestion
version
'master
submodules=True
branch='master
break
variables
v1.x
hwloc
python
depends_on
@
:1
TBH
additional
dependencies
clause
Linux-specific
short
comment
patch
'awk
Might
whole
compatibility
table
=================
========================
llvmlite
versions
compatible
LLVM
versions
=================
========================
comment
compatibility
table
README.rst
strings
rid
wait
suggestion
self.spec.satisfies
%
gcc
+fortran
multiple
build
systems
better
Package
scheduler
variant
self.spec.variants
'scheduler
]
.value
string
list
least
spack-python
shell
list
desirable
effect
[
'libgcrypt
]
.prefix.share.aclocal
necessary
release
versions
hash
security
reasons
sense
case
commit
hash
conditional
exception
comment
pretty
useless
line
English
sure
necessary
comment
library
version
reference
//github.com/imagemin/optipng-bin/issues/97
comment
patch
@
luszczek
Could
comment
link
patch
e.g
See
https
//github.com/Reference-ScaLAPACK/scalapack/issues/9
version
i.e
when=
@
worth
mentioning
affect
symlink
target
symlink
related
>
files
~
filter_file
backup=False
files
text
list
filter_file
install
IMO
clearer
otherwise
paths
~
i.e
home
directory
paths
~
backup
file
editors
IMO
something
worth
comment
check
suggestion
https
//github.com/spack/spack/pull/11579
'+python
self.spec
F811
redefinition
unused
'docker_tasker
line
comment
easier
list
comprehension
needs
comments
order
things
e.g
sure
order
right
diff_ids
ordered
oldest
first
history
newest
oldest
first
=
[
diff_id
layer
[
'Size
]
diff_id
layer
zip
diff_ids
history
typed_digests
docker_digests
nice
comment
media
>
digest
line
image
>
digests
repository
Stickler
py.test
fixtures
work
line
noqa
comment
docker_tasker
fixture
Let
comment
F401
unused
F811
redefinition
unused
line
None
E302
blank
lines
F811
redefinition
unused
'docker_tasker
line
E501
line
characters
Let
comment
F401
unused
Could
logic
basic_auth
=
HTTPBasicAuthWithB64
self.auth_b64
elif
self.username
self.password
basic_auth
HTTPBasicAuth
self.username
self.password
basic_auth
None
V1
self.v1_auth
basic_auth
self.v1_auth
=
V2
....
basic_auth
self.v2_auths.append
basic_auth
comment
valid
auth
v1
ImageName.parse
image_id
block
sure
exceptions
call
exceptions
bug
try
image_id
=
TypeError
KeyError
IndexError
TypeError
KeyError
IndexError
base_image
=
base_image
=
ImageName.parse
image_id
exceptions
comment
i.e
build
plugin
error
set_media_types
return
values
non-numpy
run-results
expert_demos_ex
add
comment
code
helpful
pragma
cover
lines
main
console
blocks
comment
optional
dependencies
expected/non-critical
error
Looks
ready
FIXME
'stable-baselines
@
git+https
//github.com/hill-a/stable-baselines.git
vec-normalize-pickle
suggestion
normalize_kwargs
=
dict
kwargs
reading
documentation
try
tag
SSH
command
crashes
try
yield
instance_ip
rest
code
excerpt
documentation
example
contextlib
import
contextmanager
@
contextmanager
def
managed_resource
*
args
*
*
kwds
Code
resource
e.g
resource
=
acquire_resource
*
args
*
*
kwds
try
yield
resource
Code
resource
e.g
release_resource
resource
>
>
managed_resource
timeout=3600
resource
Resource
end
block
code
block
exception
smaller
file
s3mi
ok
smaller
file
s3mi
ok.
please
code
comment
obvious
least
k
please
valuable
non-obvious
info
code
comment
phylo
tree
creation
taxon
unknown
superkingdom
k
k_config
key
None
superkingdom_name
=
self.additional_attributes.get
superkingdom_name
None
time
Sorry
default
value
one
separate
PR
None
us-central1
comment
appropriate
Thanks
comment
everything
comment
changes
description
conversation
fine
i.e
SMTP
servers
u/p
authentication
flags
server
CodaLab
Add
brief
comment
matches
group
read
permissions
comment
correct
arbitrary
streams
bytes
strings
Python2
new
bytes
type
Python3
unicode
type
Unicode
data
logic
comments
TODO
everything
unicode
nit
bit
wordy
something
table_columns_valid
idk
thoughts
comment
chunk
size
place
repo
w/o
Please
explanation
code
append
join
seem
unnecessary
simple
error
message
easy
story
comment
block
bit
business
context
obvious
initiated
person
clcs
=
[
ControlListEntry.create
clc
Description
None
False
clc
ML7f1
ML6b1
ML6b2
ML13c
ML13d1
ML13d2
ML1a
Ml1b
]
]
comment
+1
Could
docstring
bit
database
lock
possibility
people
same
reference
code
same
time
bug
main
application
reference
number
function
pernickety
least
comment
Comment
please
flag
rule
inactive
rule
inactive
clear
code
clear
anyone
requirement
mistake
Comment
Let
comment
condition
colorbar
fixed
color
string
purpose
statement
obvious
default
ylabel
ylabel
None
flux
column
ylabel
Normalized
Flux
ylabel
Flux
ylabel
=
f
column
Add
unit
available
self
[
column
]
.unit
ylabel
+=
f
self
[
column
]
.unit.to_string
latex_inline
few
lines
comments
equations
duplicate
line
prompt-toolkit
>
=2.0.0
line
data_by_field.get
column_id
None
function
comment
Resolve
directives
value
dictionary
value
callable
view
default
value
config
object
defaults
place
max
keepalive
value
case
MAX_KEEPALIVE
comment
value
limitations
load
balancer
>
first_stage
=
None
[
]
length
=
line
BKTODO
generic
please
better
fix
spot
value
seconds
miliseconds
comment
please
email
template
comment
universal
tagging
tremendous
nit
math
xmlrpc_cache_expires=24
*
Hours
clear
inclusion
monkeypatch
fixture
touch
suggestion
sort
incident
grid
creation
date
main_incident_grid.sort
key=lambda
incident_dict
incident_dict.get
'creationdate
reverse=True
default
value
specific
error
fine
whole
error
dev
comment
add
comment
comment
please
add
comment
logic
polling
section
PEP8
length
readable
add
comment
comment
cases
test
ValueError
code
section
i
comments
PLACEHOLDER
consistent
First
.alchemy
import
TencentAlchemyDataset
data/chem/__init__.py
.chem
import
Tox21
TencentAlchemyDataset
os
line
+1
+2
undfined
undefined
Please
comment
pylint
warning
global
knownNodes
pylint
disable=global-statement
Pep8
validation
comment
true
jnp.sort
necessary
additional
information
comment
helpful
information
comment
return_shape
helpful
nit
extra
line
Add
TODO
number
Comment
XLA
FFTs
innermost
axes
necessary
mysterious
sure
API
surface
docstring
function
jnp.bfloat16
arrays
code
most
code
TF
world
jnp.bfloat16
rng_factory
testcase
argument
jtu.rand_default
kind
pattern
general
form
masking
rule
polymorphic
shapes
common
case
convenience
wrappers
refactor
TODO
mattjj
generalize
mask
rule
signature
line
example
functional
model
line
example
functional
API
comment
upwards
Can
comment
new
version
handy
code
whole
file
windows
dtype
_dtype_with_checking_system
something
comments
new
version
important
Re
default
CBSD
category
[
'cbsdCategory
]
KeyError
exception
lot
simpler
blank
line
Please
implement
other
tests
https
//github.com/exercism/problem-specifications/blob/master/exercises/food-chain/canonical-data.json
Could
comment
version
canonical-data.json
tests
applicable
format
Tests
problem-specifications//canonical-data.json
@
v1.0.0
comment
version
canonical-data.json
tests
aplicable
format
Tests
problem-specifications//canonical-data.json
@
v1.0.0
suggestion
Additional
tests
track
def
test_two_sides_are_equal_and_third_side_is_larger
m
=
mn
//
n
m
>
n
sort
second
sort
following
=
n2
b
*
m
*
>
b
b
=
b
yield
b
m2
+
machine
~25
%
comprehension
solution
readable
problem
track-specific
tests
canonical
tests
other
exercises
test
comment
track-specific
test
canonical
same
assertNotEqual
node.children
clearer
useful
lines
comments
step
easier
something
breaks
future
line
comment
PR
issue
Reference
issue
number
expected
assert_frame_equal
move
issue
number
comment
title
issue
number
aliases
Array
comment
issue
number
comment
doesnt
array
classes
much
arithmetic
tests
issue
number
comment
positional
setter
Ah
obvious
compat.PY36
greater
any_int_dtype
fixture
Can
something
True
empty
result
issue
number
changed
tests
Can
original
issue
number
comment
first
line
GH16394
xfail
regression
*
try/except
comment
original
issue
something
https
//github.com/pandas-dev/pandas/issues/32493
FIXME
comment
expected
Series
constructor
tm.assert_series_equal
result
=
=
tm.assert_frame_equal
result
GitHub
issue
number
comment
tests
example
useful
changes
cause
test
discussion
context
test
many
things
Exception
noqa
E722
warning
makeTimeDataFrame
comment
=
comment
issue
number
internal
methods
user
comment
Can
comment
index
df
issue
number
comment
comment
actual
explanation
link
github
issue
number
comment
comment
logic
branching
issue
number
previous
comment
ImportError
msg
+
missing_dependencies
issue
number
comment
issue
comment
bit
redundant
line
tm.assert_sp_array_equal
len
comment
GH
issue
number
new
sequence
elements
middle
separator
confusing
issues
number
comment
issue
number
ValueError
inf
MySQL
err
strings
comment
reply
work
green
issue
number
imports
top
parametrize
x.Date
=
x
[
'Date
]
Can
comment
link
github
issue
comment
little
bit
e.g
change
change
PR
statement
result
stil
work
triple-quotes
newlines
memory
test
sample_time
test
times
%
difference
peak
memory
usage
comment
comment
GH
reference
relevant
discussion
assert_raises_regex
e.g
error
gh
issue
number
comment
GH
number
comment
possible
more
error
message
AFAICT
modified
test
changes
error
message
GH
issue
number
comment
minor
nit
let
=
data.apply
dict
previous
line
result
latter
consistent
most
other
tests
issue
number
comment
Can
test
value
default
issue
number
comment
issue
number
comment
comment
_holder
comments
tz_naive_fixture
https
//github.com/pandas-dev/pandas/blob/26b3e7de56fdebaf1842b01d747a1a30a126c54a/pandas/conftest.py
L290
preference
assert
cast
@
jbrockmendel
suggestion
assert
table
None
mypy
@
simonjayhawkins
mypy
error
pandas/core/arrays/boolean.py:62
error
Signature
type
incompatible
supertype
BaseMaskedDtype
[
]
base
class
version
*
uses
return
type
class
attribute
type
Type
property
warning
superclass
NumericArray
Integer
/
comment
way
same
branch
ExtensionArray
check
nice
generic
possible
Reference
issue
number
same
comments
*
*
np.nan
same
pow
continue
elif
gh
issue
number
comment
issue
reference
issue
open
pr
number
comment
Reference
issue
number
comment
same
comments
issue
number
comment
regex
_msg_validate_usecols_names
.format
issue
number
common.py
tables.parameters
*
files
pytest.importorskip
Reference
issue
comment
TODO
Any
tuple
dynamic
typing
further
refinement
df
same
time
need
place
body
Same
comments
other
test
able
match
argument
pytest.raises
BaseMethodsTests
test_equals
theory
none
other
methods
other
tests
bit
onerous
fine
custom
test
suggestion
https
//github.com/pandas-dev/pandas/issues/34660
assert
pd.Series
data
.equals
pd.Series
data
hmm
npfuncs
i
test_datetimes
array
np.nan
issue
number
issue
number
Can
issue
number
comment
readable
result
assert
result
=
data.groupby
key
]
data
]
.nunique
]
assert
result
==
None
different
meanings
None
prints
columns
whereas
prints
fit
terminal
width
quick
test
shows
None
limit
i.e
columns
hmm
None
auto-detect
same
hmm
NOT
same
None
odd
example
Well
value
None
pandas
i.e
import
pandas
pd
pd.options.display.max_columns
=
None
results
columns
ellipsis
skipped
columns
output
value
config_init.py
clue
clue
enough
comment
Let
try-except
Python
comment
importlib
Python
issue
number
comment
OP
issue
=
=
tm.assert_frame_equal
result
issue
number
comment
issue
number
Reference
issue
number
comment
functional
definition
Applies
newly-added
tests
specific
Reference
issue
number
line
e.g
gh-7757
isort
skip
Can
match
kwarg
error
message
GH
issue
comment
straight
move
issue
number
comment
GH
comment
issue
number
comment
issue
number
comment
issue
number
Can
assert_frame_equal
issue
number
issue
PR
number
comment
issue
number
comment
Reference
issue
number
line
Can
tm.assert_series_equal
result
issue
number
issue
number
comment
comment
==
user
facing
impact
Grouper
public
object
try/except
1-line
comment
issue
number
comment
Reference
issue
number
pls
1-line
comment
best
bool
discussion
use
bool
type
annotations
truthy
value
other
times
x
False
True
header
parameter
docstring
ExcelFormatter
header
boolean
list
string
default
True
Write
column
names
list
string
aliases
column
tuple
list
np.ndarray
ABCIndex
current
accepted
types
master
current
mypy
issue
header
Union
[
Sequence
[
Label
]
bool
]
is_list_like
str
Sequence
comment
dict_keys
abc.Set
github
issue
number
comment
issue
number
comment
raise
line
/
issue
number
comment
use
d
=
self.create_index
case
comment
line
issue
number
comment
.....
case
indexer
comment
issue
number
same
Reference
issue
line
comment
f-strings
correct_title
=
re.sub
rf
word
\b
CAP_EXCEPTIONS_DICT
[
word.lower
]
correct_title
issue
number
issue
number
comment
1-line
comment
one
obvious
others
GitHub
issue
number
comment
conditions
main
if/else
IOW
is_list_like
arg
getattr
arg
'ndim
arg
=
arg.item
unchanged
elif
is_list_like
arg
getattr
arg
'ndim
return
Useful
tests/resample/test_base.py
:test_resample_loffset_arg_type
code
questionable
loffset
bug
comment
suggestion
https
//github.com/pandas-dev/pandas/issues/27388
msg
object
attribute
issue
number
comment
right
wrong
issue
dtype
let
comment
default
_ndarray_values
codes
Categorical
defines
itemsize
categories
consistent
case
good
avoids
*
args
*
*
passing
hmm
only
thing
self._assert_series_equal
tiny
bit
rest
codebase
tm.assert_series_equal
tm.assert_sp_series_equal
ideas
better
/
consistent
way
good
comment
effect
sub-classes
comment
issue
number
case
cases
gh
issue
number
comment
possible
all_arithmetic_operators
similar
test
Grouper
test_groupby
issue
number
issue
number
comment
data2
constructor
issue
reference
same
same
comment
issue
numbers
comments
releveant
issues
comments
e.g
issues
issue
number
comment
make
idxpos
Reference
issue
number
line
comment
github
issue
number
GH
new
option
TODO
next
pass
]
test
body
=
Series
[
]
dtype='period
[
D
]
result
=
Series
[
]
dtype='datetime64
[
]
.dt.to_period
'D
issue
number
comment
Hmm
message
own
loop
Could
variables
result
comparison
tm.assert_index_equal
result
reference
GitHub
issue
comment
equivalent
df
=
pd.DataFrame
columns=
[
'foo
]
dtype=int
common
resource
multiple
places
dot_types
.dot
something
Great
description
comment
block
more
aligned
tests
issue
number
top
bottom
OP
e.g
idx
=
period_range
result
=
idx
==
result.all
above
check
Could
expected
result
use
tm.assert_numpy_array_equal
result
=
idx
==
idx.values
=
np.array
tm.assert_numpy_array_equal
result
comment
github
issue
number
GH
Minor
nit
pseudo-standard
tm.assert_index_equal
result
nice
variable
result
line
comparison
last
line
self.obj
==
value
missing-argument
case
i
comment
obsolete
comment
special
case
comment
issue
number
comment
Can
issue
number
comment
new
error
message
Reference
issue
number
comment
issue
number
issue
number
comment
comment
github
issue
number
GH
commit
number
PR
number
comment
able
issue
number
comment
comment
PR
things
iloc
vs
loc
Is
test
keyword
call
OK
expected
frame
assert_frame_equal
issue
number
Same
comment
above
thanks
result
particular
reason
youre
filterwarnings
dtype
argument
test
extract_array
Index
@
jbrockmendel
correct
values
Series
use
extract_array
https
//github.com/pandas-dev/pandas/blob/a1f605697e44e7668b64841baf4ab2988470d08c/pandas/core/generic.py
L3273-L3278
sure
case
_maybe_cache_changed
value
something
Series
DataFrame
iset
other
places
same
issue
Could
comment
issue
number
GH
test
name
bit
descriptive
test_describe_timezone_dtype
test_describe_with_tz
ref
GH
number
comment
Just
first
argument
second
tm.assert_series_equal
result
standard
tests
comment
issue
assertion
e.g
~~~
~~~
OR
~~~
gh-16909
~~~
issue
number
PR
number
comment
issue
number
issue
number
issue
number
comment
issue
number
comment
Move
import
file
test
reference
issue
number
comment
test
function
def
Good
suggestion
reference
https
//python-rq.org/docs/results/
q.enqueue
foo
result_ttl=-1
result
jobs
'build_n_run_queue
queue
tasks
same
time
n
important
free
sense
comment
please
distinct
sure
cloud
comment
assert
comment
Last
halyard
version
write_component_version
w/o
line
conflicting
change
shot
Seems
problems
Halyard
https
//github.com/lwander/spinnaker/blob/3dc2be0723766d69ce69a59820cc8009ad766d8a/dev/build_prevalidation.py
L91.
[
Codacy
]
https
//app.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//app.codacy.com/app/frank_10/quality-report/pullRequest
prid=1783266
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//www.codacy.com/app/frank_10/quality-report/pullRequest
prid=1025662
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
method
]
https
//www.codacy.com/app/frank_10/quality-report/pullRequest
prid=1025662
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
class
]
https
//www.codacy.com/app/frank_10/quality-report/pullRequest
prid=1025662
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
class
]
https
//www.codacy.com/app/frank_10/quality-report/pullRequest
prid=1025662
[
Codacy
]
https
//www.codacy.com/assets/images/favicon.png
Issue
[
class
]
https
//www.codacy.com/app/frank_10/quality-report/pullRequest
prid=1025662
Sure
Done
PTAL
couple
nits
short
comment
make
_sparse_to_dense_grads
>
sparse_to_dense_grads
module
space
grads
lint
comment
Comment
DTYPE_MAP
[
flags.dtype
]
KeyError
Fewer
lines
isinstance
check
unit
Please
comment
someone
next
time
timeout
Wait
integration
test
MAC
address
OVS
interface
comment
Please
comment
let
phase
GanState
typical
DLState
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
D103
public
function
*
*
[
pep8
]
*
*
<
sub
>
[
reviewdog
]
https
//github.com/reviewdog/reviewdog
dog
<
/sub
>
D103
public
function
len
assert
raw_trajectory
latter
Generic
extractor
big
tests
URLs
extractor
Tests
generic
embeds
generic
extractor
PS
C
\Dev\youtube-dl\master
>
py
-3.5
.\test\test_all_urls.py
F
.............
======================================================================
FAIL
test_no_duplicates
Traceback
recent
call
last
File
.\test\test_all_urls.py
line
test_no_duplicates
ie.suitable
url
%
s
URL
%
r
%
type
ie
.__name__
url
AssertionError
False
true
PikselIE
URL
//www.uscourts.gov/cameras-courts/state-washington-vs-donald-j-trump-et-al'
tests
FAILED
failures=1
better
test
generic
extractor
test
URL
generic
extractor
[
https
//player.piksel.com/v/v80kqp41
]
https
//player.piksel.com/v/v80kqp41
Add
comment
test
NOQA
comment
other
long
lines
module
code
cut-and-paste
logic
identical
different
methods
kind
tricky
Chances
high
problem
failure
cache
invalidation
containers
new
container
per-instance
container
instances
issue
new
theme
values
old
theme
_property_values
application
code
right
loop
right
new
__themed_values__
cache
_property_values
something
Delete
cached
values
old
theme
k
old_dict.keys
v
=
old_values.get
k
None
sure
k
self._property_values
check
v
None
isinstance
v
PropertyValueContainer
v._unmodified_default_value
k
self._property_values
del
self._property_values
]
trigger_if_changed
trigger_if_changed
code
_new_
theme
new
value
_property_values
registration
codepath
way
more
root
cause
fix
condition
bit
circumspect
bit
comment
field
glyph
methods
sure
comment
current
code
exact
equivalent
defaults
defaults.copy
defaults.setdefault
'text_color
'black
trait_defaults
trait_defaults.copy
trait_defaults.setdefault
'color
get_default_color
trait_defaults.setdefault
feeling
new
dictionaries
defaults
state
contents
constructor
happy
setdefault
version
come
Add
example
please
comment
sleep
required
Comment
good
mixture
goods
values
values
i.e
software
physical
else
return
None
bit
request
none
>
TODO
different
error
[
]
length
=
worth
guidelines
least
Typescript
guidance
errors
configuration
issues
python
guidelines
something
similar
please
item
backlog
TODO
code
comment
TODO
SetAuthProviderOperation
operation
SAS
token
auth
SetX509AuthProviderOperation
operation
certs
auth
Let
import
HerokuWorker
reference
BaseWorker
import
section
worth
comment
similar
commit
comment
way
search
NaN
entire
out_pixel
array
i.e
loop
i
test
loop
iteration
check
loop
create
problems
calculations
remainder
loop
big
performance
comment
user
hint
param
wording
control
flag
something
Subtract
master
background
C'est
pour
vérifier
s'il
s'agit
d'une
édition
d'un
nouveau
commentaire
Dans
le
premier
cas
n'ajoute
pas
le
choix
casquette
ah
bien
vu
tu
peux
ajouter
un
commentaire
pour
dire
ça
stp
pourquoi
reaction
Je
pas
bien
l
’
intérêt
du
ici
comment
jupyterlab
non-standard
mime
type
block
JS
body
message
handler
callback
comment
A
short
comment
explain
helpful
OAuth2Authentication
OAuth2AuthenticationAllowInactiveUser
comment
add
comment
job
search
filter
type
data
jobs
setup
Please
same
test_job_list_view_filters_job_query
condition
thing
Integer
count
b
boolean
value
i.e
False
c
comment
fix
options
specific
widget
Sure
build
orange
coverage
Si
tu
veux
rendre
la
regex
jolie
tu
peux
mettre
à
la
fin
sans
besoin
d'un
c'est
odo
qui
dit
genre
[
a-zA-Z0-9_.-
]
je
viens
tester
et
Sinon
c'est
nickel
merci
beaucoup
docstring
wrong
comments
negative
condition
bit
obscure
code
Basically
sequence
glyphs
by/from
time
end
parse_substitute_
method
something
wrong
sub
rule
unknown
invalid
contextual
substitution
apostrophe
frequent
comment
little
less
space
usage
session.send_request
Request
self.method
params
self.view
lambda
response
sublime.set_timeout
lambda
self.handle_response
response
easier
suggestion
functools
partial
suggestion
def
invoke
p
Dict
[
str
Any
]
>
None
callback_object
=
self._callback_object
callback_object
callback_object.on_payload
p
sublime.set_timeout_async
partial
invoke
payload
%
sure
function
expensive
PR
AC
LSP-elm
>
line
finish
AC
end
items
=
list
self.format_completion
reason
combination
normalized_documentation
transform_region
items
[
output
]
https
//user-images.githubusercontent.com/22029477/80403905-add90200-88c0-11ea-88bf-13b30842c21e.gif
lines
conditional
statement
shutil.which
'restorecon
failure
os.path.basename
more
methinks
let
use
==
startswith
comment
OpenBSD
%
r
__
[
Flake8
]
__
comment
<
Comment
[
SideCI
]
https
//sideci.com
>
comment
IDE-specific
comments
only
change
comment
good
dependent
user
support
user
TODO
code
minimum
version
postgres
upserts
rid
new_entry
usage
new_entry
True
....
elif
new_entry
False
....
RuntimeError
upsert
None
'can_native_upsert
False
paranoia
check
Use
self.parse_duration
config
valid
least
email
slow
times
docstring
remote
users
new
table
docstring
comment
particular
version
others
others
Actually
issue
[
image
]
https
//user-images.githubusercontent.com/1342360/84499789-2c400680-acab-11ea-905b-2fe8d10a2191.png
use
setUp
MediaRepoTests
https
//github.com/wolever/parameterized/blob/ff5a1dac3a704777100380229dce4ea149da8d41/CHANGELOG.txt
L22
comment
please
quick
comment
necessary
comment
helpful
comment
sure
>
stream
positions
something
additional
streams
right
fix
comment
SQL
fine
MAX
great
GROUP
BY
clause
general
multiple
user
agents
device
record
ideal
world
record
UA
useragent
column
array
sqlite
processing
harder
record
UA
complicated
SQL
recent
easy
postgres
sqlite
sound
faff
much
MAX
u.user_agent
Note
query
fine
SQLite
columns
GROUP
BY
clause
entry
random
row
comment
single
warning
comment
data
lengths
IMO
SOURCE_DATE_EPOCH
bug
good
environment
variables
purposes
good
tidbit
comment
Same
thing
previous
comment
opsdroid
arg
👍
comment
multiple
lines
suggestion
Test
original
object
new
attribute
Same
fake_script
'relation-list
=
]
[
remoteapp1/0
remoteapp1/1
]
||
exit
bit
extensive
example
fake_script
'relation-ids
=
db1
]
echo
[
db1:4
]
||
echo
[
]
user_id_to_anonymous_id
function
simpler
version
suggestion
user_ids
[
cls.submitting_user_id
team_member_1_id
team_member_2_id
]
cls.team_member_ids
=
[
user_id
user_id
user_ids
]
quick
comment
date
number
class
list
dupes
common
filters/actions
sigh
good
way
line
dependency
botocore
other
providers
single
underscore
private
double
causes
references
class
value
imo
schema
validation
version
spec
such
warnings
Nit
fix
indentation
suggestion
TODO
[
gh-1829
]
investigate
os.add_dll_directory
work
Python
os.environ.setdefault
Riviera
test
Questa
FLI
particular
behavior
scheduler
comment
reality
brief
comment
nice
change
pretty
weird
suggestion
package_files
'cocotb/share/makefiles
+
package_files
'cocotb/share/include
+
package_files
'cocotb/share/def
list
concatenation
comment
naming
files
confusing
nr.dmnd.md5
function
though
file
True
md5
comparison
marker
least
md5
file
other
comment
comment
parent
taxdump
file
OK
untarred
component
files
thinking
high
level
scratch
mongodb
problem
fact
action
changes
different
models
behavior
models
classic
use
case
controller
good
example
awkwardness
model
behavior
model
models
simple
controller
function
Errata
package
lists
sync
upload
code
unit
key
metadata
repo_id
sooner
other
examples
controllers
plugins
Deletion
case
Errata
model
auto-delete
package
list
entries
reasonable
similar
automatic
cascade
delete
only
cross-model
implicit
coupling
data
model
foreign
key
relationship
Nobody
sleep
mhrivnak
tl
dr
db
way
repo_id
merge
pkglist
pkglist
multiple
collections
erratum
repo_id
collection
erratum
multiple
pkglists
multiple
collections
field
ErratumPkglist
model
pkglist
collection
change
repo_id
erratum
merge
pkglists
pre_save_signal
]
https
//github.com/pulp/pulp_rpm/pull/1049/files
diff-df55e4e5c922fdb2a0fefedecd7013c5R1151
mongoengine
version
arguments
signals
e.g
model.save
*
*
kwargs
overkill
other
ideas
sense
errata
model
collection
Errata
general
errata
whole
repo
sense
reponame
solutions
bit
suggestion
Pkglist
multiple
collections
case
pkglist
looks
pkglist
[
name
reponame
packages
[
name
reponame
packages
[
Reponame
same
collection
redundant
way
reponame
collection
import
erratum
unit
structure
pkglist
db
redundant
reponame
db
collection
place
Errata
option
pkglist
memory
something
pkglist
reponame
'collections
[
packages
[
packages
[
Errata
model
best
evils
Please
kind
fixme
todo
comment
separate
link
patternfly
Breadcrumb
widget
Text
widget
afterwards
simpler
way
commands
access
bodhi
cli.commands
[
'releases
]
something
less
code
main
Print
deprecation
warning
bodhi
command
click.echo
utility
Please
use
'bodhi
releases
[
'releases
]
purpose
statement
empty
TBD
comment
consistent
name
list
determiner
please
comment
import
fallback
parent_cluster
put
else
comment
K8s
node
K8S
kind
defeats
point
abstraction
downstream
clients
dict
same
circumstances
suggestion
Ayukha
Can
reason
change
comment
line
TODO
URL
django
backend
evalapi.cloudcv.org
things
value
bytes
GB
MB
easier
most
docker
give
result
bytes
able
extra
conversion
default
value
high
GB
sounds
comment
logic
comments
fields
comment
line
check
check
checks
field
empty
endpoint
Maintainers
hacky
way
todo
one
time
hence
Please
comment
hardcoded
value
comment
same
comment
easier
someone
code
first
time
line
Geofence
_generate_locations
bug
old
version
simplified
version
reason
comments
before
pics
[
image
]
https
//cloud.githubusercontent.com/assets/24545326/23793939/99a6d986-0585-11e7-99e8-ba29927919e9.png
original
way
complicated
steps
order
worker
hex
speedscan
comment
value
undefined
reason
select_vhost
function
same
behavior
original
implementation
James
original
commit
place
help
selection
select_vhost
Nice
catch
authenticator
type
result
change
suggestion
import
Union
Iterable
Optional
smallest
final
thing
linter
unhappy
own
line
part
function
comment
comment
use
certonly
Same
comment
update_registration
comment
arguments
values
third
party
library
like
[
tabulate
]
https
//pypi.org/project/tabulate/
dev_constraints.txt
tools/pip_install.py
script
setup
tox
use
[
positional
arguments
https
//tox.readthedocs.io/en/latest/example/general.html
interactively-passing-positional-arguments
script
package
latter
feels
overkill
things
bit
flexible
use
[
format
options
https
//docs.python.org/3.8/library/string.html
formatspec
[
f-strings
]
https
//www.python.org/dev/peps/pep-0498/
variables
cell
width
dynamic
library
though
https
//github.com/certbot/certbot/pull/5608
discussion_r171141004
Can
description
True
server-side
database
cursors
invalid
cursor
errors
pgbouncer
function
filter_products
reason
CourseRuns
False
Programs
intuitive
detail
comment
sys.argv
[
]
comment
Please
meaning
positive
argument
suggestion
time
step
optional
suggestion
Delete
last
better
await
ed
higher
e.g
manager
suggestion
TODO
move
tests
=
math.ceil
abs
segment
data_start_time
/
seasonality
suggestion
TODO
use
ModelState
window_size
=
cache
[
'windowSize
]
suggestion
TODO
convenient
way
labeled
segments
POSITIVE_SEGMENTS
=
[
neat
files
way
repetition
grades/api.py
less
necessary
FA/non-FA
runs
test
case
couple
values
@
ddt.data
None
'foo
def
test_compute_grade_odd_current_grade
_compute_grade_for_non_fa
function
case
grade
edX
number
course_run
[
self.run_no_fa
self.run_fa
]
course_key1
=
course_run.edx_course_key
current_grade1
=
[
course_key1
]
current_grade1.data
[
'percent
]
=
odd_value
current_grade1.save
=
CachedEdxUserData
self.user
run_data1
=
user_edx_data1.get_run_data
course_key1
compute_grade_func
=
api._get_compute_func
course_run
grade1
=
compute_grade_func
run_data1
assert
similar
test
case
runs
certificates
self.run_no_fa_with_cert
method
suggestion
https
//github.com/pydata/xarray/pull/4292/files
details
label_value
=
label
[
label.dtype.kind
mM
label.item
fine
comment
encoding
netCDF4-python
dataset
rank
method
DataArray
/
Dataset
consistency
nice
untested
argument
order
little
puzzles
suggestion
dimensions
dim
ds.dims
suggestion
coord
names
k
self._variables
comment
original
issue
future
change
dims
==
fine
Style
comment
double
nested
list
comprehension
tough
lot
easier
Python
atop_args
=
[
]
arg
dims
zip
args
input_dims
s
=
-getattr
arg
dims
element
arg
[
s
]
atop_args.append
element
link
StackOverflow
post
]
https
//stackoverflow.com/questions/17430105/autofmt-xdate-deletes-x-axis-labels-of-all-subplots
comment
datetime64
logic
latest
version
matplotlib
sort
built-in
support
datetime64
https
//github.com/matplotlib/matplotlib/pull/9779
Are
array.shape
array.dtype
objects
dataset
data
disk
array
values
__getitem__
python
class
BaseNetCDF4Array
NdimSizeLenMixin
def
__init__
variable_name
datastore
self.datastore
=
datastore
self.variable_name
=
variable_name
file
open
variable
metadata
array
=
self.get_array
autoclose=False
self.dtype
=
array.dtype
self.shape
=
array.shape
def
get_array
self.datastore.ensure_open
autoclose=autoclose
return
self.datastore.ds.variables
self.variable_name
]
def
__getitem__
key
array
=
self.get_array
autoclose=True
array
[
key
]
def
__array__
dtype=None
return
np.asarray
]
dtype=dtype
comment
regression
test
suggestion
pragma
cover
clause
coverage
calculations
Typo
Tets
Rename
OAuth2AllowInActiveUsersTests
comment
Could
group
__future__
imports
isort
trick
Same
previous
comment
default
comment
misunderstanding
future
Do
translators
diff
Please
doc
comments
isort
comment
line
Could
group
__future__
imports
single
line
migration
files
isort
care
calls
comment
effect
iloveagent57
calls
comment
L619
comment
irrelevant
single
line
comment
suggestion
Get
ID
block
user
last
specified
course
corresponding
unit
test
change
token_type
test
https
//github.com/edx/edx-platform/blob/a4f03620a41b4d8b6a0de1f3bc5581e505230b17/openedx/core/djangoapps/oauth_dispatch/tests/test_views.py
L220
See
following
article
HTTP
header
Django
test
client
https
//stackoverflow.com/questions/31902901/django-test-client-method-override-header
Personally
..
/tests
list
past
list
modules
anything
usable
easier
docs
file
use-case
Thoughts
Please
comment
string
invalid
method
package
name
version
case
proper
parameters
name
docstring
Please
expand
parameter
explanation
data
present
computeresource.py
please
Requirement
Computeresource
top
file
Same
comment
validate_repo_content
product
name
repo
entity
confusing
mismatch
case
method
docstring
i
helper
names
search
repo
name
+
product
name
bit
debatable
product
name
repo
name
unique
same
org
issues
unlikely
Update
helper
product
entity
repo
entity
worst
case
Update
helper
args
repo
least
intuitive
@
rochacbruno
yeah
BZ
CLOSED
WONTFIX
resolution
PM
plan
wait_for_publish
@
latran
Just
more
algorithm
problem
same
output
difference
performance
difference
UI
System
Level
weird
stuff
multiple
outputs
output
different
loss
function
im
strange
concat
short
comment
helpful
suggestion
time-sequence
dimension
last
LSTM
layers
Permute
ok
brief
easier
code
isolation
suggestion
random_features=False
option
random
features
i.e
np.ones
np.random.random
next
line
anything
features
little
bit
pest
list
definitions
comment
subtle
CMS
workers
same
LMS
LMS
Maybe
cleaner
Django
template
engine
free
comment
@
swalladge
native
English
speaker
provision
emails
provision
emails
provisioning_failed_emails
something
provisioning_failure_notifcation_emails
suggestion
more
explanation
class
docstring
workaround
comment
good
persistent
code
Several
attributes
methods
old
QNode
new
location
new
QNode/tape
tests
tape
non-tape
mode
running
list
changes
tests
tape
mode
default
better
benchmarks
suggestions
alternative
me_tables
me_tables
something
elems
docstring
return
type
none
__repr__
observable
sure
cores
return
type
process
suggestion
Todo
tape
return
type
MeasurementProcess
self.obs.return_type
None
QNode
scalar
default
Might
good
comment
test
suggestion
this_dir
=
this_dir.replace
\\
/
windows
comment
code
look
alert
group=posterior
divergent_group
sample_stats
elif
group=prior
divergent_group
sample_stats_prior
divergences
False
Get
draws
combine
chains
divergences
hasattr
data
divergent_group
hasattr
getattr
data
divergent_group
divergent_group
warning
informative
comma
error
Same
comment
specific
ValueError
good
error
text
intended
ValueError
Docstrings
tests
nice
simple
method
name
example
glance
bad
group
group
Does
bad
group
group
string
comment
magic
number
import
top
happy
global
logging_initialized
=
True
global
comment
closer
line
idea
del
args
context
comment
line
value
minor
file
extract
initial
doc
data
format
memory
Gb
format
daemons
Minor
”
....
”
W605
todo
'ec2_key_name
format
same
information
param
e.g
request
side
>
=
two_years_and_six_months_ago
comment
pushdata
bug
data
bugs
commits
dates
bug_retriever
sync
days
best
way
beginning
loop
Python
commit
commits
commit.ever_backedout
continue
https
//github.com/mozilla/bugbug/pull/188
discussion_r258457469
comment
commits
days
kind
way
assertion
https
//github.com/mozilla/bugbug/pull/1040/files
r339354740
other
matches
exception
line
same
branches
branches
if-else
Nit
variable
name
function
_transform
rename
p
link
source
code
function
users
unused
arguments
ideal
kwargs
warnining
'params
Add
OMP
environment
comment
👍
lt
operator
function
output
suggestion
conans.client.tools.scm
import
*
pylint
disable=unused-import
conans.client.tools.settings
import
pylint
disable=unused-import
comment
issue
comment
FIXME
Conan
old
path
comment
docs
download-cache
checksum
useless
cd
hello
comment
date
issue
code
mode
semver
config
level
dict
.get
bit
explicit
mapping
looks
kind
magic
number
comment
link
WindowsError
[
Error
]
clearer
full
error
message
message
assertive
Windows
error
WindowsError
[
Error
filename
extension
long
user
doubts
error
long
paths
*
short_paths
solution
empty
print
function
new
line
i
Locations
way
text
empty
print
calls
Same
comment
regd
Interactions
indentation
help
documentation
cleaner
readable
textwrap.indent
r
\t
new
definitions
response
[
comment
]
https
//github.com/enthought/traitsui/issues/1316
issuecomment-704903499
stretch
goal
values
constants.py
Pyface
class
few
places
current
move
screen
width/height
dimensions
import
time
Corran
screen
dimensions
https
//github.com/enthought/traitsui/blob/32458481d7a38f3d4811020fcf1837ea1b8088c2/traitsui/wx/helper.py
L231
Such
move
likely
behavioural
change
screen
size
code
e.g
import
traitsui.api
move
code
screen
size
widget
good
correct
thing
thoughts
evaluations
@
corranwebster
Did
comment
getter
property
Just
access
.screen_width
suggestion
screen_dx
=
SystemMetrics
function
def
stdout_text
type
self.stdout
string_types
return
self.stdout
hasattr
self.stdout
'decode
return
self.stdout.decode
raise
TypeError
Unable
stdout
string-like
type
conf_file
/etc/sysconfig/network-scripts/ifcfg-
%
s
%
interface
issue
number
comment
Just
interest
part
docstring
wrong
headers
HTTP
headers
line
quick
line
break
additional
comment
if-else
block
great
docstring
test
bit
specific
easier
test_colormap_palette_mpl
same
docstring
Assert
colors
mpl
colormap
docstring
test
bit
specific
easier
test_colormap_palette_yb
same
docstring
Assert
colors
yellowbrick
colormap
request
curious
memodict
no-multiple
objects
default
arguments
concern
https
//docs.quantifiedcode.com/python-anti-patterns/correctness/mutable_default_value_as_argument.html
suggestion
clip.metadata.get
'cmx_3600
None
closer
setdefault
initial
value
line
line
unnecessary
underscores
arguments
function
signature
comment
logic
use
concept
next
task
signature
error
callback
need
comment
unit
test
Do
idea
potential
state
code
I.e
enum
module
level
import
top
file
TODO
items
Please
TODO
items
\n
line
change
end
line
function
definition
next
line
comparison
line
Right
nice
catch
need
WHERE
clause
way
sql
generic
statement
violation
type
work
please
TODO
worth
violation
tuples
Feel
free
TODO
central
type
violation
definitions
useful
nit
string
substitution
consistent
%
s
%
s
%
member.type
member.name
possible
fix
things
PR
in-scope
TODO
sense
lines
86-91
value
None
return
int
value
try/except
case
int
conversion
Thoughts
comment
error
message
boolean
result
comment
latest_version
super
nice
something
Checks
information
cache
date.
Black
changes
suggestion
path
=
template._apply_fields
cur_fields
continuation
line
under-indented
visual
indent
Just
heads
isort
imports
noqa
F401
instance
comment
block
comment
please
order
import
https
//developers.home-assistant.io/docs/en/development_guidelines.html
ordering-of-imports
self._color
none
init
local
variable
'entity
Add
as_dict
Add
comment
suggestion
discover
gather
HTTPAdapter
pools
d_id
new_devices
platform
reason
decorator
domain
keyword
argument
block
comment
least
spaces
inline
comment
<
br
>
inline
comment
redefinition
unused
line
constant
constant
name
something
specific
ISY
ISY_MEDIUM_SPEED
comment
<
br
>
line
characters
br
>
whitespace
block
comment
'lmnotify.LaMetricManager
unused
entity
class
Move
adjustment
assignment
level
level
=
position
block
comment
block
comment
check
Use
comments
first
line
module/class/method
doc
string
general
Exception
important
error
issue
aboit
invalid
codepage
TypeError
errors
case
least
users
type
things
default
sensors
single
entry
blueprint
config_flow.py
doesn
’
t
match
developer
documents
sure
s
intentional
something
unused
block
comment
known
bug
pylint
suggestion
.const
import
DOMAIN
pylint
disable=unused-import
repr
wanted
%
r
format
string
afaik
Use
Python
code
comment
blank
line
end
file
line
characters
comment
line
characters
continuation
line
indentation
Same
Could
single-line
comment
necessity
getattr
regular
attribute
access
okay
tasks
same
time
comment
lat/Long
optional
hass.config
Stale
docstring
state
Please
comment
line
characters
least
spaces
inline
comment
<
br
>
inline
comment
either
setup
sync
async
setup
platform
method
items
optional
least
something
item
unused
Register
HTTP
view
QR
code
fly
way
file
current
state
undeleted
URL
timeout
use
url
variable
least
spaces
inline
comment
<
br
>
inline
comment
pylint
disable=import-error
mark
context
function
context
wrapper
Could
comment
list
Stale
comment
blank
line
Add
comment
backwards
compat
developers
reason
PR
right
def
start_response_exception
status
headers
e
=
Exception
exception
e
test
sc
=
int
s.get_tag
http.status_code
eq_
sc
non
digit
string
range
[
line
]
https
//github.com/DataDog/dd-trace-py/blob/master/ddtrace/contrib/pylons/middleware.py
L44
taht
e.code
int
e.code
=
int
comment
function
span.resource
mongodb.query
tag
Similar
[
comment
ASGI
integration
]
https
//github.com/DataDog/dd-trace-py/pull/1567
discussion_r458333341
bit
concerned
context
propagation
Python
case
kwargs
Python
lets
handle_request
val1
val2
val3
args
val1
val2
val3
kwargs
handle_request
request=val1
write_callback=val2
stream_callback=val3
args
kwargs
'request
val1
val2
val3
O_o
Please
docstring
unresponsive
sleep
better
snappy
response
input
kinds
chat
services
Could
constant
comment
comment
call
necessary
care
parent
class
explain
comment
one
comment
choice
]
[
:1
]
user
able
icons
arguments
fine
defaults
alt
[
facebook
parrot
emoji
]
https
//emojipedia.org/facebook/4.0/parrot/
default
D
end
None
exists
split
criticial_processes_list
branch
assert
more
insight
part
Message
assert
line
condition
Please
reword
message
failure
Remove
blank
line
EOF
hard
statement
complicated
distribution
scope
suggestion
distribution_scopes
DEV
STAGE
PROD
]
Make
request
distribution
scope
distribution_scopes.index
distribution_scope
<
distribution_scopes.index
resolved_distrbution_scope
floor_divide
self.count
reminder
self.count
numpy
<
requirement
Centos/RHEL
RDO
numpy
queens
Pas
tellement
Sécurité
inutile
C'est
possible
que
ça
soit
Done
comment
purpose
specific
salt
comment
purpose
value
strange
little
comment
redundant
choices
comment
w
comment
comment
Could
comment
only
detail
models
suggestion
Dict
[
str
Dict
[
str
Any
]
]
Options
dense
subgraph
identification
heuristics
PR
wrapper
function
future
consideration
complexity
users
wrapped
callables
stop
Code
Details
sidebar
TOC
something
process
SF
documentation
suggestion
^^^^^^^^^^^^
comparison
easier
mind
future
PRs
@
ixfoduap
point
nice
short
code
function
docstring
something
Strawberry
Fields
PennyLane
Minor
comment
function
docstrings
readable
less
technical
users
type-hint
notation
something
plain
simple
Converts
undirected
NetworkX
graph
real
symmetric
NumPy
adjacency
matrix
NetworkX
graph
object
input
return
types
Args
Returns
section
🤔
quite
wary
target
name
target
name
changes
future
way
device
API
target
arbitrary
number
modes
range
modes
logic
account
E.g.
modes_total
device.modes
something
PR
Walrus
impact
TODO
comment
todo
dim
confusing
name
param_shape
I.e
param_shape
default
exception
singe
line
comment
appropriate
except/pass
combo
Could
logic
comments
please
TODO
issue
number
GitHub
TODO
TODO
i
change
info
[
]
=
False
=
True
environment
horizon
limit
=
True
i.e
=
]
i
configuration
current
implementation
gym
info
[
]
=
True
horizon
limit
valid
https
//github.com/openai/gym/releases/tag/0.12.4
noqa
document
shape
constraints
parameter
documentation
torch
documentation
examples
same
comment
default
args
@
formatting
PR
pytorch
documentations
torch.nn
import
functional
F
pylint
disable=import-error
work
i
comment
flaw
next
person
magic
import
abstract
implementers
ints
function
only
ints
None
documentation
easier
interface
clearer
file
pylint
disable=redefined-outer-name
suggested
approach
other
tests
fixtures
conftest.py
problem
suggestion
pylint
disable=pointless-statement
best
todo
directive
searchable
todo
check
specific
instance
id
time
pass
columns
different
comment
block
something
Load
submodules
other
libraries
Featuretools
namespace
comment
block
something
Load
primitives
other
libraries
Featuretools
namespace
hasattr
comment
block
something
Call
functions
other
libraries
DFS
arguments
comment
sense
Path
None
None
data
comment
EEXIST
refers
class_cache
number
primitives
small
custom
primitives
few
caching
comment
None
Unknown
variable
type
Can
import
uuid
google.cloud
import
bigquery
import
pytest
import
natality_tutorial
Same
comment
ditto
more
sense
accessapproval
first
service
returned
list
apigateway
close
bottom
more
permissions
next
page
check
race
condition
when.two
CI
builds
same
script
unique
id
comment
unique
dataset
id
existence
more
comments
fixture
Please
comment
test
body
Well
test
invocation
target
function
function
test
body
test
target
function
case
simple
ok
test
functions
suggestion
@
pytest.fixture
scope=
module
def
cleaner
datasets_to_delete
=
[
]
yield
datasets_to_delete
dataset
datasets_to_delete
client.delete_dataset
dataset
delete_contents=True
not_found_ok=True
def
test_create_dataset_and_table
capsys
cleaner
helper.create_dataset
project_id
dataset_id
dataset
cleaner.append
dataset_id
created_table
=
helper.create_table
....
expected_schema
==
created_table.schema
sure
output
change
sample
Node.js
Go
samples
empty/204
responses
msg
part
HTTP
response
Pub/Sub
change
fine
comment
Use
single
quotes
docstrings
.format
%
suggestion
cost
model
rates
valid
non-OpenShift
source
type
data.get
'markup
'rates
data
[
'source_type
]
=
suggestion
entry
table/model
point
migrations
entry
[
default_cost_type
comment
data
migration
something
migrations
super-squashed
last
time
suggestion
manifest_accessor.delete_cost_usage_reports_older_than
self._provider
expiration_date
LOG.info
CostUsageReportManifest
provider
type
%
s
period
%
s
self._provider
expiration_date
suggestion
exception
task
trigger
Celery
retry
logic
raise
TaskRunningError
msg
suggestion
exception
task
trigger
Celery
retry
logic
raise
TaskRunningError
msg
default
value
getenv
call
DEBUG
=
os.getenv
'DJANGO_DEBUG
DEBUG
=
DEBUG
==
DEBUG
True
cifar.yaml
exists
INSTEAD
dataset.yaml
things
unrelated
catch
broader
exceptions
comment
something
exceptions
unit
timeout
comment
Did
joblib
docs
float
timeout
official
SC
documentation
problems
future
side
effect
huge
number
huge
masses
tracks
error
comment
times
domain
diagonal
docstring
radius
float
radius
more
third
size
domain
MAX_DISTANCE_IN_GRID_CELLS
constant
uses
module
suggestion
import
iris
import
dask.array
da
Kedze
je
doverihodny
Tak
FIXME
attachment.content_type
whitelisted
content
types
mozeme
vyhodit
@
martinmacko47
Co
tak
keby
sme
pre
field
nastavili
default=DAYS_TO_PUBLISH_INFOREQUEST
null=False
Tym
padom
sa
nam
vyrazne
zjednodusil
kod
sure
content_types
init_app
benefits
documentation
case
isoformat
attribute
datetime
present
http
url
URLInfo
dvc.path_info
url
=
URLInfo
https
//example.org/file.txt
url
exists
suggestion
assert
tree.exists
url
True
bug
HttpError
JSON
type
error
GC
implementation
method
retry
better
_retriable_
exceptions
error
codes
locations
reasons
limits
example
Please
TODO
s
code
issue
significant
github
issue
assign
TODO
Same
method
object_storage
message
Are
workers
local_worker
Same
comment
register
class
constructors
args
methods
methods
suggestion
building
set
methods
syft
ex
load
global
package
private
constant
hours
seconds
repeated
conversion
condition
testing
suggestion
_SQS_MSG_LIFETIME_IN_SEC
=
int
os.environ.get
'24
timestamp
string
time
module
suggestion
flow_start_time
=
flow_info.get
.get
flow_start_time
time.time
flow_start_time
>
_SQS_MSG_LIFETIME_IN_SEC
exc
=
NotABugFatalTaskError
Flow
Timeout
.format
flow_info
flow_start_time
raise
self.retry
max_retries=0
exc=exc
New
flow
add
time
stamp
node_args
[
]
=
time.time
related
fix
suggestion
Disable
NewRelic
APM
function
newrelic.agent.ignore_transaction
flag=True
good
relevant
caller
function
comment
strings
keys
documentation
same
time
nice
metric
names
group
shorter
names
<
>
/
<
>
message
across
nice
graphs
New
Relic
suggestion
Annotations
Elasticsearch
MISSING
=
Synced/Missing
Annotations
different
Elasticsearch
DIFFERENT
=
Synced/Different
Annotations
jobs
FORCED
=
Synced/Forced
TOTAL_INDEXED
=
Synced/Total
Jobs
annotations
date
Elasticsearch
UP_TO_DATE
=
Completed/UpToDate
Jobs
annotations
DB
DELETED_FROM_DB
=
Completed/DeletedFromDB
TOTAL_COMPLETED
=
Completed/Total
terminology
bit
floppy
general
suggestion
csp_insecure_optout=True
view
own
custom
Content
Security
Policy
comment
route
Content
Security
Policy
sidebar
app
case
view
alternative
CSP
headers
CALLBACLBOX
GAP
comment
trie
hash
actual
key
SecureTrie
data_encoder
b
use
EMPTY_TX_ID
May
sha3
rootblock.get_hash
coinbase
sure
tx_hash
unique
comment
field
purpose
Add
comment
strings
possible
Visual
Basic
above
multiline_string_delimiters
string_delimiters
worth
..
..
https
//github.com/coala/coala/issues/5587
please
comments
old
PR
helper
function
test
debugger
instance
list
commands
run
return
text
debugger
output
end
python
output
=
self.execute_debugger
[
q
c
q
c
]
class
necessary
functions
conditions
access
obj
[
]
[
]
pragma
nt
cover
filename
windows
other
coala
code
case-insensitivity
windows
case
pragma
cover
TEST_BEARS_NAME
preferred
quotation
marks
*
QuotesBear
severity
NORMAL
section
python
issue
following
patch
diff
a/tests/results/DiffTest.py
+++
b/tests/results/DiffTest.py
@
@
-157,7
+157,7
@
@
uut
=
Diff
self.file
self.assertFalse
bool
uut
uut.rename
=
test
+
uut.rename
=
self.assertTrue
bool
uut
uut.rename
=
False
uut.delete
=
True
number
object
numpy
instance
json
serializable
ie
=
numpy.int32
json.dumps
my-number
something
numpy
conversion
isinstance
np.float
return
float
elif
isinstance
np.integer
return
int
comment
inline
example
comment
run_data
latest
metric
key
clarity
artifact_root_uri
None
root
directory
class
FileStore
AbstractStore
....
def
__init__
root_directory=None
artifact_root_uri=None
Create
new
FileStore
root
directory
default
artifact
root
URI.
super
FileStore
self
.__init__
self.root_directory
=
root_directory
_default_root_dir
self.artifact_root_uri
=
artifact_root_uri
self.root_directory
comment
case
thing
code
O
awesome
idea
pandas.read_csv
Thanks
@
Nit
space
period
next
sentence
mlflow.exceptions.MlflowException
out-of-date
database
schema
version
ff01da956556
backup
database
db
upgrade
sqlite
///mydb
database
latest
schema
NOTE
schema
migration
database
downtime
please
database
documentation
more
detail
@
andychow-db
Are
only
exception
types
json.loads
method
documentation
json.loads
refers
https
//docs.python.org/3/library/json.html
json.JSONDecodeError
subclass
TypeError
Exception
best
practice
class
exception
bit
change
same
run
first
time
run
run
okay
nice
field
support
comment
line
previous
end_time
i.e
value
docs
start_run
run
status
run
change
other
team
members
Just
sure
everyone
board
sense
comment
underlying
library
behavior
single
file
API
behavior
empty
list
fact
clearer
way
stripped_path
path
return
shrinath-suresh
Please
detailed
comments
logic
optimizer
future
behaviour
user
feedback
Apply
change
way
mlflow.project
comment
suggestion
0-indexed
position
pagination
=
request.args.get
comment
API
gateway
timeout
sure
Elastic
returns
few
seconds
suggestion
MAX_QUERY_DURATION
=
keys
successive
regex
groupby
common_prefixes
S3
API
language
comment
sentence
start
symbol
TODO
new
_get_optimizer
method
C.DTYPE_INT8
[
nit
]
Bias
....
noted
MXNet
access
private
members
small
TODO
comment
MXNet
changes
Same
above
comment
clear
function
comment
clarity
Add
comment
clarity
First
time
seek
necessary
necessary
comment
familiar
transport
code
objects
current
commit
description
get_folder_list
change
parameters
transport.put
loop
folders
loop
objects
file
names
temporary
file
name
something
looping
objects
process
content
temporary
file
Again
sure
code
comment
brief
explanation
changes
commit
message
suggestion
reference
issue
number
comment
comment
pylint
necessary
let
dead
code
call
try/except
helps
exceptions
handler
code
relevant
line
code
much
simpler
following
entire
method
message
stack
extraction
msg
f'\nThe
method
method
return
value
self._name
.open
context
manager.\n
+
\
wrap
call
<
node
instance
>
.open
warning
+
\
exception
aiida-core==2.0.0
.\n'
try
caller
=
traceback.format_stack
-3
]
Exception
pylint
disable=broad-except
msg
+=
line
code
responsible
warning
else
msg
f'The
call
\n
caller
warnings.warn
msg
AiidaDeprecationWarning
pylint
disable=no-member
line
qb.all
qb2.all
true
code
Ah
dictionary
json-compatible
default
method
@
lekah
Damn
sorry
'non-existent-key
None
Luciano
long
blush
assignment
statement
suggestion
user_namespace
=
runtime_configuration.metadata.get
'user_namespace
statement
simpler
way
>
>
import
pint
>
>
>
ureg
=
pint.UnitRegistry
>
>
ureg.define
*
molar
>
>
ureg.my_mM
==
ureg.mM
False
>
>
*
ureg.my_mM
*
ureg.mM
True
*
original_units
*
units
equal
unit
documentation
cellmlmanip
library
better
same
Add
comments
query
query
part
function
Will
inline
comments
>
result
lines
exact
base
version
content
correct
Repo
versions
diffs
git
direct
relationship
content
content
latest
repo
version
content
set
new
repo
version
comment
import
mongoengine
<
useful
i
comment
i
strong
feelings
TODO
Worth
i
i
test
atomic
version
other
test
similar
test
Person
plugin
Please
add
comments
conversion
todo
case
model
checkpoint
lock
self._pending_tasks
]
access
worker
record
tasks
end_time
ceiling
command
Just
good
practice
crazy
banks
assert
key
self.param_lookup
pre-existing
edge-case
bug
sngl_id
location
trigger
corresponding
HDF_TRIGGER_MERGE
file
incremental
integers
*
*
requirement
sngl_id
unique
sngls
coincidences
XML
format
old
code
*
possible
*
non-unique
entries
sort
problem
Tito
same
thing
..
description
XML
format
in-line
comments
familiarity
block
whole
thing
sense
good
place
documentation
PEP8
indented
code
report
indent
tabs
variable
above
addattrs
=
p
val
addattrs
SEOBNRv4
next
line
None
Same
comment
TODO
issue
Pauli
measurements
CliffordSimulator
everything
qubit
id
operation
collections.Iterable
recurse
known
problematic
type
string
iterable
error
test
making
sure
string
case
test
qubits
generator
__eq__
comparisons
Optional
elements
matrix
formula
[
paper
]
https
//arxiv.org/abs/1707.03429
python
pre_z_phase
=
np.exp
*
np.pi
*
self.lmda
post_z_phase
=
np.exp
*
np.pi
*
self.phi
y_phase
=
np.exp
*
np.pi
*
np.theta
c
s
=
y_phase.real
*
np.array
[
[
pre_z_phase.conj
post_z_phase.conj
c
]
]
bit
formulas
good
unit
test
Done
work
only
documentation
change
protocol
class
cls
'_value_equality_approximate_values_
setattr
cls
values_getter
TODO
nice
comment
special
handling
future
readers
S
H
process
able
something
key
value
sweepable.items
above
code
tricky
while
values
Victory
comment
itertools
possible
entire
dictionary
time
new
list
condition
length
control_values
q
=
cirq.GridQubit
optimize
belongs
sim.run
outside
test
code
r.data
[
]
ints
line
comment
assertion
and/or
Comment
gate
gate
easy
Sycamore
chip
link
nature
publication
unitary
gate
super
JSONField
self
initial
data
str
initial
=
str
data
need
docstring
superclass
str
comparison
useful
comments
docstring
comment
line
deprecation
tests
subclasses
super
Use
single
quotes
string
single
quote
[
Python
style
]
https
//docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
python-style
comment
readability
Exception
appropriate
broad
type
check
@
felixxm
collation
valid
identifiers
better
solution
suggestion
function
=
template
=
%
expressions
%
function
s
%
collation
s'
Inspired
https
//www.postgresql.org/docs/current/sql-syntax-lexical.html
SQL-SYNTAX-IDENTIFIERS
collation_re
=
_lazy_re_compile
r'^
[
\w\-
]
+
def
__init__
expression
collation
collation
raise
ValueError
f'Invalid
collation
name
collation
self.collation
=
collation
pattern
strict
references
collations
other
schemas
schema
collation
least
address
immediate
concerns
SQL
injection
vector
sure
test
change
hard
negative
test
hard-coded
hash
line
comment
[
observation
]
https
//code.djangoproject.com/ticket/31667
comment:1
everyone
unicode_literals
need
Thanks
key
test
much
more
sense
related_name=
+
second
symmetricalfriendship_set
caller
PersonalSelfRefM2MSymmetrical
object
first
defined
directionality
second
intuitive
correct
[
documentation
PR
]
https
//github.com/django/django/pull/11298/files
diff-7e6909c7694e8a3ae170c2a22f9b6e0cR1577
python
tony
=
PersonSelfRefM2MSymmetrical.objects.create
name=
Tony
=
PersonSelfRefM2MSymmetrical.objects.create
name=
Chris
tony.friends.add
chris
tony.symmetricalfriendship_set.first
SymmetricalFriendship.objects.get
first=tony
False
tony.symmetricalfriendship_set.first
SymmetricalFriendship.objects.get
second=tony
True
Might
worth
test
Treat
large/small
floats
Decimals
Redundant
right
None
blank
line
size
cache
more
sense
size
single
write
python
self.__dict__.pop
None
@
timgraham
something
self.a1
=
Aritcle.objects.create
headline=
pub_date=
something
afterwards
suggestion
sql_column_inline_fk_immediate
=
CONSTRAINTS
%
name
s
IMMEDIATE
SET
CONSTRAINTS
%
name
DEFERRED'
comment
week_day
lookup
elif
lookup_type
==
WEEKDAY
integer
0-6
Monday=0
return
%
s
%
field_name
suggestion
return
.get_group_by_cols
test
SECRET_KEY
specific
value
legacy_encoded
depends
exact
value
SECRET_KEY
chances
secret
key
test
settings
slim
code
more
other
return
copy.deepcopy
bool
other
previous
condition
return
copy.deepcopy
other
searching
group
unnecessary
capturing
suggestion
r'^
*
\s
ASC|DESC
*
results
search
=
self.ordering_parts.search
sql
.group
=
self.ordering_parts.search
sql
.group
comment
question
May
system
exceptions
BaseException
SystemExit
KeyboardInterrupt
GeneratorExit
i
reason
except
KeyboardInterrupt
reason
Exception
import
top
file
Looks
good
comment
sha1-signed
value.
query.alias_map
.alias_refcount
pattern
other
location
file
setup
purposes
sum
returns
method
False
True
tickets
tests
chop
locale
r
format
issues
i.e
fields
same
model
multiple
times
e.g
parent__field1__field2__pk__field1
pk
_cls
field
relation
e.g
part
==
'pk
fld
=
_cls._meta.pk
fld
=
_cls._meta.get_field
part
fld.is_relation
_cls
=
fld.get_path_info
-1
]
.to_opts.model
_cls
=
None
fixes
multiple
times
fields
same
model
test
=
_cls._meta.get_field
part
fld.is_relation
_cls
=
fld.get_path_info
-1
]
.to_opts.model
_cls
=
None
second
pk
test
_cls
None
lookup
case
part
==
'pk
fld
=
_cls._meta.pk
fld
=
_cls._meta.get_field
part
case
get_field
'pk
issue
Maybe
time
previous
field
i.e
part
==
'pk
==
_cls._meta.pk
e.g
parent__pk__pk
cases
infinite
loop
following
simplified
scenario
unlikely
issue
class
A
Model
b
=
models.ForeignKey
B
CASCADE
primary_key=True
class
B
Model
=
models.ForeignKey
A
CASCADE
primary_key=True
LTS
memo
extra
safe
to_python_field
=
pk
=
set
to_python_field
to_python_field.remote_field
to_python_field
=
to_python_field.target_field
break
seen.add
to_python_field
Makes
sense
test
useful
nencoding
parameters
defaults
OPTIONS
old
version
something
conn_params.update
'UTF-8
'UTF-8
bit
simpler
comment
useful
expression
complicated
e.g
different
kind
expressions
Value
Case
able
use
cases
regexp
IMO
message
paste
queryset
repr
enough
clear
message
e.g
diff
diff
git
a/django/db/models/sql/compiler.py
b/django/db/models/sql/compiler.py
index
..
a/django/db/models/sql/compiler.py
+++
b/django/db/models/sql/compiler.py
@
@
-553,9
+553,9
@
@
class
SQLCompiler
None
warnings.warn
%
s
QuerySet
Django
Add
.order_by
%
s
current
query
%
+
Add
.order_by
%
s
current
query
%
self.query.model.__name__
.join
+
repr
f
f
RemovedInDjango31Warning
stacklevel=4
code
paragraphs
type
thing
one
gray
area
attribute
name
_fk
attribute
particular
attribute
FK
constraint
_while_
column
matters
line
tuple
deconstruction
number
places
query
params
.as_sql
other
SQLCompiler
methods
bit
logic
SQLCompiler.get_order_by
way
supports
many
forms
asc/desc
field
name
form
comment
significance
value
useful
comment
add_index
opclass
comment
suggestion
class
ModelFieldsCacheTest
TestCase
def
test_fields_cache_reset_on_copy
department1
=
Department.objects.create
id=1
department2
=
Department.objects.create
id=2
=
Worker.objects.create
name='worker
department=department1
worker2
=
copy.copy
worker1
self.assertEqual
worker2.department
department1
fields
base
object
worker2.department
=
department2
self.assertEqual
worker2.department
department2
self.assertEqual
worker1.department
department1
much
value
comment
Chop
blank
line
inline
comment
empty
file
expired.
parentheses
var
val
fact
line
python
context.update
var
val.resolve
context
var
val
self.extra_context.items
try
order
final
lingerers
try
django.utils.deprecation
import
ImportError
raise
Exception
Django
Django
script
venv
use
'django-admin
pip
install
-U
Django
separate
test
method
Extra
test
coverage
floats
ints
Adding
comment
redundant
next
line
additional
test
coverage
separate
commit
along
side
bug
fix
clear
code
future
comment
__class__.__name__
useful
app_label
'.ModelAdmin
string
ModelAdmin
subclass
case
error
model
%
s
app
'admin_registration
case
model
%
s
'admin_registration.PersonAdmin
need
empty
values
Default
empty
value
=
PubForm
pub_form.mocked_mode
pub
=
mf2.save
commit=False
self.assertEqual
pub.mode
default_mode
Above
comment
line
comment
line
comment
useful
e.g
db
need
below
return
blank
line
unintentional
sure
exact
intention
util
func
value
integer
value
==
int
value
calculation
case
dashboard
items
long
time
minutes
Hey
Thanks
sense
comment
background
Could
comment
wierd
function
True
TODO
code
suggestion
predict_y
argument
values
full_cov=False
suggestion
typing_extensions
python
compatibility
suggestion
default
=
config.default_positive_minimum
lower
=
default
lower
None
lower
former
code
open
ticket
mypy
i
suggestion
>
>
>
dp_count
[
]
-5
test
case
enough
Nice
So
zip
https
//docs.python.org/3/library/functions.html
zip
python
char_a
char_b
zip
a_binary
b_binary
last
request
PR
>
>
prime_factors
*
*
doctest
NORMALIZE_WHITESPACE
<
next
line
readable
GitHub
editor
left-right
scrolling
>
https
//docs.python.org/3/library/doctest.html
doctest.NORMALIZE_WHITESPACE
suggestion
i
cluster
suggestion
format
bitcode
edges
bitcode
suggestion
support.append
i
/
len
cluster
suggestion
print
\n
Edge
List\n
i
EL
print
i
suggestion
return
new_x
__name__
__main__
import
doctest
doctest.modtest
print
f
convert_to_2d
=
print
f
rotate
y
=
suggestion
image
URL
content
field
first
meta
tag
property
og
image
image_url
=
soup.find
meta
property
og
image
content
suggestion
image_data
=
requests.get
imgURL
.content
file_name
=
f
%
Y-
%
m-
%
d_
%
H
%
M
%
S
.jpg
open
file_name
wb
fp
fp.write
image_data
single-letter
variable
names
code
look
reader
code
response
image_data
attention
f-strings
expressive
complex
types
datetimes
line
comment
suffice
python
numpy.random
import
uniform
circle_dots
sum
int
circle
uniform
-1.0
uniform
-1.0
_
range
iterations
suggestion
*
%
divide_by_number
suggestion
>
>
>
=
[
ft
ft
ft
ft
ft
]
>
example1
[
ft
ft
ft
ft
ft
]
>
>
natural
sort
algorithm
sort
meaning
computer
code
point
>
>
natural_sort
example1
[
ft
ft
ft
ft
ft
]
>
>
example2
=
[
'Elm11
'Elm12
'Elm2
'elm0
'elm1
'elm10
'elm13
]
>
example2
'Elm12
'Elm2
'elm0
'elm1
'elm10
'elm13
]
>
>
natural_sort
example2
'elm1
'Elm2
'elm9
'elm10
'Elm11
'Elm12
]
suggestion
https
//en.wikipedia.org/wiki/Lucas_number
recursive_lucas_number
n
int
>
int
re-write
[
Python
built-in
]
https
//docs.python.org/3/library/functions.html
suggestion
Return
kth
smallest
element
binary
search
tree
suggestion
Perform
inorder
traversal
values
nodes
list
arr
suggestion
import
ascii_uppercase
dict1
=
char
i
i
char
enumerate
ascii_uppercase
=
i
char
i
char
enumerate
ascii_uppercase
Dict
comprehensions
logic
function
uses
privacy
notice
times
comment
TODO
refactor
helper
function
fine
github
action
tests
reminder
TFP
stable
specific
package
release
Per
discussion
Slack
change
time
dimension
left
empty
dimensions
name
important
loc
=0
TODO
comment
case
scipy
interface
own
sure
shapes
comment
logits.max
dim=2
different
fwd
functions
different
tasks
number
places
special
cases
fine/standard
more
comments
special
cases
necessary
stale
=
>
something
people
WiC
server
comments
Add
comment
how/why
differs
SuperGLUE
version
@
dirk-thomas
nit
suggestion
keep-alive
argument
argparse
exclusive
group
comments
request
None
means
warning
error
comment
plz
case
comment
please
receiver
i
valid
data
form
valid
necessary
data
data
invalid
form
invalid
kinds
other
reasons
data
invalid
test
first
run
comment
reason
django
case
disabledness
update
comment
iterations
number
argument
F401
'geopandas
unused
suggestion
iterate
subcategories
bottom-up
aggregation
entry
sub_variables
unused
F401
'pyam.iiasa.read_iiasa
unused
docstring
please
v
branch
names
region
docstring
constant
opportunity
possible
latest
TODO
Same
comment
benefit
flake8
http
//flake8.pycqa.org/en/3.1.1/user/ignoring-errors.html
in-line-ignoring-errors
comment
celery
task
example
url
video
geo-blocked
videos
alternative
method
https
//github.com/streamlink/streamlink/pull/1576
pullrequestreview-126887060
Add
comment
individual
components
associated
meanings
meaning
sentence
docstring
user-facing
function
confused
sentence
mean
parameter
scaling
factor
suggestion
m1
bool
return
type
Please
use
please
arguments
response
description
Licence
comment
comment
need
Could
comment
vmgroup
default
DS
@
calvinsID
Nit
comment
original
method
backend
API
get
hand
hold
cli_ctx
cli_ctx.get_progress_controller
little
bit
line
comment
Yugang
Suggest
usage
error
valid
sku
linux
plan
....
do
runtime
project
file
>
pass
[
]
length
=
comments
pass
means
test
sometime
many
cases
recommendation
list
cases
PR
description
logger.debug
args
sure
meeting
design
Seconds
comment
comment
service-endpoints
later
useful
feature
old
implementation
az
verion
debug
Suppress
exception
DLL
load
win32file
specified
module
change
informative
error
az
verion
debug
Suppress
exception
Traceback
recent
call
last
File
d
\cli\azure-cli\src\azure-cli\azure\cli\__main__.py
line
<
module
>
raise
ex
File
d
\cli\azure-cli\src\azure-cli\azure\cli\__main__.py
line
<
module
>
sys.exit
exit_code
SystemExit
handling
above
exception
exception
Traceback
recent
call
last
File
d
\cli\azure-cli\src\azure-cli-telemetry\azure\cli\telemetry\__init__.py
line
<
module
>
import
portalocker
File
D
\cli\env38\lib\site-packages\portalocker\__init__.py
line
<
module
>
import
portalocker
File
D
\cli\env38\lib\site-packages\portalocker\portalocker.py
line
<
module
>
import
win32file
ImportError
DLL
load
win32file
specified
module
handling
above
exception
exception
Traceback
recent
call
last
File
d
\cli\azure-cli\src\azure-cli-core\azure\cli\core\decorators.py
line
_wrapped_func
return
func
*
args
*
*
kwargs
d
\cli\azure-cli\src\azure-cli-core\azure\cli\core\telemetry.py
line
conclude
azure.cli.telemetry
import
File
d
\cli\azure-cli\src\azure-cli-telemetry\azure\cli\telemetry\__init__.py
line
<
module
>
import
portalocker
File
D
\cli\env38\lib\site-packages\portalocker\__init__.py
line
<
module
>
import
portalocker
File
D
\cli\env38\lib\site-packages\portalocker\portalocker.py
line
<
module
>
import
win32file
ImportError
DLL
load
win32file
specified
module
comment
code
mistake
test
case
delete
IP
address
true
comments
comments
next
reader
Please
TODO
workaround
service
side
issue
concise
way
Python
resource_group
=
namespace.resource_group_name
resource_group
resource_group
None
…
values
values
default
'is_default
property
pls
description
help
file
cert
file
permission
change
necessary
[
CI
]
https
//travis-ci.org/Azure/azure-cli/jobs/524569053
L1570
import
statement
urlsplit
import
spaces
previous
char
space
following
char
variable
name
change
breaking
change
*
*
command
cert
*
*
case
future
cert
live
run
fails
Too
many
print
logger
comment
reason
PR
knack
query
implementation
result
OrderedDict.
nit
comments
format
change
CLI
core
odd
fields
change
webapp_name
message
ex.status_code
ex.error_code
[
AuthorizationPermissionMismatch
AuthorizationFailure
AuthenticationFailed
]
tag
check
suggestion
passing
dbfs_path.absolute_path
extra
logic
_with_retries
methods
comments
situations
frames
k
encodable
k
large
header
collections
optimization
serialization
likely
rare
case
odd
people
large
complex
values
keys
something
type
obj
dict
len
=5
try
msgpack.dumps
list
Exception
dict_safe
=
False
dict_safe
=
True
type
obj
dict
dict_safe
type
obj
tuple
list
rest
code
comment
compatibility
old
Python
string
fact
ssl
required
Purpose
enum
_get_tls_context
return
None
better
dummy
object
explicit
error
APIs
ssl
module
required
APIs
Minor
comment
specific
OSError
exception
small
comment
coroutine
code
sense
TODO
note
code
necessary
worth
git
blame
sure
Same
other
below
object
prometheus
client
conflicts
multiple
times
boolean
values
bools
strings
default
values
yaml
file
project
default
values
code
ucx
section
distributed/distributed.yaml
file
things
following
=
dask.config.get
ucx.infiniband
intermediate
value
configuration
dask.config.get
ucx.infiniband
concise
easier
future
reviewers
enable_nvlink
ucx_conf
TODO
comm
scheduler
remote
case
inline
comment
nprocs
option
cli/dask_worker.py
significant
helpful
subtle
change
assertion
exception
s
situation
safe
catch-all
handler
syntax
errors
broken
things
potential
debugging
mystery
downstream
implementations
Dask
Cluster
types
type
something
isinstance
getattr
address
scheduler_address
None
str
comment
example
better
read
separate
test
dataset
predictions/evaluation
same
training
data
reload
trained
predictor
disk
task.fit
new
feature
generators
users
outputs
confusing
Original
Features
exact
raw
dtype
raw
dtype
'int
|
[
'age
'fnlwgt
'education-num
]
'object
'object
|
[
'workclass
'education
'marital-status
Original
Features
raw
dtype
special
dtypes
[
]
|
[
'age
'fnlwgt
'education-num
]
'object
[
]
|
[
'workclass
'education
'marital-status
]
Features
exact
raw
dtype
raw
dtype
'category
|
[
'workclass
'education
'marital-status
]
'int
|
[
'age
'fnlwgt
'education-num
]
Features
raw
dtype
special
dtypes
[
]
|
[
'workclass
'education
'marital-status
]
'int
[
]
|
[
'age
'fnlwgt
'education-num
print-structure
Types
features
original
data
Types
features
preprocessed
data
behind
types
terms
pairs
b
unclear
user
perspective
eg
type
type
b
'special
dtypes
corresponds
empty
list
better
anything
special
dtype
features
type
few
print
statement
such
little
information
TODO
kwarg
FeatureGenerator
Add
TODO
categoricals
safety
code
self.num_classes
None
num_classes
self.num_classes
num_classes
Guess
better
y_train
E501
line
characters
file
comment
need
realpath
thinking
Might
worth
comment
context_path_names
comment
mentions
Version
unpacking
secret_key
public_key
message
signature
=
line.split
unpack
afterwards
e.g
signature
=
signature
]
correct
PrecertedSignedCerificateTimestamps
X.509
certificate
OCSP
extension
different
easier
binaries
[
os.path.dirname
_accessible_output2.__file__
'lib
'lib
better
collect_dynamic_libs
'module-name
https
//pyinstaller.readthedocs.io/en/stable/hooks.html
useful-items-in-pyinstaller-utils-hooks
Add
comment
line
classifier
exists
Sorry
last
comment
Done
check
exception
info
underlying
errors
try/except
@
vojtechjelinek
earlier
comment
>
Just
config_domain.PROMO_BAR_ENABLED
Just
context
way
comment
state_name
version
exp_version
old_exp_version
little
comment
old
state
model
new
state
error
message
stub
logging.error
latter
tests
multiline
stuff
break
everything
right
use
single
quotes
backend
@
oppia/dev-workflow-team
lint
checks
Question
error
message
space
type
info
other
docstrings
examples
something
value_generators_dict
dict
str
BaseValueGenerator
Dictionary
mapping
Use
.update_interaction_hints
line
nit
add
period
end
def
escape_html
html_data
Done
Ok
Follow
alphabetical
order
can_play_exploration
decorator
exploration
id
changes
frontend
backend
full_thread_id
concept
change
frontend
new
decorators
can_view_thread
can_comment_on_thread
need
Shall
follow
PR
code
migration
note
comment
comment
idea
dict
model
instance
MapReduce
pipeline.
typeinfo
incorrect
entire
function
sure
Do
length
return
value
actual
value
general
try
strictest
test
possible
Ditto
IDs
suggestion
dependency
ids
single
line
comment
same
thing
Suggest
brief
comment
status
check
assertion
behavior
case
correct
Ditto
comment
re.escape
bad
idea
comment
line
Note
change_dict
[
'skill_id
]
None
change
context
suggestion
skill_id
null
change
dict
case
type
change_dict
fully-determined
set
keys
topic
editor
questions
skill
skill
descriptions
corresponding
IDs
Same
comment
above
Done
info
comments
declarations
Added
comment
Maybe
explanation
comments
comment
other
people
tags
RTE
comment
line
field
user-related
Again
cleaner
set
values
subset
desired
set
loop
better
tuple
non-modifiable
@
ankita240796
backend
test
case
state
new
name
old
name
state
former
old
name
ExplorationVersionsDiff
new
object
more
sense
rename-dict
old
state
name
way
algorithm
data
delete
stuff
old
state
names
new
state
names
rename
dict
new
states
Returns
docstring
return
value
set
models
set
strings
Could
change
previous
review
general
sure
code
Done
comment
hard
track
previous
comments
Thanks
file
migration
finishes
comment
someone
stuff
list
time
file
user_id
different
gae_user_id
least
kind
TODO/issue
comment
specific
input
type
Dataset
Reader
update
stack_raster_tifs
warning
TODO
detail_answer.raw_data
]
check
valid
first
need
str
line
return
change
bit
broad
Trakt
endpoint
collected
episodes
Did
literal_binds
https
//docs.sqlalchemy.org/en/rel_1_2/faq/sqlexpressions.html
how-do-i-render-sql-expressions-as-strings-possibly-with-bound-parameters-inlined
string
timestamp
other
timestamps
UserMetadata
quoted
strings
passwordUpdate
float
response
other
timestamps
Please
comment
logic
rationale
Nit
May
mention
https
//github.com/googleapis/googleapis/blob/master/google/rpc/code.proto
comment
mappings
comments
duplicate
first
paragraph
docstring
May
useful
method
example
try/except
block
exists
long
time
same
comment
signature
weirdness
w/
binnumbers
unique_bin_numbers
empty
NumPy
array
useful
comment
test
test
gh-12418
nice
suggestion
minimize
*
]
constraints
lin_cons
errors
required
field
major
refactoring
comment
data
example
'fields
self.request.query_params
\
'current_user_permissions
self.request.query_params
'fields
]
data
'current_user_permissions
]
=
get_object_perms
instance
self.request.user
value
other
error
messages
consistency
Good
idea
context
others
suggestion
sure
sub-fields
Optional
[
Union
[
ForwardRef
'Node
Leaf
]
]
PrettyWood
sure
case
IndexError
error
suggestion
Modify
constraints
differences
IEEE
floats
json
comment
please
commit
default_factory
case
below
Better
model_class
model
clear
noqa
F811
other
examples
code
base
codecs.escape_decode
Python
if-else
comment
later
point
time
fix
Returns
hack
explicit
list
names
list
per
line
future
clean
diff
file
standard
coding
utf-8
top
Please
reader
role
available
notes
]
http
//coaster.readthedocs.io/en/latest/sqlalchemy/roles.html
future
private
events
reader
role
comments
Comment
votes
UI
Has
case
db
join
Voteset
order_by
Voteset.score
Comment.created_at.desc
Vote.count
separate
method
comments
Thanks
function
file
Make
json
request
bodies
consistency
ditto
above
comment
prescient
necessary
comment
Could
https
//github.com/CenterForOpenScience/osf.io/pull/9022/files
diff-e454a52b84234680cffb5f12a0695a05R49
similar
question
others
lists
suggestion
setattr
_locals
name
]
__module__
httpx
check
pods
endpoint
data
See
nope
stuff
sure
script
comment
part
merge
other
places
file
create_config
create_fake_build_artifacts
functions
https
//github.com/dcos/dcos/pull/1132
unit
test
artifacts
helper
genconf
presence
complete.latest.json
build
artifact
above
variable
function
additional
comments
usage
clearer
comment
Nice
spot
Thanks
comment
right
way
new
API
smart_open
*
*
below
comment
inaccurate
only
reason
whole
thing
memory
call
Mac
reason
version
Edit
accordance
comment
viz
enumerate
idiomatic
method
separate
in_vocab_idxs
out_vocab_entities
ops
mask
options
use
text
<
http
//
>
_
references
[
]
_
references
file
serious
change
documentation
building
_might_
breaking
change
getboolean
throws
exception
value
empty
someone
config
file
setup
suggestions
best
good
way
GMT_COMPATIBILITY
original
gmt.conf
suggestion
lib.call_module
prefix
pygmt
replies
GMT
modern
mode
GMT_COMPATIBILITY
lib.call_module
comment
pygmt
GMT_COMPATIBILITY=6
xarray
builtin
[
sort
]
https
//xarray-test.readthedocs.io/en/latest/reshaping.html
sort
mechanism
code
heaps
suggestion
[
i
i
inc
]
Sort
negative
increments
=
[
abs
i
i
inc
]
grid
=
grid.sortby
variables=list
grid.dims
matrix
as_c_contiguous
grid.values
:-1
]
Note
warning
*
*
*
commit
change
file
change
lines
good
unit
tests
sure
possible
combination
flipped
latitude/longitude
coordinates
suggestion
>
>
>
my_module
region='bla
projection='meh
J=
bla
doctest
+NORMALIZE_WHITESPACE
Traceback
recent
call
last
pygmt.exceptions.GMTInvalidInput
Arguments
short-form
J
long-form
projection
[
doctest
+NORMALIZE_WHITESPACE
]
https
//docs.python.org/3.8/library/doctest.html
doctest.NORMALIZE_WHITESPACE
datetime
doctest
https
//github.com/GenericMappingTools/pygmt/blob/9a4c0a0177dac03e05d219c01105f272c9911655/pygmt/clib/conversion.py
L287-L289
great
idea
globbing
strings
certain
length
couple
changes
*
simple
len
comparison
string
limit
globbing
strings
least
other
characters
foo
characters
*
final
character
check
False
sure
section
process
*
regular
Signoffs
ie
Release
Rule
signoff
*
signoffs
sum
signoffs
Release
product
right
way
section
explanatory
comment
obvious
different
types
Required
Signoffs
unused
lot
sense
sanity
multiple
matches
more
work
e.g
description
field
previous
comment
unique
cookies
json_encode
quotes
example
%
s=\
%
s\
%
field_name
scalyr_util.json_encode
field_value
way
customers
parsers
extra
fields
values
test
cases
example
output
timestamp=2015-09-05
space
hard
key
value
pair
change
timestamp=
2015-09-05
right
thing
documentation
mention
self
getter
documenation
nice
Add
comment
attributes
parent
such
logfile
event.
Relook
comments
method
implementation
details
change
reasonable
safe
side
condition
dev
install
unable
documentation
sub-
version
Python
devlib
document
Py3.6
right
devlib
Py3.5
projects
incl
WA
Python
necessary
minimum
version
Python
Py3.6
sense
common
stable
[
years
old
bug-fix
support
end
last
year
]
https
//www.python.org/downloads/release/python-360/
valuable
new
features
f-strings
PR
necessary
version
Python
is/will
projects
@
@
marcbonnici
__init__
method
cov
covariance_matrix
covariance_matrix
cov
few
tests
public
methods
docstring
param
torch.Tensor
point
section
return
section
conditions
need
nested
statements
empty
string
foo
easier
foo
None
something
python
crash_signature
=
params.get
crash_signature
crash_signature
len
crash_signature
>
crash_signature
params
len
params
crash_signature
]
>
crash_signature
comment
kind
issue
treeherder.config.settings
comment
rationale
length
bug
comment
failsafe
Other
shipit
check_bug_info
bit
strange
moment
bit
cache
cached
value
whiteboard
value
something
caller
function
thing
things
list
whole
class
bit
TLC
switchover
Anyway
call
chain
reason
bug_info
None
request
Bugzilla
API
fetch_bug_details
returns
None
obvious
particular
line
code
comment
other
instances
preferred_quotation
str_contents
add_escape
str_contents
str_contents.replace
preferred_quotation
+
preferred_quotation
coala_utils.string_process.escape
optional
function
such
scenarios
thing
worth
comment
snippet
quotation
string
preferred
quotation
string
+1
E265
comment
*
Origin
PycodestyleBear
E265
Section
code
PEP8
*
Origin
PEP8Bear
Section
issue
following
patch
diff
a/tmp/tmpbh8l44q4/bears/general/QuotesBear.py
+++
b/tmp/tmpbh8l44q4/bears/general/QuotesBear.py
@
@
-41,7
+41,7
@
@
force_preferred_quotation
return
Escape
quotes
present
+
Escape
quotes
present
escape_str
=
+
preferred_quotation
str_contents
=
str_contents.replace
preferred_quotation
escape_str
uncommented
Sorry
i
Use
pragma
nocover
naaah
please
use
file
file
\+
little
comment
case
separate
commit
Try
meaningful
code
user
config
file
.stylelintrc
cur
dir
user
coverage
test
test
test
case
test_create_arguments
possible
solution
stylelint_config_file
same
point
sense
smile
Ok
comment
test
such
comment
code
please
people
test
n
https
//github.com/FFmpeg/FFmpeg/archive/n
version
.zip
version
metric
e2e
🤔
system.processes.priorities
http_check
default
agent
headers
request
case
comment
standby
role
f
case
role
True
standby
standby
role
else
master
work
=
def
process
msg
kwargs
self.extra
[
'_check_id
]
=
self.check.check_id
kwargs
'extra
]
=
self.extra
return
msg
sure
historical
comment
piece
info
useful
nit
Could
aggregator.assert_all_metrics_covered
aggregator.assert_metrics_using_metadata
get_metadata_metrics
sense
tag
tag
wrong
commit
example
safe
Just
_tags
=
list
scraper_config
[
'custom_tags
]
reason
jvm
category
metrics
gauge
mapping
https
//github.com/DataDog/integrations-core/blob/master/ibm_was/datadog_checks/ibm_was/ibm_was.py
L22-L29
Maybe
correct
suggestion
del
check
Agent
check
int
better
suggestion
GAUGE
suggestion
GAUGE
>
suggestion
GAUGE
>
comment
number
suggestion
Does
windows
zookeeper
image
compatible
windows
architecture
interface
tags
interface
netgear_ifX300_v1
comment
manufacturer
product
name
version
hardware
interface
profile
couchDB3
CouchDB2
comment
suggestion
value
write_persistent_cache
same
key
*
*
key
*
*
_str_
key
Good
point
comment
rsq
Nistats
code
term
PR
explicit
name
function
attribute
better
example
r_square
lot
more
self-documenting
rsq
Residuals
r-square
same
docstring
Docstring
forth
comment
nice
medium
developers
checks
way
i
p.model
suggestion
tau
=
tau_e
*
k
*
*
ar1
precision
note
way
new
theano
six.moves.urllib.parse
import
quote
urlquote
urlquote
TEST_GIT_URI
safe=
E265
block
comment
F821
name
'get_orchestrator_build_logs
F811
redefinition
unused
line
F811
redefinition
unused
'openshift
line
required
param
plugin
good
point
flexible
Configuration
uses
plugin
optional
fatal
orchestrate_build
plugin
path
Configuration
instance
Pandas
circular
references
comments
part
code
documentation
refactoring
process
functions
better
comments
reason
functions
testable
case
comment
function
e.g
similar
one
def
Npix_composing_ring
image
return
np.sum
image
Npix_above_threshold
image
[
]
return
np.sum
image
>
threshold
if-clause
Npix_above_threshold
pix_im
*
minpix
Npix_composing_ring
pix_im
minpix
Comments
stale
smell
time
somebody
code
forgets
comment
new
functions
little
unit
test
sure
block
comment
indentation
multiple
comment
br
>
unexpected
indentation
comment
try
block
comment
block
comment
path
check
valid
suggestion
Empty
source_dir_id
location
comment
functionality
Thoughts
[
]
spread
serv_tv
=
self.add_preload_service
SERV_TELEVISION
[
CHAR_REMOTE_KEY
*
self.chars_tv
]
suggestion
sense
comment
list
characteristics
unique
accessory
type
tuple
dict
check
code
code
comment
skip_sidx
suggestion
hsv_color
=
self._hsv_color
self.device.supports_color
hsv_color
return
round
hsv_color
[
-1
]
*
suggestion
pylint
disable=unsubscriptable-object
return
round
hsv_color
[
-1
]
*
None
suggestion
return
round
self._hsv_color
[
-1
]
*
return
None
end
bigger
change
few
minor
bugs
better
explicit/implicit
documentation
OK.
async_dispatcher_send
self.hass
DOMAIN
self._update_v1_api_state
Please
comment
temporary
library
Stale
comment
suggestion
keypad
elk.keypads
pylint
disable=no-member
https
//github.com/gwww/elkm1/blob/main/elkm1_lib/elk.py
L70
level
weird
Switch
things
storage
LAST_SCANNED
suggestion
await
helper.async_create_item
TAG_ID
tag_id
LAST_SCANNED
dt_util.utcnow
options
data
better
conditipm
check
need
data
entry
entity
platform
return
value
False
linter
homeassistant/components/alexa/intent.py:50:4
W0107
Unnecessary
pass
statement
unnecessary-pass
bug
linter
Use
comments
suggestion
timeout
_async_update_data
data
devices
POLLING_TIMEOUT_MULTIPLIER
Timeout
initial
entry
setup
async_setup_entry
SETUP_ENTRY_TIMEOUT_SEC
Multiplier
update_interval
devices
SLEEP_PERIOD_MULTIPLIER
Multiplier
update_interval
non-sleeping
devices
init
method
sure
right
identifier
deCONZ
deconz
libraries
appliances
plug
device
class
comment
backwards
compatibility
suggestion
.const
import
DOMAIN
pylint
disable=unused-import
suggestion
Test
network
status
golden
nice
documentation
own
machine
yeah
conf/
dict
updates
LOGGING
[
'root
]
=
'handlers
[
]
logging.INFO
.update
LOGGING
[
'root
]
.update
'level
logging.DEBUG
LOGGING
[
'root
]
=
'root
logging.INFO
other
dict
elements
update
recursive
few
comments
separate
steps
step
method
hard
comment
issue
link
frontend
~~Just
better
Paginator
~~
Nevermind
able
addon_details_box.html
additional
changes
comment
sure
Add
associated
checks
test_indexers.py
ES
doc
comment
sure
refactoring
Had
django
single
instance
empty
list
case
UPDATE
anything
extra
field
status
DiscoveryItem
version
_decode
version
string
suggestion
list_filter
=
Suggestion
reporter
'anonymous
user
something
comment
remark
comment
grid_center
generous
input
params
MiroDudik
@
riedgar-ms
force_L1_norm
different
suggestion
comment
issues
default
implementation
default
pos_label=None
meaning
same
pos_label=1
my_labels
_get_labels_for_confusion_matrix
subset
exception
bad
corner
case
e.g.
unique
labels
]
case
Could
test
case
NEWSPIDER_MODULE
lipstick
Docstrings
middle
function
implementation
suggestion
Windows
versions
interpret
ANSI
escape
sequences
terminal
processing
Enable
enivornment
variable
ENABLE_VIRTUAL_TERMINAL_PROCESSING
terminal
processing
Shouldn
’
t
single
statement
platform.release
platform.version
=
Isn
’
t
=
string
comparison
problematic
’
t
obvious
code
comment
*
_py_files
tests/CrawlerProcess
list
comment
line
brief
explanation
files
comment
seconds
loop
bit
large
installation
dataset
Everything
%
PASS
rate
telemetry
purposes
Everything
%
PASS
rate
interesting
more
first
batch
regardless
fine
more
LIMIT
current
ones
Anything
pass
rate
>
%
sure
ones
PASS
rate
closer
e.g
fine
kind
bit
pass
rate
closer
occasional
pass
actionable
stable
test
suite
Use
dict.fromkeys
data
large
data
structure
new
dictionary
same
keys
values
None
comment
what/why
list
data.values
data.values
modernrpc
JSON
try
JS
client
browser
bleach
scenarios
wrong
SUT
bleach.clean
funtion
markdown2html
function
conversion
Markdown
bleach
unwanted
HTML
tags
explicit
list
tags
attributes
similar
comments
fact
particular
case
functional
permissions
scenarios
same
conditions/various
scenarios
functionality
part
value
msg
parameter
signature
clear
https
//docs.python.org/3/library/unittest.html
unittest.TestCase.assertIsNotNone
second
parameter
necessary
b/c
assertion
clear
page
TP
status
code
bandit
happy
squash
wait
function
PR
better
comment
please
comment
nice
way
params
example
OSD
OCS
capacity
OSD
clear
state
OSD
cluster
point
lot
own
function
way
description
docstring
osds
=
ocp_pod_obj.get
selector=constants.OSD_APP_LABEL
]
reason
top
file
other
imports
please
comment
Add
comment
import
statement
suggestion
pod
unsolvable
import
loop
ocs_ci.ocs.resources.pod
import
get_all_pods
get_pvc_name
comment
reason
Okay
Please
comment
strange
file
same
error
model
lasso
example
pep8
space
comma
suggestion
custom
markers
PytestUnknownMarkWarning
config.addinivalue_line
nit
skip
line
variable
loop
X
fine
Add
test
functions
test
function
classes
strings
surprises
==
use
assert_raise_message
error
message
top
exception
type
SearchCV
name
Comment
test
issue
suggestion
@
pytest.mark.parametrize
array_constructor
array
sparse_csr
sparse_csc
]
def
test_standard_scaler_sample_weight
Xw
X
array_constructor
with_mean
sparse
X
=
_convert_container
X
array_constructor
=
_convert_container
Xw
array_constructor
comment
>
parameter
combinations
plots
useful
short
comments
e.g
Canonical
case
cat
behaviour
equivalent
https
//github.com/scikit-learn/scikit-learn/pull/12077
issuecomment-478579388
test
value
suggestion
condition
early
sphinx
expert
app.builder
filter_search_index
builder
HTML
sphinx-specific
hooks
event
sphinx
actual
terms
builders
basis
/10
PEP8
space
Please
line
length
chars
PEP8
indentation
please
predictions
cross_val_predict
LogisticRegression
X.tolist
method='decision_function
suggestion
TODO
Remove
warn_checker
y_is_x
suggestion
warn_checker
=
pytest.warns
FutureWarning
suggestion
ax=disp1.axes_
doctest
+SKIP
hard
good
comment
non-regression
issue
xxx
version
sp_version
parse_version
None
X
Y
comment
sp_version
sklearn.utils.fixes
Nit
suggestion
V
=
np.var
X
axis=0
ddof=1
dtype=np.float64
difference
case
user
data
copy
chunked
operation
documentation
warning
label_index
[
]
.size
i.e
outlier_label
classes_
nice
better
approach
[
second
example
Pytest
doc
]
https
//docs.pytest.org/en/latest/assert.html
assertions-about-expected-exceptions
only
pytest
less
year
match
argument
false
positives
CI
date
pytest
issue
worth
minimum
pytest
requirements
dev
documentation
comment
remove
https
//github.com/joblib/joblib/issues/1071
pep8
related
warnings
suggestion
Cython
import
Tempita
SkipTest
estimator
object
previous
iterations
py
try
estimator
=
_construct_instance
Estimator
SkipTest
continue
yield
name
estimator
something
comment
relevant
line
below
internal
version
keyword
deprecation
comment
X
indexable
axes
suggestion
clf.fit
X
y
max_iter
==
attribute
docstring
scorers
first
y_true
signature
eg
https
//scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html
sklearn.metrics.accuracy_score
https
//scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html
sklearn.metrics.r2_score
correct
OMG
boom
necessary
iteration
default
alpha
division
zero
log10
short
comment
necessary
ellipsis
case
suggestion
appropriate
arguments
method
sure
suggestion
doctest
+NORMALIZE_WHITESPACE
original
URL
+1
comment
original
dataset
URL
obscure
usage
np.load
zip
file
memory
safe
path
Windows
comment
docstring
numpy.load
helpful
suggestion
sample_weight
hessians
comment
above
clause
small
comment
Any
specific
reason
empty
array
special
case
better
column_or_1d
first
validation
WDYT
Add
comment
one-node
trees
ensemble
flat
Please
comment
n_init=1
default
test
space
travis
Could
doctest
+ELLIPSIS
end
cov.covariance_
line
]
https
//docs.python.org/3/library/doctest.html
directives
suggestion
TODO
test
@
pytest.mark.parametrize
PLSRegression
PLSCanonical
CCA
PLSSVD
comment
comment
cases
sparse
input
sparse
output
suggestion
>
>
>
disp.plot
doctest
+SKIP
suggestion
>
>
>
disp
=
PrecisionRecallDisplay
precision=precision
recall=recall
>
>
disp.plot
doctest
+SKIP
comment
is_sparse
available
older
versions
pandas
suggestion
influence
seed
hashes
=
[
[
foo
bar
baz
foo
.encode
comment
pairwise_distances
more
familiar
users
pdist
hah
aware
possible
bit
magical
OK.
suggestion
FIXME
need
https
//github.com/DataBiosphere/azul/issues/1448
=
k
v
k
v
queues.items
config.work_queue_names
precedence
v
codebase
Please
stick
conventions
contributions
wrong
logic
use
config.work_queue_names
Creative
approach
test
structure
new
test
cases
entity_id
empty
string
test_cases
list
note
slight
change
params
order
None
case
entity_ids
None
same
current
implementation
entity_ids
query
test
case
intended
situation
possible
suggestion
test_cases
[
project
entity
integration
[
]
[
]
project
entity
ids
different
integrations
[
'cddab57b-6868-4be4-806f-395ed9dd635a
'90bd6933-40c0-48d4-8d76-778c103bf545
]
[
'dbfe9394-a326-4574-9632-fbadb51a7b1a
]
project
entity
different
integrations
[
]
[
'e8b3ca4f-bcf5-42eb-b58c-de6d7e0fe138
]
entity
ids
empty
string
matching
integrations
]
[
]
entity
ids
integrations
None
[
'dbfe9394-a326-4574-9632-fbadb51a7b1a
'977854a0-2eea-4fec-9459-d4807fe79f0c
'e8b3ca4f-bcf5-42eb-b58c-de6d7e0fe138
]
portal_integrations_db.return_value
=
self._portal_integrations_db
mock.patch.object
type
config
'prod
entity_ids
integration_ids
test_cases
params
dict
integration_type='get
entity_ids
None
params
'entity_ids
]
=
entity_ids
self.subTest
*
*
params
response_json
=
self._get_integrations
params
found_integration_ids
=
self._extract_integration_ids
response_json
self.assertEqual
integration_ids
found_integration_ids
document
tester
addrindex
TODO
in-memory
database
connect
external
database
nothing
comment
dependency
running
mysql
database
work
TODO
backend
more
generic
Windows
focus
look
names
bunch
elif
comparisons
interested
TODO
it's
suggestion
def
_apply_layered_relation_to_rison
layer_id
int
rison_parameters
Dict
[
str
Any
]
>
None
version
presto
version
number
sure
available
comment
link
issue
lib
Github
PR
best
option
sqlparse==0.3.0
PINNED
PR
comment
thanks
feature
flag
Please
add
line
change
last
row
more
generic
error
dtype
=
col
[
'type
]
.__class__.__name__
col_obj.is_num
base
column
class
todo
link
issue
rid
retry
underlying
issue
ticket
warnings
second
third
..
r
v
.\d+
shorter
r
v
somebody
v1
somebody
v1.1
somebody
v1.1.1
sure
config
variable
ForgedAlliance
executable
constant
game
outcome
logic
hard
Nitpick
please
space
linter
Team
default
block
code
branch
NEVER
printing
Did
performance
implication
.git
directory
workflow
rerun
large
projects
reasoning
change
TimeoutError
download
more
comment
process_commit
method
above
comment
issue
LFS
better
line
TODO
comment
change
Let
clean
comment
sense
code
Load
priority
skills
order
time
MSM
self.load_skill_list
PRIORITY_SKILLS
comment
confusing
helpful
reasoning
code
.git
lock
files
future
somebody
someone
.git/index.lock
reason
comment
reasoning
decision
locking
mechanism
TODO:18.08
attention
things
comprehensive
set
docstrings/comments
function
hard
code
general
strategy
chunking/generators/multiprocessing
*
kind
iterable
object
contents
Are
multiple
levels
iterables
purpose
docstring
>
Helper
method
generator
get_frame_inputs
generators
slice
size
MULTIPROCESSING_CHUNK_SIZE
terse
get_frame_inputs
function
output
better
long
way
understandable
kind
off
topic
vim
j
formatoptions
help
fo-table
j
sense
comment
leader
lines
example
joining
int
i
index
~
//
list
~
Becomes
int
i
index
list
import
top
others
circular
dependency
error
restructuring
things
comment
gh
issue
comment
processes
line
belongs
regular
manticore
output
info
level
i
debug
line
hack
line
evm
i
line
general
analysis
output
info
level
suggestion
def
_ks_assemble
asm
str
>
bytes
string
Keystone
late
importing
Keystone
installation
Keystone
tests
global
ks
keystone
import
Ks
KS_ARCH_ARM64
KS_MODE_LITTLE_ENDIAN
None
ks
=
Ks
KS_ARCH_ARM64
KS_MODE_LITTLE_ENDIAN
suggestion
def
assemble
asm
str
>
bytes
string
assembly
cache
first
entry
Keystone
used.
assembly_cache
return
binascii.unhexlify
assembly_cache
[
asm
]
return
binascii.unhexlify
_ks_assemble
asm
suggestion
def
assemble
asm
str
mode=CS_MODE_ARM
>
bytes
string
assembly
cache
first
entry
Keystone
used.
assembly_cache
[
mode
]
return
binascii.unhexlify
assembly_cache
[
mode
]
[
]
return
binascii.unhexlify
_ks_assemble
asm
mode=mode
weird
PR
additional
uses
self.pc
self._pc
self.pc
https
//github.com/trailofbits/manticore/blob/master/manticore/platforms/evm.py
L722-L723
PR
only
use
self._pc
file
*
https
//github.com/trailofbits/manticore/blob/master/manticore/platforms/evm.py
L1125
Either
something
latter
bug
self.pc
=
self.pc
=
sure
anything
tests
tests
everything
@
feliam
comment
comment
subtle
comment
nested
'try
statements
I.e
important
block
'except
CancelledError
Could
comment
_warning
path
built-in
module.
specific
case
path
custom
message
necessary
test
obvious
same
other
messages
assertEqual
check
Please
comment
asyncio
document
code
lazy
import
async_case
obvious
first
read
comment
legacy
asyncio.iscoroutine
need
tests
Remove
above
comment
comment
eval
\xa0
SyntaxError
invalid
character
identifier
text
important
Python
parser
change
matching
Python
parser
\xa0
array
obvious
same
error
cases
New
code
PEP
sense
PyMethod
PyFunction
same
Sphinx
version
comment
subprocess.py
tempfile.py
zipfile.py
Yep
rest
change
doctests
part
test
suite
useful
commit
*
anything
lines
coveragepy
%
other
modules
snippet
difflib
pickle
%
coverage
Please
maintenance
module
many
such
cases
standard
library
comment
sources
build
reproducible
necessary
exception
correct
type
message
complex
operation
separated
line
Example
n
=
padchars
[
-5
]
last
[
-n
]
Oh
GitHub
comment
indentation
level
dedent
code
pid
[
comment
effect
bpo
issue
]
https
//bugs.python.org/issue38724
msg356598
return
code
args
args
suggestion
f
returncode
args
>
cool
same
proc
repr
change
same
comment
isinstance
example
bpo-10945
bdist_wininst
available
Windows
=
sys.platform
=
win32
good
repeated
comment
line
tar.getmembers
pass
tarfile.is_tarfile
tarfile.open
free
comment
block
Mac
OS
end
line
character
lines
plain
Python
comment
docstring
set_trace_callback
content
bpo-26187
Docstring
Just
comment
reference
bpo-26187
target_file
comment
something
ignore
comments
Please
comment
.mo
file
comment
messages.po
EdX
Studio
comment
inline
data
explaining
comment
atomicity
list
dict
short
comment
purpose
copy
suggestion
Original
value
threading.excepthook
__excepthook__
=
suggestion
Preserve
docstring
value
node.value.replace
\\
value
=
value.replace
\
calls
following
data
open
great
somes
tests
Example
some_data
=
mock
=
mock_open
read_data=some_data
self.assertEqual
mock
.read
foo\nbar\nba
.read
z
.read
sig.replace
parameters=new_params
docstring/comment
role
nparams
/
self._nparams
top-level
test
non-ASCII
cases
test
test_normalization
comment
test
non-ASCII
characters
private
function
_Py_normalize_encoding
non-ASCII
letters
vague
sure
diff
simple
suggestion
import
top
level
function
used
code
test_imap4_host_default_value
IMAP4
empty
string
default
host
localhost
different
host
config
-1234567890
comment
tests
Windows
new
feature
Python
new
wrapper
link
bpo
wrapper
decorator
name
skip
message
new
skip
message
other
comment
PR
sys.platform.startswith
'win
skipInVenv
helpful
brief
comment
purpose
test
purpose
obvious
name
test
context
bpo
issue
PR
comments
Delete
parenmatch
other
class
imports
circular
import
problem
whitespace
comment
necessary
pretty
surprising
more
sense
comment
[
bug
report
]
[
bug
]
comment
safe
error
[
bug
]
http
//bugs.python.org/issue29808
case
necessary
'SimpleNamespace
Please
use
single
quotes
short
comment
warn_on_full_buffer
keyword-only
parameter
specific
reason
submodule
better
way
map
lambda
t
t
message
[
'authenticationfail
'loginviayourwebbrowser
[
]
]
unused
@
rcomer
Awesome
spot
eyes
+1
comment
matplotlib.use
future
developer
back
matplotlib.rcdefaults
thanks
grinning
behaviour
title
title
formatter
priority
lesson
__never__
new
feature
full
documentation
logic
ignore_index
suggestion
return
*
tp
/
*
tp
+
fp_plus_fn
+
variation
ignore_index
None
ignore_idx
=
ignore_index
due
issues
ignore_index_fn
iou_vector
torch.Tensor
>
torch.Tensor
ignore_idx
>
=
len
iou_vector
raise
ValueError
ignore_index
larger
length
IoU
vector
.format
ignore_idx
iou_vector
=
list
range
iou_vector
indices.remove
ignore_idx
return
iou_vector
[
]
return
MetricsLambda
ignore_index_fn
iou
suggestion
val
=
repr
val.__self__
mutation
class
many
different
names
dimension
full
parameters
test
cases
different
different
class
simpler
bit
afraid
lot
conditions
good
sign
suggestion
self._ranker
tp.Any
=
None
TODO
typing
self._config.ranker
nsga2
self._ranker
self._config.ranker
=
simple
NotImplementedError
f
Unknown
ranker
self._config.ranker
class
anything
mere
function
Aka
sort
memoization
function
better
clearer
API
python
.optimization
import
optimizerlib
optimizers
.optimization.optimizerlib
import
registry
other
proposition
IRC
Python
shim
cache_clear
thank
understand
noop
cache_clear
shim
path
something
suggestion
hasattr
util.get_linux_distro
cache_clear
util.get_linux_distro.cache_clear
tests
function
lru_cache
pytest.raises
CiTestCase
little
confusing
pytest
test
class
something
suggestion
class
TestMaybeB64Decode
Test
maybe_b64decode
helper
function
@
pytest.mark.parametrize
invalid_input
str
bytes
int
def
test_raises_error_on_non_bytes
invalid_input
maybe_b64decode
error
data
bytes
pytest.raises
TypeError
hc_helper.maybe_b64decode
invalid_input
@
pytest.mark.parametrize
[
data
b64
value
same
b
data
b
data
data
b64
value
base64.b64encode
b
data
b
data
]
test_happy_path
assert
==
hc_helper.maybe_b64decode
in_data
s/pytest.raises/self.assertRaises/
fun
comment
suggestion
random
breadcrumb
good
suggestion
Name
/path'
NETWORK_NAME_FILTER
=
r
^.+
/
*
previous
tarball
format
.tar.xz
wont
handle
.gz
build_dir
untracked
generated
supervisor
file
docker_args
]
equal
file
path
add
comment
condition
Imports
top
StrictRedis
method
fixture
clear
flush
minimum
comment
print
+1
committing
problem
similar
comment
..
Will
table
POLICER
different
keys
TABLE
global
namespace
DB
Prefer
docstrings
comments
depreciation
error
message
underscore
binary
Prefer
docstrings
comments
docstrings
comments
Delete
blank
line
blank
lines
functions
standard
user
forget
project
id
CH
concern
environment
variables
project_id
error
user
parameter
wrong
dataset
project
environment
variable
developer
environment
variable
habit
drive-backed
table
EmailNotificationTest.setUp
GDrive
aspect
regular
table
fake_dict
better
test
resources
feasible
comment
special
requirements
test
e.g
account
access
particular
spreadsheet
existence
table
spreadsheet
comment
sure
Iterable
[
Any
]
time
NamedType
try
SlackApiError
client.conversations_list
fails
SlackApiError
case
unit
import
validation.main.py
valid
slack_channel
suggestion
def
_is_channel_available
Test
Slack
channel
available
return
client
_get_slack_client
channel_name
=
_get_slack_channel_name
try
response
=
client.conversations_list
limit=sys.maxsize
max
size
hardcoded
int
response.status_code
channel
response.data
[
'channels
]
channel
]
==
channel_name
return
True
SlackApiError
e
logging.error
e
return
False
helpful
brief
comment
ImportError
branch
chance
thing
pmd
structure
Can
comment
try/except
Reference
issue
comment
try/except
Reference
issue
explanatory
comments
nit
file_handle
fuzzer_handle
__str__
str
call
comment
type
bytes
such
python
cert_contents
compute_metadata.get
'instance/attributes/tls-cert
.encode
str
necessary
single
ndb.put_multi
fuzzers
end
individual
put
nit
Applies
binaries
coverage
own
cov
ft
comment
description
Done
comment
low
temperature
Same
other
comments
fine
few
jobs
discussed
duplicated
frame
stack
Could
TODO
CL
OK
ball
rolling
functionality
change
comment
line
preferred
quotation
marks
*
Origin
QuotesBear
Section
all.python
issue
following
patch
diff
a/plugins/coala_lowercase_c.py
+++
b/plugins/coala_lowercase_c.py
@
@
-8,7
+8,7
@
coala
lower
case
c.
def
callback_message
msg
emots
[
angry
+
=
[
angry
disappointed
triumph
match_coala
=
re.search
r
^|
[
^\w
]
C+
[
Oo
]
+
[
Aa
]
+
[
Ll
]
+
[
Aa
]
+
[
^\w
]
preferred
quotation
marks
*
Origin
QuotesBear
Section
all.python
issue
following
patch
diff
a/plugins/coala_lowercase_c.py
+++
b/plugins/coala_lowercase_c.py
@
@
-8,7
+8,7
@
coala
lower
case
c.
def
callback_message
msg
emots
[
angry
+
=
[
angry
disappointed
triumph
match_coala
=
re.search
r
^|
[
^\w
]
C+
[
Oo
]
+
[
Aa
]
+
[
Ll
]
+
[
Aa
]
+
[
^\w
]
preferred
quotation
marks
*
Origin
QuotesBear
Section
all.python
issue
following
patch
diff
a/plugins/coala_lowercase_c.py
+++
b/plugins/coala_lowercase_c.py
@
@
-5,7
+5,7
@
@
class
Coala_lowercase_c
BotPlugin
coala
lower
case
c.
+
coala
lower
case
c.
def
callback_message
msg
emots
[
angry
preferred
quotation
marks
*
Origin
QuotesBear
Section
all.python
issue
following
patch
diff
a/plugins/coala_lowercase_c.py
+++
b/plugins/coala_lowercase_c.py
@
@
-8,7
+8,7
@
coala
lower
case
c.
def
callback_message
msg
emots
[
angry
+
=
[
angry
disappointed
triumph
match_coala
=
re.search
r
^|
[
^\w
]
C+
[
Oo
]
+
[
Aa
]
+
[
Ll
]
+
[
Aa
]
+
[
^\w
]
Line
longer
Origin
LineLengthBear
Section
all.linelength
*
Line
longer
Origin
LineLengthBear
Section
all.linelength
E501
line
characters
Origin
PycodestyleBear
E501
Section
E501
line
characters
Origin
PycodestyleBear
E501
Section
more
line
properties
easier
different
case
constructor
instance
self.traintuples_keys
=
asset.traintuples
hasattr
asset
'traintuples
other
solution
required
properties
ComputePlan
class
traintuple_keys
CI
full
end
tests
deployed
backend
suggestion
See
https
//github.com/intel/dffml/issues/816
numpy
>
=1.16.2
suggestion
See
https
//github.com/intel/dffml/issues/816
numpy
>
=1.16.4
suggestion
See
https
//github.com/intel/dffml/issues/816
INSTALL_REQUIRES
=
[
numpy
>
=1.16.4
]
+
suggestion
See
https
//github.com/intel/dffml/issues/816
numpy
>
=1.16.4
suggestion
See
https
//github.com/intel/dffml/issues/816
numpy
>
=1.16.4
suggestion
See
https
//github.com/intel/dffml/issues/816
numpy
>
=1.16.2
suggestion
See
https
//github.com/intel/dffml/issues/816
numpy
>
=1.16.2
suggestion
entrypoint
name
Indent
additional
spaces
[
flake8
E128
]
https
//lintlyci.github.io/Flake8Rules/rules/E128.html
@
drehak
pls
todo
msg
line
InitrdIncludes
msg
suggestion
url
=
https
//access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/configuring_basic_system_settings/
using-python3
noqa
E501
title
=
Difference
Python
versions
support
RHEL
more
releases
suggestion
RELEASES
=
TODO
bad
bad
hardcode
suggestion
RH
repositories
RHSM
RHUI
seatbelts
other
actors
Amazon-id
plugin
@
Skullman
tuple
<
class
>
comment
options
'split
suggestion
bulk
export
database
False
hack
config
non-standard
proyect
make-summaries-multilines
trick
make-summary-multi-line
Additional
information
User
argument
modern
suggestion
space
comment
submodule
difference
other
branch
Just
future
reference
comment
least
look
click
documentation
file
handling
sure
kind
things
better
way
type
return
value
format
Please
examples
other
parsers
https
//github.com/RedHatInsights/insights-core/blob/f58f26eb08bbea38fd4899e6b8a7eae056522c9f/insights/parsers/blkid.py
L76
look
https
//www.sphinx-doc.org/en/master/usage/extensions/example_google.html
Could
above
logic
comprehension
something
[
include
item
IncludeConfig
item
item
conf
]
documentation
loop
function
interface
necessary
self.patches
attribute
works
way
format
lines
different
others
more
ehtest
valid
line
original
logic
_parse_line
bug
double
confirm
result
lot
vishwanathjadhav
releaseVer
same
way
diff
a/insights/parsers/rhsm_releasever.py
+++
b/insights/parsers/rhsm_releasever.py
@
@
-43,13
+43,12
@
@
class
RhsmReleaseVer
JSONParser
super
RhsmReleaseVer
self
.parse_content
content
self.set
=
self.major
=
self.minor
=
None
rel_splits
[
]
'releaseVer
self.data
raise
SkipException
data
rel
=
self.data
[
'releaseVer
]
rel
None
rel_splits
rel.split
rel
=
self.data.get
'releaseVer
rel
None
+
raise
SkipException
data
+
rel_splits
rel.split
case
error
database
something
structure
conditions
fails
IntegrityError
Mind
FILTER_STAT_KEYS_TO_VALUES
[
should_filter
]
]
expression
KeyError
s
tsdb.incr
above
comment
concern
comment
helpful
model
fine
feature
gate
sort
whole
process
piece
data
imo
Same
comment
paginator
model
instances
result.data.get
order
order
starts
falsey
_nit_
constant
legibility
👍
Same
message.lower
loop
key_id
data
blob
function
discover
module
alias
fields
timeout
error
rule
async
task
sure
comment
trigger
serializer
clear
nit
extra
empty
lines
sure
no-op
post_comment
alias
certain
jobs
queues
group
hash
group
mutable
little
bit
difficult
top
level
key
comment
link
reference
tukey
fence
good
comment
//github.com/getsentry/sentry/pull/20412/files
r477411239
way
filters
new
conditions
subset
conditions
event
attributes
afaict
scttcper
simple
loop
call
point
stored
key
non-empty
example
key
=
six.text_type
self.public_key_object
trusted_relay
org.get_option
sentry
trusted-relays
[
]
trusted_relay
trusted_relay.get
public_key
key
return
True
return
False
Does
bunch
group
ids
metric
lot
data
sure
best
way
data
kind
action
ie
bookmarking
user
etc
projects
organization
query
nice
aspect
frontend
installation
page
button
something
lines
comment
accurate
more
ok
good
call
certain
default
values
leeandher
finalize_upload
value
error
sense
try/except
case
leeandher
Nit
hasattr
property
exists
self.date_field
getattr
i
good
idea
data
kind
lot
fields
helpful
action
couple
top
head
nice
namedtuple
something
Multiple
returns
python
bit
confusing
match
groups
context
nice
comment
^
TODO
keys
necessary
odd
statement
purpose
comment
new
list
container
user
request
download
query
parameter
file
ExportedData
Stole
https
//github.com/getsentry/snuba/blob/e15c8c51140d55fa87772c150b62a11dc9bedee7/snuba/processor.py
L86
message
ambiguous
message
value
docstring
return
type
impersonation
other
parts
application
other
usage
case
insensitive
Everythign
exact
sourceMappingURL
case
matter
day
source
code
browsers
space
optional
optional
//
@
syntax
valid
legacy
anything
newer
>
//
@
syntax
valid
legacy
anything
newer
Sure
>
space
//
optional
optional
anyone
complain
padding
rjust
length
string
padding
size
suggestion
r
same
suggestion
r
https
python
stuff
escapes
link
suggestion
depends_on
mpi
MPI
link
dependency
@
ferdonline
option
latest
neuron
version
git=git
suggestion
TODO
IME
package
paths
x
==
nitpick
comment
line
bulid_command
slurmworkermanager
command
i
fine
flag
comment
calculation
raw_to_block_has_append
calculation
>
None
schema
blocks
None
comment
append
None
larger
max
memory
system
things
comment
Maybe
comment
filesystem
need
upload
results
suggestion
import
import
tempfile
unittest.mock
import
patch
import
please
EnvironmentError
second
python3.3
alias
OSError
https
//docs.python.org/3.8/library/exceptions.html
EnvironmentError
Should
OSError
possible
comment
OSError
thinking
readable
fashion
little
comment
awhile
nerd_face
new
option
Did
example
start.sh
May
documentation
Could
comments
method
score
None
good
comment
/
GraphQL
implementation
Part
problem
calls
data
slash
redirect
way
/
front-end
userSetUserSetting
able
anything
@
justin0022
suggestions
fine
/
nice
consistent
comment
change
email
block
comment
Could
comment
logic
block
comment
whitespace
operator
SyntaxError
invalid
syntax
<
br
>
blank
lines
class
function
definition
<
br
>
whitespace
bitwise
shift
operator
<
br
>
whitespace
operator
whitespace
operator
SyntaxError
invalid
syntax
<
br
>
blank
lines
class
function
definition
<
br
>
whitespace
bitwise
shift
operator
<
br
>
whitespace
operator
starting
position
circular
buffer
next
state
buffer
while
loop
inefficient
batch_idx
len
exp
index
mapping
last
exp
buffer
specific
exception
DSSException
more
context
print
f'Dispatch
Job
ID
Whoa
specific
i.e.
result_list
=
[
]
type
typing.Sequence
[
dict
]
bundles
value
print
statement
error
valid
True
more
pythonic
Please
comment
lines
checkout
misconfiguration
reminder
TODO
connection
error
new_height
pre-commit
height
election
new_height
validator
set
new_height
+
会有这种情况吗？
有range，但是levels为空
这里为啥直接break
break之后没加锁直接返回True了
bit
code
axis
argument
equivalent
sample
change
matches
description
useful
thing
channel
row_axis
col_axis
case
current
code
good
Typo
space
uuid
description
terse
respect
unexpected
signature
i
Please
comment
sequences
system
index
Please
line
several
Any
preference
type
good-enough
catch-all
ValueError
docstring
error
message
wrong
catch-all
exceptions
specific
class
statement
comment
helpful
waffle
flag
ticket
JIRA
temporary
stage
roll-out
plan
comment
ticket
details
ticket
true
waffle
flag
comment
value
//github.com/wemake-services/wemake-python-styleguide/blob/dc96ff3dea3c5b759cd93bbb681702673b7b607f/wemake_python_styleguide/options/defaults.py
L55
Wrong
Inline
comment
awesome
TODO
@
sobolevn
refactor
single
visitor
Currently
values
bad
strings
tuples
other
primitives
wrong
values
nit
people
dataset
labels
hyphen
Invalid
value
other
validation
error
messages
>
last
label
clone
rewind
Done
comment
tree
structure
chosen
HPO
term
hpo_id
ancestor
children
terms
comment
code
Suggest
imports
line
comment
boolean
variable
x
=
False
type
check
error
Codacy
sense
context
types
objects
rare
type
something
specific
codacy
codacy
test
line
following
comment
end
line
pylint
disable=unidiomatic-typecheck
same
comment
above
python
decorators
'allow_negative_index
]
=
tuple
str
decorators
'allow_negative_index
]
.args
code
difficult
choice
variables
names
i
j
integer
indices
actual
elements
iterable
container
templates
pseudo-code
First
process
unions
Next
process
templates
=
*
dtypes
t
templates
arg_codes
replace_template
c
t
c
arg_codes
t.args
function
new
function
signature
certain
template
T
possible
values
Please
something
comments
section
step
please
TODO
rmahjoubi
changes
sufficient
improvement
TODO
comment
Forgotten
comment
@
EmilyBourne
@
comment
issue
long
time
meaning
whole
point
rid
field
self._get_name
path
fix
comment
TODO
call
logic
filters
PythonSetup.interpreter_constraints
filters
sure
PIC
modification
paths
Files
relative
buildroot
Resources
relative
srcroot
comment
difference
isinstance
test
has_resources
true
Resources
targets
exact
type
test
correct
comment
distinction
Files
target
sources
buildroot/srcroot
dichotomy
design
Field
additional
field
types
validations
Someone
singular
vs
plural
Field
sticking
point
installation
additional
field
types
plugins
Field
last
comment
https
//github.com/pantsbuild/pants/issues/4535
issuecomment-380654441
more
context
output
EngineDisplay
stdout/err
function
FFI
call
TODO
fine
minor
optimization
matter
TODO
effect
HydratedTargets
signature
fast_test
source
globs
targets
previous
formulation
BUILD
files
test
result
Address
effect
tests
able
source
glob
expansion
behaviour
Optional.of
TestResult
other
newtype
coordinator_of_tests
filtering
little
bit
TODO/NB
coordinator_of_tests
nice
filtering
closer
python
test_results
=
yield
[
Get
TestResult
HydratedTarget
tgt
tgt
targets
build_config.is_union_member
TestTarget
tgt
tgt.adaptor
Thank
TODO
dead
code
Sorry
hard
error
flag
v2
no-v1
nit
whitespace
ExceptionSink
commands
options
little
easier
python_native_code.py
@
rule
CToolchain
[
Select
PythonNativeCode
]
def
select_c_toolchain_for_local_dist_compilation
python_native_code
llvm_c_toolchain
=
yield
Get
LLVMCToolchain
NativeToolchain
python_native_code.native_toolchain
yield
llvm_c_toolchain.c_toolchain
@
rule
CppToolchain
[
Select
PythonNativeCode
]
def
select_cpp_toolchain_for_local_dist_compilation
python_native_code
llvm_cpp_toolchain
=
yield
Get
LLVMCppToolchain
NativeToolchain
python_native_code.native_toolchain
yield
engine
matches
Exactly
constraint
type-checking
@
rule
return
types
edits
comment
@
rule
CToolchain
[
Select
PythonNativeCode
]
def
select_c_toolchain_for_local_dist_compilation
python_native_code
return
Get
LLVMCToolchain
NativeToolchain
python_native_code.native_toolchain
@
rule
CppToolchain
[
Select
PythonNativeCode
]
def
select_cpp_toolchain_for_local_dist_compilation
python_native_code
return
Get
LLVMCppToolchain
NativeToolchain
python_native_code.native_toolchain
error
message
excerpt
./pants
test
tests/python/pants_test/backend/python/tasks
python_native_code_testing
-vsk
test_python_create_platform_specific_distribution
E
ExecutionError
unexpected
Throw
state
s
E
Select
<
pants.backend.python.subsystems.python_native_code.PythonNativeCode
object
>
=SetupPyNativeTools
E
Noop
No
task
available
value
@
stuhood
correct
Exactly
type
constraint
rule
results
something
Nit
type
ignore
preferred
specific
error
e.g
type
ignore
[
call-args
]
ignore
build-support/bin/mypy.py
look
code
comments
self.name
bit
strange
comment
appropriate
thing
good
explicit
property
tool
name
option
task
multiple
places
subsystem
distribution
message
cacheable
purpose
comment
comments
ticket
great
worth
CI
burn
helpful
comment
describes
approach
lie
isort
run
Python
Python
version
flake8
bandit
confident
user
Python
machine
Pants
constraints
upcoming
isort
same
constraint
happy
change
dependent_target_constraint
class
constant
source_target_constraint
override
line
class-level
bits
overridden
comment
above
TODO
line
lockstep
comment
import
specific
Will
TODO
passthru
args
https
//github.com/pantsbuild/pants/issues/8579
functional
style
filter
predicate
tgts
map
insert_or_append_tgt_by_platform
tgts
hard
comment
code
Target
task
direction
time
awareness
Task-specific
dependencies
exports
Task-level
concern
jvm_compile
needs
exports
strict_deps
mean
other
Tasks
more
general
theory
gen
target
sure
sense
review
unit
tests
method
new
functionality
hack
https
//github.com/pantsbuild/pants/pull/6039/files
diff-3d23a0b5af958441c095d5acd551ac16L58
@
illicitonion
definitive
take
hack
comment
shot
file
issue
hack
Afaict
cleanup
extraneous
purpose
PR
nice
cleanup
logic
fine
function
readable/maintainable
bit
something
lines
renamed
function
name
+
docstring
def
inject_synthetic_dist_requirements
build_graph
local_built_dists
synthetic_address
binary_tgt=None
synthetic
PythonRequirement
objects
PythonDistribution
BuildGraph
def
should_create_req
bin_tgt
loc
bin_tgt
return
True
<
Add
comment
necessary
return
[
tgt.id
loc
tgt
bin_tgt.closure
]
def
python_requirement_from_wheel
path
base
=
os.path.basename
path
whl_dir
=
os.path.dirname
path
whl_metadata
=
base.split
'-
=
'=='.join
[
]
]
]
PythonRequirement
req_name
repository=whl_dir
local_whl_reqs
=
[
python_requirement_from_wheel
whl_location
whl_location
local_built_dists
should_create_req
binary_tgt
whl_location
]
local_whl_reqs
return
]
addr
=
Address.parse
synthetic_address
build_graph.inject_synthetic_target
addr
PythonRequirementLibrary
requirements=local_whl_reqs
return
[
build_graph.get_target
addr
new
block
comment
requests
docs
https
//requests.readthedocs.io/en/master/user/advanced/
ssl-cert-verification
suggestion
bool
True
iff
snapshot
source
roots
date
method
boolean
Similar
PexInterpreterContraints
logic
_also_
looks
something
CreatePex
factory
function
same
Great
documentation
mapping
reason
dictionaries
duplicate
keys
multiple
s
example
helpful
e.g
warnings-filters=
DeprecationWarning
option
ignore
great
logic
MirroredTargetOptionMixin
harder
future
Could
method
comment
native_build_step_settings.py
python
selected_variant
=
self._native_build_step_settings.get_toolchain_variant_for_target
native_library_target
return
self._request_single
toolchain_type
self._toolchain_variant_request
selected_variant
Pierre
thank
minor
question
comment
SchedulerSession
Session
scheduler
function
materialize_directories
scheduler
session
need
function
materialize_directories
scheduler
session
SchedulerSession
function
raw
string
nice
diff
original
values
total
workers
total
nodes
clearer
itertools.compress
itertools
import
compress
result
=
list
compress
to_kill
Filters
iterable
bool
values
second
minor
previous
dcc.Markdown
file
pp
folder
previous
comment
rarfiles
unwanted
files
solution
excessive
results
loop
iteration
sure
https
//stackoverflow.com/a/13145419/7597273
max
tuple
highest
score
result
score
first
item
best_result
=
max
iteritems
wanted_results
key=operator.itemgetter
]
opinion
best_result
sorted_results
cleaner
effective
more
results
same
score
scores
life
repeat
Thanks
assert
RESULT
Line
kind
Model
class
string
elemental
cmake
system
libraries
fails
Power
system
main
documentation
FindGMP
others
cmake
directory
thanks
Good
point
whole
variant
if-statement
part
PR
P.S
difference
opencl
opencv
opengl
curious
opencl
package
next
week
user
xl
PR
xl
other
versions
boost
i.e.
only
version
XL
patch
versions
other
regular
xl
short
comment
i.e
external
MPI
bg-q
libs
lib
folder
py-gtk
comment
docstring
top
users
py-pygobject
Python-based
GTK3
current
behaviour
happy
new
build_targets
reason
other
packages
comment
FindInMap
array
values
validation
*
_layer
=
viewer.add_
*
data
canonical
form
napari
possible
aspect
added
layer
e.g
assert
image_layer.dims.ndim
Similar
comment
add_layer_type
private
resolves
view_layer_by_type
*
kwargs
need
special
handle
ndisplay
note
offset
eg
vispy
places
coordinates
corners
pixel
centers
data
values
pixel
centers
data
space
space
way
more
concise
Same
comment
—
use
skimage.util.img_as_ubyte
comment
comment
necessary
need
class
comment
comment
warning
filter
scipy
Could
comment
+1
comment
code
big
level
usual
comment
:-1
converts
numpy-style
coordinates
dims
model
concept
dimensions
function
information
right
dimensions
leading
dimension
TODO
useful
comment
Please
comments
space
eq
operator
aws
disable_static_collector
args.settings
'static_collector
settings
is_devstack
==
True
mistake
something
change
following
changes
Please
comment
Please
comment
change
Wrong
docstring
style
>
Wrong
style
Fixed
Sphinx
index
line
comments
same
comment
useful
suggestion
Note
weights
comment
anything
comment
something
'sbd
built-in
part
spacy
rule-based
sentence
splitting
true
comment
default
value
tqdm
magic
number
comment
Docstrings
double
quotes
OrderedDict
result
=
OrderedDict
function
need
underscore
name
inputs
list
empty
tuples
updated
>
package
simple
philosophy
CORS
use
cases
domain
different
headers
methods
default
submission
cookies
domains
disabled
due
security
implications
documentation
credential
’
ed
requests
sure
sort
CSRF
protection
sanic_cors
Sweet
separate
request
variable
dictionary
second
argument
readable
way
part
request
user
field
likely
something
parameters
best
answer
argument
ourselves
urlsplit
path
component
http
//chat.zulip.org/user_uploads/foo
/user_uploads/foo
user_uploads/foo
code
block
quote
paragraph
processors
python-markdown
ordering
Maybe
worth
block
comment
top
ordering
upstream
places
behavior
adjusting
places
comment
rename
different
DataFrames
original
labels
name
Ah
okay
same
Spark
column
Koalas
column
labels
different
..
shell
short
comment
@
rxin
comment
top
Shall
short
comment
resolved_copy
comment
resolved_copy
opposite
case
example
kser.div
np.nan
comment
koalas
ks
other
data
types
such
BooleanType
DateType
TimestampType
comment
useful
API
field
API
limitations
frontend
DateForm
day
month
year
field
comment
th
conditon
comment
form
forms
]
long
overdue
thanks
one
false
positive
Scala
code
D
suggestion
def
get_configuration
section
str
key
str
>
Optional
[
]
change
default
snowflake_conn_id
previous
default
worth
default
note
UPDATING.md
suggestion
'WTforms
TODO
Remove
https
//github.com/dpgaspar/Flask-AppBuilder/issues/1356
WDYT
@
potiuk
track
quick
fixes
issues
other
libraries
deps
possible
TODO
chance
other
fix
other
option
Connection
code
CLI
code
httplib2
things
'httplib2~=0.9
means
>
=0.9
==0.9
*
circular
dep
much
time
one
~
default
value
fine
fallback
combinations
problem
tests
operator
configuration
variable
imports
works
shrug
state
state
errant
delete
suggestion
counter
same
results
simpler
code
Counter
task.state
task
upstream_tasks_sorted
results
way
counter
[
State.SKIPPED
]
counter
[
State.UPSTREAM_FAILED
]
suggestion
login
=
None
type
None
Python
annotations
variables
version
invalid
annotations
invalid
annotations
comment
helpful
dependency
code
comment
helpful
important
current
pylint
version
suggestion
binary
TODO
SSZ
reminder
idiomatic
way
python
pytest.raises
ValueError
match=message
validate_enode_uri
rationale
change
comment
keys
out
date
i
%
*
number
greater
equal
*
comment
clear
trio
version
suggestion
API
client
url
self-hosted
resources
resource.filetype
==
form._fields.get
'url
.data
suggestion
self.assert400
response
possible
arguments
signature
functions
comment
fine
array
bit
weird
new_excel_file
create
new
file
test
end
test
different
fpath
new
test
and/or
rename
first
test
obvious
TODO
back
mypyc
path
relative
current
working
directory
Style
nit
move
separate
line
Added
comment
Aarg
wild
goose
chase
name
decorator_call_hook
suggestion
sys.version_info
=
explanatory
comment
low-level
integers
values
values
values
possible
least
contexts
good
way
right
TODO
comment
new
analyzer
dangerous
error
special
code
unknown
names
TBH
logic
comment
error
message
self.foo
name
attribute
Attribute
foo
nice
import
mypy.fscache
file
callback
file
contents
example
dependency
injection
rid
decode_python_encoding
DecodeError
imports
Style
nit
docstrings
variables
Please
comment
definition
Add
comment
suggestion
current
class
suggestion
interested
first
Base
suggestion
other
highest
bases
suggestion
runtime
Base.__init_subclass__
TODO
_is_subtype
trace
let
line
block
tear_down
place
easier
comment
exceptions
None
potential
bug
cause
trouble
possible
non-
None
value
merge
least
TODO
comment
improvement
crawl_up
comment
function
header
docstring
exception
things
pear-shaped
Please
short
comment
check
fine-grained
dependencies
something
Add
comment
sense
typ
file
console_entry
repetition
download-mypyc-wheels
script
current
directory
checkout
script
comment
Hmm
good
point
variable
options
line
overshadows
options
outer
scope
line
option
option
line
one-letter
o
fine
name
context
same
line
optional
argument
constructor
much
cleaner
parameter
implicit
constructor
[
commit
]
https
//github.com/python/mypy/commit/6de11e10b3af3ec0b974a7f69664d63f337003ee
fine
Add
comment
bit
surprising
rid
special
case
A
]
Instance
new
check
below
Instance
test
case
comment
correct
cleaner
info.get
attr.name
None
check
try/except
something
other
tuple
example
fine
runtime
python
try
Exception
'foo
'bar
Exception
b
]
print
b
prints
bar
Unsupported
exception
handler
syntax
specific
warning
item.name
ast27.Tuple
ast27.List
other
comments
better
consistency
LoadInt
constant
value
comment
new_messages
new
messages
side
effect
method
something
explicit
Document
attribute
first
item
problems
overloaded
methods
good
comment
follow-up
issue
fix
trivial
comment
Other
explicit
type
comment
List
[
str
]
self-check
worth
comment
warnings
<
>
python-only
please
comment
config.py
file
MeasurementStats
custom_types
config_addon.py
equivalent
field
config.py
WaveformInfo
lines
present
tests
python
class
SessionReference
object
lots
stuff
def
__init__
encoding='windows-1251
self._session_number
=
session_number
self._library
=
_library_singleton.get
last
line
Seems
strange
lower
final
python_name
reasoning
Most
private
unnecessary
code
consistency
ok
comment
nit
sort
i
many
comment
line
backends
jaeger
resources
service.name
people
same
issue
suggestion
other
resource
lowercase
period
other
docstrings
Same
thing
other
args/returns
PR
sense
PEP8
bit
text
chars
different
text
widths
same
file
unnecessary
hassle
obvious
benefit
bit
exception
Do
_empty_events
_empty_links
same
problem
suggestion
Generic
method
metric
value
https
//github.com/open-telemetry/opentelemetry-python/pull/466/files
r390487500
inconsistent
rest
codebase
enum
Just
types
mapping
time
corresponding
enums
Python
types
first-class
objects
int
bits
bits
version
integer
float
python
skills
comment
more
collection
pass
exit
type
aliases
helpful
real
type
e.g
types.py
reshape
fine
framework-agnostic
batch_length
favor
-1
spaces
keyword
arguments
spaces
operators
necessary
suggestion
steps
context
numceps
=
features.shape
pylint
disable=E0633
suggestion
def
auth_oidc
params
=
self.get_options
'jwt
'mount_point
params
]
=
params.pop
'role_id
self.hvac_has_auth_methods
hasattr
self.client.auth
'oidc
hasattr
self.client.auth.oidc
response
=
self.client.auth.oidc.jwt_login
*
*
params
AnsibleError
OIDC
authentication
HVAC
version
higher
client
token
JWT/OIDC
login
https
//github.com/hvac/hvac/issues/644
=
response
[
'auth
]
[
'client_token
]
suggestion
def
auth_jwt
params
=
self.get_options
'jwt
'mount_point
params
]
=
params.pop
'role_id
self.hvac_has_auth_methods
hasattr
self.client.auth
'jwt
hasattr
self.client.auth.jwt
response
=
self.client.auth.jwt.jwt_login
*
*
params
AnsibleError
JWT
authentication
HVAC
version
higher
client
token
JWT/OIDC
login
https
//github.com/hvac/hvac/issues/644
=
response
[
'auth
]
[
'client_token
]
suggestion
state
present
line
need
loop
nice
specifier
sets
i.e
>
=3.6.2
such
specifier
sets
past
python_version
future
pkg_resources
suggestion
def
expected_version
current
str
str
>
bool
pkg_resources
regular
requirement
string
x
serves
requirement
name
current
pkg_resources.Requirement.parse
f
amounts
invoice_lines
suggestion
elem.amount
=
sum
'price_subtotal
suggestion
Done
Mark
todo
versions
=
TransferStatusEnum.COMPLETE
something
effect
refspec
real
more
review
number
least
comment
actual
refspec
intention
/bin/cp
clear
Let
comments
copy
test
assert
..
AssertTrue
AssertFalse
name
variable
impression
value
container
id
CONTAINER_ID_ENV_VARIABLE
similar
add
comments
default
value
comment
comment
columns
lines
suggestion
attempts
retry
suggestion
return
True
True
mistaken
current
code
return
False
matter
value
attempts
retry
attempts
=
retry
old
version
attempts
retry
behavior
change
retry
==
attempts
other
comment
annotations
parameters
core
core
add
comment
stand
Could
constant
easier
Same
eh
..
something
dramatic
django
@
anomam
run_parallel_calculations=False|True
tests
something
optional
xfail
reason
windows
failures
python
conftest
import
platform_is_windows
pytest.mark.parametrize
'run_parallel_calculations
[
False
pytest.param
True
marks=pytest.mark.xfail
platform_is_windows
def
test_pvfactors_timeseries
run_parallel_calculations
test
arg
long
time
Returns
Location
time
interest
table
document
line
length
OK
complaining
lines
noqa
E501
code
comment
line
Does
line
lambda
x
list
float
x.strip
[
]
.split
sure
pros/cons
np.array
list
justified
opening
parenthesis
space
indent
line
opening
parenthesis
readability
rid
empty
else
block
other
documentation
Change
attribute
name
note
whats
new
old
name
forecast.rst
documentation
particular
reason
assert
data.empty
detailed
check
data.empty
sufficient
suggestion
np.logical_and
ee
>
Does
information
Please
comment
Python
pickling
unpickling
objects
file
binary
text
place
open
calls
pickle
loads
dumps
mode
reading
rb
mode
wb
comment
obsolete
comment
extension
points
several
times
initialisation
termination
Might
worth
comment
additions
userguide
translators
comment
line
Translators
message
status
bar
clipboard
values
defaults
config
spec
true
good
comments
intent
list
reason
values
config
Please
comment
UIA
implementation
bad
AttributeError
source/core.py
line
appArgs.configPath
comment
suggestion
>
Dict
[
Location
Location
apparent
apparent
..
metadata
yeah
i
compilation
context
mean
small
doc
suggestion
TODO
remove
months
following
check
compatibility
config
file
suggestion
print
Warning
DOMAIN_ANALYZER_WHITELISTED_DOMAINS
Please
update
timesketch.conf
suggestion
@
pytest.mark.parametrize
interface
qml.qnodes.decorator.ALLOWED_INTERFACES
@
pytest.mark.usefixtures
skip_if_no_torch_support
skip_if_no_tf_support
failing
tests
smile
useful
error
good
TODO
suggestion
objective
function
flattened
parameter
array
objective_fn_flat
=
lambda
x_flat
gen
objective_fn
unflatten
x_flat
x
generators=gen
case
above
principle
yes
_flatten
function
PR
python
console
formatting
line
>
>
>
output
>
>
>
line
jupyter
notebook
cell
print
statements
order
different
>
>
>
d_occ_orbitals
active_orbitals
gen_active_space
'./pyscf/sto-3g
d_occ_indices
doubly-occupied
molecular
orbitals
]
>
>
>
active
molecular
orbitals
]
>
>
*
len
active_indices
number
qubits
simulation
Todo
heisenberg_obs
class
method
static
method
'hack
@
dhermes
Imports
top-level
source
code
necessary
import
cycles
surprising
len
df
len
list
df
Ditto
unittest.skipIf
test
pandas
Import
classes
partitioned_column
names
directory
file
os.walk
dfs
search
test
current
master
binary
operations
index
get_dtypes
empty
sequence
comment
if-else
statement
scary
others
Please
suggestion
TODO
handle
tuple
case
Series.__getitem__
isinstance
key
tuple
good
temporary
solution
future
better
way
series
TODO
issue